[
  {
    "id":"neg-d21-0",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04166",
    "b_title":[
      "On Two Parameter Time-Changed Poisson Random Fields with Drifts"
    ],
    "b_abstract":[
      "We study the composition of bivariate L\\'evy process with bivariate inverse\nsubordinator. The explicit expressions for its dispersion and auto correlation\nmatrices are obtained. Also, the time-changed two parameter L\\'evy processes\nwith rectangular increments are studied. We introduce some time-changed\nvariants of the Poisson random field in plane with and without drift, and\nderive the associated fractional differential equations for their\ndistributions. Later, we consider some time-changed L\\'evy processes where the\ntime-changing components are two parameter Poisson random fields with drifts.\nMoreover, two parameter coordinatewise semigroup operators associated with some\nof the introduced processes are discussed."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.09176",
    "c_title":[
      "Existence of Periodic and Stationary Solutions to Distribution-Dependent\n  SDEs"
    ],
    "c_abstract":[
      "We investigate the periodic and stationary solutions of\ndistribution-dependent stochastic differential equations. While generally, the\nsemigroups associated with the equations are nonlinear, we show that the\nmethods of weak convergence and Lyapunov functions can be combined to give\nefficient criteria for the existence of periodic and stationary solutions.\nConcrete examples are presented to illustrate the novel criteria."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-1",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18931",
    "b_title":[
      "Axion Emission from Proton Cooper Pairs in Neutron Stars"
    ],
    "b_abstract":[
      "We investigate axion emission from singlet proton Cooper pairs in neutron\nstars, a process that dominates axion emission in young neutron stars in the\nKSVZ model. By re-deriving its emissivity, we confirm consistency with most\nexisting literature, except for a recent study that exhibits a different\ndependence on the effective mass. This discrepancy results in more than an\norder-of-magnitude deviation in emissivity, significantly impacting constraints\non the KSVZ axion from the cooling observations of the Cassiopeia A neutron\nstar. Furthermore, we examine uncertainties arising from neutron-star equations\nof state and their role in the discrepancy, finding that the large deviation\npersists regardless of the choice of equations of state."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.10465",
    "c_title":[
      "Pion transverse charge density from $e^+$$e^-$ annihilation data and\n  logarithmic dispersion relations"
    ],
    "c_abstract":[
      "The transverse charge density of the pion is extracted from a dispersive\nanalysis of the $e^+e^- \\rightarrow \\pi^+\\pi^-$ exclusive annihilation data. A\nlogarithmic dispersion relation is used to compute the unknown phase of the\ntimelike pion form factor from the modulus obtained from the annihilation cross\nsection. The method is model-independent and permits quantitative uncertainty\nestimates. The density is obtained with few-percent accuracy down to $b \\sim\n0.1$ fm; at smaller distances it depends qualitatively on the assumed\nhigh-energy behavior of the timelike form factor. Implications for pion\nstructure and the relevance of pQCD asymptotics are discussed."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-2",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01833",
    "b_title":[
      "Impact of charge transfer excitons on unidirectional exciton transport\n  in lateral TMD heterostructures"
    ],
    "b_abstract":[
      "Lateral heterostructures built of monolayers of transition metal\ndichalcogenides (TMDs) are characterized by a thin 1D interface exhibiting a\nlarge energy offset. Recently, the formation of spatially separated\ncharge-transfer (CT) excitons at the interface has been demonstrated. The\ntechnologically important exciton propagation across the interface and the\nimpact of CT excitons has remained in the dark so far. In this work, we\nmicroscopically investigate the spatiotemporal exciton dynamics in the\nexemplary hBN-encapsulated WSe$_2$-MoSe$_2$ lateral heterostructure and reveal\na highly interesting interplay of energy offset-driven unidirectional exciton\ndrift across the interface and efficient capture into energetically lower CT\nexcitons at the interface. This interplay triggers a counterintuitive thermal\ncontrol of exciton transport with a less efficient propagation at lower\ntemperatures - opposite to the behavior in conventional semiconductors. We\npredict clear signatures of this intriguing exciton propagation both in far-\nand near-field photoluminescence experiments. Our results present an important\nstep toward a microscopic understanding of the technologically relevant\nunidirectional exciton transport in lateral heterostructures."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.08611",
    "c_title":[
      "Spin-flip Scattering at a Chiral Interface of Helical Chains"
    ],
    "c_abstract":[
      "We investigate spin-flip scattering processes of electrons when they pass a\nchiral interface, which is the boundary between right- and left-handed\none-dimensional chain. We construct a minimal $p$-orbital model consisting of\nthe right- and left-handed one-dimensional threefold helical chains connected\nat $z=0$ with the nearest neighbor hopping and the spin-orbit coupling. The\ndynamics of spin-polarized wave packet passing through the interface, the\nGreen's functions, and electronic states near the interface are analyzed\nnumerically. We find that the microscopic structure of the interface is\nimportant and this strongly affects the local electronic orbital state. This in\naddition to the spin-orbit coupling determines whether the spin flip occurs or\nnot at the chiral interface and suggests a possible spin transport control by\nthe orbital configuration at the chiral interface."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-3",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11434",
    "b_title":[
      "The blazar PKS 0605-085 as the origin of the KM3-230213A ultra high\n  energy neutrino event"
    ],
    "b_abstract":[
      "The KM3Net Collaboration has recently reported on the observation of a\nremarkable event KM3-230213A that could have been produced by an ultra high\nenergy cosmic neutrino. The origin of this event is still unclear. In\nparticular, the cosmogenic neutrino scenario is not favoured due to the\nnon-observation of a similar event by the IceCube detector, and most galactic\nscenarios are disfavoured as well. We show that the blazar PKS 0605-085 is a\nviable source of the KM3-230213A event. In particular, even though this blazar\nis located at 2.4$^{\\circ}$ from the KM3-230213A event, the association between\nthe blazar and the event is not unlikely due to a sizable direction systematic\nuncertainty of $\\approx 1.5^{\\circ}$ reported by the KM3Net Collaboration.\nFurthermore, we show that the observation of a $\\approx$72 PeV neutrino from\nPKS 0605-085 is entirely possible given that a $\\approx$7.5 PeV neutrino could\nhave been observed from another blazar TXS 0506+056. Finally, we consider\n$\\gamma$-ray constraints on the number of observable neutrino events and show\nthat for the case of the external photon field production mechanism these\nconstraints could be relaxed due to the often-neglected effect of the\nisotropisation of the hadronically-produced electrons in the magnetic field of\nthe blob. We encourage further multi-wavelength observations of the blazar PKS\n0605-085."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17253",
    "c_title":[
      "r-Process Nucleosynthesis and Radioactively Powered Transients from\n  Magnetar Giant Flares"
    ],
    "c_abstract":[
      "We present nucleosynthesis and light-curve predictions for a new site of the\nrapid neutron capture process ($r$-process) from magnetar giant flares (GFs).\nMotivated by observations indicating baryon ejecta from GFs, Cehula et al.\n(2024) proposed mass ejection occurs after a shock is driven into the magnetar\ncrust during the GF. We confirm using nuclear reaction network calculations\nthat these ejecta synthesize moderate yields of third-peak $r$-process nuclei\nand more substantial yields of lighter $r$-nuclei, while leaving a sizable\nabundance of free neutrons in the outermost fastest expanding ejecta layers.\nThe final $r$-process mass fraction and distribution are sensitive to the\nrelative efficiencies of $\\alpha$-capture and $n$-capture freeze-outs. We use\nour nucleosynthesis output in a semi-analytic model to predict the light curves\nof novae breves, the transients following GFs powered by radioactive decay. For\na baryonic ejecta mass similar to that inferred of the 2004 Galactic GF from\nSGR 1806-20, we predict a peak UV\/optical luminosity of $\\sim\n10^{39}$-$10^{40}\\,\\rm erg\\,s^{-1}$ at $\\sim 10$-$15$ minutes, rendering such\nevents potentially detectable following a gamma-ray trigger by wide-field\ntransient monitors such as ULTRASAT\/UVEX to several Mpc. The peak luminosity\nand timescale of the transient increase with the GF strength due to the larger\nejecta mass. Although GFs likely contribute 1-10% of the total Galactic\n$r$-process budget, their short delay-times relative to star-formation make\nthem an attractive source to enrich the earliest generations of stars."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-4",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05561",
    "b_title":[
      "Test Case Generation for Dialogflow Task-Based Chatbots"
    ],
    "b_abstract":[
      "Chatbots are software typically embedded in Web and Mobile applications\ndesigned to assist the user in a plethora of activities, from chit-chatting to\ntask completion. They enable diverse forms of interactions, like text and voice\ncommands. As any software, even chatbots are susceptible to bugs, and their\npervasiveness in our lives, as well as the underlying technological\nadvancements, call for tailored quality assurance techniques. However, test\ncase generation techniques for conversational chatbots are still limited. In\nthis paper, we present Chatbot Test Generator (CTG), an automated testing\ntechnique designed for task-based chatbots. We conducted an experiment\ncomparing CTG with state-of-the-art BOTIUM and CHARM tools with seven chatbots,\nobserving that the test cases generated by CTG outperformed the competitors, in\nterms of robustness and effectiveness."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15441",
    "c_title":[
      "On the Effectiveness of Large Language Models in Writing Alloy Formulas"
    ],
    "c_abstract":[
      "Declarative specifications have a vital role to play in developing safe and\ndependable software systems. Writing specifications correctly, however, remains\nparticularly challenging. This paper presents a controlled experiment on using\nlarge language models (LLMs) to write declarative formulas in the well-known\nlanguage Alloy. Our use of LLMs is three-fold. One, we employ LLMs to write\ncomplete Alloy formulas from given natural language descriptions (in English).\nTwo, we employ LLMs to create alternative but equivalent formulas in Alloy with\nrespect to given Alloy formulas. Three, we employ LLMs to complete sketches of\nAlloy formulas and populate the holes in the sketches by synthesizing Alloy\nexpressions and operators so that the completed formulas accurately represent\nthe desired properties (that are given in natural language). We conduct the\nexperimental evaluation using 11 well-studied subject specifications and employ\ntwo popular LLMs, namely ChatGPT and DeepSeek. The experimental results show\nthat the LLMs generally perform well in synthesizing complete Alloy formulas\nfrom input properties given in natural language or in Alloy, and are able to\nenumerate multiple unique solutions. Moreover, the LLMs are also successful at\ncompleting given sketches of Alloy formulas with respect to natural language\ndescriptions of desired properties (without requiring test cases). We believe\nLLMs offer a very exciting advance in our ability to write specifications, and\ncan help make specifications take a pivotal role in software development and\nenhance our ability to build robust software."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-5",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02677",
    "b_title":[
      "Quality assurance and reporting for FLASH clinical trials:the experience\n  of the FEATHER trial"
    ],
    "b_abstract":[
      "Research on ultra-high dose rate (UHDR) radiation therapy has indicated its\npotential to spare normal tissue while maintaining equivalent tumor control\ncompared to conventional treatments. First clinical trials are underway. The\nrandomized phase II\/III FEATHER clinical trial at the Paul Scherrer Institute\nin collaboration with the University of Zurich Animal Hospital is one of the\nfirst curative domestic animal trials to be attempted, and it is designed to\nprovide a good example for human trials. However, the lack of standardized\nquality assurance (QA) guidelines for FLASH clinical trials presents a\nsignificant challenge in trial design. This work aims to demonstrate the\ndevelopment and testing of QA and reporting procedures implemented in the\nFEATHER clinical trial. We have expanded the clinical QA program to include\nUHDR-specific QA and additional patient-specific QA. Furthermore, we have\nmodified the monitor readout to enable time-resolved measurements, allowing\ndelivery log files to be used for dose and dose rate recalculations. Finally,\nwe developed a reporting strategy encompassing relevant parameters for\nretrospective studies. We evaluated our QA and reporting procedures with\nsimulated treatments. This testing confirmed that our QA procedures effectively\nensure the correct and safe delivery of the planned dose. Additionally, we\ndemonstrated that we could reconstruct the delivered dose and dose rate using\nthe delivery log files. We developed and used in practice a comprehensive QA\nand reporting protocol for a FLASH clinical trial at the Paul Scherrer\nInstitute. This work aims to establish guidelines and standardize reporting\npractices for future advancements in the FLASH-RT field."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.03731",
    "c_title":[
      "A Physiological-Model-Based Neural Network Framework for Blood Pressure\n  Estimation from Photoplethysmography Signals"
    ],
    "c_abstract":[
      "Continuous blood pressure (BP) estimation via photoplethysmography (PPG)\nremains a significant challenge, particularly in providing comprehensive\ncardiovascular insights for hypertensive complications. This study presents a\nnovel physiological model-based neural network (PMB-NN) framework for BP\nestimation from PPG signals, incorporating the identification of total\nperipheral resistance (TPR) and arterial compliance (AC) to enhance\nphysiological interpretability. Preliminary experimental results, obtained from\na single healthy participant under varying activity intensities, demonstrated\npromising accuracy, with a median root mean square error of 6.69 mmHg for\nsystolic BP and 3.26 mmHg for diastolic BP. The median (min, max) difference\nbetween estimated and measured TPR was 0.043 (0.024, 0.061) mmHg*s\/cm^3. As\nexpected, estimated TPR decreased with increasing activity intensity, while AC\nincreased within a physiologically plausible range (0.5-2.5 cm^3\/mmHg)."
    ],
    "c_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-6",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01344",
    "b_title":[
      "Machine Learning for Modeling Wireless Radio Metrics with Crowdsourced\n  Data and Local Environment Features"
    ],
    "b_abstract":[
      "This paper presents a suite of machine learning models, CRC-ML-Radio Metrics,\ndesigned for modeling RSRP, RSRQ, and RSSI wireless radio metrics in 4G\nenvironments. These models utilize crowdsourced data with local environmental\nfeatures to enhance prediction accuracy across both indoor at elevation and\noutdoor urban settings. They achieve RMSE performance of 9.76 to 11.69 dB for\nRSRP, 2.90 to 3.23 dB for RSRQ, and 9.50 to 10.36 dB for RSSI, evaluated on\nover 300,000 data points in the Toronto, Montreal, and Vancouver areas. These\nresults demonstrate the robustness and adaptability of the models, supporting\nprecise network planning and quality of service optimization in complex\nCanadian urban environments."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14652",
    "c_title":[
      "Decoupled SGDA for Games with Intermittent Strategy Communication"
    ],
    "c_abstract":[
      "We focus on reducing communication overhead in multiplayer games, where\nfrequently exchanging strategies between players is not feasible and players\nhave noisy or outdated strategies of the other players. We introduce Decoupled\nSGDA, a novel adaptation of Stochastic Gradient Descent Ascent (SGDA). In this\napproach, players independently update their strategies based on outdated\nopponent strategies, with periodic synchronization to align strategies. For\nStrongly-Convex-Strongly-Concave (SCSC) games, we demonstrate that Decoupled\nSGDA achieves near-optimal communication complexity comparable to the\nbest-known GDA rates. For weakly coupled games where the interaction between\nplayers is lower relative to the non-interactive part of the game, Decoupled\nSGDA significantly reduces communication costs compared to standard SGDA. Our\nfindings extend to multi-player games. To provide insights into the effect of\ncommunication frequency and convergence, we extensively study the convergence\nof Decoupled SGDA for quadratic minimax problems. Lastly, in settings where the\nnoise over the players is imbalanced, Decoupled SGDA significantly outperforms\nfederated minimax methods."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-7",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10370",
    "b_title":[
      "Explicit Formulas for the Alexander Polynomial of Pretzel Knots"
    ],
    "b_abstract":[
      "We provide explicit formulas for the Alexander polynomial of Pretzel knots\nand establish several immediate corollaries, including the characterization of\nPretzel knots with a trivial Alexander polynomial."
    ],
    "b_categories":[
      [
        "math.GT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11548",
    "c_title":[
      "Dijkgraaf-Witten invariant in topological $K$-theory"
    ],
    "c_abstract":[
      "Given a finite group $G$, we define a new invariant of odd-dimensional\noriented closed manifolds and call it the KDW invariant. This invariant is a\nDijkgraaf--Witten invariant in terms of $K$-theory. In this paper, we compute\nthe invariant of the Brieskorn homology spheres with\n$G=\\mathrm{PSL}_2(\\mathbb{F}_p)$. We should remark that, in this computational\nresult, the fundamental groups of the Brieskorn homology spheres and\n$\\mathrm{PSL}_2(\\mathbb{F}_p)$ are not nilpotent."
    ],
    "c_categories":[
      [
        "math.GT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-8",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12487",
    "b_title":[
      "$\\lambda$ and $\\rho$ trajectories for the doubly heavy baryons in the\n  diquark picture"
    ],
    "b_abstract":[
      "We present the explicit form of the Regge trajectory relations for the doubly\nheavy baryons $\\Xi_{QQ'}$ and $\\Omega_{QQ'}$ $(Q,Q'=b,c)$ in the diquark\npicture. Using the derived Regge trajectory relations, we estimate the masses\nof the $\\lambda$-excited states and the $\\rho$-excited states, which are\nconsistent with other theoretical predictions. Both the $\\lambda$-trajectories\nand $\\rho$-trajectories are discussed. We show that the $\\rho$-trajectories\nbehave differently from the $\\lambda$-trajectories. Specifically, the\n$\\rho$-trajectories behave as $M{\\sim}x_{\\rho}^{2\/3}$ $(x_{\\rho}=n_r,l)$,\nwhereas the $\\lambda$-trajectories follow $M{\\sim}x_{\\lambda}^{1\/2}$\n$(x_{\\lambda}=N_r,L)$. By using the obtained relations, the baryon Regge\ntrajectory provides a straightforward and easy method for estimating the\nspectra of both the $\\lambda$-excited states and $\\rho$-excited states."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.16648",
    "c_title":[
      "High-quality Peccei-Quinn symmetry from the interplay of vertical and\n  horizontal gauge symmetries"
    ],
    "c_abstract":[
      "We explore a class of axion models where an accidental $\\mathrm{U}(1)$\nPeccei-Quinn (PQ) symmetry automatically emerges from the interplay of vertical\n(grand-unified) and horizontal (flavor) gauge symmetries. Focusing on a\nspecific Pati-Salam realization, we analyze the quality of the PQ symmetry and\ndemonstrate that the model non-trivially reproduces the Standard Model flavor\nstructure. In the pre-inflationary PQ-breaking scenario, the axion mass window\nis predicted to be $m_a \\in [2 \\times 10^{-8}, 10^{-3}]\\,\\mathrm{eV}$. A\nhigh-quality axion, immune to the PQ quality problem, is obtained instead for\n$m_a \\gtrsim 0.01\\,\\mathrm{eV}$, corresponding to a post-inflationary\nPQ-breaking scenario. A distinctive feature of this setup is the presence of\nparametrically light fermions, known as anomalons, which are introduced to\ncancel the gauge anomalies of the flavor symmetry. For the most favorable\nvalues of the PQ-breaking scale needed to address the PQ quality problem, the\nanomalons are expected to have masses below the eV scale. We further\ninvestigate their cosmological production in the early universe, highlighting\nhow measurements of $\\Delta N_{\\rm eff}$ could serve as a low-energy probe of\nthe ultraviolet dynamics addressing the PQ quality problem."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-9",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06493",
    "b_title":[
      "Whole-Body Integrated Motion Planning for Aerial Manipulators"
    ],
    "b_abstract":[
      "Efficient motion planning for Aerial Manipulators (AMs) is essential for\ntackling complex manipulation tasks, yet achieving coupled trajectory planning\nremains challenging. In this work, we propose, to the best of our knowledge,\nthe first whole-body integrated motion planning framework for aerial\nmanipulators, which is facilitated by an improved Safe Flight Corridor (SFC)\ngeneration strategy and high-dimensional collision-free trajectory planning. In\nparticular, we formulate an optimization problem to generate feasible\ntrajectories for both the quadrotor and manipulator while ensuring collision\navoidance, dynamic feasibility, kinematic feasibility, and waypoint\nconstraints. To achieve collision avoidance, we introduce a variable geometry\napproximation method, which dynamically models the changing collision volume\ninduced by different manipulator configurations. Moreover, waypoint constraints\nin our framework are defined in $\\mathrm{SE(3)\\times\\mathbb{R}^3}$, allowing\nthe aerial manipulator to traverse specified positions while maintaining\ndesired attitudes and end-effector states. The effectiveness of our framework\nis validated through comprehensive simulations and real-world experiments\nacross various environments."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.08697",
    "c_title":[
      "Bilevel Learning for Bilevel Planning"
    ],
    "c_abstract":[
      "A robot that learns from demonstrations should not just imitate what it sees\n-- it should understand the high-level concepts that are being demonstrated and\ngeneralize them to new tasks. Bilevel planning is a hierarchical model-based\napproach where predicates (relational state abstractions) can be leveraged to\nachieve compositional generalization. However, previous bilevel planning\napproaches depend on predicates that are either hand-engineered or restricted\nto very simple forms, limiting their scalability to sophisticated,\nhigh-dimensional state spaces. To address this limitation, we present IVNTR,\nthe first bilevel planning approach capable of learning neural predicates\ndirectly from demonstrations. Our key innovation is a neuro-symbolic bilevel\nlearning framework that mirrors the structure of bilevel planning. In IVNTR,\nsymbolic learning of the predicate \"effects\" and neural learning of the\npredicate \"functions\" alternate, with each providing guidance for the other. We\nevaluate IVNTR in six diverse robot planning domains, demonstrating its\neffectiveness in abstracting various continuous and high-dimensional states.\nWhile most existing approaches struggle to generalize (with <35% success rate),\nour IVNTR achieves an average of 77% success rate on unseen tasks.\nAdditionally, we showcase IVNTR on a mobile manipulator, where it learns to\nperform real-world mobile manipulation tasks and generalizes to unseen test\nscenarios that feature new objects, new states, and longer task horizons. Our\nfindings underscore the promise of learning and planning with abstractions as a\npath towards high-level generalization."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-10",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16120",
    "b_title":[
      "Probabilistic Prompt Distribution Learning for Animal Pose Estimation"
    ],
    "b_abstract":[
      "Multi-species animal pose estimation has emerged as a challenging yet\ncritical task, hindered by substantial visual diversity and uncertainty. This\npaper challenges the problem by efficient prompt learning for Vision-Language\nPretrained (VLP) models, \\textit{e.g.} CLIP, aiming to resolve the\ncross-species generalization problem. At the core of the solution lies in the\nprompt designing, probabilistic prompt modeling and cross-modal adaptation,\nthereby enabling prompts to compensate for cross-modal information and\neffectively overcome large data variances under unbalanced data distribution.\nTo this end, we propose a novel probabilistic prompting approach to fully\nexplore textual descriptions, which could alleviate the diversity issues caused\nby long-tail property and increase the adaptability of prompts on unseen\ncategory instance. Specifically, we first introduce a set of learnable prompts\nand propose a diversity loss to maintain distinctiveness among prompts, thus\nrepresenting diverse image attributes. Diverse textual probabilistic\nrepresentations are sampled and used as the guidance for the pose estimation.\nSubsequently, we explore three different cross-modal fusion strategies at\nspatial level to alleviate the adverse impacts of visual uncertainty. Extensive\nexperiments on multi-species animal pose benchmarks show that our method\nachieves the state-of-the-art performance under both supervised and zero-shot\nsettings. The code is available at https:\/\/github.com\/Raojiyong\/PPAP."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14455",
    "c_title":[
      "Triple Path Enhanced Neural Architecture Search for Multimodal Fake News\n  Detection"
    ],
    "c_abstract":[
      "Multimodal fake news detection has become one of the most crucial issues on\nsocial media platforms. Although existing methods have achieved advanced\nperformance, two main challenges persist: (1) Under-performed multimodal news\ninformation fusion due to model architecture solidification, and (2) weak\ngeneralization ability on partial-modality contained fake news. To meet these\nchallenges, we propose a novel and flexible triple path enhanced neural\narchitecture search model MUSE. MUSE includes two dynamic paths for detecting\npartial-modality contained fake news and a static path for exploiting potential\nmultimodal correlations. Experimental results show that MUSE achieves stable\nperformance improvement over the baselines."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-11",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09359",
    "b_title":[
      "Yield-Stress Fluid Mixing: Localization Mechanisms and Regime\n  Transitions"
    ],
    "b_abstract":[
      "We explore the mechanisms and regimes of mixing in yield-stress fluids by\nsimulating the stirring of an infinite, two-dimensional domain filled with a\nBingham fluid. A cylindrical stirrer moves along a circular path at constant\nspeed to stir the fluid, with an initially quiescent domain marked by a passive\ndye in the lower half, facilitating the analysis of dye interface evolution and\nmixing dynamics. We first examine the mixing process in Newtonian fluids,\nidentifying three key mechanisms: interface stretching and folding around the\nstirrer's path, diffusion across streamlines, and dye advection and interface\nstretching due to vortex shedding. Introducing yield stress into the system\nleads to notable localization effects in mixing, manifesting through three\nmechanisms: advection of vortices within a finite distance of the stirrer,\nvortex entrapment near the stirrer, and complete suppression of vortex shedding\nat high yield stresses. Based on these mechanisms, we classify three distinct\nmixing regimes in yield-stress fluids: (i) Regime SE, where shed vortices\nescape the central region, (ii) Regime ST, where shed vortices remain trapped\nnear the stirrer, and (iii) Regime NS, where no vortex shedding occurs. These\nregimes are quantitatively distinguished through spectral analysis of energy\noscillations, revealing transitions and the critical Bingham and Reynolds\nnumbers. The transitions are captured through effective Reynolds numbers,\nsupporting a hypothesis that mixing regime transitions in yield-stress fluids\nshare fundamental characteristics with bluff-body flow dynamics. The findings\nprovide a mechanistic framework for understanding and predicting mixing\nbehaviors in yield-stress fluids, suggesting that the localization mechanisms\nand mixing regimes observed here are archetypal for stirred-tank applications."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.06434",
    "c_title":[
      "Droplets Suspended Beneath a Fiber Hub"
    ],
    "c_abstract":[
      "Droplet-fiber interactions, prevalent in nature and widely applied across\nvarious engineering fields, have garnered significant research interest. Many\nworks have focused on the interactions between droplets and single or two\nfibers. However, the wetting behavior of droplets, especially the maximum\ndroplets that can be retained, on fiber hubs formed by many fibers is rarely\nstudied. The current work explores the capability of fiber hubs to retain\nliquid droplets. We develop analytical and semi-empirical models to predict the\nmaximum droplet volume on a fiber hub, validating them against experimental\ndata. The variation of maximum volume follows two distinct regimes as the fiber\ncount increases, with a critical fiber number ($n^* = 32$) marking the\ntransition between them. In Regime I ($n\\le n^*$), the volume increases with\nfiber number, and the stability of a droplet is dictated by the pinning of\nthree-phase contact lines. In Regime II ($n>n^*$), the volume plateaus, with\ndroplets under a fiber hub behaving similarly to those on a flat surface, where\nthe stability is governed by Rayleigh-Taylor instability."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-12",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01415",
    "b_title":[
      "Improving the Efficiency of VVC using Partitioning of Reference Frames"
    ],
    "b_abstract":[
      "In response to the growing demand for high-quality videos, Versatile Video\nCoding (VVC) was released in 2020, building on the hybrid coding architecture\nof its predecessor, HEVC, achieving about 50% bitrate reduction for the same\nvisual quality. It introduces more flexible block partitioning, enhancing\ncompression efficiency at the cost of increased encoding complexity. To make\nefficient use of VVC in practical applications, optimization is essential.\nVVenC, an optimized open-source VVC encoder, introduces multiple presets to\naddress the trade-off between compression efficiency and encoder complexity.\nAlthough an optimized set of encoding tools has been selected for each preset,\nthe rate-distortion (RD) search space in the encoder presets still poses a\nchallenge for efficient encoder implementations. In this paper, we propose\nEarly Termination using Reference Frames (ETRF), which improves the trade-off\nbetween encoding efficiency and time complexity and positions itself as a new\npreset between medium and fast presets. The CTU partitioning map of the\nreference frames in lower temporal layers is employed to accelerate the\nencoding of frames in higher temporal layers. The results show a reduction in\nthe encoding time of around 21% compared to the medium preset. Specifically,\nfor videos with high spatial and temporal complexities, which typically require\nlonger encoding times, the proposed method achieves a better trade-off between\nbitrate savings and encoding time compared to the fast preset."
    ],
    "b_categories":[
      [
        "cs.MM"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17038",
    "c_title":[
      "Multi-modal and Metadata Capture Model for Micro Video Popularity\n  Prediction"
    ],
    "c_abstract":[
      "As short videos have become the primary form of content consumption across\nvarious industries, accurately predicting their popularity has become key to\nenhancing user engagement and optimizing business strategies. This report\npresents a solution for the 2024 INFORMS Data Mining Challenge, focusing on our\ndeveloped 3M model (Multi-modal and Metadata Capture Model), which is a\nmulti-modal popularity prediction model. The 3M model integrates video, audio,\ndescriptions, and metadata to fully explore the multidimensional information of\nshort videos. We employ a retriever-based method to retrieve relevant instances\nfrom a multi-modal memory bank, filtering similar videos based on visual,\nacoustic, and text-based features for prediction. Additionally, we apply a\nrandom masking method combined with a semi-supervised model for incomplete\nmulti-modalities to leverage the metadata of videos. Ultimately, we use a\nnetwork to synthesize both approaches, significantly improving the accuracy of\npredictions. Compared to traditional tag-based algorithms, our model\noutperforms existing methods on the validation set, showing a notable increase\nin prediction accuracy. Our research not only offers a new perspective on\nunderstanding the drivers of short video popularity but also provides valuable\ndata support for identifying market opportunities, optimizing advertising\nstrategies, and enhancing content creation. We believe that the innovative\nmethodology proposed in this report provides practical tools and valuable\ninsights for professionals in the field of short video popularity prediction,\nhelping them effectively address future challenges."
    ],
    "c_categories":[
      [
        "cs.MM"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-13",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19111",
    "b_title":[
      "On the Baum-Connes conjecture for $D_{\\infty}$"
    ],
    "b_abstract":[
      "We make an exposition of the proof of the Baum-Connes conjecture for the\ninfinite dihedral group following the ideas of Higson and Kasparov."
    ],
    "b_categories":[
      [
        "math.KT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.04251",
    "c_title":[
      "Separation and excision in functor homology"
    ],
    "c_abstract":[
      "We prove separation and excision results in functor homology. These results\nexplain how the global Steinberg decomposition of functors proved by Djament,\nTouz{\\'e} and Vespa behaves in Ext and Tor computations."
    ],
    "c_categories":[
      [
        "math.KT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-14",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02253",
    "b_title":[
      "Network Digital Twin for 5G-Enabled Mobile Robots"
    ],
    "b_abstract":[
      "The maturity and commercial roll-out of 5G networks and its deployment for\nprivate networks makes 5G a key enabler for various vertical industries and\napplications, including robotics. Providing ultra-low latency, high data rates,\nand ubiquitous coverage and wireless connectivity, 5G fully unlocks the\npotential of robot autonomy and boosts emerging robotic applications,\nparticularly in the domain of autonomous mobile robots. Ensuring seamless,\nefficient, and reliable navigation and operation of robots within a 5G network\nrequires a clear understanding of the expected network quality in the\ndeployment environment. However, obtaining real-time insights into network\nconditions, particularly in highly dynamic environments, presents a significant\nand practical challenge. In this paper, we present a novel framework for\nbuilding a Network Digital Twin (NDT) using real-time data collected by robots.\nThis framework provides a comprehensive solution for monitoring, controlling,\nand optimizing robotic operations in dynamic network environments. We develop a\npipeline integrating robotic data into the NDT, demonstrating its evolution\nwith real-world robotic traces. We evaluate its performances in radio-aware\nnavigation use case, highlighting its potential to enhance energy efficiency\nand reliability for 5Genabled robotic operations."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15429",
    "c_title":[
      "Optimum Network Slicing for Ultra-reliable Low Latency Communication\n  (URLLC) Services in Campus Networks"
    ],
    "c_abstract":[
      "Within 3GPP, the campus network architecture has evolved as a deployment\noption for industries and can be provisioned using network slicing over already\ninstalled 5G public network infrastructure. In campus networks, the\nultra-reliable low latency communication (URLLC) service category is of major\ninterest for applications with strict latency and high-reliability\nrequirements. One way to achieve high reliability in a shared infrastructure is\nthrough resource isolation, whereby network slicing can be optimized to\nadequately reserve computation and transmission capacity. This paper proposes\nan approach for vertical slicing the radio access network (RAN) to enable the\ndeployment of multiple and isolated campus networks to accommodate URLLC\nservices. To this end, we model RAN function placement as a mixed integer\nlinear programming problem with URLLC-related constraints. We demonstrate that\nour approach can find optimal solutions in real-world scenarios. Furthermore,\nunlike existing solutions, our model considers the user traffic flow from a\nknown source node on the network's edge to an unknown \\textit{a priori}\ndestination node. This flexibility could be explored in industrial campus\nnetworks by allowing dynamic placement of user plane functions (UPFs) to serve\nthe URLLC."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-15",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01634",
    "b_title":[
      "Finding Large Sets Without Arithmetic Progressions of Length Three: An\n  Empirical View and Survey II"
    ],
    "b_abstract":[
      "There has been much work on the following question: given n how large can a\nsubset of {1,...,n} be that has no arithmetic progressions of length 3. We call\nsuch sets 3-free. Most of the work has been asymptotic. In this paper we sketch\napplications of large 3-free sets, review the literature of how to construct\nlarge 3-free sets, and present empirical studies on how large such sets\nactually are. The two main questions considered are (1) How large can a 3-free\nset be when n is small, and (2) How do the methods in the literature compare to\neach other? In particular, when do the ones that are asymptotically better\nactually yield larger sets? (This paper overlaps with our previous paper with\nthe title { Finding Large 3-Free Sets I: the Small n Case}.)"
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.01020",
    "c_title":[
      "Quadratic Embedding Constants of Strongly Regular Graphs"
    ],
    "c_abstract":[
      "We obtain an explicit formula for the quadratic embedding constant (QEC) of a\nstrongly regular graph $\\mathrm{srg}(n,k,\\lambda,\\mu)$ with $\\mu\\ge1$. By using\nQEC we give a necessary and sufficient condition for a strongly regular graph\nto admit a quadratic embeddingin a Euclidean space."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-16",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08080",
    "b_title":[
      "NLI under the Microscope: What Atomic Hypothesis Decomposition Reveals"
    ],
    "b_abstract":[
      "Decomposition of text into atomic propositions is a flexible framework\nallowing for the closer inspection of input and output text. We use atomic\ndecomposition of hypotheses in two natural language reasoning tasks,\ntraditional NLI and defeasible NLI, to form atomic sub-problems, or granular\ninferences that models must weigh when solving the overall problem. These\natomic sub-problems serve as a tool to further understand the structure of both\nNLI and defeasible reasoning, probe a model's consistency and understanding of\ndifferent inferences, and measure the diversity of examples in benchmark\ndatasets. Our results indicate that LLMs still struggle with logical\nconsistency on atomic NLI and defeasible NLI sub-problems. Lastly, we identify\ncritical atomic sub-problems of defeasible NLI examples, or those that most\ncontribute to the overall label, and propose a method to measure the\ninferential consistency of a model, a metric designed to capture the degree to\nwhich a model makes consistently correct or incorrect predictions about the\nsame fact under different contexts."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02374",
    "c_title":[
      "MedEthicEval: Evaluating Large Language Models Based on Chinese Medical\n  Ethics"
    ],
    "c_abstract":[
      "Large language models (LLMs) demonstrate significant potential in advancing\nmedical applications, yet their capabilities in addressing medical ethics\nchallenges remain underexplored. This paper introduces MedEthicEval, a novel\nbenchmark designed to systematically evaluate LLMs in the domain of medical\nethics. Our framework encompasses two key components: knowledge, assessing the\nmodels' grasp of medical ethics principles, and application, focusing on their\nability to apply these principles across diverse scenarios. To support this\nbenchmark, we consulted with medical ethics researchers and developed three\ndatasets addressing distinct ethical challenges: blatant violations of medical\nethics, priority dilemmas with clear inclinations, and equilibrium dilemmas\nwithout obvious resolutions. MedEthicEval serves as a critical tool for\nunderstanding LLMs' ethical reasoning in healthcare, paving the way for their\nresponsible and effective use in medical contexts."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-17",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03654",
    "b_title":[
      "Data Augmentation for Deep Learning Regression Tasks by Machine Learning\n  Models"
    ],
    "b_abstract":[
      "Deep learning (DL) models have gained prominence in domains such as computer\nvision and natural language processing but remain underutilized for regression\ntasks involving tabular data. In these cases, traditional machine learning (ML)\nmodels often outperform DL models. In this study, we propose and evaluate\nvarious data augmentation (DA) techniques to improve the performance of DL\nmodels for tabular data regression tasks. We compare the performance gain of\nNeural Networks by different DA strategies ranging from a naive method of\nduplicating existing observations and adding noise to a more sophisticated DA\nstrategy that preserves the underlying statistical relationship in the data.\nOur analysis demonstrates that the advanced DA method significantly improves DL\nmodel performance across multiple datasets and regression tasks, resulting in\nan average performance increase of over 10\\% compared to baseline models\nwithout augmentation. The efficacy of these DA strategies was rigorously\nvalidated across 30 distinct datasets, with multiple iterations and evaluations\nusing three different automated deep learning (AutoDL) frameworks: AutoKeras,\nH2O, and AutoGluon. This study demonstrates that by leveraging advanced DA\ntechniques, DL models can realize their full potential in regression tasks,\nthereby contributing to broader adoption and enhanced performance in practical\napplications."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05000",
    "c_title":[
      "Load Forecasting for Households and Energy Communities: Are Deep\n  Learning Models Worth the Effort?"
    ],
    "c_abstract":[
      "Accurate load forecasting is crucial for predictive control in many energy\ndomain applications, with significant economic and ecological implications. To\naddress these implications, this study provides an extensive benchmark of\nstate-of-the-art deep learning models for short-term load forecasting in energy\ncommunities. Namely, LSTM, xLSTM, and Transformers are compared with benchmarks\nsuch as KNNs, synthetic load models, and persistence forecasting models. This\ncomparison considers different scales of aggregation (e.g., number of household\nloads) and varying training data availability (e.g., training data time spans).\nFurther, the impact of transfer learning from synthetic (standard) load\nprofiles and the deep learning model size (i.e., parameter count) is\ninvestigated in terms of forecasting error. Implementations are publicly\navailable and other researchers are encouraged to benchmark models using this\nframework. Additionally, a comprehensive case study, comprising an energy\ncommunity of 50 households and a battery storage demonstrates the beneficial\nfinancial implications of accurate predictions. Key findings of this research\ninclude: (1) Simple persistence benchmarks outperform deep learning models for\nshort-term load forecasting when the available training data is limited to six\nmonths or less; (2) Pretraining with publicly available synthetic load profiles\nimproves the normalized Mean Absolute Error (nMAE) by an average of 1.28%pt\nduring the first nine months of training data; (3) Increased aggregation\nsignificantly enhances the performance of deep learning models relative to\npersistence benchmarks; (4) Improved load forecasting, with an nMAE reduction\nof 1.1%pt, translates to an economic benefit of approximately 600EUR per year\nin an energy community comprising 50 households."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-18",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13053",
    "b_title":[
      "Evaluation of patient activation and dosimetry after Boron Neutron\n  Capture Therapy"
    ],
    "b_abstract":[
      "Boron Neutron Capture Therapy (BNCT) is a form of radiotherapy based on the\nirradiation of the tumour with a low energy neutron beam, after the\nadministration of a selective drug enriched in boron-10. The therapy exploits\nthe high cross section of thermal neutron capture in boron, generating two\nlow-range charged particles. The availability of accelerators able to generate\nhigh-intensity neutron beams via proton nuclear interaction is boosting the\nconstruction of new clinical centres. One of these is under development in\nItaly, using a 5 MeV, 30 mA proton radiofrequency accelerator coupled to a\nberyllium target, funded by the Complementary Plan to the Recovery and\nResilience National Plan, under the project ANTHEM. The present study focuses\non radiation protection aspects of patients undergoing BNCT, specifically on\nthe activation of their organs and tissues. A criterion to establish the\nrelevance of such activation after BNCT has been proposed. Based on the current\nItalian regulatory framework, the level of patient activation following BNCT\ntreatment does not pose a significant radiological concern, even shortly after\nirradiation. Another aspect is the activation of patient's excretions, which\ncan impact on the design of the building and requires a process for the\ndischarge. The described study contributes to the radiation protection study\nfor the ANTHEM BNCT centre in Italy."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10511",
    "c_title":[
      "Numerical Analysis of Antenna Parameter Influence on Brightness\n  Temperature in Medical Microwave Radiometers"
    ],
    "c_abstract":[
      "This article presents a study on the influence of antenna parameters in\nmedical microwave radiometers on brightness temperature. A series of\ncomputational experiments was conducted to analyse the dependence of brightness\ntemperature on antenna characteristics. Various antenna parameters and their\neffect on the distribution of electromagnetic fields in biological tissues were\nexamined. It was demonstrated that considering the antenna mismatch parameter\nis crucial when modelling the brightness temperature of biological tissues,\ncontributing about 2 percent to its formation. The depth range of brightness\ntemperature measurement was determined. The dependence of brightness\ntemperature on the antenna diameter and frequency was established. The findings\nof this study can be applied to improve medical microwave radiometers and\nenhance their efficiency in the early diagnosis of various diseases."
    ],
    "c_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-19",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05145",
    "b_title":[
      "On Maximum Induced Forests of the Balanced Bipartite Graphs"
    ],
    "b_abstract":[
      "We are examining a specific type of graph called a balanced bipartite graph.\nThe balanced bipartite graph, such as $\\mathcal{B}$, has two parts, $V_1$ and\n$V_2$, each containing $n$ vertices, for a total of $2n$ vertices. The degree\nof a vertex $v$ in $V_1\\cup\\,V_2$ is denoted by $d_\\mathcal{B}(v)$. The minimum\ndegree of any vertex in the graph $\\mathcal{B}$ is represented by\n$\\delta(\\mathcal{B})$. If $S$ is a subset of $V_1\\cup\\,V_2$, then the subgraph\nof $\\mathcal{B}$ induced by $S$ is the graph that has $S$ as its vertex set and\ncontains all the edges of $\\mathcal{B}$ that have both endpoints in $S$. This\nsubgraph is denoted by $\\mathcal{B}[S]$. The forest number of a graph\n$\\mathcal{B}$ is the size of the largest subset of vertices of $\\mathcal{B}$\nthat form an induced forest. We use $f(\\mathcal{B})$ to represent the forest\nnumber of graph $\\mathcal{B}$. A decycling set or a feedback vertex set of a\ngraph is a set of vertices whose removal results in a forest. The smallest\npossible size of a decycling set of $\\mathcal{B}$ is represented by\n$\\nabla(\\mathcal{B})$. Finding the decycling number of $\\mathcal{B}$ is\nequivalent to determining the largest order of an induced forest, i.e.,\n$f(\\mathcal{B})+\\nabla(\\mathcal{B})=2n$. In this essay, we study the structure\nand cardinality of the largest subsets of vertices of graph $\\mathcal{B}$ that\nform induced forests."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.11473",
    "c_title":[
      "The saturation number of W 4"
    ],
    "c_abstract":[
      "For a fixed graph $H$, a graph $G$ is called $H$-saturated if $G$ does not\ncontain $H$ as a (not necessarily induced) subgraph, but $G+e$ contains a copy\nof $H$ for any $e\\in E(\\overline{G})$. The saturation number of $H$, denoted by\n${\\rm sat}(n,H)$, is the minimum number of edges in an $n$-vertex $H$-saturated\ngraph. A wheel $W_n$ is a graph obtained from a cycle of length $n$ by adding a\nnew vertex and joining it to every vertex of the cycle. A well-known result of\nErd\\H{o}s, Hajnal and Moon shows that ${\\rm sat}(n,W_3)=2n-3$ for all $n\\geq 4$\nand $K_2\\vee \\overline{K_{n-2}}$ is the unique extremal graph, where $\\vee$\ndenotes the graph join operation. In this paper, we study the saturation number\nof $W_4$. We prove that ${\\rm sat}(n,W_4)=\\lfloor\\frac{5n-10}{2}\\rfloor$ for\nall $n\\geq 6$ and give a complete characterization of the extremal graphs."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-20",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10108",
    "b_title":[
      "Thermal Conduction and Thermal-Driven Winds in Magnetized Viscous\n  Accretion Disk Dynamics"
    ],
    "b_abstract":[
      "This paper investigates the effects of saturated thermal conduction (TC) and\nthermal-driven winds (TDWs) on magnetized advection-dominated accretion onto a\nrotating black hole (BH). We incorporate dissipative processes in the\nmagnetized accretion flow and expect the accretion disk to be threaded by\npredominantly toroidal and turbulent magnetic fields. We solve the\nmagnetohydrodynamics equations and construct a self-consistent steady model of\nthe magnetized accretion flow surrounding a rotating BH, which includes TC and\nTDWs. We seek global accretion solutions spanning from the BH horizon to a\nlarge distance and analyze the solution's characteristics as a function of\ndissipation parameters. Accretion solutions with multiple critical points may\nexhibit shock waves if they meet the standing shock criteria. We found steady,\nglobal transonic, and shocked accretion solutions around the rotating BH. In\nparticular, the wind parameter ($m$) and the saturated conduction parameter\n($\\Phi_{\\rm s}$) significantly influence the dynamical behavior of shocks. The\nshock location moves away from the BH horizon as $\\Phi_{\\rm s}$ and $m$\nincrease, assuming fixed conditions at the disk's outer edge. Our formalism\nexplains the declining phase of BH outbursts, characterized by a monotonic\ndecrease in QPO frequency as the burst decays. Based on our findings, we\nconclude that the combined effect of $\\Phi_{\\rm s}$ and $m$ parameters\nsubstantially alters the steady shock specific energy vs angular momentum\nparameter space and also modifies the corresponding post-shock luminosity vs\nQPO frequency parameter space. We propose, based on our theoretical model, that\nthe $\\Phi_{\\rm s}$ and $m$ parameters may significantly influence the evolution\nof the BH outbursts."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12135",
    "c_title":[
      "The relativistic outflow driven by the large-scale magnetic field from\n  an accretion disk"
    ],
    "c_abstract":[
      "Outflows\/jets are ubiquitous in a wide range of astrophysical objects, yet\nthe mechanisms responsible for their generation remain elusive. One hypothesis\nis that they are magnetically driven. Based on general relativistic MHD\nequations, we establish a formulation to describe the outflows driven by\nlarge-scale magnetic fields from the accretion disk in Schwarzschild spacetime.\nThe outflow solution manifests as a contour level of a ``Bernoulli\" function,\nwhich is determined by ensuring that it passes through both the slow and fast\nmagnetosonic points. This approach is a general relativistic extension to the\nclassical treatment of Cao and Spruit (1994). The initial plasma $\\beta$ that\npermits magnetically driven outflow solutions is constrained, with the slow\nmagnetosonic point above the footpoint setting an upper limit\n($\\beta_\\mathrm{b}\\lesssim 2$) and the Alfv\\'en point inside the light cylinder\nsetting a lower limit ($\\beta_\\mathrm{b}\\gtrsim 0.02$). The higher the\nmagnetization, the higher the temperature allowed, leading to relativistic\noutflows\/jets. We investigate the relativistic outflows\/jets of several typical\nobjects such as active galactic nuclei (AGN), X-ray binaries (XRBs) and\ngamma-ray bursts (GRBs). The results indicate that all of these phenomena\nrequire strongly magnetized, high-temperature outflows as initial conditions,\nsuggesting a potential association between the production of relativistic\noutflows\/jets and corona-like structures."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-21",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12283",
    "b_title":[
      "The nature of an imaginary quasi-periodic oscillation in the\n  soft-to-hard transition of MAXI J1820+070"
    ],
    "b_abstract":[
      "A recent study shows that if the power spectra (PS) of accreting compact\nobjects consist of a combination of Lorentzian functions that are coherent in\ndifferent energy bands but incoherent with each other, the same is true for the\nReal and Imaginary parts of the cross spectrum (CS). Using this idea, we\ndiscovered imaginary quasi-periodic oscillations (QPOs) in NICER observations\nof the black hole candidate MAXI J1820+070. The imaginary QPOs appear as narrow\nfeatures with a small Real and large Imaginary part in the CS but are not\nsignificantly detected in the PS when they overlap in frequency with other\nvariability components. The coherence function drops and the phase lags\nincrease abruptly at the frequency of the imaginary QPO. We show that the\nmulti-Lorentzian model that fits the PS and CS of the source in two energy\nbands correctly reproduces the lags and the coherence, and that the narrow drop\nof the coherence is caused by the interaction of the imaginary QPO with other\nvariability components. The imaginary QPO appears only in the decay of the\noutburst, during the transition from the high-soft to the low-hard state of\nMAXI J1820+070, and its frequency decreases from approximately 5 Hz to around 1\nHz as the source spectrum hardens. We also analysed the earlier observations of\nthe transition, where no narrow features were seen, and we identified a QPO in\nthe PS that appears to evolve into the imaginary QPO as the source hardens. As\nfor the type-B and C QPOs in this source, the rms spectrum of the imaginary QPO\nincreases with energy. The lags of the imaginary QPO are similar to those of\nthe type-B and C QPOs above 2 keV but differ from the lags of those other QPOs\nbelow that energy. While the properties of this imaginary QPO resemble those of\ntype-C QPOs, we cannot rule out that it is a new type of QPO."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.13435",
    "c_title":[
      "Radio observations of the ultra-long GRB 220627A reveal a hot cocoon\n  supporting the blue supergiant progenitor scenario"
    ],
    "c_abstract":[
      "We present the discovery of the radio afterglow of the most distant\nultra-long gamma-ray burst (GRB) detected to date, GRB~220627A at redshift\n$z=3.084$. Its prompt gamma-ray light curve shows a double-pulse profile, with\nthe pulses separated by a period of quiescence lasting ${\\sim} 15\\,$min,\nleading to early speculation it could be a strongly gravitationally lensed GRB.\nHowever, our analysis of the $\\textit{Fermi}$\/GBM spectra taken during the time\nintervals of both pulses show clear differences in their spectral energy\ndistributions, disfavouring the lensing scenario. We observed the radio\nafterglow from $7$ to $456\\,$d post-burst: an initial, steep decay ($F_{\\nu}\n\\propto t^{-2}$) is followed by a shallower decline ($F_{\\nu} \\propto\nt^{-1\/2}$) after ${\\sim} 20\\,$d. Our afterglow modelling shows that these radio\nproperties can be explained by the presence of a slow, wide ejecta component in\naddition to a fast, narrow ejecta component, consistent with the picture of a\nhighly-collimated jet and its thermal cocoon decelerating into the ambient\nmedium. The properties of the cocoon point toward a progenitor with a large\nstellar radius, supporting the blue supergiant scenario proposed for ultra-long\nGRBs. We also conducted an independent test of the lensing hypothesis via Very\nLong Baseline Interferometry (VLBI) observations at ${\\sim} 12\\,$d post-burst\nby searching, for the first time, for multiple images of the candidate lensed\nGRB afterglow. Our experiment highlighted the growing need for developments in\nreal-time correlation capabilities for time-critical VLBI experiments,\nparticularly as we advance towards the SKA and ngVLA era of radio astronomy."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-22",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08670",
    "b_title":[
      "Transient growth and nonlinear breakdown of wavelet-based resolvent\n  modes in turbulent channel flow"
    ],
    "b_abstract":[
      "We study the effectiveness of the time-localised principal resolvent forcing\nmode at actuating the near wall cycle of turbulence. The mode is restricted to\na wavelet pulse and computed from an SVD of the windowed wavelet-based\nresolvent operator so that it produces the largest amplification via the\nlinearised Navier-Stokes equations. We then inject this time-localised mode\ninto the turbulent minimal flow unit at different intensities, and measure the\ninstantaneous deviation of the system's response from the optimal resolvent\nresponse mode. This is possible under the new formulation, which enables the\nmodes to represent transient trajectories. For the most energetic spatial wave\nnumbers in the minimal flow unit -- constant in the streamwise direction and\nonce-periodic in the spanwise direction -- the forcing mode takes the shape of\nstreamwise rolls and produces a response mode in the form of streamwise streaks\nthat transiently grow and decay. For initial times and close to the wall, the\nDNS response matches the principal response mode well, but due to\nnonlinearities, the response across all forcing intensities decays prematurely,\nand a higher forcing intensity leads to faster energy decay. The principal\nforcing mode still leads to significant energy amplification and is more\neffective than a randomly-generated forcing structure and the second suboptimal\nresolvent forcing mode at amplifying the near-wall streaks. We compute the\nnonlinear energy transfer to secondary modes and observe that the breakdown of\nthe actuated mode proceeds similarly across all forcing intensities: in the\nnear-wall region, the induced streak forks into a structure twice periodic in\nthe spanwise direction; in the outer region, the streak breaks up into a\nstructure that is once periodic in the streamwise direction. In both regions,\nspanwise gradients account for the dominant share of nonlinear energy transfer."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.11292",
    "c_title":[
      "Discussion on \"Resurrecting a Neglected Measurement Technique for\n  Air-Water Flows\""
    ],
    "c_abstract":[
      "Over the last years, there has been a renewed interest in differentiating\nvarious contributions to the air concentration in high Froude-number\nself-aerated flows, see for example Kramer (2024), comprising entrained and\nentrapped air. The former is characterized by entrained air packets and\nbubbles, while entrapped air corresponds to air transported along wave peaks\nand troughs. Entrapped air was first measured by Killen (1968) using a\nso-called dipping probe, while a physical interpretation of the dipping probe\nsignals was provided only later by Wilhelms and Gulliver (2005).\n  Since then, it has been commonly accepted that two different measurement\ninstruments, for example a dipping probe and a common phase-detection probe,\nare required to fully quantify entrained and entrapped air. Recently, an\narticle entitled \"Resurrecting a Neglected Measurement Technique for Air-Water\nFlows\" was published by Wilhelms and Gulliver (2024), who re-iterated the\nimportance of applying these concepts for cavitation prevention and air-water\ngas transfer, as well as the need for two separate measurement instruments. The\nauthors are congratulated for their seminal works on entrained and entrapped\nair (Wilhelms and Gulliver 2005; Wilhelms and Gulliver 2024), and it is\nstipulated that these concepts have been overlooked in the last two decades.\n  In this discussion, a simple discrimination technique for phase-detection\nprobe signals is proposed, which allows to differentiate entrained and\nentrapped air from existing datasets, recorded with a state-of-the-art dual-tip\nphase-detection probe. It is believed that this novel signal processing method\nwill make Killen's (1968) dipping probe redundant, and that it will be useful\nfor the validation of non-intrusive measurements of entrapped air, as well as\nfor the development of physics-based models for air-water mass transfer in\nself-aerated flows."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-23",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13448",
    "b_title":[
      "Criteria for asymptotic stability of eventually continuous Markov-Feller\n  semigroups"
    ],
    "b_abstract":[
      "In this paper, we establish three criteria for the asymptotic behavior of\nMarkov-Feller semigroups. First, we present a criterion for convergence in\ntotal variation to a unique invariant measure, requiring only $TV$-eventual\ncontinuity of the semigroup at a single point. Second, we propose two new\ncriteria for asymptotic stability that require eventual continuity at a single\npoint. This localized condition is more practical and easier to check. To\nillustrate the advantages of our framework, we provide an explicit example\nwhere verifying eventual continuity at a single point is straightforward,\nwhereas establishing the corresponding global property is challenging."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.10915",
    "c_title":[
      "First passage times with fast immigration"
    ],
    "c_abstract":[
      "Many scientific questions can be framed as asking for a first passage time\n(FPT), which generically describes the time it takes a random \"searcher\" to\nfind a \"target.\" The important timescale in a variety of biophysical systems is\nthe time it takes the fastest searcher(s) to find a target out of many\nsearchers. Previous work on such fastest FPTs assumes that all searchers are\ninitially present in the domain, which makes the problem amenable to extreme\nvalue theory. In this paper, we consider an alternative model in which\nsearchers progressively enter the domain at a constant \"immigration\" rate. In\nthe fast immigration rate limit, we determine the probability distribution and\nmoments of the $k$-th fastest FPT. Our rigorous theory applies to many models\nof stochastic motion, including random walks on discrete networks and diffusion\non continuous state spaces. Mathematically, our analysis involves studying the\nextrema of an infinite sequence of random variables which are both not\nindependent and not identically distributed. Our results constitute a rare\ninstance in which extreme value statistics can be determined exactly for\nstrongly correlated random variables."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-24",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19769",
    "b_title":[
      "QORT-Former: Query-optimized Real-time Transformer for Understanding Two\n  Hands Manipulating Objects"
    ],
    "b_abstract":[
      "Significant advancements have been achieved in the realm of understanding\nposes and interactions of two hands manipulating an object. The emergence of\naugmented reality (AR) and virtual reality (VR) technologies has heightened the\ndemand for real-time performance in these applications. However, current\nstate-of-the-art models often exhibit promising results at the expense of\nsubstantial computational overhead. In this paper, we present a query-optimized\nreal-time Transformer (QORT-Former), the first Transformer-based real-time\nframework for 3D pose estimation of two hands and an object. We first limit the\nnumber of queries and decoders to meet the efficiency requirement. Given\nlimited number of queries and decoders, we propose to optimize queries which\nare taken as input to the Transformer decoder, to secure better accuracy: (1)\nwe propose to divide queries into three types (a left hand query, a right hand\nquery and an object query) and enhance query features (2) by using the contact\ninformation between hands and an object and (3) by using three-step update of\nenhanced image and query features with respect to one another. With proposed\nmethods, we achieved real-time pose estimation performance using just 108\nqueries and 1 decoder (53.5 FPS on an RTX 3090TI GPU). Surpassing\nstate-of-the-art results on the H2O dataset by 17.6% (left hand), 22.8% (right\nhand), and 27.2% (object), as well as on the FPHA dataset by 5.3% (right hand)\nand 10.4% (object), our method excels in accuracy. Additionally, it sets the\nstate-of-the-art in interaction recognition, maintaining real-time efficiency\nwith an off-the-shelf action recognition module."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07331",
    "c_title":[
      "ERANet: Edge Replacement Augmentation for Semi-Supervised Meniscus\n  Segmentation with Prototype Consistency Alignment and Conditional\n  Self-Training"
    ],
    "c_abstract":[
      "Manual segmentation is labor-intensive, and automatic segmentation remains\nchallenging due to the inherent variability in meniscal morphology, partial\nvolume effects, and low contrast between the meniscus and surrounding tissues.\nTo address these challenges, we propose ERANet, an innovative semi-supervised\nframework for meniscus segmentation that effectively leverages both labeled and\nunlabeled images through advanced augmentation and learning strategies. ERANet\nintegrates three key components: edge replacement augmentation (ERA), prototype\nconsistency alignment (PCA), and a conditional self-training (CST) strategy\nwithin a mean teacher architecture. ERA introduces anatomically relevant\nperturbations by simulating meniscal variations, ensuring that augmentations\nalign with the structural context. PCA enhances segmentation performance by\naligning intra-class features and promoting compact, discriminative feature\nrepresentations, particularly in scenarios with limited labeled data. CST\nimproves segmentation robustness by iteratively refining pseudo-labels and\nmitigating the impact of label noise during training. Together, these\ninnovations establish ERANet as a robust and scalable solution for meniscus\nsegmentation, effectively addressing key barriers to practical implementation.\nWe validated ERANet comprehensively on 3D Double Echo Steady State (DESS) and\n3D Fast\/Turbo Spin Echo (FSE\/TSE) MRI sequences. The results demonstrate the\nsuperior performance of ERANet compared to state-of-the-art methods. The\nproposed framework achieves reliable and accurate segmentation of meniscus\nstructures, even when trained on minimal labeled data. Extensive ablation\nstudies further highlight the synergistic contributions of ERA, PCA, and CST,\nsolidifying ERANet as a transformative solution for semi-supervised meniscus\nsegmentation in medical imaging."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-25",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15010",
    "b_title":[
      "A new emitter for electrospray and electrohydrodynamic jet printing"
    ],
    "b_abstract":[
      "We propose using a dielectric beveled nozzle for electrospray and\nelectrohydrodynamic jet printing. This nozzle stabilizes the liquid ejection of\nlow-conductivity liquids, considerably reducing the minimum flow rate below\nwhich the flow becomes unstable. This translates into a significant reduction\nof the minimum jet diameter. Due to its dielectric character, electrochemical\nreactions occurring in metallic beveled nozzles (e.g. hypodermic needles) do\nnot occur, preserving the purity of the liquid. This property makes this nozzle\nappropriate for Electrospray Ionization Mass Spectrometry (ESI-MS) or\nbioplotting. We illustrate the capabilities of this new technique by conducting\n(i) electrospray experiments with Newtonian liquids and (ii)\nelectrohydrodynamic jet printing experiments with viscoelastic fluids. Jets\nwith diameters around 1 $\\mu$m are produced with low-conductivity liquids such\nas octanol and glycerine. Viscoelastic threads a few microns in diameter are\ngently deposited on a moving substrate to print out uniform lines tens of\nnanometers in height. Due to the strong stabilizing effect of the beveled\nnozzle, the minimum flow rate and jet diameter were much smaller than the\nrespective values obtained with the cylindrical capillary in the electrospray\nand electrohydrodynamic jet printing experiments. The proposed technique opens\nnew routes for electrospray and electrohydrodynamic jet printing."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.01165",
    "c_title":[
      "Solving all laminar flows around airfoils all-at-once using a parametric\n  neural network solver"
    ],
    "c_abstract":[
      "Recent years have witnessed increasing research interests of physics-informed\nneural networks (PINNs) in solving forward, inverse, and parametric problems\ngoverned by partial differential equations (PDEs). Despite their promise, PINNs\nstill face significant challenges in many scenarios due to ill-conditioning.\nTime-stepping-oriented neural network (TSONN) addresses this by reformulating\nthe ill-conditioned optimization problem into a series of well-conditioned\nsub-problems, greatly improving its ability to handle complex scenarios. This\npaper presents a new solver for laminar flow around airfoils based on TSONN and\nmesh transformation, validated across various test cases. Specifically, the\nsolver achieves mean relative errors of approximately 3.6% for lift\ncoefficients and 1.4% for drag coefficients. Furthermore, this paper extends\nthe solver to parametric problems involving flow conditions and airfoil shapes,\ncovering nearly all laminar flow scenarios in engineering. The shape parameter\nspace is defined as the union of 30% perturbations applied to each airfoil in\nthe UIUC airfoil database, with Reynolds numbers ranging from 100 to 5000 and\nangles of attack spanning from -5{\\deg} to 15{\\deg}. The parametric solver\nsolves all laminar flows within the parameter space in just 4.6 day, at\napproximately 40 times the computational cost of solving a single flow. The\nmodel training involves hundreds of millions of flow conditions and airfoil\nshapes, ultimately yielding a surrogate model with strong generalization\ncapability that does not require labeled data. Specifically, the surrogate\nmodel achieves average errors of 4.6% for lift coefficients and 1.1% for drag\ncoefficients, demonstrating its potential for high generalizability,\ncost-effectiveness, and efficiency in addressing high-dimensional parametric\nproblems and surrogate modeling."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-26",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07141",
    "b_title":[
      "Exact Thermal Distributions in Integrable Classical and Quantum Gases"
    ],
    "b_abstract":[
      "We consider one-dimensional, integrable many-body classical and quantum\nsystems in thermal equilibrium. In the classical case, we use the classical\nlimit of the Bethe equations to obtain a self-consistent integral equation\nwhose solution gives the distribution of asymptotic Bethe momenta, or\nrapidities, as well as the classical partition function in the canonical\nensemble, and the thermal energy dispersion. For quantum gases, we obtain a\nsimilar integral equation, albeit in the grand canonical ensemble, with\ncompletely analogous results. We apply our theory to the classical and quantum\nTonks and Calogero-Sutherland models, and our results are in perfect agreement\nwith standard calculations using Yang-Yang thermodynamics. Remarkably, we show\nin a straightforward manner that the thermodynamics of the quantum\nCalogero-Sutherland model is in one-to-one correspondence with the ideal Fermi\ngas upon simple rescalings of chemical potential and density."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.07293",
    "c_title":[
      "Feedback cooling of fermionic atoms in optical lattices"
    ],
    "c_abstract":[
      "We discuss the preparation of topological insulator states with fermionic\nultracold atoms in optical lattices by means of measurement-based Markovian\nfeedback control. The designed measurement and feedback operators induce an\neffective dissipative channel that stabilizes the desired insulator state,\neither in an exact way or approximately in the case where additional\nexperimental constraints are assumed. Successful state preparation is\ndemonstrated in one-dimensional insulators as well as for Haldane's Chern\ninsulator, by calculating the fidelity between the target ground state and the\nsteady state of the feedback-modified master equation. The fidelity is obtained\nvia time evolution of the system with moderate sizes. For larger 2D systems, we\ncompare the mean occupation of the single-particle eigenstates for the ground\nand steady state computed through mean-field kinetic equations."
    ],
    "c_categories":[
      [
        "cond-mat.quant-gas"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-27",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00641",
    "b_title":[
      "How to Probe: Simple Yet Effective Techniques for Improving Post-hoc\n  Explanations"
    ],
    "b_abstract":[
      "Post-hoc importance attribution methods are a popular tool for \"explaining\"\nDeep Neural Networks (DNNs) and are inherently based on the assumption that the\nexplanations can be applied independently of how the models were trained.\nContrarily, in this work we bring forward empirical evidence that challenges\nthis very notion. Surprisingly, we discover a strong dependency on and\ndemonstrate that the training details of a pre-trained model's classification\nlayer (less than 10 percent of model parameters) play a crucial role, much more\nthan the pre-training scheme itself. This is of high practical relevance: (1)\nas techniques for pre-training models are becoming increasingly diverse,\nunderstanding the interplay between these techniques and attribution methods is\ncritical; (2) it sheds light on an important yet overlooked assumption of\npost-hoc attribution methods which can drastically impact model explanations\nand how they are interpreted eventually. With this finding we also present\nsimple yet effective adjustments to the classification layers, that can\nsignificantly enhance the quality of model explanations. We validate our\nfindings across several visual pre-training frameworks (fully-supervised,\nself-supervised, contrastive vision-language training) and analyse how they\nimpact explanations for a wide range of attribution methods on a diverse set of\nevaluation metrics."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15671",
    "c_title":[
      "CHROME: Clothed Human Reconstruction with Occlusion-Resilience and\n  Multiview-Consistency from a Single Image"
    ],
    "c_abstract":[
      "Reconstructing clothed humans from a single image is a fundamental task in\ncomputer vision with wide-ranging applications. Although existing monocular\nclothed human reconstruction solutions have shown promising results, they often\nrely on the assumption that the human subject is in an occlusion-free\nenvironment. Thus, when encountering in-the-wild occluded images, these\nalgorithms produce multiview inconsistent and fragmented reconstructions.\nAdditionally, most algorithms for monocular 3D human reconstruction leverage\ngeometric priors such as SMPL annotations for training and inference, which are\nextremely challenging to acquire in real-world applications. To address these\nlimitations, we propose CHROME: Clothed Human Reconstruction with\nOcclusion-Resilience and Multiview-ConsistEncy from a Single Image, a novel\npipeline designed to reconstruct occlusion-resilient 3D humans with multiview\nconsistency from a single occluded image, without requiring either ground-truth\ngeometric prior annotations or 3D supervision. Specifically, CHROME leverages a\nmultiview diffusion model to first synthesize occlusion-free human images from\nthe occluded input, compatible with off-the-shelf pose control to explicitly\nenforce cross-view consistency during synthesis. A 3D reconstruction model is\nthen trained to predict a set of 3D Gaussians conditioned on both the occluded\ninput and synthesized views, aligning cross-view details to produce a cohesive\nand accurate 3D representation. CHROME achieves significant improvements in\nterms of both novel view synthesis (upto 3 db PSNR) and geometric\nreconstruction under challenging conditions."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-28",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17176",
    "b_title":[
      "On high discrepancy $1$-factorizations of complete graphs"
    ],
    "b_abstract":[
      "We proved that for every sufficiently large $n$, the complete graph $K_{2n}$\nwith an arbitrary edge signing $\\sigma: E(K_{2n}) \\to \\{-1, +1\\}$ admits a high\ndiscrepancy $1$-factor decomposition. That is, there exists a universal\nconstant $c > 0$ such that every edge-signed $K_{2n}$ has a perfect matching\ndecomposition $\\{\\psi_1, \\ldots, \\psi_{2n-1}\\}$, where for each perfect\nmatching $\\psi_i$, the discrepancy $\\lvert \\frac{1}{n} \\sum_{e\\in E(\\psi_i)}\n\\sigma(e) \\rvert$ is at least $c$."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.17737",
    "c_title":[
      "Domination and Multistate Systems"
    ],
    "c_abstract":[
      "Domination theory has been studied extensively in the context of binary\nmonotone systems, where the structure function is a sum of products of the\ncomponent state variables, and with coefficients given by the signed domination\nfunction. Using e.g., matroid theory, many useful properties of the signed\ndomination function has been derived. In this paper we show how some of these\nresults can be extended to multistate systems. In particular, we show how the\nsigned domination function can be extended to such systems. Using M\\\"{o}bius\ninversion we show how the signed domination function can be expressed in terms\nof a multistate structure function. Moreover, using this expression we show how\ncalculating the signed domination function of a multistate system can be\nreduced to calculating the signed domination function of an associated binary\nsystem. This way many results from binary theory can easily be extended to\nmultistate theory."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-29",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04190",
    "b_title":[
      "Partition Constraints for Conjunctive Queries: Bounds and Worst-Case\n  Optimal Joins"
    ],
    "b_abstract":[
      "In the last decade, various works have used statistics on relations to\nimprove both the theory and practice of conjunctive query execution. Starting\nwith the AGM bound which took advantage of relation sizes, later works\nincorporated statistics like functional dependencies and degree constraints.\nEach new statistic prompted work along two lines; bounding the size of\nconjunctive query outputs and worst-case optimal join algorithms. In this work,\nwe continue in this vein by introducing a new statistic called a\n\\emph{partition constraint}. This statistic captures latent structure within\nrelations by partitioning them into sub-relations which each have much tighter\ndegree constraints. We show that this approach can both refine existing\ncardinality bounds and improve existing worst-case optimal join algorithms."
    ],
    "b_categories":[
      [
        "cs.DB"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13822",
    "c_title":[
      "NeurBench: Benchmarking Learned Database Components with Data and\n  Workload Drift Modeling"
    ],
    "c_abstract":[
      "Learned database components, which deeply integrate machine learning into\ntheir design, have been extensively studied in recent years. Given the dynamism\nof databases, where data and workloads continuously drift, it is crucial for\nlearned database components to remain effective and efficient in the face of\ndata and workload drift. Adaptability, therefore, is a key factor in assessing\ntheir practical applicability. However, existing benchmarks for learned\ndatabase components either overlook or oversimplify the treatment of data and\nworkload drift, failing to evaluate learned database components across a broad\nrange of drift scenarios. This paper presents NeurBench, a new benchmark suite\nthat applies measurable and controllable data and workload drift to enable\nsystematic performance evaluations of learned database components. We quantify\ndiverse types of drift by introducing a key concept called the drift factor.\nBuilding on this formulation, we propose a drift-aware data and workload\ngeneration framework that effectively simulates real-world drift while\npreserving inherent correlations. We employ NeurBench to evaluate\nstate-of-the-art learned query optimizers, learned indexes, and learned\nconcurrency control within a consistent experimental process, providing\ninsights into their performance under diverse data and workload drift\nscenarios."
    ],
    "c_categories":[
      [
        "cs.DB"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-30",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20812",
    "b_title":[
      "Towards Reliable Vector Database Management Systems: A Software Testing\n  Roadmap for 2030"
    ],
    "b_abstract":[
      "The rapid growth of Large Language Models (LLMs) and AI-driven applications\nhas propelled Vector Database Management Systems (VDBMSs) into the spotlight as\na critical infrastructure component. VDBMS specializes in storing, indexing,\nand querying dense vector embeddings, enabling advanced LLM capabilities such\nas retrieval-augmented generation, long-term memory, and caching mechanisms.\nHowever, the explosive adoption of VDBMS has outpaced the development of\nrigorous software testing methodologies tailored for these emerging systems.\nUnlike traditional databases optimized for structured data, VDBMS face unique\ntesting challenges stemming from the high-dimensional nature of vector data,\nthe fuzzy semantics in vector search, and the need to support dynamic data\nscaling and hybrid query processing. In this paper, we begin by conducting an\nempirical study of VDBMS defects and identify key challenges in test input\ngeneration, oracle definition, and test evaluation. Drawing from these\ninsights, we propose the first comprehensive research roadmap for developing\neffective testing methodologies tailored to VDBMS. By addressing these\nchallenges, the software testing community can contribute to the development of\nmore reliable and trustworthy VDBMS, enabling the full potential of LLMs and\ndata-intensive AI applications."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15134",
    "c_title":[
      "BitsAI-CR: Automated Code Review via LLM in Practice"
    ],
    "c_abstract":[
      "Code review remains a critical yet resource-intensive process in software\ndevelopment, particularly challenging in large-scale industrial environments.\nWhile Large Language Models (LLMs) show promise for automating code review,\nexisting solutions face significant limitations in precision and practicality.\nThis paper presents BitsAI-CR, an innovative framework that enhances code\nreview through a two-stage approach combining RuleChecker for initial issue\ndetection and ReviewFilter for precision verification. The system is built upon\na comprehensive taxonomy of review rules and implements a data flywheel\nmechanism that enables continuous performance improvement through structured\nfeedback and evaluation metrics. Our approach introduces an Outdated Rate\nmetric that can reflect developers' actual adoption of review comments,\nenabling automated evaluation and systematic optimization at scale. Empirical\nevaluation demonstrates BitsAI-CR's effectiveness, achieving 75.0% precision in\nreview comment generation. For the Go language which has predominant usage at\nByteDance, we maintain an Outdated Rate of 26.7%. The system has been\nsuccessfully deployed at ByteDance, serving over 12,000 Weekly Active Users\n(WAU). Our work provides valuable insights into the practical application of\nautomated code review and offers a blueprint for organizations seeking to\nimplement automated code reviews at scale."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-31",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01028",
    "b_title":[
      "KaLM-Embedding: Superior Training Data Brings A Stronger Embedding Model"
    ],
    "b_abstract":[
      "As retrieval-augmented generation prevails in large language models,\nembedding models are becoming increasingly crucial. Despite the growing number\nof general embedding models, prior work often overlooks the critical role of\ntraining data quality. In this work, we introduce KaLM-Embedding, a general\nmultilingual embedding model that leverages a large quantity of cleaner, more\ndiverse, and domain-specific training data. Our model has been trained with key\ntechniques proven to enhance performance: (1) persona-based synthetic data to\ncreate diversified examples distilled from LLMs, (2) ranking consistency\nfiltering to remove less informative samples, and (3) semi-homogeneous task\nbatch sampling to improve training efficacy. Departing from traditional\nBERT-like architectures, we adopt Qwen2-0.5B as the pre-trained model,\nfacilitating the adaptation of auto-regressive language models for general\nembedding tasks. Extensive evaluations of the MTEB benchmark across multiple\nlanguages show that our model outperforms others of comparable size, setting a\nnew standard for multilingual embedding models with <1B parameters."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01275",
    "c_title":[
      "Enhancing Non-English Capabilities of English-Centric Large Language\n  Models through Deep Supervision Fine-Tuning"
    ],
    "c_abstract":[
      "Large language models (LLMs) have demonstrated significant progress in\nmultilingual language understanding and generation. However, due to the\nimbalance in training data, their capabilities in non-English languages are\nlimited. Recent studies revealed the English-pivot multilingual mechanism of\nLLMs, where LLMs implicitly convert non-English queries into English ones at\nthe bottom layers and adopt English for thinking at the middle layers. However,\ndue to the absence of explicit supervision for cross-lingual alignment in the\nintermediate layers of LLMs, the internal representations during these stages\nmay become inaccurate. In this work, we introduce a deep supervision\nfine-tuning method (DFT) that incorporates additional supervision in the\ninternal layers of the model to guide its workflow. Specifically, we introduce\ntwo training objectives on different layers of LLMs: one at the bottom layers\nto constrain the conversion of the target language into English, and another at\nthe middle layers to constrain reasoning in English. To effectively achieve the\nguiding purpose, we designed two types of supervision signals: logits and\nfeature, which represent a stricter constraint and a relatively more relaxed\nguidance. Our method guides the model to not only consider the final generated\nresult when processing non-English inputs but also ensure the accuracy of\ninternal representations. We conducted extensive experiments on typical\nEnglish-centric large models, LLaMA-2 and Gemma-2, and the results on multiple\nmultilingual datasets show that our method significantly outperforms\ntraditional fine-tuning methods."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-32",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11479",
    "b_title":[
      "High Quality Single Crystal of Kitaev Spin Liquid Candidate Material\n  RuBr3 Synthesized under High Pressure"
    ],
    "b_abstract":[
      "Kitaev quantum spin liquids have attracted significant attention in condensed\nmatter physics over the past decade. To understand their emergent quantum\nphenomena, high-quality single crystals of substantial size are essential.\nHere, we report the synthesis of single crystals of the Kitaev quantum spin\nliquid candidate RuBr3, achieving millimeter-sized crystals through a self-flux\nmethod under high pressure and high temperature conditions. The crystals\nexhibit well-defined cleavage planes with a lustrous appearance. Transport\ncharacterizations exhibit a narrow band-gap semiconducting behavior with 0.13\neV and 0.11 eV band-gap in ab plane and along c axis, respectively. Magnetic\nmeasurement shows a transition to antiferromagnetic (AFM) state at\napproximately 29 K both in ab plane and along c axis. Notably, the N\\'eel\ntemperature increases to 34 K with an applied magnetic field of up to 7 T in\nthe ab plane, but without any change along c axis. The large size and high\nquality of RuBr3 single crystals provide a valuable platform for investigating\nvarious interactions, particularly the Kitaev interaction, and for elucidating\nthe intrinsic physical properties of Kitaev quantum spin liquids."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.13585",
    "c_title":[
      "Solving fractional electron states in twisted MoTe$_2$ with deep neural\n  network"
    ],
    "c_abstract":[
      "The emergence of moir\\'e materials, such as twisted transition-metal\ndichalcogenides (TMDs), has created a fertile ground for discovering novel\nquantum phases of matter. However, solving many-electron problems in moir\\'e\nsystems presents significant challenges due to strong electron correlation and\nstrong moir\\'e band mixing. Recent advancements in neural quantum states hold\nthe promise for accurate and unbiased variational solutions. Here, we introduce\na powerful neural wavefunction to solve ground states of twisted MoTe2 across\nvarious fractional fillings, reaching unprecedented accuracy and system size.\nFrom the full structure factor and quantum weight, we conclude that our neural\nwavefunction accurately captures both the electron crystal at $\\nu = 1\/3$ and\nvarious fractional quantum liquids in a unified manner."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-33",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11411",
    "b_title":[
      "Beyond the Hype: Benchmarking LLM-Evolved Heuristics for Bin Packing"
    ],
    "b_abstract":[
      "Coupling Large Language Models (LLMs) with Evolutionary Algorithms has\nrecently shown significant promise as a technique to design new heuristics that\noutperform existing methods, particularly in the field of combinatorial\noptimisation. An escalating arms race is both rapidly producing new heuristics\nand improving the efficiency of the processes evolving them. However, driven by\nthe desire to quickly demonstrate the superiority of new approaches, evaluation\nof the new heuristics produced for a specific domain is often cursory: testing\non very few datasets in which instances all belong to a specific class from the\ndomain, and on few instances per class. Taking bin-packing as an example, to\nthe best of our knowledge we conduct the first rigorous benchmarking study of\nnew LLM-generated heuristics, comparing them to well-known existing heuristics\nacross a large suite of benchmark instances using three performance metrics.\nFor each heuristic, we then evolve new instances won by the heuristic and\nperform an instance space analysis to understand where in the feature space\neach heuristic performs well. We show that most of the LLM heuristics do not\ngeneralise well when evaluated across a broad range of benchmarks in contrast\nto existing simple heuristics, and suggest that any gains from generating very\nspecialist heuristics that only work in small areas of the instance space need\nto be weighed carefully against the considerable cost of generating these\nheuristics."
    ],
    "b_categories":[
      [
        "cs.NE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07375",
    "c_title":[
      "A RankNet-Inspired Surrogate-Assisted Hybrid Metaheuristic for Expensive\n  Coverage Optimization"
    ],
    "c_abstract":[
      "Coverage optimization generally involves deploying a set of facilities to\nbest satisfy the demands of specified points, with broad applications in fields\nsuch as location science and sensor networks. Recent applications reveal that\nthe subset site selection coupled with continuous angular parameter\noptimization can be formulated as Mixed-Variable Optimization Problems (MVOPs).\nMeanwhile, high-fidelity discretization and visibility analysis significantly\nincrease computational cost and complexity, evolving the MVOP into an Expensive\nMixed-Variable Optimization Problem (EMVOP). While canonical Evolutionary\nAlgorithms have yielded promising results, their reliance on numerous fitness\nevaluations is too costly for our problem. Furthermore, most surrogate-assisted\nmethods face limitations due to their reliance on regression-based models. To\naddress these issues, we propose the RankNet-Inspired Surrogate-assisted Hybrid\nMetaheuristic (RI-SHM), an extension of our previous work. RI-SHM integrates\nthree key components: (1) a RankNet-based pairwise global surrogate that\ninnovatively predicts rankings between pairs of individuals, bypassing the\nchallenges of fitness estimation in discontinuous solution space; (2) a\nsurrogate-assisted local Estimation of Distribution Algorithm that enhances\nlocal exploitation and helps escape from local optima; and (3) a fitness\ndiversity-driven switching strategy that dynamically balances exploration and\nexploitation. Experiments demonstrate that our algorithm can effectively handle\nlarge-scale coverage optimization tasks of up to 300 dimensions and more than\n1,800 targets within desirable runtime. Compared to state-of-the-art algorithms\nfor EMVOPs, RI-SHM consistently outperforms them by up to 56.5$\\%$ across all\ntested instances."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-34",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18363",
    "b_title":[
      "Stretchable Capacitive and Resistive Strain Sensors: Accessible\n  Manufacturing Using Direct Ink Writing"
    ],
    "b_abstract":[
      "As robotics advances toward integrating soft structures, anthropomorphic\nshapes, and complex tasks, soft and highly stretchable mechanotransducers are\nbecoming essential. To reliably measure tactile and proprioceptive data while\nensuring shape conformability, stretchability, and adaptability, researchers\nhave explored diverse transduction principles alongside scalable and versatile\nmanufacturing techniques. Nonetheless, many current methods for stretchable\nsensors are designed to produce a single sensor configuration, thereby limiting\ndesign flexibility. Here, we present an accessible, flexible, printing-based\nfabrication approach for customizable, stretchable sensors. Our method employs\na custom-built printhead integrated with a commercial 3D printer to enable\ndirect ink writing (DIW) of conductive ink onto cured silicone substrates. A\nlayer-wise fabrication process, facilitated by stackable trays, allows for the\ndeposition of multiple liquid conductive ink layers within a silicone matrix.\nTo demonstrate the method's capacity for high design flexibility, we fabricate\nand evaluate both capacitive and resistive strain sensor morphologies.\nExperimental characterization showed that the capacitive strain sensor\npossesses high linearity (R^2 = 0.99), high sensitivity near the 1.0\ntheoretical limit (GF = 0.95), minimal hysteresis (DH = 1.36%), and large\nstretchability (550%), comparable to state-of-the-art stretchable strain\nsensors reported in the literature."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.01304",
    "c_title":[
      "Towards Autonomous Wood-Log Grasping with a Forestry Crane: Simulator\n  and Benchmarking"
    ],
    "c_abstract":[
      "Forestry machines operated in forest production environments face challenges\nwhen performing manipulation tasks, especially regarding the complicated\ndynamics of underactuated crane systems and the heavy weight of logs to be\ngrasped. This study investigates the feasibility of using reinforcement\nlearning for forestry crane manipulators in grasping and lifting heavy wood\nlogs autonomously. We first build a simulator using Mujoco physics engine to\ncreate realistic scenarios, including modeling a forestry crane with 8 degrees\nof freedom from CAD data and wood logs of different sizes. We further implement\na velocity controller for autonomous log grasping with deep reinforcement\nlearning using a curriculum strategy. Utilizing our new simulator, the proposed\ncontrol strategy exhibits a success rate of 96% when grasping logs of different\ndiameters and under random initial configurations of the forestry crane. In\naddition, reward functions and reinforcement learning baselines are implemented\nto provide an open-source benchmark for the community in large-scale\nmanipulation tasks. A video with several demonstrations can be seen at\nhttps:\/\/www.acin.tuwien.ac.at\/en\/d18a\/"
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-35",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03959",
    "b_title":[
      "Phase diagram of the hard-sphere potential model in three and four\n  dimensions using a pseudo-hard-sphere potential"
    ],
    "b_abstract":[
      "The hard-sphere potential has become a cornerstone in the study of both\nmolecular and complex fluids. Despite its mathematical simplicity, its\nimplementation in fixed time-step molecular simulations remains a formidable\nchallenge due to the discontinuity at contact. To circumvent the issues\nassociated with the ill-defined force at contact, a continuous\npotential--referred to here as the pseudo-hard-sphere (pHS) potential--has\nrecently been proposed [J. Chem, Phys. 149, 164907 (2018)]. This potential is\nconstructed to match the second virial coefficient of the hard-sphere potential\nand is expected to mimic its thermodynamic properties. However, this hypothesis\nhas only been partially validated within the fluid region of the phase diagram\nfor hard-sphere dispersions in two and three dimensions. In this contribution,\nwe examine the ability of the continuous pHS potential to reproduce the\nequation of state of a hard-sphere fluid, not only in the fluid phase but also\nacross the fluid-solid coexistence region. Our focus is primarily on\nhard-sphere systems in three and four dimensions. We compare the results\nobtained from Brownian dynamics simulations of the pHS potential with those\nderived from refined event-driven simulations of the corresponding hard-sphere\npotential. Furthermore, we provide a comparative analysis with theoretical\nequations of state based on both mean-field and integral equation\napproximations."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.05166",
    "c_title":[
      "Stirring supercooled colloidal liquids at the particle scale"
    ],
    "c_abstract":[
      "We study the decay of tangential velocity profiles with distance from a local\ndisturbance in hard-sphere colloidal suspensions as the colloidal glass\ntransition is approached. The disturbance, generated by a dimer of\nsuperparamagnetic particles rotated by an external magnetic field, enables a\nprecise characterization of the system's response through confocal microscopy\nand tracking of individual particle dynamics. The tangential velocity profiles\nexhibit nearly exponential decay with distance. As particle density increases\ntoward the colloidal glass transition, the characteristic length scale derived\nfrom exponential fits grows. We also observe that the colloidal particles slip\nagainst the rotating dimer, with less slip in samples which are closer to the\nglass transition."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-36",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03613",
    "b_title":[
      "CLIP is Strong Enough to Fight Back: Test-time Counterattacks towards\n  Zero-shot Adversarial Robustness of CLIP"
    ],
    "b_abstract":[
      "Despite its prevalent use in image-text matching tasks in a zero-shot manner,\nCLIP has been shown to be highly vulnerable to adversarial perturbations added\nonto images. Recent studies propose to finetune the vision encoder of CLIP with\nadversarial samples generated on the fly, and show improved robustness against\nadversarial attacks on a spectrum of downstream datasets, a property termed as\nzero-shot robustness. In this paper, we show that malicious perturbations that\nseek to maximise the classification loss lead to `falsely stable' images, and\npropose to leverage the pre-trained vision encoder of CLIP to counterattack\nsuch adversarial images during inference to achieve robustness. Our paradigm is\nsimple and training-free, providing the first method to defend CLIP from\nadversarial attacks at test time, which is orthogonal to existing methods\naiming to boost zero-shot adversarial robustness of CLIP. We conduct\nexperiments across 16 classification datasets, and demonstrate stable and\nconsistent gains compared to test-time defence methods adapted from existing\nadversarial robustness studies that do not rely on external networks, without\nnoticeably impairing performance on clean images. We also show that our\nparadigm can be employed on CLIP models that have been adversarially finetuned\nto further enhance their robustness at test time. Our code is available\n\\href{https:\/\/github.com\/Sxing2\/CLIP-Test-time-Counterattacks}{here}."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15138",
    "c_title":[
      "VideoGen-of-Thought: Step-by-step generating multi-shot video with\n  minimal manual intervention"
    ],
    "c_abstract":[
      "Current video generation models excel at short clips but fail to produce\ncohesive multi-shot narratives due to disjointed visual dynamics and fractured\nstorylines. Existing solutions either rely on extensive manual\nscripting\/editing or prioritize single-shot fidelity over cross-scene\ncontinuity, limiting their practicality for movie-like content. We introduce\nVideoGen-of-Thought (VGoT), a step-by-step framework that automates multi-shot\nvideo synthesis from a single sentence by systematically addressing three core\nchallenges: (1) Narrative Fragmentation: Existing methods lack structured\nstorytelling. We propose dynamic storyline modeling, which first converts the\nuser prompt into concise shot descriptions, then elaborates them into detailed,\ncinematic specifications across five domains (character dynamics, background\ncontinuity, relationship evolution, camera movements, HDR lighting), ensuring\nlogical narrative progression with self-validation. (2) Visual Inconsistency:\nExisting approaches struggle with maintaining visual consistency across shots.\nOur identity-aware cross-shot propagation generates identity-preserving\nportrait (IPP) tokens that maintain character fidelity while allowing trait\nvariations (expressions, aging) dictated by the storyline. (3) Transition\nArtifacts: Abrupt shot changes disrupt immersion. Our adjacent latent\ntransition mechanisms implement boundary-aware reset strategies that process\nadjacent shots' features at transition points, enabling seamless visual flow\nwhile preserving narrative continuity. VGoT generates multi-shot videos that\noutperform state-of-the-art baselines by 20.4% in within-shot face consistency\nand 17.4% in style consistency, while achieving over 100% better cross-shot\nconsistency and 10x fewer manual adjustments than alternatives."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-37",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10901",
    "b_title":[
      "Involutions on Tip-Augmented Plane Trees for Leaf Interchanging"
    ],
    "b_abstract":[
      "This paper constructs two involutions on tip-augmented plane trees, as\ndefined by Donaghey, that interchange two distinct types of leaves while\npreserving all other leaves. These two involutions provide bijective\nexplanations addressing a question posed by Dong, Du, Ji, and Zhang in their\nwork."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.06886",
    "c_title":[
      "On the extreme complexity of certain nearly regular graphs"
    ],
    "c_abstract":[
      "The complexity of a graph is the number of its labeled spanning trees. It is\ndemonstrated that the seven known triangle-free strongly regular graphs, such\nas the Higman-Sims graph, are graphs of maximal complexity among all graphs of\nthe same order and degree; their complements are shown to be of minimal\ncomplexity. A generalization to nearly regular graphs with two distinct\neigevalues of the Laplacian is presented. Conjectures and applications of these\nresults to biological problems on neuronal activity are described."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-38",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13226",
    "b_title":[
      "Auto-Configuring Entity Resolution Pipelines"
    ],
    "b_abstract":[
      "The same real-world entity (e.g., a movie, a restaurant, a person) may be\ndescribed in various ways on different datasets. Entity Resolution (ER) aims to\nfind such different descriptions of the same entity, this way improving data\nquality and, therefore, data value. However, an ER pipeline typically involves\nseveral steps (e.g., blocking, similarity estimation, clustering), with each\nstep requiring its own configurations and tuning. The choice of the best\nconfiguration, among a vast number of possible combinations, is a\ndataset-specific and labor-intensive task both for novice and expert users,\nwhile it often requires some ground truth knowledge of real matches. In this\nwork, we examine ways of automatically configuring a state of-the-art\nend-to-end ER pipeline based on pre-trained language models under two settings:\n(i) When ground truth is available. In this case, sampling strategies that are\ntypically used for hyperparameter optimization can significantly restrict the\nsearch of the configuration space. We experimentally compare their relative\neffectiveness and time efficiency, applying them to ER pipelines for the first\ntime. (ii) When no ground truth is available. In this case, labelled data\nextracted from other datasets with available ground truth can be used to train\na regression model that predicts the relative effectiveness of parameter\nconfigurations. Experimenting with 11 ER benchmark datasets, we evaluate the\nrelative performance of existing techniques that address each problem, but have\nnot been applied to ER before."
    ],
    "b_categories":[
      [
        "cs.DB"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16190",
    "c_title":[
      "AdaNDV: Adaptive Number of Distinct Value Estimation via Learning to\n  Select and Fuse Estimators"
    ],
    "c_abstract":[
      "Estimating the Number of Distinct Values (NDV) is fundamental for numerous\ndata management tasks, especially within database applications. However, most\nexisting works primarily focus on introducing new statistical or learned\nestimators, while identifying the most suitable estimator for a given scenario\nremains largely unexplored. Therefore, we propose AdaNDV, a learned method\ndesigned to adaptively select and fuse existing estimators to address this\nissue. Specifically, (1) we propose to use learned models to distinguish\nbetween overestimated and underestimated estimators and then select appropriate\nestimators from each category. This strategy provides a complementary\nperspective by integrating overestimations and underestimations for error\ncorrection, thereby improving the accuracy of NDV estimation. (2) To further\nintegrate the estimation results, we introduce a novel fusion approach that\nemploys a learned model to predict the weights of the selected estimators and\nthen applies a weighted sum to merge them. By combining these strategies, the\nproposed AdaNDV fundamentally distinguishes itself from previous works that\ndirectly estimate NDV. Moreover, extensive experiments conducted on real-world\ndatasets, with the number of individual columns being several orders of\nmagnitude larger than in previous studies, demonstrate the superior performance\nof our method."
    ],
    "c_categories":[
      [
        "cs.DB"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-39",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08713",
    "b_title":[
      "The low-frequency flattening of the radio spectrum of giant HII regions\n  in M 101"
    ],
    "b_abstract":[
      "In galaxies, the flattening of the spectrum at low radio frequencies below\n300 MHz has been the subject of some debate. A turnover at low frequencies\ncould be caused by multiple physical processes, which can yield new insights\ninto the properties of the ionised gas in the interstellar medium. We\ninvestigate the existence and nature of the low-frequency turnover in the HII\nregions of M 101. We study the nearby galaxy M 101 using the LOw Frequency\nARray (LOFAR) at frequencies of 54 and 144 MHz, Apertif at 1370 MHz, and\npublished combined map from the Very Large Array (VLA) and Effelesberg\ntelescope at 4850 MHz. The spectral index between 54 and 144 MHz is inverted at\nthe centres of HII regions. We find a significant low-frequency flattening at\nthe centres of five out of six HII regions that we selected for this study. The\nlow frequency flattening in HII regions of M 101 can be explained with two\ndifferent free-free absorption models. The flattening is localised in a region\nsmaller than 1.5 kpc and can only be detected with high resolution (better than\n45''). The detection of low frequency flattening has important consequences for\nusing radio continuum observations below 100 MHz to measure extinction-free\nstar-formation rates."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02080",
    "c_title":[
      "Insight into the physical processes that shape the metallicity profiles\n  in galaxies"
    ],
    "c_abstract":[
      "The distribution of chemical elements in the star-forming regions can store\ninformation on the chemical enrichment history of the galaxies. Negative\nmetallicity gradients are expected in galaxies forming inside-out. However,\nobservations show that the metallicity profiles can be broken. We aim to study\nthe diversity of metallicity profiles that can arise in the current\ncosmological context and compare them with available observations. We also seek\nto identify the physical processes responsible for breaks in metallicity\nprofiles by using two galaxies as case studies. We analyze central galaxies\nfrom the cosmological simulations of the CIELO project, within the stellar mass\nrange [$10^{8.5}$, $10^{10.5}$] M$_\\odot$ at $z=0$. A new algorithm, DB-A, was\ndeveloped to fit multiple power laws to the metallicity profiles, enabling a\nflexible assessment of metallicity gradients in various galactic regions. The\nsimulations include detailed modeling of gas, metal-dependent cooling, star\nformation, and supernova feedback. At $z=0$, we find diverse profile shapes,\nincluding inner and outer drops and rises, with some galaxies exhibiting double\nbreaks. Gradient values align with observations. A temporal analysis of Local\nGroup analogs shows inner and outer breaks occurring at all cosmic times, with\nouter breaks being more frequent. Metallicity gradients show high variability\nat high redshift, transitioning to mild evolution at lower redshift. Most inner\nbreaks show central oxygen enhancement, linked to gas accretion and star\nformation. Inner drops result from disrupted gas due to feedback-driven\noutflows. Outer breaks with high metallicities arise from re-accreted material,\nextended star formation, and CGM-driven gas mixing. Outer drops are common at\nhigh redshift, linked to metal-poor gas accretion from cold flows. We highlight\nthe complex interplay of these processes which often act together."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-40",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01494",
    "b_title":[
      "Instantaneous convective heat transfer at the wall: a depiction of\n  turbulent boundary layer structures"
    ],
    "b_abstract":[
      "We demonstrate the ability to experimentally measure fluctuations of the\nconvective heat transfer coefficient at the wall in a turbulent boundary layer.\nFor this, we measure two-dimensional fields of wall-temperature fluctuations\nbeneath a zero-pressure-gradient turbulent boundary layer, at two moderate\nfriction Reynolds numbers ($Re_\\tau \\approx 990$ and $Re_\\tau \\approx 1800$).\nSpatiotemporal data of wall-temperature are acquired by means of a\nheated-thin-foil sensor as sensing hardware, and an infrared camera as\ntemperature detector. At low $Re_\\tau$ conditions, the fields of the Nusselt\nnumber fluctuations are populated by elongated structures comprising streamwise\nand spanwise length scales comparable to those of near-wall streaks. At higher\n$Re_\\tau$ conditions, the effective width and length of the coherent $Nu$\nfluctuations increases. These findings are based on two-point correlations, as\nwell as streamwise-spanwise energy spectra of $Nu$ fluctuations. The convective\nvelocities of the $Nu$ fluctuations are also computed with the available time\nresolution from the measurements. This allows for resolving the multi-scale\nnature of convective footprints of wall-bounded turbulence: our experimental\ndata reflect that larger streaks in the footprint convect at velocities in the\norder of the free-stream velocity, while the more energetic smaller-scale\nfeatures move at velocities in the order of $10u_\\tau$. Measurements of the\nkind presented here offer a promising method for sensing, as they can be used\nas input to flow control systems."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09145",
    "c_title":[
      "A numerical modeling of wave-inclined slats interaction for particle\n  methods"
    ],
    "c_abstract":[
      "MPS-VG, a Virtual Grating (VG) model for the Lagrangian mesh-free Moving\nParticle Semi-implicit (MPS) method is proposed for replacing conventional\nparticle-based solid modeling of gratings with a set of thin inclined slats.\nUnlike most approaches for perforated wave energy dampening devices, in which\nthe flow through the device is simplified by pressure loss or damping effects\nwithout flow deflection, MPS-VG models the angular deviation caused by\nhydrodynamic impact on inclined slats. Both accuracy and computational\nperformance of the model were checked through a simulation of wet dam break\nscenarios with the grating structures placed horizontally or vertically. The\nresults were compared with those from fully particle-based modeling. MPS-VG\ncorrectly predicted complex wave-structure interactions using a relatively\nlow-resolution model and significantly reduced processing time and memory\nstorage compared to conventional particle-based MPS modeling. The evaluation of\nthe performance of the gratings with inclined slats as wave energy dampers\nrevealed the horizontal gratings outperformed the vertical ones. Therefore,\nqualitative and quantitative agreements strengthened the potential of MPS-VG as\na practical and computationally efficient tool for the study of multi-scale\nphenomena of wave impacts on grating with inclined slats."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-41",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13052",
    "b_title":[
      "One-Class Domain Adaptation via Meta-Learning"
    ],
    "b_abstract":[
      "The deployment of IoT (Internet of Things) sensor-based machine learning\nmodels in industrial systems for anomaly classification tasks poses significant\nchallenges due to distribution shifts, as the training data acquired in\ncontrolled laboratory settings may significantly differ from real-time data in\nproduction environments. Furthermore, many real-world applications cannot\nprovide a substantial number of labeled examples for each anomalous class in\nevery new environment. It is therefore crucial to develop adaptable machine\nlearning models that can be effectively transferred from one environment to\nanother, enabling rapid adaptation using normal operational data. We extended\nthis problem setting to an arbitrary classification task and formulated the\none-class domain adaptation (OC-DA) problem setting. We took a meta-learning\napproach to tackle the challenge of OC-DA, and proposed a task sampling\nstrategy to adapt any bi-level meta-learning algorithm to OC-DA. We modified\nthe well-established model-agnostic meta-learning (MAML) algorithm and\nintroduced the OC-DA MAML algorithm. We provided a theoretical analysis showing\nthat OC-DA MAML optimizes for meta-parameters that enable rapid one-class\nadaptation across domains. The OC-DA MAML algorithm is evaluated on the\nRainbow-MNIST meta-learning benchmark and on a real-world dataset of\nvibration-based sensor readings. The results show that OC-DA MAML significantly\nimproves the performance on the target domains and outperforms MAML using the\nstandard task sampling strategy."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04054",
    "c_title":[
      "Precision Agriculture Revolution: Integrating Digital Twins and Advanced\n  Crop Recommendation for Optimal Yield"
    ],
    "c_abstract":[
      "With the help of a digital twin structure, Agriculture 4.0 technologies like\nweather APIs (Application programming interface), GPS (Global Positioning\nSystem) modules, and NPK (Nitrogen, Phosphorus and Potassium) soil sensors and\nmachine learning recommendation models, we seek to revolutionize agricultural\nproduction through this concept. In addition to providing precise crop growth\nforecasts, the combination of real-time data on soil composition,\nmeteorological dynamics, and geographic coordinates aims to support crop\nrecommendation models and simulate predictive scenarios for improved water and\npesticide management."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-42",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05331",
    "b_title":[
      "Modal Force Partitioning -- A Method for Determining the Aerodynamic\n  Loads for Decomposed Flow Modes with Application to Aeroacoustic Noise"
    ],
    "b_abstract":[
      "Aerodynamic loads play a central role in many fluid dynamics applications,\nand we present a method for identifying the structures (or modes) in a flow\nthat make dominant contributions to the time-varying aerodynamic loads in a\nflow. The method results from the combination of the force partitioning method\n(Menon and Mittal, J. Fluid Mech., 907:A37, 2021) and modal decomposition\ntechniques such as Reynolds decomposition, triple decomposition, and proper\northogonal decomposition, and is applied here to three distinct flows -\ntwo-dimensional flows past a circular cylinder and an airfoil, and the\nthree-dimensional flow over a revolving rectangular wing. We show that the\nforce partitioning method applied to modal decomposition of velocity fields\nresults in complex, and difficult to interpret inter-modal interactions. We\ntherefore propose and apply modal decomposition directly to the $Q$-field\nassociated with these flows. The variable $Q$ is a non-linear observable that\nis typically used to identify vortices in a flow, and we find that the direct\ndecomposition of $Q$ leads to results that are more amenable to interpretation.\nWe also demonstrate that this modal force partitioning can be extended to\nprovide insights into the far-field aeroacoustic loading noise of these flows."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.05976",
    "c_title":[
      "Self-similar Features in Sub-secondary Breakup of a Droplet and Ligament\n  Mediated Fragmentation under Extreme Conditions"
    ],
    "c_abstract":[
      "Droplet formation is relevant in many applications spanning natural and\nartificial settings. Comprehending droplet aerobreakup or air-assisted\nsecondary atomization is challenging, especially in high-speed flow scenarios.\nThis entails multi-scale interface deformations with intricate wave dynamics\nthat conform to a non-linear cascade. In the present study, we look into\nshockwave-induced breakups and associated intermediate processes happening at\nsmaller spatiotemporal scales across the disintegrating droplet interface at\ndifferent Weber numbers ($We \\sim 10^3$). We observe the undulations to follow\nbreakup patterns that resemble a scaled-down version of a secondary atomization\nevent. These sub-secondary breakup processes end with corrugated ligaments that\ngenerate the final daughter droplets. The size distribution of these droplets\nis estimated using a Depth from Defocus (DFD) technique. These illustrate the\ntransient nature of aerobreakup, where the normalized statistics in subsequent\ntime periods and different $We$ are observed to follow a universal\ndistribution. This conforms to a gamma distribution where the associated fit\nparameters agree well with the coefficients determined from ligament shape\nfactors, corresponding to the limit associated with most extreme corrugations.\nScaling laws based on $We$ are deduced for the averaged statistics using a high\nenergy chaotic breakup mechanism. These observations reinforce the idea of a\nself-similar mechanism for catastrophic aerobreakup of a droplet."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-43",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17072",
    "b_title":[
      "Decoding Financial Health in Kenyas' Medical Insurance Sector: A\n  Data-Driven Cluster Analysis"
    ],
    "b_abstract":[
      "This study examines insurance companies' financial performance and reporting\ntrends within the medical sector using advanced clustering techniques to\nidentify distinct patterns. Four clusters were identified by analyzing\nfinancial ratios and time series data, each representing unique financial\nperformance and reporting consistency combinations. Dynamic Time Warping (DTW)\nand KMeans clustering were employed to capture temporal variations and uncover\nkey insights into company behaviors. The findings reveal that resilient\nperformers consistently report and have financial stability, making them\nreliable options for policyholders. In contrast, clusters of underperforming\ncompanies and those with reporting gaps highlight operational challenges and\nissues related to data consistency. These insights emphasize the importance of\ntransparency and timely reporting to ensure the sector's resilience. This study\ncontributes to the literature by integrating time series analysis into\nfinancial clustering, offering practical recommendations for improving data\ngovernance and financial stability in the insurance sector. Future research\ncould further investigate non-financial indicators and explore alternative\nclustering methods to provide a deeper understanding of performance dynamics."
    ],
    "b_categories":[
      [
        "q-fin.CP"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2501.16697",
    "c_title":[
      "An Analysis of the Interdependence Between Peanut and Other Agricultural\n  Commodities in China's Futures Market"
    ],
    "c_abstract":[
      "This study analyzes historical data from five agricultural commodities in the\nChinese futures market to explore the correlation, cointegration, and Granger\ncausality between Peanut futures and related futures. Multivariate linear\nregression models are constructed for prices and logarithmic returns, while\ndynamic relationships are examined using VAR and DCC-EGARCH models. The results\nreveal a significant dynamic linkage between Peanut and Soybean Oil futures\nthrough DCC-EGARCH, whereas the VAR model suggests limited influence from other\nfutures. Additionally, the application of MLP, CNN, and LSTM neural networks\nfor price prediction highlights the critical role of time step configurations\nin forecasting accuracy. These findings provide valuable insights into the\ninterconnectedness of agricultural futures markets and the efficacy of advanced\nmodeling techniques in financial analysis."
    ],
    "c_categories":[
      [
        "q-fin.CP"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-44",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10141",
    "b_title":[
      "Mapless Collision-Free Flight via MPC using Dual KD-Trees in Cluttered\n  Environments"
    ],
    "b_abstract":[
      "Collision-free flight in cluttered environments is a critical capability for\nautonomous quadrotors. Traditional methods often rely on detailed 3D map\nconstruction, trajectory generation, and tracking. However, this cascade\npipeline can introduce accumulated errors and computational delays, limiting\nflight agility and safety. In this paper, we propose a novel method for\nenabling collision-free flight in cluttered environments without explicitly\nconstructing 3D maps or generating and tracking collision-free trajectories.\nInstead, we leverage Model Predictive Control (MPC) to directly produce safe\nactions from sparse waypoints and point clouds from a depth camera. These\nsparse waypoints are dynamically adjusted online based on nearby obstacles\ndetected from point clouds. To achieve this, we introduce a dual KD-Tree\nmechanism: the Obstacle KD-Tree quickly identifies the nearest obstacle for\navoidance, while the Edge KD-Tree provides a robust initial guess for the MPC\nsolver, preventing it from getting stuck in local minima during obstacle\navoidance. We validate our approach through extensive simulations and\nreal-world experiments. The results show that our approach significantly\noutperforms the mapping-based methods and is also superior to imitation\nlearning-based methods, demonstrating reliable obstacle avoidance at up to 12\nm\/s in simulations and 6 m\/s in real-world tests. Our method provides a simple\nand robust alternative to existing methods."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02277",
    "c_title":[
      "Active Robot Curriculum Learning from Online Human Demonstrations"
    ],
    "c_abstract":[
      "Learning from Demonstrations (LfD) allows robots to learn skills from human\nusers, but its effectiveness can suffer due to sub-optimal teaching, especially\nfrom untrained demonstrators. Active LfD aims to improve this by letting robots\nactively request demonstrations to enhance learning. However, this may lead to\nfrequent context switches between various task situations, increasing the human\ncognitive load and introducing errors to demonstrations. Moreover, few prior\nstudies in active LfD have examined how these active query strategies may\nimpact human teaching in aspects beyond user experience, which can be crucial\nfor developing algorithms that benefit both robot learning and human teaching.\nTo tackle these challenges, we propose an active LfD method that optimizes the\nquery sequence of online human demonstrations via Curriculum Learning (CL),\nwhere demonstrators are guided to provide demonstrations in situations of\ngradually increasing difficulty. We evaluate our method across four simulated\nrobotic tasks with sparse rewards and conduct a user study (N=26) to\ninvestigate the influence of active LfD methods on human teaching regarding\nteaching performance, post-guidance teaching adaptivity, and teaching\ntransferability. Our results show that our method significantly improves\nlearning performance compared to three other LfD baselines in terms of the\nfinal success rate of the converged policy and sample efficiency. Additionally,\nresults from our user study indicate that our method significantly reduces the\ntime required from human demonstrators and decreases failed demonstration\nattempts. It also enhances post-guidance human teaching in both seen and unseen\nscenarios compared to another active LfD baseline, indicating enhanced teaching\nperformance, greater post-guidance teaching adaptivity, and better teaching\ntransferability achieved by our method."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-45",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06535",
    "b_title":[
      "Convergence rate for the coupon collector's problem with Stein's method"
    ],
    "b_abstract":[
      "In this paper, we consider the classical coupon collector problem with\nuniform probabilities. Since the seminal paper by P. Erd\\\"os and A. R\\'enyi\n\\cite{ErRe}, it is well-known that the renormalized number of attempts required\nto complete a collection of $n$ items distributed with uniform probability\ntends to a Gumbel distribution when $n$ goes to infinity. We propose to\ndetermine how fast this convergence takes place for a certain distance to be\nintroduced by using the so-called generator approach of Stein's method. To do\nso, we introduce a semi-group similar to the classical Ornstein-Uhlenbeck\nsemi-group and whose stationary measure is the standard Gumbel distribution. We\ngive its essential properties and apply them to prove that the renormalized\nnumber of attempts converges to the Gumbel distribution at rate $\\log n\/n$."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11233",
    "c_title":[
      "Milstein Approximation for Free Stochastic Differential Equations"
    ],
    "c_abstract":[
      "This paper derives a new numerical method for approximating Free Stochastic\nDifferential Equations with strong convergence order one. Previously, the\nauthors derived a free variant of the Euler-Maruyama method, which obeys strong\nconvergence order of 0.5. In this paper these results are extended using\nmultiple operator integrals and Taylor expansion of Operator Functions. The new\nmethod can be viewed as the free variant of the Milstein-Method for Stochastic\nDifferential Equations. In addition, we generalize the results of the free\nEuler-Maruyama method to Lp({\\phi}), 1 \\leq p \\leq \\infty."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-46",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19561",
    "b_title":[
      "Quantum Level-Crossing Induced by Anisotropy in Spin-1 Heisenberg\n  Dimers: Applications to Quantum Stirling Engines"
    ],
    "b_abstract":[
      "This work explores the thermodynamic performance of a quantum Stirling heat\nengine implemented with an anisotropic spin-1 Heisenberg dimer as the working\nmedium. Using the Hamiltonian of the system, we analyze the interplay of\nanisotropy, magnetic field, and exchange interactions and their influence on\nthe energy spectrum and the quantum level crossing. Our results reveal that\ndouble-degenerate point (DDP) and a triple-degenerate point (TDP) play pivotal\nroles in shaping the operational regimes and efficiency of the quantum Stirling\nengine. At those points, the Carnot efficiency reaches higher work output and\nenhanced stability, making it a robust candidate for optimal thermodynamic\nperformance. These findings highlight the potential of anisotropic spin systems\nas viable platforms for quantum heat engines and contribute to advancing the\nfield of quantum thermodynamics."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.15409",
    "c_title":[
      "Particle Pairing Caused Subdiffusion of Heavy Particles in the\n  Imbalanced Hubbard Model"
    ],
    "c_abstract":[
      "The imbalanced Hubbard model features a transition between dynamic regimes\ndepending on the mass ratio and coupling strength between two different\nparticle species. A slowdown of the lighter particle transport can be\nattributed to an emergent effective disorder induced by the heavy particles for\nhigh mass ratio and strong coupling. This subdiffusive regime has been\ninterpreted as a Griffiths phase, linking the effect to the coexistence of\nmetallic and insulating regions. Here, we investigate the dynamics of the heavy\nparticles, which also reveals subdiffusive behavior, yet cannot be explained\nwithin the Griffiths picture. We demonstrate that heavy particles predominantly\nform small clusters, mainly pairs, during the dynamical process, which reduces\ntheir propagation speed and transiently shifts the time-dependent diffusion\nconstant into the subdiffusive regime at late times. The necessary attraction\nbetween particles driving this process can be understood within the\nBorn-Oppenheimer approximation. We introduce a classical one-dimensional random\nwalk model that can quantitatively reproduce the subdiffusion dynamics in the\nstrong coupling regime."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-47",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09404",
    "b_title":[
      "Agent-Based Simulation of a Perpetual Futures Market"
    ],
    "b_abstract":[
      "I introduce an agent-based model of a Perpetual Futures market with\nheterogeneous agents trading via a central limit order book. Perpetual Futures\n(henceforth Perps) are financial derivatives introduced by the economist Robert\nShiller, designed to peg their price to that of the underlying Spot market.\nThis paper extends the limit order book model of Chiarella et al. (2002) by\ntaking their agent and orderbook parameters, designed for a simple stock\nexchange, and applying it to the more complex environment of a Perp market with\nlong and short traders who exhibit both positional and basis-trading behaviors.\nI find that despite the simplicity of the agent behavior, the simulation is\nable to reproduce the most salient feature of a Perp market, the pegging of the\nPerp price to the underlying Spot price. In contrast to fundamental simulations\nof stock markets which aim to reproduce empirically observed stylized facts\nsuch as the leptokurtosis and heteroscedasticity of returns, volatility\nclustering and others, in derivatives markets many of these features are\nprovided exogenously by the underlying Spot price signal. This is especially\ntrue of Perps since the derivative is designed to mimic the price of the Spot\nmarket. Therefore, this paper will focus exclusively on analyzing how market\nand agent parameters such as order lifetime, trading horizon and spread affect\nthe premiums at which Perps trade with respect to the underlying Spot market. I\nshow that this simulation provides a simple and robust environment for\nexploring the dynamics of Perpetual Futures markets and their microstructure in\nthis regard. Lastly, I explore the ability of the model to reproduce the\neffects of biasing long traders to trade positionally and short traders to\nbasis-trade, which was the original intention behind the market design, and is\na tendency observed empirically in real Perp markets."
    ],
    "b_categories":[
      [
        "q-fin.TR"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2502.03194",
    "c_title":[
      "Efficient Triangular Arbitrage Detection via Graph Neural Networks"
    ],
    "c_abstract":[
      "Triangular arbitrage is a profitable trading strategy in financial markets\nthat exploits discrepancies in currency exchange rates. Traditional methods for\ndetecting triangular arbitrage opportunities, such as exhaustive search\nalgorithms and linear programming solvers, often suffer from high computational\ncomplexity and may miss potential opportunities in dynamic markets. In this\npaper, we propose a novel approach to triangular arbitrage detection using\nGraph Neural Networks (GNNs). By representing the currency exchange network as\na graph, we leverage the powerful representation and learning capabilities of\nGNNs to identify profitable arbitrage opportunities more efficiently.\nSpecifically, we formulate the triangular arbitrage problem as a graph-based\noptimization task and design a GNN architecture that captures the complex\nrelationships between currencies and exchange rates. We introduce a relaxed\nloss function to enable more flexible learning and integrate Deep Q-Learning\nprinciples to optimize the expected returns. Our experiments on a synthetic\ndataset demonstrate that the proposed GNN-based method achieves a higher\naverage yield with significantly reduced computational time compared to\ntraditional methods. This work highlights the potential of using GNNs for\nsolving optimization problems in finance and provides a promising approach for\nreal-time arbitrage detection in dynamic financial markets."
    ],
    "c_categories":[
      [
        "q-fin.TR"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-48",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04012",
    "b_title":[
      "Malleable Robots"
    ],
    "b_abstract":[
      "This chapter is about the fundamentals of fabrication, control, and\nhuman-robot interaction of a new type of collaborative robotic manipulators,\ncalled malleable robots, which are based on adjustable architectures of varying\nstiffness for achieving high dexterity with lower mobility arms. Collaborative\nrobots, or cobots, commonly integrate six or more degrees of freedom (DOF) in a\nserial arm in order to allow positioning in constrained spaces and adaptability\nacross tasks. Increasing the dexterity of robotic arms has been indeed\ntraditionally accomplished by increasing the number of degrees of freedom of\nthe system; however, once a robotic task has been established (e.g., a\npick-and-place operation), the motion of the end-effector can be normally\nachieved using less than 6-DOF (i.e., lower mobility). The aim of malleable\nrobots is to close the technological gap that separates current cobots from\nachieving flexible, accessible manufacturing automation with a reduced number\nof actuators."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15961",
    "c_title":[
      "IA-TIGRIS: An Incremental and Adaptive Sampling-Based Planner for Online\n  Informative Path Planning"
    ],
    "c_abstract":[
      "Planning paths that maximize information gain for robotic platforms has\nwide-ranging applications and significant potential impact. To effectively\nadapt to real-time data collection, informative path planning must be computed\nonline and be responsive to new observations. In this work, we present\nIA-TIGRIS, an incremental and adaptive sampling-based informative path planner\nthat can be run efficiently with onboard computation. Our approach leverages\npast planning efforts through incremental refinement while continuously\nadapting to updated world beliefs. We additionally present detailed\nimplementation and optimization insights to facilitate real-world deployment,\nalong with an array of reward functions tailored to specific missions and\nbehaviors. Extensive simulation results demonstrate IA-TIGRIS generates\nhigher-quality paths compared to baseline methods. We validate our planner on\ntwo distinct hardware platforms: a hexarotor UAV and a fixed-wing UAV, each\nhaving unique motion models and configuration spaces. Our results show up to a\n41% improvement in information gain compared to baseline methods, suggesting\nsignificant potential for deployment in real-world applications."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-49",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11889",
    "b_title":[
      "MQG4AI Towards Responsible High-risk AI -- Illustrated for Transparency\n  Focusing on Explainability Techniques"
    ],
    "b_abstract":[
      "As artificial intelligence (AI) systems become increasingly integrated into\ncritical domains, ensuring their responsible design and continuous development\nis imperative. Effective AI quality management (QM) requires tools and\nmethodologies that address the complexities of the AI lifecycle. In this paper,\nwe propose an approach for AI lifecycle planning that bridges the gap between\ngeneric guidelines and use case-specific requirements (MQG4AI). Our work aims\nto contribute to the development of practical tools for implementing\nResponsible AI (RAI) by aligning lifecycle planning with technical, ethical and\nregulatory demands. Central to our approach is the introduction of a flexible\nand customizable Methodology based on Quality Gates, whose building blocks\nincorporate RAI knowledge through information linking along the AI lifecycle in\na continuous manner, addressing AIs evolutionary character. For our present\ncontribution, we put a particular emphasis on the Explanation stage during\nmodel development, and illustrate how to align a guideline to evaluate the\nquality of explanations with MQG4AI, contributing to overall Transparency."
    ],
    "b_categories":[
      [
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05764",
    "c_title":[
      "The EU Digital Services Act: what does it mean for online advertising\n  and adtech?"
    ],
    "c_abstract":[
      "What does the Digital Services Act (DSA) mean for online advertising? We\ndescribe and analyse the DSA rules that are most relevant for online\nadvertising and adtech (advertising technology). We also highlight to what\nextent the DSA's advertising rules add something to the rules in the General\nData Protection Regulation (GDPR) and the ePrivacy Directive. The DSA\nintroduces several specific requirements for online advertising. First, the DSA\nimposes transparency requirements in relation to advertisements. Second, very\nlarge online platforms (VLOPs) should develop a publicly available repository\nwith information about the ads they presented. Third, the DSA bans\nprofiling-based advertising (behavioural advertising) if it uses sensitive data\nor if it targets children. Besides these specific provisions, the general rules\nof the DSA on illegal content also apply to advertising. Advertisements are a\nform of information, and thus subject to the general DSA rules. Moreover, we\nconclude that the DSA applies to some types of ad tech companies. For example,\nad networks, companies that connect advertisers to publishers of apps and\nwebsites, should be considered platforms. Some ad networks may even qualify as\nVLOPs. Hence, ad networks must comply with the more general obligations in the\nDSA. The application of these general rules to advertisements and ad networks\ncan have far-reaching effects that have been underexplored and deserve further\nresearch. We also show that certain aspects of the DSA are still unclear. For\ninstance, we encourage the European Commission or regulators to clarify the\nconcepts of 'online platform' and 'recipients' in the context of ad networks\nand other adtech companies."
    ],
    "c_categories":[
      [
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-50",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10249",
    "b_title":[
      "Understanding the relationships between the perceptions of burnout and\n  instability in Software Engineering"
    ],
    "b_abstract":[
      "Changes are inherent in software development, often increasing developers'\nperception of instability. Understanding the relationship between human factors\nand Software Engineering processes is crucial to mitigating and preventing\nissues. One such factor is burnout, a recognized disease that impacts\nproductivity, turnover, and, most importantly, developers' well-being.\nInvestigating the link between instability and burnout can help organizations\nimplement strategies to improve developers' work conditions and performance.\n  This study aims to identify and describe the relationship between perceived\ninstability and burnout among software developers. A cross-sectional survey was\nconducted with 411 respondents, using convenience sampling and self-selection.\nIn addition to analyzing variable relationships, confirmatory factor analysis\nwas applied.\n  Key findings include: (1) A significant positive relationship between burnout\n(exhaustion and cynicism) and team, technological, and task instability; (2) A\nweak negative relationship between efficacy and technological\/team instability,\nwith no correlation to task instability; (3) Exhaustion was the most frequently\nreported burnout symptom, while task instability was the most perceived type of\ninstability.\n  These results are valuable for both industry and academia, providing insights\nto reduce burnout and instability among software engineers. Future research can\nfurther explore the impact of instability, offering new perspectives on\nmonitoring and mitigating its effects in software development."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04976",
    "c_title":[
      "On the Diagnosis of Flaky Job Failures: Understanding and Prioritizing\n  Failure Categories"
    ],
    "c_abstract":[
      "The continuous delivery of modern software requires the execution of many\nautomated pipeline jobs. These jobs ensure the frequent release of new software\nversions while detecting code problems at an early stage. For TELUS, our\nindustrial partner in the telecommunications field, reliable job execution is\ncrucial to minimize wasted time and streamline Continuous Deployment (CD). In\nthis context, flaky job failures are one of the main issues hindering CD. Prior\nstudies proposed techniques based on machine learning to automate the detection\nof flaky jobs. While valuable, these solutions are insufficient to address the\nwaste associated with the diagnosis of flaky failures, which remain largely\nunexplored due to the wide range of underlying causes. This study examines\n4,511 flaky job failures at TELUS to identify the different categories of flaky\nfailures that we prioritize based on Recency, Frequency, and Monetary (RFM)\nmeasures. We identified 46 flaky failure categories that we analyzed using\nclustering and RFM measures to determine 14 priority categories for future\nautomated diagnosis and repair research. Our findings also provide valuable\ninsights into the evolution and impact of these categories. The identification\nand prioritization of flaky failure categories using RFM analysis introduce a\nnovel approach that can be used in other contexts."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-51",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01176",
    "b_title":[
      "Prognostics and Health Management of Wafer Chemical-Mechanical Polishing\n  System using Autoencoder"
    ],
    "b_abstract":[
      "The Prognostics and Health Management Data Challenge (PHM) 2016 tracks the\nhealth state of components of a semiconductor wafer polishing process. The\nultimate goal is to develop an ability to predict the measurement on the wafer\nsurface wear through monitoring the components health state. This translates to\ncost saving in large scale production. The PHM dataset contains many time\nseries measurements not utilized by traditional physics based approach. On the\nother hand task, applying a data driven approach such as deep learning to the\nPHM dataset is non-trivial. The main issue with supervised deep learning is\nthat class label is not available to the PHM dataset. Second, the feature space\ntrained by an unsupervised deep learner is not specifically targeted at the\npredictive ability or regression. In this work, we propose using the\nautoencoder based clustering whereby the feature space trained is found to be\nmore suitable for performing regression. This is due to having a more compact\ndistribution of samples respective to their nearest cluster means. We justify\nour claims by comparing the performance of our proposed method on the PHM\ndataset with several baselines such as the autoencoder as well as\nstate-of-the-art approaches."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10053",
    "c_title":[
      "AirRAG: Activating Intrinsic Reasoning for Retrieval Augmented\n  Generation using Tree-based Search"
    ],
    "c_abstract":[
      "Leveraging the autonomous decision-making capabilities of large language\nmodels (LLMs) has demonstrated superior performance in reasoning tasks.\nHowever, despite the success of iterative or recursive retrieval-augmented\ngeneration (RAG) techniques, these methods are often constrained to a single\nsolution space when confronted with complex problems. In this paper, we propose\na novel thinking pattern in RAG that integrates system analysis with efficient\nreasoning actions, significantly activating intrinsic reasoning capabilities\nand expanding the solution space of specific tasks via Monte Carlo Tree Search\n(MCTS), which we refer to as AirRAG. Specifically, our approach designs five\nfundamental reasoning actions, which are expanded to a broad tree-based\nreasoning space using MCTS. The approach also incorporates self-consistency\nverification to explore potential reasoning paths and inference scaling law.\nAdditionally, computationally optimal strategies are employed to allocate more\ninference resources to key actions, thereby enhancing overall performance.\nExperimental results demonstrate the effectiveness of AirRAG, showing\nsignificant performance gains on complex question-answering datasets.\nFurthermore, AirRAG is flexible and lightweight, making it easy to integrate\nwith other advanced technologies."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-52",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07456",
    "b_title":[
      "Anatomy-Aware Conditional Image-Text Retrieval"
    ],
    "b_abstract":[
      "Image-Text Retrieval (ITR) finds broad applications in healthcare, aiding\nclinicians and radiologists by automatically retrieving relevant patient cases\nin the database given the query image and\/or report, for more efficient\nclinical diagnosis and treatment, especially for rare diseases. However\nconventional ITR systems typically only rely on global image or text\nrepresentations for measuring patient image\/report similarities, which overlook\nlocal distinctiveness across patient cases. This often results in suboptimal\nretrieval performance. In this paper, we propose an Anatomical\nLocation-Conditioned Image-Text Retrieval (ALC-ITR) framework, which, given a\nquery image and the associated suspicious anatomical region(s), aims to\nretrieve similar patient cases exhibiting the same disease or symptoms in the\nsame anatomical region. To perform location-conditioned multimodal retrieval,\nwe learn a medical Relevance-Region-Aligned Vision Language (RRA-VL) model with\nsemantic global-level and region-\/word-level alignment to produce\ngeneralizable, well-aligned multi-modal representations. Additionally, we\nperform location-conditioned contrastive learning to further utilize cross-pair\nregion-level contrastiveness for improved multi-modal retrieval. We show that\nour proposed RRA-VL achieves state-of-the-art localization performance in\nphase-grounding tasks, and satisfying multi-modal retrieval performance with or\nwithout location conditioning. Finally, we thoroughly investigate the\ngeneralizability and explainability of our proposed ALC-ITR system in providing\nexplanations and preliminary diagnosis reports given retrieved patient cases\n(conditioned on anatomical regions), with proper off-the-shelf LLM prompts."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06755",
    "c_title":[
      "Sparse Autoencoders for Scientifically Rigorous Interpretation of Vision\n  Models"
    ],
    "c_abstract":[
      "To truly understand vision models, we must not only interpret their learned\nfeatures but also validate these interpretations through controlled\nexperiments. Current approaches either provide interpretable features without\nthe ability to test their causal influence, or enable model editing without\ninterpretable controls. We present a unified framework using sparse\nautoencoders (SAEs) that bridges this gap, allowing us to discover\nhuman-interpretable visual features and precisely manipulate them to test\nhypotheses about model behavior. By applying our method to state-of-the-art\nvision models, we reveal key differences in the semantic abstractions learned\nby models with different pre-training objectives. We then demonstrate the\npractical usage of our framework through controlled interventions across\nmultiple vision tasks. We show that SAEs can reliably identify and manipulate\ninterpretable visual features without model re-training, providing a powerful\ntool for understanding and controlling vision model behavior. We provide code,\ndemos and models on our project website: https:\/\/osu-nlp-group.github.io\/SAE-V."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-53",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17532",
    "b_title":[
      "The spectrum of the multi-frequency quasi-periodic CMV matrices contains\n  intervals"
    ],
    "b_abstract":[
      "We investigate the spectral structure of multi-frequency quasi-periodic CMV\nmatrices with Verblunsky coefficients defined by shifts on the $d$-dimensional\ntorus. Under the positive Lyapunov exponent regime and standard Diophantine\nfrequency conditions, we establish that the spectrum of these operators\ncontains intervals on the unit circle."
    ],
    "b_categories":[
      [
        "math.SP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.17516",
    "c_title":[
      "Spectrum of weighted composition operators. Part XI. The essential\n  spectra of some weighted composition operators on the disc algebra"
    ],
    "c_abstract":[
      "We obtain a complete description of semi-Fredholm spectra of operators of the\nform $(Tf)(z) = w(z)f(B(z)$ acting on the disc algebra in the case when $B$ is\neither elliptic or double parabolic finite Blaschke product of degree $d \\geq\n2$ and $w$ has no zeros on the unit circle. In the case when $B$ has zeros on\nthe unit circle we provide only some partial results. Our results hint on the\npossibility of interesting connections between the spectral properties of\nweighted composition operators and complex dynamics."
    ],
    "c_categories":[
      [
        "math.SP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-54",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17604",
    "b_title":[
      "OmniScience: A Domain-Specialized LLM for Scientific Reasoning and\n  Discovery"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) have demonstrated remarkable potential in\nadvancing scientific knowledge and addressing complex challenges. In this work,\nwe introduce OmniScience, a specialized large reasoning model for general\nscience, developed through three key components: (1) domain adaptive\npretraining on a carefully curated corpus of scientific literature, (2)\ninstruction tuning on a specialized dataset to guide the model in following\ndomain-specific tasks, and (3) reasoning-based knowledge distillation through\nfine-tuning to significantly enhance its ability to generate contextually\nrelevant and logically sound responses. We demonstrate the versatility of\nOmniScience by developing a battery agent that efficiently ranks molecules as\npotential electrolyte solvents or additives. Comprehensive evaluations reveal\nthat OmniScience is competitive with state-of-the-art large reasoning models on\nthe GPQA Diamond and domain-specific battery benchmarks, while outperforming\nall public reasoning and non-reasoning models with similar parameter counts. We\nfurther demonstrate via ablation experiments that domain adaptive pretraining\nand reasoning-based knowledge distillation are critical to attain our\nperformance levels, across benchmarks."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.04569",
    "c_title":[
      "ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making"
    ],
    "c_abstract":[
      "Despite recent advances in artificial intelligence (AI), it poses challenges\nto ensure personalized decision-making in tasks that are not considered in\ntraining datasets. To address this issue, we propose ValuePilot, a two-phase\nvalue-driven decision-making framework comprising a dataset generation toolkit\nDGT and a decision-making module DMM trained on the generated data. DGT is\ncapable of generating scenarios based on value dimensions and closely mirroring\nreal-world tasks, with automated filtering techniques and human curation to\nensure the validity of the dataset. In the generated dataset, DMM learns to\nrecognize the inherent values of scenarios, computes action feasibility and\nnavigates the trade-offs between multiple value dimensions to make personalized\ndecisions. Extensive experiments demonstrate that, given human value\npreferences, our DMM most closely aligns with human decisions, outperforming\nClaude-3.5-Sonnet, Gemini-2-flash, Llama-3.1-405b and GPT-4o. This research is\na preliminary exploration of value-driven decision-making. We hope it will\nstimulate interest in value-driven decision-making and personalized\ndecision-making within the community."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-55",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06466",
    "b_title":[
      "Inflatable Kirigami Crawlers"
    ],
    "b_abstract":[
      "Kirigami offers unique opportunities for guided morphing by leveraging the\ngeometry of the cuts. This work presents inflatable kirigami crawlers created\nby introducing cut patterns into heat-sealable textiles to achieve locomotion\nupon cyclic pneumatic actuation. Inflating traditional air pouches results in\nsymmetric bulging and contraction. In inflated kirigami actuators, the\naccumulated compressive forces uniformly break the symmetry, enhance\ncontraction compared to simple air pouches by two folds, and trigger local\nrotation of the sealed edges that overlap and self-assemble into an architected\nsurface with emerging scale-like features. As a result, the inflatable kirigami\nactuators exhibit a uniform, controlled contraction with asymmetric localized\nout-of-plane deformations. This process allows us to harness the geometric and\nmaterial nonlinearities to imbue inflatable textile-based kirigami actuators\nwith predictable locomotive functionalities. We thoroughly characterized the\nprogrammed deformations of these actuators and their impact on friction. We\nfound that the kirigami actuators exhibit directional anisotropic friction\nproperties when inflated, having higher friction coefficients against the\ndirection of the movement, enabling them to move across surfaces with varying\nroughness. We further enhanced the functionality of inflatable kirigami\nactuators by introducing multiple channels and segments to create functional\nsoft robotic prototypes with versatile locomotion capabilities."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16066",
    "c_title":[
      "Rejecting Outliers in 2D-3D Point Correspondences from 2D\n  Forward-Looking Sonar Observations"
    ],
    "c_abstract":[
      "Rejecting outliers before applying classical robust methods is a common\napproach to increase the success rate of estimation, particularly when the\noutlier ratio is extremely high (e.g. 90%). However, this method often relies\non sensor- or task-specific characteristics, which may not be easily\ntransferable across different scenarios. In this paper, we focus on the problem\nof rejecting 2D-3D point correspondence outliers from 2D forward-looking sonar\n(2D FLS) observations, which is one of the most popular perception device in\nthe underwater field but has a significantly different imaging mechanism\ncompared to widely used perspective cameras and LiDAR. We fully leverage the\nnarrow field of view in the elevation of 2D FLS and develop two compatibility\ntests for different 3D point configurations: (1) In general cases, we design a\npairwise length in-range test to filter out overly long or short edges formed\nfrom point sets; (2) In coplanar cases, we design a coplanarity test to check\nif any four correspondences are compatible under a coplanar setting. Both tests\nare integrated into outlier rejection pipelines, where they are followed by\nmaximum clique searching to identify the largest consistent measurement set as\ninliers. Extensive simulations demonstrate that the proposed methods for\ngeneral and coplanar cases perform effectively under outlier ratios of 80% and\n90%, respectively."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-56",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05558",
    "b_title":[
      "Large Memory Network for Recommendation"
    ],
    "b_abstract":[
      "Modeling user behavior sequences in recommender systems is essential for\nunderstanding user preferences over time, enabling personalized and accurate\nrecommendations for improving user retention and enhancing business values.\nDespite its significance, there are two challenges for current sequential\nmodeling approaches. From the spatial dimension, it is difficult to mutually\nperceive similar users' interests for a generalized intention understanding;\nfrom the temporal dimension, current methods are generally prone to forgetting\nlong-term interests due to the fixed-length input sequence. In this paper, we\npresent Large Memory Network (LMN), providing a novel idea by compressing and\nstoring user history behavior information in a large-scale memory block. With\nthe elaborated online deployment strategy, the memory block can be easily\nscaled up to million-scale in the industry. Extensive offline comparison\nexperiments, memory scaling up experiments, and online A\/B test on Douyin\nE-Commerce Search (ECS) are performed, validating the superior performance of\nLMN. Currently, LMN has been fully deployed in Douyin ECS, serving millions of\nusers each day."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11414",
    "c_title":[
      "Unbiased Learning to Rank with Query-Level Click Propensity Estimation:\n  Beyond Pointwise Observation and Relevance"
    ],
    "c_abstract":[
      "Most existing unbiased learning-to-rank (ULTR) approaches are based on the\nuser examination hypothesis, which assumes that users will click a result only\nif it is both relevant and observed (typically modeled by position). However,\nin real-world scenarios, users often click only one or two results after\nexamining multiple relevant options, due to limited patience or because their\ninformation needs have already been satisfied. Motivated by this, we propose a\nquery-level click propensity model to capture the probability that users will\nclick on different result lists, allowing for non-zero probabilities that users\nmay not click on an observed relevant result. We hypothesize that this\npropensity increases when more potentially relevant results are present, and\nrefer to this user behavior as relevance saturation bias. Our method introduces\na Dual Inverse Propensity Weighting (DualIPW) mechanism -- combining\nquery-level and position-level IPW -- to address both relevance saturation and\nposition bias. Through theoretical derivation, we prove that DualIPW can learn\nan unbiased ranking model. Experiments on the real-world Baidu-ULTR dataset\ndemonstrate that our approach significantly outperforms state-of-the-art ULTR\nbaselines. The code and dataset information can be found at\nhttps:\/\/github.com\/Trustworthy-Information-Access\/DualIPW."
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-57",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03390",
    "b_title":[
      "State-of-the-art Methods for Pseudo-Boolean Solving with SCIP"
    ],
    "b_abstract":[
      "The Pseudo-Boolean problem deals with linear or polynomial constraints with\ninteger coefficients over Boolean variables. The objective lies in optimizing a\nlinear objective function, or finding a feasible solution, or finding a\nsolution that satisfies as many constraints as possible. In the 2024\nPseudo-Boolean competition, solvers incorporating the SCIP framework won five\nout of six categories it was competing in. From a total of 1,207 instances,\nSCIP successfully solved 759, while its parallel version FiberSCIP solved 776.\nBased on the results from the competition, we further enhanced SCIP's\nPseudo-Boolean capabilities. This article discusses the results and presents\nthe winning algorithmic ideas."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.19000",
    "c_title":[
      "Bilevel optimization for the deployment of refuelling stations for\n  electric vehicles on road networks"
    ],
    "c_abstract":[
      "This work consists of a procedure to optimally select, among a group of\ncandidate sites where gas stations were already located, a sufficient number of\ncharging points in order to guarantee that an electric vehicle can make its\njourney without a problem of energy autonomy and that each selected charging\nstation has another one that serves as useful support in case of failure\n(reinforced coverage service). For this purpose, we propose a bilevel model\nthat, in a former level, minimizes the number of refuelling points necessary to\nguarantee a reinforced service coverage for all users who transit from their\norigin to destination and, as a second level, maximize the volume of demand\nthat can be satisfied subject to budgetary restrictions. With the first of the\nobjectives we are addressing the typical requirement of the administration,\nwhich consists of guaranteeing the viability of the solutions, and the second\nof the objectives is a criterion typically used by the private sector\ninitiative, compatible with the profit maximization."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-58",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08977",
    "b_title":[
      "Development and Validation of the Provider Documentation Summarization\n  Quality Instrument for Large Language Models"
    ],
    "b_abstract":[
      "As Large Language Models (LLMs) are integrated into electronic health record\n(EHR) workflows, validated instruments are essential to evaluate their\nperformance before implementation. Existing instruments for provider\ndocumentation quality are often unsuitable for the complexities of\nLLM-generated text and lack validation on real-world data. The Provider\nDocumentation Summarization Quality Instrument (PDSQI-9) was developed to\nevaluate LLM-generated clinical summaries. Multi-document summaries were\ngenerated from real-world EHR data across multiple specialties using several\nLLMs (GPT-4o, Mixtral 8x7b, and Llama 3-8b). Validation included Pearson\ncorrelation for substantive validity, factor analysis and Cronbach's alpha for\nstructural validity, inter-rater reliability (ICC and Krippendorff's alpha) for\ngeneralizability, a semi-Delphi process for content validity, and comparisons\nof high-versus low-quality summaries for discriminant validity. Seven physician\nraters evaluated 779 summaries and answered 8,329 questions, achieving over 80%\npower for inter-rater reliability. The PDSQI-9 demonstrated strong internal\nconsistency (Cronbach's alpha = 0.879; 95% CI: 0.867-0.891) and high\ninter-rater reliability (ICC = 0.867; 95% CI: 0.867-0.868), supporting\nstructural validity and generalizability. Factor analysis identified a 4-factor\nmodel explaining 58% of the variance, representing organization, clarity,\naccuracy, and utility. Substantive validity was supported by correlations\nbetween note length and scores for Succinct (rho = -0.200, p = 0.029) and\nOrganized ($\\rho = -0.190$, $p = 0.037$). Discriminant validity distinguished\nhigh- from low-quality summaries ($p < 0.001$). The PDSQI-9 demonstrates robust\nconstruct validity, supporting its use in clinical practice to evaluate\nLLM-generated summaries and facilitate safer integration of LLMs into\nhealthcare workflows."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.08220",
    "c_title":[
      "Optimization of Link Configuration for Satellite Communication Using\n  Reinforcement Learning"
    ],
    "c_abstract":[
      "Satellite communication is a key technology in our modern connected world.\nWith increasingly complex hardware, one challenge is to efficiently configure\nlinks (connections) on a satellite transponder. Planning an optimal link\nconfiguration is extremely complex and depends on many parameters and metrics.\nThe optimal use of the limited resources, bandwidth and power of the\ntransponder is crucial. Such an optimization problem can be approximated using\nmetaheuristic methods such as simulated annealing, but recent research results\nalso show that reinforcement learning can achieve comparable or even better\nperformance in optimization methods. However, there have not yet been any\nstudies on link configuration on satellite transponders. In order to close this\nresearch gap, a transponder environment was developed as part of this work. For\nthis environment, the performance of the reinforcement learning algorithm PPO\nwas compared with the metaheuristic simulated annealing in two experiments. The\nresults show that Simulated Annealing delivers better results for this static\nproblem than the PPO algorithm, however, the research in turn also underlines\nthe potential of reinforcement learning for optimization problems."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-59",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06555",
    "b_title":[
      "Chiral supersolid and dissipative time crystal in Rydberg-dressed\n  Bose-Einstein condensates with Raman-induced spin-orbit coupling"
    ],
    "b_abstract":[
      "Spin-orbit coupling (SOC) is one of the key factors that affect the chiral\nsymmetry of matter by causing the spatial symmetry breaking of the system. We\nfind that Raman-induced SOC can induce a chiral supersolid phase with a helical\nantiskyrmion lattice in balanced Rydberg-dressed two-component Bose-Einstein\ncondensates (BECs) in a harmonic trap by modulating the Raman coupling\nstrength, strong contrast with the mirror symmetric supersolid phase containing\nskyrmion-antiskyrmion lattice pair for the case of Rashba SOC. Two ground-state\nphase diagrams are presented as a function of the Rydberg interaction strength\nand the SOC strength, as well as that of the Rydberg interaction strength and\nthe Raman coupling strength, respectively. It is shown that the interplay among\nRaman-induced SOC, soft-core long-range Rydberg interactions, and contact\ninteractions favors rich ground-state structures including half-quantum vortex\nphase, stripe supersolid phase, toroidal stripe phase with a central\nAnderson-Toulouse coreless vortex, checkerboard supersolid phase, mirror\nsymmetric supersolid phase, chiral supersolid phase and standing-wave\nsupersolid phase. In addition, the effects of rotation and in-plane quadrupole\nmagnetic field on the ground state of the system are analyzed. In these two\ncases, the chiral supersolid phase is broken and the ground state tends to form\na miscible phase. Furthermore, the stability and superfluid properties of the\ntwo-component BECs with Raman-induced SOC and Rydberg interactions in free\nspace are revealed by solving the Bogoliubov-de Gennes equation. Finally, we\ndemonstrate that when the initial state is a chiral supersolid phase the\nrotating harmonic trapped system sustains dissipative continuous time crystal\nby studying the rotational dynamic behaviors of the system."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05210",
    "c_title":[
      "Two- and many-body physics of ultracold molecules dressed by dual\n  microwave fields"
    ],
    "c_abstract":[
      "We investigate the two- and many-body physics of the ultracold polar\nmolecules dressed by dual microwaves with distinct polarizations. Using Floquet\ntheory and multichannel scattering calculations, we identify a regime with the\nlargest elastic-to-inelastic scattering ratio which is favorable for performing\nevaporative cooling. Furthermore, we derive and, subsequently, validate an\neffective interaction potential that accurately captures the dynamics of\nmicrowave-shielded polar molecules (MSPMs). We also explore the ground-state\nproperties of the ultracold gases of MSPMs by computing physical quantities\nsuch as gas density, condensate fraction, momentum distribution, and\nsecond-order correlation. It is shown that the system supports a weakly\ncorrelated expanding gas state and a strongly correlated self-bound gas state.\nSince the dual-microwave scheme introduces addition control knob and is\nessential for creating ultracold Bose gases of polar molecules, our work pave\nthe way for studying two- and many-body physics of the ultracold polar\nmolecules dressed by dual microwaves."
    ],
    "c_categories":[
      [
        "cond-mat.quant-gas"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-60",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15523",
    "b_title":[
      "InteractiveEdu: An Open-source Interactive Floor for Exergame as a\n  Learning Platform"
    ],
    "b_abstract":[
      "Children tend to be constantly exposed to technologies, such as smartphones,\ntablets, and gaming consoles, drawn by the interactive and visually stimulating\nnature of digital platforms. Thus, integrating the teaching process with\ntechnological gadgets may enhance engagement and foster interactive learning\nexperiences, besides equipping students with the digital skills for today's\nincreasingly technology-driven world. The main goal of this work is to provide\nan open-source and manageable tool that teachers can use as an everyday\nactivity and as an exergame. For this, we present a prototype of an interactive\nplatform that students use to answer a quiz by moving to segments available on\nan interactive floor. All the platform design and implementation directions are\npublicly available."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11015",
    "c_title":[
      "Wireless charging and readout via textile coil for continuous full-body\n  wearable computing"
    ],
    "c_abstract":[
      "The growing use of wearable devices for activity tracking, healthcare, and\nhaptics faces challenges due to the bulkiness and short lifespan of batteries.\nIntegration of a textile-based wireless charging and readout system into\neveryday clothing can enable seamless power supply and data collection around\nthe body. However, expanding such system to cover the entire body is\nchallenging, as it increases electromagnetic interference with the body,\ndegrading the performance of wireless system. This article introduces a\nmeandered textile coil designed for body-scale, efficient wireless charging and\nreadout. The meander coil can confine a strong inductive field near the body\nsurface, ensuring W-class safe charging and sensitive readout with uW-class low\npower. Moreover, its zigzag design is simple enough for mass production on\nindustrial knitting machines. Therefore, the body-scale meander coil can\ncontinuously operate battery-free wearable devices across the body, leading to\nubiquitous deployment of continuous full-body wearable computing into everyday\nclothing."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-61",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09177",
    "b_title":[
      "Approximate Dynamical Quantum Error-Correcting Codes"
    ],
    "b_abstract":[
      "Quantum error correction plays a critical role in enabling fault-tolerant\nquantum computing by protecting fragile quantum information from noise. While\ngeneral-purpose quantum error correction codes are designed to address a wide\nrange of noise types, they often require substantial resources, making them\nimpractical for near-term quantum devices. Approximate quantum error correction\nprovides an alternative by tailoring codes to specific noise environments,\nreducing resource demands while maintaining effective error suppression.\nDynamical codes, including Floquet codes, introduce a dynamic approach to\nquantum error correction, employing time-dependent operations to stabilize\nlogical qubits. In this work, we combine the flexibility of dynamical codes\nwith the efficiency of approximate quantum error correction to offer a\npromising avenue for addressing dominant noise in quantum systems. We construct\nseveral approximate dynamical codes using the recently developed strategic code\nframework. As a special case, we recover the approximate static codes widely\nstudied in the existing literature. By analyzing these approximate dynamical\ncodes through semidefinite programming, we establish the uniqueness and\nrobustness of the optimal encoding, decoding, and check measurements. We also\ndevelop a temporal Petz recovery map suited to approximate dynamical codes."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04285",
    "c_title":[
      "Exponentially Better Bounds for Quantum Optimization via Dynamical\n  Simulation"
    ],
    "c_abstract":[
      "We provide several quantum algorithms for continuous optimization that do not\nrequire any gradient estimation. Instead, we encode the optimization problem\ninto the dynamics of a physical system and coherently simulate the time\nevolution. This allows us, in certain cases, to obtain exponentially better\nquery upper bounds relative to the best known upper bounds for gradient-based\noptimization schemes which utilize quantum computers only for the evaluation of\ngradients. Our first two algorithms can find local optima of a differentiable\nfunction $f: \\mathbb{R}^N \\rightarrow \\mathbb{R}$ by simulating either\nclassical or quantum dynamics with friction via a time-dependent Hamiltonian.\nWe show that these methods require $O(N\\kappa^2\/h_x^2\\epsilon)$ queries to a\nphase oracle to find an $\\epsilon$-approximate local optimum of a locally\nquadratic objective function, where $\\kappa$ is the condition number of the\nHessian matrix and $h_x$ is the discretization spacing. In contrast, we show\nthat gradient-based methods require $O(N(1\/\\epsilon)^{\\kappa \\log(3)\/4})$\nqueries. Our third algorithm can find the global optimum of $f$ by preparing a\nclassical low-temperature thermal state via simulation of the classical\nLiouvillian operator associated with the Nos\\'e Hamiltonian. We use results\nfrom the quantum thermodynamics literature to bound the thermalization time for\nthe discrete system. Additionally, we analyze barren plateau effects that\ncommonly plague quantum optimization algorithms and observe that our approach\nis vastly less sensitive to this problem than standard gradient-based\noptimization. Our results suggests that these dynamical optimization approaches\nmay be far more scalable for future quantum machine learning, optimization and\nvariational experiments than was widely believed."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-62",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04370",
    "b_title":[
      "FILM: Framework for Imbalanced Learning Machines based on a new unbiased\n  performance measure and a new ensemble-based technique"
    ],
    "b_abstract":[
      "This research addresses the challenges of handling unbalanced datasets for\nbinary classification tasks. In such scenarios, standard evaluation metrics are\noften biased by the disproportionate representation of the minority class.\nConducting experiments across seven datasets, we uncovered inconsistencies in\nevaluation metrics when determining the model that outperforms others for each\nbinary classification problem. This justifies the need for a metric that\nprovides a more consistent and unbiased evaluation across unbalanced datasets,\nthereby supporting robust model selection. To mitigate this problem, we propose\na novel metric, the Unbiased Integration Coefficients (UIC), which exhibits\nsignificantly reduced bias ($p < 10^{-4}$) towards the minority class compared\nto conventional metrics. The UIC is constructed by aggregating existing metrics\nwhile penalising those more prone to imbalance. In addition, we introduce the\nIdentical Partitions for Imbalance Problems (IPIP) algorithm for imbalanced ML\nproblems, an ensemble-based approach. Our experimental results show that IPIP\noutperforms other baseline imbalance-aware approaches using Random Forest and\nLogistic Regression models in three out of seven datasets as assessed by the\nUIC metric, demonstrating its effectiveness in addressing imbalanced data\nchallenges in binary classification tasks. This new framework for dealing with\nimbalanced datasets is materialized in the FILM (Framework for Imbalanced\nLearning Machines) R Package, accessible at https:\/\/github.com\/antoniogt\/FILM."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05079",
    "c_title":[
      "On a Connection Between Imitation Learning and RLHF"
    ],
    "c_abstract":[
      "This work studies the alignment of large language models with preference data\nfrom an imitation learning perspective. We establish a close theoretical\nconnection between reinforcement learning from human feedback RLHF and\nimitation learning (IL), revealing that RLHF implicitly performs imitation\nlearning on the preference data distribution. Building on this connection, we\npropose DIL, a principled framework that directly optimizes the imitation\nlearning objective. DIL provides a unified imitation learning perspective on\nalignment, encompassing existing alignment algorithms as special cases while\nnaturally introducing new variants. By bridging IL and RLHF, DIL offers new\ninsights into alignment with RLHF. Extensive experiments demonstrate that DIL\noutperforms existing methods on various challenging benchmarks."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-63",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04530",
    "b_title":[
      "Classification of polynomial models without 2-jet determination in\n  $\\mathbb{C}^3$"
    ],
    "b_abstract":[
      "An intriguing phenomenon regarding Levi-degenerate hypersurfaces is the\nexistence of nontrivial infinitesimal symmetries with vanishing 2-jets at a\npoint. In this work we consider polynomial models of Levi-degenerate real\nhypersurfaces in $\\mathbb{C}^3$ of finite Catlin multitype. Exploiting the\nstructure of the corresponding Lie algebra, we characterize completely models\nwithout 2-jet determination, including an explicit description of their\nsymmetry algebras."
    ],
    "b_categories":[
      [
        "math.CV"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.16313",
    "c_title":[
      "Area functional and majorant series estimates in the class of bounded\n  functions in the disk"
    ],
    "c_abstract":[
      "In this article, the new inequalities for the weighted sums of coefficients\nin the class of bounded functions in the disk are obtained. We develop the\nmethods of I.R.~Kayumov and S.~Ponnusamy, using E.~Reich's theorem on the\nmajorization of subordinate functions. The sharp estimates for the area of the\nimage of the disk of radius $r$ under the action of the function which is\nexpanded into a lacunary series of standard form are obtained. Under\nsignificantly lower than in \\cite{Khas} restrictions on the initial\ncoefficient, the estimates for the Bohr--Bombieri function of the Hadamard\nconvolution operator are proved. Using the example of the differentiation\noperator, it is shown that in some cases the new method for calculating the\nlower bound for the Bohr radius of the Hadamard operator with a fixed initial\ncoefficient is more effective than the known one."
    ],
    "c_categories":[
      [
        "math.CV"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-64",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02314",
    "b_title":[
      "Photo-induced Dynamics and Momentum Distribution of Chiral Charge\n  Density Waves in 1T-TiSe$_{2}$"
    ],
    "b_abstract":[
      "Exploring the photoinduced dynamics of chiral states offers promising avenues\nfor advanced control of condensed matter systems. Photoinduced or photoenhanced\nchirality in 1T-TiSe$_{2}$ has been suggested as a fascinating platform for\noptical manipulation of chiral states. However, the mechanisms underlying\nchirality training and its interplay with the charge density wave (CDW) phase\nremain elusive. Here, we use time-resolved X-ray diffraction (tr-XRD) with\ncircularly polarized pump lasers to probe the photoinduced dynamics of\nchirality in 1T-TiSe$_{2}$. We observe a notable ($\\sim$20%) difference in CDW\nintensity suppression between left- and right-circularly polarized pumps.\nAdditionally, we reveal momentum-resolved circular dichroism arising from\ndomains of different chirality, providing a direct link between CDW and\nchirality. An immediate increase in CDW correlation length upon laser pumping\nis detected, suggesting the photoinduced expansion of chiral domains. These\nresults both advance the potential of light-driven chirality by elucidating the\nmechanism driving chirality manipulation in TiSe$_2$, and they demonstrate that\ntr-XRD with circularly polarized pumps is an effective tool for chirality\ndetection in condensed matter systems."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.08362",
    "c_title":[
      "Altermagnetism and beyond in the $t$-$t^\\prime$-$\\delta$ Fermi-Hubbard\n  model"
    ],
    "c_abstract":[
      "In this work, we revisit the phase diagram of the $t$-$t^\\prime$-$\\delta$\nFermi-Hubbard model on the square lattice to gain a more comprehensive\nunderstanding of this correlated model at half filling. This model has recently\nbecome a prominent topic of research because it hosts altermagnetic phases.\nUsing mean-field analysis, we identify four metallic phases and two insulating\nphases with nontrivial magnetic orders at an intermediate value of $\\delta =\n0.5$, presenting a rich ground-state phase diagram in the $U$-$t^\\prime$ plane.\nWe also highlight the distinct features of the Fermi surface topology for each\nmetallic phase. To go beyond the mean-field theory, we employ the\ndensity-matrix renormalization group method to simulate the ground state\nnumerically. The phase boundaries are determined from the discontinuities and\npeaks in the entanglement entropy and magnetizations. In addition to the phases\nidentified in the mean-field theory, we find a valence-bond solid state in a\nnarrow intermediate-$t'$ region. Our work offers a firm step forward in\nunderstanding the complex behaviors of correlated electrons in the\n$t$-$t^\\prime$-$\\delta$ Hubbard model over a large parameter space."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-65",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16826",
    "b_title":[
      "Noise2Score3D:Unsupervised Tweedie's Approach for Point Cloud Denoising"
    ],
    "b_abstract":[
      "Building on recent advances in Bayesian statistics and image denoising, we\npropose Noise2Score3D, a fully unsupervised framework for point cloud denoising\nthat addresses the critical challenge of limited availability of clean data.\nNoise2Score3D learns the gradient of the underlying point cloud distribution\ndirectly from noisy data, eliminating the need for clean data during training.\nBy leveraging Tweedie's formula, our method performs inference in a single\nstep, avoiding the iterative processes used in existing unsupervised methods,\nthereby improving both performance and efficiency. Experimental results\ndemonstrate that Noise2Score3D achieves state-of-the-art performance on\nstandard benchmarks, outperforming other unsupervised methods in Chamfer\ndistance and point-to-mesh metrics, and rivaling some supervised approaches.\nFurthermore, Noise2Score3D demonstrates strong generalization ability beyond\ntraining datasets. Additionally, we introduce Total Variation for Point Cloud,\na criterion that allows for the estimation of unknown noise parameters, which\nfurther enhances the method's versatility and real-world utility."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08673",
    "c_title":[
      "Keypoint Detection and Description for Raw Bayer Images"
    ],
    "c_abstract":[
      "Keypoint detection and local feature description are fundamental tasks in\nrobotic perception, critical for applications such as SLAM, robot localization,\nfeature matching, pose estimation, and 3D mapping. While existing methods\npredominantly operate on RGB images, we propose a novel network that directly\nprocesses raw images, bypassing the need for the Image Signal Processor (ISP).\nThis approach significantly reduces hardware requirements and memory\nconsumption, which is crucial for robotic vision systems. Our method introduces\ntwo custom-designed convolutional kernels capable of performing convolutions\ndirectly on raw images, preserving inter-channel information without converting\nto RGB. Experimental results show that our network outperforms existing\nalgorithms on raw images, achieving higher accuracy and stability under large\nrotations and scale variations. This work represents the first attempt to\ndevelop a keypoint detection and feature description network specifically for\nraw images, offering a more efficient solution for resource-constrained\nenvironments."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-66",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16895",
    "b_title":[
      "Unlocking Scientific Concepts: How Effective Are LLM-Generated Analogies\n  for Student Understanding and Classroom Practice?"
    ],
    "b_abstract":[
      "Teaching scientific concepts is essential but challenging, and analogies help\nstudents connect new concepts to familiar ideas. Advancements in large language\nmodels (LLMs) enable generating analogies, yet their effectiveness in education\nremains underexplored. In this paper, we first conducted a two-stage study\ninvolving high school students and teachers to assess the effectiveness of\nLLM-generated analogies in biology and physics through a controlled in-class\ntest and a classroom field study. Test results suggested that LLM-generated\nanalogies could enhance student understanding particularly in biology, but\nrequire teachers' guidance to prevent over-reliance and overconfidence.\nClassroom experiments suggested that teachers could refine LLM-generated\nanalogies to their satisfaction and inspire new analogies from generated ones,\nencouraged by positive classroom feedback and homework performance boosts.\nBased on findings, we developed and evaluated a practical system to help\nteachers generate and refine teaching analogies. We discussed future directions\nfor developing and evaluating LLM-supported teaching and learning by analogy."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15518",
    "c_title":[
      "Robot Character Generation and Adaptive Human-Robot Interaction with\n  Personality Shaping"
    ],
    "c_abstract":[
      "We present a novel framework for designing emotionally agile robots with\ndynamic personalities and memory-based learning, with the aim of performing\nadaptive and non-deterministic interactions with humans while conforming to\nshared social understanding. While existing work has largely focused on emotion\nrecognition and static response systems, many approaches rely on sentiment\nanalysis and action mapping frameworks that are pre-defined with limited\ndimensionality and fixed configurations, lacking the flexibility of dynamic\npersonality traits and memory-enabled adaptation. Other systems are often\nrestricted to limited modes of expression and fail to develop a causal\nrelationship between human behavior and the robot's proactive physical actions,\nresulting in constrained adaptability and reduced responsiveness in complex,\ndynamic interactions. Our methodology integrates the Big Five Personality\nTraits, Appraisal Theory, and abstracted memory layers through Large Language\nModels (LLMs). The LLM generates a parameterized robot personality based on the\nBig Five, processes human language and sentiments, evaluates human behavior\nusing Appraisal Theory, and generates emotions and selects appropriate actions\nadapted by historical context over time. We validated the framework by testing\nthree robots with distinct personalities in identical background contexts and\nfound that personality, appraisal, and memory influence the adaptability of\nhuman-robot interactions. The impact of the individual components was further\nvalidated through ablation tests. We conclude that this system enables robots\nto engage in meaningful and personalized interactions with users, and holds\nsignificant potential for applications in domains such as pet robots, assistive\nrobots, educational robots, and collaborative functional robots, where\ncultivating tailored relationships and enriching user experiences are\nessential."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-67",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07348",
    "b_title":[
      "Ultrasonic Medical Tissue Imaging Using Probabilistic Inversion:\n  Leveraging Variational Inference for Speed Reconstruction and Uncertainty\n  Quantification"
    ],
    "b_abstract":[
      "Full Waveform Inversion (FWI) is a promising technique for achieving\nhigh-resolution imaging in medical ultrasound. Traditional FWI methods suffer\nfrom issues related to computational efficiency, dependence on initial models,\nand the inability to quantify uncertainty. This study introduces the Stein\nVariational Gradient Descent (SVGD) algorithm into FWI, aiming to improve\ninversion performance and enhance uncertainty quantification. By deriving the\nposterior gradient, the study explores the integration of SVGD with FWI and\ndemonstrates its ability to approximate complex priors. In-silico experiments\nwith synthetic data and real-world breast tissue data highlight the advantages\nof the SVGD-based framework over conventional FWI. SVGD-based FWI improves\ninversion quality, provides more reliable uncertainty quantification, and\noffers a tighter bound for the prior distribution. These findings show that\nprobabilistic inversion is a promising tool for addressing the limitations of\ntraditional FWI methods in ultrasonic imaging of medical tissues."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.03731",
    "c_title":[
      "A Physiological-Model-Based Neural Network Framework for Blood Pressure\n  Estimation from Photoplethysmography Signals"
    ],
    "c_abstract":[
      "Continuous blood pressure (BP) estimation via photoplethysmography (PPG)\nremains a significant challenge, particularly in providing comprehensive\ncardiovascular insights for hypertensive complications. This study presents a\nnovel physiological model-based neural network (PMB-NN) framework for BP\nestimation from PPG signals, incorporating the identification of total\nperipheral resistance (TPR) and arterial compliance (AC) to enhance\nphysiological interpretability. Preliminary experimental results, obtained from\na single healthy participant under varying activity intensities, demonstrated\npromising accuracy, with a median root mean square error of 6.69 mmHg for\nsystolic BP and 3.26 mmHg for diastolic BP. The median (min, max) difference\nbetween estimated and measured TPR was 0.043 (0.024, 0.061) mmHg*s\/cm^3. As\nexpected, estimated TPR decreased with increasing activity intensity, while AC\nincreased within a physiologically plausible range (0.5-2.5 cm^3\/mmHg)."
    ],
    "c_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-68",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12642",
    "b_title":[
      "Training Data Attribution (TDA): Examining Its Adoption & Use Cases"
    ],
    "b_abstract":[
      "This report investigates Training Data Attribution (TDA) and its potential\nimportance to and tractability for reducing extreme risks from AI. First, we\ndiscuss the plausibility and amount of effort it would take to bring existing\nTDA research efforts from their current state, to an efficient and accurate\ntool for TDA inference that can be run on frontier-scale LLMs. Next, we discuss\nthe numerous research benefits AI labs will expect to see from using such TDA\ntooling. Then, we discuss a key outstanding bottleneck that would limit such\nTDA tooling from being accessible publicly: AI labs' willingness to disclose\ntheir training data. We suggest ways AI labs may work around these limitations,\nand discuss the willingness of governments to mandate such access. Assuming\nthat AI labs willingly provide access to TDA inference, we then discuss what\nhigh-level societal benefits you might see. We list and discuss a series of\npolicies and systems that may be enabled by TDA. Finally, we present an\nevaluation of TDA's potential impact on mitigating large-scale risks from AI\nsystems."
    ],
    "b_categories":[
      [
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.06913",
    "c_title":[
      "Towards Fair and Privacy-Aware Transfer Learning for Educational\n  Predictive Modeling: A Case Study on Retention Prediction in Community\n  Colleges"
    ],
    "c_abstract":[
      "Predictive analytics is widely used in learning analytics, but many\nresource-constrained institutions lack the capacity to develop their own models\nor rely on proprietary ones trained in different contexts with little\ntransparency. Transfer learning holds promise for expanding equitable access to\npredictive analytics but remains underexplored due to legal and technical\nconstraints. This paper examines transfer learning strategies for retention\nprediction at U.S. two-year community colleges. We envision a scenario where\ncommunity colleges collaborate with each other and four-year universities to\ndevelop retention prediction models under privacy constraints and evaluate\nrisks and improvement strategies of cross-institutional model transfer. Using\nadministrative records from 4 research universities and 23 community colleges\ncovering over 800,000 students across 7 cohorts, we identify performance and\nfairness degradation when external models are deployed locally without\nadaptation. Publicly available contextual information can forecast these\nperformance drops and offer early guidance for model portability. For\ndevelopers under privacy regulations, sequential training selecting\ninstitutions based on demographic similarities enhances fairness without\ncompromising performance. For institutions lacking local data to fine-tune\nsource models, customizing evaluation thresholds for sensitive groups\noutperforms standard transfer techniques in improving performance and fairness.\nOur findings suggest the value of transfer learning for more accessible\neducational predictive modeling and call for judicious use of contextual\ninformation in model training, selection, and deployment to achieve reliable\nand equitable model transfer."
    ],
    "c_categories":[
      [
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-69",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05342",
    "b_title":[
      "Discounting under inequality and lobbyists disagreement"
    ],
    "b_abstract":[
      "The appropriate discount rate for evaluating policies is a critical\nconsideration in economic decision-making. This paper presents a new model for\ncalculating the derived discount rate for a society that includes different\ngroups with varying desirable discount rates. The model takes into account\nequality in society and is designed to be used by social planners. The derived\ndiscount rate is a useful tool for examining the social planner's approach to\npolicies related to the future of society. If the discount rate is determined\ncorrectly, it can help determine the amount of growth and equality in society,\nas well as the level of attention paid to long-term public projects. The model\ncan be customized for different distributions of wealth and discount rates,\nallowing researchers to extract desired results. Analysis of the model shows\nthat when equality in society is considered, the derived discount rate is lower\nthan the result obtained using Hamilton's method. Social planners must consider\nthat this may increase disagreement in more consuming groups of society at\nfirst."
    ],
    "b_categories":[
      [
        "econ.TH"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2503.06007",
    "c_title":[
      "Paying and Persuading"
    ],
    "c_abstract":[
      "We study the joint design of information and transfers when an informed\nSender can motivate Receiver by both paying and (Bayesian) persuading. We\nintroduce an augmented concavification method to characterize Sender's value\nfrom jointly designing information and transfers. We use this characterization\nto show Sender strictly benefits from combining information and payments\nwhenever the actions induced at adjacent kinks in the augmented concavification\ndiffer from those in the information-only concavification. When Receiver has an\noutside option, Sender always first increases the informativeness of their\nexperiment before adjusting transfers - payments change if and only if full\nrevelation does not meet Receiver's outside option constraint. Moreover, we\nshow repeated interactions cannot restore ex-post efficiency, even with\ntransfers and arbitrarily patient agents. However, Sender benefits from linking\nincentives so long as Receiver prefers the stage-game optimal information\nstructure to no information. Our results have implications for platforms such\nas Uber, where both monetary rewards and strategic information disclosure\ninfluence driver behavior."
    ],
    "c_categories":[
      [
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-70",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08368",
    "b_title":[
      "Local damage detection in rolling element bearings based on a Single\n  Ensemble Empirical Mode Decomposition"
    ],
    "b_abstract":[
      "A Single Ensemble Empirical Mode Decomposition (SEEMD) is proposed for\nlocating the damage in rolling element bearings. The SEEMD does not require a\nnumber of ensembles from the addition or subtraction of noise every time while\nprocessing the signals. The SEEMD requires just a single sifting process of a\nmodified raw signal to reduce the computation time significantly. The other\nadvantage of the SEEMD method is its success in dealing with non-Gaussian or\nnon-stationary perturbing signals. In SEEMD, initially, a fractional Gaussian\nnoise (FGN) is added to the raw signal to emphasize on high frequencies of the\nsignal. Then, a convoluted white Gaussian noise is multiplied to the resulting\nsignal which changes the spectral content of the signal which helps in\nextraction of the weak periodic signal. Finally, the obtained signal is\ndecomposed by using a single sifting process. The proposed methodology is\napplied to the raw signals obtained from the mining industry. These signals are\ndifficult to analyze since cyclic impulsive components are obscured by noise\nand other interference. Based on the results, the proposed method can\neffectively detect the fault where the signal of interest (SOI) has been\nextracted with good quality."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.03856",
    "c_title":[
      "Enhanced Beampattern Synthesis Using Electromagnetically Reconfigurable\n  Antennas"
    ],
    "c_abstract":[
      "Beampattern synthesis seeks to optimize array weights to shape radiation\npatterns, playing a critical role in various wireless applications. In addition\nto theoretical advancements, recent hardware innovations have facilitated new\navenues to enhance beampattern synthesis performance. This paper studies the\nbeampattern synthesis problem using newly proposed electromagnetically\nreconfigurable antennas (ERAs). By utilizing spherical harmonics decomposition,\nwe simultaneously optimize each antenna's radiation pattern and phase shift to\nmatch a desired beampattern of the entire array. The problem is formulated for\nboth far-field and near-field scenarios, with the optimization solved using\nRiemannian manifold techniques. The simulation results validate the\neffectiveness of the proposed solution and illustrate that ERAs exhibit\nsuperior beampattern synthesis capabilities compared to conventional fixed\nradiation pattern antennas. This advantage becomes increasingly significant as\nthe array size grows."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-71",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04561",
    "b_title":[
      "On the Mordell-Weil rank and $2$-Selmer group of a family of elliptic\n  curves"
    ],
    "b_abstract":[
      "We consider the parametric family of elliptic curves over $\\mathbb{Q}$ of the\nform $E_{m} : y^{2} = x(x - n_{1})(x - n_{2}) + t^{2}$, where $n_{1}$, $n_{2}$\nand $t$ are particular polynomial expressions in an integral variable $m$. In\nthis paper, we investigate the torsion group $E_{m}(\\mathbb{Q})_{\\rm{tors}}$, a\nlower bound for the Mordell-Weil rank $r({E_{m}})$ and the $2$-Selmer group\n${\\rm{Sel}}_{2}(E_{m})$ under certain conditions on $m$. This extends the\nprevious works done in this direction, which are mostly concerned with the\nMordell-Weil ranks of various parametric families of elliptic curves."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.12325",
    "c_title":[
      "Estimates for short character sums evaluated at homogeneous polynomials"
    ],
    "c_abstract":[
      "Let $p$ be a prime. We prove bounds on short Dirichlet character sums\nevaluated at a class of homogeneous polynomials in arbitrary dimensions. In\nevery dimension, this bound is nontrivial for sums over boxes with side lengths\nas short as $p^{1\/4 + \\kappa}$ for any $\\kappa>0$. Our methods capitalize on\nthe relationship between characters mod $p$ and characters over finite field\nextensions as well as bounds on the multiplicative energy of sets in products\nof finite fields."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-72",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15734",
    "b_title":[
      "Prioritized Value-Decomposition Network for Explainable AI-Enabled\n  Network Slicing"
    ],
    "b_abstract":[
      "Network slicing aims to enhance flexibility and efficiency in next-generation\nwireless networks by allocating the right resources to meet the diverse\nrequirements of various applications. Managing these slices with machine\nlearning (ML) algorithms has emerged as a promising approach however\nexplainability has been a challenge. To this end, several Explainable\nArtificial Intelligence (XAI) frameworks have been proposed to address the\nopacity in decision-making in many ML methods. In this paper, we propose a\nPrioritized Value-Decomposition Network (PVDN) as an XAI-driven approach for\nresource allocation in a multi-agent network slicing system. The PVDN method\ndecomposes the global value function into individual contributions and\nprioritizes slice outputs, providing an explanation of how resource allocation\ndecisions impact system performance. By incorporating XAI, PVDN offers valuable\ninsights into the decision-making process, enabling network operators to better\nunderstand, trust, and optimize slice management strategies. Through\nsimulations, we demonstrate the effectiveness of the PVDN approach with\nimproving the throughput by 67% and 16%, while reducing latency by 35% and 22%,\ncompared to independent and VDN-based resource allocation methods."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01397",
    "c_title":[
      "An Empirical Smart Contracts Latency Analysis on Ethereum Blockchain for\n  Trustworthy Inter-Provider Agreements"
    ],
    "c_abstract":[
      "As 6G networks evolve, inter-provider agreements become crucial for dynamic\nresource sharing and network slicing across multiple domains, requiring\non-demand capacity provisioning while enabling trustworthy interaction among\ndiverse operators. To address these challenges, we propose a blockchain-based\nDecentralized Application (DApp) on Ethereum that introduces four smart\ncontracts, organized into a Preliminary Agreement Phase and an Enforcement\nPhase, and measures their gas usage, thereby establishing an open marketplace\nwhere service providers can list, lease, and enforce resource sharing. We\npresent an empirical evaluation of how gas price, block size, and transaction\ncount affect transaction processing time on the live Sepolia Ethereum testnet\nin a realistic setting, focusing on these distinct smart-contract phases with\nvarying computational complexities. We first examine transaction latency as the\nnumber of users (batch size) increases, observing median latencies from 12.5 s\nto 23.9 s in the Preliminary Agreement Phase and 10.9 s to 24.7 s in the\nEnforcement Phase. Building on these initial measurements, we perform a\ncomprehensive Kruskal-Wallis test (p < 0.001) to compare latency distributions\nacross quintiles of gas price, block size, and transaction count. The post-hoc\nanalyses reveal that high-volume blocks overshadow fee variations when\ntransaction logic is more complex (effect sizes up to 0.43), whereas gas price\nexerts a stronger influence when the computation is lighter (effect sizes up to\n0.36). Overall, 86% of transactions finalize within 30 seconds, underscoring\nthat while designing decentralized applications, there must be a balance\nbetween contract complexity and fee strategies. The implementation of this work\nis publicly accessible online."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-73",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12972",
    "b_title":[
      "Skip That Beat: Augmenting Meter Tracking Models for Underrepresented\n  Time Signatures"
    ],
    "b_abstract":[
      "Beat and downbeat tracking models are predominantly developed using datasets\nwith music in 4\/4 meter, which decreases their generalization to repertories in\nother time signatures, such as Brazilian samba which is in 2\/4. In this work,\nwe propose a simple augmentation technique to increase the representation of\ntime signatures beyond 4\/4, namely 2\/4 and 3\/4. Our augmentation procedure\nworks by removing beat intervals from 4\/4 annotated tracks. We show that the\naugmented data helps to improve downbeat tracking for underrepresented meters\nwhile preserving the overall performance of beat tracking in two different\nmodels. We also show that this technique helps improve downbeat tracking in an\nunseen samba dataset."
    ],
    "b_categories":[
      [
        "cs.SD"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.08131",
    "c_title":[
      "Methods for pitch analysis in contemporary popular music: highlighting\n  pitch uncertainty in Primaal's commercial works"
    ],
    "c_abstract":[
      "We identify characteristic features of how pitch is manipulated for\nexpressive purposes by Hyper Music, a mainstream commercial music company\nspecialising in advertisement music for global corporations. The study shows\nthat the use and organisation of pitch in the company's `Primaal' brand differs\nfrom Western classical music. Through interviews with producers and in-depth\nanalysis of their work, we reveal that their methods centre on a conscious aim\nto construct a musical discourse based on pitch uncertainty, contrasting with\nthe clear transmission of well-defined pitches in Western classical traditions.\nAccording to the Primaal producers, who acknowledge the influence of artists\nsuch as Kanye West and Daft Punk and use widely available technology, pitch\nuncertainty captures the listener's attention. We provide analyses of musical\nexcerpts demonstrating their approach, alongside descriptions of the tools and\nmethods employed to achieve their expressive goals. These goals and methods are\nplaced in a broader historical context, contrasting with fundamental principles\nof pitch organisation in Western music. Techniques used by Hyper Music to\nintroduce and control pitch uncertainty include boosting upper partials,\nexpressive use of inharmonicity, continuous pitch distributions around 'poles'\ntied to specific 'modes', and continuously evolving pitch. We examine these\ntechniques from a psychoacoustic perspective, and conduct listening tests\ncorroborating some of the observations. The ultimate goal of the study is to\nintroduce a set of methods suited to the analysis of pitch in contemporary\npopular music."
    ],
    "c_categories":[
      [
        "cs.SD"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-74",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06773",
    "b_title":[
      "Pareto Set Learning for Multi-Objective Reinforcement Learning"
    ],
    "b_abstract":[
      "Multi-objective decision-making problems have emerged in numerous real-world\nscenarios, such as video games, navigation and robotics. Considering the clear\nadvantages of Reinforcement Learning (RL) in optimizing decision-making\nprocesses, researchers have delved into the development of Multi-Objective RL\n(MORL) methods for solving multi-objective decision problems. However, previous\nmethods either cannot obtain the entire Pareto front, or employ only a single\npolicy network for all the preferences over multiple objectives, which may not\nproduce personalized solutions for each preference. To address these\nlimitations, we propose a novel decomposition-based framework for MORL, Pareto\nSet Learning for MORL (PSL-MORL), that harnesses the generation capability of\nhypernetwork to produce the parameters of the policy network for each\ndecomposition weight, generating relatively distinct policies for various\nscalarized subproblems with high efficiency. PSL-MORL is a general framework,\nwhich is compatible for any RL algorithm. The theoretical result guarantees the\nsuperiority of the model capacity of PSL-MORL and the optimality of the\nobtained policy network. Through extensive experiments on diverse benchmarks,\nwe demonstrate the effectiveness of PSL-MORL in achieving dense coverage of the\nPareto front, significantly outperforming state-of-the-art MORL methods in the\nhypervolume and sparsity indicators."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13895",
    "c_title":[
      "Geometric Principles for Machine Learning of Dynamical Systems"
    ],
    "c_abstract":[
      "Mathematical descriptions of dynamical systems are deeply rooted in\ntopological spaces defined by non-Euclidean geometry. This paper proposes\nleveraging structure-rich geometric spaces for machine learning to achieve\nstructural generalization when modeling physical systems from data, in contrast\nto embedding physics bias within model-free architectures. We consider model\ngeneralization to be a function of symmetry, invariance and uniqueness, defined\nas a topological mapping from state space dynamics to the parameter space. We\nillustrate this view through the machine learning of linear time-invariant\ndynamical systems, whose dynamics reside on the symmetric positive definite\nmanifold."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-75",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17877",
    "b_title":[
      "$(p, q)$-Sobolev inequality and Nash inequality on forward complete\n  Finsler metric measure manifolds"
    ],
    "b_abstract":[
      "In this paper, we carry out in-depth research centering around the $(p,\nq)$-Sobolev inequality and Nash inequality on forward complete Finsler metric\nmeasure manifolds under the condition that ${\\rm Ric}_{\\infty} \\geq -K$ for\nsome $K \\geq 0$. We first obtain a global $p$-Poincar\\'{e} inequality on such\nFinsler manifolds. Based on this, we can derive a $(p, q)$-Sobolev inequality.\nFurthermore, we establish a global optimal $(p, q)$-Sobolev inequality with a\nsharp Sobolev constant. Finally, as an application of the $p$-Poincar\\'{e}\ninequality, we prove a Nash inequality."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.05955",
    "c_title":[
      "Area-minimizing unit vector fields on some spherical annuli"
    ],
    "c_abstract":[
      "We establish in this paper a sharp lower bound for the area of a unit vector\nfield $V$ defined on some spherical annuli in the Euclidean sphere\n$\\mathbb{S}^2$."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-76",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11266",
    "b_title":[
      "Optimum Power Allocation for Low Rank Wi-Fi Channels: A Comparison with\n  Deep RL Framework"
    ],
    "b_abstract":[
      "Upcoming Augmented Reality (AR) and Virtual Reality (VR) systems require high\ndata rates ($\\geq$ 500 Mbps) and low power consumption for seamless experience.\nWith an increasing number of subscribing users, the total number of antennas\nacross all transmitting users far exceeds the number of antennas at the access\npoint (AP). This results in a low rank wireless channel, presenting a\nbottleneck for uplink communication systems. The current uplink systems that\nuse orthogonal multiple access (OMA) and the proposed non-orthogonal multiple\naccess (NOMA), fail to achieve the required data rates \/ power consumption\nunder predominantly low rank channel scenarios. This paper introduces an\noptimal power sub carrier allocation algorithm for multi-carrier NOMA, named\nminPMAC, and an associated time-sharing algorithm that adaptively changes\nsuccessive interference cancellation decoding orders to maximize sum data rates\nin these low rank channels. This Lagrangian based optimization technique,\nalthough globally optimum, is prohibitive in terms of runtime, proving\ninefficient for real-time scenarios. Hence, we propose a novel near-optimal\ndeep reinforcement learning-based energy sum optimization (DRL-minPMAC) which\nachieves real-time efficiency. Extensive experimental evaluations show that\nminPMAC achieves 28\\% and 39\\% higher data rates than NOMA and OMA baselines.\nFurthermore, the proposed DRL-minPMAC runs ~5 times faster than minPMAC and\nachieves 83\\% of the global optimum data rates in real time"
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.18111",
    "c_title":[
      "A Two-Stage Rotation-Based Super-Resolution Signature Estimation for\n  Spatial Wideband Systems"
    ],
    "c_abstract":[
      "Spatial and temporal delays in a wireless multi-antenna system, paired with\nan orthogonal frequency division multiplexing (OFDM) waveform, can be utilized\nto estimate the Angle of Arrival (AoA) and Time of Arrival (ToA) of scatterers\nin the radio channel through spectral estimation techniques. However, in\nmillimeter-wave (mmWave) and TeraHertz (THz) systems, the spatial delays across\nthe aperture of massive array elements are comparable to the inverse of the\nsignal bandwidth. As a result, these delays cannot be approximated solely by\nphase terms, necessitating consideration of the Spatial Wideband Effect (SWE).\nThe SWE in the mmWave\/THz system causes migration of the actual AoA-ToA coarse\nbins. Moreover, a finite grid measurement of complex sinusoidal signals of\ncontinuous frequencies results in spectral leakage whenever there is a grid\nmismatch. In this work, given the Discrete Fourier Transform's computational\nefficiency and broad practical applicability, we propose utilizing the inverse\nDiscrete Fourier Transform (DFT) for the initial 2-D spectrum estimation of the\nchannel response. Further, in this paper, we propose a two-stage efficient\nrotation-based algorithm for fine-tuned signature estimation of spatial\nwideband systems with uniform linear arrays. Specifically, we utilize the\nrotation-based method to identify the correct coarse bin in the first stage\nfollowed by 2D-rotation based fine-tuning around the corrected coarse bin in\nthe second stage. The proposed technique in this work can be used for handling\nbeam squint effect in different applications like near-filed communications,\nwideband Multiple Input Multiple Output (MIMO) radar, channel estimation in\nExtremely Large (XL)-MIMO for 6G and beyond systems etc. The effectiveness of\nour proposed algorithm over the existing narrowband super-resolution estimation\nalgorithms is established numerically through computer simulations."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-77",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16985",
    "b_title":[
      "From Hyper Roughness to Jumps as $H \\to -1\/2$"
    ],
    "b_abstract":[
      "We investigate the weak limit of the hyper-rough square-root process as the\nHurst index $H$ goes to $-1\/2\\,$. This limit corresponds to the fractional\nkernel $t^{H - 1 \/ 2}$ losing integrability. We establish the joint convergence\nof the couple $(X, M)\\,$, where $X$ is the hyper-rough process and $M$ the\nassociated martingale, to a fully correlated Inverse Gaussian L\\'evy jump\nprocess. This unveils the existence of a continuum between hyper-rough\ncontinuous models and jump processes, as a function of the Hurst index. Since\nwe prove a convergence of continuous to discontinuous processes, the usual\nSkorokhod $J_1$ topology is not suitable for our problem. Instead, we obtain\nthe weak convergence in the Skorokhod $M_1$ topology for $X$ and in the\nnon-Skorokhod $S$ topology for $M$."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.16306",
    "c_title":[
      "The Paradox of Anti-Inductive Dice"
    ],
    "c_abstract":[
      "We identify a new type of paradoxical behavior in dice, where the sum of\nindependent rolls produces a deceptive sequence of dominance relations. We call\nthese ``anti-inductive dice\". Consider a game with two players and two\nnon-identical dice. Each rolls their die $k$ times, adding the results, and the\nplayer with the highest sum wins. For each $k$, this induces a dominance\nrelation between dice, with $A[k]\\succ B[k]$ if $A$ is more likely than $B$ to\nwin after $k$ rolls, and vice versa. For certain classes of dice, the limiting\nbehavior of these relations is well-established in the literature, but the\ntransient behavior, the subject of this paper, is less well-understood. This\ntransient behavior, even for dice with only 4 faces, contains an immensely rich\nparameter space with fractal-like behavior."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-78",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16848",
    "b_title":[
      "Hybrid Phenology Modeling for Predicting Temperature Effects on Tree\n  Dormancy"
    ],
    "b_abstract":[
      "Biophysical models offer valuable insights into climate-phenology\nrelationships in both natural and agricultural settings. However, there are\nsubstantial structural discrepancies across models which require site-specific\nrecalibration, often yielding inconsistent predictions under similar climate\nscenarios. Machine learning methods offer data-driven solutions, but often lack\ninterpretability and alignment with existing knowledge. We present a phenology\nmodel describing dormancy in fruit trees, integrating conventional biophysical\nmodels with a neural network to address their structural disparities. We\nevaluate our hybrid model in an extensive case study predicting cherry tree\nphenology in Japan, South Korea and Switzerland. Our approach consistently\noutperforms both traditional biophysical and machine learning models in\npredicting blooming dates across years. Additionally, the neural network's\nadaptability facilitates parameter learning for specific tree varieties,\nenabling robust generalization to new sites without site-specific\nrecalibration. This hybrid model leverages both biophysical constraints and\ndata-driven flexibility, offering a promising avenue for accurate and\ninterpretable phenology modeling."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18580",
    "c_title":[
      "Node Classification and Search on the Rubik's Cube Graph with GNNs"
    ],
    "c_abstract":[
      "This study focuses on the application of deep geometric models to solve the\n3x3x3 Rubik's Cube. We begin by discussing the cube's graph representation and\ndefining distance as the model's optimization objective. The distance\napproximation task is reformulated as a node classification problem,\neffectively addressed using Graph Neural Networks (GNNs). After training the\nmodel on a random subgraph, the predicted classes are used to construct a\nheuristic for $A^*$ search. We conclude with experiments comparing our\nheuristic to that of the DeepCubeA model."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-79",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12464",
    "b_title":[
      "SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety\n  Guardrails in Large Language Models"
    ],
    "b_abstract":[
      "Deploying large language models (LLMs) in real-world applications requires\nrobust safety guard models to detect and block harmful user prompts. While\nlarge safety guard models achieve strong performance, their computational cost\nis substantial. To mitigate this, smaller distilled models are used, but they\noften underperform on \"hard\" examples where the larger model provides accurate\npredictions. We observe that many inputs can be reliably handled by the smaller\nmodel, while only a small fraction require the larger model's capacity.\nMotivated by this, we propose SafeRoute, a binary router that distinguishes\nhard examples from easy ones. Our method selectively applies the larger safety\nguard model to the data that the router considers hard, improving efficiency\nwhile maintaining accuracy compared to solely using the larger safety guard\nmodel. Experimental results on multiple benchmark datasets demonstrate that our\nadaptive model selection significantly enhances the trade-off between\ncomputational cost and safety performance, outperforming relevant baselines."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.04405",
    "c_title":[
      "Comparative Study of Zero-Shot Cross-Lingual Transfer for Bodo POS and\n  NER Tagging Using Gemini 2.0 Flash Thinking Experimental Model"
    ],
    "c_abstract":[
      "Named Entity Recognition (NER) and Part-of-Speech (POS) tagging are critical\ntasks for Natural Language Processing (NLP), yet their availability for\nlow-resource languages (LRLs) like Bodo remains limited. This article presents\na comparative empirical study investigating the effectiveness of Google's\nGemini 2.0 Flash Thinking Experiment model for zero-shot cross-lingual transfer\nof POS and NER tagging to Bodo. We explore two distinct methodologies: (1)\ndirect translation of English sentences to Bodo followed by tag transfer, and\n(2) prompt-based tag transfer on parallel English-Bodo sentence pairs. Both\nmethods leverage the machine translation and cross-lingual understanding\ncapabilities of Gemini 2.0 Flash Thinking Experiment to project English POS and\nNER annotations onto Bodo text in CONLL-2003 format. Our findings reveal the\ncapabilities and limitations of each approach, demonstrating that while both\nmethods show promise for bootstrapping Bodo NLP, prompt-based transfer exhibits\nsuperior performance, particularly for NER. We provide a detailed analysis of\nthe results, highlighting the impact of translation quality, grammatical\ndivergences, and the inherent challenges of zero-shot cross-lingual transfer.\nThe article concludes by discussing future research directions, emphasizing the\nneed for hybrid approaches, few-shot fine-tuning, and the development of\ndedicated Bodo NLP resources to achieve high-accuracy POS and NER tagging for\nthis low-resource language."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-80",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03755",
    "b_title":[
      "Regularization via f-Divergence: An Application to Multi-Oxide\n  Spectroscopic Analysis"
    ],
    "b_abstract":[
      "In this paper, we address the task of characterizing the chemical composition\nof planetary surfaces using convolutional neural networks (CNNs). Specifically,\nwe seek to predict the multi-oxide weights of rock samples based on\nspectroscopic data collected under Martian conditions. We frame this problem as\na multi-target regression task and propose a novel regularization method based\non f-divergence. The f-divergence regularization is designed to constrain the\ndistributional discrepancy between predictions and noisy targets. This\nregularizer serves a dual purpose: on the one hand, it mitigates overfitting by\nenforcing a constraint on the distributional difference between predictions and\nnoisy targets. On the other hand, it acts as an auxiliary loss function,\npenalizing the neural network when the divergence between the predicted and\ntarget distributions becomes too large. To enable backpropagation during neural\nnetwork training, we develop a differentiable f-divergence and incorporate it\ninto the f-divergence regularization, making the network training feasible. We\nconduct experiments using spectra collected in a Mars-like environment by the\nremote-sensing instruments aboard the Curiosity and Perseverance rovers.\nExperimental results on multi-oxide weight prediction demonstrate that the\nproposed $f$-divergence regularization performs better than or comparable to\nstandard regularization methods including $L_1$, $L_2$, and dropout. Notably,\ncombining the $f$-divergence regularization with these standard regularization\nfurther enhances performance, outperforming each regularization method used\nindependently."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03251",
    "c_title":[
      "RiemannGFM: Learning a Graph Foundation Model from Riemannian Geometry"
    ],
    "c_abstract":[
      "The foundation model has heralded a new era in artificial intelligence,\npretraining a single model to offer cross-domain transferability on different\ndatasets. Graph neural networks excel at learning graph data, the omnipresent\nnon-Euclidean structure, but often lack the generalization capacity. Hence,\ngraph foundation model is drawing increasing attention, and recent efforts have\nbeen made to leverage Large Language Models. On the one hand, existing studies\nprimarily focus on text-attributed graphs, while a wider range of real graphs\ndo not contain fruitful textual attributes. On the other hand, the sequential\ngraph description tailored for the Large Language Model neglects the structural\ncomplexity, which is a predominant characteristic of the graph. Such\nlimitations motivate an important question: Can we go beyond Large Language\nModels, and pretrain a universal model to learn the structural knowledge for\nany graph? The answer in the language or vision domain is a shared vocabulary.\nWe observe the fact that there also exist shared substructures underlying graph\ndomain, and thereby open a new opportunity of graph foundation model with\nstructural vocabulary. The key innovation is the discovery of a simple yet\neffective structural vocabulary of trees and cycles, and we explore its\ninherent connection to Riemannian geometry. Herein, we present a universal\npretraining model, RiemannGFM. Concretely, we first construct a novel product\nbundle to incorporate the diverse geometries of the vocabulary. Then, on this\nconstructed space, we stack Riemannian layers where the structural vocabulary,\nregardless of specific graph, is learned in Riemannian manifold offering\ncross-domain transferability. Extensive experiments show the effectiveness of\nRiemannGFM on a diversity of real graphs."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-81",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04542",
    "b_title":[
      "Ego vs. Exo and Active vs. Passive: Investigating the Effects of\n  Viewpoint and Navigation on Spatial Immersion and Understanding in Immersive\n  Storytelling"
    ],
    "b_abstract":[
      "Visual storytelling combines visuals and narratives to communicate important\ninsights. While web-based visual storytelling is well-established, leveraging\nthe next generation of digital technologies for visual storytelling,\nspecifically immersive technologies, remains underexplored. We investigated the\nimpact of the story viewpoint (from the audience's perspective) and navigation\n(when progressing through the story) on spatial immersion and understanding.\nFirst, we collected web-based 3D stories and elicited design considerations\nfrom three VR developers. We then adapted four selected web-based stories to an\nimmersive format. Finally, we conducted a user study (N=24) to examine\negocentric and exocentric viewpoints, active and passive navigation, and the\ncombinations they form. Our results indicated significantly higher preferences\nfor egocentric+active (higher agency and engagement) and exocentric+passive\n(higher focus on content). We also found a marginal significance of viewpoints\non story understanding and a strong significance of navigation on spatial\nimmersion."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17258",
    "c_title":[
      "Controlling AI Agent Participation in Group Conversations: A\n  Human-Centered Approach"
    ],
    "c_abstract":[
      "Conversational AI agents are commonly applied within single-user, turn-taking\nscenarios. The interaction mechanics of these scenarios are trivial: when the\nuser enters a message, the AI agent produces a response. However, the\ninteraction dynamics are more complex within group settings. How should an\nagent behave in these settings? We report on two experiments aimed at\nuncovering users' experiences of an AI agent's participation within a group, in\nthe context of group ideation (brainstorming). In the first study, participants\nbenefited from and preferred having the AI agent in the group, but participants\ndisliked when the agent seemed to dominate the conversation and they desired\nvarious controls over its interactive behaviors. In the second study, we\ncreated functional controls over the agent's behavior, operable by group\nmembers, to validate their utility and probe for additional requirements.\nIntegrating our findings across both studies, we developed a taxonomy of\ncontrols for when, what, and where a conversational AI agent in a group should\nrespond, who can control its behavior, and how those controls are specified and\nimplemented. Our taxonomy is intended to aid AI creators to think through\nimportant considerations in the design of mixed-initiative conversational\nagents."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-82",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15213",
    "b_title":[
      "Sig2text, a Vision-language model for Non-cooperative Radar Signal\n  Parsing"
    ],
    "b_abstract":[
      "Automatic non-cooperative analysis of intercepted radar signals is essential\nfor intelligent equipment in both military and civilian domains. Accurate\nmodulation identification and parameter estimation enable effective signal\nclassification, threat assessment, and the development of countermeasures. In\nthis paper, we propose a symbolic approach for radar signal recognition and\nparameter estimation based on a vision-language model that combines\ncontext-free grammar with time-frequency representation of radar waveforms. The\nproposed model, called Sig2text, leverages the power of vision transformers for\ntime-frequency feature extraction and transformer-based decoders for symbolic\nparsing of radar waveforms. By treating radar signal recognition as a parsing\nproblem, Sig2text can effectively recognize and parse radar waveforms with\ndifferent modulation types and parameters. We evaluate the performance of\nSig2text on a synthetic radar signal dataset and demonstrate its effectiveness\nin recognizing and parsing radar waveforms with varying modulation types and\nparameters. The training code of the model is available at\nhttps:\/\/github.com\/Na-choneko\/sig2text."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00090",
    "c_title":[
      "Tensor-based Model Reduction and Identification for Generalized Memory\n  Polynomial"
    ],
    "c_abstract":[
      "Power amplifiers (PAs) are essential components in wireless communication\nsystems, and the design of their behavioral models has been an important\nresearch topic for many years. The widely used generalized memory polynomial\n(GMP) model suffers from rapid growth in the number of parameters with\nincreasing memory depths and nonlinearity order, which leads to a significant\nincrease in model complexity and the risk of overfitting. In this study, we\nintroduce tensor networks to compress the unknown coefficient tensor of the GMP\nmodel, resulting in three novel tensor-based GMP models. These models can\nachieve comparable performance to the GMP model, but with far fewer parameters\nand lower complexity. For the identification of these models, we derive the\nalternating least-squares (ALS) method to ensure the rapid updates and\nconvergence of model parameters in an iterative manner. In addition, we notice\nthat the horizontal slices of the third-order data tensor constructed from the\ninput signals are Vandermonde matrices, which have a numerically low-rank\nstructure. Hence, we further propose the RP-ALS algorithm, which first performs\na truncated higher-order singular value decomposition on the data tensor to\ngenerate random projections, then conducts the ALS algorithm for the\nidentification of projected models with downscaled dimensions, thus reducing\nthe computational effort of the iterative process. The experimental results\nshow that the proposed models outperform the full GMP model and sparse GMP\nmodel via LASSO regression in terms of the reduction in the number of\nparameters and running complexity."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-83",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16164",
    "b_title":[
      "Asymptotically Optimal Path Planning With an Approximation of the\n  Omniscient Set"
    ],
    "b_abstract":[
      "The asymptotically optimal version of Rapidly-exploring Random Tree (RRT*) is\noften used to find optimal paths in a high-dimensional configuration space. The\nwell-known issue of RRT* is its slow convergence towards the optimal solution.\nA possible solution is to draw random samples only from a subset of the\nconfiguration space that is known to contain configurations that can improve\nthe cost of the path (omniscient set). A fast convergence rate may be achieved\nby approximating the omniscient with a low-volume set. In this letter, we\npropose new methods to approximate the omniscient set and methods for their\neffective sampling. First, we propose to approximate the omniscient set using\nseveral (small) hyperellipsoids defined by sections of the current best\nsolution. The second approach approximates the omniscient set by a convex hull\ncomputed from the current solution. Both approaches ensure asymptotical\noptimality and work in a general n-dimensional configuration space. The\nexperiments have shown superior performance of our approaches in multiple\nscenarios in 3D and 6D configuration spaces."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05693",
    "c_title":[
      "Vertical Vibratory Transport of Grasped Parts Using Impacts"
    ],
    "c_abstract":[
      "In this paper, we use impact-induced acceleration in conjunction with\nperiodic stick-slip to successfully and quickly transport parts vertically\nagainst gravity. We show analytically that vertical vibratory transport is more\ndifficult than its horizontal counterpart, and provide guidelines for achieving\noptimal vertical vibratory transport of a part. Namely, such a system must be\ncapable of quickly realizing high accelerations, as well as supply normal\nforces at least several times that required for static equilibrium. We also\nshow that for a given maximum acceleration, there is an optimal normal force\nfor transport. To test our analytical guidelines, we built a vibrating surface\nusing flexures and a voice coil actuator that can accelerate a magnetic ram\ninto various materials to generate impacts. The surface was used to transport a\npart against gravity. Experimentally obtained motion tracking data confirmed\nthe theoretical model. A series of grasping tests with a vibrating-surface\nequipped parallel jaw gripper confirmed the design guidelines."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-84",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12945",
    "b_title":[
      "Unraveling quantum phase estimation: exploring the impact of\n  multi-photon interference on the quantum Fisher information"
    ],
    "b_abstract":[
      "Quantum interference is known to become extinct with distinguishing\ninformation, as illustrated by the ubiquitous double-slit experiment or the\ntwo-photon HOM effect. In the former case single particle interference is\ndestroyed with which-path information while in the latter bunching interference\ntails-off as photons become distinguishable. It has been observed that when\nmore than two particles are involved, these interference patterns are in\ngeneral a non monotonic function of the distinguishability. Here we perform a\ncomprehensive characterization, both theoretically and experimentally, of\nfour-photon interference by analyzing the corresponding correlation functions,\ncontemplating several degrees of distinguishability across different\nparameters. This study provides all the necessary tools to quantify the impact\nof multi-photon interference on precision measurements of parameters such as\nphase, frequency, and time difference. We apply these insights to quantify the\nprecision in the estimation of an interferometric phase in a two-port\ninterferometer using a four-photon state. Our results reveal that, for certain\nphase values, partially distinguishable multi-photon states can achieve higher\nFisher information values compared to the two-photon experiment. These findings\nhighlight the potential of distinguishable multi-photon states for enhanced\nprecision in quantum metrology and related applications."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.07986",
    "c_title":[
      "QGHNN: A quantum graph Hamiltonian neural network"
    ],
    "c_abstract":[
      "Representing and learning from graphs is essential for developing effective\nmachine learning models tailored to non-Euclidean data. While Graph Neural\nNetworks (GNNs) strive to address the challenges posed by complex,\nhigh-dimensional graph data, Quantum Neural Networks (QNNs) present a\ncompelling alternative due to their potential for quantum parallelism. However,\nmuch of the current QNN research tends to overlook the vital connection between\nquantum state encoding and graph structures, which limits the full exploitation\nof quantum computational advantages. To address these challenges, this paper\nintroduces a quantum graph Hamiltonian neural network (QGHNN) to enhance graph\nrepresentation and learning on noisy intermediate-scale quantum computers.\nConcretely, a quantum graph Hamiltonian learning method (QGHL) is first created\nby mapping graphs to the Hamiltonian of the topological quantum system. Then,\nQGHNN based on QGHL is presented, which trains parameters by minimizing the\nloss function and uses the gradient descent method to learn the graph.\nExperiments on the PennyLane quantum platform reveal that QGHNN outperforms all\nassessment metrics, achieving the lowest mean squared error of \\textbf{$0.004$}\nand the maximum cosine similarity of \\textbf{$99.8\\%$}, which shows that QGHNN\nnot only excels in representing and learning graph information, but it also has\nhigh robustness ability. QGHNN can reduce the impact of quantum noise and has\nsignificant potential application in future research of quantum knowledge\ngraphs and recommendation systems."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-85",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16220",
    "b_title":[
      "Star formation in low brightness galaxies and in the extended gaseous\n  disks of normal galaxies"
    ],
    "b_abstract":[
      "We analyze the available observational data on the radial distribution of gas\nand young stellar populations in the disks of low surface brightness (LSB)\ngalaxies and in the outer regions or the extended disks of normal brightness\n(HSB) galaxies. These cases involve star formation under special conditions of\nlow volume and surface gas density. There is no well-defined boundary between\nthese subgroups of galaxies that we consider, but in non-dwarf LSB galaxies the\nrate of current star formation within the wide range of radial distances\nappears to be higher compared to the outer disks of most of HSB galaxies at\nsimilar values of the surface gas density. The factors that could stimulate the\ncompression of the rarefied gas at the periphery of galaxies are briefly\ndiscussed. Attention is drawn to the idea that the densities of LSB disks\nestimated from their brightness may be underestimated."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.16607",
    "c_title":[
      "Predictions for Detecting a Turndown in the Baryonic Tully Fisher\n  Relation"
    ],
    "c_abstract":[
      "The baryonic Tully Fisher relation (bTFR) provides an empirical connection\nbetween baryonic mass and dynamical mass (measured by the maximum rotation\nvelocity) for galaxies. Due to the impact of baryonic feedback in the shallower\npotential wells of dwarf galaxies, the bTFR is predicted to turn down at low\nmasses from the extrapolated power-law relation at high masses. The low-mass\nend of the bTFR is poorly constrained due to small samples and difficulty in\nconnecting the galaxy's gas kinematics to its dark matter halo. Simulations can\nhelp us understand this connection and interpret observations. We measure the\nbTFR with 66 dwarf galaxies from the Marvel-ous and Marvelous Massive Dwarfs\nhydrodynamic simulations. Our sample has M$_\\star = 10^6-10^9$ M$_\\odot$, and\nis mostly gas dominated. We compare five velocity methods: V$_\\text{out,circ}$\n(spatially resolved mass-enclosed), V$_\\text{out,mid}$ (spatially resolved\nmidplane gravitational potential), and unresolved HI linewidths at different\npercentages of the peak flux (W$_\\text{10}$, W$_\\text{20}$, and W$_\\text{50}$).\nWe find an intrinsic turndown in the bTFR for maximum halo speeds $\\lesssim 50$\nkm s$^{-1}$ (or total baryonic mass, M$_\\text{bary}\\lesssim 10^{8.5}$\nM$_\\odot$). We find that observing HI in lower-mass galaxies to the\nconventional surface density limit of 1M$_\\odot$pc$^{-2}$ is not enough to\ndetect a turndown in the bTFR; none of the HI velocity methods (spatially\nresolved or unresolved) recover the turndown, and we find bTFR slopes\nconsistent with observations of higher-mass galaxies. However, we predict that\nthe turndown can be recovered by resolved rotation curves if the HI limit is\n$\\lesssim 0.08$ M$_\\odot$ pc$^{-2}$, which is within the sensitivity of current\nHI surveys like FEASTS and MHONGOOSE."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-86",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15279",
    "b_title":[
      "Chaos aided regime of Laser\/Electromagnetic Energy Absorption by plasma"
    ],
    "b_abstract":[
      "The absorption of laser energy by plasma is of paramount importance for\nvarious applications. Collisional and resonant processes are often invoked for\nthis purpose. However, in some contexts (e.g. in vacuum and the JxB heating),\nthe energy transfer occurs even when plasma is collisionless, and there is no\nresonant process involved. The energy absorption in these cases has been\nattributed to the sheath electrostatic fields that get generated as the\nelectrons are pulled out in the vacuum from the plasma medium. The origin of\nirreversibility aiding the absorption, in these cases, remains to be\nunderstood. Particle-In-Cell (PIC) simulations using the OSIRIS 4.0 platform\nhave been carried out. The nearby trajectories of lighter electron species\ninvolved in the interaction with the laser show exponential separation. This is\nconfirmed by the positive Lyapunov index and also by other characterizations.\nThe observations in these cases are contrasted with the electron cyclotron\nresonant case, which shows negligible chaos in the electron trajectories\ndespite the energy absorption percentage being high."
    ],
    "b_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.18399",
    "c_title":[
      "T3ST code: Turbulent Transport in Tokamaks via Stochastic Trajectories"
    ],
    "c_abstract":[
      "We introduce the Turbulent Transport in Tokamaks via Stochastic Trajectories\n(T3ST) code, designed to address the problem of turbulent transport using a\nstatistical approach complementary to gyrokinetics. The code employs\ntest-particle methods to track the dynamics of charged particles in\naxisymmetric magnetic equilibria, accounting for both turbulence and Coulomb\ncollisions. The turbulence is decoupled from plasma dynamics and represented\nthrough a statistical ensemble of synthetic random fields with specified\nspectral properties. This approach enables T3ST to compute transport\ncoefficients as Lagrangian correlations - orders of magnitude faster than\ngyrokinetic codes."
    ],
    "c_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-87",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16108",
    "b_title":[
      "Control of a non-stationary dynamic system with estimating a strategy of\n  human resources management by the integral indicators method"
    ],
    "b_abstract":[
      "A general idea research is a lack of articles to estimate system indicator of\nthe effectiveness of the strategy of human resources management (HR) at an\neconomic object (enterprise). We are use the method of integral indicators for\na comprehensive assessment of the activities of an economic object\n(enterprise). The economic object is formalized as a nonstationary dynamic\nsystem. The system has a dimension of 1.2 million parameters. The parameters of\nthe object under research (business processes) are compared with staff\nresponsibilities. The sanctions mode is set by blocking staff responsibilities\nin the interval in each time period t. The integral indicator is calculated\naccording to the standard mode (Strategy 1) of the economic object (enterprise)\nand without blocking the staff responsibilities. Also, the integral indicator\nis calculated according to the non-standard operating mode of the enterprise\n(Strategy 2) with the blocking of staff responsibilities. The difference\nbetween the integral indicator of Strategy 2 and Strategy 1 is an estimation of\nthe impact of the imposed sanctions. The resource consumption for the\nrestoration of the normal operation of an economic object after the imposed\nsanctions is give (61.63 million rubles). Example 2 introduces equipment\nsanctions from America for a new project. An analysis of the indicators of a\nnew project is carried out with the search and use of analog equipment."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.00981",
    "c_title":[
      "Linear-Quadratic Optimal Control for Mean-Field Stochastic Differential\n  Equations in Infinite-Horizon with Regime Switching"
    ],
    "c_abstract":[
      "This paper is concerned with stochastic linear quadratic (LQ, for short)\noptimal control problems in an infinite horizon with conditional mean-field\nterm in a switching regime environment. The orthogonal decomposition introduced\nin [21] has been adopted. Desired algebraic Riccati equations (AREs, for short)\nand a system of backward stochastic differential equations (BSDEs, for short)\nin infinite time horizon with the coefficients depending on the Markov chain\nhave been derived. The determination of closed-loop optimal strategy follows\nfrom the solvability of ARE and BSDE. Moreover, the solvability of BSDEs leads\nto a characterization of open-loop solvability of the optimal control problem."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-88",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08012",
    "b_title":[
      "Gigahertz-Frequency, Acousto-Optic Phase Modulation of Visible Light in\n  a CMOS-Fabricated Photonic Circuit"
    ],
    "b_abstract":[
      "Here we present an efficient, visible-light, gigahertz-frequency\nacousto-optic modulator fabricated on a 200 mm wafer in a volume CMOS foundry.\nOur device combines a piezoelectric transducer and a photonic waveguide within\na single microstructure that confines both a propagating optical mode and an\nelectrically excitable breathing-mode mechanical resonance. By tuning the\ndevice's geometry to optimize the optomechanical interaction, we achieve\nmodulation depths exceeding 2 rad with 15 mW applied microwave power at 2.31\nGHz in a 2 mm long device. This corresponds to a modulation figure of merit of\n$V_{\\pi}\\cdot L$ = 0.26 Vcm in a visible-light, integrated acousto-optics\nplatform that can be straightforwardly extended to a wide range of optical\nwavelengths and modulation frequencies. For the important class of\ngigahertz-frequency modulators that can handle hundreds of milliwatts of\nvisible-light optical power, which are critical for scalable quantum control\nsystems, this represents a 15x decrease in $V_{\\pi}$ and a 100x decrease in\nrequired microwave power compared to the commercial state-of-the-art and\nexisting work in the literature."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.00936",
    "c_title":[
      "Fabrication and characterization of shape- and topology-optimized\n  optical cavities with deep sub-wavelength confinement for interfacing with\n  colloidal quantum dots"
    ],
    "c_abstract":[
      "We employ a combined shape- and topology-optimization strategy to design\nmanufacturable two-dimensional photonic crystal-based optical nanocavities that\nconfine light to length scales well below the resonance wavelength. We present\ndetails of the design strategy as well as scanning electron micrographs of the\nfabricated indium phosphide cavities with a compact footprint of\n~\"4.5{\\lambda}*4.5{\\lambda}\" , which feature gaps on the order of 10 nm and\ntheoretical mode volumes in the gap center below (0.1 ({\\lambda}\/2n_air))^3.\nSubsequent optical characterization of the far-field emission as well as\nPurcell-enhanced photoluminescence from the cavities with and without\nspin-coated colloidal quantum dots are compared to numerical simulations. The\nresults corroborate the potential of the design strategy and fabrication\nprocess for ensuring high yield and reliable performance as well as the\nviability of the material platform for exploring light-matter interaction with\ncolloidal QDs."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-89",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12669",
    "b_title":[
      "Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite\n  Solar Cell Research"
    ],
    "b_abstract":[
      "The rapid advancement of perovskite solar cells (PSCs) has led to an\nexponential growth in research publications, creating an urgent need for\nefficient knowledge management and reasoning systems in this domain. We present\na comprehensive knowledge-enhanced system for PSCs that integrates three key\ncomponents. First, we develop Perovskite-KG, a domain-specific knowledge graph\nconstructed from 1,517 research papers, containing 23,789 entities and 22,272\nrelationships. Second, we create two complementary datasets: Perovskite-Chat,\ncomprising 55,101 high-quality question-answer pairs generated through a novel\nmulti-agent framework, and Perovskite-Reasoning, containing 2,217 carefully\ncurated materials science problems. Third, we introduce two specialized large\nlanguage models: Perovskite-Chat-LLM for domain-specific knowledge assistance\nand Perovskite-Reasoning-LLM for scientific reasoning tasks. Experimental\nresults demonstrate that our system significantly outperforms existing models\nin both domain-specific knowledge retrieval and scientific reasoning tasks,\nproviding researchers with effective tools for literature review, experimental\ndesign, and complex problem-solving in PSC research."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10197",
    "c_title":[
      "MathConstruct: Challenging LLM Reasoning with Constructive Proofs"
    ],
    "c_abstract":[
      "While Large Language Models (LLMs) demonstrate impressive performance in\nmathematics, existing math benchmarks come with significant limitations. Many\nfocus on problems with fixed ground-truth answers, and are often saturated due\nto problem simplicity or the viability of guessing or memorization. Crucially,\nthey capture only a narrow subset of relevant math problems. To address this\nresearch gap, we introduce \\mc, a new benchmark of 126 challenging problems\nsourced from various math competitions, which targets constructive proofs, a\nwidely encountered problem type requiring the construction of mathematical\nobjects with specific properties. These proofs are particularly suitable for\nLLM evaluation, as solution correctness can be easily verified. Our automated\nverifiers also enable MathConstruct to generate problem variations, used to\nevaluate robustness. State-of-the-art LLMs solve only 54% of MathConstruct\nproblems, highlighting its complexity and importance for LLM evaluation."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-90",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02414",
    "b_title":[
      "Transolver++: An Accurate Neural Solver for PDEs on Million-Scale\n  Geometries"
    ],
    "b_abstract":[
      "Although deep models have been widely explored in solving partial\ndifferential equations (PDEs), previous works are primarily limited to data\nonly with up to tens of thousands of mesh points, far from the million-point\nscale required by industrial simulations that involve complex geometries. In\nthe spirit of advancing neural PDE solvers to real industrial applications, we\npresent Transolver++, a highly parallel and efficient neural solver that can\naccurately solve PDEs on million-scale geometries. Building upon previous\nadvancements in solving PDEs by learning physical states via Transolver,\nTransolver++ is further equipped with an extremely optimized parallelism\nframework and a local adaptive mechanism to efficiently capture eidetic\nphysical states from massive mesh points, successfully tackling the thorny\nchallenges in computation and physics learning when scaling up input mesh size.\nTransolver++ increases the single-GPU input capacity to million-scale points\nfor the first time and is capable of continuously scaling input size in linear\ncomplexity by increasing GPUs. Experimentally, Transolver++ yields 13% relative\npromotion across six standard PDE benchmarks and achieves over 20% performance\ngain in million-scale high-fidelity industrial simulations, whose sizes are\n100$\\times$ larger than previous benchmarks, covering car and 3D aircraft\ndesigns."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.20954",
    "c_title":[
      "Robust and Efficient Writer-Independent IMU-Based Handwriting\n  Recognization"
    ],
    "c_abstract":[
      "Online handwriting recognition (HWR) using data from inertial measurement\nunits (IMUs) remains challenging due to variations in writing styles and the\nlimited availability of high-quality annotated datasets. Traditional models\noften struggle to recognize handwriting from unseen writers, making\nwriter-independent (WI) recognition a crucial but difficult problem. This paper\npresents an HWR model with an encoder-decoder structure for IMU data, featuring\na CNN-based encoder for feature extraction and a BiLSTM decoder for sequence\nmodeling, which supports inputs of varying lengths. Our approach demonstrates\nstrong robustness and data efficiency, outperforming existing methods on WI\ndatasets, including the WI split of the OnHW dataset and our own dataset.\nExtensive evaluations show that our model maintains high accuracy across\ndifferent age groups and writing conditions while effectively learning from\nlimited data. Through comprehensive ablation studies, we analyze key design\nchoices, achieving a balance between accuracy and efficiency. These findings\ncontribute to the development of more adaptable and scalable HWR systems for\nreal-world applications."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-91",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12790",
    "b_title":[
      "Anomalous exchange correlation of quasiparticles with entangled Nambu\n  spinors"
    ],
    "b_abstract":[
      "Entanglement of spin degree of freedom can drastically alter the orbital\nexchange symmetry of electrons, switching their bunching and antibunching\nbehaviors and the resultant current correlations in the Hanbury-Brown-Twiss\ninterferometry. Here, we investigate the exchange correlation of quasiparticles\nwith entanglement encoded in the Nambu spinors, or the electron-hole degree of\nfreedom. In contrast to the conventional correspondence between spin\nentanglement and current correlation, we find that singlet (triplet)\nentanglement of Nambu spinors results in suppressed (enhanced) current\ncorrelation. This effect arises because the charge degree of freedom itself\nencodes the entanglement. We propose implementing this phenomenon in the edge\nstates of a quantum Hall system, where the entangled states of the Nambu\nspinors can be continuously tuned by gate voltages. Our study reveals a novel\nrelationship between entanglement and charge correlations, offering an\neffective approach for detecting entanglement of Nambu spinors."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10801",
    "c_title":[
      "Tuning magnetism in graphene nanoribbons via strain and adatoms"
    ],
    "c_abstract":[
      "We investigate the impact of strain and adsorbed H adatoms on the magnetic\nproperties of zigzag graphene nanoribbons (ZGNRs) using a combination of\ntight-binding and density functional theory methods for both, ferromagnetic\n(FM) and antiferromagnetic edge configurations (AFM). Our study reveals that\nlongitudinal strain induces a significant enhancement in the edge magnetic\nmoment, that we attribute to strain-driven modifications in the band structure.\nIn addition, we describe H~adatoms within the tight-binding approach by\nemploying both an unrelaxed vacancy model and the Anderson impurity model. By\ncomparing to density functional theory results, we corroborate that the\nAnderson impurity model is best suited to describe H adsorption. We then focus\non the metallic FM edge configuration of the ZGNRs to better exploit the tuning\nof its properties. We find that the magnetic configuration of H~adatoms is\nstrongly influenced by the edges, with an AFM coupling between edges and the\nH~adatom. In fact, the magnetic spatial pattern of the H adatom differs to that\nfound in graphene due to this edge coupling. Importantly, we find robust\ndiscrete plateaus of integer magnetic moment as strain is varied in the\ndefected ZGNRs, that we relate to changes in the band structure, namely, a\nhalf-metallic character or the opening of a gap. This behavior can be of\ninterest for magnetic applications of carbon-based nanostructures"
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-92",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02154",
    "b_title":[
      "Structural constraints to compare phenomenal experience"
    ],
    "b_abstract":[
      "This article defines a partial order structure to study the relationship\nbetween levels and contents of conscious subjective experience in a single\nmathematical set-up. We understand phenomenal structure as extrapolated\nrelationships among experiences, instead of fixed properties of specific\nexperiences. Our mathematical account is based on multilayer network theory.\nMultilayer theory is a generalization of graph and network theory, widely used\nin several scientific domains. This structure is also the underlying conceptual\nand mathematical structure of most current models of conscious experience. From\nour simple set of assumptions, yet rigorous analysis, we conclude that assuming\nthe comparison and quantification among phenomenal experiences yield only\npartial comparison, rather than commonly assumed absolute comparability. This\nhas implications for evolutionary and animal consciousness: evolution may\nencompass diverse modes of experiencing, not necessarily implying larger ones\non an absolute scale. Our characterization elucidates structural constraints on\nexperiential comparisons imposed by assumptions and choices made by modellers\nas active participants in the scientific process. In summary, in light of our\nphenomenological intuitions, it might be right that some experiences carry\nqualitative aspects that make them incompatible or non-comparable with other\nexperiences, quantitatively speaking. Some experiences are comparable (e.g. at\nsome experiential levels), but others are not. These results have direct\nimplications for consciousness science, evolution and animal consciousness."
    ],
    "b_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2503.07798",
    "c_title":[
      "Risk and Protective Factors in Parkinsons Disease"
    ],
    "c_abstract":[
      "Understanding the risk and protective factors associated with Parkinsons\ndisease (PD) is crucial for improving outcomes for patients, individuals at\nrisk, healthcare providers, and healthcare systems. Studying these factors not\nonly enhances our knowledge of the disease but also aids in developing\neffective prevention, management, and treatment strategies. This paper reviews\nthe key risk and protective factors associated with PD, with a particular focus\non the biological mechanisms underlying these factors. Risk factors include\ngenetic mutations, racial predispositions, and environmental exposures, all of\nwhich contribute to an increased likelihood of developing PD or accelerating\ndisease progression. Conversely, protective factors such as regular physical\nexercise, adherence to a Mediterranean diet, and higher urate levels have\ndemonstrated potential to reduce inflammation and support mitochondrial\nfunction, thereby mitigating disease risk. However, identifying and validating\nthese factors presents significant challenges. To overcome challenges, we\npropose several solutions and recommendations. Future research should\nprioritize the development of standardized biomarkers for early diagnosis,\ninvestigate gene-environment interactions in greater depth, and refine animal\nmodels to better mimic human PD pathology. Additionally, we offer actionable\nrecommendations for PD prevention and management, tailored to healthy\nindividuals, patients diagnosed with PD, and healthcare systems. These\nstrategies aim to improve clinical outcomes, enhance quality of life, and\noptimize healthcare delivery for PD."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-93",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02568",
    "b_title":[
      "Short-Term Balmer Line Emission Variability in M Dwarfs"
    ],
    "b_abstract":[
      "M Dwarfs make up the majority of stars, offering an avenue for discovering\nexoplanets due to their smaller sizes. However, their magnetic activity poses\nchallenges for exoplanet detection, characterization, and planetary\nhabitability. Understanding its magnetic activity, including surface starspots\nand internal dynamos, is crucial for exoplanet research. In this study, we\npresent short-term variability in four Balmer emission lines \\ha, \\hb, \\hg, and\n\\hd\\ for a sample of 77 M dwarfs of varying spectral types, and binarity. Stars\nwere observed using the MDM Observatory's Ohio State Multi-Object Spectrograph\non the 2.4m Telescope and the Modular Spectrograph on the 1.3 m Telescope.\nThese data are combined with TESS photometry to explore the connection between\nspectroscopic and photometric variability. We observe sporadic short-term\nvariability in Balmer lines for some stars, on timescale $\\gtrsim$ 15-min, but\nmuch shorter than the stellar rotation period. We calculate periods for stars\nlacking those measurements, re-evaluated the relationship between amplitude\n(\\rvar)-activity relation for the \\ha \\ line from\n\\citet{garcia_soto_contemporaneous_2023}, and extended our analysis to the \\hb,\n\\hg \\ and \\hd \\ lines, which indicates that the relation becomes increasingly\ndispersed for higher-order Balmer lines. This is consistent with increased\nintrinsic variability from lower to higher order lines. Additionally, we\ncompute the Balmer decrement, using \\hb \\ as the fiducial, for stars where we\ncould measure \\hg \\ and\/or \\hd. The Balmer decrement can show distinct patterns\nduring white-light flares, with significant differences even for the same star.\nWe also find evidence for dark spots on \\object{TIC 283866910}."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.16710",
    "c_title":[
      "NuSTAR detection of a hot stellar superflare with a temperature of 95 MK\n  in hard X-rays"
    ],
    "c_abstract":[
      "A search of the hard X-ray archive data of NuSTAR found a transient source,\nNuSTAR J230059+5857.4, during an observation of 1E 2259+586 on 2013 April 25. A\nmulti-wavelength analysis using X-ray, optical, and IR data, mostly taken in\nits quiescent phase, was conducted to identify the origin of NuSTAR\nJ230059+5857.4 and elucidate the phenomena associated with the flare activity.\nThe results indicated that NuSTAR J230059+5857.4 was a stellar flare that\noccurred on a single M-dwarf, M-dwarf binary, or pre-main-sequence star. NuSTAR\nJ230059+5857.4 exhibited the higher emission measure and higher temperature,\n8.60+2.15\/-1.73x10^54 cm^-3 and 8.21+2.71\/-1.86 keV, respectively, on average\nthan the nominal values of stellar flares reported in the past. The flare loop\nsize estimated on the basis of the model to balance the plasma and magnetic\npressures was larger than the stellar radius by a factor of several. Since\nbased on solar flare loops, this flare loop scale is excessively large, we\nconjecture that the observed large emission measure is possible to be\nattributed to the observation of mutually-associated multiple flares\nsimultaneously occurring on the stellar surface, known as sympathetic flares.\nThanks to the large effective area of NuSTAR in the hard X-ray band, we can\nconduct detailed discussion about a temperature variation associated with the\nflare. Investigation of the temperature variation during the flare revealed\nthat the temperature remained significantly higher than during the quiescent\nphase even after the count rate dropped to around 5% of the peak. The sustained\nhigh temperature over the long duration is consistent with the idea of\nsympathetic flares. We found that it is essential to use theoretical models to\nevaluate loops and assess temporal changes in temperature as done in this study\nto determine whether there are multiple flares or not when analyzing flare\nobservation data."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-94",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14044",
    "b_title":[
      "Leveraging 13C NMR spectroscopic data derived from SMILES to predict the\n  functionality of small biomolecules by machine learning: a case study on\n  human Dopamine D1 receptor antagonists"
    ],
    "b_abstract":[
      "This study contributes to ongoing research which aims to predict small\nbiomolecule functionality using Carbon-13 Nuclear Magnetic Resonance ($^{13}$C\nNMR) spectrum data and machine learning (ML). The approach was demonstrated\nusing a bioassay on human dopamine D1 receptor antagonists. The Simplified\nMolecular Input Line Entry System (SMILES) notations of compounds in this\nbioassay were extracted and converted into spectroscopic data by software\ndesigned for this purpose. The resulting data was then used for ML with\nscikit-learn algorithms. The ML models were trained by 27,756 samples and\ntested by 5,466. From the estimators K-Nearest neighbor, Decision Tree\nClassifier, Random Forest Classifier, Gradient Boosting Classifier, XGBoost\nClassifier, and Support Vector Classifier, the last performed the best,\nachieving 71.5 % accuracy, 77.4 % precision, 60.6% recall, 68 % F1, 71.5 % ROC,\nand 0.749 cross-validation score with 0.005 standard deviation. The methodology\ncan be applied to predict any functionality of any compound when relevant data\nare available. It was hypothesized also that increasing the number of samples\nwould increase accuracy. In addition to the SMILES $^{13}$C NMR spectrum ML\nmodel, the time- , and cost-efficient CID_SID ML model was developed. This\nmodel allows researchers who have developed a compound and obtained its PubChem\nCID and SID to check whether their compound is also a human dopamine D1\nreceptor antagonist based solely on the PubChem identifiers. The metrics of the\nCID_SID ML model were 80.2% accuracy, 86.3% precision, 70.4% recall, 77.6% F1,\n79.9% ROC, five-fold cross-validation score of 0.8071 with 0.0047 Standard\ndeviation."
    ],
    "b_categories":[
      [
        "q-bio.OT"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2502.15597",
    "c_title":[
      "From FAIR to CURE: Guidelines for Computational Models of Biological\n  Systems"
    ],
    "c_abstract":[
      "Guidelines for managing scientific data have been established under the FAIR\nprinciples requiring that data be Findable, Accessible, Interoperable, and\nReusable. In many scientific disciplines, especially computational biology,\nboth data and models are key to progress. For this reason, and recognizing that\nsuch models are a very special type of 'data', we argue that computational\nmodels, especially mechanistic models prevalent in medicine, physiology and\nsystems biology, deserve a complementary set of guidelines. We propose the CURE\nprinciples, emphasizing that models should be Credible, Understandable,\nReproducible, and Extensible. We delve into each principle, discussing\nverification, validation, and uncertainty quantification for model credibility;\nthe clarity of model descriptions and annotations for understandability;\nadherence to standards and open science practices for reproducibility; and the\nuse of open standards and modular code for extensibility and reuse. We outline\nrecommended and baseline requirements for each aspect of CURE, aiming to\nenhance the impact and trustworthiness of computational models, particularly in\nbiomedical applications where credibility is paramount. Our perspective\nunderscores the need for a more disciplined approach to modeling, aligning with\nemerging trends such as Digital Twins and emphasizing the importance of data\nand modeling standards for interoperability and reuse. Finally, we emphasize\nthat given the non-trivial effort required to implement the guidelines, the\ncommunity moves to automate as many of the guidelines as possible."
    ],
    "c_categories":[
      [
        "q-bio.OT"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-95",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08111",
    "b_title":[
      "Interstellar dust revealed by light from cosmic dawn"
    ],
    "b_abstract":[
      "The obscuration of light from a distant galaxy has raised the possibility\nthat a type of carbon dust existed in the earliest epochs of the Universe --\nchallenging the idea that stars had not yet evolved enough to make such\nmaterial."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07550",
    "c_title":[
      "The Expanding 3-Kiloparsec Arms are neither Expanding nor Spiral Arms,\n  but X1 Orbits driven by the Galactic Bar"
    ],
    "c_abstract":[
      "Near the center of our Milky Way is a bar-like structure and the so-called\nExpanding 3-kpc arms. We currently have limited knowledge of this important\nregion, since we are about 8.2 kpc from the center and cannot directly observe\nit at optical wavelengths, owing to strong extinction from interstellar dust.\nHere we present extremely precise VLBI measurements of water maser sources from\nthe BeSSeL Survey, where extinction is not a problem, which accurately\ndetermine the 3-dimensional locations and motions of three massive young stars.\nCombined with previous measurements, these stars delineate a trail of orbits\noutlining the Milky Way's Galactic Bar. We present the first measurements\ncapturing the dynamics of quasi-elliptical (X1) orbits around the Galactic Bar.\nOur findings provide evidence substantiating the existence of such orbits\npopulated by massive young stars. Our measurements of the position and velocity\nof a number of massive young stars, previously identified with the Expanding\n3-kpc arms, show that they are more likely located in the X1 orbits about the\nGalactic Bar. Also, some stars previously assigned to the Norma spiral arm\nappear to be in these orbits, which suggests that this spiral arm does not\nextend past the end of the bar."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-96",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03450",
    "b_title":[
      "Skeletonisation Scale-Spaces"
    ],
    "b_abstract":[
      "The medial axis transform is a well-known tool for shape recognition. Instead\nof the object contour, it equivalently describes a binary object in terms of a\nskeleton containing all centres of maximal inscribed discs. While this shape\ndescriptor is useful for many applications, it is also sensitive to noise:\nSmall boundary perturbations can result in large unwanted expansions of the\nskeleton. Pruning offers a remedy by removing unwanted skeleton parts. In our\ncontribution, we generalise this principle to skeleton sparsification: We show\nthat subsequently removing parts of the skeleton simplifies the associated\nshape in a hierarchical manner that obeys scale-space properties.\n  To this end, we provide both a continuous and discrete theory that\nincorporates architectural and simplification statements as well as\ninvariances. We illustrate how our skeletonisation scale-spaces can be employed\nfor practical applications with two proof-of-concept implementations for\npruning and compression."
    ],
    "b_categories":[
      [
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15595",
    "c_title":[
      "Causal Modeling of fMRI Time-series for Interpretable Autism Spectrum\n  Disorder Classification"
    ],
    "c_abstract":[
      "Autism spectrum disorder (ASD) is a neurological and developmental disorder\nthat affects social and communicative behaviors. It emerges in early life and\nis generally associated with lifelong disabilities. Thus, accurate and early\ndiagnosis could facilitate treatment outcomes for those with ASD. Functional\nmagnetic resonance imaging (fMRI) is a useful tool that measures changes in\nbrain signaling to facilitate our understanding of ASD. Much effort is being\nmade to identify ASD biomarkers using various connectome-based machine learning\nand deep learning classifiers. However, correlation-based models cannot capture\nthe non-linear interactions between brain regions. To solve this problem, we\nintroduce a causality-inspired deep learning model that uses time-series\ninformation from fMRI and captures causality among ROIs useful for ASD\nclassification. The model is compared with other baseline and state-of-the-art\nmodels with 5-fold cross-validation on the ABIDE dataset. We filtered the\ndataset by choosing all the images with mean FD less than 15mm to ensure data\nquality. Our proposed model achieved the highest average classification\naccuracy of 71.9% and an average AUC of 75.8%. Moreover, the inter-ROI\ncausality interpretation of the model suggests that the left precuneus, right\nprecuneus, and cerebellum are placed in the top 10 ROIs in inter-ROI causality\namong the ASD population. In contrast, these ROIs are not ranked in the top 10\nin the control population. We have validated our findings with the literature\nand found that abnormalities in these ROIs are often associated with ASD."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-97",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06846",
    "b_title":[
      "On the eternal non-Markovianity of qubit maps"
    ],
    "b_abstract":[
      "As is well known, unital Pauli maps can be eternally non-CP-divisible. In\ncontrast, here we show that in the case of non-unital maps, eternal\nnon-Markovianity in the non-unital part is ruled out. In the unital case, the\neternal non-Markovianity can be obtained by a convex combination of two\ndephasing semigroups, but not all three of them. We study these results and the\nramifications arising from them."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17526",
    "c_title":[
      "Amplified quantum battery via dynamical modulation"
    ],
    "c_abstract":[
      "We investigate the charging dynamics of a frequency-modulated quantum battery\n(QB) placed within a dissipative cavity environment. Our study focuses on the\ninteraction of such a battery under both weak and strong coupling regimes,\nemploying a model in which the quantum battery and charger are represented as\nfrequency-modulated qubits indirectly coupled through a zero-temperature\nenvironment. It is demonstrated that both the modulation frequency and\namplitude are crucial for optimizing the charging process and the ergotropy of\nthe quantum battery. Specifically, high-amplitude, low-frequency modulation\nsignificantly enhances charging performance and work extraction in the strong\ncoupling regime. As an intriguing result, it is deduced that modulation at very\nlow frequencies leads to the emergence of energy storage and work extraction in\nthe weak coupling regime. Such a result can never be achieved without\nmodulation in the weak coupling regime. These results highlight the importance\nof adjusting modulation parameters to optimize the performance of quantum\nbatteries for real-world applications in quantum technologies."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-98",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15543",
    "b_title":[
      "Energy Extraction from Rotating Black Hole with Quintessential Energy\n  through the Penrose Process"
    ],
    "b_abstract":[
      "We investigate the geometry, dynamics, and collision mechanisms in the\nergoregion of KerrNewman-AdS black hole influenced by quintessential energy.\nParticle splittings within the ergoregion are analyzed, demonstrating their\nrole in energy extraction via the Penrose process. Increased spin elongates the\nergosphere, while higher quintessential parameters expand static limits and\ndistort photon regions. Prograde orbits benefit from reduced energy and angular\nmomentum due to frame-dragging, whereas retrograde orbits require higher\nenergy. Quintessential energy weakens the gravitational pull, shifts stable\norbit radii, and enhances orbital chaos, as indicated by Lyapunov exponents.\nThe Penrose process demonstrates efficiencies ranging from 5% to 35%, with peak\nefficiency achieved at high spin, but diminishing with increased charge or\nquintessential energy due to reduced frame-dragging. We derive the exprssion\nfor irreducible mass and discuss its dependence on cosmological and\nquintessence parameters, revealing their role in limiting extractable energy."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03212",
    "c_title":[
      "Cosmic dynamics and observational constraints in $f(Q)$ gravity with\n  affine equation of state"
    ],
    "c_abstract":[
      "In this study, we explore the cosmological implications of $f(Q)$ gravity\nwith an affine equation of state (EoS). We study the impact of affine EoS on\nthe cosmic evolution in model and derive the functional form of $f(Q)$ gravity\nrealizing this kind of scenario. We show that the non-metricity scalar may\ndescribe the unified scenario in which the universe transits from the\ndecelerated expansion into the accelerated expansion. The model parameters are\nconstrained through the Bayesian analysis based on $\\chi^{2}$ minimization\ntechnique with the observational data of the cosmic chronometer and supernovae\ntype Ia. The cosmic dynamics based on constrained parameters describe the\nobservable universe evolution. The present day values of the cosmological\nparameters along with the current age of the universe are compatible with the\nobservations."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-99",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05913",
    "b_title":[
      "GDL 1.1, a smart and green language"
    ],
    "b_abstract":[
      "GDL, a free interpreter for the IDL language, continues to develop smoothly,\ndriven by feedback and requests from an increasingly active and growing user\nbase, especially since GDL was made available on GitHub. Among the most notable\nfeatures introduced in recent years are stable Widgets; extensive testing on\nM1, M2, and M3 processors; excellent computational performance (including\nOpenMP support) demonstrated across a comprehensive benchmark; simplified\ncompilation and installation processes; and the availability of SHMMAP and\nBridge functions, which enable concurrent GDL runs on shared RAM in HPC\nenvironments.\n  As developers of GDL, we believe this language holds a valuable place in\ntoday's world, where efficiency and low-power computing are essential. GDL (not\nto mention IDL), written in C\/C++, demonstrates exceptional efficiency in\n\"real-world\" benchmarks, making it one of the few interpreted languages that\ncan truly be considered \"green.\" Moreover, it is likely the only interpreter\naccompanied by a vast collection of free, well-tested, and proven astronomical\nprocedures developed by colleagues over the years. GDL also stands out for its\nsuitability for long-term projects, thanks to its stable and reliable syntax."
    ],
    "b_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.06968",
    "c_title":[
      "AAS2RTO: Automated Alert Streams to Real-Time Observations: Preparing\n  for rapid follow-up of transient objects in the era of LSST"
    ],
    "c_abstract":[
      "The upcoming Vera C. Rubin Legacy Survey of Space and Time (LSST) will\ndiscover tens of thousands of astrophysical transients per night, far outpacing\navailable spectroscopic follow-up capabilities. Carefully prioritising\ncandidates for follow-up observations will maximise the scientific return from\nsmall telescopes with a single-object spectrograph. We introduce AAS2RTO, an\nastrophysical transient candidate prioritisation tool written in Python.\nAAS2RTO is flexible in that any number of criteria that consider observed\nproperties of transients can be implemented. The visibility of candidates from\na given observing site is also considered. The prioritised list of candidates\nprovided by AAS2RTO is continually updated when new transient data are made\navailable. Therefore, it can be applied to observing campaigns with a wide\nvariety of scientific motivations. AAS2RTO uses a greedy algorithm to\nprioritise candidates. Candidates are represented by a single numerical value,\nor `score'. Scores are computed by constructing simple numerical factors which\nindividually consider the competing facets of a candidate which make it\nsuitable for follow-up observation. AAS2RTO is currently configured to work\nprimarily with photometric data from the Zwicky Transient Facility (ZTF),\ndistributed by certified LSST community brokers. We provide an example of how\nAAS2RTO can be used by defining a set of criteria to prioritise observations of\ntype Ia supernovae (SNe Ia) close to peak brightness, in preparation for\nobservations with the spectrograph at the Danish-1.54m telescope. Using a\nsample of archival alerts from ZTF, we evaluate the criteria we have designed\nto estimate the number of SNe Ia that we will be able to observe with a 1.5m\ntelescope. Finally, we evaluate the performance of our criteria when applied to\nmock LSST observations of SNe Ia."
    ],
    "c_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-100",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09342",
    "b_title":[
      "GASPACHO: Gaussian Splatting for Controllable Humans and Objects"
    ],
    "b_abstract":[
      "We present GASPACHO: a method for generating photorealistic controllable\nrenderings of human-object interactions. Given a set of multi-view RGB images\nof human-object interactions, our method reconstructs animatable templates of\nthe human and object as separate sets of Gaussians simultaneously. Different\nfrom existing work, which focuses on human reconstruction and ignores objects\nas background, our method explicitly reconstructs both humans and objects,\nthereby allowing for controllable renderings of novel human object interactions\nin different poses from novel-camera viewpoints. During reconstruction, we\nconstrain the Gaussians that generate rendered images to be a linear function\nof a set of canonical Gaussians. By simply changing the parameters of the\nlinear deformation functions after training, our method can generate renderings\nof novel human-object interaction in novel poses from novel camera viewpoints.\nWe learn the 3D Gaussian properties of the canonical Gaussians on the\nunderlying 2D manifold of the canonical human and object templates. This in\nturns requires a canonical object template with a fixed UV unwrapping. To\ndefine such an object template, we use a feature based representation to track\nthe object across the multi-view sequence. We further propose an occlusion\naware photometric loss that allows for reconstructions under significant\nocclusions. Several experiments on two human-object datasets - BEHAVE and\nDNA-Rendering - demonstrate that our method allows for high-quality\nreconstruction of human and object templates under significant occlusion and\nthe synthesis of controllable renderings of novel human-object interactions in\nnovel human poses from novel camera views."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15106",
    "c_title":[
      "Distilling 3D distinctive local descriptors for 6D pose estimation"
    ],
    "c_abstract":[
      "Three-dimensional local descriptors are crucial for encoding geometric\nsurface properties, making them essential for various point cloud understanding\ntasks. Among these descriptors, GeDi has demonstrated strong zero-shot 6D pose\nestimation capabilities but remains computationally impractical for real-world\napplications due to its expensive inference process. Can we retain GeDi's\neffectiveness while significantly improving its efficiency? In this paper, we\nexplore this question by introducing a knowledge distillation framework that\ntrains an efficient student model to regress local descriptors from a GeDi\nteacher. Our key contributions include: an efficient large-scale training\nprocedure that ensures robustness to occlusions and partial observations while\noperating under compute and storage constraints, and a novel loss formulation\nthat handles weak supervision from non-distinctive teacher descriptors. We\nvalidate our approach on five BOP Benchmark datasets and demonstrate a\nsignificant reduction in inference time while maintaining competitive\nperformance with existing methods, bringing zero-shot 6D pose estimation closer\nto real-time feasibility. Project Website: https:\/\/tev-fbk.github.io\/dGeDi\/"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-101",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05025",
    "b_title":[
      "Microscopic origin of magnetoferroelectricity in monolayer NiBr$_{2}$\n  and NiI$_{2}$"
    ],
    "b_abstract":[
      "We investigate the magnetoelectric properties of the monolayer NiX$_{2}$ (X =\nBr, I) through first-principles calculations. Our calculations predict that the\nNiBr$_{2}$ monolayer exhibits a cycloidal magnetic ground state. For the\nNiI$_{2}$ monolayer, a proper-screw helical magnetic ground state with\nmodulation vector \\(\\boldsymbol{Q} = (q, 0, 0)\\) is adopted, approximated based\non experimental observations. The electric polarization in NiBr$_{2}$ shows a\nlinear dependence on the spin-orbit coupling strength \\(\\lambda_{\\text{SOC}}\\),\nwhich can be adequately described by the generalized Katsura-Nagaosa-Balatsky\n(gKNB) model, considering contributions from up to the third nearest-neighbor\nspin pairs. In contrast, the electric polarization in NiI$_{2}$ exhibits a\ndistinct dependence on \\(q\\) and \\(\\lambda_{\\text{SOC}}\\), which cannot be\nfully explained by the gKNB mechanism alone. To address this, the \\(p\\)-\\(d\\)\nhybridization mechanism is extended to NiI$_{2}$ to explain the observed\nbehavior. The respective contributions from the \\(p\\)-\\(d\\) hybridization and\nthe gKNB mechanism in NiI$_{2}$ are then quantitatively evaluated. Overall, our\nwork elucidates the microscopic mechanisms underlying multiferroicity in\nNiBr$_{2}$ and NiI$_{2}$ monolayers, with the conclusions readily applicable to\ntheir bulk forms."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20836",
    "c_title":[
      "Effect of substrate temperature on the deposition of Al-doped ZnO thin\n  films using high power impulse magnetron sputtering"
    ],
    "c_abstract":[
      "Al-doped ZnO thin films were deposited using reactive high power impulse\nmagnetron sputtering at substrate temperatures between room temperature and 600\n$\\bullet$ C. Two sample series with different oxygen partial pressures were\nstudied. The films with the lowest resistivity of 3 x 10 -4 $\\Omega$cm were\ndeposited at the highest substrate temperature of 600 $\\bullet$ C. The\nimprovement of the electrical properties could be related to an improvement of\nthe mobility due to the improved crystallinity. This improved crystallinity\nalso increased the stability of the films towards ambient moisture. On the\nother hand, the detrimental influence of negative oxygen bombardment could be\navoided, as the HiPIMS process can take place in the metal or transition mode\neven at relatively high oxygen partial pressures."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-102",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07295",
    "b_title":[
      "GestLLM: Advanced Hand Gesture Interpretation via Large Language Models\n  for Human-Robot Interaction"
    ],
    "b_abstract":[
      "This paper introduces GestLLM, an advanced system for human-robot interaction\nthat enables intuitive robot control through hand gestures. Unlike conventional\nsystems, which rely on a limited set of predefined gestures, GestLLM leverages\nlarge language models and feature extraction via MediaPipe to interpret a\ndiverse range of gestures. This integration addresses key limitations in\nexisting systems, such as restricted gesture flexibility and the inability to\nrecognize complex or unconventional gestures commonly used in human\ncommunication.\n  By combining state-of-the-art feature extraction and language model\ncapabilities, GestLLM achieves performance comparable to leading\nvision-language models while supporting gestures underrepresented in\ntraditional datasets. For example, this includes gestures from popular culture,\nsuch as the ``Vulcan salute\" from Star Trek, without any additional\npretraining, prompt engineering, etc. This flexibility enhances the naturalness\nand inclusivity of robot control, making interactions more intuitive and\nuser-friendly.\n  GestLLM provides a significant step forward in gesture-based interaction,\nenabling robots to understand and respond to a wide variety of hand gestures\neffectively. This paper outlines its design, implementation, and evaluation,\ndemonstrating its potential applications in advanced human-robot collaboration,\nassistive robotics, and interactive entertainment."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14855",
    "c_title":[
      "Sensorized gripper for human demonstrations"
    ],
    "c_abstract":[
      "Ease of programming is a key factor in making robots ubiquitous in\nunstructured environments. In this work, we present a sensorized gripper built\nwith off-the-shelf parts, used to record human demonstrations of a box in box\nassembly task. With very few trials of short interval timings each, we show\nthat a robot can repeat the task successfully. We adopt a Cartesian approach to\nrobot motion generation by computing the joint space solution while\nconcurrently solving for the optimal robot position, to maximise\nmanipulability. The statistics of the human demonstration are extracted using\nGaussian Mixture Models (GMM) and the robot is commanded using impedance\ncontrol."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-103",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14022",
    "b_title":[
      "Reliability Evaluation of Generalized $K_4$-Hypercubes Based on Five\n  Link Fault Patterns"
    ],
    "b_abstract":[
      "As the scale of data centers continues to grow, there is an increasing demand\nfor interconnection networks to resist malicious attacks. Hence, it is\nnecessary to evaluate the reliability of networks under various fault patterns.\nThe family of generalized $K_4$-hypercubes serve as interconnection networks of\ndata centers, characterized by topological structures with exceptional\nproperties. The $h$-extra edge-connectivity $\\lambda_h$, the $l$-super\nedge-connectivity $\\lambda^l$, the $l$-average degree edge-connectivity\n$\\overline{\\lambda^l}$, the $l$-embedded edge-connectivity $\\eta_l$ and the\ncyclic edge-connectivity $\\lambda_c$ are vital parameters to accurately assess\nthe reliability of interconnection networks. Let integer $n\\geq3$. This paper\nobtains the optimal solution of the edge isoperimetric problem and its explicit\nrepresentation, which offers an upper bound of the $h$-extra edge-connectivity\nof an $n$-dimensional $K_4$-hypercube $H_n^4$. As an application, we presents\n$\\lambda_h(H_n^4)$ for $1\\leq h\\leq 2^{\\lceil n\/2 \\rceil }$. Moreover, for\n$2^{\\lceil n\/2\\rceil+t}-g_t \\le h\\le2^{\\lceil n\/2\\rceil+t}$,\n$g_t=\\lceil(2^{2t+2+\\gamma})\/3\\rceil$,\n  $0\\leq t \\leq\\lfloor n\/2\\rfloor-1 $, $\\gamma=0$ for even $n$ and $\\gamma=1$\nfor odd $n$, $\\lambda_h(H_n^4)$ is a constant $(\\lfloor n\/2\\rfloor-t)2^{\\lceil\nn\/2\\rceil+t}$. The above lower and upper bounds of the integer $h$ are both\nsharp. Furthermore, $\\lambda^l(H_n^4)$, $\\overline{\\lambda^l}(H_n^4)$,\n$\\lambda_{2^l}(H_n^4)$, and $\\eta_l(H_n^4)$ share a common value $(n-l)2^l$ for\n$2\\leq l\\leq n-1$, and we determines the values of $\\lambda_c(H_n^4)$."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.19835",
    "c_title":[
      "Disjoint $X$-paths in bidirected graphs"
    ],
    "c_abstract":[
      "Let $B$ be a bidirected multigraph with signing $\\sigma$, let $X$ be a set of\nvertices in $B$, and let $k$ be a non-negative integer. For any pair of vertex\nsets $S,T\\subset V(B)$ satisfying $X\\cap S = X\\cap T$, we denote by $B_{S,T}$\nthe multigraph with the same vertex set as $B$ and with edge set consisting of\nthose edges $e$ of $B$ each of whose endvertices $v$ satisfies $v\\notin S\\cup\nT$ or $v\\in S\\setminus T$, $\\sigma(v,e)=-$ or $v\\in T\\setminus S$,\n$\\sigma(v,e)=+$. We prove that $B$ admits a set of $k$ pairwise disjoint\n$X$-paths if and only if for any $S,T\\subseteq V(B)$ with $X\\cap S = X\\cap T$,\nthe inequality $\\left\\lvert S\\cap T \\right\\rvert +\\sum \\lfloor \\tfrac{1}{2}\n\\left\\lvert V(C)\\cap (X\\cup S\\cup T) \\right\\rvert \\rfloor \\geq k$ holds where\nthe sum is indexed by the components of $B_{S,T}$. This result is a\ngeneralization of a result of Gallai from undirected graphs to bidirected ones.\nFurthermore, we will deduce from this a kind of an Erd\\H{o}s-P\\'osa property\nfor $X$-paths in bidirected multigraphs."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-104",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12034",
    "b_title":[
      "Application of Machine Learning Techniques for Secure Traffic in\n  NoC-based Manycores"
    ],
    "b_abstract":[
      "Like most computer systems, a manycore can also be the target of security\nattacks. It is essential to ensure the security of the NoC since all\ninformation travels through its channels, and any interference in the traffic\nof messages can reflect on the entire chip, causing communication problems.\nAmong the possible attacks on NoC, Denial of Service (DoS) attacks are the most\ncited in the literature. The state of the art shows a lack of work that can\ndetect such attacks through learning techniques. On the other hand, these\ntechniques are widely explored in computer network security via an Intrusion\nDetection System (IDS). In this context, the main goal of this document is to\npresent the progress of a work that explores an IDS technique using machine\nlearning and temporal series for detecting DoS attacks in NoC-based manycore\nsystems. To fulfill this goal, it is necessary to extract traffic data from a\nmanycore NoC and execute the learning techniques in the extracted data.\nHowever, while low-level platforms offer precision and slow execution,\nhigh-level platforms offer higher speed and data incompatible with reality.\nTherefore, a platform is being developed using the OVP tool, which has a higher\nlevel of abstraction. To solve the low precision problem, the developed\nplatform will have its data validated with a low-level platform."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17405",
    "c_title":[
      "When Everyday Devices Become Weapons: A Closer Look at the Pager and\n  Walkie-talkie Attacks"
    ],
    "c_abstract":[
      "Battery-powered technologies like pagers and walkie-talkies have long been\nintegral to civilian and military operations. However, the potential for such\neveryday devices to be weaponized has largely been underestimated in the realm\nof cybersecurity. In September 2024, Lebanon experienced a series of\nunprecedented, coordinated explosions triggered through compromised pagers and\nwalkie-talkies, creating a new category of attack in the domain of\ncyber-physical warfare. This attack not only disrupted critical communication\nnetworks but also resulted in injuries, loss of life, and exposed significant\nnational security vulnerabilities, prompting governments and organizations\nworldwide to reevaluate their cybersecurity frameworks. This article provides\nan in-depth investigation into the infamous Pager and Walkie-Talkie attacks,\nanalyzing both technical and non-technical dimensions. Furthermore, the study\nextends its scope to explore vulnerabilities in other battery-powered\ninfrastructures, such as battery management systems, highlighting their\npotential exploitation. Existing prevention and detection techniques are\nreviewed, with an emphasis on their limitations and the challenges they face in\naddressing emerging threats. Finally, the article discusses emerging\nmethodologies, particularly focusing on the role of physical inspection, as a\ncritical component of future security measures. This research aims to provide\nactionable insights to bolster the resilience of cyber-physical systems in an\nincreasingly interconnected world."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-105",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05324",
    "b_title":[
      "Atlas of AI Risks: Enhancing Public Understanding of AI Risks"
    ],
    "b_abstract":[
      "The prevailing methodologies for visualizing AI risks have focused on\ntechnical issues such as data biases and model inaccuracies, often overlooking\nbroader societal risks like job loss and surveillance. Moreover, these\nvisualizations are typically designed for tech-savvy individuals, neglecting\nthose with limited technical skills. To address these challenges, we propose\nthe Atlas of AI Risks-a narrative-style tool designed to map the broad risks\nassociated with various AI technologies in a way that is understandable to\nnon-technical individuals as well. To both develop and evaluate this tool, we\nconducted two crowdsourcing studies. The first, involving 40 participants,\nidentified the design requirements for visualizing AI risks for decision-making\nand guided the development of the Atlas. The second study, with 140\nparticipants reflecting the US population in terms of age, sex, and ethnicity,\nassessed the usability and aesthetics of the Atlas to ensure it met those\nrequirements. Using facial recognition technology as a case study, we found\nthat the Atlas is more user-friendly than a baseline visualization, with a more\nclassic and expressive aesthetic, and is more effective in presenting a\nbalanced assessment of the risks and benefits of facial recognition. Finally,\nwe discuss how our design choices make the Atlas adaptable for broader use,\nallowing it to generalize across the diverse range of technology applications\nrepresented in a database that reports various AI incidents."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13041",
    "c_title":[
      "Study Protocol: Shared Achievements: Exploring the Design of Gameful\n  Collaborative Elements and Fostering Social Relatedness through Team Effort\n  Contributions in a Social Physical Activity App"
    ],
    "c_abstract":[
      "This study protocol outlines the design and methodology of a research study\ninvestigating collaborative game elements to promote physical activity within\ndigital health interventions. The study aims to examine how social relatedness\ninfluences motivation and adherence to step-count goals. Participants will use\nShared Achievements, a minimalistic multiplayer step counter game, over two\nweeks, one week contributing absolute step counts and one week sharing step\ncounts as a relative percentage of a team goal. Data will be collected through\nusage metrics and participant feedback to evaluate engagement, motivation, and\nperceived challenges. Findings will inform the design of digital health tools\nthat balance competition and collaboration, optimising social and behavioural\nsupport mechanisms."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-106",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08311",
    "b_title":[
      "Inference in dynamic models for panel data using the moving block\n  bootstrap"
    ],
    "b_abstract":[
      "Inference in linear panel data models is complicated by the presence of fixed\neffects when (some of) the regressors are not strictly exogenous. Under\nasymptotics where the number of cross-sectional observations and time periods\ngrow at the same rate, the within-group estimator is consistent but its limit\ndistribution features a bias term. In this paper we show that a panel version\nof the moving block bootstrap, where blocks of adjacent cross-sections are\nresampled with replacement, replicates the limit distribution of the\nwithin-group estimator. Confidence ellipsoids and hypothesis tests based on the\nreverse-percentile bootstrap are thus asymptotically valid without the need to\ntake the presence of bias into account."
    ],
    "b_categories":[
      [
        "econ.EM"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2501.16711",
    "c_title":[
      "Bayesian Analyses of Structural Vector Autoregressions with Sign, Zero,\n  and Narrative Restrictions Using the R Package bsvarSIGNs"
    ],
    "c_abstract":[
      "The R package bsvarSIGNs implements state-of-the-art algorithms for the\nBayesian analysis of Structural Vector Autoregressions identified by sign,\nzero, and narrative restrictions. It offers fast and efficient estimation\nthanks to the deployment of frontier econometric and numerical techniques and\nalgorithms written in C++. The core model is based on a flexible Vector\nAutoregression with estimated hyper-parameters of the Minnesota prior and the\ndummy observation priors. The structural model can be identified by sign, zero,\nand narrative restrictions, including a novel solution, making it possible to\nuse the three types of restrictions at once. The package facilitates predictive\nand structural analyses using impulse responses, forecast error variance and\nhistorical decompositions, forecasting and conditional forecasting, as well as\nanalyses of structural shocks and fitted values. All this is complemented by\ncolourful plots, user-friendly summary functions, and comprehensive\ndocumentation. The package was granted the Di Cook Open-Source Statistical\nSoftware Award by the Statistical Society of Australia in 2024."
    ],
    "c_categories":[
      [
        "econ.EM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-107",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02934",
    "b_title":[
      "Train on classical, deploy on quantum: scaling generative quantum\n  machine learning to a thousand qubits"
    ],
    "b_abstract":[
      "We propose an approach to generative quantum machine learning that overcomes\nthe fundamental scaling issues of variational quantum circuits. The core idea\nis to use a class of generative models based on instantaneous quantum\npolynomial circuits, which we show can be trained efficiently on classical\nhardware. Although training is classically efficient, sampling from these\ncircuits is widely believed to be classically hard, and so computational\nadvantages are possible when sampling from the trained model on quantum\nhardware. By combining our approach with a data-dependent parameter\ninitialisation strategy, we do not encounter issues of barren plateaus and\nsuccessfully circumvent the poor scaling of gradient estimation that plagues\ntraditional approaches to quantum circuit optimisation. We investigate and\nevaluate our approach on a number of real and synthetic datasets, training\nmodels with up to one thousand qubits and hundreds of thousands of parameters.\nWe find that the quantum models can successfully learn from high dimensional\ndata, and perform surprisingly well compared to simple energy-based classical\ngenerative models trained with a similar amount of hyperparameter optimisation.\nOverall, our work demonstrates that a path to scalable quantum generative\nmachine learning exists and can be investigated today at large scales."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.14804",
    "c_title":[
      "Noise Mitigation in Single Microwave Photon Counting by Cascaded Quantum\n  Measurements"
    ],
    "c_abstract":[
      "While single-photon counting is routinely achieved in the optical domain,\noperational single microwave photon detectors (SMPDs) have only recently been\ndemonstrated. SMPDs are critical for sensing weak signals from incoherent\nemitters, with applications ranging from the detection of individual electron\nspins and dark-matter candidates to advancements in hybrid quantum devices and\nsuperconducting quantum computing. These detectors offer a substantial\nadvantage over quantum-limited amplification schemes by bypassing the standard\nquantum limit for power detection, therefore further reductions in their\nintrinsic noise are essential for advancing quantum sensing at microwave\nfrequencies. Several SMPD designs utilize the state of a superconducting qubit\nto encode the detection of an itinerant photon, and rely on a non-destructive\nphoton-qubit interaction. Here, we leverage this Quantum-Non-Demolition feature\nby repeatedly measuring the impinging photon with cascaded Four-Wave-Mixing\nprocesses and encoding the detection on several qubits. This cascaded detector\nmitigates the intrinsic local noise of individual qubits, achieving a\ntwo-order-of-magnitude reduction in intrinsic detector noise at the cost of\nhalving the efficiency. We report an intrinsic sensitivity of\n$8(1)\\times10^{-24}\\text{W}\/\\sqrt{\\text{Hz}}$, with an operational sensitivity\nof $5.9(6)\\times 10^{-23}\\text{W}\/\\sqrt{\\text{Hz}}$ limited by thermal photons\nin the input line."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-108",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06179",
    "b_title":[
      "Measuring Non-Gaussian Magic in Fermions: Convolution, Entropy, and the\n  Violation of Wick's Theorem and the Matchgate Identity"
    ],
    "b_abstract":[
      "Classically hard to simulate quantum states, or \"magic states\", are\nprerequisites to quantum advantage, highlighting an apparent separation between\nclassically and quantumly tractable problems. Classically simulable states such\nas Clifford circuits on stabilizer states, free bosonic states, free fermions,\nand matchgate circuits are all in some sense Gaussian. While free bosons and\nfermions arise from quadratic Hamiltonians, recent works have demonstrated that\nbosonic and qudit systems converge to Gaussians and stabilizers under\nconvolution. In this work, we similarly identify convolution for fermions and\nfind efficient measures of non-Gaussian magic in pure fermionic states. We\ndemonstrate that three natural notions for the Gaussification of a state, (1)\nthe Gaussian state with the same covariance matrix, (2) the fixed point of\nconvolution, and (3) the closest Gaussian in relative entropy, coincide by\nproving a central limit theorem for fermionic systems. We then utilize the\nviolation of Wick's theorem and the matchgate identity to quantify non-Gaussian\nmagic in addition to a SWAP test."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05103",
    "c_title":[
      "Predicting Spin-Dependent Coulomb Interaction Based on the Yang-Mills\n  Equations"
    ],
    "c_abstract":[
      "The standard Coulomb interaction is one of four fundamental interactions in\nNature. It is interesting to know how will the standard Coulomb interaction be\nmodified when it meets spin. Since the standard Coulomb potential is a simple\nbut fundamental solution of Maxwell's equations, hence Maxwell's equations can\npredict the existence of the standard Coulomb potential. The Yang-Mills\nequations are the natural generalizations of Maxwell's equations from the\nAbelian potentials to the non-Abelian ones, thus based on the Yang-Mills\nequations, one can predict the reasonable form of spin-dependent Coulomb\npotential, which naturally reduces the standard Coulomb potential if without\nconsidering the spin. Our work sheds a new light to how to couple spin with\nfundamental interactions."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-109",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04640",
    "b_title":[
      "Coil geometry with large openings for a HSR3-like stellarator reactor\n  for fast replacement of in-vessel components"
    ],
    "b_abstract":[
      "Advanced stellarators require convoluted modular coils to produce a plasma\nwith satisfactory performance. Moreover, the number of coils is sometimes high\nto decrease the modular ripple created by the coils. For reactor stellarators,\nthese requirements imply relatively small ports for in-vessel access and\nmaintenance, i.e. in comparison with tokamaks. The blankets and divertor\nmodules will have to be replaced periodically (about each 1-4 years depending\non the design) due to neutron damage, and also erosion of divertor targets.\nBlanket modules are activated, thus, all the maintenance operations have to be\nproduced remotely. In order to reduce the shutdown time and cost during\ncomponent replacement, and to reduce the number, speed and other specifications\nof the remote maintenance equipment, the number of blanket modules in the\nreactor should be low and thus, the blanket modules should be large (in\nrelation to the minor and major radius). Nevertheless, the size of the openings\nbetween coils limits the maximum size of the blanket and divertor modules,\nthough several potential enhancements have been proposed in the past for\nstellarators, like straightening the outboard segments of the coils and the\nmovement and\/or expansion of certain coils to have wider access. The present\nwork reports on a coil geometry for the 'Helias Stellarator Reactor' (HSR) of\nthree periods (HSR3) with coils located far from the plasma at the outboard\nregion of the straight-like sector. This feature creates natural wide openings\nat such regions of the coils, which may be utilized to allow access to large\nblanket and divertor modules."
    ],
    "b_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.18399",
    "c_title":[
      "T3ST code: Turbulent Transport in Tokamaks via Stochastic Trajectories"
    ],
    "c_abstract":[
      "We introduce the Turbulent Transport in Tokamaks via Stochastic Trajectories\n(T3ST) code, designed to address the problem of turbulent transport using a\nstatistical approach complementary to gyrokinetics. The code employs\ntest-particle methods to track the dynamics of charged particles in\naxisymmetric magnetic equilibria, accounting for both turbulence and Coulomb\ncollisions. The turbulence is decoupled from plasma dynamics and represented\nthrough a statistical ensemble of synthetic random fields with specified\nspectral properties. This approach enables T3ST to compute transport\ncoefficients as Lagrangian correlations - orders of magnitude faster than\ngyrokinetic codes."
    ],
    "c_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-110",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08915",
    "b_title":[
      "The case for a low dark matter density in dynamical dark energy model\n  from local probes"
    ],
    "b_abstract":[
      "In this work we investigate, through a Bayesian study, the ability of a local\nlow matter density $\\Omega_{\\rm M}$, in discrepancy with the value usually\ninferred from the CMB angular power spectrum, to accommodate observations from\nlocal probes without being in tension with the local values of the Hubble\nconstant $H_0$ or the matter fluctuation $\\sigma_8$ parameters. For that, we\ncombine multiple local probes, with the criteria that they either can constrain\nthe matter density parameter independently from the CMB constraints, or can\nhelp in doing so after making their relevant observations more model\nindependent by relaxing their relevant calibration parameters. We assume\nhowever, either a dynamical dark energy model, or the standard $\\Lambda$CDM\nmodel, when computing the corresponding theoretical observables. We also add,\nin almost all of our Monte Carlo runs, the latest Baryonic acoustic\noscillations (BAO) measurements from the DESI year one release to our core\ngroup. We found that, within $\\Lambda$CDM model, for different combinations of\nour probes, we can accommodate a low matter density along with the $H_0$ and\n$\\sigma_8$ values usually obtained from local probes, providing we promote the\nsound drag $r_s$ component in BAO calculations to a free parameter, and that\neven if we combine with the Pantheon+ Supernova sample. Assuming $w_0w_a$CDM,\nwe also found that relaxing $r_s$ allow us to accommodate $\\Omega_{\\rm M}$,\n$H_0$ and $\\sigma_8$ within their local values, with still however a preference\nfor $w_0w_a$ values far from $\\Lambda$CDM. However, when including Pantheon+\nSupernova sample, we found that the latter preference for high matter density\npushes $\\sigma_8$ to much smaller values, mitigating by then a low matter\ndensity solution to the two common tensions. We conclude that a low matter\ndensity value, helps in preserving the concordance within $\\Lambda$CDM model.\n(abridged)"
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.14742",
    "c_title":[
      "Validation of the DESI DR2 Measurements of Baryon Acoustic Oscillations\n  from Galaxies and Quasars"
    ],
    "c_abstract":[
      "The Dark Energy Spectroscopic Instrument (DESI) data release 2 (DR2) galaxy\nand quasar clustering data represents a significant expansion of data from DR1,\nproviding improved statistical precision in BAO constraints across multiple\ntracers, including bright galaxies (BGS), luminous red galaxies (LRGs),\nemission line galaxies (ELGs), and quasars (QSOs). In this paper, we validate\nthe BAO analysis of DR2. We present the results of robustness tests on the\nblinded DR2 data and, after unblinding, consistency checks on the unblinded DR2\ndata. All results are compared to those obtained from a suite of mock catalogs\nthat replicate the selection and clustering properties of the DR2 sample. We\nconfirm the consistency of DR2 BAO measurements with DR1 while achieving a\nreduction in statistical uncertainties due to the increased survey volume and\ncompleteness. We assess the impact of analysis choices, including different\ndata vectors (correlation function vs. power spectrum), modeling approaches and\nsystematics treatments, and an assumption of the Gaussian likelihood, finding\nthat our BAO constraints are stable across these variations and assumptions\nwith a few minor refinements to the baseline setup of the DR1 BAO analysis. We\nsummarize a series of pre-unblinding tests that confirmed the readiness of our\nanalysis pipeline, the final systematic errors, and the DR2 BAO analysis\nbaseline. The successful completion of these tests led to the unblinding of the\nDR2 BAO measurements, ultimately leading to the DESI DR2 cosmological analysis,\nwith their implications for the expansion history of the Universe and the\nnature of dark energy presented in the DESI key paper."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-111",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12953",
    "b_title":[
      "Frame-wise Conditioning Adaptation for Fine-Tuning Diffusion Models in\n  Text-to-Video Prediction"
    ],
    "b_abstract":[
      "Text-video prediction (TVP) is a downstream video generation task that\nrequires a model to produce subsequent video frames given a series of initial\nvideo frames and text describing the required motion. In practice TVP methods\nfocus on a particular category of videos depicting manipulations of objects\ncarried out by human beings or robot arms. Previous methods adapt models\npre-trained on text-to-image tasks, and thus tend to generate video that lacks\nthe required continuity. A natural progression would be to leverage more recent\npre-trained text-to-video (T2V) models. This approach is rendered more\nchallenging by the fact that the most common fine-tuning technique, low-rank\nadaptation (LoRA), yields undesirable results. In this work, we propose an\nadaptation-based strategy we label Frame-wise Conditioning Adaptation (FCA).\nWithin the module, we devise a sub-module that produces frame-wise text\nembeddings from the input text, which acts as an additional text condition to\naid generation. We use FCA to fine-tune the T2V model, which incorporates the\ninitial frame(s) as an extra condition. We compare and discuss the more\neffective strategy for injecting such embeddings into the T2V model. We conduct\nextensive ablation studies on our design choices with quantitative and\nqualitative performance analysis. Our approach establishes a new\nstate-of-the-art for the task of TVP. The project page is at\nhttps:\/\/github.com\/Cuberick-Orion\/FCA ."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08933",
    "c_title":[
      "PromptGAR: Flexible Promptive Group Activity Recognition"
    ],
    "c_abstract":[
      "We present PromptGAR, a novel framework that addresses the limitations of\ncurrent Group Activity Recognition (GAR) approaches by leveraging multi-modal\nprompts to achieve both input flexibility and high recognition accuracy. The\nexisting approaches suffer from limited real-world applicability due to their\nreliance on full prompt annotations, the lack of long-term actor consistency,\nand under-exploration of multi-group scenarios. To bridge the gap, we proposed\nPromptGAR, which is the first GAR model to provide input flexibility across\nprompts, frames, and instances without the need for retraining. Specifically,\nwe unify bounding boxes, skeletal keypoints, and areas as point prompts and\nemploy a recognition decoder for cross-updating class and prompt tokens. To\nensure long-term consistency for extended activity durations, we also introduce\na relative instance attention mechanism that directly encodes instance IDs.\nFinally, PromptGAR explores the use of area prompts to enable the selective\nrecognition of the particular group activity within videos that contain\nmultiple concurrent groups. Comprehensive evaluations demonstrate that\nPromptGAR achieves competitive performances both on full prompts and diverse\nprompt inputs, establishing its effectiveness on input flexibility and\ngeneralization ability for real-world applications."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-112",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10280",
    "b_title":[
      "Evidence for the gravity-driven and magnetically-regularized gas flows\n  feeding the massive protostellar cluster in Cep A"
    ],
    "b_abstract":[
      "The hierarchical interplay among gravity, magnetic fields, and turbulent gas\nflows in delivering the necessary material to form massive protostellar\nclusters remains enigmatic. We have performed high-resolution (beam size\n$\\sim$14 arcsec $\\simeq$ 0.05 pc at a distance 725 pc) 850 $\\mu$m dust\npolarization and C$^{18}$O molecular line observations of Cepheus A (Cep A),\nthe second closest massive star-forming region, using the 15-meter James Clerk\nMaxwell Telescope (JCMT) along with the SCUBA-2\/POL-2 and HARP instruments. Our\nkey analyses reveal that (i) morphologically, all three fields--gravitational\n(G), magnetic (B), and kinetic (K) fields--are aligned with each other, and\n(ii) energetically, they exhibit a hierarchical relationship with gravitational\n($E_{\\mathrm{G}}$) > magnetic ($E_{\\mathrm{B}}$) > kinetic ($E_{\\mathrm{K}}$).\nGravity dominates in Cep A clump and, as a primary active player, dictates the\nother two agents. Consequently, gravity plays two active roles: (i) induces gas\nflows and (ii) drags B-field lines toward the gravitational trough. Since\nmagnetic energy dominates kinetic energy, $E_{\\mathrm{B}}$ > $E_{\\mathrm{K}}$,\nthe \"dragged-in\" B-field as a secondary active player can mitigate turbulence\nand instabilities, thereby regularizing gas flows into a more ordered\nconfiguration. At the $\\sim$0.60 pc clump scale, these flows deliver material\nat a substantially high rate of $\\sim$ 2.1$\\times$10$^{-4}$ M$_{\\odot}$\nyr$^{-1}$ toward the cluster center. Our study, for the first time, presents\nnew insights into how B-fields and turbulent gas flows passively assist the\nactive role of gravity in the formation of a protostellar cluster, contrasting\nwith the standard notion that these agents primarily oppose gravitational\ncollapse."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20433",
    "c_title":[
      "Aeos: The Impact of Pop III Initial Mass Function and Star-by-Star\n  Models in Galaxy Simulations"
    ],
    "c_abstract":[
      "We explore the effect of variations in the Population III (Pop III) initial\nmass function (IMF) and star-by-star feedback on early galaxy formation and\nevolution using the Aeos simulations. We compare simulations with two different\nPop III IMFs: $M_\\text{char} = 10 \\, \\mathrm{M}_\\odot$ and $M_{\\rm max} = 100\n\\, \\mathrm{M}_\\odot$ (Aeos10) and $M_\\text{char} = 20 \\, \\mathrm{M}_\\odot$ and\n$M_{\\rm max} = 300 \\, \\mathrm{M}_\\odot$ (Aeos20). Aeos20 produces significantly\nmore ionizing photons, ionizing 30% of the simulation volume by $z \\approx 14$,\ncompared to 9% in Aeos10. This enhanced ionization suppresses galaxy formation\non the smallest scales. Differences in Pop III IMF also affect chemical\nenrichment. Aeos20 produces Population II (Pop II) stars with higher\nabundances, relative to iron, of light and $\\alpha$-elements, a stronger\nodd-even effect, and a higher frequency of carbon-enhanced metal-poor stars.\nThe abundance scatter between different Pop II galaxies dominates the\ndifferences due to Pop III IMF, though, implying a need for a larger sample of\nPop II stars to interpret the impact of Pop III IMF on early chemical\nevolution. We also compare the Aeos simulations to traditional simulations that\nuse single stellar population particles. We find that star-by-star modeling\nproduces a steeper mass-metallicity relation due to less bursty feedback. These\nresults highlight the strong influence of the Pop III IMF on early galaxy\nformation and chemical evolution, emphasizing the need to account for IMF\nuncertainties in simulations and the importance of metal-poor Pop II stellar\nchemical abundances when studying the first stars."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-113",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07798",
    "b_title":[
      "Risk and Protective Factors in Parkinsons Disease"
    ],
    "b_abstract":[
      "Understanding the risk and protective factors associated with Parkinsons\ndisease (PD) is crucial for improving outcomes for patients, individuals at\nrisk, healthcare providers, and healthcare systems. Studying these factors not\nonly enhances our knowledge of the disease but also aids in developing\neffective prevention, management, and treatment strategies. This paper reviews\nthe key risk and protective factors associated with PD, with a particular focus\non the biological mechanisms underlying these factors. Risk factors include\ngenetic mutations, racial predispositions, and environmental exposures, all of\nwhich contribute to an increased likelihood of developing PD or accelerating\ndisease progression. Conversely, protective factors such as regular physical\nexercise, adherence to a Mediterranean diet, and higher urate levels have\ndemonstrated potential to reduce inflammation and support mitochondrial\nfunction, thereby mitigating disease risk. However, identifying and validating\nthese factors presents significant challenges. To overcome challenges, we\npropose several solutions and recommendations. Future research should\nprioritize the development of standardized biomarkers for early diagnosis,\ninvestigate gene-environment interactions in greater depth, and refine animal\nmodels to better mimic human PD pathology. Additionally, we offer actionable\nrecommendations for PD prevention and management, tailored to healthy\nindividuals, patients diagnosed with PD, and healthcare systems. These\nstrategies aim to improve clinical outcomes, enhance quality of life, and\noptimize healthcare delivery for PD."
    ],
    "b_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2502.17287",
    "c_title":[
      "Automated generation of epilepsy surgery resection masks; The RAMPS\n  pipeline"
    ],
    "c_abstract":[
      "MRI-based delineation of brain tissue removed by epilepsy surgery can be\nchallenging due to post-operative brain shift. In consequence, most studies use\nmanual approaches which are prohibitively time-consuming for large sample\nsizes, require expertise, and can be prone to errors.\n  We propose RAMPS (Resections And Masks in Preoperative Space), an automated\npipeline to generate a 3D resection mask of pre-operative tissue. Our pipeline\nleverages existing software including FreeSurfer, SynthStrip, Sythnseg and ANTS\nto generate a mask in the same space as the patient's pre-operative T1 weighted\nMRI. We compare our automated masks against manually drawn masks and two other\nexisting pipelines (Epic-CHOP and ResectVol).\n  Comparing to manual masks (N=87), RAMPS achieved a median(IQR) dice\nsimilarity of 0.86(0.078) in temporal lobe resections, and 0.72(0.32) in\nextratemporal resections. In comparison to other pipelines, RAMPS had higher\ndice similarities (N=62) (RAMPS:0.86, Epic-CHOP: 0.72, ResectVol: 0.72).\n  We release a user-friendly, easy to use pipeline, RAMPS, open source for\naccurate delineation of resected tissue."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-114",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08262",
    "b_title":[
      "Addressing the sustainable AI trilemma: a case study on LLM agents and\n  RAG"
    ],
    "b_abstract":[
      "Large language models (LLMs) have demonstrated significant capabilities, but\ntheir widespread deployment and more advanced applications raise critical\nsustainability challenges, particularly in inference energy consumption. We\npropose the concept of the Sustainable AI Trilemma, highlighting the tensions\nbetween AI capability, digital equity, and environmental sustainability.\nThrough a systematic case study of LLM agents and retrieval-augmented\ngeneration (RAG), we analyze the energy costs embedded in memory module designs\nand introduce novel metrics to quantify the trade-offs between energy\nconsumption and system performance. Our experimental results reveal significant\nenergy inefficiencies in current memory-augmented frameworks and demonstrate\nthat resource-constrained environments face disproportionate efficiency\npenalties. Our findings challenge the prevailing LLM-centric paradigm in agent\ndesign and provide practical insights for developing more sustainable AI\nsystems."
    ],
    "b_categories":[
      [
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00012",
    "c_title":[
      "Lessons from complexity theory for AI governance"
    ],
    "c_abstract":[
      "The study of complex adaptive systems, pioneered in physics, biology, and the\nsocial sciences, offers important lessons for AI governance. Contemporary AI\nsystems and the environments in which they operate exhibit many of the\nproperties characteristic of complex systems, including nonlinear growth\npatterns, emergent phenomena, and cascading effects that can lead to tail\nrisks. Complexity theory can help illuminate the features of AI that pose\ncentral challenges for policymakers, such as feedback loops induced by training\nAI models on synthetic data and the interconnectedness between AI systems and\ncritical infrastructure. Drawing on insights from other domains shaped by\ncomplex systems, including public health and climate change, we examine how\nefforts to govern AI are marked by deep uncertainty. To contend with this\nchallenge, we propose a set of complexity-compatible principles concerning the\ntiming and structure of AI governance, and the risk thresholds that should\ntrigger regulatory intervention."
    ],
    "c_categories":[
      [
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-115",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06908",
    "b_title":[
      "An estimate for positive definite functions on finite abelian groups and\n  its applications"
    ],
    "b_abstract":[
      "This paper concentrates on positive definite functions on finite abelian\ngroups, which are central to harmonic analysis and related fields. By\nleveraging the group structure and employing Fourier analysis, we establish a\nlower bound for the second largest value of positive definite functions. For\nillustrative purposes, we present three applications of our lower bound: (a) We\nobtain both lower and upper bounds for arbitrary functions on finite abelian\ngroups; (b) We derive lower bounds for the relaxation and mixing times of\nrandom walks on finite abelian groups. Notably, our bound for the relaxation\ntime achieves a quadratic improvement over the previously known one; (c) We\ndetermine a new lower bound for the size of the sumset of two subsets of finite\nabelian groups."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.05097",
    "c_title":[
      "Surjective isometries on function spaces with derivatives"
    ],
    "c_abstract":[
      "Let $A$ be a complex Banach space with a norm $\\|f\\|=\\|f\\|_X+\\|d(f)\\|_Y$ for\n$f\\in A$, where $d$ is a complex linear map from $A$ onto a Banach space $B$,\nand $\\|\\cdot\\|_K$ represents the supremum norm on a compact Hausdorff space\n$K$. In this paper, we characterize surjective isometries on $(A,\\|\\cdot\\|)$,\nwhich may be nonlinear. This unifies former results on surjective isometries\nbetween specific function spaces."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-116",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05875",
    "b_title":[
      "Extended weak order for the affine symmetric group"
    ],
    "b_abstract":[
      "The extended weak order on a Coxeter group $W$ is the poset of biclosed sets\nin its root system. In (Barkley-Speyer 2024), it was shown that when\n$W=\\widetilde{S}_n$ is the affine symmetric group, then the extended weak order\nis a quotient of the lattice $L_n$ of translation-invariant total orderings of\nthe integers. In this article, we give a combinatorial introduction to $L_n$\nand the extended weak order on $\\widetilde{S}_n$. We show that $L_n$ is an\nalgebraic completely semidistributive lattice. We describe its canonical join\nrepresentations using a cyclic version of Reading's non-crossing arc diagrams.\nWe also show analogous statements for the lattice of all total orders of the\nintegers, which is the extended weak order on the symmetric group $S_\\infty$. A\nkey property of both of these lattices is that they are profinite; we also\nprove that a profinite lattice is join semidistributive if and only if its\ncompact elements have canonical join representations. We conjecture that the\nextended weak order of any Coxeter group is a profinite semidistributive\nlattice."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.11991",
    "c_title":[
      "Further results on staircase (cyclic) words"
    ],
    "c_abstract":[
      "We find the two-variables generating function for the statistic which counts\nthe number of variations in a word bounded by $1$. Thus, we refine and extend\nprevious results concerning staircase words, which are words in which the\nvariation between all consecutive letters is bounded by $1$. We obtain the\nanalogue results for cyclic words."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-117",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19713",
    "b_title":[
      "Unlocking Hidden Information in Sparse Small-Angle Neutron Scattering\n  Measurement"
    ],
    "b_abstract":[
      "Small-angle neutron scattering (SANS) is a powerful technique for probing the\nnanoscale structure of materials. However, the fundamental limitations of\nneutron flux pose significant challenges for rapid, high-fidelity data\nacquisition required in many experiments. To circumvent this difficulty, we\nintroduce a Bayesian statistical framework based on Gaussian process regression\n(GPR) to infer high-quality SANS intensity profiles from measurements with\nsuboptimal signal-to-noise ratios (SNR). Unlike machine learning approaches\nthat depend on extensive training datasets, the proposed one-shot method\nleverages the intrinsic mathematical properties of the scattering function,\nsmoothness and continuity, offering a generalizable solution beyond the\nconstraints of data-intensive techniques. By examining existing SANS\nexperimental data, we demonstrate that this approach can reduce measurement\ntime by between one and two orders of magnitude while maintaining accuracy and\nadaptability across different SANS instruments. By improving both efficiency\nand reliability, this method extends the capabilities of SANS, enabling broader\napplications in time-sensitive and low-flux experimental conditions."
    ],
    "b_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.13388",
    "c_title":[
      "Probe position determination with multichannel I-V measurements in a\n  two-dimensional sheet$\\colon$ Computational method and mathematical analysis"
    ],
    "c_abstract":[
      "Atomically thin films and surfaces exhibit many distinctive two-dimensional\nelectronic properties that are absent in bulk crystals. In situ microscale\nmulti-probe measurements have been utilized as an effective method to identify\nthe electrical conductivity of such thin films and surfaces. Precise\ndetermination of multi-probe positions is crucial for accurate characterization\nof the conductance. However, traditional methods that use microscopes for\ndetermining multi-probe positions often impose significant constraints on\nexperimental setups. In some cases, installing a microscope is not even\nfeasible. Therefore, in this study, we propose a novel method to determine\nprobe positions using electrical signals from the probes. This method enables\nprecise determination of probe positions using a reference sheet and reference\nprobes, even at low or high temperatures and under ultra-high vacuum or\nhigh-pressure conditions. The proposed method simplifies the integration of\nmicroscale multi-probe measurement systems into various devices, thereby\nadvancing research on thin films and surfaces."
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-118",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12101",
    "b_title":[
      "Existence and regularity in the fully nonlinear one-phase free boundary\n  problem"
    ],
    "b_abstract":[
      "We consider viscosity solution to one-phase free boundary problems for\ngeneral fully nonlinear operators and free boundary condition depending on the\nnormal vector. We show existence of viscosity solutions via the Perron's method\nand we prove $C^{2,\\alpha}$ regularity of flat free boundaries via a quadratic\nimprovement of flatness. Finally, we obtain the higher regularity of the free\nboundary via an hodograph transform."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.07003",
    "c_title":[
      "Nishida-Smoller type large solutions and exponential growth for the\n  compressible Navier-Stokes equations with slip boundary conditions in 3D\n  bounded domain"
    ],
    "c_abstract":[
      "This paper concerns the isentropic compressible Navier-Stokes equations in a\nthree-dimensional (3D) bounded domain with slip boundary conditions and vacuum.\nIt is shown that the classical solutions to the initial-boundary-value problem\nof this system with large initial energy and vacuum exist globally in time and\nhave an exponential decay rate which is decreasing with respect to the\nadiabatic exponent $\\gamma>1$ provided that the fluid is nearly isothermal\n(namely, the adiabatic exponent is close enough to 1). This constitutes an\nextension of the celebrated result for the one-dimensional Cauchy problem of\nthe isentropic Euler equations that has been established in 1973 by Nishida and\nSmoller (Comm. Pure Appl. Math. 26 (1973), 183-200). In addition, it is also\nshown that the gradient of the density will grow unboundedly with an\nexponential rate when the initial vacuum appears (even at a point). In contrast\nto previous related works, where either small initial energy are required or\nboundary effects are ignored, this establishes the first result on the global\nexistence and exponential growth of large-energy solutions with vacuum to the\n3D isentropic compressible Navier-Stokes equations with slip boundary\nconditions."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-119",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01778",
    "b_title":[
      "An Accessible Formulation for Defining the SI Second Based on Multiple\n  Atomic Transitions"
    ],
    "b_abstract":[
      "This work presents a novel formulation for a redefinition of the second based\non the weighted arithmetic mean of multiple normalized frequencies. We\ndemonstrate that it is mathematically equivalent to the previously discussed\nimplementation employing a geometric mean. In our reformulation, the\nnormalization of frequencies provides the defining constants with immediate\nphysical meaning, while maintaining the decoupling of assigned weights from the\nfrequencies of the reference transitions. We believe that a definition based on\nthis formulation would be significantly more accessible to both experts and\nnon-specialists, enhancing understanding and facilitating broader acceptance.\nWe hope that this approach will help overcome barriers to the adoption of a\nredefinition that effectively values all state-of-the-art atomic clocks."
    ],
    "b_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.18266",
    "c_title":[
      "Doppler-free spectroscopy of the Cs $6\\text{S}_{1\/2}-7\\text{P}_{3\/2}$\n  atomic transition at 456 nm in a nanometric-thick vapor layer"
    ],
    "c_abstract":[
      "The features of Doppler-free resonances detected by probing the $^{133}$Cs\natom $6S_{1\/2}-7P_{3\/2}$ transition at 456 nm in a nanometric-thick vapor layer\nare investigated. The matrix element of this transition is about 11 times\nsmaller than that of the Cs D$_2$ line (852 nm). When the vapor layer thickness\nis $\\ell = \\lambda\/2 \\simeq 230$ nm, we observe Dicke narrowing of the lines,\naccompanied by a red frequency shift of the atomic transitions, which is\nattributed to atom-surface interactions. Realizing optical pumping with\n$\\ell\\simeq 460$ nm in a single-pass configuration, we observe Doppler-free\nresonances with a linewidth $<20$ MHz, located at the atomic transitions\nfrequencies with a correspondence of the amplitudes to the transition\nintensities. These narrow resonances are of interest for high-resolution\nspectroscopy and instrumentation, and could serve as a frequency reference."
    ],
    "c_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-120",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01823",
    "b_title":[
      "Persistent fermionic entanglement under decoherence"
    ],
    "b_abstract":[
      "We consider a system of two indistinguishable fermions (with four accessible\nstates each) that suffers decoherence without dissipation due to its coupling\nwith a global bosonic bath at a fixed temperature. Using an appropriate measure\nof fermionic entanglement, we identify families of two-fermion states whose\nentanglement persists throughout the evolution, either fully or partially,\ndespite the noisy effects of the interaction with the bath, and independently\nof its temperature. The identified resilience to decoherence provides valuable\ninsights into the entanglement dynamics of open systems of indistinguishable\nfermions, and into the conditions under which long-lived entanglement emerges\nunder more general decoherence channels."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.06367",
    "c_title":[
      "Observing the exponential growth of the eigenmodes in the absence of\n  coalescence for a non-Hermitian circuit with an unavoidable inductor\n  dissipation"
    ],
    "c_abstract":[
      "We investigate, both experimentally and theoretically, the eigenmodes of an\nelectronic circuit in which gain and loss $RLC$ resonators are coupled through\na capacitor. Due to the unavoidable magnetic loss in the inductors, we find\nthat the eigenmode coalescence no longer emerges in contrast to the\nconventional non-Hermitian systems with the spontaneous $\\cal{PT}$-symmetry\nbreaking. In particular, we find a transition from the exponential decay to\nexponential growth in the amplitude of the periodic voltage oscillations of the\nresonators. The transition occurs near the exceptional points of the\nnon-Hermitian circuit without considering the dissipations in inductors. We\nintroduce a small resistor of three orders of magnitude smaller than that of\nthe $RLC$ resonators to mimic the energy dissipation in inductors and\nnumerically solve the equivalent non-Hermitian Schr{\\\" o}dinger equation. The\nnumerical results can well reproduce experimental observations. Our above\nfindings unambiguously indicate that the exponential growth behavior beyond the\nexceptional points is robust against some unavoidable dissipative\nperturbations."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-121",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11053",
    "b_title":[
      "Pricing American Parisian Options under General Time-Inhomogeneous\n  Markov Models"
    ],
    "b_abstract":[
      "This paper develops general approaches for pricing various types of\nAmerican-style Parisian options (down-in\/-out, perpetual\/finite-maturity) with\ngeneral payoff functions based on continuous-time Markov chain (CTMC)\napproximation under general 1D time-inhomogeneous Markov models. For the\ndown-in types, by conditioning on the Parisian stopping time, we reduce the\npricing problem to that of a series of vanilla American options with different\nmaturities and their prices integrated with the distribution function of the\nParisian stopping time yield the American Parisian down-in option price. This\nfacilitates an efficient application of CTMC approximation to obtain the\napproximate option price by calculating the required quantities. For the\nperpetual down-in cases under time-homogeneous models, significant\ncomputational cost can be reduced. The down-out cases are more complicated, for\nwhich we use the state augmentation approach to record the excursion duration\nand then the approximate option price is obtained by solving a series of\nvariational inequalities recursively with the Lemke's pivoting method. We show\nthe convergence of CTMC approximation for all the types of American Parisian\noptions under general time-inhomogeneous Markov models, and the accuracy and\nefficiency of our algorithms are confirmed with extensive numerical\nexperiments."
    ],
    "b_categories":[
      [
        "q-fin.CP"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2502.14766",
    "c_title":[
      "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and\n  Convergence Analysis"
    ],
    "c_abstract":[
      "We propose a structural default model for portfolio-wide valuation\nadjustments (xVAs) and represent it as a system of coupled backward stochastic\ndifferential equations. The framework is divided into four layers, each\ncapturing a key component: (i) clean values, (ii) initial margin and Collateral\nValuation Adjustment (ColVA), (iii) Credit\/Debit Valuation Adjustments\n(CVA\/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding\nValuation Adjustment (FVA). Because these layers depend on one another through\ncollateral and default effects, a naive Monte Carlo approach would require\ndeeply nested simulations, making the problem computationally intractable.\n  To address this challenge, we use an iterative deep BSDE approach, handling\neach layer sequentially so that earlier outputs serve as inputs to the\nsubsequent layers. Initial margin is computed via deep quantile regression to\nreflect margin requirements over the Margin Period of Risk. We also adopt a\nchange-of-measure method that highlights rare but significant defaults of the\nbank or counterparty, ensuring that these events are accurately captured in the\ntraining process.\n  We further extend Han and Long's (2020) a posteriori error analysis to BSDEs\non bounded domains. Due to the random exit from the domain, we obtain an order\nof convergence of $\\mathcal{O}(h^{1\/4-\\epsilon})$ rather than the usual\n$\\mathcal{O}(h^{1\/2})$.\n  Numerical experiments illustrate that this method drastically reduces\ncomputational demands and successfully scales to high-dimensional,\nnon-symmetric portfolios. The results confirm its effectiveness and accuracy,\noffering a practical alternative to nested Monte Carlo simulations in\nmulti-counterparty xVA analyses."
    ],
    "c_categories":[
      [
        "q-fin.CP"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-122",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15647",
    "b_title":[
      "Computing homology of $\\mathbb{Z}_k$-complexes from their quotients"
    ],
    "b_abstract":[
      "In this paper, we investigate the question of how one can recover the\nhomology of a simplicial complex $X$ equipped with a regular action of a finite\ngroup $G$ from the structure of its quotient space $X\/G.$ Specifically, we\ndescribe a process for enriching the structure of the chain complex\n$C_\\ast(X\/G; \\mathbb{F})$ using the data of a complex of groups, a framework\ndeveloped by Bridson and Corsen for encoding the local structure of a group\naction. We interpret this data through the lens of matrix representations of\nthe acting group, and combine this structure with the standard simplicial\nboundary matrices for $X\/G$ to construct a surrogate chain complex. In the case\n$G = \\mathbb{Z}_k,$ the group ring $\\mathbb{F}G$ is commutative and matrices\nover $\\mathbb{F}G$ admit a Smith normal form, allowing us to recover the\nhomology of $G$ from this surrogate complex. This algebraic approach\ncomplements the geometric compression algorithm for equivariant simplicial\ncomplexes described by Carbone, Nanda, and Naqvi."
    ],
    "b_categories":[
      [
        "math.AT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11119",
    "c_title":[
      "On an article published in the racsam"
    ],
    "c_abstract":[
      "In this Note, we provide the comments on the paper [A note on the hit problem\nfor the polynomial algebra in the case of odd primes and its application] which\nwas published in the RACSAM [Rev. Real. Acad. Cienc. Exactas. Fis. Nat. Ser.\nA-Mat. 118, 22 (2024)]. We will show that some of the results in this paper are\nnot new and others are false."
    ],
    "c_categories":[
      [
        "math.AT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-123",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03355",
    "b_title":[
      "Testing general covariance in effective models motivated by Loop Quantum\n  Gravity"
    ],
    "b_abstract":[
      "In this work we introduce a criterion for testing general covariance in\neffective quantum gravity theories. It adapts the criterion based on general\nspacetime diffeomorphisms of the Einstein-Hilbert action to the case of\neffective canonical models. While the main purpose is to test models obtained\nin Loop Quantum Gravity, the criterion is not limited to those physical systems\nand may be applied to any canonically formulated modified theory of gravity.\nThe approach here is hence not that of finding an effective model, but rather\nto analyze a given one represented by a quantum corrected Hamiltonian.\nSpecifically, we will apply the criterion to spherically symmetric spacetimes\nin the vacuum with inverse triad and holonomy modifications that arise as a\nconsequence of the loop quantization procedure. It is found that, in addition\nto the initial modifications of the Hamiltonian, quantum corrections of the\nclassical metric itself are needed as well in order to obtain generally\ncovariant models. A comparison with a recent alternative criterion is included\nin the discussion."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.12377",
    "c_title":[
      "Mukkamala-Pere\\~niguez master function for even-parity perturbations of\n  the Schwarzschild spacetime"
    ],
    "c_abstract":[
      "Mukkamala and Pere\\~niguez recently discovered a new master function for\neven-parity metric perturbations of the Schwarzschild spacetime. Remarkably,\nthis function satisfies the Regge-Wheeler equation (instead of the Zerilli\nequation), which was previously understood to govern the odd-parity sector of\nthe perturbation only. In this paper I follow up on their work. First, I\nidentify a source term for their Regge-Wheeler equation, constructed from the\nperturbing energy-momentum tensor. Second, I relate the new master function to\nthe radiation fields at future null infinity and the event horizon. Third, I\nreconstruct the metric perturbation from the new master function, in the\nRegge-Wheeler gauge. The main conclusion of this work is that the greater\nsimplicity of the Regge-Wheeler equation (relative to the Zerilli equation) is\noffset by a greater complexity of obtaining the radiation fields and\nreconstructing the metric."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-124",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12753",
    "b_title":[
      "Propagation of extreme events in multiplex neuronal networks"
    ],
    "b_abstract":[
      "In previous studies, the propagation of extreme events across nodes in\nmonolayer networks has been extensively studied. In this work, we extend this\ninvestigation to explore the propagation of extreme events between two distinct\nlayers in a multiplex network. We consider a two-layer network, where one layer\nis globally coupled and exhibits extreme events, while the second layer remains\nuncoupled. The interlayer connections between the layers are either\nunidirectional or bidirectional. We find that unidirectional coupling between\nthe layers can induce extreme events in the uncoupled layer, whereas\nbidirectional coupling tends to mitigate extreme events in the globally coupled\nlayer. To characterize extreme and non-extreme states, we use probability plots\nto identify distinct regions in the parameter space. Additionally, we study the\nrobustness of extreme events emergence by examining various network topologies\nin the uncoupled layer. The mechanism behind the occurrence of extreme events\nis explored, with a particular focus on the transition from asynchronous states\nto a fully synchronized excitable state. For numerical simulations, we use\nnonidentical FitzHugh-Nagumo neurons at each node, which captures the dynamical\nbehavior of both coupled and uncoupled layers. Our findings suggest that\nextreme events in the uncoupled layer emerge through the gradual disappearance\nof disorder, accompanied by occasional bursts of synchronized activity. Results\nobtained in this work will serve a starting point in understanding the dynamics\nbehind the propagation of extreme events in real-world networks."
    ],
    "b_categories":[
      [
        "nlin.CD"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11278",
    "c_title":[
      "Path integral approach for predicting the diffusive statistics of\n  geometric phases in chaotic Hamiltonian systems"
    ],
    "c_abstract":[
      "From the integer quantum Hall effect, to swimming at low Reynolds number,\ngeometric phases arise in the description of many different physical systems.\nIn many of these systems the temporal evolution prescribed by the geometric\nphase can be directly measured by an external observer. By definition,\ngeometric phases rely on the history of the system's internal dynamics, and so\ntheir measurement is directly related to temporal correlations in the system.\nThey, thus, provide a sensitive tool for studying chaotic Hamiltonian systems.\nIn this work we present a toy model consisting of an autonomous,\nlow-dimensional, chaotic Hamiltonian system designed to have a simple planar\ninternal state space, and a single geometric phase. The diffusive phase\ndynamics in the highly chaotic regime is thus governed by the loop statistics\nof planar random walks. We show that the na\\\"ive loop statistics result in\nballistic behavior of the phase, and recover the diffusive behavior by\nconsidering a bounded shape space, or a quadratic confining potential."
    ],
    "c_categories":[
      [
        "nlin.CD"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-125",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14886",
    "b_title":[
      "Surgical Scene Understanding in the Era of Foundation AI Models: A\n  Comprehensive Review"
    ],
    "b_abstract":[
      "Recent advancements in machine learning (ML) and deep learning (DL),\nparticularly through the introduction of foundational models (FMs), have\nsignificantly enhanced surgical scene understanding within minimally invasive\nsurgery (MIS). This paper surveys the integration of state-of-the-art ML and DL\ntechnologies, including Convolutional Neural Networks (CNNs), Vision\nTransformers (ViTs), and foundational models like the Segment Anything Model\n(SAM), into surgical workflows. These technologies improve segmentation\naccuracy, instrument tracking, and phase recognition in surgical endoscopic\nvideo analysis. The paper explores the challenges these technologies face, such\nas data variability and computational demands, and discusses ethical\nconsiderations and integration hurdles in clinical settings. Highlighting the\nroles of FMs, we bridge the technological capabilities with clinical needs and\noutline future research directions to enhance the adaptability, efficiency, and\nethical alignment of AI applications in surgery. Our findings suggest that\nsubstantial progress has been made; however, more focused efforts are required\nto achieve seamless integration of these technologies into clinical workflows,\nensuring they complement surgical practice by enhancing precision, reducing\nrisks, and optimizing patient outcomes."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.20814",
    "c_title":[
      "Improved 3D Point-Line Mapping Regression for Camera Relocalization"
    ],
    "c_abstract":[
      "In this paper, we present a new approach for improving 3D point and line\nmapping regression for camera re-localization. Previous methods typically rely\non feature matching (FM) with stored descriptors or use a single network to\nencode both points and lines. While FM-based methods perform well in\nlarge-scale environments, they become computationally expensive with a growing\nnumber of mapping points and lines. Conversely, approaches that learn to encode\nmapping features within a single network reduce memory footprint but are prone\nto overfitting, as they may capture unnecessary correlations between points and\nlines. We propose that these features should be learned independently, each\nwith a distinct focus, to achieve optimal accuracy. To this end, we introduce a\nnew architecture that learns to prioritize each feature independently before\ncombining them for localization. Experimental results demonstrate that our\napproach significantly enhances the 3D map point and line regression\nperformance for camera re-localization. The implementation of our method will\nbe publicly available at: https:\/\/github.com\/ais-lab\/pl2map\/."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-126",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05820",
    "b_title":[
      "User Selection in Near-Field Gigantic MIMO Systems with Modular Arrays"
    ],
    "b_abstract":[
      "Modular Arrays (MAs) are a promising architecture to enable multi-user\ncommunications in next-generation multiple-input multiple-output (MIMO) systems\nbased on extra-large (XL) or gigantic MIMO (gMIMO) deployments, trading off an\nimproved spatial resolution with characteristic interference patterns\nassociated to grating lobes. In this work, we analyze whether MAs can\noutperform conventional collocated deployments, in terms of achievable sum-rate\nand served users in a multi-user downlink set-up. First, we provide a rigorous\nanalytical characterization of the inter-user interference for modular gMIMO\nsystems operating in the near field. Then, we leverage these results to\noptimize the user selection and precoding mechanisms, designing two algorithms\nthat largely outperform existing alternatives in the literature, with different\nalgorithmic complexities. Results show that the proposed algorithms yield over\n70% improvements in achievable sum-spectral efficiencies compared to the state\nof the art. We also illustrate how MAs allow to serve a larger number of users\nthanks to their improved spatial resolution, compared to the collocated\ncounterpart."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04796",
    "c_title":[
      "DULRTC-RME: A Deep Unrolled Low-rank Tensor Completion Network for Radio\n  Map Estimation"
    ],
    "c_abstract":[
      "Radio maps enrich radio propagation and spectrum occupancy information, which\nprovides fundamental support for the operation and optimization of wireless\ncommunication systems. Traditional radio maps are mainly achieved by extensive\nmanual channel measurements, which is time-consuming and inefficient. To reduce\nthe complexity of channel measurements, radio map estimation (RME) through\nnovel artificial intelligence techniques has emerged to attain higher\nresolution radio maps from sparse measurements or few observations. However,\nblack box problems and strong dependency on training data make learning-based\nmethods less explainable, while model-based methods offer strong theoretical\ngrounding but perform inferior to the learning-based methods. In this paper, we\ndevelop a deep unrolled low-rank tensor completion network (DULRTC-RME) for\nradio map estimation, which integrates theoretical interpretability and\nlearning ability by unrolling the tedious low-rank tensor completion\noptimization into a deep network. It is the first time that algorithm unrolling\ntechnology has been used in the RME field. Experimental results demonstrate\nthat DULRTC-RME outperforms existing RME methods."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-127",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09534",
    "b_title":[
      "AI in Support of Diversity and Inclusion"
    ],
    "b_abstract":[
      "In this paper, we elaborate on how AI can support diversity and inclusion and\nexemplify research projects conducted in that direction. We start by looking at\nthe challenges and progress in making large language models (LLMs) more\ntransparent, inclusive, and aware of social biases. Even though LLMs like\nChatGPT have impressive abilities, they struggle to understand different\ncultural contexts and engage in meaningful, human like conversations. A key\nissue is that biases in language processing, especially in machine translation,\ncan reinforce inequality. Tackling these biases requires a multidisciplinary\napproach to ensure AI promotes diversity, fairness, and inclusion. We also\nhighlight AI's role in identifying biased content in media, which is important\nfor improving representation. By detecting unequal portrayals of social groups,\nAI can help challenge stereotypes and create more inclusive technologies.\nTransparent AI algorithms, which clearly explain their decisions, are essential\nfor building trust and reducing bias in AI systems. We also stress AI systems\nneed diverse and inclusive training data. Projects like the Child Growth\nMonitor show how using a wide range of data can help address real world\nproblems like malnutrition and poverty. We present a project that demonstrates\nhow AI can be applied to monitor the role of search engines in spreading\ndisinformation about the LGBTQ+ community. Moreover, we discuss the SignON\nproject as an example of how technology can bridge communication gaps between\nhearing and deaf people, emphasizing the importance of collaboration and mutual\ntrust in developing inclusive AI. Overall, with this paper, we advocate for AI\nsystems that are not only effective but also socially responsible, promoting\nfair and inclusive interactions between humans and machines."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09545",
    "c_title":[
      "The Value of Goal Commitment in Planning"
    ],
    "c_abstract":[
      "In this paper, we revisit the concept of goal commitment from early planners\nin the presence of current forward chaining heuristic planners. We present a\ncompilation that extends the original planning task with commit actions that\nenforce the persistence of specific goals once achieved, thereby committing to\nthem in the search sub-tree. This approach imposes a specific goal achievement\norder in parts of the search tree, potentially introducing dead-end states.\nThis can reduce search effort if the goal achievement order is correct.\nOtherwise, the search algorithm can expand nodes in the open list where goals\ndo not persist. Experimental results demonstrate that the reformulated tasks\nsuit state-of-the-art agile planners, enabling them to find better"
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-128",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17511",
    "b_title":[
      "Spectral flow of Callias operators, odd K-cowaist, and positive scalar\n  curvature"
    ],
    "b_abstract":[
      "On a complete Riemannian manifold $M$, we study the spectral flow of a family\nof Callias operators on $M$. We derive a codimension zero formula when\ndimension of $M$ is odd and a codimension one formula when dimension of $M$ is\neven. These can be seen as analogues of Gromov--Lawson's relative index theorem\nand classical Callias index theorem, respectively. Secondly, we introduce an\nintrinsic definition of K-cowaist on odd-dimensional manifolds, making use of\nthe odd Chern character of a smooth map from $M$ to a unitary group. It behaves\njust like the usual K-cowaist on even-dimensional manifolds. We then apply the\nnotion of odd K-cowaist and the tool of spectral flow to investigate problems\nrelated to positive scalar curvature on spin manifolds. In particular, we prove\ninfinite odd K-cowaist to be an obstruction to the existence of PSC metrics. We\nobtain quantitative scalar curvature estimates on complete non-compact\nmanifolds and scalar-mean curvature estimates on compact manifolds with\nboundary. They extend several previous results optimally, which unfolds a major\nadvantage of our method via spectral flow and odd K-cowaist."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.12277",
    "c_title":[
      "Weakly almost-Fuchsian manifolds are nearly-Fuchsian"
    ],
    "c_abstract":[
      "We show that a hyperbolic three-manifold $M$ containing a closed minimal\nsurface with principal curvatures in $[-1,1]$ also contains nearby\n(non-minimal) surfaces with principal curvatures in $(-1,1)$. When $M$ is\ncomplete and homeomorphic to $S\\times\\mathbb{R}$, for $S$ a closed surface,\nthis implies that $M$ is quasi-Fuchsian, answering a question left open from\nUhlenbeck's 1983 seminal paper. Additionally, our result implies that there\nexist (many) quasi-Fuchsian manifolds that contain a closed surface with\nprincipal curvatures in $(-1,1)$, but no closed minimal surface with principal\ncurvatures in $(-1,1)$, disproving a conjecture from the 2000s."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-129",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09531",
    "b_title":[
      "Anisotropic temperature-dependent lattice parameters and elastic\n  constants from first principles"
    ],
    "b_abstract":[
      "The Quasi-harmonic Approximation (QHA) is a widely used method for\ncalculating the temperature dependence of lattice parameters and the thermal\nexpansion coefficients from first principles. However, applying QHA to\nanisotropic systems typically requires several dozens or even hundreds of\nphonon band structure calculations, leading to high computational costs. The\nZero Static Internal Stress Approximation (ZSISA) QHA method partly addresses\nsuch caveat, but the computational load of its implementation remains high, so\nthat its volumetric-only counterpart v-ZSISA-QHA is preferred. In this work, we\npresent an efficient implementation of the ZSISA-QHA, enabling its application\nacross a wide range of crystal structures under varying temperature (T) and\npressure (P) conditions. By incorporating second-order derivatives of the\nvibrational free energy with respect to lattice degrees of freedom, we\nsignificantly reduce the number of required phonon band structure calculations\nfor the determination of all lattice parameters and angles. For hexagonal,\ntrigonal, and tetragonal systems, only six phonon band structure calculations\nare needed, while 10, 15, and 28 calculations suffice for orthorhombic,\nmonoclinic, and triclinic systems, respectively. This method is tested for a\nvariety of non-cubic materials, from uniaxial ones like ZnO and CaCO3 to\nmonoclinic or triclinic materials such as ZrO2, HfO2, and Al2SiO5,\ndemonstrating a significant reduction in computational effort while maintaining\naccuracy in modeling anisotropic thermal expansion, unlike the v-ZSISA-QHA. The\nmethod is also applied to the first-principles calculation of\ntemperature-dependent elastic constants, with only up to six more phonon band\nstructure calculations, depending on the crystallographic system."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03175",
    "c_title":[
      "Structural, vibrational, and transport properties of compound forming\n  liquid Li-Bi alloys"
    ],
    "c_abstract":[
      "Due to the compound forming tendency, some of the liquid metal alloys show\nanomalous behavior in their physical and chemical properties. Near the compound\nforming concentration, their electrical resistivity is beyond the metallic\nvalues and hence they may be labelled as liquid semiconductors. Lithium-Bismuth\nis one such system. It shows some interesting features in terms of physical and\nchemical properties such as departure from nearly free electron theory, very\nhigh value of electrical resistivity near the compound forming composition.\nWhile dealing with the electrical resistivity of liquid alloys with very high\nvalues of electrical resistivity, the famously used approaches such as\nFaber-Ziman theory and Morgan theory have some limitations. Hence, some\nmodifications in these theoretical formalisms are required in order to\nreproduce the experimental values of the electrical transport properties. We,\nin the present work have modeled liquid Li-Bi system using model potential\nformalism in conjunction with the established theoretical models along with\nsuitable modifications to study structural, elastic and transport properties.\nIn particular, we have treated the effective valence of pure Li and Bi as\nparameters and we have calculated the phase shifts using model potentials\nrather than muffin-tin potential. The results are compared with the results of\nmolecular dynamics simulation and other theoretical models. It is observed that\nthe t-matrix formulation in conjunction with the model potential formalism is\nable to reproduce the correct trends in the electrical resistivity isotherm.\nWhereas the results of Faber-Ziman and Morgan theory are highly underestimated,\nthe non-metallic behavior near the critical composition can be explained\nclearly from the present results of electrical resistivity. Further, phonon\nfrequencies and sound velocities are also estimated."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-130",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06548",
    "b_title":[
      "Unsupervised detection and fitness estimation of emerging SARS-CoV-2\n  variants. Application to wastewater samples (ANRS0160)"
    ],
    "b_abstract":[
      "Repeated waves of emerging variants during the SARS-CoV-2 pandemics have\nhighlighted the urge of collecting longitudinal genomic data and developing\nstatistical methods based on time series analyses for detecting new threatening\nlineages and estimating their fitness early in time. Most models study the\nevolution of the prevalence of particular lineages over time and require a\nprior classification of sequences into lineages. Such process is prone to\ninduce delays and bias. More recently, few authors studied the evolution of the\nprevalence of mutations over time with alternative clustering approaches,\navoiding specific lineage classification. Most of the aforementioned methods\nare however either non parametric or unsuited to pooled data characterizing,\nfor instance, wastewater samples. In this context, we propose an alternative\nunsupervised method for clustering mutations according to their frequency\ntrajectory over time and estimating group fitness from time series of pooled\nmutation prevalence data. Our model is a mixture of observed count data and\nlatent group assignment and we use the expectation-maximization algorithm for\nmodel selection and parameter estimation. The application of our method to time\nseries of SARS-CoV-2 sequencing data collected from wastewater treatment plants\nin France from October 2020 to April 2021 shows its ability to agnostically\ngroup mutations according to their probability of belonging to B.1.160, Alpha,\nBeta, B.1.177 variants with selection coefficient estimates per group in\ncoherence with the viral dynamics in France reported by Nextstrain. Moreover,\nour method detected the Alpha variant as threatening as early as supervised\nmethods (which track specific mutations over time) with the noticeable\ndifference that, since unsupervised, it does not require any prior information\non the set of mutations."
    ],
    "b_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2503.09007",
    "c_title":[
      "Reconstructing Noisy Gene Regulation Dynamics Using\n  Extrinsic-Noise-Driven Neural Stochastic Differential Equations"
    ],
    "c_abstract":[
      "Proper regulation of cell signaling and gene expression is crucial for\nmaintaining cellular function, development, and adaptation to environmental\nchanges. Reaction dynamics in cell populations is often noisy because of (i)\ninherent stochasticity of intracellular biochemical reactions (``intrinsic\nnoise'') and (ii) heterogeneity of cellular states across different cells that\nare influenced by external factors (``extrinsic noise''). In this work, we\nintroduce an extrinsic-noise-driven neural stochastic differential equation\n(END-nSDE) framework that utilizes the Wasserstein distance to accurately\nreconstruct SDEs from trajectory data from a heterogeneous population of cells\n(extrinsic noise). We demonstrate the effectiveness of our approach using both\nsimulated and experimental data from three different systems in cell biology:\n(i) circadian rhythms, (ii) RPA-DNA binding dynamics, and (iii) NF$\\kappa$B\nsignaling process. Our END-nSDE reconstruction method can model how cellular\nheterogeneity (extrinsic noise) modulates reaction dynamics in the presence of\nintrinsic noise. It also outperforms existing time-series analysis methods such\nas recurrent neural networks (RNNs) and long short-term memory networks\n(LSTMs). By inferring cellular heterogeneities from data, our END-nSDE\nreconstruction method can reproduce noisy dynamics observed in experiments. In\nsummary, the reconstruction method we propose offers a useful surrogate\nmodeling approach for complex biophysical processes, where high-fidelity\nmechanistic models may be impractical."
    ],
    "c_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-131",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10947",
    "b_title":[
      "The anomalous density of states and quasi-localized vibration through\n  homogeneous thermalization of an inhomogeneous elastic system"
    ],
    "b_abstract":[
      "Amorphous solids are dynamically inhomogeneous due to in lack of\ntranslational symmetry and hence exhibit vibrational properties different from\ncrystalline solids with anomalous low frequency vibrational density of states\n(VDOS) and related low temperature thermal properties. However, an\ninterpretation of their origin from basic physical laws is still needed\ncompared with rapidly progressed particle level investigations. In this work,\nwe start with the quasi-equilibrium condition, which requires elastic potential\nenergy to be homogeneously distributed even in an inhomogeneous elastic solid\nover long time observation. Analytical result shows that the anomalous low\nfrequency VDOS behavior $D(\\omega) \\propto \\omega^4$ can be obtained when the\nquasi-equilibrium condition is satisfied on an inhomogeneous elastic system.\nUnder high frequency after a crossover depending on the length scale of\ninhomogeneity, the power law of VDOS is changed to square $D(\\omega) \\propto\n\\omega^2$ which is Debye's law for crystalline solids. These features agree\nwith recent particle level investigations. Our work suggest that the universal\nlow frequency anomaly of amorphous solids can be considered as a result of\nhomogeneous thermalization."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.13361",
    "c_title":[
      "Liquid water transport model in hydrophilic granular : Preliminary\n  validation with drying rate of hierarchical granular"
    ],
    "c_abstract":[
      "The drying rate profile of granular beds can be divided into the constant\nrate period (CRP), which is characterized by a nearly constant drying rate, and\nthe falling rate period (FRP), in which the drying rate rapidly decays. In\norder to explain this behavior quantitatively, we proposed a simple\none-dimensional power law model in which the product of the water permeability\nand the pressure gradient is assumed to be proportional to the cube of the\nsaturation. To test this model, we measured the drying rates of glass beads and\nhierarchical granular materials produced by sintering and breaking glass beads.\nOur results and those of previous experiments showed consistency with the power\nlaw. The obtained proportional constant of the experimental power law also\nshows a rough agreement with that estimated from previous studies on water\npermeability and capillary pressure. Drying behavior in FRP also agrees with\nour model in some points. The remnant deviation of the model from experimental\nresults may be attributed to the inhomogeneity of granular media, which was\nqualitatively verified."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-132",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13646",
    "b_title":[
      "D.Va: Validate Your Demonstration First Before You Use It"
    ],
    "b_abstract":[
      "In-context learning (ICL) has demonstrated significant potential in enhancing\nthe capabilities of large language models (LLMs) during inference. It's\nwell-established that ICL heavily relies on selecting effective demonstrations\nto generate outputs that better align with the expected results. As for\ndemonstration selection, previous approaches have typically relied on intuitive\nmetrics to evaluate the effectiveness of demonstrations, which often results in\nlimited robustness and poor cross-model generalization capabilities. To tackle\nthese challenges, we propose a novel method, \\textbf{D}emonstration\n\\textbf{VA}lidation (\\textbf{D.Va}), which integrates a demonstration\nvalidation perspective into this field. By introducing the demonstration\nvalidation mechanism, our method effectively identifies demonstrations that are\nboth effective and highly generalizable. \\textbf{D.Va} surpasses all existing\ndemonstration selection techniques across both natural language understanding\n(NLU) and natural language generation (NLG) tasks. Additionally, we demonstrate\nthe robustness and generalizability of our approach across various language\nmodels with different retrieval models."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.18730",
    "c_title":[
      "Predicting the Road Ahead: A Knowledge Graph based Foundation Model for\n  Scene Understanding in Autonomous Driving"
    ],
    "c_abstract":[
      "The autonomous driving field has seen remarkable advancements in various\ntopics, such as object recognition, trajectory prediction, and motion planning.\nHowever, current approaches face limitations in effectively comprehending the\ncomplex evolutions of driving scenes over time. This paper proposes FM4SU, a\nnovel methodology for training a symbolic foundation model (FM) for scene\nunderstanding in autonomous driving. It leverages knowledge graphs (KGs) to\ncapture sensory observation along with domain knowledge such as road topology,\ntraffic rules, or complex interactions between traffic participants. A bird's\neye view (BEV) symbolic representation is extracted from the KG for each\ndriving scene, including the spatio-temporal information among the objects\nacross the scenes. The BEV representation is serialized into a sequence of\ntokens and given to pre-trained language models (PLMs) for learning an inherent\nunderstanding of the co-occurrence among driving scene elements and generating\npredictions on the next scenes. We conducted a number of experiments using the\nnuScenes dataset and KG in various scenarios. The results demonstrate that\nfine-tuned models achieve significantly higher accuracy in all tasks. The\nfine-tuned T5 model achieved a next scene prediction accuracy of 86.7%. This\npaper concludes that FM4SU offers a promising foundation for developing more\ncomprehensive models for scene understanding in autonomous driving."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-133",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15201",
    "b_title":[
      "A Training-free Synthetic Data Selection Method for Semantic\n  Segmentation"
    ],
    "b_abstract":[
      "Training semantic segmenter with synthetic data has been attracting great\nattention due to its easy accessibility and huge quantities. Most previous\nmethods focused on producing large-scale synthetic image-annotation samples and\nthen training the segmenter with all of them. However, such a solution remains\na main challenge in that the poor-quality samples are unavoidable, and using\nthem to train the model will damage the training process. In this paper, we\npropose a training-free Synthetic Data Selection (SDS) strategy with CLIP to\nselect high-quality samples for building a reliable synthetic dataset.\nSpecifically, given massive synthetic image-annotation pairs, we first design a\nPerturbation-based CLIP Similarity (PCS) to measure the reliability of\nsynthetic image, thus removing samples with low-quality images. Then we propose\na class-balance Annotation Similarity Filter (ASF) by comparing the synthetic\nannotation with the response of CLIP to remove the samples related to\nlow-quality annotations. The experimental results show that using our method\nsignificantly reduces the data size by half, while the trained segmenter\nachieves higher performance. The code is released at\nhttps:\/\/github.com\/tanghao2000\/SDS."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.21244",
    "c_title":[
      "Anatomically-guided masked autoencoder pre-training for aneurysm\n  detection"
    ],
    "c_abstract":[
      "Intracranial aneurysms are a major cause of morbidity and mortality\nworldwide, and detecting them manually is a complex, time-consuming task.\nAlbeit automated solutions are desirable, the limited availability of training\ndata makes it difficult to develop such solutions using typical supervised\nlearning frameworks. In this work, we propose a novel pre-training strategy\nusing more widely available unannotated head CT scan data to pre-train a 3D\nVision Transformer model prior to fine-tuning for the aneurysm detection task.\nSpecifically, we modify masked auto-encoder (MAE) pre-training in the following\nways: we use a factorized self-attention mechanism to make 3D attention\ncomputationally viable, we restrict the masked patches to areas near arteries\nto focus on areas where aneurysms are likely to occur, and we reconstruct not\nonly CT scan intensity values but also artery distance maps, which describe the\ndistance between each voxel and the closest artery, thereby enhancing the\nbackbone's learned representations. Compared with SOTA aneurysm detection\nmodels, our approach gains +4-8% absolute Sensitivity at a false positive rate\nof 0.5. Code and weights will be released."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-134",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14494",
    "b_title":[
      "Deeply Supervised Flow-Based Generative Models"
    ],
    "b_abstract":[
      "Flow based generative models have charted an impressive path across multiple\nvisual generation tasks by adhering to a simple principle: learning velocity\nrepresentations of a linear interpolant. However, we observe that training\nvelocity solely from the final layer output underutilizes the rich inter layer\nrepresentations, potentially impeding model convergence. To address this\nlimitation, we introduce DeepFlow, a novel framework that enhances velocity\nrepresentation through inter layer communication. DeepFlow partitions\ntransformer layers into balanced branches with deep supervision and inserts a\nlightweight Velocity Refiner with Acceleration (VeRA) block between adjacent\nbranches, which aligns the intermediate velocity features within transformer\nblocks. Powered by the improved deep supervision via the internal velocity\nalignment, DeepFlow converges 8 times faster on ImageNet with equivalent\nperformance and further reduces FID by 2.6 while halving training time compared\nto previous flow based models without a classifier free guidance. DeepFlow also\noutperforms baselines in text to image generation tasks, as evidenced by\nevaluations on MSCOCO and zero shot GenEval."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16559",
    "c_title":[
      "LoRA-X: Bridging Foundation Models with Training-Free Cross-Model\n  Adaptation"
    ],
    "c_abstract":[
      "The rising popularity of large foundation models has led to a heightened\ndemand for parameter-efficient fine-tuning methods, such as Low-Rank Adaptation\n(LoRA), which offer performance comparable to full model fine-tuning while\nrequiring only a few additional parameters tailored to the specific base model.\nWhen such base models are deprecated and replaced, all associated LoRA modules\nmust be retrained, requiring access to either the original training data or a\nsubstantial amount of synthetic data that mirrors the original distribution.\nHowever, the original data is often inaccessible due to privacy or licensing\nissues, and generating synthetic data may be impractical and insufficiently\nrepresentative. These factors complicate the fine-tuning process considerably.\nTo address this challenge, we introduce a new adapter, Cross-Model Low-Rank\nAdaptation (LoRA-X), which enables the training-free transfer of LoRA\nparameters across source and target models, eliminating the need for original\nor synthetic training data. Our approach imposes the adapter to operate within\nthe subspace of the source base model. This constraint is necessary because our\nprior knowledge of the target model is limited to its weights, and the criteria\nfor ensuring the adapter's transferability are restricted to the target base\nmodel's weights and subspace. To facilitate the transfer of LoRA parameters of\nthe source model to a target model, we employ the adapter only in the layers of\nthe target model that exhibit an acceptable level of subspace similarity. Our\nextensive experiments demonstrate the effectiveness of LoRA-X for text-to-image\ngeneration, including Stable Diffusion v1.5 and Stable Diffusion XL."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-135",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19953",
    "b_title":[
      "GeoEdit: Geometric Knowledge Editing for Large Language Models"
    ],
    "b_abstract":[
      "Regular updates are essential for maintaining up-to-date knowledge in large\nlanguage models (LLMs). Consequently, various model editing methods have been\ndeveloped to update specific knowledge within LLMs. However, training-based\napproaches often struggle to effectively incorporate new knowledge while\npreserving unrelated general knowledge. To address this challenge, we propose a\nnovel framework called Geometric Knowledge Editing (GeoEdit). GeoEdit utilizes\nthe geometric relationships of parameter updates from fine-tuning to\ndifferentiate between neurons associated with new knowledge updates and those\nrelated to general knowledge perturbations. By employing a direction-aware\nknowledge identification method, we avoid updating neurons with directions\napproximately orthogonal to existing knowledge, thus preserving the model's\ngeneralization ability. For the remaining neurons, we integrate both old and\nnew knowledge for aligned directions and apply a \"forget-then-learn\" editing\nstrategy for opposite directions. Additionally, we introduce an\nimportance-guided task vector fusion technique that filters out redundant\ninformation and provides adaptive neuron-level weighting, further enhancing\nmodel editing performance. Extensive experiments on two publicly available\ndatasets demonstrate the superiority of GeoEdit over existing state-of-the-art\nmethods."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06204",
    "c_title":[
      "Non-literal Understanding of Number Words by Language Models"
    ],
    "c_abstract":[
      "Humans naturally interpret numbers non-literally, effortlessly combining\ncontext, world knowledge, and speaker intent. We investigate whether large\nlanguage models (LLMs) interpret numbers similarly, focusing on hyperbole and\npragmatic halo effects. Through systematic comparison with human data and\ncomputational models of pragmatic reasoning, we find that LLMs diverge from\nhuman interpretation in striking ways. By decomposing pragmatic reasoning into\ntestable components, grounded in the Rational Speech Act framework, we pinpoint\nwhere LLM processing diverges from human cognition -- not in prior knowledge,\nbut in reasoning with it. This insight leads us to develop a targeted solution\n-- chain-of-thought prompting inspired by an RSA model makes LLMs'\ninterpretations more human-like. Our work demonstrates how computational\ncognitive models can both diagnose AI-human differences and guide development\nof more human-like language understanding capabilities."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-136",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14406",
    "b_title":[
      "Effects of time-periodic drive in the linear response for planar-Hall\n  set-ups with Weyl and multi-Weyl semimetals"
    ],
    "b_abstract":[
      "We investigate the influence of a time-periodic drive on three-dimensional\nWeyl and multi-Weyl semimetals in planar-Hall\/planar-thermal-Hall set-ups. The\ndrive is modelled here by circularly-polarized electromagnetic fields, whose\neffects are incorporated by a combination of the Floquet theorem and the van\nVleck perturbation theory, applicable in the high-frequency limit. We evaluate\nthe longitudinal and in-plane transverse components of the linear-response\ncoefficients using the semiclassical Boltzmann formalism. We demonstrate the\nexplicit expressions of these transport coefficients in certain limits of the\nsystem parameters, where it is possible to derive the explicit analytical\nexpressions. Our results demonstrate that the topological charges of the\ncorresponding semimetals etch their trademark signatures in these transport\nproperties, which can be observed in experiments."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07477",
    "c_title":[
      "Robust zero modes in PbTe-Pb hybrid nanowires"
    ],
    "c_abstract":[
      "Majorana zero modes in tunneling conductance are expected to manifest as\nrobust zero bias peaks (ZBPs). While ZBPs alone are not conclusive evidence of\nMajorana modes due to alternative explanations, robust ZBPs remain a crucial\nand necessary first-step indicator in the search for topological states. Here,\nwe report the observation of robust ZBPs in PbTe-Pb hybrid nanowires. The peak\nheight can reach $2e^2\/h$, though it does not yet form a quantized plateau.\nImportantly, these ZBPs can remain non-split over sizable ranges in both\nmagnetic field and gate voltage scans, highlighting their robustness. We\ndiscuss possible interpretations based on Majorana zero modes as well as\nAndreev bound states."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-137",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10982",
    "b_title":[
      "Enhanced Multi-View Pedestrian Detection Using Probabilistic Occupancy\n  Volume"
    ],
    "b_abstract":[
      "Occlusion poses a significant challenge in pedestrian detection from a single\nview. To address this, multi-view detection systems have been utilized to\naggregate information from multiple perspectives. Recent advances in multi-view\ndetection utilized an early-fusion strategy that strategically projects the\nfeatures onto the ground plane, where detection analysis is performed. A\npromising approach in this context is the use of 3D feature-pulling technique,\nwhich constructs a 3D feature volume of the scene by sampling the corresponding\n2D features for each voxel. However, it creates a 3D feature volume of the\nwhole scene without considering the potential locations of pedestrians. In this\npaper, we introduce a novel model that efficiently leverages traditional 3D\nreconstruction techniques to enhance deep multi-view pedestrian detection. This\nis accomplished by complementing the 3D feature volume with probabilistic\noccupancy volume, which is constructed using the visual hull technique. The\nprobabilistic occupancy volume focuses the model's attention on regions\noccupied by pedestrians and improves detection accuracy. Our model outperforms\nstate-of-the-art models on the MultiviewX dataset, with an MODA of 97.3%, while\nachieving competitive performance on the Wildtrack dataset."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.12720",
    "c_title":[
      "GenStereo: Towards Open-World Generation of Stereo Images and\n  Unsupervised Matching"
    ],
    "c_abstract":[
      "Stereo images are fundamental to numerous applications, including extended\nreality (XR) devices, autonomous driving, and robotics. Unfortunately,\nacquiring high-quality stereo images remains challenging due to the precise\ncalibration requirements of dual-camera setups and the complexity of obtaining\naccurate, dense disparity maps. Existing stereo image generation methods\ntypically focus on either visual quality for viewing or geometric accuracy for\nmatching, but not both. We introduce GenStereo, a diffusion-based approach, to\nbridge this gap. The method includes two primary innovations (1) conditioning\nthe diffusion process on a disparity-aware coordinate embedding and a warped\ninput image, allowing for more precise stereo alignment than previous methods,\nand (2) an adaptive fusion mechanism that intelligently combines the\ndiffusion-generated image with a warped image, improving both realism and\ndisparity consistency. Through extensive training on 11 diverse stereo\ndatasets, GenStereo demonstrates strong generalization ability. GenStereo\nachieves state-of-the-art performance in both stereo image generation and\nunsupervised stereo matching tasks. Our framework eliminates the need for\ncomplex hardware setups while enabling high-quality stereo image generation,\nmaking it valuable for both real-world applications and unsupervised learning\nscenarios. Project page is available at https:\/\/qjizhi.github.io\/genstereo"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-138",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06021",
    "b_title":[
      "FedEM: A Privacy-Preserving Framework for Concurrent Utility\n  Preservation in Federated Learning"
    ],
    "b_abstract":[
      "Federated Learning (FL) enables collaborative training of models across\ndistributed clients without sharing local data, addressing privacy concerns in\ndecentralized systems. However, the gradient-sharing process exposes private\ndata to potential leakage, compromising FL's privacy guarantees in real-world\napplications. To address this issue, we propose Federated Error Minimization\n(FedEM), a novel algorithm that incorporates controlled perturbations through\nadaptive noise injection. This mechanism effectively mitigates gradient leakage\nattacks while maintaining model performance. Experimental results on benchmark\ndatasets demonstrate that FedEM significantly reduces privacy risks and\npreserves model accuracy, achieving a robust balance between privacy protection\nand utility preservation."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06099",
    "c_title":[
      "Fine-Tuning Federated Learning-Based Intrusion Detection Systems for\n  Transportation IoT"
    ],
    "c_abstract":[
      "The rapid advancement of machine learning (ML) and on-device computing has\nrevolutionized various industries, including transportation, through the\ndevelopment of Connected and Autonomous Vehicles (CAVs) and Intelligent\nTransportation Systems (ITS). These technologies improve traffic management and\nvehicle safety, but also introduce significant security and privacy concerns,\nsuch as cyberattacks and data breaches. Traditional Intrusion Detection Systems\n(IDS) are increasingly inadequate in detecting modern threats, leading to the\nadoption of ML-based IDS solutions. Federated Learning (FL) has emerged as a\npromising method for enabling the decentralized training of IDS models on\ndistributed edge devices without sharing sensitive data. However, deploying\nFL-based IDS in CAV networks poses unique challenges, including limited\ncomputational and memory resources on edge devices, competing demands from\ncritical applications such as navigation and safety systems, and the need to\nscale across diverse hardware and connectivity conditions. To address these\nissues, we propose a hybrid server-edge FL framework that offloads pre-training\nto a central server while enabling lightweight fine-tuning on edge devices.\nThis approach reduces memory usage by up to 42%, decreases training times by up\nto 75%, and achieves competitive IDS accuracy of up to 99.2%. Scalability\nanalyses further demonstrates minimal performance degradation as the number of\nclients increase, highlighting the framework's feasibility for CAV networks and\nother IoT applications."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-139",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11072",
    "b_title":[
      "Box Confidence Depth: simulation-based inference with hyper-rectangles"
    ],
    "b_abstract":[
      "This work presents a novel simulation-based approach for constructing\nconfidence regions in parametric models, which is particularly suited for\ngenerative models and situations where limited data and conventional asymptotic\napproximations fail to provide accurate results. The method leverages the\nconcept of data depth and depends on creating random hyper-rectangles, i.e.\nboxes, in the sample space generated through simulations from the model,\nvarying the input parameters. A probabilistic acceptance rule allows to\nretrieve a Depth-Confidence Distribution for the model parameters from which\npoint estimators as well as calibrated confidence sets can be read-off. The\nmethod is designed to address cases where both the parameters and test\nstatistics are multivariate."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.07545",
    "c_title":[
      "Kolmogorov-Smirnov Estimation of Self-Similarity in Long-Range Dependent\n  Fractional Processes"
    ],
    "c_abstract":[
      "This paper investigates the estimation of the self-similarity parameter in\nfractional processes. We re-examine the Kolmogorov-Smirnov (KS) test as a\ndistribution-based method for assessing self-similarity, emphasizing its\nrobustness and independence from specific probability distributions. Despite\nthese advantages, the KS test encounters significant challenges when applied to\nfractional processes, primarily due to intrinsic data dependencies that induce\nboth intradependent and interdependent effects. To address these limitations,\nwe propose a novel method based on random permutation theory, which effectively\nremoves autocorrelations while preserving the self-similarity structure of the\nprocess. Simulation results validate the robustness of the proposed approach,\ndemonstrating its effectiveness in providing reliable estimation in the\npresence of strong dependencies. These findings establish a statistically\nrigorous framework for self-similarity analysis in fractional processes, with\npotential applications across various scientific domains."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-140",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16314",
    "b_title":[
      "An experimental investigation of quantum frequency correlations\n  resilience against white and colored noise"
    ],
    "b_abstract":[
      "Understanding the impact of disturbances in quantum channels is of paramount\nimportance for the implementation of many quantum technologies, as noise can be\ndetrimental to quantum correlations. Among the various types of disturbances,\nwe explore the effects of white and colored noise and experimentally test the\nresilience of a quantum ghost spectrometer against these two types of noise,\nshowing that it is always robust against white noise, whereas colored noise\nintroduces a huge impact on the process."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.14988",
    "c_title":[
      "Fault-Tolerant Optical Quantum Computation using 3D Hybrid Cluster\n  States"
    ],
    "c_abstract":[
      "Hybridizing different physical systems or degrees of freedom offers\nsignificant advantages for realizing practical, universal, scalable, and\nfault-tolerant quantum computation (FTQC). Here, we propose optical FTQC\nschemes with low squeezing thresholds by leveraging the strengths of both\ndiscrete-variable (DV) and continuous-variable (CV) systems while utilizing\nfrequency, time, and orbital angular momentum degrees of freedom. First, we\ndesign an optical entanglement generator (OEG) capable of producing various\ntypes of entangled pairs, including cluster pairs, hybrid entangled pairs, and\nGKP Bell pairs, which can be flexibly chosen by adjusting the measurement\nbasis. Additionally, the OEG features extra ports for directly inputting\n(outputting) data (result) states via quantum teleportation, eliminating the\nneed for optical switches. Secondly, large-scale one-dimensional,\ntwo-dimensional, and three-dimensional (3D) hybrid cluster states, composed of\nDV Gottesman-Kitaev-Preskill (GKP) qubits and CV squeezed states, are\ndeterministically generated using the entangled pairs passed through a\ntime-delay system. Moreover, we optimize the surface-GKP code to further reduce\nlogical errors during the stabilizer measurements in the surface code. By\ncombining the 3D cubic hybrid cluster state with the modified surface-GKP code\nand accounting for full circuit-level noise, FTQC is achieved with a squeezing\nthreshold of 10 dB. Moreover, our method can also generate a 3D macronode\nRaussendorf-Harrington-Goyal (RHG) cluster state, facilitating an alternative\nFTQC scheme via the RHG-GKP code. Our work provides a viable pathway toward\nfuture optical FTQC architectures."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-141",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11923",
    "b_title":[
      "Bikernels by monochromatic paths"
    ],
    "b_abstract":[
      "In this paper, we introduce the concept of bikernel by monochromatic paths of\na bicolored digraph. This concept is strongly motivated by the existing notions\nof kernels, kernels by monochromatic paths, and double stable augmented\ncategories. We establish sufficient and necessary conditions for several\nfamilies of bicolored digraphs to have a bikernel by monochromatic paths. Also,\nwe characterize bicolored digraphs without monochromatic cycles that possess a\nbikernel by monochromatic paths. Similarly, we characterize bicolored digraphs\nwith monochromatic cycles that also have a bikernel by monochromatic paths.\nFurthermore, we prove sufficient and necessary conditions for some families of\ndigraphs to be $BK$-colorable. This means that a bicoloration of the digraph\nexists where the resulting bicolored digraph has a bikernel."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.01913",
    "c_title":[
      "Arithmetical Structures On Fan Graphs"
    ],
    "c_abstract":[
      "In this paper, we study the arithmetical structures on Fan Graphs Fn. Let G\nbe a finite and connected graph. An arithmetical structure on G is a pair (d,\nr) of positive integer vectors such that r is primitive (the greatest common\ndivisor of its coefficients is 1) and (diag(d)-A)r = 0, where A represents the\nadjacency matrix of G. This work explores the combinatorial properties of the\narithmetical structures associated with Fn. Further, we discuss the arrow-star\ngraph, a structure derived from the fan graph, along with its properties.\nAdditionally, we investigate the critical group linked to each such structure\non Fn."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-142",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02515",
    "b_title":[
      "Orbital Order Triggered Out-of-Plane Ferroelectricity in Magnetic\n  Transition Metal di-halide Monolayers"
    ],
    "b_abstract":[
      "Although multiferroics have undergone extensive examination for several\ndecades, the occurrence of ferroelectricity induced by orbital order is only\nscarcely documented. In this study, we propose the existence of spontaneous\nferroelectric states featuring a finite out-of-plane polarization in monolayer\ncompounds of magnetic transition metal di-halides. Our first principles\nanalysis reveals that partially occupied d-orbital states within octahedra\nexhibit a preference for spatial orbital order within a two-dimensional\nlattice. The absence of inversion symmetry, arising from orbital order, serves\nas the driving force introducing additional electric polarization along the\nout-of-plane direction. Unlike previous reported orbital orders arising from\nmetal states in lattice, the non-colinear ones we studied in this work relate\nto the transition between two insulator states. The resultant asymmetric\nJahn-Teller distortions are accompanied as the consequence producing additional\nionic polarization. Importantly, our findings indicate that this mechanism is\nnot confined to a specific material but is a shared characteristic among a\nseries of monolayer transition metal magnetic di-halides, proposing an\ninnovative form of intrinsic two-dimensional multiferroic physics."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.07564",
    "c_title":[
      "Discovery of a Highly Anisotropic Type-II Ferromagnetic Weyl State\n  Exhibiting a 3D Quantum Hall Effect"
    ],
    "c_abstract":[
      "Topological semimetals, particularly Weyl semimetals (WSMs), are crucial\nplatforms for exploring emergent quantum phenomena due to their unique\nelectronic structures and potential to transition into various topological\nphases. In this study, we report the discovery of a ferromagnetic (FM) type-II\nWSM in Mn(Bi1-xSbx)4Te7, which exhibits a remarkable three-dimensional (3D)\nquantum Hall effect (QHE). By precisely tuning the chemical potential through\nSb doping, we obtained samples with the Fermi level near the charge neutrality\npoint for x = ~ 0.27. This was confirmed by spectroscopy measurements (ARPES\nand STS), and these samples showed strong quantum oscillations along with a key\ntransport signature of a Weyl state - chiral anomaly, and Fermi surface\nreconstruction driven by FM ordering. Our theoretical analysis indicates that\nthis Weyl state evolves from a parent nodal ring state, where higher-order\nk-terms split the nodal line into type-II Weyl nodes. The Weyl state exhibits\nsignificant anisotropy, characterized by a pronounced reduction in Fermi\nvelocity along the kz-axis, likely accounting for the observed 3D QHE. These\nresults not only highlight the exceptional tunability of the Mn(Bi1-xSbx)4Te7\nsystem, where precise control of the chemical potential and magnetic properties\nopens access to novel quantum phases, but also advance the understanding of FM\nWSMs."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-143",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13638",
    "b_title":[
      "Teaming up MET plus jet with Drell-Yan in the SMEFT"
    ],
    "b_abstract":[
      "The Standard Model Effective Field Theory (SMEFT) is a widely utilized\nframework for exploring new physics effects in a model-independent manner. In\nprevious studies, Drell-Yan collider data has emerged as a promising signature\ndue to its energy enhancement relative to Standard Model predictions. We\npresent recent works, extending this approach by also considering the \"missing\nenergy + jet\" signature, which can constrain related dineutrino couplings and\nsimilarly benefits from energy enhancement. The combination of these\nobservables allows for constraining a broader selection of operators and helps\nresolve flat directions in a global analysis. Overall, the bounds probe the\nmulti-TeV range, with the strongest reaching up to $10\\; \\text{TeV}$ for\nfour-fermion interactions and $7 \\;\\text{TeV}$ for gluonic dipole interactions.\nFurthermore, we find that low energy flavor observables improve limits by up to\na factor of three for dipole operators. We also estimate sensitivities to new\nphysics at future hadron colliders including the $\\sqrt{s} = 27 \\;\\text{TeV}$\nHE-LHC and the $\\sqrt{s} = 100 \\; \\text{TeV}$ FCC-hh."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.01399",
    "c_title":[
      "Global Neutrino Constraints on the Minimal U(1)$_{L_\\mu-L_\\tau}$ Model"
    ],
    "c_abstract":[
      "We examine the minimal U(1)$_{L_\\mu-L_\\tau}$ gauge model in light of the\nlatest neutrino data, including neutrino oscillations, cosmological\nobservations, direct mass measurements, and neutrinoless double-beta decay.\nUsing the most conservative oscillation data, we find that normal ordering is\nexcluded at approximately the 90% confidence level (CL). Incorporating\ncosmological constraints from Cosmic Microwave Background (CMB) observations\nstrengthens this exclusion to about 95% CL, while further including Baryon\nAcoustic Oscillation (BAO) data increases it to nearly 99% CL. The inverted\nordering is even more strongly disfavored. Our analysis is performed within a\nfrequentist framework, minimizing sensitivity to prior assumptions inherent in\nBayesian approaches. These results impose strong constraints on the viability\nof the minimal U(1)$_{L_\\mu-L_\\tau}$ gauge model."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-144",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19896",
    "b_title":[
      "GenPC: Zero-shot Point Cloud Completion via 3D Generative Priors"
    ],
    "b_abstract":[
      "Existing point cloud completion methods, which typically depend on predefined\nsynthetic training datasets, encounter significant challenges when applied to\nout-of-distribution, real-world scans. To overcome this limitation, we\nintroduce a zero-shot completion framework, termed GenPC, designed to\nreconstruct high-quality real-world scans by leveraging explicit 3D generative\npriors. Our key insight is that recent feed-forward 3D generative models,\ntrained on extensive internet-scale data, have demonstrated the ability to\nperform 3D generation from single-view images in a zero-shot setting. To\nharness this for completion, we first develop a Depth Prompting module that\nlinks partial point clouds with image-to-3D generative models by leveraging\ndepth images as a stepping stone. To retain the original partial structure in\nthe final results, we design the Geometric Preserving Fusion module that aligns\nthe generated shape with input by adaptively adjusting its pose and scale.\nExtensive experiments on widely used benchmarks validate the superiority and\ngeneralizability of our approach, bringing us a step closer to robust\nreal-world scan completion."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15978",
    "c_title":[
      "A Survey on fMRI-based Brain Decoding for Reconstructing Multimodal\n  Stimuli"
    ],
    "c_abstract":[
      "In daily life, we encounter diverse external stimuli, such as images, sounds,\nand videos. As research in multimodal stimuli and neuroscience advances,\nfMRI-based brain decoding has become a key tool for understanding brain\nperception and its complex cognitive processes. Decoding brain signals to\nreconstruct stimuli not only reveals intricate neural mechanisms but also\ndrives progress in AI, disease treatment, and brain-computer interfaces. Recent\nadvancements in neuroimaging and image generation models have significantly\nimproved fMRI-based decoding. While fMRI offers high spatial resolution for\nprecise brain activity mapping, its low temporal resolution and signal noise\npose challenges. Meanwhile, techniques like GANs, VAEs, and Diffusion Models\nhave enhanced reconstructed image quality, and multimodal pre-trained models\nhave boosted cross-modal decoding tasks. This survey systematically reviews\nrecent progress in fMRI-based brain decoding, focusing on stimulus\nreconstruction from passive brain signals. It summarizes datasets, relevant\nbrain regions, and categorizes existing methods by model structure.\nAdditionally, it evaluates model performance and discusses their effectiveness.\nFinally, it identifies key challenges and proposes future research directions,\noffering valuable insights for the field. For more information and resources\nrelated to this survey, visit https:\/\/github.com\/LpyNow\/BrainDecodingImage."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-145",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19380",
    "b_title":[
      "Creative Problem-Solving: A Study with Blind and Low Vision Software\n  Professionals"
    ],
    "b_abstract":[
      "Background: Software engineering requires both technical skills and creative\nproblem-solving. Blind and low-vision software professionals (BLVSPs) encounter\nnumerous workplace challenges, including inaccessible tools and collaboration\nhurdles with sighted colleagues. Objective: This study explores the innovative\nstrategies employed by BLVSPs to overcome these accessibility barriers,\nfocusing on their custom solutions and the importance of supportive\ncommunities. Methodology: We conducted semi-structured interviews with 30\nBLVSPs and used reflexive thematic analysis to identify key themes. Results:\nFindings reveal that BLVSPs are motivated to develop creative and adaptive\nsolutions, highlighting the vital role of collaborative communities in\nfostering shared problem-solving. Conclusion: For BLVSPs, creative\nproblem-solving is essential for navigating inaccessible work environments, in\ncontrast to sighted peers, who pursue optimization. This study enhances\nunderstanding of how BLVSPs navigate accessibility challenges through\ninnovation."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.02708",
    "c_title":[
      "AsserT5: Test Assertion Generation Using a Fine-Tuned Code Language\n  Model"
    ],
    "c_abstract":[
      "Writing good software tests can be challenging, therefore approaches that\nsupport developers are desirable. While generating complete tests automatically\nis such an approach commonly proposed in research, developers may already have\nspecific test scenarios in mind and thus just require help in selecting the\nmost suitable test assertions for these scenarios. This can be done using deep\nlearning models to predict assertions for given test code. Prior research on\nassertion generation trained these models specifically for the task, raising\nthe question how much the use of larger models pre-trained on code that have\nemerged since then can improve their performance. In particular, while\nabstracting identifiers has been shown to improve specifically trained models,\nit remains unclear whether this also generalises to models pre-trained on\nnon-abstracted code. Finally, even though prior work demonstrated high accuracy\nit remains unclear how this translates into the effectiveness of the assertions\nat their intended application -- finding faults. To shed light on these open\nquestions, in this paper we propose AsserT5, a new model based on the\npre-trained CodeT5 model, and use this to empirically study assertion\ngeneration. We find that the abstraction and the inclusion of the focal method\nare useful also for a fine-tuned pre-trained model, resulting in test\nassertions that match the ground truth assertions precisely in up to 59.5\\% of\ncases, more than twice as precise as prior models. However, evaluation on real\nbugs from the Defects4J dataset shows that out of 138 bugs detectable with\nassertions in real-world projects, AsserT5 was only able to suggest\nfault-finding assertions for 33, indicating the need for further improvements."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-146",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10810",
    "b_title":[
      "Next-to-leading power jet functions in the small-mass limit in QED"
    ],
    "b_abstract":[
      "We investigate the factorization properties of the massive fermion form\nfactor in QED, to next-to-leading power in the fermion mass, and up to two-loop\norder. For this purpose we define new jet functions that have multiple\nconnections to the hard part as operator matrix elements, and compute them to\nsecond order in the coupling. We test our factorization formula using these new\njet functions in a region-based analysis and find that factorization indeed\nholds. We address a number of subtle aspects such as rapidity regulators and\nexternal line corrections, and we find an interesting sequence of relations\namong the jet functions."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.15649",
    "c_title":[
      "Supercooled Dark Scalar Phase Transitions explanation of NANOGrav data"
    ],
    "c_abstract":[
      "The evidence of a Stochastic Gravitational Wave Background (SGWB) in the nHz\nfrequency range is posed to open a new window on the Universe. A preferred\nexplanation relies on a supercooled first order phase transition at the 100 MeV\n- GeV scale. In this article, we address the feasibility going from the\nparticle physics model to the production of the gravitational waves. We take a\nminimal approach for the dark sector model introducing the fewest ingredients\nrequired, namely a new U(1) gauge group and a dark scalar that dynamically\nbreaks the symmetry. Supercooling poses challenges in the analysis that put\nunder question the feasibility of this explanation: we address them, going\nbeyond previous studies by carefully considering the effects of a vacuum\ndomination phase and explicitly tracking the phase transition from its onset to\nits completion. We find that the proposed model can successfully give origin to\nthe observed PTA SGWB signal. The strong supercooling imposes a correlation\nbetween the new gauge coupling and the scalar quartic one, leading to a\nsignificant hierarchy between the (heavier) gauge boson and the dark scalar.\nUltimately, information on phase transitions from SGWB observations could\nprovide a direct probe of the microphysics of the Early Universe and be used to\nguide future searches of dark sector in laboratories."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-147",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10622",
    "b_title":[
      "CWTHF: Identifying Dark Matter Halos with Continuous Wavelet Transform"
    ],
    "b_abstract":[
      "Cosmological simulations are an important method for investigating the\nevolution of the Universe. In order to gain further insight into the processes\nof structure formation, it is necessary to identify isolated bound objects\nwithin the simulations, namely, the dark matter halos. The continuous wavelet\ntransform (CWT) is an effective tool used as a halo finder due to its ability\nto extract clustering information from the input data. In this study, we\nintroduce CWTHF (Continuous Wavelet Transform Halo Finder), the first\nwavelet-based, MPI-parallelized halo finder, marking a novel approach in the\nfield of cosmology. We calculate the CWT from the cloud-in-cell (CIC) grid and\nsegment the grid based on the local CWT maxima. We then investigate the effects\nof the parameters that influence our program and identify the default settings.\nA comparison with the conventional friends-of-friends (FOF) method demonstrates\nthe viability of CWT for halo finding. Although the actual performance is not\nfaster than FOF, the linear time complexity of $\\mathcal{O}(N)$ of our\nidentification scheme indicates its significant potential for future\noptimization and application."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.09769",
    "c_title":[
      "Cosmological tensions and $\\mathcal{Q}_{\\rm CDM}$ as an alternative to\n  $\\Lambda$CDM"
    ],
    "c_abstract":[
      "The Standard Model of cosmology, $\\Lambda$CDM, while enormously successful,\nis currently unable to account for several cosmological anomalies the most\nprominent of which are in the measurements of the Hubble parameter and $S_8$.\nAdditionally, the inclusion of the cosmological constant is theoretically\nunappealing. This has lead to extensions of the model such as the use of fluid\nequations for interacting dark matter and dark energy which, however, are ad\nhoc since they do not appear to arise from a Lagrangian. Recently, we have\nproposed $\\mathcal{Q}_{\\rm CDM}$ as an alternative to $\\Lambda$CDM which is a\ndynamical model of a quintessence field interacting with dark matter within a\nfield theoretic approach. In this approach, we analyze the effect of the dark\nmatter mass, the dark matter-dark energy interaction strength and the dark\nmatter self-interaction on the cosmological parameters. Further, within\n$\\mathcal{Q}_{\\rm CDM}$ we investigate the possible alleviation of the Hubble\ntension and the $S_8$ anomaly and the nature of dark energy."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-148",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20545",
    "b_title":[
      "SoS1: O1 and R1-Like Reasoning LLMs are Sum-of-Square Solvers"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) have achieved human-level proficiency across\ndiverse tasks, but their ability to perform rigorous mathematical problem\nsolving remains an open challenge. In this work, we investigate a fundamental\nyet computationally intractable problem: determining whether a given\nmultivariate polynomial is nonnegative. This problem, closely related to\nHilbert's Seventeenth Problem, plays a crucial role in global polynomial\noptimization and has applications in various fields. First, we introduce\nSoS-1K, a meticulously curated dataset of approximately 1,000 polynomials,\nalong with expert-designed reasoning instructions based on five progressively\nchallenging criteria. Evaluating multiple state-of-the-art LLMs, we find that\nwithout structured guidance, all models perform only slightly above the random\nguess baseline 50%. However, high-quality reasoning instructions significantly\nimprove accuracy, boosting performance up to 81%. Furthermore, our 7B model,\nSoS-7B, fine-tuned on SoS-1K for just 4 hours, outperforms the 671B DeepSeek-V3\nand GPT-4o-mini in accuracy while only requiring 1.8% and 5% of the computation\ntime needed for letters, respectively. Our findings highlight the potential of\nLLMs to push the boundaries of mathematical reasoning and tackle NP-hard\nproblems."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09611",
    "c_title":[
      "EVaDE : Event-Based Variational Thompson Sampling for Model-Based\n  Reinforcement Learning"
    ],
    "c_abstract":[
      "Posterior Sampling for Reinforcement Learning (PSRL) is a well-known\nalgorithm that augments model-based reinforcement learning (MBRL) algorithms\nwith Thompson sampling. PSRL maintains posterior distributions of the\nenvironment transition dynamics and the reward function, which are intractable\nfor tasks with high-dimensional state and action spaces. Recent works show that\ndropout, used in conjunction with neural networks, induces variational\ndistributions that can approximate these posteriors. In this paper, we propose\nEvent-based Variational Distributions for Exploration (EVaDE), which are\nvariational distributions that are useful for MBRL, especially when the\nunderlying domain is object-based. We leverage the general domain knowledge of\nobject-based domains to design three types of event-based convolutional layers\nto direct exploration. These layers rely on Gaussian dropouts and are inserted\nbetween the layers of the deep neural network model to help facilitate\nvariational Thompson sampling. We empirically show the effectiveness of\nEVaDE-equipped Simulated Policy Learning (EVaDE-SimPLe) on the 100K Atari game\nsuite."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-149",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15256",
    "b_title":[
      "Ionized envelopes around protoplanets and the role of radiative feedback\n  in gas accretion"
    ],
    "b_abstract":[
      "Planetary growth within protoplanetary disks involves accreting material from\ntheir surroundings, yet the underlying mechanisms and physical conditions of\nthe accreting gas remain debated. This study aims to investigate the dynamics\nand thermodynamic properties of accreting gas giants, and to characterize the\nenvelope that forms near the planet during accretion. We employ\nthree-dimensional hydrodynamical simulations of a Jupiter-mass planet embedded\nin a viscous gaseous disk. Our models incorporate a non-isothermal energy\nequation to compute gas and radiation energy diffusion and include radiative\nfeedback from the planet. Results indicate that gas accretion occurs\nsupersonically towards the planet, forming an ionized envelope that extends\nfrom the planetary surface up to 0.2 times the Hill radius in the no-feedback\nmodel, and up to 0.4 times the Hill radius in the feedback model. The\nenvelope's radius, or ionization radius, acts as a boundary halting supersonic\ngas inflow and is pivotal for estimating accretion rates and H$\\alpha$ emission\nluminosities. Including radiative feedback increases accretion rates,\nespecially within the ionization radius and from areas to the right of the\nplanet when the star is positioned to the left. The accretion luminosities\ncalculated at the ionization radius are substantially lower than those\ncalculated at the Hill radius, highlighting potential misinterpretations in the\nnon-detection of H$\\alpha$ emissions as indicators of ongoing planet formation."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.15081",
    "c_title":[
      "Orbits of very distant asteroid satellites"
    ],
    "c_abstract":[
      "The very wide binary asteroid (VWBA) population is a small subset of the\npopulation of known binary and multiple asteroids made of systems with very\nwidely orbiting satellites and long orbital periods, on the order of tens to\nhundreds of days. The origin of these systems is debatable, and most members of\nthis population are poorly characterized. We have compiled all available\nhigh-angular resolution imaging archival data of VWBA systems from large\nground- and space-based telescopes. We measure the astrometric positions of the\nsatellite relative to the primary and analyze the dynamics of the satellites\nusing the Genoid genetic algorithm. Additionally, we use a NEATM thermal model\nto estimate the diameters of two systems, and we model the orbit of Litva's\ninner satellite using photometric lightcurve observations. We determine the\neffective diameters of binary systems Christophedumas and Alconrad to be 4.7 +\n0.4km and 5.2 + 0.3km respectively. We determine new orbital solutions for five\nsystems, Huenna, Litva, (3548) Eurybates, Pauling, and Alconrad. We find a\nsignificantly eccentric best-fit orbital solution for the outer satellite of\nLitva, a moderately eccentric solution for Alconrad, and a nearly circular\nsolution for Pauling. We also confirm previously reported orbital solutions for\n(379) Huenna and Eurybates. It is unlikely that BYORP expansion could be solely\nresponsible for the formation of VWBAs. It is possible that the satellites of\nthese systems were formed through YORP spin-up and then later scattered onto\nvery wide orbits. Additionally, we find that some members of the population are\nunlikely to have formed satellites through YORP spin-up, and a collisional\nformation history is favored. In particular, this applies to VWBAs within large\ndynamical families, or large VWBA systems such as Huenna and NASA's Lucy\nmission target Eurybates."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-150",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18636",
    "b_title":[
      "Transfer Learning Assisted Fast Design Migration Over Technology Nodes:\n  A Study on Transformer Matching Network"
    ],
    "b_abstract":[
      "In this study, we introduce an innovative methodology for the design of\nmm-Wave passive networks that leverages knowledge transfer from a pre-trained\nsynthesis neural network (NN) model in one technology node and achieves swift\nand reliable design adaptation across different integrated circuit (IC)\ntechnologies, operating frequencies, and metal options. We prove this concept\nthrough simulation-based demonstrations focusing on the training and comparison\nof the coefficient of determination (R2) of synthesis NNs for 1:1 on-chip\ntransformers in GlobalFoundries(GF) 22nm FDX+ (target domain), with and without\ntransfer learning from a model trained in GF 45nm SOI (source domain). In the\nexperiments, we explore varying target data densities of 0.5%, 1%, 5%, and 100%\nwith a complete dataset of 0.33 million in GF 22FDX+, and for comparative\nanalysis, apply source data densities of 25%, 50%, 75%, and 100% with a\ncomplete dataset of 2.5 million in GF 45SOI. With the source data only at\n30GHz, the experiments span target data from two metal options in GF 22FDX+ at\nfrequencies of 30 and 39 GHz. The results prove that the transfer learning with\nthe source domain knowledge (GF 45SOI) can both accelerate the training process\nin the target domain (GF 22FDX+) and improve the R2 values compared to models\nwithout knowledge transfer. Furthermore, it is observed that a model trained\nwith just 5% of target data and augmented by transfer learning achieves R2\nvalues superior to a model trained with 20% of the data without transfer,\nvalidating the advantage seen from 1% to 5% data density. This demonstrates a\nnotable reduction of 4X in the necessary dataset size highlighting the efficacy\nof utilizing transfer learning to mm-Wave passive network design. The PyTorch\nlearning and testing code is publicly available at\nhttps:\/\/github.com\/ChenhaoChu\/RFIC-TL."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01741",
    "c_title":[
      "Secrecy Rate Maximization for 6G Reconfigurable Holographic Surfaces\n  Assisted Systems"
    ],
    "c_abstract":[
      "Reconfigurable holographic surfaces (RHS) have emerged as a transformative\nmaterial technology, enabling dynamic control of electromagnetic waves to\ngenerate versatile holographic beam patterns. This paper addresses the problem\nof secrecy rate maximization for an RHS-assisted systems by joint designing the\ndigital beamforming, artificial noise (AN), and the analog holographic\nbeamforming. However, such a problem results to be non-convex and challenging.\nTherefore, to solve it, a novel alternating optimization algorithm based on the\nmajorization-maximization (MM) framework for RHS-assisted systems is proposed,\nwhich rely on surrogate functions to facilitate efficient and reliable\noptimization. In the proposed approach, digital beamforming design ensures\ndirected signal power toward the legitimate user while minimizing leakage to\nthe unintended receiver. The AN generation method projects noise into the null\nspace of the legitimate user channel, aligning it with the unintended receiver\nchannel to degrade its signal quality. Finally, the holographic beamforming\nweights are optimized to refine the wavefronts for enhanced secrecy rate\nperformance Simulation results validate the effectiveness of the proposed\nframework, demonstrating significant improvements in secrecy rate compared to\nthe benchmark method."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-151",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10101",
    "b_title":[
      "Strong and weak sharp bounds for Neural Network Operators in\n  Sobolev-Orlicz spaces and their quantitative extensions to Orlicz spaces"
    ],
    "b_abstract":[
      "In this paper, we establish sharp bounds for a family of Kantorovich-type\nneural network operators within the general frameworks of Sobolev-Orlicz and\nOrlicz spaces. We establish both strong (in terms of the Luxemburg norm) and\nweak (in terms of the modular functional) estimates, using different\napproaches. The strong estimates are derived for spaces generated by\n$\\varphi$-functions that are $N$-functions or satisfy the\n$\\Delta^\\prime$-condition. Such estimates also lead to convergence results with\nrespect to the Luxemburg norm in several instances of Orlicz spaces, including\nthe exponential case. Meanwhile, the weak estimates are achieved under less\nrestrictive assumptions on the involved $\\varphi$-function. To obtain these\nresults, we introduce some new tools and techniques in Orlicz spaces. Central\nto our approach is the Orlicz Minkowski inequality, which allows us to obtain\nunified strong estimates for the operators. We also present a weak (modular)\nversion of this inequality holding under weaker conditions. Additionally, we\nintroduce a novel notion of discrete absolute $\\varphi$-moments of hybrid type,\nand we employ the Hardy-Littlewood maximal operator within Orlicz spaces for\nthe asymptotic analysis. Furthermore, we introduce the new space\n$\\mathcal{W}^{1,\\varphi}(I)$, which is embedded in the Sobolev-Orlicz space\n$W^{1,\\varphi}(I)$ and modularly dense in $L^\\varphi(I)$. This allows to\nachieve asymptotic estimates for a wider class of $\\varphi$-functions,\nincluding those that do not meet the $\\Delta_2$-condition. For the extension to\nthe whole Orlicz-setting, we generalize a Sobolev-Orlicz density result given\nby H. Musielak using Steklov functions, providing a modular counterpart.\nFinally, we explore the relationships between weak and strong Orlicz Lipschitz\nclasses, providing qualitative results for the rate of convergence of the\noperators."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.12265",
    "c_title":[
      "On the harmonic generalized Cauchy-Kovalevskaya extension and its\n  connection with the Fueter-Sce theorem"
    ],
    "c_abstract":[
      "One of the primary objectives of this paper is to establish a generalized\nCauchy-Kovalevskaya extension for axially harmonic functions. We demonstrate\nthat the result can be expressed as a power series involving Bessel-type\nfunctions of specific differential operators acting on two initial functions.\nAdditionally, we analyze the decomposition of the harmonic CK extension in\nterms of integrals over the sphere $ \\mathbb{S}^{m-1} $ involving functions of\nplane wave type.\n  Another key goal of this paper is to explore the relationship between the\nharmonic Cauchy-Kovalevskaya extension and the Fueter-Sce theorem. The\nFueter-Sce theorem outlines a two-step process for constructing axially\nmonogenic functions in $ \\mathbb{R}^{m+1}$ starting from holomorphic functions\nin one complex variable. The first step generates the class of slice monogenic\nfunctions, while the second step produces axially monogenic functions by\napplying the pointwise differential operator $\n\\Delta_{\\mathbb{R}{^{m+1}}}^{\\frac{m-1}{2}} $ with $m$ being odd, known as the\nFueter-Sce map, to a slice monogenic function.\n  By suitably factorizing the Fueter-Sce map, we introduce the set of axially\nharmonic functions, which serves as an intermediate class between slice\nmonogenic and axially monogenic functions. In this paper, we establish a\nconnection between the harmonic CK extension and the factorization of the\nFueter-Sce map. This connection leads to a new notion of harmonic polynomials,\nwhich we show to form a basis for the Riesz potential. Finally, we also\nconstruct a basis for the space of axially harmonic functions."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-152",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15613",
    "b_title":[
      "Pick-and-place Manipulation Across Grippers Without Retraining: A\n  Learning-optimization Diffusion Policy Approach"
    ],
    "b_abstract":[
      "Current robotic pick-and-place policies typically require consistent gripper\nconfigurations across training and inference. This constraint imposes high\nretraining or fine-tuning costs, especially for imitation learning-based\napproaches, when adapting to new end-effectors. To mitigate this issue, we\npresent a diffusion-based policy with a hybrid learning-optimization framework,\nenabling zero-shot adaptation to novel grippers without additional data\ncollection for retraining policy. During training, the policy learns\nmanipulation primitives from demonstrations collected using a base gripper. At\ninference, a diffusion-based optimization strategy dynamically enforces\nkinematic and safety constraints, ensuring that generated trajectories align\nwith the physical properties of unseen grippers. This is achieved through a\nconstrained denoising procedure that adapts trajectories to gripper-specific\nparameters (e.g., tool-center-point offsets, jaw widths) while preserving\ncollision avoidance and task feasibility. We validate our method on a Franka\nPanda robot across six gripper configurations, including 3D-printed fingertips,\nflexible silicone gripper, and Robotiq 2F-85 gripper. Our approach achieves a\n93.3% average task success rate across grippers (vs. 23.3-26.7% for diffusion\npolicy baselines), supporting tool-center-point variations of 16-23.5 cm and\njaw widths of 7.5-11.5 cm. The results demonstrate that constrained diffusion\nenables robust cross-gripper manipulation while maintaining the sample\nefficiency of imitation learning, eliminating the need for gripper-specific\nretraining. Video and code are available at https:\/\/github.com\/yaoxt3\/GADP."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06292",
    "c_title":[
      "Occupancy-SLAM: An Efficient and Robust Algorithm for Simultaneously\n  Optimizing Robot Poses and Occupancy Map"
    ],
    "c_abstract":[
      "Joint optimization of poses and features has been extensively studied and\ndemonstrated to yield more accurate results in feature-based SLAM problems.\nHowever, research on jointly optimizing poses and non-feature-based maps\nremains limited. Occupancy maps are widely used non-feature-based environment\nrepresentations because they effectively classify spaces into obstacles, free\nareas, and unknown regions, providing robots with spatial information for\nvarious tasks. In this paper, we propose Occupancy-SLAM, a novel\noptimization-based SLAM method that enables the joint optimization of robot\ntrajectory and the occupancy map through a parameterized map representation.\nThe key novelty lies in optimizing both robot poses and occupancy values at\ndifferent cell vertices simultaneously, a significant departure from existing\nmethods where the robot poses need to be optimized first before the map can be\nestimated. Evaluations using simulations and practical 2D laser datasets\ndemonstrate that the proposed approach can robustly obtain more accurate robot\ntrajectories and occupancy maps than state-of-the-art techniques with\ncomparable computational time. Preliminary results in the 3D case further\nconfirm the potential of the proposed method in practical 3D applications,\nachieving more accurate results than existing methods."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-153",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15966",
    "b_title":[
      "The Extraordinary Long-lasting Infrared Echo of PS16dtm Reveals an\n  Extremely Energetic Nuclear Outburst"
    ],
    "b_abstract":[
      "PS16dtm is one of the earliest reported candidate tidal disruption events\n(TDEs) in active galactic nuclei (AGNs) and displays a remarkably bright and\nlong-lived infrared (IR) echo revealed by multi-epoch photometry from the\nWide-field Infrared Survey Explorer (WISE). After a rapid rise in the first\nyear, the echo remains persistently at a high state from July 2017 to July\n2024, the latest epoch, and keeps an almost constant color. We have fitted the\nextraordinary IR emission with a refined dust echo model by taking into account\nthe dust sublimation process. The fitting suggests that an extremely giant dust\nstructure with a new inner radius of $\\sim1.6$ pc and an ultra-high peak\nbolometric luminosity, i.e., $\\sim6\\times10^{46} \\rm erg~s^{-1}$ for typical\n0.1$\\mu$m-sized silicate grain, is required to account for the IR echo. This\nwork highlights the distinctive value of IR echoes in measuring the accurate\nintrinsic bolometric luminosity, and thus the total radiated energy of TDEs,\nwhich could be severely underestimated by traditional methods, i.e. probably by\nmore than an order of magnitude in PS16dtm. Such large energetic output\ncompared to normal TDEs could be boosted by the pre-existing accretion disk and\ngas clouds around the black hole. Our model can be validated in the near future\nby IR time-domain surveys such as Near-Earth Object (NEO) Surveyor, given the\nrecent retirement of WISE. In addition, the potential for spatially resolving a\nreceding dusty torus after a TDE could also be an exciting subject in the era\nof advanced IR interferometry."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.15680",
    "c_title":[
      "Spatial dependence of the break in the energy spectrum of cosmic rays in\n  the new anisotropic diffusion approach"
    ],
    "c_abstract":[
      "At present, there is no consensus on whether the spectral break in the cosmic\nray flux of all elements around 4 PeV is a general characteristic of the Milky\nWay or is determined by a combination of factors that significantly affect the\nenergy position of the knee. We argue that considering the anisotropic\npropagation of cosmic rays within a realistically modeled Galactic magnetic\nfield, along with the acceleration limits in various source populations, allows\nfor an accurate description of local experimental data from LHAASO, Tibet\nAS$\\gamma$, and Fermi-LAT for gamma rays. To demonstrate this, we constructed a\ndiffusion propagation model with a general form diffusion tensor within a\ntwo-component magnetic field and determined both the local cosmic ray spectrum\nand the spectra for specific regions of the Milky Way. We calculated the\nintegral flux of diffuse gamma rays in the inner and outer regions of the\nGalaxy, finding that the spectral shape of the resulting flux aligns with\nexperimental data."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-154",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05824",
    "b_title":[
      "Aerial Reliable Collaborative Communications for Terrestrial Mobile\n  Users via Evolutionary Multi-Objective Deep Reinforcement Learning"
    ],
    "b_abstract":[
      "Unmanned aerial vehicles (UAVs) have emerged as the potential aerial base\nstations (BSs) to improve terrestrial communications. However, the limited\nonboard energy and antenna power of a UAV restrict its communication range and\ntransmission capability. To address these limitations, this work employs\ncollaborative beamforming through a UAV-enabled virtual antenna array to\nimprove transmission performance from the UAV to terrestrial mobile users,\nunder interference from non-associated BSs and dynamic channel conditions.\nSpecifically, we introduce a memory-based random walk model to more accurately\ndepict the mobility patterns of terrestrial mobile users. Following this, we\nformulate a multi-objective optimization problem (MOP) focused on maximizing\nthe transmission rate while minimizing the flight energy consumption of the UAV\nswarm. Given the NP-hard nature of the formulated MOP and the highly dynamic\nenvironment, we transform this problem into a multi-objective Markov decision\nprocess and propose an improved evolutionary multi-objective reinforcement\nlearning algorithm. Specifically, this algorithm introduces an evolutionary\nlearning approach to obtain the approximate Pareto set for the formulated MOP.\nMoreover, the algorithm incorporates a long short-term memory network and\nhyper-sphere-based task selection method to discern the movement patterns of\nterrestrial mobile users and improve the diversity of the obtained Pareto set.\nSimulation results demonstrate that the proposed method effectively generates a\ndiverse range of non-dominated policies and outperforms existing methods.\nAdditional simulations demonstrate the scalability and robustness of the\nproposed CB-based method under different system parameters and various\nunexpected circumstances."
    ],
    "b_categories":[
      [
        "cs.NE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.12743",
    "c_title":[
      "Cancermorphic Computing Toward Multilevel Machine Intelligence"
    ],
    "c_abstract":[
      "Despite their potential to address crucial bottlenecks in computing\narchitectures and contribute to the pool of biological inspiration for\nengineering, pathological biological mechanisms remain absent from\ncomputational theory. We hereby introduce the concept of cancer-inspired\ncomputing as a paradigm drawing from the adaptive, resilient, and evolutionary\nstrategies of cancer, for designing computational systems capable of thriving\nin dynamic, adversarial or resource-constrained environments. Unlike known\nbioinspired approaches (e.g., evolutionary and neuromorphic architectures),\ncancer-inspired computing looks at emulating the uniqueness of cancer cells\nsurvival tactics, such as somatic mutation, metastasis, angiogenesis and immune\nevasion, as parallels to desirable features in computing architectures, for\nexample decentralized propagation and resource optimization, to impact areas\nlike fault tolerance and cybersecurity. While the chaotic growth of cancer is\ncurrently viewed as uncontrollable in biology, randomness-based algorithms are\nalready being successfully demonstrated in enhancing the capabilities of other\ncomputing architectures, for example chaos computing integration. This vision\nfocuses on the concepts of multilevel intelligence and context-driven mutation,\nand their potential to simultaneously overcome plasticity-limited neuromorphic\napproaches and the randomness of chaotic approaches. The introduction of this\nconcept aims to generate interdisciplinary discussion to explore the potential\nof cancer-inspired mechanisms toward powerful and resilient artificial systems."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-155",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12429",
    "b_title":[
      "A Compact One-Way Fault-Tolerant Optical Quantum Computation"
    ],
    "b_abstract":[
      "One-way quantum computation is a promising approach to achieving universal,\nscalable, and fault-tolerant quantum computation. However, a main challenge\nlies in the creation of universal, scalable three-dimensional cluster states.\nHere, an experimental scheme is proposed for building large-scale canonical\nthree-dimensional cubic cluster states, which are compatible with the majority\nof qubit error-correcting codes, using the spatiospectral modes of an optical\nparametric oscillator. Combining with Gottesman-Kitaev-Preskill states, one-way\nfault-tolerant optical quantum computation can be achieved with a lower\nfault-tolerant squeezing threshold. Our scheme drastically simplify\nexperimental configurations, paving the way for compact realizations of one-way\nfault-tolerant optical quantum computation."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.18465",
    "c_title":[
      "Degree of simplicity of Floquet states of a periodically driven\n  Bose-Hubbard dimer"
    ],
    "c_abstract":[
      "We investigate numerically computed Floquet states of a Bose-Hubbard dimer\nwhich is subjected to strong, time-periodic forcing with respect to their\ncoherence, invoking a measure for their degree of simplicity previously\nsuggested by Leggett. This serves to ascertain the validity of the mean-field\napproximation under conditions such that the time-dependent nonlinear\nGross-Pitaevskii equation has chaotic solutions. It is shown that for\nsufficiently large particle numbers the exact N-particle Floquet state\nsemiclassically associated with the innermost quantized invariant tube\nsurrounding a stable periodic mean-field orbit represents a macroscopically\noccupied single-particle state, i.e., a Floquet condensate."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-156",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07811",
    "b_title":[
      "CodeCoR: An LLM-Based Self-Reflective Multi-Agent Framework for Code\n  Generation"
    ],
    "b_abstract":[
      "Code generation aims to produce code that fulfills requirements written in\nnatural languages automatically. Large language Models (LLMs) like ChatGPT have\ndemonstrated promising effectiveness in this area. Nonetheless, these LLMs\noften fail to ensure the syntactic and semantic correctness of the generated\ncode. Recently, researchers proposed multi-agent frameworks that guide LLMs\nwith different prompts to analyze programming tasks, generate code, perform\ntesting in a sequential workflow. However, the performance of the workflow is\nnot robust as the code generation depends on the performance of each agent. To\naddress this challenge, we propose CodeCoR, a self-reflective multi-agent\nframework that evaluates the effectiveness of each agent and their\ncollaborations. Specifically, for a given task description, four agents in\nCodeCoR generate prompts, code, test cases, and repair advice, respectively.\nEach agent generates more than one output and prunes away the low-quality ones.\nThe generated code is tested in the local environment: the code that fails to\npass the generated test cases is sent to the repair agent and the coding agent\nre-generates the code based on repair advice. Finally, the code that passes the\nmost number of generated test cases is returned to users. Our experiments on\nfour widely used datasets, HumanEval, HumanEval-ET, MBPP, and MBPP-ET,\ndemonstrate that CodeCoR significantly outperforms existing baselines (e.g.,\nCodeCoT and MapCoder), achieving an average Pass@1 score of 77.8%."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09475",
    "c_title":[
      "Guided Debugging of Auto-Translated Code Using Differential Testing"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) hold great promise in the task of code\ntranslation. However, the lack of explainability complicates the identification\nof the inevitable translation errors. In this paper, we propose tHinter, a\ndebugging tool to locate translation errors in auto-translated code. The core\nidea of tHinter is that correctly translated, the source and translated code\nshould present the same functionalities, giving the same output for the same\ninput. Hence, lines in the translated code responsible for output differences\nare possibly translation errors. First, tHinter employs fuzzing to generate\ndiverse test cases that thoroughly explore the translated code. Then, tHinter\nrelies on a heuristic algorithm to pinpoint translation errors from coverage\ninformation and differential testing execution results of those test cases.\nThis heuristic algorithm is designed to leverage both the statistics and the\nexpertise of developers. Comprehensive experiments with real code show its\neffectiveness. It reduces 71% lines developers need to review during debugging\nand increases the likelihood of the LLM fixing translation errors in a single\nquery by 59%. Developers generally consider it satisfactory and helpful."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-157",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15647",
    "b_title":[
      "Bivariate local permutation polynomials, their companions, and related\n  enumeration results"
    ],
    "b_abstract":[
      "We introduce two new families of permutation group polynomials over finite\nfields of arbitrary characteristic, which are special types of bivariate local\npermutation polynomials. For each family, we explicitly construct their\ncompanions. Furthermore, we precisely determine the total number of permutation\ngroup polynomials equivalent to the proposed families. Moreover, we resolve the\nproblem of enumerating permutation group polynomials that are equivalent to\n$e$-Klenian polynomials over finite fields for $e\\geq 1$, a problem previously\nnoted as nontrivial by Gutierrez and Urroz (2023)."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.12083",
    "c_title":[
      "Further results on $r$-Euler-Mahonian statistics"
    ],
    "c_abstract":[
      "As natural generalizations of the descent number ($\\des$) and the major index\n($\\maj$), Rawlings introduced the notions of the $r$-descent number ($r\\des$)\nand the $r$-major index ($r\\maj$) for a given positive integer $r$. A pair\n$(\\st_1, \\st_2)$ of permutation statistics is said to be $r$-Euler-Mahonian if\n$ (\\mathrm{st_1}, \\mathrm{st_2})$ and\n  $ (r\\des, r\\maj)$ are equidistributed over the set $\\mathfrak{S}_{n}$ of all\npermutations of $\\{1,2,\\ldots, n\\}$. The main objective of this paper is to\nconfirm a recent conjecture posed by Liu which asserts that $(g\\exc_\\ell,\ng\\den_\\ell)$ is $(g+\\ell-1)$-Euler-Mahonian for all positive integers $g$ and\n$\\ell$, where $g\\exc_\\ell$ denotes the $g$-gap $\\ell$-level excedance number\nand $g\\den_\\ell$ denotes the $g$-gap $\\ell$-level Denert's statistic. This is\naccomplished via a bijective proof of the equidistribution of $(g\\exc_\\ell,\ng\\den_\\ell)$ and $ (r\\des, r\\maj)$ where $r=g+\\ell-1$.\n  Setting $g=\\ell=1$, our result recovers the equidistribution of $(\\des,\n\\maj)$ and $(\\exc, \\den)$, which was first conjectured by Denert and proved by\nFoata and Zeilberger. Our second main result is concerned with the analogous\nresult for $(g\\exc_\\ell, g\\den_{g+\\ell})$ which states that $(g\\exc_\\ell,\ng\\den_{g+\\ell})$ is $(g+\\ell-1)$-Euler-Mahonian for all positive integers $g$\nand $\\ell$."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-158",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02807",
    "b_title":[
      "AE-NeRF: Augmenting Event-Based Neural Radiance Fields for Non-ideal\n  Conditions and Larger Scene"
    ],
    "b_abstract":[
      "Compared to frame-based methods, computational neuromorphic imaging using\nevent cameras offers significant advantages, such as minimal motion blur,\nenhanced temporal resolution, and high dynamic range. The multi-view\nconsistency of Neural Radiance Fields combined with the unique benefits of\nevent cameras, has spurred recent research into reconstructing NeRF from data\ncaptured by moving event cameras. While showing impressive performance,\nexisting methods rely on ideal conditions with the availability of uniform and\nhigh-quality event sequences and accurate camera poses, and mainly focus on the\nobject level reconstruction, thus limiting their practical applications. In\nthis work, we propose AE-NeRF to address the challenges of learning event-based\nNeRF from non-ideal conditions, including non-uniform event sequences, noisy\nposes, and various scales of scenes. Our method exploits the density of event\nstreams and jointly learn a pose correction module with an event-based NeRF\n(e-NeRF) framework for robust 3D reconstruction from inaccurate camera poses.\nTo generalize to larger scenes, we propose hierarchical event distillation with\na proposal e-NeRF network and a vanilla e-NeRF network to resample and refine\nthe reconstruction process. We further propose an event reconstruction loss and\na temporal loss to improve the view consistency of the reconstructed scene. We\nestablished a comprehensive benchmark that includes large-scale scenes to\nsimulate practical non-ideal conditions, incorporating both synthetic and\nchallenging real-world event datasets. The experimental results show that our\nmethod achieves a new state-of-the-art in event-based 3D reconstruction."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10592",
    "c_title":[
      "CameraCtrl II: Dynamic Scene Exploration via Camera-controlled Video\n  Diffusion Models"
    ],
    "c_abstract":[
      "This paper introduces CameraCtrl II, a framework that enables large-scale\ndynamic scene exploration through a camera-controlled video diffusion model.\nPrevious camera-conditioned video generative models suffer from diminished\nvideo dynamics and limited range of viewpoints when generating videos with\nlarge camera movement. We take an approach that progressively expands the\ngeneration of dynamic scenes -- first enhancing dynamic content within\nindividual video clip, then extending this capability to create seamless\nexplorations across broad viewpoint ranges. Specifically, we construct a\ndataset featuring a large degree of dynamics with camera parameter annotations\nfor training while designing a lightweight camera injection module and training\nscheme to preserve dynamics of the pretrained models. Building on these\nimproved single-clip techniques, we enable extended scene exploration by\nallowing users to iteratively specify camera trajectories for generating\ncoherent video sequences. Experiments across diverse scenarios demonstrate that\nCameraCtrl Ii enables camera-controlled dynamic scene synthesis with\nsubstantially wider spatial exploration than previous approaches."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-159",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15062",
    "b_title":[
      "Exact Fit Attention in Node-Holistic Graph Convolutional Network for\n  Improved EEG-Based Driver Fatigue Detection"
    ],
    "b_abstract":[
      "EEG-based fatigue monitoring can effectively reduce the incidence of related\ntraffic accidents. In the past decade, with the advancement of deep learning,\nconvolutional neural networks (CNN) have been increasingly used for EEG signal\nprocessing. However, due to the data's non-Euclidean characteristics, existing\nCNNs may lose important spatial information from EEG, specifically channel\ncorrelation. Thus, we propose the node-holistic graph convolutional network\n(NHGNet), a model that uses graphic convolution to dynamically learn each\nchannel's features. With exact fit attention optimization, the network captures\ninter-channel correlations through a trainable adjacency matrix. The\ninterpretability is enhanced by revealing critical areas of brain activity and\ntheir interrelations in various mental states. In validations on two public\ndatasets, NHGNet outperforms the SOTAs. Specifically, in the intra-subject,\nNHGNet improved detection accuracy by at least 2.34% and 3.42%, and in the\ninter-subjects, it improved by at least 2.09% and 15.06%. Visualization\nresearch on the model revealed that the central parietal area plays an\nimportant role in detecting fatigue levels, whereas the frontal and temporal\nlobes are essential for maintaining vigilance."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14809",
    "c_title":[
      "PREM: Privately Answering Statistical Queries with Relative Error"
    ],
    "c_abstract":[
      "We introduce $\\mathsf{PREM}$ (Private Relative Error Multiplicative weight\nupdate), a new framework for generating synthetic data that achieves a relative\nerror guarantee for statistical queries under $(\\varepsilon, \\delta)$\ndifferential privacy (DP). Namely, for a domain ${\\cal X}$, a family ${\\cal F}$\nof queries $f : {\\cal X} \\to \\{0, 1\\}$, and $\\zeta > 0$, our framework yields a\nmechanism that on input dataset $D \\in {\\cal X}^n$ outputs a synthetic dataset\n$\\widehat{D} \\in {\\cal X}^n$ such that all statistical queries in ${\\cal F}$ on\n$D$, namely $\\sum_{x \\in D} f(x)$ for $f \\in {\\cal F}$, are within a $1 \\pm\n\\zeta$ multiplicative factor of the corresponding value on $\\widehat{D}$ up to\nan additive error that is polynomial in $\\log |{\\cal F}|$, $\\log |{\\cal X}|$,\n$\\log n$, $\\log(1\/\\delta)$, $1\/\\varepsilon$, and $1\/\\zeta$. In contrast, any\n$(\\varepsilon, \\delta)$-DP mechanism is known to require worst-case additive\nerror that is polynomial in at least one of $n, |{\\cal F}|$, or $|{\\cal X}|$.\nWe complement our algorithm with nearly matching lower bounds."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-160",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07307",
    "b_title":[
      "AttenST: A Training-Free Attention-Driven Style Transfer Framework with\n  Pre-Trained Diffusion Models"
    ],
    "b_abstract":[
      "While diffusion models have achieved remarkable progress in style transfer\ntasks, existing methods typically rely on fine-tuning or optimizing pre-trained\nmodels during inference, leading to high computational costs and challenges in\nbalancing content preservation with style integration. To address these\nlimitations, we introduce AttenST, a training-free attention-driven style\ntransfer framework. Specifically, we propose a style-guided self-attention\nmechanism that conditions self-attention on the reference style by retaining\nthe query of the content image while substituting its key and value with those\nfrom the style image, enabling effective style feature integration. To mitigate\nstyle information loss during inversion, we introduce a style-preserving\ninversion strategy that refines inversion accuracy through multiple resampling\nsteps. Additionally, we propose a content-aware adaptive instance\nnormalization, which integrates content statistics into the normalization\nprocess to optimize style fusion while mitigating the content degradation.\nFurthermore, we introduce a dual-feature cross-attention mechanism to fuse\ncontent and style features, ensuring a harmonious synthesis of structural\nfidelity and stylistic expression. Extensive experiments demonstrate that\nAttenST outperforms existing methods, achieving state-of-the-art performance in\nstyle transfer dataset."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07298",
    "c_title":[
      "ALLVB: All-in-One Long Video Understanding Benchmark"
    ],
    "c_abstract":[
      "From image to video understanding, the capabilities of Multi-modal LLMs\n(MLLMs) are increasingly powerful. However, most existing video understanding\nbenchmarks are relatively short, which makes them inadequate for effectively\nevaluating the long-sequence modeling capabilities of MLLMs. This highlights\nthe urgent need for a comprehensive and integrated long video understanding\nbenchmark to assess the ability of MLLMs thoroughly. To this end, we propose\nALLVB (ALL-in-One Long Video Understanding Benchmark). ALLVB's main\ncontributions include: 1) It integrates 9 major video understanding tasks.\nThese tasks are converted into video QA formats, allowing a single benchmark to\nevaluate 9 different video understanding capabilities of MLLMs, highlighting\nthe versatility, comprehensiveness, and challenging nature of ALLVB. 2) A fully\nautomated annotation pipeline using GPT-4o is designed, requiring only human\nquality control, which facilitates the maintenance and expansion of the\nbenchmark. 3) It contains 1,376 videos across 16 categories, averaging nearly 2\nhours each, with a total of 252k QAs. To the best of our knowledge, it is the\nlargest long video understanding benchmark in terms of the number of videos,\naverage duration, and number of QAs. We have tested various mainstream MLLMs on\nALLVB, and the results indicate that even the most advanced commercial models\nhave significant room for improvement. This reflects the benchmark's\nchallenging nature and demonstrates the substantial potential for development\nin long video understanding."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-161",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01599",
    "b_title":[
      "A temperate super-Jupiter imaged with JWST in the mid-infrared"
    ],
    "b_abstract":[
      "Of the ~25 directly imaged planets to date, all are younger than 500Myr and\nall but 6 are younger than 100Myr. Eps Ind A (HD209100, HIP108870) is a K5V\nstar of roughly solar age (recently derived as 3.7-5.7Gyr and\n3.5$^{+0.8}_{-1.3}$Gyr). A long-term radial velocity trend as well as an\nastrometric acceleration led to claims of a giant planet orbiting the nearby\nstar (3.6384$\\pm$0.0013pc). Here we report JWST coronagraphic images that\nreveal a giant exoplanet which is consistent with these radial and astrometric\nmeasurements, but inconsistent with the previously claimed planet properties.\nThe new planet has temperature ~275K, and is remarkably bright at 10.65um and\n15.50um. Non-detections between 3.5-5um indicate an unknown opacity source in\nthe atmosphere, possibly suggesting a high metallicity, high carbon-to-oxygen\nratio planet. The best-fit temperature of the planet is consistent with\ntheoretical thermal evolution models, which are previously untested at this\ntemperature range. The data indicates that this is likely the only giant planet\nin the system and we therefore refer to it as ``b\", despite it having\nsignificantly different orbital properties than the previously claimed planet\n``b\"."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.05694",
    "c_title":[
      "The discovery and characterization of Earth-crossing asteroid 2024\n  YR$_4$"
    ],
    "c_abstract":[
      "We describe observations and physical characteristics of Earth-crossing\nasteroid 2024 YR$_4$, discovered on 2024 December 27 by the Asteroid\nTerrestrial-impact Last Alert System. The asteroid has semi-major axis, $a$ =\n2.52 au, eccentricity, $e$ = 0.66, inclination $i$ = 3.41$^{\\circ}$, and a\n$\\sim$0.003 au Earth minimum orbit intersection distance. We obtained g, r, i,\nand Z imaging with the Gemini South\/Gemini Multi-Object Spectrograph on 2025\nFebruary 7. We measured a g-i spectral slope of 13$\\pm$3 $\\%$\/100 nm, and color\nindices g-r = 0.70$\\pm$0.10, r-i = 0.25$\\pm$0.06, i-Z = -0.27$\\pm$0.10. 2024\nYR$_4$ has a spectrum that best matches R-type and Sa-type asteroids and a\ndiameter of $\\sim$30-65 m using our measured absolute magnitude of\n23.9$\\pm$0.3, and assuming an albedo of 0.15-0.4. The lightcurve of 2024 YR$_4$\nshows $\\sim$0.4 mag variations with a rotation period of $\\sim$1170 s. We use\nphotometry of 2024 YR$_4$ from Gemini and other sources taken between 2024\nDecember to 2025 February to determine the asteroid's spin vector and shape,\nfinding that it has an oblate, $\\sim$3:1 a:c axial ratio and a pole direction\nof $\\lambda$, $\\beta$ = $\\sim$42$^{\\circ}$, $\\sim$-25$^{\\circ}$. Finally, we\ncompare the orbital elements of 2024 YR$_4$ with the NEO population model and\nfind that its most likely sources are resonances between the inner and central\nMain Belt."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-162",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00740",
    "b_title":[
      "FaceShot: Bring Any Character into Life"
    ],
    "b_abstract":[
      "In this paper, we present FaceShot, a novel training-free portrait animation\nframework designed to bring any character into life from any driven video\nwithout fine-tuning or retraining. We achieve this by offering precise and\nrobust reposed landmark sequences from an appearance-guided landmark matching\nmodule and a coordinate-based landmark retargeting module. Together, these\ncomponents harness the robust semantic correspondences of latent diffusion\nmodels to produce facial motion sequence across a wide range of character\ntypes. After that, we input the landmark sequences into a pre-trained\nlandmark-driven animation model to generate animated video. With this powerful\ngeneralization capability, FaceShot can significantly extend the application of\nportrait animation by breaking the limitation of realistic portrait landmark\ndetection for any stylized character and driven video. Also, FaceShot is\ncompatible with any landmark-driven animation model, significantly improving\noverall performance. Extensive experiments on our newly constructed character\nbenchmark CharacBench confirm that FaceShot consistently surpasses\nstate-of-the-art (SOTA) approaches across any character domain. More results\nare available at our project website https:\/\/faceshot2024.github.io\/faceshot\/."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08677",
    "c_title":[
      "OmniPaint: Mastering Object-Oriented Editing via Disentangled\n  Insertion-Removal Inpainting"
    ],
    "c_abstract":[
      "Diffusion-based generative models have revolutionized object-oriented image\nediting, yet their deployment in realistic object removal and insertion remains\nhampered by challenges such as the intricate interplay of physical effects and\ninsufficient paired training data. In this work, we introduce OmniPaint, a\nunified framework that re-conceptualizes object removal and insertion as\ninterdependent processes rather than isolated tasks. Leveraging a pre-trained\ndiffusion prior along with a progressive training pipeline comprising initial\npaired sample optimization and subsequent large-scale unpaired refinement via\nCycleFlow, OmniPaint achieves precise foreground elimination and seamless\nobject insertion while faithfully preserving scene geometry and intrinsic\nproperties. Furthermore, our novel CFD metric offers a robust, reference-free\nevaluation of context consistency and object hallucination, establishing a new\nbenchmark for high-fidelity image editing. Project page:\nhttps:\/\/yeates.github.io\/OmniPaint-Page\/"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-163",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16407",
    "b_title":[
      "Deep Feynman-Kac Methods for High-dimensional Semilinear Parabolic\n  Equations: Revisit"
    ],
    "b_abstract":[
      "Deep Feynman-Kac method was first introduced to solve parabolic partial\ndifferential equations(PDE) by Beck et al. (SISC, V.43, 2021), named Deep\nSplitting method since they trained the Neural Networks step by step in the\ntime direction. In this paper, we propose a new training approach with two\ndifferent features. Firstly, neural networks are trained at all time steps\nglobally, instead of step by step. Secondly, the training data are generated in\na new way, in which the method is consistent with a direct Monte Carlo scheme\nwhen dealing with a linear parabolic PDE. Numerical examples show that our\nmethod has significant improvement both in efficiency and accuracy."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03964",
    "c_title":[
      "A comparative study of uncertainty quantification methods in gust\n  response analysis of a Lift-Plus-Cruise eVTOL aircraft wing"
    ],
    "c_abstract":[
      "Wind gusts, being inherently stochastic, can significantly influence the\nsafety and performance of aircraft. This study investigates a three-dimensional\nuncertainty quantification (UQ) problem to explore how uncertainties in gust\nand flight conditions affect the structural response of a Lift-Plus-Cruise\neVTOL aircraft wing. The analysis employs an unsteady aeroelastic model with a\none-way coupling between a panel method aerodynamic solver and a shell analysis\nstructural solver to predict the wing's response under varying conditions.\nAdditionally, this paper presents a comparative evaluation of commonly used\nnon-intrusive UQ methods, including non-intrusive polynomial chaos, kriging,\nMonte Carlo, univariate dimension reduction, and gradient-enhanced univariate\ndimension reduction. These methods are assessed based on their effectiveness in\nestimating various risk measures-mean, standard deviation, and 95th\npercentile-of critical structural response outputs such as maximum tip\ndisplacement and average strain energy. The numerical results reveal\nsignificant variability in the structural response outputs, even under\nrelatively small ranges of uncertain inputs. This highlights the sensitivity of\nthe system to uncertainties in gust and flight conditions. Furthermore, the\nperformance of the implemented UQ methods varies significantly depending on the\nspecific risk measures and the quantity of interest being analyzed."
    ],
    "c_categories":[
      [
        "cs.CE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-164",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05959",
    "b_title":[
      "Estimation and Restoration of Unknown Nonlinear Distortion using\n  Diffusion"
    ],
    "b_abstract":[
      "The restoration of nonlinearly distorted audio signals, alongside the\nidentification of the applied memoryless nonlinear operation, is studied. The\npaper focuses on the difficult but practically important case in which both the\nnonlinearity and the original input signal are unknown. The proposed method\nuses a generative diffusion model trained unconditionally on guitar or speech\nsignals to jointly model and invert the nonlinear system at inference time.\nBoth the memoryless nonlinear function model and the restored audio signal are\nobtained as output. Successful example case studies are presented including\ninversion of hard and soft clipping, digital quantization, half-wave\nrectification, and wavefolding nonlinearities. Our results suggest that, out of\nthe nonlinear functions tested here, the cubic Catmull-Rom spline is best\nsuited to approximating these nonlinearities. In the case of guitar recordings,\ncomparisons with informed and supervised methods show that the proposed blind\nmethod is at least as good as they are in terms of objective metrics.\nExperiments on distorted speech show that the proposed blind method outperforms\ngeneral-purpose speech enhancement techniques and restores the original voice\nquality. The proposed method can be applied to audio effects modeling,\nrestoration of music and speech recordings, and characterization of analog\nrecording media."
    ],
    "b_categories":[
      [
        "eess.AS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01183",
    "c_title":[
      "DiffRhythm: Blazingly Fast and Embarrassingly Simple End-to-End\n  Full-Length Song Generation with Latent Diffusion"
    ],
    "c_abstract":[
      "Recent advancements in music generation have garnered significant attention,\nyet existing approaches face critical limitations. Some current generative\nmodels can only synthesize either the vocal track or the accompaniment track.\nWhile some models can generate combined vocal and accompaniment, they typically\nrely on meticulously designed multi-stage cascading architectures and intricate\ndata pipelines, hindering scalability. Additionally, most systems are\nrestricted to generating short musical segments rather than full-length songs.\nFurthermore, widely used language model-based methods suffer from slow\ninference speeds. To address these challenges, we propose DiffRhythm, the first\nlatent diffusion-based song generation model capable of synthesizing complete\nsongs with both vocal and accompaniment for durations of up to 4m45s in only\nten seconds, maintaining high musicality and intelligibility. Despite its\nremarkable capabilities, DiffRhythm is designed to be simple and elegant: it\neliminates the need for complex data preparation, employs a straightforward\nmodel structure, and requires only lyrics and a style prompt during inference.\nAdditionally, its non-autoregressive structure ensures fast inference speeds.\nThis simplicity guarantees the scalability of DiffRhythm. Moreover, we release\nthe complete training code along with the pre-trained model on large-scale data\nto promote reproducibility and further research."
    ],
    "c_categories":[
      [
        "eess.AS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-165",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19084",
    "b_title":[
      "Laser: Efficient Language-Guided Segmentation in Neural Radiance Fields"
    ],
    "b_abstract":[
      "In this work, we propose a method that leverages CLIP feature distillation,\nachieving efficient 3D segmentation through language guidance. Unlike previous\nmethods that rely on multi-scale CLIP features and are limited by processing\nspeed and storage requirements, our approach aims to streamline the workflow by\ndirectly and effectively distilling dense CLIP features, thereby achieving\nprecise segmentation of 3D scenes using text. To achieve this, we introduce an\nadapter module and mitigate the noise issue in the dense CLIP feature\ndistillation process through a self-cross-training strategy. Moreover, to\nenhance the accuracy of segmentation edges, this work presents a low-rank\ntransient query attention mechanism. To ensure the consistency of segmentation\nfor similar colors under different viewpoints, we convert the segmentation task\ninto a classification task through label volume, which significantly improves\nthe consistency of segmentation in color-similar areas. We also propose a\nsimplified text augmentation strategy to alleviate the issue of ambiguity in\nthe correspondence between CLIP features and text. Extensive experimental\nresults show that our method surpasses current state-of-the-art technologies in\nboth training speed and performance. Our code is available on:\nhttps:\/\/github.com\/xingy038\/Laser.git."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00521",
    "c_title":[
      "2DMCG:2DMambawith Change Flow Guidance for Change Detection in Remote\n  Sensing"
    ],
    "c_abstract":[
      "Remote sensing change detection (CD) has made significant advancements with\nthe adoption of Convolutional Neural Networks (CNNs) and Transformers. While\nCNNs offer powerful feature extraction, they are constrained by receptive field\nlimitations, and Transformers suffer from quadratic complexity when processing\nlong sequences, restricting scalability. The Mamba architecture provides an\nappealing alternative, offering linear complexity and high parallelism.\nHowever, its inherent 1D processing structure causes a loss of spatial\ninformation in 2D vision tasks. This paper addresses this limitation by\nproposing an efficient framework based on a Vision Mamba variant that enhances\nits ability to capture 2D spatial information while maintaining the linear\ncomplexity characteristic of Mamba. The framework employs a 2DMamba encoder to\neffectively learn global spatial contextual information from multi-temporal\nimages. For feature fusion, we introduce a 2D scan-based, channel-parallel\nscanning strategy combined with a spatio-temporal feature fusion method, which\nadeptly captures both local and global change information, alleviating spatial\ndiscontinuity issues during fusion. In the decoding stage, we present a feature\nchange flow-based decoding method that improves the mapping of feature change\ninformation from low-resolution to high-resolution feature maps, mitigating\nfeature shift and misalignment. Extensive experiments on benchmark datasets\nsuch as LEVIR-CD+ and WHU-CD demonstrate the superior performance of our\nframework compared to state-of-the-art methods, showcasing the potential of\nVision Mamba for efficient and accurate remote sensing change detection."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-166",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04698",
    "b_title":[
      "ConceptMaster: Multi-Concept Video Customization on Diffusion\n  Transformer Models Without Test-Time Tuning"
    ],
    "b_abstract":[
      "Text-to-video generation has made remarkable advancements through diffusion\nmodels. However, Multi-Concept Video Customization (MCVC) remains a significant\nchallenge. We identify two key challenges in this task: 1) the identity\ndecoupling problem, where directly adopting existing customization methods\ninevitably mix attributes when handling multiple concepts simultaneously, and\n2) the scarcity of high-quality video-entity pairs, which is crucial for\ntraining such a model that represents and decouples various concepts well. To\naddress these challenges, we introduce ConceptMaster, an innovative framework\nthat effectively tackles the critical issues of identity decoupling while\nmaintaining concept fidelity in customized videos. Specifically, we introduce a\nnovel strategy of learning decoupled multi-concept embeddings that are injected\ninto the diffusion models in a standalone manner, which effectively guarantees\nthe quality of customized videos with multiple identities, even for highly\nsimilar visual concepts. To further overcome the scarcity of high-quality MCVC\ndata, we carefully establish a data construction pipeline, which enables\nsystematic collection of precise multi-concept video-entity data across diverse\nconcepts. A comprehensive benchmark is designed to validate the effectiveness\nof our model from three critical dimensions: concept fidelity, identity\ndecoupling ability, and video generation quality across six different concept\ncomposition scenarios. Extensive experiments demonstrate that our ConceptMaster\nsignificantly outperforms previous approaches for this task, paving the way for\ngenerating personalized and semantically accurate videos across multiple\nconcepts."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.12249",
    "c_title":[
      "Minuscule Cell Detection in AS-OCT Images with Progressive Field-of-View\n  Focusing"
    ],
    "c_abstract":[
      "Anterior Segment Optical Coherence Tomography (AS-OCT) is an emerging imaging\ntechnique with great potential for diagnosing anterior uveitis, a\nvision-threatening ocular inflammatory condition. A hallmark of this condition\nis the presence of inflammatory cells in the eye's anterior chamber, and\ndetecting these cells using AS-OCT images has attracted research interest.\nWhile recent efforts aim to replace manual cell detection with automated\ncomputer vision approaches, detecting extremely small (minuscule) objects in\nhigh-resolution images, such as AS-OCT, poses substantial challenges: (1) each\ncell appears as a minuscule particle, representing less than 0.005\\% of the\nimage, making the detection difficult, and (2) OCT imaging introduces\npixel-level noise that can be mistaken for cells, leading to false positive\ndetections. To overcome these challenges, we propose a minuscule cell detection\nframework through a progressive field-of-view focusing strategy. This strategy\nsystematically refines the detection scope from the whole image to a target\nregion where cells are likely to be present, and further to minuscule regions\npotentially containing individual cells. Our framework consists of two modules.\nFirst, a Field-of-Focus module uses a vision foundation model to segment the\ntarget region. Subsequently, a Fine-grained Object Detection module introduces\na specialized Minuscule Region Proposal followed by a Spatial Attention Network\nto distinguish individual cells from noise within the segmented region.\nExperimental results demonstrate that our framework outperforms\nstate-of-the-art methods for cell detection, providing enhanced efficacy for\nclinical applications. Our code is publicly available at:\nhttps:\/\/github.com\/joeybyc\/MCD."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-167",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04440",
    "b_title":[
      "RSAR: Restricted State Angle Resolver and Rotated SAR Benchmark"
    ],
    "b_abstract":[
      "Rotated object detection has made significant progress in the optical remote\nsensing. However, advancements in the Synthetic Aperture Radar (SAR) field are\nlaggard behind, primarily due to the absence of a large-scale dataset.\nAnnotating such a dataset is inefficient and costly. A promising solution is to\nemploy a weakly supervised model (e.g., trained with available horizontal boxes\nonly) to generate pseudo-rotated boxes for reference before manual calibration.\nUnfortunately, the existing weakly supervised models exhibit limited accuracy\nin predicting the object's angle. Previous works attempt to enhance angle\nprediction by using angle resolvers that decouple angles into cosine and sine\nencodings. In this work, we first reevaluate these resolvers from a unified\nperspective of dimension mapping and expose that they share the same\nshortcomings: these methods overlook the unit cycle constraint inherent in\nthese encodings, easily leading to prediction biases. To address this issue, we\npropose the Unit Cycle Resolver, which incorporates a unit circle constraint\nloss to improve angle prediction accuracy. Our approach can effectively improve\nthe performance of existing state-of-the-art weakly supervised methods and even\nsurpasses fully supervised models on existing optical benchmarks (i.e.,\nDOTA-v1.0 dataset). With the aid of UCR, we further annotate and introduce\nRSAR, the largest multi-class rotated SAR object detection dataset to date.\nExtensive experiments on both RSAR and optical datasets demonstrate that our\nUCR enhances angle prediction accuracy. Our dataset and code can be found at:\nhttps:\/\/github.com\/zhasion\/RSAR."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01654",
    "c_title":[
      "A Shared Encoder Approach to Multimodal Representation Learning"
    ],
    "c_abstract":[
      "Multimodal representation learning has demonstrated remarkable potential in\nenabling models to process and integrate diverse data modalities, such as text\nand images, for improved understanding and performance. While the medical\ndomain can benefit significantly from this paradigm, the scarcity of paired\nmultimodal data and reliance on proprietary or pretrained encoders pose\nsignificant challenges. In this work, we present a shared encoder framework for\nmultimodal representation learning tailored to the medical domain. Our approach\nemploys a single set of encoder parameters shared across modalities, augmented\nwith learnable modality features. Empirical results demonstrate that our shared\nencoder idea achieves superior performance compared to separate\nmodality-specific encoders, demonstrating improved generalization in\ndata-constrained settings. Notably, the performance gains are more pronounced\nwith fewer training examples, underscoring the efficiency of our shared encoder\nframework for real-world medical applications with limited data. Our code and\nexperiment setup are available at\nhttps:\/\/github.com\/VectorInstitute\/shared_encoder."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-168",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03734",
    "b_title":[
      "Improving noisy free-energy measurements by adding more noise"
    ],
    "b_abstract":[
      "Estimating free-energy differences using nonequilibrium work relations, such\nas the Jarzynski equality, is hindered by poor convergence when work\nfluctuations are large. For systems governed by overdamped Langevin dynamics,\nwe propose the counterintuitive approach of adding noise in order to increase\nthe precision of such calculations. By introducing additional stochastic\nfluctuations to the system and rescaling its potential energy, we leave the\nthermodynamics of the system unchanged while increasing its relaxation rate.\nFor a given time-dependent protocol this modification reduces dissipated work,\nleading to more accurate free-energy estimates. We demonstrate this principle\nusing computer simulations applied to two model systems. However, the regime of\napplicability of this strategy is likely limited, because it requires control\nof the system's potential energy in a way that is feasible in only a few\nexperimental settings."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.10692",
    "c_title":[
      "Instabilities, thermal fluctuations, defects and dislocations in the\n  crystal-$R_I$-$R_{II}$ rotator phase transitions of n-alkanes"
    ],
    "c_abstract":[
      "The theoretical study of instabilities, thermal fluctuations, and topological\ndefects in the crystal-rotator-I-rotator-II ($X-R_{I}-R_{II}$) phase\ntransitions of n-alkanes has been conducted. First, we examine the nature of\nthe $R_{I}-R_{II}$ phase transition in nanoconfined alkanes. We propose that\nunder confined conditions, the presence of quenched random orientational\ndisorder makes the $R_{I}$ phase unstable. This disorder-mediated transition\nfalls within the Imry-Ma universality class. Next, we discuss the role of\nthermal fluctuations in certain rotator phases, as well as the influence of\ndislocations on the $X-R_I$ phase transition. Our findings indicate that the\nHerringbone order in the $X$-phase and the Hexatic order in the $R_{II}$-phase\nexhibit quasi-long-range characteristics. Furthermore, we find that in two\ndimensions, the unbinding of dislocations does not result in a disordered\nliquid state."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-169",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06126",
    "b_title":[
      "Limit of quasilinear equations and related extremal problems"
    ],
    "b_abstract":[
      "We perform a complete analysis of the limiting behaviour of a class of\nquasilinear problems with Dirichlet boundary data g. We show that the Lipschitz\nconstant of g plays a role in controlling the Gamma-convergence of the natural\nenergies. However the solutions converge uniformly to solution of a limiting\nequation irrelevant to the Lipschitz constant of g. The limiting equation has\nno coercivity in u. We prove that the limiting equation admits a weak\ncomparison principle and has a unique viscosity solution. We also obtain a\nPoincare inequality in the Sobolev-Orlicz space for discontinuous operator,\nwhich paves the way for our study of an extremal problem where its operator\nbecomes unbounded in a subdomain. Upon giving proper meaning to its solution,\nwe show that the extremal problem has a unique solution. It turns out the\nsolution has sufficient continuity, although operator is discontinuous. In the\nappendix we provide some technical inequalities which play crucial roles in the\nproof of uniqueness and we believe will be of independent interest."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.12804",
    "c_title":[
      "A remark on isolated removable singularity of harmonic maps in dimension\n  two"
    ],
    "c_abstract":[
      "For a ball $B_R(0)\\subset\\mathbb{R}^2$, we provide sufficient conditions such\nthat a harmonic map $u\\in C^\\infty(B_R(0)\\setminus\\{0\\}, N)$, with a\nself-similar bound on its gradient, belongs to $C^\\infty(B_R(0))$. Those\nconditions also guarantee the triviality of such harmonic maps when $R=\\infty$."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-170",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15722",
    "b_title":[
      "INRet: A General Framework for Accurate Retrieval of INRs for Shapes"
    ],
    "b_abstract":[
      "Implicit neural representations (INRs) have become an important method for\nencoding various data types, such as 3D objects or scenes, images, and videos.\nThey have proven to be particularly effective at representing 3D content, e.g.,\n3D scene reconstruction from 2D images, novel 3D content creation, as well as\nthe representation, interpolation, and completion of 3D shapes. With the\nwidespread generation of 3D data in an INR format, there is a need to support\neffective organization and retrieval of INRs saved in a data store. A key\naspect of retrieval and clustering of INRs in a data store is the formulation\nof similarity between INRs that would, for example, enable retrieval of similar\nINRs using a query INR. In this work, we propose INRet, a method for\ndetermining similarity between INRs that represent shapes, thus enabling\naccurate retrieval of similar shape INRs from an INR data store. INRet flexibly\nsupports different INR architectures such as INRs with octree grids, triplanes,\nand hash grids, as well as different implicit functions including\nsigned\/unsigned distance function and occupancy field. We demonstrate that our\nmethod is more general and accurate than the existing INR retrieval method,\nwhich only supports simple MLP INRs and requires the same architecture between\nthe query and stored INRs. Furthermore, compared to converting INRs to other\nrepresentations (e.g., point clouds or multi-view images) for 3D shape\nretrieval, INRet achieves higher accuracy while avoiding the conversion\noverhead."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10545",
    "c_title":[
      "From Linear to Spline-Based Classification:Developing and Enhancing SMPA\n  for Noisy Non-Linear Datasets"
    ],
    "c_abstract":[
      "Building upon the concepts and mechanisms used for the development in Moving\nPoints Algorithm, we will now explore how non linear decision boundaries can be\ndeveloped for classification tasks. First we will look at the classification\nperformance of MPA and some minor developments in the original algorithm. We\nthen discuss the concepts behind using cubic splines for classification with a\nsimilar learning mechanism and finally analyze training results on synthetic\ndatasets with known properties."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-171",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13738",
    "b_title":[
      "Asymptotics of Transversality in Periodic Curves of Quadratic Rational\n  Maps"
    ],
    "b_abstract":[
      "We compute the Euler characteristic of the moduli space of quadratic rational\nmaps with a periodic marked critical point of a given period."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.16066",
    "c_title":[
      "Nagumo's Theorem for Dubovitskij-Miljutin Tangent Cones"
    ],
    "c_abstract":[
      "This paper focuses on a class of additive perturbations in dynamical systems.\nAn equivalence statement for this construction is discovered, and consequently,\na method of checking a notion of positive invariance with perturbation. The\nresulting conclusion is an equivalence between a more strict definition of\npositive invariance, based on a perturbation extension of the system and the\nDubovitskij-Miljutin tangent cone."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-172",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06397",
    "b_title":[
      "Factor Modelling for Biclustering Large-dimensional Matrix-valued Time\n  Series"
    ],
    "b_abstract":[
      "A novel unsupervised learning method is proposed in this paper for\nbiclustering large-dimensional matrix-valued time series based on an entirely\nnew latent two-way factor structure. Each block cluster is characterized by its\nown row and column cluster-specific factors in addition to some common matrix\nfactors which impact on all the matrix time series. We first estimate the\nglobal loading spaces by projecting the observation matrices onto the row or\ncolumn loading space corresponding to common factors. The loading spaces for\ncluster-specific factors are then further recovered by projecting the\nobservation matrices onto the orthogonal complement space of the estimated\nglobal loading spaces. To identify the latent row\/column clusters\nsimultaneously for matrix-valued time series, we provide a $K$-means algorithm\nbased on the estimated row\/column factor loadings of the cluster-specific weak\nfactors. Theoretically, we derive faster convergence rates for global loading\nmatrices than those of the state-of-the-art methods available in the literature\nunder mild conditions. We also propose an one-pass eigenvalue-ratio method to\nestimate the numbers of global and cluster-specific factors. The consistency\nwith explicit convergence rates is also established for the estimators of the\nlocal loading matrices, the factor numbers and the latent cluster memberships.\nNumerical experiments with both simulated data as well as a real data example\nare also reported to illustrate the usefulness of our proposed method."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.16874",
    "c_title":[
      "A dynamic copula model for probabilistic forecasting of non-Gaussian\n  multivariate time series"
    ],
    "c_abstract":[
      "Multivariate time series (MTS) data often include a heterogeneous mix of\nnon-Gaussian distributional features (asymmetry, multimodality, heavy tails)\nand data types (continuous and discrete variables). Traditional MTS methods\nbased on convenient parametric distributions are typically ill-equipped to\nmodel this heterogeneity. Copula models provide an appealing alternative, but\npresent significant obstacles for fully Bayesian inference and probabilistic\nforecasting. To overcome these challenges, we propose a novel and general\nstrategy for posterior approximation in MTS copula models and apply it to a\nGaussian copula built from a dynamic factor model. This framework provides\nscalable, fully Bayesian inference for cross-sectional and serial dependencies\nand nonparametrically learns heterogeneous marginal distributions. We validate\nthis approach by establishing posterior consistency and confirm excellent\nfinite-sample performance even under model misspecification using simulated\ndata. We apply our method to crime count and macroeconomic MTS data and find\nsuperior probabilistic forecasting performance compared to popular MTS models.\nThese results demonstrate that the proposed method is a versatile,\ngeneral-purpose utility for probabilistic forecasting of MTS that works well\nacross of range of applications with minimal user input."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-173",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08629",
    "b_title":[
      "Optical probes of coherence in two dimensional Bose gases of polaritons"
    ],
    "b_abstract":[
      "Due to their photonic components, exciton-polariton systems provide a\nconvenient platform to study the coherence properties of weakly-interacting\nBose gases and the Bose-Einstein condensate transition. In particular, optical\ninterferometry enables the measurement of the first-order coherence function\nwhich provides insight into the phase of the system. In this paper, we analyze\nthe buildup of coherence in finite-sized, noninteracting, equilibrium Bose\ngases through the condensate fraction and the related coherent fraction,\ndefined via the first-order coherence function. Our results provide a baseline\nto compare against experimental data. Discrepancies may indicate where\ninteracting or nonequilibrium models are necessary to describe the system. In\nthe normal phase, before the Bose-Einstein condensate transition, Bose gases\nexhibit partial spatial and temporal coherence. This significantly alters the\nparaxial propagation and interference of optical signals from exciton-polariton\nsystems. Therefore, we also analyze diffraction related to the introduction of\napertures and time-delay between interferometry arms, given the partial\ncoherence of the source. Comparison to experiment shows remarkable agreement\nwith the noninteracting Bose gas theory, even approaching the quasi-condensate\nregime."
    ],
    "b_categories":[
      [
        "cond-mat.quant-gas"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.16140",
    "c_title":[
      "Exactly Solvable Models of Interacting Chiral Bosons and Fermions on a\n  Lattice"
    ],
    "c_abstract":[
      "We consider one-dimensional theories of chiral fermions and bosons on a\nlattice, which arise as edge states of two-dimensional topological matter\nbreaking time-reversal invariance. We show that hard core bosons or their spin\nchain equivalent exhibit properties that are similar to free fermions, solving\nthe many-body problem exactly. For fermions, we study the effect of a static\nimpurity exactly and show the orthogonality catastrophe in the continuum limit\nvia bosonization. The interacting many-fermion problem in the continuum limit\nis solved exactly using simple momentum conservation arguments."
    ],
    "c_categories":[
      [
        "cond-mat.quant-gas"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-174",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18739",
    "b_title":[
      "Singleshot Multispectral Imaging via a Chromatic Metalens Array"
    ],
    "b_abstract":[
      "Real time, singleshot multispectral imaging systems are crucial for\nenvironment monitoring and biomedical imaging. Most singleshot multispectral\nimagers rely on complex computational backends, which precludes real time\noperations. In this work, we leverage the spectral selectivity afforded by\nengineered photonic materials to perform bulk of the multispectral data\nextraction in the optical domain, thereby circumventing the need for heavy\nbackend computation. We use our imager to extract multispectral data for two\nreal world objects at 8 predefined spectral channels in the 400 to 900 nm\nwavelength range. For both objects, an RGB image constructed using extracted\nmultispectral data shows good agreement with an image taken using a phone\ncamera, thereby validating our imaging approach. We believe that the proposed\nsystem can provide new avenues for the development of highly compact and low\nlatency multispectral imaging technologies."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03514",
    "c_title":[
      "Hosting Second Order Exceptional Point in an All-lossy Dual-Core\n  Photonic Crystal Fiber"
    ],
    "c_abstract":[
      "We report an all-lossy index-guided dual-core photonic crystal fiber (PCF)\nthat hosts a second-order exceptional point (EP) in the systems parameter\nspace. By appropriately selecting a parametric encirclement scheme around the\nEP, the interaction between the coupled modes has been studied, and the mode\nconversion is subsequently observed."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-175",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00485",
    "b_title":[
      "Homomorphism Expressivity of Spectral Invariant Graph Neural Networks"
    ],
    "b_abstract":[
      "Graph spectra are an important class of structural features on graphs that\nhave shown promising results in enhancing Graph Neural Networks (GNNs). Despite\ntheir widespread practical use, the theoretical understanding of the power of\nspectral invariants -- particularly their contribution to GNNs -- remains\nincomplete. In this paper, we address this fundamental question through the\nlens of homomorphism expressivity, providing a comprehensive and quantitative\nanalysis of the expressive power of spectral invariants. Specifically, we prove\nthat spectral invariant GNNs can homomorphism-count exactly a class of specific\ntree-like graphs which we refer to as parallel trees. We highlight the\nsignificance of this result in various contexts, including establishing a\nquantitative expressiveness hierarchy across different architectural variants,\noffering insights into the impact of GNN depth, and understanding the subgraph\ncounting capabilities of spectral invariant GNNs. In particular, our results\nsignificantly extend Arvind et al. (2024) and settle their open questions.\nFinally, we generalize our analysis to higher-order GNNs and answer an open\nquestion raised by Zhang et al. (2024)."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01157",
    "c_title":[
      "Unify and Anchor: A Context-Aware Transformer for Cross-Domain Time\n  Series Forecasting"
    ],
    "c_abstract":[
      "The rise of foundation models has revolutionized natural language processing\nand computer vision, yet their best practices to time series forecasting\nremains underexplored. Existing time series foundation models often adopt\nmethodologies from these fields without addressing the unique characteristics\nof time series data. In this paper, we identify two key challenges in\ncross-domain time series forecasting: the complexity of temporal patterns and\nsemantic misalignment. To tackle these issues, we propose the ``Unify and\nAnchor\" transfer paradigm, which disentangles frequency components for a\nunified perspective and incorporates external context as domain anchors for\nguided adaptation. Based on this framework, we introduce ContexTST, a\nTransformer-based model that employs a time series coordinator for structured\nrepresentation and the Transformer blocks with a context-informed\nmixture-of-experts mechanism for effective cross-domain generalization.\nExtensive experiments demonstrate that ContexTST advances state-of-the-art\nforecasting performance while achieving strong zero-shot transferability across\ndiverse domains."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-176",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15222",
    "b_title":[
      "Model Hubs and Beyond: Analyzing Model Popularity, Performance, and\n  Documentation"
    ],
    "b_abstract":[
      "With the massive surge in ML models on platforms like Hugging Face, users\noften lose track and struggle to choose the best model for their downstream\ntasks, frequently relying on model popularity indicated by download counts,\nlikes, or recency. We investigate whether this popularity aligns with actual\nmodel performance and how the comprehensiveness of model documentation\ncorrelates with both popularity and performance. In our study, we evaluated a\ncomprehensive set of 500 Sentiment Analysis models on Hugging Face. This\nevaluation involved massive annotation efforts, with human annotators\ncompleting nearly 80,000 annotations, alongside extensive model training and\nevaluation. Our findings reveal that model popularity does not necessarily\ncorrelate with performance. Additionally, we identify critical inconsistencies\nin model card reporting: approximately 80\\% of the models analyzed lack\ndetailed information about the model, training, and evaluation processes.\nFurthermore, about 88\\% of model authors overstate their models' performance in\nthe model cards. Based on our findings, we provide a checklist of guidelines\nfor users to choose good models for downstream tasks."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04511",
    "c_title":[
      "Beyond Sample-Level Feedback: Using Reference-Level Feedback to Guide\n  Data Synthesis"
    ],
    "c_abstract":[
      "LLMs demonstrate remarkable capabilities in following natural language\ninstructions, largely due to instruction-tuning on high-quality datasets. While\nsynthetic data generation has emerged as a scalable approach for creating such\ndatasets, maintaining consistent quality standards remains challenging. Recent\napproaches incorporate feedback to improve data quality, but typically operate\nat the sample level, generating and applying feedback for each response\nindividually. In this work, we propose Reference-Level Feedback, a novel\nmethodology that instead collects feedback based on high-quality reference\nsamples from carefully curated seed data. We use this feedback to capture rich\nsignals of desirable characteristics and propagate it throughout the data\nsynthesis process. We present REFED, a dataset of 10K instruction-response\npairs synthesized using such feedback. We demonstrate the effectiveness of our\napproach by showing that Llama-3.1-8B-Instruct finetuned on REFED achieves\nstate-of-the-art performance among similar-sized SFT-based models on AlpacaEval\n2.0 and strong results on Arena-Hard. Through extensive experiments, we show\nthat our approach consistently outperforms traditional sample-level feedback\nmethods with significantly fewer feedback collections and improves performance\nacross different model architectures."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-177",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09323",
    "b_title":[
      "Three non-zero solutions of a Neumann eigenvalue problems involving the\n  fractional p-Laplacian"
    ],
    "b_abstract":[
      "In the present paper, we establish a multiplicity result for a following\nclass of nonlocal Neumann eigenvalue problems involving the fractional\np-Laplacian.\n  \\begin{align} \\begin{cases}\n  (-\\Delta)^{s}_{p}u + a(x) \\abs{u}^{p-2}u =\\lambda h(x,u) & \\text {in }\n\\Omega,\n  \\mathcal{N}_{s,p}u=0 & \\text {in } \\mathbb{R}^N \\setminus \\overline{\\Omega},\n  \\end{cases}\n  \\end{align}\n  Precisely, we demonstrate the existence of an open interval for positive\neigenvalues $\\lambda$, for which the problem has at least three non-zero\nsolutions in $W^{s,p}_{\\Omega}.$"
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.14577",
    "c_title":[
      "Regularity of Supersolutions"
    ],
    "c_abstract":[
      "The regularity for the supersolutions of the Evolutionary p-Laplace Equation\nis considered. In particular,the equivalence of viscosity supersolutions and\np-supercaloric functions (lower semicontinuous supersolutions defined via a\ncomparison principle) is considered. Bounded viscosity supersolutions are, in\nfact, weak supersolutions belonging to a natural Sobolev Space."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-178",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05876",
    "b_title":[
      "Morse index and symmetry-breaking bifurcation of positive solutions to\n  the one-dimensional Liouville type equation with a step function weight"
    ],
    "b_abstract":[
      "\\begin{equation*}\n  \\left\\{\n  \\begin{array}{l}\n  u'' + \\lambda h(x,\\alpha) e^u = 0, \\quad x \\in (-1,1), \\\\[1ex]\n  u(-1) = u(1) = 0,\n  \\end{array}\n  \\right. \\end{equation*} where $\\lambda>0$, $0<\\alpha<1$, $h(x,\\alpha)=0$ for\n$|x|<\\alpha$, and $h(x,\\alpha)=1$ for $\\alpha \\le |x| \\le 1$. We compute the\nMorse index of positive even solutions, and then we prove the existence of an\nunbounded connected set of positive non-even solutions emanating from a\nsymmetry-breaking bifurcation point."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.10351",
    "c_title":[
      "Energy release and Griffith's criterion for phase-field fracture"
    ],
    "c_abstract":[
      "Phase field evolutions are obtained by means of time discrete schemes,\nproviding (or selecting) at each time step an equilibrium configuration of the\nsystem, which is usually computed by descent methods for the free energy\n(e.g.staggered and monolithic schemes) under a suitable irreversibility\nconstraint on the phase-field parameter. We study in detail the time continuous\nlimits of these evolutions considering monotonicity as irreversibility\nconstraint and providing a general result, which holds independently of the\nscheme employed in the incremental problem. In particular, we show that in the\nsteady state regime the limit evolution is simultaneous (in displacement and\nphase field parameter) and satisfies Griffith's criterion in terms of toughness\nand phase field energy release rate. In the unsteady regime the limit evolution\nmay instead depend on the adopted scheme and Griffith's criterion may not hold.\nWe prove also the thermodynamical consistency of the monotonicity constraint\nover the whole evolution, and we study the system of PDEs (actually, a weak\nvariational inequality) in the steady state regime. Technically, the proof\nemploys a suitable reparametrization of the time discrete points, whose\nKuratowski limit characterizes the set of steady state propagation. The study\nof the quasi-static time continuous limit relies on the strong convergence of\nthe phase field function together with the convergence of the power identity."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-179",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17679",
    "b_title":[
      "Rotational Excitation of Vinyl Cyanide by Collisions with Helium Atoms\n  at Low Temperature"
    ],
    "b_abstract":[
      "Among the numerous molecular systems found in the interstellar medium (ISM),\nvinyl cyanide is the first identified olephinic nitrile. While it has been\nobserved in various sources, its detection in Sgr B2 is notable as the\n2$_{11}$-2$_{12}$ rotational transition exhibits maser features. This indicates\nthat local thermodynamic equilibrium conditions are not fulfilled, and an\naccurate estimation of the molecular abundance in such conditions involves\nsolving the statistical equilibrium equations taking into account the\ncompetition between the radiative and collisional processes. This in turn\nrequires the knowledge of rotational excitation data for collisions with the\nmost abundant species - He or H$_2$. In this paper the first three-dimensional\nCH$_2$CHCN - He potential energy surface is computed using explicitly\ncorrelated coupled-cluster theory [(CCSD(T)-F12] with a combination of two\nbasis sets. Scattering calculations of the rotational (de-)excitation of\nCH$_2$CHCN induced by He atoms are performed with the quantum-mechanical\nclose-coupling method in the low-energy regime. Rotational state-to-state cross\nsections derived from these calculations are used to compute the corresponding\nrate coefficients. The interaction potential exhibits a high anisotropy, with a\nglobal minimum of $-53.5$ cm$^{-1}$ and multiple local minima. Collisional\ncross sections are calculated for total energies up to 100 cm$^{-1}$. By\nthermally averaging the cross-sections, collisional rate coefficients are\ndetermined for temperatures up to 20 K. A propensity favouring the transitions\nwith $\\Delta k_a=0$ is observed."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04965",
    "c_title":[
      "Unveiling IZw18 age's mystery: Resolved Stellar Populations and Star\n  Formation History Study with JWST\/NIRCam"
    ],
    "c_abstract":[
      "With its peculiar appearance, I Zw 18 has long been considered a unique\nexample of a young galaxy in the nearby Universe. In this paper, we summarize\nthe observational history of this famous galaxy, discuss the controversies\nsurrounding its evolutionary state, and present new insights gained from\nJWST\/NIRCam observations. These recent findings shed light on one of the most\nintriguing mysteries in extragalactic astronomy."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-180",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16906",
    "b_title":[
      "AutoLogi: Automated Generation of Logic Puzzles for Evaluating Reasoning\n  Abilities of Large Language Models"
    ],
    "b_abstract":[
      "While logical reasoning evaluation of Large Language Models (LLMs) has\nattracted significant attention, existing benchmarks predominantly rely on\nmultiple-choice formats that are vulnerable to random guessing, leading to\noverestimated performance and substantial performance fluctuations. To obtain\nmore accurate assessments of models' reasoning capabilities, we propose an\nautomated method for synthesizing open-ended logic puzzles, and use it to\ndevelop a bilingual benchmark, AutoLogi. Our approach features program-based\nverification and controllable difficulty levels, enabling more reliable\nevaluation that better distinguishes models' reasoning abilities. Extensive\nevaluation of eight modern LLMs shows that AutoLogi can better reflect true\nmodel capabilities, with performance scores spanning from 35% to 73% compared\nto the narrower range of 21% to 37% on the source multiple-choice dataset.\nBeyond benchmark creation, this synthesis method can generate high-quality\ntraining data by incorporating program verifiers into the rejection sampling\nprocess, enabling systematic enhancement of LLMs' reasoning capabilities across\ndiverse datasets."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14682",
    "c_title":[
      "Bridging the Gap: Transforming Natural Language Questions into SQL\n  Queries via Abstract Query Pattern and Contextual Schema Markup"
    ],
    "c_abstract":[
      "Large language models have demonstrated excellent performance in many tasks,\nincluding Text-to-SQL, due to their powerful in-context learning capabilities.\nThey are becoming the mainstream approach for Text-to-SQL. However, these\nmethods still have a significant gap compared to human performance, especially\non complex questions. As the complexity of questions increases, the gap between\nquestions and SQLs increases. We identify two important gaps: the structural\nmapping gap and the lexical mapping gap. To tackle these two gaps, we propose\nPAS-SQL, an efficient SQL generation pipeline based on LLMs, which alleviates\ngaps through Abstract Query Pattern (AQP) and Contextual Schema Markup (CSM).\nAQP aims to obtain the structural pattern of the question by removing\ndatabase-related information, which enables us to find structurally similar\ndemonstrations. CSM aims to associate database-related text span in the\nquestion with specific tables or columns in the database, which alleviates the\nlexical mapping gap. Experimental results on the Spider and BIRD datasets\ndemonstrate the effectiveness of our proposed method. Specifically, PAS-SQL +\nGPT-4o sets a new state-of-the-art on the Spider benchmark with an execution\naccuracy of 87.9\\%, and achieves leading results on the BIRD dataset with an\nexecution accuracy of 64.67\\%."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-181",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09680",
    "b_title":[
      "The Complete Spitzer Survey of Stellar Structure in Galaxies (CS$^4$G)"
    ],
    "b_abstract":[
      "The Spitzer Survey of Stellar Structure in Galaxies (S$^4$G), together with\nits Early Type Galaxy (ETG) extension, stand as the most extensive dataset of\ndeep, uniform mid-infrared (mid-IR; 3.6 and 4.5$\\,\\mu$m) imaging for a sample\nof $2817$ nearby ($d<40 \\,$Mpc) galaxies. However, the velocity criterion used\nto select the original sample results in an additional 422 galaxies without HI\ndetection that ought to have been included in the S$^4$G on the basis of their\noptical recession velocities. In order to create a complete magnitude-, size-\nand volume-limited sample of nearby galaxies, we collect $3.6\\,\\mu$m and\n$i$-band images using archival data from different surveys and complement it\nwith new observations for the missing galaxies. We denote the sample of these\nadditional galaxies as Disc Galaxy (DG) extension. We present the Complete\nSpitzer Survey of Stellar Structure in Galaxies (CS$^4$G), encompassing a\nsample of $3239$ galaxies with consistent imaging, surface brightness profiles,\nphotometric parameters, and revised morphological classification. Following the\noriginal strategy of the S$^4$G survey, we produce masks, surface brightness\nprofiles, and curves of growth using masked $3.6\\,\\mu$m and $i$-band images.\nFrom these profiles, we derive the integrated quantities: total magnitude,\nstellar mass, concentration parameter, and galaxy size, converting to\n$3.6\\,\\mu$m. We re-measure these parameters also for the S$^4$G and ETG to\ncreate a homogenous sample. We present new morphological revised $T$-types, and\nwe showcase mid-IR scaling relations for the photometric parameters. We\ncomplete the S$^4$G sample by incorporating 422 galaxies. The CS$^4$G includes\nat least 99.94\\% of the complete sample of nearby galaxies, meeting the\noriginal selection criteria, and it will enable a wide set of investigations\ninto galaxy structure and evolution."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.02956",
    "c_title":[
      "Evolution of the S\\'ersic Index up to z=2.5 from JWST and HST"
    ],
    "c_abstract":[
      "The James Webb Space Telescope (JWST) is unveiling the rest-frame near-IR\nstructure of galaxies. We measure the evolution with redshift of the rest-frame\noptical and near-IR S\\'ersic index ($n$), and examine the dependence on stellar\nmass and star-formation activity across the redshift range $0.5\\leq z\\leq2.5$.\nWe infer rest-frame near-IR S\\'ersic profiles for $\\approx 15.000$ galaxies in\npublicly available NIRCam imaging mosaics from the COSMOS-Web and PRIMER\nsurveys. We augment these with rest-frame optical S\\'ersic indices, previously\nmeasured from HST imaging mosaics. The median S\\'ersic index evolves slowly or\nnot at all with redshift, except for very high-mass galaxies ($M_\\star >\n10^{11}~{\\text{M}}_\\odot$), which show an increase from $n\\approx 2.5$ to\n$n\\approx 4$ at $z<1$. High-mass galaxies have higher $n$ than lower-mass\ngalaxies ($M_\\star=10^{9.5}~{\\text{M}}_\\odot$) at all redshifts, with a\nstronger dependence in the rest-frame near-IR than in the rest-frame optical at\n$z>1$. This wavelength dependence is caused by star-forming galaxies that have\nlower optical than near-IR $n$ at z>1 (but not at z<1). Both at optical and\nnear-IR wavelengths, star-forming galaxies have lower $n$ than quiescent\ngalaxies, fortifying the connection between star-formation activity and radial\nstellar mass distribution. At $z>1$ the median near-IR $n$ varies strongly with\nstar formation activity, but not with stellar mass. The scatter in near-IR $n$\nis higher in the green valley (0.25 dex) than on the star-forming sequence and\namong quiescent galaxies (0.18 dex) -- this trend is not seen in the optical\nbecause dust and young stars contribute to the variety in optical light\nprofiles. Our newly measured rest-frame near-IR radial light profiles motivate\nfuture comparisons with radial stellar mass profiles of simulated galaxies as a\nstringent constraint on processes that govern galaxy formation."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-182",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11830",
    "b_title":[
      "Application of the Pontryagin Maximum Principle to the robust\n  time-optimal control of two-level quantum systems"
    ],
    "b_abstract":[
      "We study the time-optimal robust control of a two-level quantum system\nsubjected to field inhomogeneities. We apply the Pontryagin Maximum Principle\nand we introduce a reduced space onto which the optimal dynamics is projected\ndown. This reduction leads to a complete analytical derivation of the optimal\nsolution in terms of elliptic functions and elliptic integrals. Necessary\noptimality conditions are then obtained for the original system. These\nconditions are verified numerically and lead to the optimal control protocol.\nVarious examples, ranging from state-to-state transfer to the generation of a\nNot gate, illustrate this study. The connection with other geometric\noptimization approaches that have been used to solve this problem is also\ndiscussed."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.01477",
    "c_title":[
      "Meissner-Like Currents of Photons in Anomalous Superradiant Phases"
    ],
    "c_abstract":[
      "The Meissner effect, a signature feature of superconductors, involves\ncircular surface currents that cancel an external field. In this study, we\npresent our findings on Meissner-like currents of photons in highly tunable\nlight-matter interaction systems. In a quantum Rabi zigzag chain exposed to a\nstaggered magnetic field, we identify a Meissner superradiant phase,\nmanifesting persistent chiral edge currents in the ground state.\nCounter-flowing edge currents arise in each species of cavities,leading to\ncomplete cancellation of net currents throughout the entire chain. This\nphenomenon is analogous to surface currents in the Meissner effect. The\nMeissner phase is signaled by the unusual scaling exponents of the lowest\nexcitation energy, which exhibit anomalous criticality with and without\ngeometric frustration in each species. Intriguingly, adjusting the staggered\nflux induces transitions from the Meissner phase to either the even-chiral or\nodd-chiral superradiant phases, where the chiral edge currents flow exclusively\nin even or odd cavities, respectively. Additionally, by enhancing interspecies\ninteractions, chiral currents vanish in a ferromagnetic superradiant phase. Our\nrealization of Meissner-like currents of photons opens avenues for exploring\nedge state interferometry and quantum Hall effects within light-matter coupling\nplatforms."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-183",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08229",
    "b_title":[
      "Enhancing Train Transportation in Sri Lanka: A Smart IOT based\n  Multi-Subsystem Approach using MQTT"
    ],
    "b_abstract":[
      "This research proposes a system as a solution for the challenges faced by Sri\nLanka' s historic railway system, such as scheduling delays, overcrowding,\nmanual ticketing, and management inefficiencies. It proposes a multi-subsystem\napproach, incorporating GPS tracking, RFID-based e-ticketing, seat reservation,\nand vision-based people counting. The GPS based real time train tracking system\nperforms accurately within 24 meters, with the MQTT protocol showing twice the\nspeed of the HTTP-based system. All subsystems use the MQTT protocol to enhance\nefficiency, reliability, and passenger experience. The study's data and\nmethodology demonstrate the effectiveness of these innovations in improving\nscheduling, passenger flow, and overall system performance, offering promising\nsolutions for modernizing Sri Lanka's railway infrastructure."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10731",
    "c_title":[
      "Service Function Chain Dynamic Scheduling in Space-Air-Ground Integrated\n  Networks"
    ],
    "c_abstract":[
      "As an important component of the sixth generation communication technologies,\nthe space-air-ground integrated network (SAGIN) attracts increasing attentions\nin recent years. However, due to the mobility and heterogeneity of the\ncomponents such as satellites and unmanned aerial vehicles in multi-layer\nSAGIN, the challenges of inefficient resource allocation and management\ncomplexity are aggregated. To this end, the network function virtualization\ntechnology is introduced and can be implemented via service function chains\n(SFCs) deployment. However, urgent unexpected tasks may bring conflicts and\nresource competition during SFC deployment, and how to schedule the SFCs of\nmultiple tasks in SAGIN is a key issue. In this paper, we address the dynamic\nand complexity of SAGIN by presenting a reconfigurable time extension graph and\nfurther propose the dynamic SFC scheduling model. Then, we formulate the SFC\nscheduling problem to maximize the number of successful deployed SFCs within\nlimited resources and time horizons. Since the problem is in the form of\ninteger linear programming and intractable to solve, we propose the algorithm\nby incorporating deep reinforcement learning. Finally, simulation results show\nthat the proposed algorithm has better convergence and performance compared to\nother benchmark algorithms."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-184",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19743",
    "b_title":[
      "Insight-HXMT observations on thermonuclear X-ray bursts from 4U~1608--52\n  in the low\/hard state: the energy-dependant hard X-ray deficit and cooling\n  saturation of the corona"
    ],
    "b_abstract":[
      "During thermonuclear bursts, it is suspected that {\\bf the cooling of the\ncorona by the burst emission}\n  may be the cause of hard X-ray {\\bf deficits}. Although this {\\bf deficit}\nhas been observed in nine sources, it has not been observed {\\bf from}\n4U~1608--52, a nearby prolific burster. Therefore, the authenticity and\nuniversality of the hard X-ray {\\bf deficit} may be in question. To investigate\nthis suspicion, Insight-HXMT performed cadence observations during the low\/hard\nstate of 4U~1608--52 in September 2022 and detected 10 thermonuclear X-ray\nbursts. Two of these bursts show a double-peaked structure in the soft X-ray\nband, which could be caused by the high temperature of the burst emission and a\nmarginal photospheric radius expansion (PRE) around the burst peak time. This\nis indicated by their peak fluxes being up to the Eddington limit and having a\nlarge color factor at the peak of the bursts. The hard X-ray deficit is\nsignificantly observed during bursts at $>$ 30 keV. Furthermore, the fraction\nof this deficit shows saturation at 50\\% for the first 8 bursts. This\nsaturation may indicate that the corona is layered and only a part of the\ncorona is cooled by the bursts. For example, the part close to the NS surface\nis cooled while the rest remains intact during bursts. This result provides a\nclue to the geometry of the corona, e.g., a possible scenario is that the\ncorona has two forms: a quasi-spheric corona between the NS and the disk, and a\ndisk-corona on both surfaces of the disk."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.16243",
    "c_title":[
      "EP240414a: A Gamma-Ray Burst Jet Weakened by an Extended Circumstellar\n  Material"
    ],
    "c_abstract":[
      "The recent Einstein Probe (EP) event EP240414a exhibits several unusual\nobservational features. Its prompt and afterglow emissions place it between\nlong gamma-ray bursts (LGRBs) and low-luminosity GRBs (LLGRBs). The event is\nfollowed by a fast optical transient (AT~2024gsa), initially exhibiting a\nthermal-like spectrum but later evolving into an unusually red peak at $\\sim\n3-5$ days, which is difficult to explain with thermal emission. Using our\ngeneralized analytic framework for jet propagation in a circumstellar material\n(CSM; Hamidani et al. 2025), we explore a scenario in which a conventional LGRB\njet is launched in a progenitor surrounded by a dense CSM. For a CSM of $\\sim\n0.03 M_\\odot$ extending to $\\sim 3\\times 10^{13}$ cm, we find that the jet is\nsignificantly weakened before breaking out, becoming ``barely failed'', an\nintermediate state between successful (LGRB) and completely failed (LLGRB)\njets. This scenario naturally explains EP240414a's multi-wavelength\nobservations, with the early thermal component produced by cocoon cooling\nemission, and the red peak explained by non-thermal afterglow emission from the\nmildly relativistic barely failed jet (and its inner cocoon). Our work\ndemonstrates the important role of extended CSM in shaping GRB jets and\nillustrates how early multi-wavelength follow-up observations can reveal the\nphysically diverse nature of jet-driven transients."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-185",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00708",
    "b_title":[
      "Radial symmetry, uniqueness and non-degeneracy of solutions to\n  degenerate nonlinear Schr\\\"odinger equations"
    ],
    "b_abstract":[
      "In this paper, we consider the radial symmetry, uniqueness and non-degeneracy\nof solutions to the degenerate nonlinear elliptic equation $$ -\\nabla \\cdot\n\\left(|x|^{2a} \\nabla u\\right) + \\omega u=|u|^{p-2}u \\quad \\mbox{in} \\,\\,\n\\mathbb{R}^d, $$ where $d \\geq 2$, $0<a<1$, $\\omega>0$ and\n$2<p<\\frac{2d}{d-2(1-a)}$. We proved that any ground state is radially\nsymmetric and strictly decreasing in the radial direction. Moreover, we\nestablish the uniqueness of ground states and derive the non-degeneracy of\nground states in the corresponding radially symmetric Sobolev space. This\naffirms the nature conjectures posed recently in \\cite{IS}."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03658",
    "c_title":[
      "Space-time analyticity and refined analyticity radius of the\n  Navier-Stokes equations in the critical Besov spaces"
    ],
    "c_abstract":[
      "In this paper, we establish the space-time analyticity of global solutions to\nthe incompressible Navier-Stokes equations with small initial data in critical\n\\emph{Besov} spaces $\\dot B^{3\/p-1}_{p,q}$. Time decay rates of higher order\nspace-time joint derivatives and instantaneous lower bounds of the analyticity\nradius follow as straightforward consequences. The method employed combines\nGevrey-class estimates with iterative derivative techniques. Furthermore, we\nobtain a logarithmic improvement in the lower bound for the spatial analyticity\nradius of solutions for arbitrary initial data in critical \\emph{Besov} spaces."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-186",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16312",
    "b_title":[
      "LinPrim: Linear Primitives for Differentiable Volumetric Rendering"
    ],
    "b_abstract":[
      "Volumetric rendering has become central to modern novel view synthesis\nmethods, which use differentiable rendering to optimize 3D scene\nrepresentations directly from observed views. While many recent works build on\nNeRF or 3D Gaussians, we explore an alternative volumetric scene\nrepresentation. More specifically, we introduce two new scene representations\nbased on linear primitives-octahedra and tetrahedra-both of which define\nhomogeneous volumes bounded by triangular faces. This formulation aligns\nnaturally with standard mesh-based tools, minimizing overhead for downstream\napplications. To optimize these primitives, we present a differentiable\nrasterizer that runs efficiently on GPUs, allowing end-to-end gradient-based\noptimization while maintaining realtime rendering capabilities. Through\nexperiments on real-world datasets, we demonstrate comparable performance to\nstate-of-the-art volumetric methods while requiring fewer primitives to achieve\nsimilar reconstruction fidelity. Our findings provide insights into the\ngeometry of volumetric rendering and suggest that adopting explicit polyhedra\ncan expand the design space of scene representations."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06750",
    "c_title":[
      "Accelerating Data Processing and Benchmarking of AI Models for Pathology"
    ],
    "c_abstract":[
      "Advances in foundation modeling have reshaped computational pathology.\nHowever, the increasing number of available models and lack of standardized\nbenchmarks make it increasingly complex to assess their strengths, limitations,\nand potential for further development. To address these challenges, we\nintroduce a new suite of software tools for whole-slide image processing,\nfoundation model benchmarking, and curated publicly available tasks. We\nanticipate that these resources will promote transparency, reproducibility, and\ncontinued progress in the field."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-187",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11405",
    "b_title":[
      "LayAlign: Enhancing Multilingual Reasoning in Large Language Models via\n  Layer-Wise Adaptive Fusion and Alignment Strategy"
    ],
    "b_abstract":[
      "Despite being pretrained on multilingual corpora, large language models\n(LLMs) exhibit suboptimal performance on low-resource languages. Recent\napproaches have leveraged multilingual encoders alongside LLMs by introducing\ntrainable parameters connecting the two models. However, these methods\ntypically focus on the encoder's output, overlooking valuable information from\nother layers. We propose \\aname (\\mname), a framework that integrates\nrepresentations from all encoder layers, coupled with the \\attaname mechanism\nto enable layer-wise interaction between the LLM and the multilingual encoder.\nExtensive experiments on multilingual reasoning tasks, along with analyses of\nlearned representations, show that our approach consistently outperforms\nexisting baselines."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18251",
    "c_title":[
      "How to Select Datapoints for Efficient Human Evaluation of NLG Models?"
    ],
    "c_abstract":[
      "Human evaluation is the gold-standard for evaluating text generation models.\nIt is also expensive, and to fit budgetary constraints, a random subset of the\ntest data is often chosen in practice. The randomly selected data may not\naccurately represent test performance, making this approach economically\ninefficient for model comparison. Thus, in this work, we develop a suite of\nselectors to get the most informative datapoints for human evaluation while\ntaking the evaluation costs into account. We show that selectors based on\nvariance in automated metric scores, diversity in model outputs, or Item\nResponse Theory outperform random selection. We further develop an approach to\ndistill these selectors to the scenario where the model outputs are not yet\navailable. In particular, we introduce source-based estimators, which predict\nitem usefulness for human evaluation just based on the source texts. We\ndemonstrate the efficacy of our selectors in two common NLG tasks, machine\ntranslation and summarization, and show that up to only ~50% of the test data\nis needed to produce the same evaluation result as the entire data. Our\nimplementations are published in the subset2evaluate package."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-188",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01210",
    "b_title":[
      "Every SAM Drop Counts: Embracing Semantic Priors for Multi-Modality\n  Image Fusion and Beyond"
    ],
    "b_abstract":[
      "Multi-modality image fusion, particularly infrared and visible image fusion,\nplays a crucial role in integrating diverse modalities to enhance scene\nunderstanding. Early research primarily focused on visual quality, yet\nchallenges remain in preserving fine details, making it difficult to adapt to\nsubsequent tasks. Recent approaches have shifted towards task-specific design,\nbut struggle to achieve the ``The Best of Both Worlds'' due to inconsistent\noptimization goals. To address these issues, we propose a novel method that\nleverages the semantic knowledge from the Segment Anything Model (SAM) to Grow\nthe quality of fusion results and Establish downstream task adaptability,\nnamely SAGE. Specifically, we design a Semantic Persistent Attention (SPA)\nModule that efficiently maintains source information via the persistent\nrepository while extracting high-level semantic priors from SAM. More\nimportantly, to eliminate the impractical dependence on SAM during inference,\nwe introduce a bi-level optimization-driven distillation mechanism with triplet\nlosses, which allow the student network to effectively extract knowledge at the\nfeature, pixel, and contrastive semantic levels, thereby removing reliance on\nthe cumbersome SAM model. Extensive experiments show that our method achieves a\nbalance between high-quality visual results and downstream task adaptability\nwhile maintaining practical deployment efficiency."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.18507",
    "c_title":[
      "Can Text-to-Video Generation help Video-Language Alignment?"
    ],
    "c_abstract":[
      "Recent video-language alignment models are trained on sets of videos, each\nwith an associated positive caption and a negative caption generated by large\nlanguage models. A problem with this procedure is that negative captions may\nintroduce linguistic biases, i.e., concepts are seen only as negatives and\nnever associated with a video. While a solution would be to collect videos for\nthe negative captions, existing databases lack the fine-grained variations\nneeded to cover all possible negatives. In this work, we study whether\nsynthetic videos can help to overcome this issue. Our preliminary analysis with\nmultiple generators shows that, while promising on some tasks, synthetic videos\nharm the performance of the model on others. We hypothesize this issue is\nlinked to noise (semantic and visual) in the generated videos and develop a\nmethod, SynViTA, that accounts for those. SynViTA dynamically weights the\ncontribution of each synthetic video based on how similar its target caption is\nw.r.t. the real counterpart. Moreover, a semantic consistency loss makes the\nmodel focus on fine-grained differences across captions, rather than\ndifferences in video appearance. Experiments show that, on average, SynViTA\nimproves over existing methods on VideoCon test sets and SSv2-Temporal,\nSSv2-Events, and ATP-Hard benchmarks, being a first promising step for using\nsynthetic videos when learning video-language models."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-189",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12934",
    "b_title":[
      "Time-Varying Distributed Optimization for A Class of Stochastic\n  Multi-Agent Systems"
    ],
    "b_abstract":[
      "Distributed optimization problems have received much attention due to their\nprivacy preservation, parallel computation, less communication, and strong\nrobustness. This paper presents and studies the time-varying distributed\noptimization problem for a class of stochastic multi-agent systems for the\nfirst time. For this, we initially propose a protocol in the centralized case\nthat allows the tracking error of the agent with respect to the optimal\ntrajectory to be exponentially ultimately bounded in a mean-square sense by\nstochastic Lyapunov theory. We then generalize this to the distributed case.\nTherein, the global variable can be accurately estimated in a fixed-time by our\nproposed estimator. Based on this estimator, we design a new distributed\nprotocol, and the results demonstrate that the tracking error of all agents\nwith respect to the optimal trajectory is exponentially ultimately bound in a\nmean-square sense by stochastic Lyapunov theory. Finally, simulation\nexperiments are conducted to validate the findings."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.11397",
    "c_title":[
      "Lagrangian Duality for Mixed-Integer Semidefinite Programming: Theory\n  and Algorithms"
    ],
    "c_abstract":[
      "This paper presents the Lagrangian duality theory for mixed-integer\nsemidefinite programming (MISDP). We derive the Lagrangian dual problem and\nprove that the resulting Lagrangian dual bound dominates the bound obtained\nfrom the continuous relaxation of the MISDP problem. We present a hierarchy of\nLagrangian dual bounds by exploiting the theory of integer positive\nsemidefinite matrices and propose three algorithms for obtaining those bounds.\nOur algorithms are variants of well-known algorithms for minimizing\nnon-differentiable convex functions. The numerical results on the max-$k$-cut\nproblem show that the Lagrangian dual bounds are substantially stronger than\nthe semidefinite programming bound obtained by relaxing integrality, already\nfor lower levels in the hierarchy. Computational costs for computing our bounds\nare small."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-190",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18644",
    "b_title":[
      "Prompt-oriented Output of Culture-Specific Items in Translated African\n  Poetry by Large Language Model: An Initial Multi-layered Tabular Review"
    ],
    "b_abstract":[
      "This paper examines the output of cultural items generated by Chat Generative\nPreTrained Transformer Pro in response to three structured prompts to translate\nthree anthologies of African poetry. The first prompt was broad, the second\nfocused on poetic structure, and the third prompt emphasized cultural\nspecificity. To support this analysis, four comparative tables were created.\nThe first table presents the results of the cultural items produced after the\nthree prompts, the second categorizes these outputs based on Aixela framework\nof Proper nouns and Common expressions, the third table summarizes the cultural\nitems generated by human translators, a custom translation engine, and a Large\nLanguage Model. The final table outlines the strategies employed by Chat\nGenerative PreTrained Transformer Pro following the culture specific prompt.\nCompared to the outputs of cultural items from reference human translation and\nthe custom translation engine in prior studies the findings indicate that the\nculture oriented prompts used with Chat Generative PreTrained Transformer Pro\ndid not yield significant enhancements of cultural items during the translation\nof African poetry from English to French. Among the fifty four cultural items,\nthe human translation produced thirty three cultural items in repetition, the\ncustom translation engine generated Thirty eight cultural items in repetition\nwhile Chat Generative PreTrained Transformer Pro produced forty one cultural\nitems in repetition. The untranslated cultural items revealed inconsistencies\nin Large language models approach to translating cultural items in African\npoetry from English to French."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13687",
    "c_title":[
      "Feature Extraction and Analysis for GPT-Generated Text"
    ],
    "c_abstract":[
      "With the rise of advanced natural language models like GPT, distinguishing\nbetween human-written and GPT-generated text has become increasingly\nchallenging and crucial across various domains, including academia. The\nlong-standing issue of plagiarism has grown more pressing, now compounded by\nconcerns about the authenticity of information, as it is not always clear\nwhether the presented facts are genuine or fabricated. In this paper, we\npresent a comprehensive study of feature extraction and analysis for\ndifferentiating between human-written and GPT-generated text. By applying\nmachine learning classifiers to these extracted features, we evaluate the\nsignificance of each feature in detection. Our results demonstrate that human\nand GPT-generated texts exhibit distinct writing styles, which can be\neffectively captured by our features. Given sufficiently long text, the two can\nbe differentiated with high accuracy."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-191",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17851",
    "b_title":[
      "Nearby cycles on the local model for the $\\mathrm{GU}(n-1,1)$ PEL\n  Shimura variety over a ramified prime"
    ],
    "b_abstract":[
      "In this paper, we compute the cohomology sheaves of the $\\ell$-adic nearby\ncycles on the local model of the PEL $\\mathrm{GU}(n-1,1)$ Shimura variety over\na ramified prime. The local model is known to have isolated singularities. If\n$n=2$ it has semi-stable reduction, and if $n\\geq 3$ the blow-up at the\nsingular point has semi-stable reduction. Thus, in principle one may compute\nthe nearby cycles at least on the blow-up, then use proper base change to\ndescribe them on the original local model. As a result, we prove that the\nnearby cycles are trivial when $n$ is odd, and that only a single higher\ncohomology sheaf does not vanish when $n$ is even. In this case, we also\ndescribe the Galois action by computing the associated eigenvalue of the\nFrobenius."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.10971",
    "c_title":[
      "The fourth moment of holomorphic Hecke cusp forms in shorter intervals"
    ],
    "c_abstract":[
      "Let $0<c\\le 1\/4$ be fixed. For $H = K^{\\frac{3}{4}+ c}$, we find the average\nvalue of the fourth moment of holomorphic Hecke cusp forms of weight varies\nwithin $[K,K+H]$, improving a previous result of Khan."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-192",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16655",
    "b_title":[
      "Accelerating Antibiotic Discovery with Large Language Models and\n  Knowledge Graphs"
    ],
    "b_abstract":[
      "The discovery of novel antibiotics is critical to address the growing\nantimicrobial resistance (AMR). However, pharmaceutical industries face high\ncosts (over $1 billion), long timelines, and a high failure rate, worsened by\nthe rediscovery of known compounds. We propose an LLM-based pipeline that acts\nas an alarm system, detecting prior evidence of antibiotic activity to prevent\ncostly rediscoveries. The system integrates organism and chemical literature\ninto a Knowledge Graph (KG), ensuring taxonomic resolution, synonym handling,\nand multi-level evidence classification. We tested the pipeline on a private\nlist of 73 potential antibiotic-producing organisms, disclosing 12 negative\nhits for evaluation. The results highlight the effectiveness of the pipeline\nfor evidence reviewing, reducing false negatives, and accelerating\ndecision-making. The KG for negative hits and the user interface for\ninteractive exploration will be made publicly available."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07004",
    "c_title":[
      "Demystifying Singular Defects in Large Language Models"
    ],
    "c_abstract":[
      "Large transformer models are known to produce high-norm tokens. In vision\ntransformers (ViTs), such tokens have been mathematically modeled through the\nsingular vectors of the linear approximations of layers. However, in large\nlanguage models (LLMs), the underlying causes of high-norm tokens remain\nlargely unexplored, and their different properties from those of ViTs require a\nnew analysis framework. In this paper, we provide both theoretical insights and\nempirical validation across a range of recent models, leading to the following\nobservations: i) The layer-wise singular direction predicts the abrupt\nexplosion of token norms in LLMs. ii) The negative eigenvalues of a layer\nexplain its sudden decay. iii) The computational pathways leading to high-norm\ntokens differ between initial and noninitial tokens. iv) High-norm tokens are\ntriggered by the right leading singular vector of the matrix approximating the\ncorresponding modules. We showcase two practical applications of these\nfindings: the improvement of quantization schemes and the design of LLM\nsignatures. Our findings not only advance the understanding of singular defects\nin LLMs but also open new avenues for their application. We expect that this\nwork will stimulate further research into the internal mechanisms of LLMs and\nwill therefore publicly release our code."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-193",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08016",
    "b_title":[
      "SGNetPose+: Stepwise Goal-Driven Networks with Pose Information for\n  Trajectory Prediction in Autonomous Driving"
    ],
    "b_abstract":[
      "Predicting pedestrian trajectories is essential for autonomous driving\nsystems, as it significantly enhances safety and supports informed\ndecision-making. Accurate predictions enable the prevention of collisions,\nanticipation of crossing intent, and improved overall system efficiency. In\nthis study, we present SGNetPose+, an enhancement of the SGNet architecture\ndesigned to integrate skeleton information or body segment angles with bounding\nboxes to predict pedestrian trajectories from video data to avoid hazards in\nautonomous driving. Skeleton information was extracted using a pose estimation\nmodel, and joint angles were computed based on the extracted joint data. We\nalso apply temporal data augmentation by horizontally flipping video frames to\nincrease the dataset size and improve performance. Our approach achieves\nstate-of-the-art results on the JAAD and PIE datasets using pose data with the\nbounding boxes, outperforming the SGNet model. Code is available on Github:\nSGNetPose+."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.12519",
    "c_title":[
      "Multi Activity Sequence Alignment via Implicit Clustering"
    ],
    "c_abstract":[
      "Self-supervised temporal sequence alignment can provide rich and effective\nrepresentations for a wide range of applications. However, existing methods for\nachieving optimal performance are mostly limited to aligning sequences of the\nsame activity only and require separate models to be trained for each activity.\nWe propose a novel framework that overcomes these limitations using sequence\nalignment via implicit clustering. Specifically, our key idea is to perform\nimplicit clip-level clustering while aligning frames in sequences. This coupled\nwith our proposed dual augmentation technique enhances the network's ability to\nlearn generalizable and discriminative representations. Our experiments show\nthat our proposed method outperforms state-of-the-art results and highlight the\ngeneralization capability of our framework with multi activity and different\nmodalities on three diverse datasets, H2O, PennAction, and IKEA ASM. We will\nrelease our code upon acceptance."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-194",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10910",
    "b_title":[
      "3D printed human skull phantoms for transcranial photoacoustic imaging"
    ],
    "b_abstract":[
      "Photoacoustic (PA) waves are strongly distorted and attenuated in skull bone.\nTo study these effects on PA imaging, we designed and 3D-printed\ntissue-mimicking phantoms of human skull. We present a comparison of results in\nphantom and ex vivo skull."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10544",
    "c_title":[
      "Electrical and Mechanical Modeling of Uterine Contractions Analysis\n  Using Connectivity Methods and Graph Theory"
    ],
    "c_abstract":[
      "Premature delivery is a leading cause of fetal death and morbidity, making\nthe prediction and treatment of preterm contractions critical. The\nelectrohysterographic (EHG) signal measures the electrical activity controlling\nuterine contraction. Analyzing EHG features can provide valuable insights for\nlabor detection. In this paper, we propose a framework using simulated EHG\nsignals to identify features sensitive to uterine connectivity. We focus on EHG\nsignal propagation during delivery, recorded by multiple electrodes. Simulated\nEHG signals were generated using electrical diffusion (ED) and\nmechanotransduction (EDM) to identify which connectivity methods and graph\nparameters best represent uterine synchronization. The signals were simulated\nin two scenarios: using only ED by modifying tissue resistance, and using both\nED and EDM by varying mechanotransduction model parameters. A matrix of 16\nsurface electrodes was used for the simulations. Our results show that a\nsimplified electromechanical model can monitor uterine synchronization. Feature\nselection using Fscore on real and simulated EHG signals highlighted that the\nbest features for detecting mechanotransduction shifts were H2 alone or\ncombined with Str, R2(PR), and ICOH(Str). The best features for detecting\nelectrical diffusion shifts were H2, Eff, PR, and BC."
    ],
    "c_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-195",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04507",
    "b_title":[
      "Fast Video Generation with Sliding Tile Attention"
    ],
    "b_abstract":[
      "Diffusion Transformers (DiTs) with 3D full attention power state-of-the-art\nvideo generation, but suffer from prohibitive compute cost -- when generating\njust a 5-second 720P video, attention alone takes 800 out of 945 seconds of\ntotal inference time. This paper introduces sliding tile attention (STA) to\naddress this challenge. STA leverages the observation that attention scores in\npretrained video diffusion models predominantly concentrate within localized 3D\nwindows. By sliding and attending over the local spatial-temporal region, STA\neliminates redundancy from full attention. Unlike traditional token-wise\nsliding window attention (SWA), STA operates tile-by-tile with a novel\nhardware-aware sliding window design, preserving expressiveness while being\nhardware-efficient. With careful kernel-level optimizations, STA offers the\nfirst efficient 2D\/3D sliding-window-like attention implementation, achieving\n58.79% MFU. Precisely, STA accelerates attention by 2.8-17x over\nFlashAttention-2 (FA2) and 1.6-10x over FlashAttention-3 (FA3). On the leading\nvideo DiT, HunyuanVideo, STA reduces end-to-end latency from 945s (FA3) to 685s\nwithout quality degradation, requiring no training. Enabling finetuning further\nlowers latency to 268s with only a 0.09% drop on VBench."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05631",
    "c_title":[
      "HFMF: Hierarchical Fusion Meets Multi-Stream Models for Deepfake\n  Detection"
    ],
    "c_abstract":[
      "The rapid progress in deep generative models has led to the creation of\nincredibly realistic synthetic images that are becoming increasingly difficult\nto distinguish from real-world data. The widespread use of Variational Models,\nDiffusion Models, and Generative Adversarial Networks has made it easier to\ngenerate convincing fake images and videos, which poses significant challenges\nfor detecting and mitigating the spread of misinformation. As a result,\ndeveloping effective methods for detecting AI-generated fakes has become a\npressing concern. In our research, we propose HFMF, a comprehensive two-stage\ndeepfake detection framework that leverages both hierarchical cross-modal\nfeature fusion and multi-stream feature extraction to enhance detection\nperformance against imagery produced by state-of-the-art generative AI models.\nThe first component of our approach integrates vision Transformers and\nconvolutional nets through a hierarchical feature fusion mechanism. The second\ncomponent of our framework combines object-level information and a fine-tuned\nconvolutional net model. We then fuse the outputs from both components via an\nensemble deep neural net, enabling robust classification performances. We\ndemonstrate that our architecture achieves superior performance across diverse\ndataset benchmarks while maintaining calibration and interoperability."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-196",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17809",
    "b_title":[
      "Morse-Novikov homology and $\\beta$-critical points"
    ],
    "b_abstract":[
      "Given a manifold $M$, some closed $\\beta\\in\\Omega^1(M)$ and a map $f\\in\nC^\\infty(M)$, a $\\beta$-critical point is some $x\\in M$ such that $d_\\beta\nf_{x}=0$ for the Lichnerowicz derivative $d_\\beta$. In this paper, we will give\na lower bound for the number of $\\beta$-critical points of index $i$ of a\n$\\beta$-Morse function $f$ in terms of the Morse-Novikov homology, and we\ngeneralize this result to generating functions (quadratic at infinity). We also\ngive an application to the detection of essential Liouville chords of a set\nlength. These are a type of chords that appear in locally conformally\nsymplectic geometry as even-dimensional analogues to Reeb chords."
    ],
    "b_categories":[
      [
        "math.SG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.09209",
    "c_title":[
      "Periodic orbits in time-dependent planar Stark-Zeeman systems"
    ],
    "c_abstract":[
      "Time-dependent Stark-Zeeman systems describe the motion of an electron\nattracted by a proton subject to a magnetic and a time-dependent electric\nfield. For instance the study of the dynamics of a gateway around the moon\nwhich is subject to the joint attraction of the moon, the earth and the sun\nleads to time-dependent Stark-Zeeman systems. In the time-dependent case there\nis no preserved energy. Therefore collisions cannot be regularized by blowing\nup the energy hypersurface. A new regularization technique of blowing up\ninstead of the energy hypersurface the loop space was recently discovered by\nBarutello, Ortega, and Verzini. In this article we explain how this new\nregularization technique can be applied to the study of periodic orbits in\ntime-dependent planar Stark-Zeeman systems. Since the regularization by\nblowing-up the loop space is nonlocal the regularized periodic orbits will not\nsatisfy an ODE anymore but a delay equation."
    ],
    "c_categories":[
      [
        "math.SG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-197",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12361",
    "b_title":[
      "ConFit v2: Improving Resume-Job Matching using Hypothetical Resume\n  Embedding and Runner-Up Hard-Negative Mining"
    ],
    "b_abstract":[
      "A reliable resume-job matching system helps a company recommend suitable\ncandidates from a pool of resumes and helps a job seeker find relevant jobs\nfrom a list of job posts. However, since job seekers apply only to a few jobs,\ninteraction labels in resume-job datasets are sparse. We introduce ConFit v2,\nan improvement over ConFit to tackle this sparsity problem. We propose two\ntechniques to enhance the encoder's contrastive training process: augmenting\njob data with hypothetical reference resume generated by a large language\nmodel; and creating high-quality hard negatives from unlabeled resume\/job pairs\nusing a novel hard-negative mining strategy. We evaluate ConFit v2 on two\nreal-world datasets and demonstrate that it outperforms ConFit and prior\nmethods (including BM25 and OpenAI text-embedding-003), achieving an average\nabsolute improvement of 13.8% in recall and 17.5% in nDCG across job-ranking\nand resume-ranking tasks."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19669",
    "c_title":[
      "Investigating Neurons and Heads in Transformer-based LLMs for\n  Typographical Errors"
    ],
    "c_abstract":[
      "This paper investigates how LLMs encode inputs with typos. We hypothesize\nthat specific neurons and attention heads recognize typos and fix them\ninternally using local and global contexts. We introduce a method to identify\ntypo neurons and typo heads that work actively when inputs contain typos. Our\nexperimental results suggest the following: 1) LLMs can fix typos with local\ncontexts when the typo neurons in either the early or late layers are\nactivated, even if those in the other are not. 2) Typo neurons in the middle\nlayers are responsible for the core of typo-fixing with global contexts. 3)\nTypo heads fix typos by widely considering the context not focusing on specific\ntokens. 4) Typo neurons and typo heads work not only for typo-fixing but also\nfor understanding general contexts."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-198",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03994",
    "b_title":[
      "On families of strongly divisible modules of rank 2"
    ],
    "b_abstract":[
      "Let $p$ be an odd prime, and $\\mathbf{Q}_{p^f}$ the unramified extension of\n$\\mathbf{Q}_p$ of degree $f$. In this paper, we reduce the problem of\nconstructing strongly divisible modules for $2$-dimensional semi-stable\nnon-crystalline representations of\n$\\mathrm{Gal}(\\overline{\\mathbf{Q}}_p\/\\mathbf{Q}_{p^f})$ with Hodge--Tate\nweights in the Fontaine--Laffaille range to solving systems of linear equations\nand inequalities. We also determine the Breuil modules corresponding to the\nmod-$p$ reduction of the strongly divisible modules. We expect our method to\nproduce at least one Galois-stable lattice in each such representation for\ngeneral $f$. Moreover, when the mod-$p$ reduction is an extension of distinct\ncharacters, we further expect our method to provide the two non-homothetic\nlattices. As applications, we show that our approach recovers previously known\nresults for $f=1$ and determine the mod-$p$ reduction of the semi-stable\nrepresentations with some small Hodge--Tate weights when $f=2$."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.18727",
    "c_title":[
      "Subconvexity for $\\rm GL_2 \\times GL_2$ $L$-functions in the depth\n  aspect"
    ],
    "c_abstract":[
      "Let $f$ and $g$ be holomorphic or Maass cusp forms for $\\rm SL_2(\\mathbb{Z})$\nand let $\\chi$ be a primitive Dirichlet character of prime power conductor\n$q=p^n$. For any given $\\varepsilon>0$, we establish the following subconvexity\nbound \\begin{equation*} L(1\/2,f\\otimes g \\otimes\n\\chi)\\ll_{f,g,\\varepsilon}q^{9\/10+\\varepsilon}. \\end{equation*} The proof\nemploys the DFI circle method with standard manipulations, including the\nconductor-lowering mechanism, Voronoi summation, and Cauchy--Schwarz\ninequality. The key input is certain estimates on the resulting character sums,\nobtained using the $p$-adic version of the van der Corput method."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-199",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18333",
    "b_title":[
      "Interpretability of deep-learning methods applied to large-scale\n  structure surveys"
    ],
    "b_abstract":[
      "Deep learning and convolutional neural networks in particular are powerful\nand promising tools for cosmological analysis of large-scale structure surveys.\nThey are already providing similar performance to classical analysis methods\nusing fixed summary statistics, are showing potential to break key degeneracies\nby better probe combination and will likely improve rapidly in the coming years\nas progress is made in the physical modelling through both software and\nhardware improvement. One key issue remains: unlike classical analysis, a\nconvolutional neural network's decision process is hidden from the user as the\nnetwork optimises millions of parameters with no direct physical meaning. This\nprevents a clear understanding of the potential limitations and biases of the\nanalysis, making it hard to rely on as a main analysis method. In this work, we\nexplore the behaviour of such a convolutional neural network through a novel\nmethod. Instead of trying to analyse a network a posteriori, i.e. after\ntraining has been completed, we study the impact on the constraining power of\ntraining the network and predicting parameters with degraded data where we\nremoved part of the information. This allows us to gain an understanding of\nwhich parts and features of a large-scale structure survey are most important\nin the network's prediction process. We find that the network's prediction\nprocess relies on a mix of both Gaussian and non-Gaussian information, and\nseems to put an emphasis on structures whose scales are at the limit between\nlinear and non-linear regimes."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04708",
    "c_title":[
      "Improving Cosmic Birefringence Constraints via Delensing"
    ],
    "c_abstract":[
      "We present a study on using delensing to enhance cosmic birefringence\nmeasurements based on full-sky, map-based simulations. In our analysis, we\nneglect foreground contamination and instrumental systematics to isolate the\nintrinsic impact of delensing on both isotropic and anisotropic birefringence.\nFor the isotropic case, assuming a constant rotation angle of $\\beta =\n0.35^\\circ$, delensing reduces the lensing-induced variance in the EB power\nspectrum, yielding an improvement in sensitivity of approximately 10% at 6\n$\\mu$K-arcmin noise and 25-40% at lower noise levels. For the anisotropic case,\nusing simulations at 1 $\\mu$K-arcmin noise, we reconstruct the birefringence\nangle for a scale-invariant spectrum and mitigate lensing bias by delensing,\nachieving a 50% reduction in the leading $N_{(0)}$ bias and a 30% improvement\nin the constraints on the amplitude $A_{CB}$. Our results demonstrate that\ndelensing is an effective tool for enhancing the detectability of subtle\nparity-violating signals in the cosmic microwave background with forthcoming\nexperiments such as the Simons Observatory, CMB-S4, and LiteBIRD."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-200",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09239",
    "b_title":[
      "Modelling spin-orbitronics effects at interfaces and chiral molecules"
    ],
    "b_abstract":[
      "Using orbital angular momentum (OAM) currents in nanoelectronics, for\nexample, for magnetization manipulation via spin-orbit torque (SOT), represents\na growing field known as \"spin-orbitronics\". Here, using the density functional\ntheory (DFT) and the real-time dynamics of electronic wave packets, we explore\na possibility of generation and propagation of orbital currents in two\nrepresentative systems: an oxidized Cu surface (where large OAMs are known to\nform at the Cu\/O interface) and a model molecular junction made of two carbon\nchains connected by a chiral molecule. In the Cu\/O system, the orbital\npolarization of an incident wave packet from the Cu lead is strongly enhanced\nat the Cu\/O interface but then rapidly decays in the bulk Cu due to orbital\nquenching of asymptotic bulk states. Interestingly, if a finite transmission\nacross the oxygen layer is allowed (in a tunnel junction geometry, for\nexample), a significant spin-polarization of transmitted (or reflected)\ncurrents is instead predicted which persists at a much longer distance and can\nbe further tuned by an applied in-plane voltage. For the molecular junction,\nthe mixing of the carbon $p_x$ and $p_y$ (degenerate) channels by the chiral\nmolecular orbital gives rise not only to an efficient generation of orbital\ncurrent but also to its long-range propagation along the carbon chain."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.18922",
    "c_title":[
      "Reactive sputtering of SnS thin films using sulfur plasma and a metallic\n  tin target: achieving stoichiometry and large grains"
    ],
    "c_abstract":[
      "This study presents a novel method for fabricating stoichiometric SnS thin\nfilms with large grain sizes via reactive sputtering using a metallic Sn target\nand sulfur plasma (S-plasma). Unlike conventional approaches that rely on toxic\nH2S gas, this method employs a S-plasma to enhance sulfur reactivity and\nmitigate sulfur deficiencies during film deposition. By optimizing the balance\nbetween the sputtering conditions of the Sn target and the supply conditions of\nthe S-plasma, dense single-phase SnS thin films with micron-scale grain sizes\nwere achieved at a substrate temperature of 300 degree C, achieving an in-plane\nHall mobility of 13 cm2 V-1 s-1. Furthermore, crystalline SnS thin films were\nfabricated even on a room-temperature substrate, enabling potential\napplications in flexible devices with heat-sensitive substrates. These findings\ndemonstrate the effectiveness of S-plasma in advancing SnS thin film\nfabrication, providing a safer and more efficient route to high-performance\nphotovoltaic materials."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-201",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01728",
    "b_title":[
      "Stars as cosmic scales: measuring stellar mass with microlensed\n  supernovae"
    ],
    "b_abstract":[
      "Gravitational microlensing is a unique probe of the stellar content in strong\nlens galaxies. Flux ratio anomalies from gravitationally lensed supernovae\n(glSNe), just like lensed quasars, can be used to constrain the stellar mass\nfractions at the image positions. Type Ia supernovae are of particular interest\nas knowledge of the intrinsic source brightness helps constrain the amount of\n(de)magnification from the macromodel predictions that might be due to\nmicrolensing. In addition, the presence or absence of caustic crossings in the\nlight curves of glSNe can be used to constrain the mass of the microlenses. We\nfind that a sample of 50 well-modeled glSNe Ia systems with single epoch\nobservations at peak intrinsic supernova luminosity should be able to constrain\na stellar mass-to-light ratio to within $\\sim 15\\%$. A set of systems with\nlight curve level information providing the location (or absence) of caustic\ncrossing events can also constrain the mass of the microlenses to within $\\sim\n50\\%$. Much work is needed to make such a measurement in practice, but our\nresults demonstrate the feasibility of microlensing to place constraints on\nastrophysical parameters related to the initial mass function of lensing\ngalaxies without any prior assumptions on the stellar mass."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.01982",
    "c_title":[
      "Forming the local starburst galaxy Haro 11 through hydrodynamical merger\n  simulations"
    ],
    "c_abstract":[
      "Haro 11 is the closest known Lyman continuum leaking galaxy and serves as an\nimportant laboratory for studying the escape of Lyman continuum radiation. The\ngalaxy is a metal-poor, starburst galaxy believed to be undergoing a merger\nthat might help facilitate the escape of radiation. In this study, we carry out\na large suite of numerical simulations of a merger between two disc galaxies,\nto study possible origins of Haro 11 and understand under which conditions\nvarious features of the galaxy are formed. By varying galaxy parameters\ndescribing the orbital configurations, masses, and their inclination, we\nperform a total of ~500 simulations. We demonstrate that a two-disc galaxy\nmerger is able to reproduce key, observed features of Haro 11, including its\nmorphology, gas kinematics, star formation history, and stellar population ages\nand masses. We also find that small parameter variations have minimal impact on\nthe orbits and resulting galaxy properties. In particular, we present a\nfiducial Haro 11 model that produces the single observed tidal tail, the\npresence of three stellar knots, and inner gas morphology and kinematics. By\nperforming mock observations, we compare with the results of observational data\nand discuss possible origins for various features. Furthermore, we present\nnewly gathered observational data that confirms the presence of a stellar tidal\ntail with similar length and direction as our simulations."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-202",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08618",
    "b_title":[
      "Modulation of Neuronal Firing Modes by Electric Fields in a\n  Thermosensitive FitzHugh-Nagumo Model"
    ],
    "b_abstract":[
      "The Fitzhugh-Nagumo neuronal model is used to explore the influence of the\nelectric field on thermosensitive neurons' dynamics. This study investigates\nhow the electric field affects polarization modulation in cell media induced by\nchanges in ion charge density by adding electrical field as a new variable.\nDriven by a voltage source acting as an external stimulus current, different\nfiring mode responses of the proposed model are analyzed when an external\nelectrical field is applied. Through computational analysis, the study\nevaluates the impact of parameters such as cell radius, stimulus voltage source\namplitude, frequency, and as well as the presence of an external electric\nfield. The results demonstrate distinct mode transitions of isolated neurons\nranging from spiking to bursting, regular and chaotic oscillations. These\nfindings suggest that the firing mode is triggered by periodic external\nelectric fields and cell radius, with the electric field's involvement enhanced\nto regulate neuron activity and control the dynamics. External electric fields\nand stimuli play a crucial role in neuronal firing dynamics, affecting the\ntransition between different firing modes. Understanding these effects\ncontributes to the comprehension of neural processes and the potential\nmanipulation of neural activity for various applications in neuroscience and\nbiophysics."
    ],
    "b_categories":[
      [
        "nlin.CD"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.13394",
    "c_title":[
      "On the formation of the 1:2 resonance in oscillator dynamics"
    ],
    "c_abstract":[
      "The dynamics of nonlinear oscillators are investigated. We study the\nformation of $1:2$ resonance in nonlinear periodically forced oscillators due\nto period doubling of the primary $1:1$ resonance, or born independently. We\ncompute the amplitude-frequency implicit function, the steady-state asymptotic\nsolution, for the effective equation approximating coupled oscillators. Working\nin the framework of differential properties of implicit functions, we\ndemonstrate that birth of $1:2$ resonances corresponds to singular isolated\npoints of the implicit functions. We provide numerical examples illustrating\nour theoretical findings."
    ],
    "c_categories":[
      [
        "nlin.CD"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-203",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19905",
    "b_title":[
      "Moments of quadratic Dirichlet character sums"
    ],
    "b_abstract":[
      "We consider moments of higher powers of quadratic Dirichlet character sums.\nIn a restricted region, we give their asymptotic behavior by using de la\nBret\\`{e}che's multivariable Tauberian theorem. We also give the lower bound of\nthe exponent of $\\log$ factor in the conjecture of Jutila. As an application,\nwe give a lower bound of a weighted average of shifted moments of quadratic\nDirichlet $L$-functions."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.19575",
    "c_title":[
      "Polynomial Continued Fractions for Algebraic Numbers"
    ],
    "c_abstract":[
      "Our main result is that any real cubic algebraic number has a continued\nfraction expansion with polynomial coefficients. Some generalizations are\nmentioned."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-204",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11091",
    "b_title":[
      "Aerial Vision-and-Language Navigation with Grid-based View Selection and\n  Map Construction"
    ],
    "b_abstract":[
      "Aerial Vision-and-Language Navigation (Aerial VLN) aims to obtain an unmanned\naerial vehicle agent to navigate aerial 3D environments following human\ninstruction. Compared to ground-based VLN, aerial VLN requires the agent to\ndecide the next action in both horizontal and vertical directions based on the\nfirst-person view observations. Previous methods struggle to perform well due\nto the longer navigation path, more complicated 3D scenes, and the neglect of\nthe interplay between vertical and horizontal actions. In this paper, we\npropose a novel grid-based view selection framework that formulates aerial VLN\naction prediction as a grid-based view selection task, incorporating vertical\naction prediction in a manner that accounts for the coupling with horizontal\nactions, thereby enabling effective altitude adjustments. We further introduce\na grid-based bird's eye view map for aerial space to fuse the visual\ninformation in the navigation history, provide contextual scene information,\nand mitigate the impact of obstacles. Finally, a cross-modal transformer is\nadopted to explicitly align the long navigation history with the instruction.\nWe demonstrate the superiority of our method in extensive experiments."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.08837",
    "c_title":[
      "MANTA: Diffusion Mamba for Efficient and Effective Stochastic Long-Term\n  Dense Anticipation"
    ],
    "c_abstract":[
      "Long-term dense action anticipation is very challenging since it requires\npredicting actions and their durations several minutes into the future based on\nprovided video observations. To model the uncertainty of future outcomes,\nstochastic models predict several potential future action sequences for the\nsame observation. Recent work has further proposed to incorporate uncertainty\nmodelling for observed frames by simultaneously predicting per-frame past and\nfuture actions in a unified manner. While such joint modelling of actions is\nbeneficial, it requires long-range temporal capabilities to connect events\nacross distant past and future time points. However, the previous work\nstruggles to achieve such a long-range understanding due to its limited and\/or\nsparse receptive field. To alleviate this issue, we propose a novel MANTA\n(MAmba for ANTicipation) network. Our model enables effective long-term\ntemporal modelling even for very long sequences while maintaining linear\ncomplexity in sequence length. We demonstrate that our approach achieves\nstate-of-the-art results on three datasets - Breakfast, 50Salads, and\nAssembly101 - while also significantly improving computational and memory\nefficiency. Our code is available at https:\/\/github.com\/olga-zats\/DIFF_MANTA ."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-205",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06223",
    "b_title":[
      "Investigation of Fe-Ag and Ag-Fe Interfaces in Ag-57Fe-Ag trilayer Using\n  Nuclear Resonance Scattering under X-ray Standing Wave Conditions"
    ],
    "b_abstract":[
      "Understanding the interfaces of layered nanostructures is key to optimizing\ntheir structural and magnetic properties for the desired functionality. In the\npresent work, the two interfaces of a few nm thick Fe layer in Ag-57Fe-Ag\ntrilayers are studied with a depth resolution of a fraction of a nanometer\nusing x-ray standing waves (XSWs) generated by an underlying [W-Si]x10\nmultilayer (MLT) at an x-ray incident angle around the Bragg peak of the MLT.\nInterface selectivity in Ag-57Fe-Ag trilayers was achieved by moving XSW\nantinodes across the interfaces by optimizing suitable incident angles and\nperforming depth-resolved nuclear resonance scattering (NRS) and X-ray\nfluorescence (XRF) measurements for magnetic and structural properties. The\ncombined analysis revealed that the rms roughness of 57Fe-on-Ag and Ag-on-57Fe\ninterfaces are not equal. The roughness of the 57Fe-on-Ag interface is 10\nAngstrom, while that of the Ag-on-57Fe interface is 6 Angstrom. 57Fe isotope\nsensitive NRS revealed that hyperfine field (HFF) at both interfaces of\n57Fe-on-Ag and Ag-on-57Fe interfaces are distinct, which is consistent with the\ndifference in interface roughnesses measured as root mean square (RMS)\nroughness. Thermal annealing induces 57Fe diffusion into the Ag layer, and\nannealing at 325 C transforms the sample into a paramagnetic state. This\nbehavior is attributed to forming 57Fe nanoparticles within the Ag matrix,\nexhibiting a paramagnetic nature. These findings provide deep insights into\ninterface properties crucial for developing advanced nanostructures and\nspintronic devices."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11957",
    "c_title":[
      "Oxygen vacancy engineering in pulsed laser deposited BaSnO$_3$ thin\n  films on SrTiO$_3$"
    ],
    "c_abstract":[
      "We demonstrate the tunability of oxygen content in pulsed laser deposition\n(PLD)-grown barium stannate (BaSn$O_3$, BSO) thin films by precisely\ncontrolling the background oxygen pressure over a broad range from 0.0004 mbar\nto 0.13 mbar. The introduction of oxygen vacancies significantly alters the\nstructural properties of BSO films, inducing a monotonic expansion of the\nout-of-plane lattice parameter and cell volume as the vacancy concentration\nincreases. The progressive formation of oxygen vacancies was spectroscopically\ntracked using X-ray photoelectron spectroscopy (XPS), providing direct insight\ninto the vacancy evolution. Furthermore, we show that the oxygen stoichiometry\nin BSO plays a critical role in modulating the sheet resistance of\nBSO\/LaScO$_3$ heterostructures, enabling interface metallic electron\nconduction. This oxygen content control offers a robust strategy to tailor the\nelectronic properties at the interface, highlighting its potential for oxide\nelectronics and functional interface engineering."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-206",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00712",
    "b_title":[
      "Streaming Algorithms for Network Design"
    ],
    "b_abstract":[
      "We consider the Survivable Network Design problem (SNDP) in the single-pass\ninsertion-only streaming model. The input to SNDP is an edge-weighted graph $G\n= (V, E)$ and an integer connectivity requirement $r(uv)$ for each $u, v \\in\nV$. The objective is to find a min-weight subgraph $H \\subseteq G$ s.t., for\nevery $u, v \\in V$, $u$ and $v$ are $r(uv)$-edge\/vertex-connected. Recent work\nby [JKMV24] obtained approximation algorithms for edge-connectivity\naugmentation, and via that, also derived algorithms for edge-connectivity SNDP\n(EC-SNDP). We consider vertex-connectivity setting (VC-SNDP) and obtain several\nresults for it as well as improved bounds for EC-SNDP.\n  * We provide a general framework for solving connectivity problems in\nstreaming; this is based on a connection to fault-tolerant spanners. For\nVC-SNDP we provide an $O(tk)$-approximation in $\\tilde O(k^{1-1\/t}n^{1 + 1\/t})$\nspace, where $k$ is the maximum connectivity requirement, assuming an exact\nalgorithm at the end of the stream. Using a refined LP-based analysis, we\nprovide an $O(\\beta t)$-approximation in polynomial time, where $\\beta$ is the\nbest polytime approximation w.r.t. the optimal fractional solution to a natural\nLP relaxation. When applied to EC-SNDP, our framework provides an\n$O(t)$-approximation in $\\tilde O(k^{1-1\/t}n^{1 + 1\/t})$ space, improving the\n$O(t \\log k)$-approximation of [JKMV24]; this also extends to\nelement-connectivity SNDP.\n  * We consider vertex connectivity-augmentation in the link-arrival model. The\ninput is a $k$-vertex-connected subgraph $G$, and the weighted links $L$ arrive\nin the stream; the goal is to store the min-weight set of links s.t. $G \\cup L$\nis $(k+1)$-vertex-connected. We obtain $O(1)$ approximations in near-linear\nspace for $k = 1, 2$. Our result for $k=2$ is based on SPQR tree, a novel\napplication for this well-known representation of $2$-connected graphs."
    ],
    "b_categories":[
      [
        "cs.DS"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01388",
    "c_title":[
      "Faster ED-String Matching with $k$ Mismatches"
    ],
    "c_abstract":[
      "We revisit the complexity of approximate pattern matching in an\nelastic-degenerate string. Such a string is a sequence of $n$ finite sets of\nstrings of total length $N$, and compactly describes a collection of strings\nobtained by first choosing exactly one string in every set, and then\nconcatenating them together. This is motivated by the need of storing a\ncollection of highly similar DNA sequences.\n  The basic algorithmic question on elastic-degenerate strings is pattern\nmatching: given such an elastic-degenerate string and a standard pattern of\nlength $m$, check if the pattern occurs in one of the strings in the described\ncollection. Bernardini et al.~[SICOMP 2022] showed how to leverage fast matrix\nmultiplication to obtain an\n$\\tilde{\\mathcal{O}}(nm^{\\omega-1})+\\mathcal{O}(N)$-time complexity for this\nproblem, where $w$ is the matrix multiplication exponent. However, the best\nresult so far for finding occurrences with $k$ mismatches, where $k$ is a\nconstant, is the $\\tilde{\\mathcal{O}}(nm^{2}+N)$-time algorithm of Pissis et\nal.~[CPM 2025]. This brings the question whether increasing the dependency on\n$m$ from $m^{\\omega-1}$ to quadratic is necessary when moving from $k=0$ to\nlarger (but still constant) $k$.\n  We design an $\\tilde{\\mathcal{O}}(nm^{1.5}+N)$-time algorithm for pattern\nmatching with $k$ mismatches in an elastic-degenerate string, for any constant\n$k$. To obtain this time bound, we leverage the structural characterization of\noccurrences with $k$ mismatches of Charalampopoulos et al.~[FOCS 2020] together\nwith fast Fourier transform. We need to work with multiple patterns at the same\ntime, instead of a single pattern, which requires refining the original\ncharacterization. This might be of independent interest."
    ],
    "c_categories":[
      [
        "cs.DS"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-207",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09839",
    "b_title":[
      "Coarse tree-width"
    ],
    "b_abstract":[
      "We prove two theorems about tree-decompositions in the setting of coarse\ngraph theory. First, we show that a graph $G$ admits a tree-decomposition in\nwhich each bag is contained in the union of a bounded number of balls of\nbounded radius, if and only if $G$ admits a quasi-isometry to a graph with\nbounded tree-width. (The ``if'' half is easy, but the ``only if'' half is\nchallenging.) This generalizes a recent result of Berger and Seymour,\nconcerning tree-decompositions when each bag has bounded radius.\n  Second, we show that if $G$ admits a quasi-isometry $\\phi$ to a graph $H$ of\nbounded path-width, then $G$ admits a quasi-isometry (with error only an\nadditive constant) to a graph of bounded path-width. Indeed, we will show a\nmuch stronger statement: that we can assign a non-negative integer length to\neach edge of $H$, such that the same function $\\phi$ is a quasi-isometry (with\nerror only an additive constant) to this weighted version of $H$."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.09342",
    "c_title":[
      "Monochromatic graph decompositions and monochromatic piercing inspired\n  by anti-Ramsey colorings"
    ],
    "c_abstract":[
      "Anti-Ramsey theory was initiated in 1975 by Erd\\H{o}s, Simonovits and S\\'os,\ninspiring hundreds of publications since then. The present work is the third\nand last piece of our trilogy in which we introduce a far-reaching\ngeneralization via the following two functions for any graph $G$ and family\n${\\cal F}$ of graphs:\n  If $K_2 \\in {\\cal F}$, let $f(n,G|{\\cal F})$ be the smallest integer $k$ such\nthat every edge coloring of $K_n$ with at least $k$ colors forces a copy of $G$\nin which all color classes are members of ${\\cal F}$.\n  If $K_2 \\notin {\\cal F}$, let $g(n,G|{\\cal F})$ be the largest integer $k$\nfor which there exists an edge coloring of $K_n$ using exactly $k$ colors, such\nthat every copy of $G$ contains an induced color class which is a member of\n${\\cal F}$.\n  We develop methods suitable for deriving asymptotically tight results for the\n$f$-function and the $g$-function for many combinations of $G$ and ${\\cal F}$.\n  The preceding parts of the trilogy are arXiv: 2405.19812 and 2408.04257,\npublished in Discrete Applied Math. Vol. 363 and Mathematics Vol. 12:23,\nrespectively."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-208",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05990",
    "b_title":[
      "Constraining constructions with WordNet: pros and cons for the semantic\n  annotation of fillers in the Italian Constructicon"
    ],
    "b_abstract":[
      "The paper discusses the role of WordNet-based semantic classification in the\nformalization of constructions, and more specifically in the semantic\nannotation of schematic fillers, in the Italian Constructicon. We outline how\nthe Italian Constructicon project uses Open Multilingual WordNet topics to\nrepresent semantic features and constraints of constructions."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.20975",
    "c_title":[
      "Set-Theoretic Compositionality of Sentence Embeddings"
    ],
    "c_abstract":[
      "Sentence encoders play a pivotal role in various NLP tasks; hence, an\naccurate evaluation of their compositional properties is paramount. However,\nexisting evaluation methods predominantly focus on goal task-specific\nperformance. This leaves a significant gap in understanding how well sentence\nembeddings demonstrate fundamental compositional properties in a\ntask-independent context. Leveraging classical set theory, we address this gap\nby proposing six criteria based on three core \"set-like\"\ncompositions\/operations: \\textit{TextOverlap}, \\textit{TextDifference}, and\n\\textit{TextUnion}. We systematically evaluate $7$ classical and $9$ Large\nLanguage Model (LLM)-based sentence encoders to assess their alignment with\nthese criteria. Our findings show that SBERT consistently demonstrates set-like\ncompositional properties, surpassing even the latest LLMs. Additionally, we\nintroduce a new dataset of ~$192$K samples designed to facilitate future\nbenchmarking efforts on set-like compositionality of sentence embeddings."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-209",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00680",
    "b_title":[
      "Some structural complexity results for $\\exists\\mathbb R$"
    ],
    "b_abstract":[
      "The complexity class $\\exists\\mathbb R$, standing for the complexity of\ndeciding the existential first order theory of the reals as real closed field\nin the Turing model, has raised considerable interest in recent years. It is\nwell known that NP $ \\subseteq \\exists\\mathbb R\\subseteq$ PSPACE. In their\ncompendium, Schaefer, Cardinal, and Miltzow give a comprehensive presentation\nof results together with a rich collection of open problems. Here, we answer\nsome of them dealing with structural issues of $\\exists\\mathbb R$ as a\ncomplexity class. We show analogues of the classical results of Baker, Gill,\nand Solovay finding oracles which do and do not separate NP form\n$\\exists\\mathbb R$, of Ladner's theorem showing the existence of problems in\n$\\exists\\mathbb R \\setminus$ NP not being complete for $\\exists\\mathbb R$ (in\ncase the two classes are different), as well as a characterization of\n$\\exists\\mathbb R$ by means of descriptive complexity."
    ],
    "b_categories":[
      [
        "cs.CC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.00831",
    "c_title":[
      "Hazard-free Decision Trees"
    ],
    "c_abstract":[
      "Decision trees are one of the most fundamental computational models for\ncomputing Boolean functions $f : \\{0, 1\\}^n \\mapsto \\{0, 1\\}$. It is well-known\nthat the depth and size of decision trees are closely related to time and\nnumber of processors respectively for computing functions in the CREW-PRAM\nmodel. For a given $f$, a fundamental goal is to minimize the depth and\/or the\nsize of the decision tree computing it.\n  In this paper, we extend the decision tree model to the world of hazard-free\ncomputation. We allow each query to produce three results: zero, one, or\nunknown. The output could also be: zero, one, or unknown, with the constraint\nthat we should output \"unknown\" only when we cannot determine the answer from\nthe input bits. This setting naturally gives rise to ternary decision trees\ncomputing functions, which we call hazard-free decision trees. We prove various\nlower and upper bounds on the depth and size of hazard-free decision trees and\ncompare them to their Boolean counterparts. We prove optimal separations and\nrelate hazard-free decision tree parameters to well-known Boolean function\nparameters. We show that the analogues of sensitivity, block sensitivity, and\ncertificate complexity for hazard-free functions are all polynomially\nequivalent to each other and to hazard-free decision tree depth. i.e., we prove\nthe sensitivity theorem in the hazard-free model. We then prove that\nhazard-free sensitivity satisfies an interesting structural property that is\nknown to hold in the Boolean world. Hazard-free functions with small\nhazard-free sensitivity are completely determined by their values in any\nHamming ball of small radius in $\\{0, u, 1\\}^n$."
    ],
    "c_categories":[
      [
        "cs.CC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-210",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02774",
    "b_title":[
      "Digital Model-Driven Genetic Algorithm for Optimizing Layout and Task\n  Allocation in Human-Robot Collaborative Assemblies"
    ],
    "b_abstract":[
      "This paper addresses the optimization of human-robot collaborative work-cells\nbefore their physical deployment. Most of the times, such environments are\ndesigned based on the experience of the system integrators, often leading to\nsub-optimal solutions. Accurate simulators of the robotic cell, accounting for\nthe presence of the human as well, are available today and can be used in the\npre-deployment. We propose an iterative optimization scheme where a digital\nmodel of the work-cell is updated based on a genetic algorithm. The methodology\nfocuses on the layout optimization and task allocation, encoding both the\nproblems simultaneously in the design variables handled by the genetic\nalgorithm, while the task scheduling problem depends on the result of the\nupper-level one. The final solution balances conflicting objectives in the\nfitness function and is validated to show the impact of the objectives with\nrespect to a baseline, which represents possible initial choices selected based\non the human judgment."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00647",
    "c_title":[
      "CAP: A Connectivity-Aware Hierarchical Coverage Path Planning Algorithm\n  for Unknown Environments using Coverage Guidance Graph"
    ],
    "c_abstract":[
      "Efficient coverage of unknown environments requires robots to adapt their\npaths in real time based on on-board sensor data. In this paper, we introduce\nCAP, a connectivity-aware hierarchical coverage path planning algorithm for\nefficient coverage of unknown environments. During online operation, CAP\nincrementally constructs a coverage guidance graph to capture essential\ninformation about the environment. Based on the updated graph, the hierarchical\nplanner determines an efficient path to maximize global coverage efficiency and\nminimize local coverage time. The performance of CAP is evaluated and compared\nwith five baseline algorithms through high-fidelity simulations as well as\nrobot experiments. Our results show that CAP yields significant improvements in\ncoverage time, path length, and path overlap ratio."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-211",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04093",
    "b_title":[
      "Evaluating and Testing for Actionable Treatment Effect Heterogeneity"
    ],
    "b_abstract":[
      "Developing tools for estimating heterogeneous treatment effects (HTE) and\nindividualized treatment effects has been an area of active research in recent\nyears. While these tools have proven to be useful in many contexts, a concern\nwhen deploying such methods is the degree to which incorporating HTE into a\nprediction model provides an advantage over predictive methods which do not\nallow for variation in treatment effect across individuals. To address this\nconcern, we propose a procedure which evaluates the extent to which an HTE\nmodel provides a predictive advantage. Specifically, our procedure targets the\ngain in predictive performance from using a flexible predictive model\nincorporating HTE versus an alternative model which is similar to the\nHTE-utilizing model except that it is constrained to not allow variation in\ntreatment effect. By drawing upon recent work in using nested cross-validation\ntechniques for prediction error inference, we generate confidence intervals for\nthis measure of gain in predictive performance which allows one to directly\ncalculate the level at which one is confident of a substantial HTE-modeling\ngain in prediction -- a quantity which we refer to as the h-value. Our\nprocedure is generic and can be directly used to assess the benefit of modeling\nHTE for any method that incorporates treatment effect variation."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.08945",
    "c_title":[
      "COADVISE: Covariate Adjustment with Variable Selection in Randomized\n  Controlled Trials"
    ],
    "c_abstract":[
      "Adjusting for covariates in randomized controlled trials can enhance the\ncredibility and efficiency of treatment effect estimation. However, handling\nnumerous covariates and their complex (non-linear) transformations poses a\nchallenge. Motivated by the case study of the Best Apnea Interventions for\nResearch (BestAIR) trial data from the National Sleep Research Resource (NSRR),\nwhere the number of covariates (p=114) is comparable to the sample size\n(N=196), we propose a principled Covariate Adjustment with Variable Selection\n(COADVISE) framework. COADVISE enables variable selection for covariates most\nrelevant to the outcome while accommodating both linear and nonlinear\nadjustments. This framework ensures consistent estimates with improved\nefficiency over unadjusted estimators and provides robust variance estimation,\neven under outcome model misspecification. We demonstrate efficiency gains\nthrough theoretical analysis, extensive simulations, and a re-analysis of the\nBestAIR trial data to compare alternative variable selection strategies,\noffering cautionary recommendations. A user-friendly R package, Coadvise, is\navailable to facilitate practical implementation."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-212",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06645",
    "b_title":[
      "Singularity-Based Consistent QML Estimation of Multiple Breakpoints in\n  High-Dimensional Factor Models"
    ],
    "b_abstract":[
      "This paper investigates the estimation of high-dimensional factor models in\nwhich factor loadings undergo an unknown number of structural changes over\ntime. Given that a model with multiple changes in factor loadings can be\nobservationally indistinguishable from one with constant loadings but varying\nfactor variances, this reduces the high-dimensional structural change problem\nto a lower-dimensional one. Due to the presence of multiple breakpoints, the\nfactor space may expand, potentially causing the pseudo factor covariance\nmatrix within some regimes to be singular. We define two types of breakpoints:\n{\\bf a singular change}, where the number of factors in the combined regime\nexceeds the minimum number of factors in the two separate regimes, and {\\bf a\nrotational change}, where the number of factors in the combined regime equals\nthat in each separate regime. Under a singular change, we derive the properties\nof the small eigenvalues and establish the consistency of the QML estimators.\nUnder a rotational change, unlike in the single-breakpoint case, the pseudo\nfactor covariance matrix within each regime can be either full rank or\nsingular, yet the QML estimation error for the breakpoints remains stably\nbounded. We further propose an information criterion (IC) to estimate the\nnumber of breakpoints and show that, with probability approaching one, it\naccurately identifies the true number of structural changes. Monte Carlo\nsimulations confirm strong finite-sample performance. Finally, we apply our\nmethod to the FRED-MD dataset, identifying five structural breaks in factor\nloadings between 1959 and 2024."
    ],
    "b_categories":[
      [
        "econ.EM"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2502.06446",
    "c_title":[
      "Grouped fixed effects regularization for binary choice models"
    ],
    "c_abstract":[
      "We study the application of the Grouped Fixed Effects (GFE) estimator\n(Bonhomme et al., ECMTA 90(2):625-643, 2022) to binary choice models for\nnetwork and panel data. This approach discretizes unobserved heterogeneity via\nk-means clustering and performs maximum likelihood estimation, reducing the\nnumber of fixed effects in finite samples. This regularization helps analyze\nsmall\/sparse networks and rare events by mitigating complete separation, which\ncan lead to data loss. We focus on dynamic models with few state transitions\nand network formation models for sparse networks. The effectiveness of this\nmethod is demonstrated through simulations and real data applications."
    ],
    "c_categories":[
      [
        "econ.EM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-213",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09986",
    "b_title":[
      "From Equations to Insights: Unraveling Symbolic Structures in PDEs with\n  LLMs"
    ],
    "b_abstract":[
      "Motivated by the remarkable success of artificial intelligence (AI) across\ndiverse fields, the application of AI to solve scientific problems-often\nformulated as partial differential equations (PDEs)-has garnered increasing\nattention. While most existing research concentrates on theoretical properties\n(such as well-posedness, regularity, and continuity) of the solutions,\nalongside direct AI-driven methods for solving PDEs, the challenge of\nuncovering symbolic relationships within these equations remains largely\nunexplored. In this paper, we propose leveraging large language models (LLMs)\nto learn such symbolic relationships. Our results demonstrate that LLMs can\neffectively predict the operators involved in PDE solutions by utilizing the\nsymbolic information in the PDEs. Furthermore, we show that discovering these\nsymbolic relationships can substantially improve both the efficiency and\naccuracy of the finite expression method for finding analytical approximation\nof PDE solutions, delivering a fully interpretable solution pipeline. This work\nopens new avenues for understanding the symbolic structure of scientific\nproblems and advancing their solution processes."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07337",
    "c_title":[
      "Neural Flow Samplers with Shortcut Models"
    ],
    "c_abstract":[
      "Sampling from unnormalized densities is a fundamental task across various\ndomains. Flow-based samplers generate samples by learning a velocity field that\nsatisfies the continuity equation, but this requires estimating the intractable\ntime derivative of the partition function. While importance sampling provides\nan approximation, it suffers from high variance. To mitigate this, we introduce\na velocity-driven Sequential Monte Carlo method combined with control variates\nto reduce variance. Additionally, we incorporate a shortcut model to improve\nefficiency by minimizing the number of sampling steps. Empirical results on\nboth synthetic datasets and $n$-body system targets validate the effectiveness\nof our approach."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-214",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14416",
    "b_title":[
      "Planar Kolmogorov systems with infinitely many singular points at\n  infinity"
    ],
    "b_abstract":[
      "We classify the global dynamics of the five-parameter family of planar\nKolmogorov systems \\begin{equation*}\n  \\begin{split}\n  \\dot{y}&=y \\left( b_0+ b_1 y z + b_2 y + b_3 z\\right),\n  \\dot{z}&=z\\left( c_0 + b_1 y z + b_2 y + b_3 z\\right),\n  \\end{split} \\end{equation*} which is obtained from the Lotka-Volterra systems\nof dimension three. These systems have infinitely many singular points at\ninifnity. We give the topological classification of their phase portraits in\nthe Poincar\\'e disc, so we can describe the dynamics of these systems near\ninfinity. We prove that these systems have 13 topologically distinct global\nphase portraits."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.08077",
    "c_title":[
      "Horizontality of partially hyperbolic foliations"
    ],
    "c_abstract":[
      "We show exactly which Seifert manifolds support partially hyperbolic\ndynamical systems. In particular, a circle bundle over a higher-genus surface\nsupports a partially hyperbolic system if and only if it supports an Anosov\nflow. We also show for these systems that the center-stable and center-unstable\nfoliations can be isotoped so that their leaves are transverse to the circle\nfibering. As a consequence, every partially hyperbolic system defined on the\nunit tangent bundle of a higher-genus surface is a collapsed Anosov flow."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-215",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19262",
    "b_title":[
      "Periodic propagation of singularities for heat equations with time delay"
    ],
    "b_abstract":[
      "This paper presents two remarkable phenomena associated with the heat\nequation with a time delay: namely, the propagation of singularities and\nperiodicity. These are manifested through a distinctive mode of propagation of\nsingularities in the solutions. Precisely, the singularities of the solutions\npropagate periodically in a bidirectional fashion along the time axis.\nFurthermore, this propagation occurs in a stepwise manner. More specifically,\nwhen propagating in the positive time direction, the order of the joint\nderivatives of the solution increases by 2 for each period; conversely, when\npropagating in the reverse time direction, the order of the joint derivatives\ndecreases by 2 per period. Additionally, we elucidate the way in which the\ninitial data and historical values impact such a propagation of singularities.\n  The phenomena we have discerned not only corroborate the pronounced\ndifferences between heat equations with and without time delay but also vividly\nillustrate the substantial divergence between the heat equation with a time\ndelay and the wave equation, especially when viewed from the point of view of\nsingularity propagation."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.02678",
    "c_title":[
      "Arbitrary Polynomial Decay Rates of Neutral, Collisionless Plasmas"
    ],
    "c_abstract":[
      "A multispecies, collisionless plasma is modeled by the Vlasov-Poisson system.\nAssuming the plasma is neutral and the electric field decays with sufficient\nrapidity as $t \\to\\infty$, we show that solutions can be constructed with\narbitrarily fast, polynomial rates of decay, depending upon the properties of\nthe limiting spatial average and its derivatives. In doing so, we establish,\nfor the first time, a countably infinite number of asymptotic profiles for the\ncharge density, electric field, and their derivatives, each of which is\nnecessarily realized by a sufficiently smooth solution and exceeds the\nestablished dispersive decay rates. Finally, in each case we establish a linear\n$L^\\infty$ scattering result for every particle distribution function, namely\nwe show that they converge as $t \\to \\infty$ along the transported spatial\ncharacteristics at increasingly faster rates."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-216",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00276",
    "b_title":[
      "Chinese Historical Documents Reveal Multi-Century Seasonal Shifts in\n  Tropical Cyclone Landfalls"
    ],
    "b_abstract":[
      "Paleoclimate records reveal a fuller range of natural climate variability\nthan modern records and are essential for better understanding the modern\nclimate change. However, most paleoclimate records are point-based proxies and\nlack the temporal resolution needed to analyze spatiotemporal changes in\ndestructive extremes like tropical cyclones (TCs). Here we show that historical\nrecords by pre-industrial Chinese intellectuals help investigate long-term\nvariability of TC landfalls in East Asia. Despite inherent limitations, these\nrecords show a landfalling TC climatology resembling modern observations in\nspatial-temporal distributions. Comparisons between the pre-industrial records\n(1776-1850), modern observations (1946-2020), and climate simulations reveal an\nearlier seasonal occurrence of modern TCs. However, the variations of\nseasonally aggregated landfall time show pronounced multi-century variations.\nThe modern changes and multi-decade trends appear moderate compared to\nlong-term variability in pre-industrial TC records, suggesting that an\noverreliance on modern data may lead to an underestimation of the full range of\nTC activity potentially arising from natural variability alone. Analyses of\nnewly available climate data reveal associations between past landfalling TC\nactivity and the large-scale climate variability of tropical ocean and\nextratropical land. These findings demonstrate the value of paleoclimate data\nfor exploring natural variability in TC activity and inform the development of\neffective adaptation strategies for future climate change."
    ],
    "b_categories":[
      [
        "physics.ao-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.05331",
    "c_title":[
      "The Changes of the Northern Hadley Cell Strength in Reanalyses and\n  Radiosonde Observations"
    ],
    "c_abstract":[
      "This study examines mean meridional winds and their trends in the Northern\nHadley Cell (NHC) from 1980 to 2022 using reanalysis datasets and radiosonde\nobservations. Compared to radiosonde data, reanalyses underestimate the mean\nupper-tropospheric poleward flow of the NHC but accurately capture the mean\nequatorward flow in the lower troposphere. While climate models generally\nproject a weakening of the NHC, our study finds no significant trend in\nradiosonde observations, adding to the uncertainty in future climate\nprojections. In contrast, reanalyses indicate a strengthening, primarily due to\nan intensification of the upper-tropospheric poleward flow. Our examination of\nERA5 analysis increments confirms that the NHC strengthening trend in ERA5 is\nnot an artefact of data assimilation. Instead, the increments correct the first\nguess, which underestimates the strength of the NHC, nudging it toward a\nstronger circulation."
    ],
    "c_categories":[
      [
        "physics.ao-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-217",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12964",
    "b_title":[
      "Double EPW cubes from twisted cubics on Gushel-Mukai fourfolds"
    ],
    "b_abstract":[
      "In this paper, we conduct the first systematic investigation of twisted\ncubics on Gushel-Mukai (GM) fourfolds. We then study the double EPW cube, a\n6-dimensional hyperk\\\"ahler manifold associated with a general GM fourfold $X$,\nthrough the Bridgeland moduli space, and show that it is the maximal rationally\nconnected (MRC) quotient of the Hilbert scheme of twisted cubics on $X$. We\nalso prove that a general double EPW cube admits a covering by Lagrangian\nsubvarieties constructed from the Hilbert schemes of twisted cubics on GM\nthreefolds, which provides a new example for a conjecture of O'Grady."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.02052",
    "c_title":[
      "Geometric phantom categories do not admit Noetherian t-structures"
    ],
    "c_abstract":[
      "There are no Noetherian or Artinian bounded t-structures on geometric phantom\nor quasi-phantom categories."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-218",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10739",
    "b_title":[
      "Computational Discovery of Chiasmus in Ancient Religious Text"
    ],
    "b_abstract":[
      "Chiasmus, a debated literary device in Biblical texts, has captivated mystics\nwhile sparking ongoing scholarly discussion. In this paper, we introduce the\nfirst computational approach to systematically detect chiasmus within Biblical\npassages. Our method leverages neural embeddings to capture lexical and\nsemantic patterns associated with chiasmus, applied at multiple levels of\ntextual granularity (half-verses, verses). We also involve expert annotators to\nreview a subset of the detected patterns. Despite its computational efficiency,\nour method achieves robust results, with high inter-annotator agreement and\nsystem precision@k of 0.80 at the verse level and 0.60 at the half-verse level.\nWe further provide a qualitative analysis of the distribution of detected\nchiasmi, along with selected examples that highlight the effectiveness of our\napproach."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04498",
    "c_title":[
      "Verifiable Format Control for Large Language Model Generations"
    ],
    "c_abstract":[
      "Recent Large Language Models (LLMs) have demonstrated satisfying general\ninstruction following ability. However, small LLMs with about 7B parameters\nstill struggle fine-grained format following (e.g., JSON format), which\nseriously hinder the advancements of their applications. Most existing methods\nfocus on benchmarking general instruction following while overlook how to\nimprove the specific format following ability for small LLMs. Besides, these\nmethods often rely on evaluations based on advanced LLMs (e.g., GPT-4), which\ncan introduce the intrinsic bias of LLMs and be costly due to the API calls. In\nthis paper, we first curate a fully verifiable format following dataset VFF. In\ncontrast to existing works often adopting external LLMs for\ninstruction-following validations, every sample of VFF can be easily validated\nwith a Python function. Further, we propose to leverage this verifiable feature\nto synthesize massive data for progressively training small LLMs, in order to\nimprove their format following abilities. Experimental results highlight the\nprevalent limitations in the format following capabilities of 7B level\nopen-source LLMs and demonstrate the effectiveness of our method in enhancing\nthis essential ability."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-219",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08719",
    "b_title":[
      "Extrapolated Hard Thresholding Algorithms with Finite Length for\n  Composite $\\ell_0$ Penalized Problems"
    ],
    "b_abstract":[
      "For a class of sparse optimization problems with the penalty function of\n$\\|(\\cdot)_+\\|_0$, we first characterize its local minimizers and then propose\nan extrapolated hard thresholding algorithm to solve such problems. We show\nthat the iterates generated by the proposed algorithm with $\\epsilon>0$ (where\n$\\epsilon$ is the dry friction coefficient) have finite length, without relying\non the Kurdyka-{\\L}ojasiewicz inequality. Furthermore, we demonstrate that the\nalgorithm converges to an $\\epsilon$-local minimizer of this problem. For the\nspecial case that $\\epsilon=0$, we establish that any accumulation point of the\niterates is a local minimizer of the problem. Additionally, we analyze the\nconvergence when an error term is present in the algorithm, showing that the\nalgorithm still converges in the same manner as before, provided that the\nerrors asymptotically approach zero. Finally, we conduct numerical experiments\nto verify the theoretical results of the proposed algorithm."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.12915",
    "c_title":[
      "Smoothing Accelerated Proximal Gradient Method with Backtracking for\n  Nonsmooth Multiobjective Optimization"
    ],
    "c_abstract":[
      "For the composite multi-objective optimization problem composed of two\nnonsmooth terms, a smoothing method is used to overcome the nonsmoothness of\nthe objective function, making the objective function contain at most one\nnonsmooth term. Then, inspired by the design idea of the aforementioned\nbacktracking strategy, an update rule is proposed by constructing a\nrelationship between an estimation sequence of the Lipschitz constant and a\nsmoothing factor, which results in a backtracking strategy suitable for this\nproblem, allowing the estimation sequence to be updated in a non-increasing\nmanner. On this basis, a smoothing accelerated proximal gradient algorithm\nbased on the backtracking strategy is further proposed. Under appropriate\nconditions, it is proven that all accumulation points of the sequence generated\nby this algorithm are weak Pareto optimal solutions. Additionally, the\nconvergence rate of the algorithm under different parameters is established\nusing a utility function. Numerical experiments show that, compared with the\nsubgradient algorithm, the proposed algorithm demonstrates significant\nadvantages in terms of runtime, iteration count, and function evaluations."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-220",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17927",
    "b_title":[
      "Advantage-Guided Distillation for Preference Alignment in Small Language\n  Models"
    ],
    "b_abstract":[
      "Alignment techniques enable Large Language Models (LLMs) to generate outputs\nthat align with human preferences and play a crucial role in their\neffectiveness. However, their impact often diminishes when applied to Small\nLanguage Models (SLMs), likely due to the limited capacity of these models.\nInstead of directly applying existing alignment techniques to SLMs, we propose\nto utilize a well-aligned teacher LLM to guide the alignment process for these\nmodels, thereby facilitating the transfer of the teacher's knowledge of human\npreferences to the student model. To achieve this, we first explore a\nstraightforward approach, Dual-Constrained Knowledge Distillation (DCKD), that\nemploys knowledge distillation with two KL-divergence constraints from the\naligned teacher to the unaligned student. To further enhance the student's\nability to distinguish between preferred and dispreferred responses, we then\npropose Advantage-Guided Distillation for Preference Alignment (ADPA), which\nleverages an advantage function from the aligned teacher to deliver more\nnuanced, distribution-level reward signals for the student's alignment. Our\nexperimental results show that these two approaches appreciably improve the\nalignment of SLMs and narrow the performance gap with larger counterparts.\nAmong them, ADPA demonstrates superior performance and achieves even greater\neffectiveness when integrated with DCKD. Our code is available at\nhttps:\/\/github.com\/SLIT-AI\/ADPA."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05150",
    "c_title":[
      "Interpersonal Memory Matters: A New Task for Proactive Dialogue\n  Utilizing Conversational History"
    ],
    "c_abstract":[
      "Proactive dialogue systems aim to empower chatbots with the capability of\nleading conversations towards specific targets, thereby enhancing user\nengagement and service autonomy. Existing systems typically target pre-defined\nkeywords or entities, neglecting user attributes and preferences implicit in\ndialogue history, hindering the development of long-term user intimacy. To\naddress these challenges, we take a radical step towards building a more\nhuman-like conversational agent by integrating proactive dialogue systems with\nlong-term memory into a unified framework. Specifically, we define a novel task\nnamed Memory-aware Proactive Dialogue (MapDia). By decomposing the task, we\nthen propose an automatic data construction method and create the first Chinese\nMemory-aware Proactive Dataset (ChMapData). Furthermore, we introduce a joint\nframework based on Retrieval Augmented Generation (RAG), featuring three\nmodules: Topic Summarization, Topic Retrieval, and Proactive Topic-shifting\nDetection and Generation, designed to steer dialogues towards relevant\nhistorical topics at the right time. The effectiveness of our dataset and\nmodels is validated through both automatic and human evaluations. We release\nthe open-source framework and dataset at\nhttps:\/\/github.com\/FrontierLabs\/MapDia."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-221",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10247",
    "b_title":[
      "Optimal multicore quantum computing with few interconnects"
    ],
    "b_abstract":[
      "Noisy intermediate-scale quantum processors have produced a quantum\ncomputation revolution in recent times. However, to make further advances new\nstrategies to overcome the error rate growth are needed. One possible way out\nis dividing these devices into many cores. On the other hand, the majorization\ncriterion efficiently classifies quantum circuits in terms of their complexity,\nwhich can be directly related to their ability of performing non classically\nsimulatable computations. In this paper, we use this criterion to study the\ncomplexity behavior of a paradigmatic universal family of random circuits\ndistributed into several cores with different architectures. We find that the\noptimal complexity is reached with few interconnects, this giving further hope\nto actual implementations in nowadays available devices. A universal behavior\nis found irrespective of the architecture and (approximately) of the core size.\nWe also analyze the complexity properties when scaling processors up by means\nof adding cores of the same size. We provide a conjecture to explain the\nresults."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.06110",
    "c_title":[
      "Quantum networks using rare-earth ions"
    ],
    "c_abstract":[
      "We review concepts and recent work related to creating light-matter\ninterfaces for future quantum networks based on rare-earth ion-doped crystals.\nMore precisely, we explore their unique suitability for creating photon\nsources, optical quantum memories for light, and qubits that allow quantum\ninformation processing. In addition, we review the state-of-the-art of\nelementary quantum repeater links, and provide suggestions for future research."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-222",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08107",
    "b_title":[
      "Machine Learning-Driven Volumetric Cloud Rendering: Procedural Shader\n  Optimization and Dynamic Lighting in Unreal Engine for Realistic Atmospheric\n  Simulation"
    ],
    "b_abstract":[
      "This study advances real-time volumetric cloud rendering in Computer Graphics\n(CG) by developing a specialized shader in Unreal Engine (UE), focusing on\nrealistic cloud modeling and lighting. By leveraging ray-casting-based lighting\nalgorithms, this work demonstrates the practical application of a dual-layered\nprocedural noise model, eliminating the need for conventional two-dimensional\n(2D) weather textures. The shader allows for procedurally configured skies with\na defined parameter set, offering flexibility for both artistic expression and\nrealistic simulation. Empirical results reveal that the shader achieves an\naverage rendering time of 35ms per frame while maintaining high visual accuracy\nand scene realism. Visual fidelity assessments indicate a 15% improvement in\ncloud realism over traditional 2D techniques, particularly in dynamic lighting\nscenarios. This research contributes to CG by bridging technical and aesthetic\nelements, enhancing real-time visual storytelling and immersion within gigital\nmedia environments."
    ],
    "b_categories":[
      [
        "cs.GR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16129",
    "c_title":[
      "Controllable Segmentation-Based Text-Guided Style Editing"
    ],
    "c_abstract":[
      "We present a novel approach for controllable, region-specific style editing\ndriven by textual prompts. Building upon the state-space style alignment\nframework introduced by \\emph{StyleMamba}, our method integrates a semantic\nsegmentation model into the style transfer pipeline. This allows users to\nselectively apply text-driven style changes to specific segments (e.g., ``turn\nthe building into a cyberpunk tower'') while leaving other regions (e.g.,\n``people'' or ``trees'') unchanged. By incorporating region-wise condition\nvectors and a region-specific directional loss, our method achieves\nhigh-fidelity transformations that respect both semantic boundaries and\nuser-driven style descriptions. Extensive experiments demonstrate that our\napproach can flexibly handle complex scene stylizations in real-world\nscenarios, improving control and quality over purely global style transfer\nmethods."
    ],
    "c_categories":[
      [
        "cs.GR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-223",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11511",
    "b_title":[
      "Signature of strange star as the central engine of GRB 240529A"
    ],
    "b_abstract":[
      "GRB 240529A is a long-duration gamma-ray burst (GRB) whose light curve of\nprompt emission is composed of a triple-episode structure, separated by\nquiescent gaps of tens to hundreds of seconds. More interestingly, its X-ray\nlight curve of afterglow exhibits two-plateau emissions, namely, an internal\nplateau emission that is smoothly connected with a $\\sim t^{-0.1}$ segment and\nfollowed by a $\\sim t^{-2}$ power-law decay. The three episodes in the prompt\nemission, together with two plateau emissions in X-ray, are unique in the Swift\nera. They are very difficult to explain with the standard internal\/external\nshock model by invoking a black hole central engine. However, it could be\nconsistent with the prediction of a supramassive magnetar as the central\nengine, the physical process of phase transition from magnetar to strange star,\nas well as the cooling and spin-down of the strange star. In this paper, we\npropose that the first- and second-episode emissions in the prompt $\\gamma-$ray\nof GRB 240529A are from the jet emission of a massive star collapsing into a\nsupramassive magnetar and the re-activity of central engine, respectively.\nThen, the third-episode emission of prompt is attributed to the phase\ntransition from a magnetar to a strange star. Finally, the first- and\nsecond-plateau emissions of the X-ray afterglow are powered by the cooling and\nspin-down of the strange star, respectively. The observational data of each\ncomponent of GRB 240529A are roughly coincident with the estimations of the\nabove physical picture."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.12070",
    "c_title":[
      "KM3NeT Constraint on Lorentz-Violating Superluminal Neutrino Velocity"
    ],
    "c_abstract":[
      "Lorentz invariance is a fundamental symmetry of spacetime and foundational to\nmodern physics. One of its most important consequences is the constancy of the\nspeed of light. This invariance, together with the geometry of spacetime,\nimplies that no particle can move faster than the speed of light. In this\narticle, we present the most stringent neutrino-based test of this prediction,\nusing the highest energy neutrino ever detected to date, KM3-230213A. The\narrival of this event, with an energy of $220^{+570}_{-110}\\,\\text{PeV}$, sets\na constraint on $\\delta \\equiv c_\\nu^2-1 < 4\\times10^{-22}$."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-224",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11874",
    "b_title":[
      "Large Deviations for Slow-Fast Mean-Field Diffusions"
    ],
    "b_abstract":[
      "The aim of this paper is to investigate the large deviations for a class of\nslow-fast mean-field diffusions, which extends some existing results to the\ncase where the laws of fast process are also involved in the slow component.\nDue to the perturbations of fast process and its time marginal law, one cannot\nprove the large deviations based on verifying the powerful weak convergence\ncriterion directly. To overcome this problem, we employ the functional\noccupation measure, which combined with the notion of the viable pair and the\ncontrols of feedback form to characterize the limits of controlled sequences\nand justify the upper and lower bounds of Laplace principle. As a consequence,\nthe explicit representation formula of the rate function for large deviations\nis also presented."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.01363",
    "c_title":[
      "Generalized Counting Process with Random Drift and Different Brownian\n  Clocks"
    ],
    "c_abstract":[
      "In this paper, we introduce drifted versions of the generalized counting\nprocess (GCP) with a deterministic drift and a random drift. The composition of\nstable subordinator with an independent inverse stable subordinator is taken as\nthe random drift. We derive the probability law and its governing fractional\ndifferential equations for these drifted versions. Also, we study the GCP\ntime-changed with different Brownian clocks, for example, the Brownian first\npassage-time with or without drift, elastic Brownian motion, Brownian sojourn\ntime on positive half-line and the Bessel times. For these time-changed\nprocesses, we obtain the governing system of differential equation of their\nstate probabilities, probability generating function, etc. Further, we consider\na time-changed GCP where the time-change is done by subordinators linked to\nincomplete gamma function. Later, we study the fractional integral of GCP and\nits time-changed variant."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-225",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06461",
    "b_title":[
      "Assessing instructor-AI cooperation for grading essay-type questions in\n  an introductory sociology course"
    ],
    "b_abstract":[
      "This study explores the use of artificial intelligence (AI) as a\ncomplementary tool for grading essay-type questions in higher education,\nfocusing on its consistency with human grading and potential to reduce biases.\nUsing 70 handwritten exams from an introductory sociology course, we evaluated\ngenerative pre-trained transformers (GPT) models' performance in transcribing\nand scoring students' responses. GPT models were tested under various settings\nfor both transcription and grading tasks. Results show high similarity between\nhuman and GPT transcriptions, with GPT-4o-mini outperforming GPT-4o in\naccuracy. For grading, GPT demonstrated strong correlations with the human\ngrader scores, especially when template answers were provided. However,\ndiscrepancies remained, highlighting GPT's role as a \"second grader\" to flag\ninconsistencies for assessment reviewing rather than fully replace human\nevaluation. This study contributes to the growing literature on AI in\neducation, demonstrating its potential to enhance fairness and efficiency in\ngrading essay-type questions."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15947",
    "c_title":[
      "Unreal-MAP: Unreal-Engine-Based General Platform for Multi-Agent\n  Reinforcement Learning"
    ],
    "c_abstract":[
      "In this paper, we propose Unreal Multi-Agent Playground (Unreal-MAP), an MARL\ngeneral platform based on the Unreal-Engine (UE). Unreal-MAP allows users to\nfreely create multi-agent tasks using the vast visual and physical resources\navailable in the UE community, and deploy state-of-the-art (SOTA) MARL\nalgorithms within them. Unreal-MAP is user-friendly in terms of deployment,\nmodification, and visualization, and all its components are open-source. We\nalso develop an experimental framework compatible with algorithms ranging from\nrule-based to learning-based provided by third-party frameworks. Lastly, we\ndeploy several SOTA algorithms in example tasks developed via Unreal-MAP, and\nconduct corresponding experimental analyses. We believe Unreal-MAP can play an\nimportant role in the MARL field by closely integrating existing algorithms\nwith user-customized tasks, thus advancing the field of MARL."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-226",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17849",
    "b_title":[
      "Self-organised dynamics and emergent shape spaces of active isotropic\n  fluid surfaces"
    ],
    "b_abstract":[
      "Theories of self-organised active fluid surfaces have emerged as an important\nclass of minimal models for the shape dynamics of biological membranes, cells\nand tissues. Here, we develop and apply a variational approach for active fluid\nsurfaces to systematically study the nonlinear dynamics and emergent shape\nspaces such theories give rise to. To represent dynamic surfaces, we design an\narbitrary Lagrangian-Eulerian parameterizations for deforming surfaces.\nExploiting the symmetries imposed by Onsager relations, we construct a\nvariational formulation that is based on the entropy production in active\nsurfaces. The resulting dissipation functional is complemented by Lagrange\nmultipliers to relax nonlinear geometric constraints, which allows for a direct\ncomputation of steady state solutions of surface shapes and flows. We apply\nthis framework to study the dynamics of open fluid membranes and closed active\nfluid surfaces, and characterize the space of stationary solutions that\ncorresponding surfaces and flows occupy. Our analysis rationalizes the\ninterplay of first-order shape transitions of internally and externally forced\nfluid membranes, reveals degenerate regions in stationary shape spaces of\nmechanochemically active surfaces and identifies a mechanism by which\nhydrodynamic screening controls the geometry of active surfaces undergoing cell\ndivision-like shape transformations."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.06173",
    "c_title":[
      "Driven Polymer Translocation through a Nanopore from a Confining Channel"
    ],
    "c_abstract":[
      "We consider the dynamics of pore-driven polymer translocation through a\nnanopore to semi-infinite space when the chain is initially confined and\nequilibrated in a narrow channel. To this end, we use Langevin dynamics (LD)\nsimulations and iso-flux tension propagation (IFTP) theory to characterize\nlocal and global dynamics of the translocating chain. The dynamics of the\nprocess can be described by the IFTP theory in very good agreement with the LD\nsimulations for all values of confinement in the channel. The theory reveals\nthat for channels with size comparable to or less than the end-to-end distance\nof the unconfined chain, in which the blob theory works, the scaling form of\nthe translocation time depends on both the chain contour length as well as the\nchannel width. %originating from the confinement of the spatial fluctuations of\nthe chain inside the channel. Conversely, for a very narrow channel the\ntranslocation time only depends on the chain contour length and is similar to\nthat of a rod due to the absence of spatial chain fluctuations."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-227",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02270",
    "b_title":[
      "SSNet: Saliency Prior and State Space Model-based Network for Salient\n  Object Detection in RGB-D Images"
    ],
    "b_abstract":[
      "Salient object detection (SOD) in RGB-D images is an essential task in\ncomputer vision, enabling applications in scene understanding, robotics, and\naugmented reality. However, existing methods struggle to capture global\ndependency across modalities, lack comprehensive saliency priors from both RGB\nand depth data, and are ineffective in handling low-quality depth maps. To\naddress these challenges, we propose SSNet, a saliency-prior and state space\nmodel (SSM)-based network for the RGB-D SOD task. Unlike existing convolution-\nor transformer-based approaches, SSNet introduces an SSM-based multi-modal\nmulti-scale decoder module to efficiently capture both intra- and inter-modal\nglobal dependency with linear complexity. Specifically, we propose a\ncross-modal selective scan SSM (CM-S6) mechanism, which effectively captures\nglobal dependency between different modalities. Furthermore, we introduce a\nsaliency enhancement module (SEM) that integrates three saliency priors with\ndeep features to refine feature representation and improve the localization of\nsalient objects. To further address the issue of low-quality depth maps, we\npropose an adaptive contrast enhancement technique that dynamically refines\ndepth maps, making them more suitable for the RGB-D SOD task. Extensive\nquantitative and qualitative experiments on seven benchmark datasets\ndemonstrate that SSNet outperforms state-of-the-art methods."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.18352",
    "c_title":[
      "Diffusion-4K: Ultra-High-Resolution Image Synthesis with Latent\n  Diffusion Models"
    ],
    "c_abstract":[
      "In this paper, we present Diffusion-4K, a novel framework for direct\nultra-high-resolution image synthesis using text-to-image diffusion models. The\ncore advancements include: (1) Aesthetic-4K Benchmark: addressing the absence\nof a publicly available 4K image synthesis dataset, we construct Aesthetic-4K,\na comprehensive benchmark for ultra-high-resolution image generation. We\ncurated a high-quality 4K dataset with carefully selected images and captions\ngenerated by GPT-4o. Additionally, we introduce GLCM Score and Compression\nRatio metrics to evaluate fine details, combined with holistic measures such as\nFID, Aesthetics and CLIPScore for a comprehensive assessment of\nultra-high-resolution images. (2) Wavelet-based Fine-tuning: we propose a\nwavelet-based fine-tuning approach for direct training with photorealistic 4K\nimages, applicable to various latent diffusion models, demonstrating its\neffectiveness in synthesizing highly detailed 4K images. Consequently,\nDiffusion-4K achieves impressive performance in high-quality image synthesis\nand text prompt adherence, especially when powered by modern large-scale\ndiffusion models (e.g., SD3-2B and Flux-12B). Extensive experimental results\nfrom our benchmark demonstrate the superiority of Diffusion-4K in\nultra-high-resolution image synthesis."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-228",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00677",
    "b_title":[
      "Advancing Prompt-Based Methods for Replay-Independent General Continual\n  Learning"
    ],
    "b_abstract":[
      "General continual learning (GCL) is a broad concept to describe real-world\ncontinual learning (CL) problems, which are often characterized by online data\nstreams without distinct transitions between tasks, i.e., blurry task\nboundaries. Such requirements result in poor initial performance, limited\ngeneralizability, and severe catastrophic forgetting, heavily impacting the\neffectiveness of mainstream GCL models trained from scratch. While the use of a\nfrozen pretrained backbone with appropriate prompt tuning can partially address\nthese challenges, such prompt-based methods remain suboptimal for CL of\nremaining tunable parameters on the fly. In this regard, we propose an\ninnovative approach named MISA (Mask and Initial Session Adaption) to advance\nprompt-based methods in GCL. It includes a forgetting-aware initial session\nadaption that employs pretraining data to initialize prompt parameters and\nimprove generalizability, as well as a non-parametric logit mask of the output\nlayers to mitigate catastrophic forgetting. Empirical results demonstrate\nsubstantial performance gains of our approach compared to recent competitors,\nespecially without a replay buffer (e.g., up to 18.39%, 22.06%, and 11.96%\nperformance lead on CIFAR-100, Tiny-ImageNet, and ImageNet-R, respectively).\nMoreover, our approach features the plug-in nature for prompt-based methods,\nindependence of replay, ease of implementation, and avoidance of CL-relevant\nhyperparameters, serving as a strong baseline for GCL research. Our source code\nis publicly available at https:\/\/github.com\/kangzhiq\/MISA"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15179",
    "c_title":[
      "Nonlinear Dynamical Systems for Automatic Face Annotation in Head\n  Tracking and Pose Estimation"
    ],
    "c_abstract":[
      "Facial landmark tracking plays a vital role in applications such as facial\nrecognition, expression analysis, and medical diagnostics. In this paper, we\nconsider the performance of the Extended Kalman Filter (EKF) and Unscented\nKalman Filter (UKF) in tracking 3D facial motion in both deterministic and\nstochastic settings. We first analyze a noise-free environment where the state\ntransition is purely deterministic, demonstrating that UKF outperforms EKF by\nachieving lower mean squared error (MSE) due to its ability to capture\nhigher-order nonlinearities. However, when stochastic noise is introduced, EKF\nexhibits superior robustness, maintaining lower mean square error (MSE)\ncompared to UKF, which becomes more sensitive to measurement noise and\nocclusions. Our results highlight that UKF is preferable for high-precision\napplications in controlled environments, whereas EKF is better suited for\nreal-world scenarios with unpredictable noise. These findings provide practical\ninsights for selecting the appropriate filtering technique in 3D facial\ntracking applications, such as motion capture and facial recognition."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-229",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14504",
    "b_title":[
      "Aligning Multimodal LLM with Human Preference: A Survey"
    ],
    "b_abstract":[
      "Large language models (LLMs) can handle a wide variety of general tasks with\nsimple prompts, without the need for task-specific training. Multimodal Large\nLanguage Models (MLLMs), built upon LLMs, have demonstrated impressive\npotential in tackling complex tasks involving visual, auditory, and textual\ndata. However, critical issues related to truthfulness, safety, o1-like\nreasoning, and alignment with human preference remain insufficiently addressed.\nThis gap has spurred the emergence of various alignment algorithms, each\ntargeting different application scenarios and optimization goals. Recent\nstudies have shown that alignment algorithms are a powerful approach to\nresolving the aforementioned challenges. In this paper, we aim to provide a\ncomprehensive and systematic review of alignment algorithms for MLLMs.\nSpecifically, we explore four key aspects: (1) the application scenarios\ncovered by alignment algorithms, including general image understanding,\nmulti-image, video, and audio, and extended multimodal applications; (2) the\ncore factors in constructing alignment datasets, including data sources, model\nresponses, and preference annotations; (3) the benchmarks used to evaluate\nalignment algorithms; and (4) a discussion of potential future directions for\nthe development of alignment algorithms. This work seeks to help researchers\norganize current advancements in the field and inspire better alignment\nmethods. The project page of this paper is available at\nhttps:\/\/github.com\/BradyFU\/Awesome-Multimodal-Large-Language-Models\/tree\/Alignment."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14097",
    "c_title":[
      "SCJD: Sparse Correlation and Joint Distillation for Efficient 3D Human\n  Pose Estimation"
    ],
    "c_abstract":[
      "Existing 3D Human Pose Estimation (HPE) methods achieve high accuracy but\nsuffer from computational overhead and slow inference, while knowledge\ndistillation methods fail to address spatial relationships between joints and\ntemporal correlations in multi-frame inputs. In this paper, we propose Sparse\nCorrelation and Joint Distillation (SCJD), a novel framework that balances\nefficiency and accuracy for 3D HPE. SCJD introduces Sparse Correlation Input\nSequence Downsampling to reduce redundancy in student network inputs while\npreserving inter-frame correlations. For effective knowledge transfer, we\npropose Dynamic Joint Spatial Attention Distillation, which includes Dynamic\nJoint Embedding Distillation to enhance the student's feature representation\nusing the teacher's multi-frame context feature, and Adjacent Joint Attention\nDistillation to improve the student network's focus on adjacent joint\nrelationships for better spatial understanding. Additionally, Temporal\nConsistency Distillation aligns the temporal correlations between teacher and\nstudent networks through upsampling and global supervision. Extensive\nexperiments demonstrate that SCJD achieves state-of-the-art performance. Code\nis available at https:\/\/github.com\/wileychan\/SCJD."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-230",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17404",
    "b_title":[
      "On Andr\\'e periods of mixed Tate motives"
    ],
    "b_abstract":[
      "In this note, we show that the $p$-adic periods of motives introduced\nrecently by Ancona and Fr\\u{a}\\c{t}il\\u{a} (``Andr\\'e periods'') reduce to the\nclassically studied notion in the case of Mixed Tate motives. We also connect\nAndr\\'e periods with Coleman integration by observing that the Frobenius-fixed\nde Rham paths of Besser and Vologodsky come from motivic paths in\ncharacteristic $p$ (unconditionally in the mixed Tate setting, conditionally in\ngeneral). We use this to realize special values of $p$-adic multiple\npolylogarithms as Andr\\'e periods in a concrete way."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.08854",
    "c_title":[
      "Derived-natural automorphisms on Hilbert schemes of points on generic\n  polarized K3 surfaces"
    ],
    "c_abstract":[
      "The article revisits birational and biregular automorphisms of the Hilbert\nscheme of points on a K3 surface from the perspective of derived categories.\nUnder the assumption that the K3 surface is generic, the birational and\nbiregular involutions induced by autoequivalences on the derived category of\nthe underlying K3 surface are characterized."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-231",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05344",
    "b_title":[
      "Higher rank prioritary bundles on ruled surfaces and their global\n  sections"
    ],
    "b_abstract":[
      "Let $X$ be a ruled surface over a nonsingular curve $C$ of genus $g\\geq0$.\nThe main goal of this paper is to construct simple prioritary vector bundles of\nany rank $r$ on $X$ and to give effective bounds for the dimension of their\nmodule of global sections."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.07034",
    "c_title":[
      "Algebraic normalisation"
    ],
    "c_abstract":[
      "We present a strictly geometric c-algebraic version of the analytic set\nnormalisation. With the introduced tool we prove the Nullstellensatz for\nc-algebraic functions and study the growth exponent of a c-algebraic function."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-232",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09281",
    "b_title":[
      "SoccerSynth-Detection: A Synthetic Dataset for Soccer Player Detection"
    ],
    "b_abstract":[
      "In soccer video analysis, player detection is essential for identifying key\nevents and reconstructing tactical positions. The presence of numerous players\nand frequent occlusions, combined with copyright restrictions, severely\nrestricts the availability of datasets, leaving limited options such as\nSoccerNet-Tracking and SportsMOT. These datasets suffer from a lack of\ndiversity, which hinders algorithms from adapting effectively to varied soccer\nvideo contexts. To address these challenges, we developed\nSoccerSynth-Detection, the first synthetic dataset designed for the detection\nof synthetic soccer players. It includes a broad range of random lighting and\ntextures, as well as simulated camera motion blur. We validated its efficacy\nusing the object detection model (Yolov8n) against real-world datasets\n(SoccerNet-Tracking and SportsMoT). In transfer tests, it matched the\nperformance of real datasets and significantly outperformed them in images with\nmotion blur; in pre-training tests, it demonstrated its efficacy as a\npre-training dataset, significantly enhancing the algorithm's overall\nperformance. Our work demonstrates the potential of synthetic datasets to\nreplace real datasets for algorithm training in the field of soccer video\nanalysis."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08348",
    "c_title":[
      "Design and Implementation of FourCropNet: A CNN-Based System for\n  Efficient Multi-Crop Disease Detection and Management"
    ],
    "c_abstract":[
      "Plant disease detection is a critical task in agriculture, directly impacting\ncrop yield, food security, and sustainable farming practices. This study\nproposes FourCropNet, a novel deep learning model designed to detect diseases\nin multiple crops, including CottonLeaf, Grape, Soybean, and Corn. The model\nleverages an advanced architecture comprising residual blocks for efficient\nfeature extraction, attention mechanisms to enhance focus on disease-relevant\nregions, and lightweight layers for computational efficiency. These components\ncollectively enable FourCropNet to achieve superior performance across varying\ndatasets and class complexities, from single-crop datasets to combined datasets\nwith 15 classes. The proposed model was evaluated on diverse datasets,\ndemonstrating high accuracy, specificity, sensitivity, and F1 scores. Notably,\nFourCropNet achieved the highest accuracy of 99.7% for Grape, 99.5% for Corn,\nand 95.3% for the combined dataset. Its scalability and ability to generalize\nacross datasets underscore its robustness. Comparative analysis shows that\nFourCropNet consistently outperforms state-of-the-art models such as MobileNet,\nVGG16, and EfficientNet across various metrics. FourCropNet's innovative design\nand consistent performance make it a reliable solution for real-time disease\ndetection in agriculture. This model has the potential to assist farmers in\ntimely disease diagnosis, reducing economic losses and promoting sustainable\nagricultural practices."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-233",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13689",
    "b_title":[
      "Exact statistical tests using integer programming: Leveraging an\n  overlooked approach for maximizing power for differences between binomial\n  proportions"
    ],
    "b_abstract":[
      "Traditional hypothesis testing methods for differences in binomial\nproportions can either be too liberal (Wald test) or overly conservative\n(Fisher's exact test), especially in small samples. Regulators favour\nconservative approaches for robust type I error control, though excessive\nconservatism may significantly reduce statistical power. We offer fundamental\ntheoretical contributions that extend an approach proposed in 1969, resulting\nin the derivation of a family of exact tests designed to maximize a specific\ntype of power. We establish theoretical guarantees for controlling type I error\ndespite the discretization of the null parameter space. This theoretical\nadvancement is supported by a comprehensive series of experiments to\nempirically quantify the power advantages compared to traditional hypothesis\ntests. The approach determines the rejection region through a binary decision\nfor each outcome dataset and uses integer programming to find an optimal\ndecision boundary that maximizes power subject to type I error constraints. Our\nanalysis provides new theoretical properties and insights into this approach's\ncomparative advantages. When optimized for average power over all possible\nparameter configurations under the alternative, the method exhibits remarkable\nrobustness, performing optimally or near-optimally across specific alternatives\nwhile maintaining exact type I error control. The method can be further\ncustomized for particular prior beliefs by using a weighted average. The\nfindings highlight both the method's practical utility and how techniques from\ncombinatorial optimization can enhance statistical methodology."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02514",
    "c_title":[
      "Selection from Hierarchical Data with Conformal e-values"
    ],
    "c_abstract":[
      "Distribution-free predictive inference beyond the construction of prediction\nsets has gained a lot of interest in recent applications. One such application\nis the selection task, where the objective is to design a reliable selection\nrule to pick out individuals with desired unobserved outcomes while controlling\nthe error rate. In this work, we address the selection problem in the context\nof hierarchical data, where groups of observations may exhibit distinct\nwithin-group distributions. This generalizes existing techniques beyond the\nstandard i.i.d.\/exchangeable data settings. As a correction, For hierarchical\ndata, we introduce methods to construct valid conformal e-values, enabling\ncontrol of the false discovery rate (FDR) through the e-BH procedure. In\nparticular, we introduce and compare two approaches -- subsampling conformal\ne-values and hierarchical conformal e-values. Empirical results demonstrate\nthat both approaches achieve valid FDR control while highlighting a tradeoff\nbetween stability and power. The subsampling-based method, though random,\ntypically offers higher power, whereas the hierarchical approach, being\ndeterministic, tends to be slightly less powerful. The effectiveness of the\nproposed methods is illustrated in two real-world applications."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-234",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09936",
    "b_title":[
      "Spin-squeezed vector atomic magnetometry"
    ],
    "b_abstract":[
      "Atomic magnetometers based on Zeeman shift measurement have the potential for\nhigh sensitivity and long-term stability. Like other atomic sensors including\natomic clocks and atom interferometers, the atomic magnetometer could in\nprinciple be augmented with spin squeezing for further sensitivity enhancement.\nHowever, existing atomic magnetometers are not compatible with spin squeezing\nbecause the atoms can hardly be in a pure quantum state during operation. A\nnatural challenge is the arbitrary direction of the magnetic field. In this\npaper, we propose a cold-atom-based magnetometer with spin squeezing that can\nmeasure both the magnitude and the direction of an arbitrary magnetic field.\nFor experimentally accessible parameters, we show that the technique described\nabove could achieve a sensitivity nearly three orders of magnitude higher than\nthat of the best existing magnetometers."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11239",
    "c_title":[
      "Optical-pumping attack on a quantum key distribution laser source"
    ],
    "c_abstract":[
      "We report a new type of vulnerability in practical implementations of quantum\nkey distribution systems. We show that it is possible to increase the pulse\nenergy of a source laser diode not only by injection-locking it by external\nlight near its emission wavelength of 1550 nm, but also by optically pumping it\nat a much shorter wavelength. We demonstrate 10% increase in pulse energy when\nexposing the laser diode to 1310-nm, 1.6-mW cw laser light via its fiber\npigtail. This may allow an eavesdropper to steal the secret key. A possible\ncountermeasure is to install broadband optical filters and isolators at the\nsource's output and characterise them during the security certification."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-235",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08178",
    "b_title":[
      "Detection and analysis of synchronization routes in an axially forced\n  globally unstable jet using recurrence quantification"
    ],
    "b_abstract":[
      "Quasiperiodicity, a partially synchronous state that precedes the onset of\nforced synchronization in hydrodynamic systems, exhibits distinct geometrical\npatterns based on the specific route to lock-in. In this study, we explore\nthese dynamic behaviors using recurrence quantification analysis. Focusing on a\nself-excited hydrodynamic system-a low-density jet subjected to external\nacoustic forcing at varying frequencies and amplitudes. We generate recurrence\nplots from unsteady velocity time traces. These recurrence plots provide\ninsight into the synchronization dynamics and pathways of the jet under forced\nconditions. Further, we show that recurrence quantities are helpful to detect\nand distinguish between different routes to lock-in."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.07779",
    "c_title":[
      "The route to turbulence in magnetohydrodynamic square duct flow"
    ],
    "c_abstract":[
      "The transition route from laminar to turbulent flow in a magnetohydrodynamic\n(MHD) duct with a square cross-section is investigated in the limit of low\nmagnetic Reynolds number. In the presence of a transverse magnetic field,\nHartmann and Shercliff layers are present on the walls orthogonal and parallel\nto the field direction, respectively. We assume reflection symmetries in both\ntransverse directions, and investigate the competition between transition\nmechanisms specific to each boundary layer using direct numerical simulations.\nIndependently of which wall turbulence eventually occupies, transition relies\nexclusively on a tripping of the Shercliff layer by perturbations, while the\nHartmann layer plays a passive role. This is explained, using a dynamical\nsystems interpretation, by the spatial localization of the edge states in the\nShercliff layer at the expense of the Hartmann layer. The link between these\nnon-linear coherent structures and the linear optimal modes known from\nnon-modal stability and energy stability theory is pointed out."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-236",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12686",
    "b_title":[
      "Electron transport properties of heterogeneous interfaces in solid\n  electrolyte interphase on lithium metal anodes"
    ],
    "b_abstract":[
      "In rechargeable batteries, electron transport properties of inorganics in the\nsolid-electrolyte interphase (SEI) critically determine the safety, lifespan\nand capacity loss of batteries. However, the electron transport properties of\nheterogeneous interfaces among different solid inorganics in SEI have not been\nstudied experimentally or theoretically yet, although such heterogeneous\ninterfaces exist inevitably. Here, by employing non-equilibrium Green's\nfunction (NEGF) method, we theoretically evaluated the atomic-scale electron\ntransport properties under bias voltage for LiF\/Li2O interfaces and\nsingle-component layers of them, since LiF and Li2O are common stable\ninorganics in the SEI. We reveal that heterogeneous interfaces orthogonal to\nthe external electric-field direction greatly impede electron transport in SEI,\nwhereas heterogeneous parallel-orientated interfaces enhance it. Structural\ndisorders induced by densely distributed interfaces can severely interfere with\nelectron transport. For each component, single-crystal LiF is highly effective\nto block electron transport, with a critical thickness of 2.9 nm, much smaller\nthan that of Li2O (19.0 nm). This study sheds a new light into direct and\nquantitative understanding of the electron transport properties of\nheterogeneous interfaces in SEI, which holds promise for the advancement of a\nnew generation of high-performance batteries."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.15190",
    "c_title":[
      "Decoding lithium's subtle phase stability with a machine learning force\n  field"
    ],
    "c_abstract":[
      "Understanding the phase stability of elemental lithium (Li) is crucial for\noptimizing its performance in lithium-metal battery anodes, yet this seemingly\nsimple metal exhibits complex polymorphism that requires proper accounting for\nquantum and anharmonic effects to capture the subtleties in its flat energy\nlandscape. Here we address this challenge by developing an accurate graph\nneural network-based machine learning force field and performing efficient\nself-consistent phonon calculations for bcc-, fcc-, and 9R-Li under\nnear-ambient conditions, incorporating quantum, phonon renormalization and\nthermal expansion effects. Our results reveal the important role of\nanharmonicity in determining Li's thermodynamic properties. The free energy\ndifferences between these phases, particularly fcc- and 9R-Li are found to be\nonly a few meV\/atom, explaining the experimental challenges in obtaining\nphase-pure samples and suggesting a propensity for stacking faults and related\ndefect formation. fcc-Li is confirmed as the ground state at zero temperature\nand pressure, and the predicted bcc-fcc phase boundary qualitatively matches\nexperimental phase transition lines, despite overestimation of the transition\ntemperature and pressure slope. These findings provide crucial insights into\nLi's complex polymorphism and establish an effective computational approach for\nlarge-scale atomistic simulations of Li in more realistic settings for\npractical energy storage applications."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-237",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04268",
    "b_title":[
      "ControlFill: Spatially Adjustable Image Inpainting from Prompt Learning"
    ],
    "b_abstract":[
      "In this report, I present an inpainting framework named \\textit{ControlFill},\nwhich involves training two distinct prompts: one for generating plausible\nobjects within a designated mask (\\textit{creation}) and another for filling\nthe region by extending the background (\\textit{removal}). During the inference\nstage, these learned embeddings guide a diffusion network that operates without\nrequiring heavy text encoders. By adjusting the relative significance of the\ntwo prompts and employing classifier-free guidance, users can control the\nintensity of removal or creation. Furthermore, I introduce a method to\nspatially vary the intensity of guidance by assigning different scales to\nindividual pixels."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12022",
    "c_title":[
      "Foreign object segmentation in chest x-rays through anatomy-guided shape\n  insertion"
    ],
    "c_abstract":[
      "In this paper, we tackle the challenge of instance segmentation for foreign\nobjects in chest radiographs, commonly seen in postoperative follow-ups with\nstents, pacemakers, or ingested objects in children. The diversity of foreign\nobjects complicates dense annotation, as shown in insufficient existing\ndatasets. To address this, we propose the simple generation of synthetic data\nthrough (1) insertion of arbitrary shapes (lines, polygons, ellipses) with\nvarying contrasts and opacities, and (2) cut-paste augmentations from a small\nset of semi-automatically extracted labels. These insertions are guided by\nanatomy labels to ensure realistic placements, such as stents appearing only in\nrelevant vessels. Our approach enables networks to segment complex structures\nwith minimal manually labeled data. Notably, it achieves performance comparable\nto fully supervised models while using 93\\% fewer manual annotations."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-238",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18164",
    "b_title":[
      "Closest univariate convex linear-quadratic function approximation with\n  minimal number of Pieces"
    ],
    "b_abstract":[
      "We compute the closest convex piecewise linear-quadratic (PLQ) function with\nminimal number of pieces to a given univariate piecewise linear-quadratic\nfunction. The Euclidean norm is used to measure the distance between functions.\nFirst, we assume that the number and positions of the breakpoints of the output\nfunction are fixed, and solve a convex optimization problem. Next, we assume\nthe number of breakpoints is fixed, but not their position, and solve a\nnonconvex optimization problem to determine optimal breakpoints placement.\nFinally, we propose an algorithm composed of a greedy search preprocessing and\na dichotomic search that solves a logarithmic number of optimization problems\nto obtain an approximation of any PLQ function with minimal number of pieces\nthereby obtaining in two steps the closest convex function with minimal number\nof pieces.\n  We illustrate our algorithms with multiple examples, compare our approach\nwith a previous globally optimal univariate spline approximation algorithm, and\napply our method to simplify vertical alignment curves in road design\noptimization. CPLEX, Gurobi, and BARON are used with the YALMIP library in\nMATLAB to effectively select the most efficient solver."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.01228",
    "c_title":[
      "Improved description of Blaschke--Santal\\'o diagrams via numerical shape\n  optimization"
    ],
    "c_abstract":[
      "We propose a method based on the combination of theoretical results on\nBlaschke--Santal\\'o diagrams and numerical shape optimization techniques to\nobtain improved description of Blaschke--Santal\\'o diagrams in the class of\nplanar convex sets. To illustrate our approach, we study three relevant\ndiagrams involving the perimeter $P$, the diameter $d$, the area $A$ and the\nfirst eigenvalue of the Laplace operator with Dirichlet boundary condition\n$\\lambda_1$. The first diagram is a purely geometric one involving the triplet\n$(P,d,A)$ and the two other diagrams involve geometric and spectral\nfunctionals, namely $(P,\\lambda_1,A)$ and $(d,\\lambda_1,A)$ where a strange\nphenomenon of non-continuity of the extremal shapes is observed."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-239",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06471",
    "b_title":[
      "Online Dense Point Tracking with Streaming Memory"
    ],
    "b_abstract":[
      "Dense point tracking is a challenging task requiring the continuous tracking\nof every point in the initial frame throughout a substantial portion of a\nvideo, even in the presence of occlusions. Traditional methods use optical flow\nmodels to directly estimate long-range motion, but they often suffer from\nappearance drifting without considering temporal consistency. Recent point\ntracking algorithms usually depend on sliding windows for indirect information\npropagation from the first frame to the current one, which is slow and less\neffective for long-range tracking. To account for temporal consistency and\nenable efficient information propagation, we present a lightweight and fast\nmodel with \\textbf{S}treaming memory for dense \\textbf{PO}int \\textbf{T}racking\nand online video processing. The \\textbf{SPOT} framework features three core\ncomponents: a customized memory reading module for feature enhancement, a\nsensory memory for short-term motion dynamics modeling, and a visibility-guided\nsplatting module for accurate information propagation. This combination enables\nSPOT to perform dense point tracking with state-of-the-art accuracy on the CVO\nbenchmark, as well as comparable or superior performance to offline models on\nsparse tracking benchmarks such as TAP-Vid and RoboTAP. Notably, SPOT with\n10$\\times$ smaller parameter numbers operates at least 2$\\times$ faster than\nprevious state-of-the-art models while maintaining the best performance on CVO.\nWe will release the models and codes at: https:\/\/github.com\/DQiaole\/SPOT."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04001",
    "c_title":[
      "Sa2VA: Marrying SAM2 with LLaVA for Dense Grounded Understanding of\n  Images and Videos"
    ],
    "c_abstract":[
      "This work presents Sa2VA, the first unified model for dense grounded\nunderstanding of both images and videos. Unlike existing multi-modal large\nlanguage models, which are often limited to specific modalities and tasks,\nSa2VA supports a wide range of image and video tasks, including referring\nsegmentation and conversation, with minimal one-shot instruction tuning. Sa2VA\ncombines SAM-2, a foundation video segmentation model, with LLaVA, an advanced\nvision-language model, and unifies text, image, and video into a shared LLM\ntoken space. Using the LLM, Sa2VA generates instruction tokens that guide SAM-2\nin producing precise masks, enabling a grounded, multi-modal understanding of\nboth static and dynamic visual content. Additionally, we introduce Ref-SAV, an\nauto-labeled dataset containing over 72k object expressions in complex video\nscenes, designed to boost model performance. We also manually validate 2k video\nobjects in the Ref-SAV datasets to benchmark referring video object\nsegmentation in complex environments. Experiments show that Sa2VA achieves\nstate-of-the-art across multiple tasks, particularly in referring video object\nsegmentation, highlighting its potential for complex real-world applications."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-240",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08035",
    "b_title":[
      "Group Preference Alignment: Customized LLM Response Generation from\n  In-Situ Conversations"
    ],
    "b_abstract":[
      "LLMs often fail to meet the specialized needs of distinct user groups due to\ntheir one-size-fits-all training paradigm \\cite{lucy-etal-2024-one} and there\nis limited research on what personalization aspects each group expect. To\naddress these limitations, we propose a group-aware personalization framework,\nGroup Preference Alignment (GPA), that identifies context-specific variations\nin conversational preferences across user groups and then steers LLMs to\naddress those preferences. Our approach consists of two steps: (1) Group-Aware\nPreference Extraction, where maximally divergent user-group preferences are\nextracted from real-world conversation logs and distilled into interpretable\nrubrics, and (2) Tailored Response Generation, which leverages these rubrics\nthrough two methods: a) Context-Tuned Inference (GAP-CT), that dynamically\nadjusts responses via context-dependent prompt instructions, and b)\nRubric-Finetuning Inference (GPA-FT), which uses the rubrics to generate\ncontrastive synthetic data for personalization of group-specific models via\nalignment. Experiments demonstrate that our framework significantly improves\nalignment of the output with respect to user preferences and outperforms\nbaseline methods, while maintaining robust performance on standard benchmarks."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11183",
    "c_title":[
      "Don't Get Lost in the Trees: Streamlining LLM Reasoning by Overcoming\n  Tree Search Exploration Pitfalls"
    ],
    "c_abstract":[
      "Recent advancements in tree search algorithms guided by verifiers have\nsignificantly enhanced the reasoning capabilities of large language models\n(LLMs), but at the cost of increased computational resources. In this work, we\nidentify two key challenges contributing to this inefficiency:\n$\\textit{over-exploration}$ due to redundant states with semantically\nequivalent content, and $\\textit{under-exploration}$ caused by high variance in\nverifier scoring leading to frequent trajectory switching. To address these\nissues, we propose FETCH, an e$\\textbf{f}$fici$\\textbf{e}$nt $\\textbf{t}$ree\nsear$\\textbf{ch}$ framework, which is a flexible, plug-and-play system\ncompatible with various tree search algorithms. Our framework mitigates\nover-exploration by merging semantically similar states using agglomerative\nclustering of text embeddings obtained from a fine-tuned SimCSE model. To\ntackle under-exploration, we enhance verifiers by incorporating temporal\ndifference learning with adjusted $\\lambda$-returns during training to reduce\nvariance, and employing a verifier ensemble to aggregate scores during\ninference. Experiments on GSM8K, GSM-Plus, and MATH datasets demonstrate that\nour methods significantly improve reasoning accuracy and computational\nefficiency across four different tree search algorithms, paving the way for\nmore practical applications of LLM-based reasoning. The code is available at\nhttps:\/\/github.com\/Soistesimmer\/Fetch."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-241",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04063",
    "b_title":[
      "Fuzzy Information Entropy and Region Biased Matrix Factorization for Web\n  Service QoS Prediction"
    ],
    "b_abstract":[
      "Nowadays, there are many similar services available on the internet, making\nQuality of Service (QoS) a key concern for users. Since collecting QoS values\nfor all services through user invocations is impractical, predicting QoS values\nis a more feasible approach. Matrix factorization is considered an effective\nprediction method. However, most existing matrix factorization algorithms focus\non capturing global similarities between users and services, overlooking the\nlocal similarities between users and their similar neighbors, as well as the\nnon-interactive effects between users and services. This paper proposes a\nmatrix factorization approach based on user information entropy and region\nbias, which utilizes a similarity measurement method based on fuzzy information\nentropy to identify similar neighbors of users. Simultaneously, it integrates\nthe region bias between each user and service linearly into matrix\nfactorization to capture the non-interactive features between users and\nservices. This method demonstrates improved predictive performance in more\nrealistic and complex network environments. Additionally, numerous experiments\nare conducted on real-world QoS datasets. The experimental results show that\nthe proposed method outperforms some of the state-of-the-art methods in the\nfield at matrix densities ranging from 5% to 20%."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03492",
    "c_title":[
      "Multi-Source Urban Traffic Flow Forecasting with Drone and Loop Detector\n  Data"
    ],
    "c_abstract":[
      "Traffic forecasting is a fundamental task in transportation research, however\nthe scope of current research has mainly focused on a single data modality of\nloop detectors. Recently, the advances in Artificial Intelligence and drone\ntechnologies have made possible novel solutions for efficient, accurate and\nflexible aerial observations of urban traffic. As a promising traffic\nmonitoring approach, drone-captured data can create an accurate multi-sensor\nmobility observatory for large-scale urban networks, when combined with\nexisting infrastructure. Therefore, this paper investigates the problem of\nmulti-source traffic speed prediction, simultaneously using drone and loop\ndetector data. A simple yet effective graph-based model HiMSNet is proposed to\nintegrate multiple data modalities and learn spatio-temporal correlations.\nDetailed analysis shows that predicting accurate segment-level speed is more\nchallenging than the regional speed, especially under high-demand scenarios\nwith heavier congestions and varying traffic dynamics. Utilizing both drone and\nloop detector data, the prediction accuracy can be improved compared to\nsingle-modality cases, when the sensors have lower coverages and are subject to\nnoise. Our simulation study based on vehicle trajectories in a real urban road\nnetwork has highlighted the added value of integrating drones in traffic\nforecasting and monitoring."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-242",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11364",
    "b_title":[
      "Blessing of Multilinguality: A Systematic Analysis of Multilingual\n  In-Context Learning"
    ],
    "b_abstract":[
      "While multilingual large language models generally perform adequately, and\nsometimes even rival English performance on high-resource languages (HRLs),\nthey often significantly underperform on low-resource languages (LRLs). Among\nseveral prompting strategies aiming at bridging the gap, multilingual\nin-context learning (ICL) has been particularly effective when demonstration in\ntarget languages is unavailable. However, there lacks a systematic\nunderstanding of when and why it works well.\n  In this work, we systematically analyze multilingual ICL, using\ndemonstrations in HRLs to enhance cross-lingual transfer. We show that\ndemonstrations in mixed HRLs consistently outperform English-only ones across\nthe board, particularly for tasks written in LRLs. Surprisingly, our ablation\nstudy shows that the presence of irrelevant non-English sentences in the prompt\nyields measurable gains, suggesting the effectiveness of multilingual exposure\nitself. Our results highlight the potential of strategically leveraging\nmultilingual resources to bridge the performance gap for underrepresented\nlanguages."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07418",
    "c_title":[
      "Entity Linking using LLMs for Automated Product Carbon Footprint\n  Estimation"
    ],
    "c_abstract":[
      "Growing concerns about climate change and sustainability are driving\nmanufacturers to take significant steps toward reducing their carbon\nfootprints. For these manufacturers, a first step towards this goal is to\nidentify the environmental impact of the individual components of their\nproducts. We propose a system leveraging large language models (LLMs) to\nautomatically map components from manufacturer Bills of Materials (BOMs) to\nLife Cycle Assessment (LCA) database entries by using LLMs to expand on\navailable component information. Our approach reduces the need for manual data\nprocessing, paving the way for more accessible sustainability practices."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-243",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10787",
    "b_title":[
      "Modelling and short-term forecasting of seasonal mortality"
    ],
    "b_abstract":[
      "Excess mortality, i.e. the difference between expected and observed\nmortality, is used to quantify the death toll of mortality shocks, such as\ninfectious disease-related epidemics and pandemics. However, predictions of\nexpected mortality are sensitive to model assumptions. Among three\nspecifications of a Serfling-Poisson regression for seasonal mortality, we\nanalyse which one yields the most accurate predictions. We compare the\nSerfling-Poisson models with: 1) parametric effect for the trend and\nseasonality (SP), 2) non-parametric effect for the trend and seasonality\n(SP-STSS), also known as modulation model, and 3) non-parametric effect for the\ntrend and parametric effect for the seasonality (SP-STFS). Forecasting is\nachieved with P-splines smoothing. The SP-STFS model resulted in more accurate\nhistorical forecasts of monthly rates from national statistical offices in 25\nEuropean countries. An application to the COVID-19 pandemic years illustrates\nhow excess mortality can be used to evaluate the vulnerability of populations\nand aid public health planning."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.03167",
    "c_title":[
      "User experience with educational technology in African slums"
    ],
    "c_abstract":[
      "This paper describes a project developed in co-operation with two dozen\ncommunity libraries and schools in various slums and low-income regions in\nKenya. The project was started in response to COVID-19, to allow students to\nsolve computerised math drills while schools were closed. The number of\nstudents involved reached two thousand during the first 24 months of operation.\nThe program uses a study environment, tutor-web, and access to this is provided\nby donating tablet computers to participating community libraries. Students are\nrewarded using tokens, SmileyCoins or SMLY, as they progress through the system\nand the libraries are free to sell for SMLY small food items, sanitary pads and\neven the tablets themselves. The rewards are designed to put an emphasis on\nsecondary school mathematics, so as to prepare the students for applications\ninto STEM subjects at university. Completion of the corresponding collection of\ndrills gives SmileyCoin awards sufficient to purchase a tablet."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-244",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00496",
    "b_title":[
      "Time evolution of nodes in quantum superposition states"
    ],
    "b_abstract":[
      "The nodes are traditionally viewed as fixed points where the probability\ndensity vanishes. However, this work demonstrates that these nodes exhibit\ntime-dependent oscillation in quantum superposition states. We derive this\neffect for a fundamental system: the 1D particle in a box. It is shown that the\nprobability density in a superposition of two eigenstates evolves with a\ntime-dependent interference term, introducing an oscillation of the nodes at a\nspecific frequency equal to the energy difference between the states. This\nresult suggests a deeper dynamical role for nodes in quantum systems."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.08197",
    "c_title":[
      "Quantum squeezing amplification with a weak Kerr nonlinear oscillator"
    ],
    "c_abstract":[
      "Quantum squeezed states, with reduced quantum noise, have been widely\nutilized in quantum sensing and quantum error correction applications. However,\ngenerating and manipulating these nonclassical states with a large squeezing\ndegree typically requires strong nonlinearity, which inevitably induces\nadditional decoherence that diminishes the overall performance. Here, we\ndemonstrate the generation and amplification of squeezed states in a\nsuperconducting microwave cavity with weak Kerr nonlinearity. By subtly\nengineering an off-resonant microwave drive, we observe cyclic dynamics of the\nquantum squeezing evolution for various Fock states |N> with N up to 6 in\ndisplaced frame of the cavity. Furthermore, we deterministically realize\nquantum squeezing amplification by alternately displacing the Kerr oscillator\nusing the Trotterization technique, achieving a maximum squeezing degree of\n14.6 dB and squeezing rate of 0.28 MHz. Our hardware-efficient\ndisplacement-enhanced squeezing operations provide an alternative pathway for\ngenerating large squeezed states, promising potential applications in\nquantum-enhanced sensing and quantum information processing."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-245",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14972",
    "b_title":[
      "GalactiKit: reconstructing mergers from $z=0$ debris using\n  simulation-based inference in Auriga"
    ],
    "b_abstract":[
      "We present GalactiKit, a data-driven methodology for estimating the lookback\ninfall time, stellar mass, halo mass and mass ratio of the disrupted\nprogenitors of Milky Way-like galaxies at the time of infall. GalactiKit uses\nsimulation-based inference to extract the information on galaxy formation\nprocesses encoded in the Auriga cosmological MHD simulations of Milky Way-mass\nhalos to create a model that relates the properties of mergers to those of the\ncorresponding merger debris at $z=0$. We investigate how well GalactiKit can\nreconstruct the merger properties given the dynamical, chemical, and the\ncombined chemo-dynamical information of debris. For this purpose, three models\nwere implemented considering the following properties of merger debris: (a)\ntotal energy and angular momentum, (b) iron-to-hydrogen and alpha-to-iron\nabundance ratios, and (c) a combination of all of these. We find that the\nkinematics of the debris can be used to trace the lookback time at which the\nprogenitor was first accreted into the main halo. However, chemical information\nis necessary for inferring the stellar and halo masses of the progenitors. In\nboth models (b) and (c), the stellar masses are predicted more accurately than\nthe halo masses, which could be related to the scatter in the stellar mass-halo\nmass relation. Model (c) provides the most accurate predictions for the merger\nparameters, which suggests that combining chemical and dynamical data of debris\ncan significantly improve the reconstruction of the Milky Way's assembly\nhistory."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17078",
    "c_title":[
      "Observations of the First Galaxies in the Era of JWST"
    ],
    "c_abstract":[
      "We provide a review of our current knowledge of galaxies throughout the first\nbillion years of cosmic history. This field has undergone a transformation in\nthe last two years following the launch of $\\textit{JWST}$, and we aim to\ndeliver an observational overview of what we have learned about $z\\gtrsim 5$\ngalaxies. We introduce the latest selection methods of high redshift galaxies\nand describe new measurements of the census of continuum-selected and dusty\nstar forming galaxies at $z\\gtrsim 5$. We discuss new measurements of the UV\nluminosity function at $z\\gtrsim 10$ and associated implications for early star\nformation. We then summarize what is being learned about the physical\nproperties of early galaxies, with up-to-date discussions of the sizes, masses,\nages, metallicities, abundance patterns, UV colors, dust properties, and\nionizing sources in $z\\gtrsim 5$ galaxies. We review observational evidence for\nbursty star formation histories and describe prospects for characterizing the\nduty cycle with future observations. We provide a brief overview of the insight\nbeing gained through new detections of AGN in early galaxies. Finally we\nintroduce the latest constraints on the contribution of galaxies to\nreionziation and discuss how $\\textit{JWST}$ measurements of Ly$\\alpha$\nemission offer the potential to probe the earliest stages of the process. This\nreview is meant to provide a broad introduction to those new to the\nobservational study of very high redshift galaxies."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-246",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14096",
    "b_title":[
      "GenPara: Enhancing the 3D Design Editing Process by Inferring Users'\n  Regions of Interest with Text-Conditional Shape Parameters"
    ],
    "b_abstract":[
      "In 3D design, specifying design objectives and visualizing complex shapes\nthrough text alone proves to be a significant challenge. Although advancements\nin 3D GenAI have significantly enhanced part assembly and the creation of\nhigh-quality 3D designs, many systems still to dynamically generate and edit\ndesign elements based on the shape parameters. To bridge this gap, we propose\nGenPara, an interactive 3D design editing system that leverages\ntext-conditional shape parameters of part-aware 3D designs and visualizes\ndesign space within the Exploration Map and Design Versioning Tree.\nAdditionally, among the various shape parameters generated by LLM, the system\nextracts and provides design outcomes within the user's regions of interest\nbased on Bayesian inference. A user study N = 16 revealed that \\textit{GenPara}\nenhanced the comprehension and management of designers with text-conditional\nshape parameters, streamlining design exploration and concretization. This\nimprovement boosted efficiency and creativity of the 3D design process."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00381",
    "c_title":[
      "Towards a Supporting Framework for Neuro-Developmental Disorder:\n  Considering Artificial Intelligence, Serious Games and Eye Tracking"
    ],
    "c_abstract":[
      "This paper focuses on developing a framework for uncovering insights about\nNDD children's performance (e.g., raw gaze cluster analysis, duration analysis\n\\& area of interest for sustained attention, stimuli expectancy, loss of\nfocus\/motivation, inhibitory control) and informing their teachers. The\nhypothesis behind this work is that self-adaptation of games can contribute to\nimproving students' well-being and performance by suggesting personalized\nactivities (e.g., highlighting stimuli to increase attention or choosing a\ndifficulty level that matches students' abilities). The aim is to examine how\nAI can be used to help solve this problem. The results would not only\ncontribute to a better understanding of the problems of NDD children and their\nteachers but also help psychologists to validate the results against their\nclinical knowledge, improve communication with patients and identify areas for\nfurther investigation, e.g., by explaining the decision made and preserving the\nchildren's private data in the learning process."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-247",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03017",
    "b_title":[
      "Perelman's entropy and heat kernel bounds on RCD spaces"
    ],
    "b_abstract":[
      "We study Perelman's W-entropy functional on finite-dimensional RCD spaces, a\nsynthetic generalization of spaces with Bakry-\\'{E}mery Ricci curvature bounded\nfrom below. We rigorously justify the formula for the time derivative of the\nW-entropy and derive its monotonicity and rigidity properties. Additionally, we\nestablish bounds for solutions of the heat equation, which are of independent\ninterest."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.08395",
    "c_title":[
      "Dirac Operators on Orbifold Resolutions: Uniform Elliptic Theory"
    ],
    "c_abstract":[
      "Dirac operators on Riemannian spaces play a central role in various branches\nof mathematics, encoding rich geometric and topological data. They appear as\ndeformation operators in moduli problems, including those associated with\nspecial holonomy metrics, gauge theory instantons, and calibrated submanifolds.\nThis paper investigates the behaviour of families of Dirac operators as the\nunderlying Riemannian spaces degenerate to a Riemannian orbifold in the so\ncalled adiabatic limit. Specifically, we focus on relating the kernels and\ncokernels of the family of Dirac operators to adiabatic data and establish\nuniform bounds on their right inverse. These results provide a crucial analytic\nfoundation for gluing problems on orbifold resolutions, without relying on the\nintricate iterated edge calculus developed by Mazzeo, Melrose, Schulze and\nothers. This work paves the way for forthcoming studies, where these techniques\nwill be used to address open problems in special holonomy geometry, for example\nthe construction of compact $\\mathrm{G}_2$- and $\\mathrm{Spin}(7)$-manifolds,\ngauge theory, and calibrated geometry. The methods developed here have broader\nimplications for the study of singular Riemannian spaces and their analytic\nproperties."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-248",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09374",
    "b_title":[
      "Mitigating multiple single-event upsets during deep neural network\n  inference using fault-aware training"
    ],
    "b_abstract":[
      "Deep neural networks (DNNs) are increasingly used in safety-critical\napplications. Reliable fault analysis and mitigation are essential to ensure\ntheir functionality in harsh environments that contain high radiation levels.\nThis study analyses the impact of multiple single-bit single-event upsets in\nDNNs by performing fault injection at the level of a DNN model. Additionally, a\nfault aware training (FAT) methodology is proposed that improves the DNNs'\nrobustness to faults without any modification to the hardware. Experimental\nresults show that the FAT methodology improves the tolerance to faults up to a\nfactor 3."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04287",
    "c_title":[
      "ElasticZO: A Memory-Efficient On-Device Learning with Combined Zeroth-\n  and First-Order Optimization"
    ],
    "c_abstract":[
      "Zeroth-order (ZO) optimization is being recognized as a simple yet powerful\nalternative to standard backpropagation (BP)-based training. Notably, ZO\noptimization allows for training with only forward passes and (almost) the same\nmemory as inference, making it well-suited for edge devices with limited\ncomputing and memory resources. In this paper, we propose ZO-based on-device\nlearning (ODL) methods for full-precision and 8-bit quantized deep neural\nnetworks (DNNs), namely ElasticZO and ElasticZO-INT8. ElasticZO lies in the\nmiddle between pure ZO- and pure BP-based approaches, and is based on the idea\nto employ BP for the last few layers and ZO for the remaining layers.\nElasticZO-INT8 achieves integer arithmetic-only ZO-based training for the first\ntime, by incorporating a novel method for computing quantized ZO gradients from\ninteger cross-entropy loss values. Experimental results on the classification\ndatasets show that ElasticZO effectively addresses the slow convergence of\nvanilla ZO and shrinks the accuracy gap to BP-based training. Compared to\nvanilla ZO, ElasticZO achieves 5.2-9.5% higher accuracy with only 0.072-1.7%\nmemory overhead, and can handle fine-tuning tasks as well as full training.\nElasticZO-INT8 further reduces the memory usage and training time by 1.46-1.60x\nand 1.38-1.42x without compromising the accuracy. These results demonstrate a\nbetter tradeoff between accuracy and training cost compared to pure ZO- and\nBP-based approaches, and also highlight the potential of ZO optimization in\non-device learning."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-249",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16786",
    "b_title":[
      "Average Nikolskii factors for random trigonometric polynomials"
    ],
    "b_abstract":[
      "For $1\\le p,q\\le \\infty$, the Nikolskii factor for a trigonometric polynomial\n$T_{\\bf a}$ is defined by $$\\mathcal N_{p,q}(T_{\\bf a})=\\frac{\\|T_{\\bf\na}\\|_{q}}{\\|T_{\\bf a}\\|_{p}},\\ \\ T_{\\bf\na}(x)=a_{1}+\\sum\\limits^{n}_{k=1}(a_{2k}\\sqrt{2}\\cos kx+a_{2k+1}\\sqrt{2}\\sin\nkx).$$ We study this average Nikolskii factor for random trigonometric\npolynomials with independent $N(0,\\sigma^{2})$ coefficients and obtain that the\nexact order. For $1\\leq p<q<\\infty$, the average Nikolskii factor is order\ndegree to the 0, as compared to the degree $1\/p-1\/q$ worst case bound. We also\ngive the generalization to random multivariate trigonometric polynomials."
    ],
    "b_categories":[
      [
        "math.CA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.16101",
    "c_title":[
      "Complex oscillations of non-definite Sturm-Liouville problems, II"
    ],
    "c_abstract":[
      "We correct and update a result of R.G.D. Richardson [13] dealing with the\nseparation of zeros of the real and imaginary parts of non-real eigenfunctions\nof non-definite Sturm-Liouville eigenvalue problems. We then extend it to the\ncase where the weight function is allowed to be identically zero on a\nsubinterval that excludes the end-points and study the behavior of the zeros of\nthe real and imaginary parts when the end-points are included. Examples are\ngiven illustrating the sharpness of the results along with open questions."
    ],
    "c_categories":[
      [
        "math.CA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-250",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16865",
    "b_title":[
      "Multimodal Search in Chemical Documents and Reactions"
    ],
    "b_abstract":[
      "We present a multimodal search tool that facilitates retrieval of chemical\nreactions, molecular structures, and associated text from scientific\nliterature. Queries may combine molecular diagrams, textual descriptions, and\nreaction data, allowing users to connect different representations of chemical\ninformation. To support this, the indexing process includes chemical diagram\nextraction and parsing, extraction of reaction data from text in tabular form,\nand cross-modal linking of diagrams and their mentions in text. We describe the\nsystem's architecture, key functionalities, and retrieval process, along with\nexpert assessments of the system. This demo highlights the workflow and\ntechnical components of the search system."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14137",
    "c_title":[
      "Collaborative Retrieval for Large Language Model-based Conversational\n  Recommender Systems"
    ],
    "c_abstract":[
      "Conversational recommender systems (CRS) aim to provide personalized\nrecommendations via interactive dialogues with users. While large language\nmodels (LLMs) enhance CRS with their superior understanding of context-aware\nuser preferences, they typically struggle to leverage behavioral data, which\nhave proven to be important for classical collaborative filtering (CF)-based\napproaches. For this reason, we propose CRAG, Collaborative Retrieval Augmented\nGeneration for LLM-based CRS. To the best of our knowledge, CRAG is the first\napproach that combines state-of-the-art LLMs with CF for conversational\nrecommendations. Our experiments on two publicly available movie conversational\nrecommendation datasets, i.e., a refined Reddit dataset (which we name\nReddit-v2) as well as the Redial dataset, demonstrate the superior item\ncoverage and recommendation performance of CRAG, compared to several CRS\nbaselines. Moreover, we observe that the improvements are mainly due to better\nrecommendation accuracy on recently released movies. The code and data are\navailable at https:\/\/github.com\/yaochenzhu\/CRAG."
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-251",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16362",
    "b_title":[
      "Including an infrequently measured time-dependent error-prone covariate\n  in survival analyses: a simulation-based comparison of methods"
    ],
    "b_abstract":[
      "Epidemiologic studies often evaluate the association between an exposure and\nan event risk. When time-varying, exposure updates usually occur at discrete\nvisits although changes are in continuous time and survival models require\nvalues to be constantly known. Moreover, exposures are likely measured with\nerror, and their observation truncated at the event time. We aimed to quantify\nin a Cox regression the bias in the association resulting from intermittent\nmeasurements of an error-prone exposure. Using simulations under various\nscenarios, we compared five methods: last observation carried-forward (LOCF),\nclassical two-stage regression-calibration using measurements up to the event\n(RC) or also after (PE-RC), multiple imputation (MI) and joint modeling of the\nexposure and the event (JM). The LOCF, and to a lesser extent the classical RC,\nshowed substantial bias in almost all 43 scenarios. The RC bias was avoided\nwhen considering post-event information. The MI performed relatively well, as\ndid the JM. Illustrations exploring the association of Body Mass Index and\nExecutive Functioning with dementia risk showed consistent conclusions.\nAccounting for measurement error and discrete updates is critical when studying\ntime-varying exposures. MI and JM techniques may be applied in this context,\nwhile classical RC should be avoided due to the informative truncation."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.04581",
    "c_title":[
      "Mediation analysis in longitudinal intervention studies with an ordinal\n  treatment-dependent confounder"
    ],
    "c_abstract":[
      "In interventional health studies, causal mediation analysis can be employed\nto investigate mechanisms through which the intervention affects the targeted\nhealth outcome. Identifying direct and indirect (i.e. mediated) effects from\nempirical data, however, becomes complicated if the mediator-outcome\nassociation is confounded by a variable itself affected by the treatment. Here,\nwe investigate identification of mediational effects under such post-treatment\nconfounding in a setting with a longitudinal mediator, time-to-event outcome\nand a trichotomous ordinal treatment-dependent confounder. We show that if the\nintervention always affects the treatment-dependent confounder only in one\ndirection (monotonicity), the mediational effects are identified up to a\nsensitivity parameter and derive their empirical non-parametric expressions.\nThe monotonicity assumption can be assessed from empirical data, based on\nrestrictions on the conditional distribution of the treatment-dependent\nconfounder. We avoid pitfalls related to post-treatment conditioning by\ntreating the mediator as a functional entity and defining the time-to-event\noutcome as a restricted disease-free time. In an empirical analysis, we use\ndata from the Finnish Diabetes Prevention Study to assess the extent to which\nthe effect of a lifestyle intervention on avoiding type 2 diabetes is mediated\nthrough weight reduction in a high-risk population, with other health-related\nchanges acting as treatment-dependent confounders."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-252",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15272",
    "b_title":[
      "Safe and Agile Transportation of Cable-Suspended Payload via Multiple\n  Aerial Robots"
    ],
    "b_abstract":[
      "Transporting a heavy payload using multiple aerial robots (MARs) is an\nefficient manner to extend the load capacity of a single aerial robot. However,\nexisting schemes for the multiple aerial robots transportation system (MARTS)\nstill lack the capability to generate a collision-free and dynamically feasible\ntrajectory in real-time and further track an agile trajectory especially when\nthere are no sensors available to measure the states of payload and cable.\nTherefore, they are limited to low-agility transportation in simple\nenvironments. To bridge the gap, we propose complete planning and control\nschemes for the MARTS, achieving safe and agile aerial transportation (SAAT) of\na cable-suspended payload in complex environments. Flatness maps for the aerial\nrobot considering the complete kinematical constraint and the dynamical\ncoupling between each aerial robot and payload are derived. To improve the\nresponsiveness for the generation of the safe, dynamically feasible, and agile\ntrajectory in complex environments, a real-time spatio-temporal trajectory\nplanning scheme is proposed for the MARTS. Besides, we break away from the\nreliance on the state measurement for both the payload and cable, as well as\nthe closed-loop control for the payload, and propose a fully distributed\ncontrol scheme to track the agile trajectory that is robust against imprecise\npayload mass and non-point mass payload. The proposed schemes are extensively\nvalidated through benchmark comparisons, ablation studies, and simulations.\nFinally, extensive real-world experiments are conducted on a MARTS integrated\nby three aerial robots with onboard computers and sensors. The result validates\nthe efficiency and robustness of our proposed schemes for SAAT in complex\nenvironments."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15290",
    "c_title":[
      "Reinforcement Learning for Robust Athletic Intelligence: Lessons from\n  the 2nd 'AI Olympics with RealAIGym' Competition"
    ],
    "c_abstract":[
      "In the field of robotics many different approaches ranging from classical\nplanning over optimal control to reinforcement learning (RL) are developed and\nborrowed from other fields to achieve reliable control in diverse tasks. In\norder to get a clear understanding of their individual strengths and weaknesses\nand their applicability in real world robotic scenarios is it important to\nbenchmark and compare their performances not only in a simulation but also on\nreal hardware. The '2nd AI Olympics with RealAIGym' competition was held at the\nIROS 2024 conference to contribute to this cause and evaluate different\ncontrollers according to their ability to solve a dynamic control problem on an\nunderactuated double pendulum system with chaotic dynamics. This paper\ndescribes the four different RL methods submitted by the participating teams,\npresents their performance in the swing-up task on a real double pendulum,\nmeasured against various criteria, and discusses their transferability from\nsimulation to real hardware and their robustness to external disturbances."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-253",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17988",
    "b_title":[
      "Analysis methodology of coherent oscillations in time- and\n  angle-resolved photoemission spectroscopy"
    ],
    "b_abstract":[
      "Oscillatory signals from coherently excited phonons are regularly observed in\nultrafast pump-probe experiments on condensed matter samples. Electron-phonon\ncoupling implies that coherent phonons also modulate the electronic band\nstructure. These oscillations can be probed with energy and momentum resolution\nusing time- and angle-resolved photoemission spectroscopy (trARPES) which\nreveals the orbital dependence of the electron-phonon coupling for a specific\nphonon mode. However, a comprehensive analysis remains challenging when\nmultiple coherent phonon modes couple to multiple electronic bands. Complex\nspectral line shapes due to strong correlations in quantum materials add to\nthis challenge. In this work, we examine how the frequency domain\nrepresentation of trARPES data facilitates a quantitative analysis of coherent\noscillations of the electronic bands. We investigate the frequency domain\nrepresentation of the photoemission intensity and \\tred{the first moment of the\nenergy distribution curves}. Both quantities provide complimentary information\nand are able to distinguish oscillations of binding energy, linewidth and\nintensity.We analyze a representative trARPES dataset of the transition metal\ndichalcogenide WTe$_2$ and construct composite spectra which intuitively\nillustrate how much each electronic band is affected by a specific phonon mode.\nWe also show how a linearly chirped probe pulse can generate extrinsic\nartifacts that are distinct from the intrinsic coherent phonon signal."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.07043",
    "c_title":[
      "Conditional Generative Modeling for Amorphous Multi-Element Materials"
    ],
    "c_abstract":[
      "Amorphous multi-element materials offer unprecedented tunability in\ncomposition and properties, yet their rational design remains challenging due\nto the lack of predictive structure-property relationships and the vast\nconfigurational space. Traditional modeling struggles to capture the intricate\nshort-range order that dictates their stability and functionality. We here\nintroduce ApolloX, a pioneering predictive framework for amorphous\nmulti-element materials, establishing a new paradigm by integrating\nphysics-informed generative modeling with particle swarm optimization, using\nchemical short-range order as an explicit constraint. By systematically\nnavigating the disordered energy landscape, ApolloX enables the targeted design\nof thermodynamically stable amorphous configurations. It accurately predicts\natomic-scale arrangements, including composition-driven metal clustering and\namorphization trends, which are well-validated by experiments, while also\nguiding synthesis by leveraging sluggish diffusion to control elemental\ndistribution and disorder. The resulting structural evolution, governed by\ncomposition, directly impacts catalytic performance, leading to improved\nactivity and stability with increasing amorphization. This\npredictive-experimental synergy transforms the discovery of amorphous\nmaterials, unlocking new frontiers in catalysis, energy storage, and functional\ndisordered systems."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-254",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10585",
    "b_title":[
      "Prediction uncertainty-aware planning using deep ensembles and\n  trajectory optimisation"
    ],
    "b_abstract":[
      "Human motion is stochastic and ensuring safe robot navigation in a\npedestrian-rich environment requires proactive decision-making. Past research\nrelied on incorporating deterministic future states of surrounding pedestrians\nwhich can be overconfident leading to unsafe robot behaviour. The current paper\nproposes a predictive uncertainty-aware planner that integrates neural network\nbased probabilistic trajectory prediction into planning. Our method uses a deep\nensemble based network for probabilistic forecasting of surrounding humans and\nintegrates the predictive uncertainty as constraints into the planner. We\ncompare numerous constraint satisfaction methods on the planner and evaluated\nits performance on real world pedestrian datasets. Further, offline robot\nnavigation was carried out on out-of-distribution pedestrian trajectories\ninside a narrow corridor"
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.19045",
    "c_title":[
      "Trajectory Optimization Under Stochastic Dynamics Leveraging Maximum\n  Mean Discrepancy"
    ],
    "c_abstract":[
      "This paper addresses sampling-based trajectory optimization for risk-aware\nnavigation under stochastic dynamics. Typically such approaches operate by\ncomputing $\\tilde{N}$ perturbed rollouts around the nominal dynamics to\nestimate the collision risk associated with a sequence of control commands. We\nconsider a setting where it is expensive to estimate risk using perturbed\nrollouts, for example, due to expensive collision-checks. We put forward two\nkey contributions. First, we develop an algorithm that distills the statistical\ninformation from a larger set of rollouts to a reduced-set with sample size\n$N<<\\tilde{N}$. Consequently, we estimate collision risk using just $N$\nrollouts instead of $\\tilde{N}$. Second, we formulate a novel surrogate for the\ncollision risk that can leverage the distilled statistical information\ncontained in the reduced-set. We formalize both algorithmic contributions using\ndistribution embedding in Reproducing Kernel Hilbert Space (RKHS) and Maximum\nMean Discrepancy (MMD). We perform extensive benchmarking to demonstrate that\nour MMD-based approach leads to safer trajectories at low sample regime than\nexisting baselines using Conditional Value-at Risk (CVaR) based collision risk\nestimate."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-255",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11073",
    "b_title":[
      "Blocking Ideals: a method for sieving linear extensions of a finite\n  poset"
    ],
    "b_abstract":[
      "The standard notion of poset probability of a finite poset P involves\ncalculating, for incomparable $\\alpha$, $\\beta$ in P, the number of linear\nextensions of P for which $\\alpha$ precedes $\\beta$. The fraction of those\nlinear extensions among all linear extensions of P is the probability that\n$\\alpha < \\beta$. The question of whether there is always a pair $\\alpha,\n\\beta$ such that this probability lies between 1\/3 and 2\/3, in any poset P\n(that is not a chain) is the famous \"1\/3-2\/3-conjecture\".\n  A general way of counting linear extensions of P for which $\\alpha$ precedes\n$\\beta$ is to count linear extensions of the poset obtained by adding the\nrelation $(\\alpha,\\beta)$, and its transitive consequences.\n  For chain-products, and more generally for partition posets, lattice-path\nmethods can be used to count the number of those linear extensions.\n  We present an alternative approach to find the pertinent linear extensions.\nIt relies on finding the \"blocking ideals\" in $J(P)$, where $J(P)$ is the\nlattice of order ideals in P. This method works for all finite posets.\n  We illustrate this method by using blocking ideals to find explicit formulas\nof poset probabilities in cell posets $P_{\\lambda}$ of two-row partitions.\nWell-known formulae such as the hook-length formula for $f^\\lambda$, the number\nof standard Young tableaux on a partition $\\lambda$, and the corresponding\ndeterminental formula by Jacobi-Trudi-Aitken for $f^{\\lambda \/ \\mu}$, the\nnumber of standard Young tableaux on a skew partition $\\lambda \/ \\mu$, are used\nalong the way.\n  We also calculate the limit probabilities when the elements $\\alpha,\\beta$\nare fixed cells, but the arm-lengths tend to infinity."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.12412",
    "c_title":[
      "Ordering digraphs with maximum outdegrees by their $A_{\\alpha}$ spectral\n  radius"
    ],
    "c_abstract":[
      "Let $G$ be a strongly connected digraph with $n$ vertices and $m$ arcs. For\nany real $\\alpha\\in[0,1]$, the $A_\\alpha$ matrix of a digraph $G$ is defined as\n$$A_\\alpha(G)=\\alpha D(G)+(1-\\alpha)A(G),$$ where $A(G)$ is the adjacency\nmatrix of $G$ and $D(G)$ is the outdegrees diagonal matrix of $G$. The\neigenvalue of $A_\\alpha(G)$ with the largest modulus is called the $A_\\alpha$\nspectral radius of $G$, denoted by $\\lambda_{\\alpha}(G)$. In this paper, we\nfirst obtain an upper bound on $\\lambda_{\\alpha}(G)$ for\n$\\alpha\\in[\\frac{1}{2},1)$. Employing this upper bound, we prove that for two\nstrongly connected digraphs $G_1$ and $G_2$ with $n\\ge4$ vertices and $m$ arcs,\nand $\\alpha\\in [\\frac{1}{\\sqrt{2}},1)$, if the maximum outdegree\n$\\Delta^+(G_1)\\ge 2\\alpha(1-\\alpha)(m-n+1)+2\\alpha$ and\n$\\Delta^+(G_1)>\\Delta^+(G_2)$, then $\\lambda_\\alpha(G_1)>\\lambda_\\alpha(G_2)$.\nMoreover, We also give another upper bound on $\\lambda_{\\alpha}(G)$ for\n$\\alpha\\in[\\frac{1}{2},1)$. Employing this upper bound, we prove that for two\nstrongly connected digraphs with $m$ arcs, and $\\alpha\\in[\\frac{1}{2},1)$, if\nthe maximum outdegree $\\Delta^+(G_1)>\\frac{2m}{3}+1$ and\n$\\Delta^+(G_1)>\\Delta^+(G_2)$, then\n$\\lambda_\\alpha(G_1)+\\frac{1}{4}>\\lambda_\\alpha(G_2)$."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-256",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15334",
    "b_title":[
      "Resolving Contradictory Estimates of Band Gaps of Bulk PdSe$_2$: A\n  Wannier-Localized Optimally-Tuned Screened Range-Separated Hybrid Density\n  Functional Theory Study"
    ],
    "b_abstract":[
      "Palladium diselenide (PdSe$_2$) -- a layered van der Waals material -- is\nattracting significant attention for optoelectronics due to the wide tunability\nof its band gap from the infrared through the visible range as a function of\nthe number of layers. However, there continues to be disagreement over the\nprecise nature and value of the optical band gap of bulk PdSe$_2$, owing to the\nrather small value of this gap that complicates experimental measurements and\ntheir interpretation. Here, we design and employ a Wannier-localized\noptimally-tuned screened range-separated hybrid (WOT-SRSH) functional to\ninvestigate the electronic bandstructures and optical absorption spectra of\nbulk and monolayer PdSe$_2$. In particular, we account carefully for the finite\nexciton center-of-mass momentum within a time-dependent WOT-SRSH framework to\ncalculate the \\emph{indirect} optical gap and absorption onset accurately. Our\nresults agree well with the best available photoconductivity measurements, as\nwell as with state-of-the-art many-body perturbation theory calculations,\nconfirming that bulk PdSe$_2$ has an optical gap in the mid-infrared\n(upper-bound of 0.44 eV). More generally, this work further bolsters the\nutility of the WOT-SRSH approach for predictive modeling of layered\nsemiconductors."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.13303",
    "c_title":[
      "Spontaneous Donor Defects and Voltage-Assisted Hole Doping in\n  Beta-Gallium Oxides under Multiple Epitaxy Conditions"
    ],
    "c_abstract":[
      "Beta-phase gallium oxide (beta-Ga2O3) is prone to the spontaneous formation\nof donor defects but poses a formidable challenge in achieving high-quality\np-type doping, mainly due to its exceptionally low valence band maximum (VBM).\nIn this study, we utilize first-principles computations to investigate the\norigin of spontaneous donor defects in beta-Ga2O3 grown by three typical\ntechniques: molecular beam epitaxy (MBE), metal organic chemical vapor\ndeposition (MOCVD), and halide vapor phase epitaxy (HVPE). Our findings\nelucidate that the primary donor defects vary with the growth techniques,\nspecifically Gai3+ for MBE, Hi+ and CGa+ for MOCVD, and (2VGa+Gai+2VO)+ and\nClO+ for HVPE under unintentionally doped conditions. Employing a theoretically\nproposed voltage-assisted doping method, we computationally demonstrate that\nthe dominant spontaneous donors can be significantly reduced accompanied by a\nnoticeable increase in acceptors, leading to a stepwise reduction of Fermi\nlevel to 0.52, 0.88, and 2.10 eV above VBM for the MOCVD, HVPE, and MBE\nmethods, and a hole concentration of 8.5*10^17, 8.7*10^11, and 2.7*10^-9 cm-3,\nrespectively, at room temperature without the use of external dopants. By\nintroducing Mg doping, we further reduce the Fermi level for both the MBE and\nHVPE experiments."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-257",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07773",
    "b_title":[
      "Statistical Reevaluation of the USP Classification Boundary: Smaller\n  Planets Within 1 Day, Larger Period Ratios Below 2 Days"
    ],
    "b_abstract":[
      "Terrestrial worlds with $P < 1$ day, known as ultra-short period planets\n(USPs), comprise a physically distinct population whose origins may be\nattributed to various possible formation channels within multi-planet systems.\nHowever, the conventional 1 day boundary adopted for USPs is an arbitrary\nprescription, and it has yet to be evaluated whether this specific cutoff, or\nany alternatives, may emerge from the data with minimal assumptions. We\naccordingly present a statistical evaluation of the USP classification boundary\nfor 376 multi-planet systems across Kepler, K2, and TESS. We find that USPs are\nsmaller in size ($p = 0.004$) and exhibit larger period ratios with their\nimmediate neighbors ($\\mathcal{P} = P_{2}\/P_{1}$; $p < 10^{-4}$) when compared\nto non-USP short-period ($1 < P\/\\text{days} < 5$) worlds, and that these\ndiscrepancies rapidly transition towards statistical insignificance ($p >\n0.05$) at respective orbital periods of $P_{R} = 0.97^{+0.25}_{-0.19}$ days and\n$P_{\\mathcal{P}} = 2.09^{+0.16}_{-0.22}$ days (see Figure 3). We verify that\nthese results are not driven by imprecise planetary parameters, giant\ncompanions, low-mass host stars, or detection biases. Our findings provide\nqualitative support for pathways in which proto-USPs are detached from\ncompanions and delivered to $P \\lesssim 2$ days via eccentric migration, while\na subset of these objects near $P \\sim 1$ day experience subsequent orbital\ndecay and refractory mass loss to become USPs. These results lend evidence\ntowards an astrophysical basis for the 1 day USP cutoff and encourage\nconsideration of an additional 2 day boundary within future investigations of\nUSP architectures and evolutionary dynamics."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03895",
    "c_title":[
      "HST Transmission Spectra of the Hot-Neptune HD 219666 b: Detection of\n  Water and the Challenge of Constraining Both Water and Methane with HST"
    ],
    "c_abstract":[
      "Although Neptunian-sized (2 - 5 R$_{Earth}$) planets appear to be extremely\ncommon in the Galaxy, many mysteries remain about their overall nature. To\ndate, only eleven Neptunian-sized planets have had their atmospheres\nspectroscopically characterized, and these observations hint at interesting\ndiversity within this class of planets. Much of our understanding of these\nworlds and others derive from transmission spectroscopy with the Hubble Space\nTelescope's Wide Field Camera 3 (HST\/WFC3). One key outcome of HST\/WFC3\nobservations has been the consistent detection of water but no methane in\nNeptunian atmospheres, though recent JWST observations are potentially starting\nto overturn this \"missing methane\" paradigm. In this work, we present the\ntransmission spectrum of the hot Neptune HD 219666 b from 1.1 - 1.6 $\\mu$m from\ntwo transit observations using HST\/WFC3 G141. Our fiducial atmospheric\nretrieval detects water at ~3-$\\sigma$ in HD 219666 b's atmosphere and prefers\nno contribution from methane, similar to these previous observations of other\nplanets. Motivated by recent detections of methane in Neptunian atmospheres by\nJWST, we explore additional models and find that a methane-only scenario could\nadequately fit the data, though it is not preferred and likely unphysical. We\ndiscuss the impact of this methane detection challenge on our understanding of\nplanetary atmospheres based on HST\/WFC3 observations alone, and where JWST\nobservations offer a solution."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-258",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14616",
    "b_title":[
      "Monocular Depth Estimation and Segmentation for Transparent Object with\n  Iterative Semantic and Geometric Fusion"
    ],
    "b_abstract":[
      "Transparent object perception is indispensable for numerous robotic tasks.\nHowever, accurately segmenting and estimating the depth of transparent objects\nremain challenging due to complex optical properties. Existing methods\nprimarily delve into only one task using extra inputs or specialized sensors,\nneglecting the valuable interactions among tasks and the subsequent refinement\nprocess, leading to suboptimal and blurry predictions. To address these issues,\nwe propose a monocular framework, which is the first to excel in both\nsegmentation and depth estimation of transparent objects, with only a\nsingle-image input. Specifically, we devise a novel semantic and geometric\nfusion module, effectively integrating the multi-scale information between\ntasks. In addition, drawing inspiration from human perception of objects, we\nfurther incorporate an iterative strategy, which progressively refines initial\nfeatures for clearer results. Experiments on two challenging synthetic and\nreal-world datasets demonstrate that our model surpasses state-of-the-art\nmonocular, stereo, and multi-view methods by a large margin of about\n38.8%-46.2% with only a single RGB input. Codes and models are publicly\navailable at https:\/\/github.com\/L-J-Yuan\/MODEST."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07503",
    "c_title":[
      "Think Before You Segment: High-Quality Reasoning Segmentation with GPT\n  Chain of Thoughts"
    ],
    "c_abstract":[
      "Reasoning segmentation is a challenging vision-language task that aims to\noutput the segmentation mask with respect to a complex, implicit, and even\nnon-visual query text. Previous works incorporated multimodal Large Language\nModels (MLLMs) with segmentation models to approach the difficult problem.\nHowever, their segmentation quality often falls short in complex cases,\nparticularly when dealing with out-of-domain objects with intricate structures,\nblurry boundaries, occlusions, or high similarity with surroundings. In this\npaper, we introduce ThinkFirst, a training-free reasoning segmentation\nframework that leverages GPT's chain of thought to address these challenging\ncases. Our approach allows GPT-4o or other powerful MLLMs to generate a\ndetailed, chain-of-thought description of an image. This summarized description\nis then passed to a language-instructed segmentation assistant to aid the\nsegmentation process. Our framework allows users to easily interact with the\nsegmentation agent using multimodal inputs, such as easy text and image\nscribbles, for successive refinement or communication. We evaluate the\nperformance of ThinkFirst on diverse objects. Extensive experiments show that,\nthis zero-shot-CoT approach significantly improves the vanilla reasoning\nsegmentation agent, both qualitatively and quantitatively, while being less\nsensitive or critical to user-supplied prompts after Thinking First."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-259",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10057",
    "b_title":[
      "A Generalized Modeling Approach to Liquid-driven Ballooning Membranes"
    ],
    "b_abstract":[
      "Soft robotics is advancing the use of flexible materials for adaptable\nrobotic systems. Membrane-actuated soft robots address the limitations of\ntraditional soft robots by using pressurized, extensible membranes to achieve\nstable, large deformations, yet control and state estimation remain challenging\ndue to their complex deformation dynamics. This paper presents a novel modeling\napproach for liquid-driven ballooning membranes, employing an ellipsoid\napproximation to model shape and stretch under planar deformation. Relying\nsolely on intrinsic feedback from pressure data and controlled liquid volume,\nthis approach enables accurate membrane state estimation. We demonstrate the\neffectiveness of the proposed model for ballooning membrane-based actuators by\nexperimental validation, obtaining the indentation depth error of\n$RMSE_{h_2}=0.80\\;$mm, which is $23\\%$ of the indentation range and $6.67\\%$ of\nthe unindented actuator height range. For the force estimation, the error range\nis obtained to be $RMSE_{F}=0.15\\;$N which is $10\\%$ of the measured force\nrange."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.17711",
    "c_title":[
      "Adaptive Perching and Grasping by Aerial Robot with Light-weight and\n  High Grip-force Tendon-driven Three-fingered Hand using Single Actuator"
    ],
    "c_abstract":[
      "In previous research, various types of aerial robots equipped with perching\nmechanisms have been developed to extend operational time. However, most\nexisting perching methods adopt either an upward or downward approach, making\nit difficult to perch near walls with surrounding obstacles. Additionally,\nperching hands are typically designed solely for attachment to objects and lack\nadditional functionality, imposing a payload burden during flight. To address\nthese issues, this paper proposes a lightweight robotic hand, the \"Tri-force\nhand\", capable of both perching and object grasping, as well as a new perching\nmethod called \"Pendulum-perching\". The Tri-force hand is a tendon-driven,\nthree-fingered hand utilizing a spherical joint and a two-dimensional\ndifferential plate, enabling passive actuation with a single actuator. Each\nfinger module, designed with controllable semi-tendon drive, can conform to\narbitrary shapes within its operating range, allowing both perching and\nadaptive object grasping. By integrating this hand into a fully actuated aerial\nrobot, the system can perform multi-directional approaches from the side and\nlanding using gravity. This approach is similar to Crush-perching seen in\nresearches with fixed-wing aerial robots, but it differs in its superior\ncontrol over approach speed and direction, as well as its ability to achieve\nstable detachment and re-launch. In experiments, the fabricated Tri-force hand\ndemonstrated the ability to withstand a total weight of up to 27.5 kg, grasp\nvarious objects ranging from simple to complex-shaped tools, and achieve a high\nsuccess rate in both perching and takeoff."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-260",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15137",
    "b_title":[
      "Quantum Algorithms for Matrix Operations Based on Unitary\n  Transformations and Ancillary State Measurements"
    ],
    "b_abstract":[
      "Matrix operations are of great significance in quantum computing, which\nmanipulate quantum states in information processing. This paper presents\nquantum algorithms for several important matrix operations. By leveraging\nmulti-qubit Toffoli gates and basic single-qubit operations, these algorithms\nefficiently carry out matrix row addition, row swapping, trace calculation and\ntranspose. By using the ancillary measurement techniques to eliminate redundant\ninformation, these algorithms achieve streamlined and efficient computations,\nand demonstrate excellent performance with the running time increasing\nlogarithmically as the matrix dimension grows, ensuring scalability. The\nsuccess probability depends on the matrix dimensions for the trace calculation,\nand on the matrix elements for row addition. Interestingly, the success\nprobability is a constant for matrix row swapping and transpose, highlighting\nthe reliability and efficiency."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.02658",
    "c_title":[
      "Quantum probability for statisticians; some new ideas"
    ],
    "c_abstract":[
      "It is argued from several points of view that quantum probabilities might\nplay a role in statistical settings. New approaches toward quantum foundations\nhave postulates that appear to be equally valid in macroscopic settings. One\nsuch approach is described here in detail, while one other is briefly sketched.\nIn particular, arguments behind the Born rule, which gives the basis for\nquantum probabilities, are given. A list of ideas for possible statistical\napplications of quantum probabilities is provided and discussed. A particular\narea is machine learning, where there exists substantial literature on links to\nquantum probability. Here, an idea about model reduction is sketched and is\nmotivated from a quantum probability model. Quantum models can play a role in\nmodel reduction, where the partial least squares regression model is a special\ncase. It is shown that for certain experiments, a Bayesian prior given by a\nquantum probability can be motivated. Quantum decision theory is an emerging\ndiscipline that can be motivated by this author's theory of quantum\nfoundations."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-261",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18588",
    "b_title":[
      "Mixed CP Violation and Natural Alignment in 2HDMs"
    ],
    "b_abstract":[
      "We present a new form of CP violation (CPV) that can be realised in Two-Higgs\nDoublet Models (2HDMs) and was studied recently in [1]. By examining the vacuum\nmanifold of a generic (convex) 2HDM potential, we identify scenarios that\nexhibit Mixed Spontaneous and Explicit CP Violation (MCPV), in which at least\ntwo non-degenerate CP-violating local minima coexist. We illustrate how this\nidentification is achieved at the tree level by determining the magnitude and\nphase of a novel complex parameter, which we call $r_{\\rm CP}$. Since explicit\nCP Violation vanishes in 2HDMs where SM Higgs alignment is enforced through\nglobal continuous symmetries, we investigate how to maximise CPV in such\nscenarios by introducing soft or explicit breaking of the relevant symmetries.\nIn doing so, we derive upper bounds on key CP-violating parameters that\ncharacterise misalignment with the SM, subject to constraints from the\nnon-observation of the electron electric dipole moment. Finally, we delineate\nthe region of the CP-violating parameter space in such constrained 2HDMs that\ncan be further tested at the CERN Large Hadron Collider."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11201",
    "c_title":[
      "Determination of unpolarized TMD distributions from the fit of Drell-Yan\n  and SIDIS data at N$^4$LL"
    ],
    "c_abstract":[
      "We present a fit of the transverse momentum spectrum for Drell-Yan and\nsemi-inclusive deep inelastic scattering data, based on transverse momentum\ndependent (TMD) factorization at N$^4$LL accuracy. Our analysis shows good\nagreement with the data and confirms the findings of previous studies. Based on\nthis, we extract the unpolarized TMD parton distribution functions, the TMD\nfragmentation functions, and the Collins-Soper kernel. Compared to earlier\nworks, our study incorporates several improvements, including large-$x$\nresummation, flavor and fragmentation function dependence, among others.\nAdditionally, we supplement our extraction with an analysis of the transverse\nmomentum moments of the extracted distributions."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-262",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19230",
    "b_title":[
      "Electron-beam-induced quantum interference effects in a multi-level\n  quantum emitter"
    ],
    "b_abstract":[
      "Cathodoluminescence spectroscopy has recently emerged as a novel platform for\nnanoscale control of nonclassical features of light. Here, we propose a\ntheoretical model for cathodoluminescence from a multi-level quantum emitter.\nEmploying a master equation approach and treating the electron-beam excitation\nas an incoherent broadband field source, we show that quantum interference can\narise between the different relaxation pathways. The induced-interference can\nsignificantly modify the time-dependent spectra resulting in the enhancement or\nsuppression of cathodoluminescence. We find that the excitation rate, initial\nstate of the emitter, and excited level spacing play a crucial role in\ndetermining the influence of interference. Our findings shed light on\nelectron-beam-induced quantum interference in cathodoluminescence and provides\na theoretical basis for exploring quantum optical phenomena in electron-driven\nmulti-level systems."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.14967",
    "c_title":[
      "Adaptive Non-Gaussian Quantum State Engineering"
    ],
    "c_abstract":[
      "Non-Gaussian quantum states of bosons are a key resource in quantum\ninformation science with applications ranging from quantum metrology to\nfault-tolerant quantum computation. Generation of photonic non-Gaussian\nresource states, such as Schr\\\"odinger's cat and Gottesman-Kitaev-Preskill\n(GKP) states, is challenging. In this work, we extend on existing passive\narchitectures and explore a broad set of adaptive schemes. Our numerical\nresults demonstrate a consistent improvement in the probability of success and\nfidelity of generating these non-Gaussian quantum states with equivalent\nresources. We also explore the effect of loss as the primary limiting factor\nand observe that adaptive schemes lead to more desirable outcomes in terms of\noverall probability of success and loss tolerance. Our work offers a versatile\nframework for non-Gaussian resource state generation with the potential to\nguide future experimental implementations."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-263",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09707",
    "b_title":[
      "SDSS-IV MaStar: Quantification and Abatement of Interstellar Absorption\n  in the Largest Empirical Stellar Spectral Library"
    ],
    "b_abstract":[
      "We assess the impact of CaII 3934,3969 and NaI 5891,5897 absorption arising\nin the interstellar medium (ISM) on the SDSS-IV MaNGA Stellar Library (MaStar)\nand produce corrected spectroscopy for 80% of the 24,162-star catalog. We model\nthe absorption strength of these transitions as a function of stellar distance,\nGalactic latitude, and dust reddening based upon high-spectral resolution\nstudies. With this model, we identify 6342 MaStar stars that have negligible\nISM absorption ($W^\\mathrm{ISM}$(CaII K) $<0.07$ Ang and $W^\\mathrm{ISM}$(NaI\n5891) $<0.05$ Ang). For 12,110 of the remaining stars, we replace their NaI D\nprofile (and their CaII profile for effective temperatures $T_{\\rm eff}>9000$\nK) with a coadded spectrum of low-ISM stars with similar $T_{\\rm eff}$, surface\ngravity, and metallicity. For 738 additional stars with $T_{\\rm eff}>9000$ K,\nwe replace these spectral regions with a matching ATLAS9-based BOSZ model. This\nresults in a mean reduction in $W$(CaII K) ($W$(NaI D)) of $0.4-0.7$ Ang\n($0.6-1.1$ Ang) for hot stars ($T_{\\rm eff}>7610$ K), and a mean reduction in\n$W$(NaI D) of $0.1-0.2$ Ang for cooler stars. We show that interstellar\nabsorption in simple stellar population (SSP) model spectra constructed from\nthe original library artificially enhances $W$(CaII K) by $\\gtrsim20\\%$ at\nyoung ages ($<400$ Myr); dramatically enhances the strength of stellar NaI D in\nstarbursting systems (by ${\\gtrsim}50\\%$); and enhances stellar NaI D in older\nstellar populations (${\\gtrsim}10$ Gyr) by ${\\gtrsim}10\\%$. We provide SSP\nspectra constructed from the cleaned library, and discuss the implications of\nthese effects for stellar population synthesis analyses constraining stellar\nage, [Na\/Fe] abundance, and the initial mass function."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.14101",
    "c_title":[
      "Constraints on the active galactic nucleus and starburst activity of\n  local ultraluminous infrared galaxies from a broad range of torus models"
    ],
    "c_abstract":[
      "In this paper we further explore the properties of the HERschel Ultra\nLuminous Infrared Galaxy Survey (HERUS) sample of 42 local ultraluminous\ninfrared galaxies (ULIRGs) with our recently developed Bayesian spectral energy\ndistribution (SED) fitting code SMART (Spectral energy distributions Markov\nchain Analysis with Radiative Transfer models). SMART fits SEDs exclusively\nwith multicomponent radiative transfer models. Mid-infrared spectroscopy can be\nincluded in the fitting at a spectral resolution matched to that of the\nradiative transfer models. We fit the SEDs of the HERUS ULIRGs with four\ndifferent models for the active galactic nucleus (AGN) torus, a starburst and a\nspheroidal galaxy model, to put constraints on the AGN fraction of the galaxies\nand their star formation rate (SFR). Two of the AGN torus models we explored\nare smooth and two are two-phase. We find that, in most cases, a smooth tapered\nAGN torus provides the best fit to the data. We also find that solutions with\nother torus models may predict AGN and total luminosities up to an order of\nmagnitude or more lower, but very rarely higher than the best-fitting model. In\ncontrast, we find that, with minor exceptions, the predicted SFR and stellar\nmass of the ULIRGs are generally robustly estimated irrespective of the assumed\ntorus model. This is despite the fact that one of the AGN torus models we use\nassumes fluffy grains with high emissivity in the far-infrared and\nsubmillimetre, which could potentially reduce the contribution of a starburst\nat those wavelengths and reduce the SFR."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-264",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17670",
    "b_title":[
      "Distinguished Quantized Guidance for Diffusion-based Sequence\n  Recommendation"
    ],
    "b_abstract":[
      "Diffusion models (DMs) have emerged as promising approaches for sequential\nrecommendation due to their strong ability to model data distributions and\ngenerate high-quality items. Existing work typically adds noise to the next\nitem and progressively denoises it guided by the user's interaction sequence,\ngenerating items that closely align with user interests. However, we identify\ntwo key issues in this paradigm. First, the sequences are often heterogeneous\nin length and content, exhibiting noise due to stochastic user behaviors. Using\nsuch sequences as guidance may hinder DMs from accurately understanding user\ninterests. Second, DMs are prone to data bias and tend to generate only the\npopular items that dominate the training dataset, thus failing to meet the\npersonalized needs of different users. To address these issues, we propose\nDistinguished Quantized Guidance for Diffusion-based Sequence Recommendation\n(DiQDiff), which aims to extract robust guidance to understand user interests\nand generate distinguished items for personalized user interests within DMs. To\nextract robust guidance, DiQDiff introduces Semantic Vector Quantization (SVQ)\nto quantize sequences into semantic vectors (e.g., collaborative signals and\ncategory interests) using a codebook, which can enrich the guidance to better\nunderstand user interests. To generate distinguished items, DiQDiff\npersonalizes the generation through Contrastive Discrepancy Maximization (CDM),\nwhich maximizes the distance between denoising trajectories using contrastive\nloss to prevent biased generation for different users. Extensive experiments\nare conducted to compare DiQDiff with multiple baseline models across four\nwidely-used datasets. The superior recommendation performance of DiQDiff\nagainst leading approaches demonstrates its effectiveness in sequential\nrecommendation tasks."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07219",
    "c_title":[
      "DOGR: Leveraging Document-Oriented Contrastive Learning in Generative\n  Retrieval"
    ],
    "c_abstract":[
      "Generative retrieval constitutes an innovative approach in information\nretrieval, leveraging generative language models (LM) to generate a ranked list\nof document identifiers (docid) for a given query. It simplifies the retrieval\npipeline by replacing the large external index with model parameters. However,\nexisting works merely learned the relationship between queries and document\nidentifiers, which is unable to directly represent the relevance between\nqueries and documents. To address the above problem, we propose a novel and\ngeneral generative retrieval framework, namely Leveraging Document-Oriented\nContrastive Learning in Generative Retrieval (DOGR), which leverages\ncontrastive learning to improve generative retrieval tasks. It adopts a\ntwo-stage learning strategy that captures the relationship between queries and\ndocuments comprehensively through direct interactions. Furthermore, negative\nsampling methods and corresponding contrastive learning objectives are\nimplemented to enhance the learning of semantic representations, thereby\npromoting a thorough comprehension of the relationship between queries and\ndocuments. Experimental results demonstrate that DOGR achieves state-of-the-art\nperformance compared to existing generative retrieval methods on two public\nbenchmark datasets. Further experiments have shown that our framework is\ngenerally effective for common identifier construction techniques."
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-265",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17386",
    "b_title":[
      "Data efficiency and long-term prediction capabilities for neural\n  operator surrogate models of edge plasma simulations"
    ],
    "b_abstract":[
      "Modelling of plasma dynamics is fundamental to ensure appropriate diverter\nand core performance, and is desirable for both interpreting the current\ngeneration of experiments and informing the next generation devices like ITER\n\\cite{Loarte2007Chapter4P,Eich2013ScalingOT}. Yet the computational expense of\nmany plasma simulations makes them unsuitable for real-time applications or\niterative design workflows. Neural operator surrogate models of JOREK\n\\cite{Hoelzl_2021} and STORM \\cite{Walkden2016-ys} are evaluated, investigating\ntheir capability to replicate plasma dynamics accurately whilst reducing\ncomputational cost. It is found that the accuracy of the surrogate models will\ndegrade for long term predictions, and that physics considerations are\nimportant in assessing the performance of the surrogates. Surrogates trained on\none dataset can be effectively fine tuned with only a few simulations from a\ntarget domain. This is particularly effective where the source domain is a low\nfidelity physics model and the target domain is a high fidelity model, with an\norder of magnitude improvement in performance for a small dataset and a short\nrollout."
    ],
    "b_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.08351",
    "c_title":[
      "Effects of initial spin orientation on the generation of polarized\n  electron beams from laser wakefield acceleration in plasma"
    ],
    "c_abstract":[
      "The effects of the initial spin orientation on the final electron beam\npolarization via laser wakefield acceleration in pre-polarized plasma are\ninvestigated theoretically and numerically. From a variation of the initial\nspin direction, the spin dynamics of the electron beam is found to depend on\nthe self-injection mechanism. The effects of wakefields and laser fields are\nstudied using test particle dynamics and particle-in-cell simulation based on\nthe Thomas-Bargmann-Michel-Telegdi equation, respectively. Compared to the case\nof transverse injection, the scheme of longitudinal injection is more favorable\nto obtain a highly polarization electron beam."
    ],
    "c_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-266",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09179",
    "b_title":[
      "Reachability for multiagent control systems via Lyapunov functions"
    ],
    "b_abstract":[
      "This paper concerns the problem of reachability of a given state for a\nmultiagent control system in $\\mathbb{R}^d$. In such a system, at every time\neach agent can choose his\/her velocity which depends both on his\/her position\nand on the position of the whole crowd of agents (modeled by a probability\nmeasure on $ \\mathbb{R}^d$). The main contribution of the paper is to study the\nabove reachability problem with a given rate of attainability through a\nLyapunov method adapted to the Wasserstein space of probability measures. As a\nbyproduct we obtain a new comparison result for viscosity solutions of Hamilton\nJacobi equations in the Wasserstein space."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.08228",
    "c_title":[
      "Fare Structure Design in Public Transport"
    ],
    "c_abstract":[
      "Fare planning is one among several steps in public transport planning. Fares\nare relevant for the covering of costs of the public transport operator, but\nalso affect the ridership and the passenger satisfaction. A fare structure is\nthe assignment of prices to all paths in a network. In practice, often a given\nfare structure shall be changed to fulfill new requirements, meaning that a new\nfare strategy is desired. This motivates the usage of prices of the former fare\nstructure or other desirable prices as reference prices. In this paper, we\ninvestigate the fare structure design problem that aims to determine fares such\nthat the sum of absolute deviations between the new fares and the reference\nprices is minimized. Fare strategies that are considered here are flat tariffs,\naffine distance tariffs and zone tariffs. Additionally, we regard constraints\nthat ensure that it is not beneficial to buy a ticket for a longer journey than\nactually traveled (no-elongation property) or to split a ticket into several\nsub-tickets to cover a journey (no-stopover property). Our literature review\nprovides an overview of the research on fare planning. We analyze the fare\nstructure design problem for flat, distance and zone tariffs, pointing out\nconnections to median problems. Further, we study its complexity which ranges\nfrom linear-time solvability to NP-complete cases."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-267",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14588",
    "b_title":[
      "Data Assetization via Resources-decoupled Federated Learning"
    ],
    "b_abstract":[
      "With the development of the digital economy, data is increasingly recognized\nas an essential resource for both work and life. However, due to privacy\nconcerns, data owners tend to maximize the value of data through the\ncirculation of information rather than direct data transfer. Federated learning\n(FL) provides an effective approach to collaborative training models while\npreserving privacy. However, as model parameters and training data grow, there\nare not only real differences in data resources between different data owners,\nbut also mismatches between data and computing resources. These challenges lead\nto inadequate collaboration among data owners, compute centers, and model\nowners, reducing the global utility of the three parties and the effectiveness\nof data assetization. In this work, we first propose a framework for\nresource-decoupled FL involving three parties. Then, we design a Tripartite\nStackelberg Model and theoretically analyze the Stackelberg-Nash equilibrium\n(SNE) for participants to optimize global utility. Next, we propose the\nQuality-aware Dynamic Resources-decoupled FL algorithm (QD-RDFL), in which we\nderive and solve the optimal strategies of all parties to achieve SNE using\nbackward induction. We also design a dynamic optimization mechanism to improve\nthe optimal strategy profile by evaluating the contribution of data quality\nfrom data owners to the global model during real training. Finally, our\nextensive experiments demonstrate that our method effectively encourages the\nlinkage of the three parties involved, maximizing the global utility and value\nof data assets."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18138",
    "c_title":[
      "B3C: A Minimalist Approach to Offline Multi-Agent Reinforcement Learning"
    ],
    "c_abstract":[
      "Overestimation arising from selecting unseen actions during policy evaluation\nis a major challenge in offline reinforcement learning (RL). A minimalist\napproach in the single-agent setting -- adding behavior cloning (BC)\nregularization to existing online RL algorithms -- has been shown to be\neffective; however, this approach is understudied in multi-agent settings. In\nparticular, overestimation becomes worse in multi-agent settings due to the\npresence of multiple actions, resulting in the BC regularization-based approach\neasily suffering from either over-regularization or critic divergence. To\naddress this, we propose a simple yet effective method, Behavior Cloning\nregularization with Critic Clipping (B3C), which clips the target critic value\nin policy evaluation based on the maximum return in the dataset and pushes the\nlimit of the weight on the RL objective over BC regularization, thereby\nimproving performance. Additionally, we leverage existing value factorization\ntechniques, particularly non-linear factorization, which is understudied in\noffline settings. Integrated with non-linear value factorization, B3C\noutperforms state-of-the-art algorithms on various offline multi-agent\nbenchmarks."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-268",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17046",
    "b_title":[
      "Detection of extended X-ray emission surrounding PSR B0656+14 with\n  eROSITA"
    ],
    "b_abstract":[
      "Extended very-high-energy $\\gamma$-ray emission from middle-aged pulsars as\nrevealed recently by several groundbased $\\gamma$-ray experiments has strong\nimplication on the transport of high-energy particles in the interstellar\nmedium surrounding those pulsars. The $\\gamma$-ray emission is widely believed\nto be produced by high-energy electrons and positrons accelerated by the pulsar\nwind nebulae when scattering off the interstellar radiation field via the\ninverse Compton process. Multiwavelength counterparts of the $\\gamma$-ray halos\nare expected to be present, which are, however, not observed yet. In this work,\nwe report for the first time the detection of extended X-ray emission from\n$\\sim 0.2^{\\circ}$ radius region of PSR B0656+14 with eROSITA. The spectrum of\nthe emission can be described by a power-law function with an index of\n$\\sim3.7$. The fluxes decrease with radius faster than the prediction of the\nparticle diffusion and synchrotron radiation in a uniform magnetic field,\nsuggesting the existence of a radial gradient of the magnetic field strength as\n$\\sim r^{-1}$. The magnetic field strength in the X-ray emitting region is\nconstrained to be $4-10~\\mu$G."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.13435",
    "c_title":[
      "Radio observations of the ultra-long GRB 220627A reveal a hot cocoon\n  supporting the blue supergiant progenitor scenario"
    ],
    "c_abstract":[
      "We present the discovery of the radio afterglow of the most distant\nultra-long gamma-ray burst (GRB) detected to date, GRB~220627A at redshift\n$z=3.084$. Its prompt gamma-ray light curve shows a double-pulse profile, with\nthe pulses separated by a period of quiescence lasting ${\\sim} 15\\,$min,\nleading to early speculation it could be a strongly gravitationally lensed GRB.\nHowever, our analysis of the $\\textit{Fermi}$\/GBM spectra taken during the time\nintervals of both pulses show clear differences in their spectral energy\ndistributions, disfavouring the lensing scenario. We observed the radio\nafterglow from $7$ to $456\\,$d post-burst: an initial, steep decay ($F_{\\nu}\n\\propto t^{-2}$) is followed by a shallower decline ($F_{\\nu} \\propto\nt^{-1\/2}$) after ${\\sim} 20\\,$d. Our afterglow modelling shows that these radio\nproperties can be explained by the presence of a slow, wide ejecta component in\naddition to a fast, narrow ejecta component, consistent with the picture of a\nhighly-collimated jet and its thermal cocoon decelerating into the ambient\nmedium. The properties of the cocoon point toward a progenitor with a large\nstellar radius, supporting the blue supergiant scenario proposed for ultra-long\nGRBs. We also conducted an independent test of the lensing hypothesis via Very\nLong Baseline Interferometry (VLBI) observations at ${\\sim} 12\\,$d post-burst\nby searching, for the first time, for multiple images of the candidate lensed\nGRB afterglow. Our experiment highlighted the growing need for developments in\nreal-time correlation capabilities for time-critical VLBI experiments,\nparticularly as we advance towards the SKA and ngVLA era of radio astronomy."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-269",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08820",
    "b_title":[
      "Ghost Kohnert posets"
    ],
    "b_abstract":[
      "Recently, Pan and Yu showed that Lascoux polynomials can be defined in terms\nof certain collections of diagrams consisting of unit cells arranged in the\nfirst quadrant. Starting from certain initial diagrams, one forms a finite set\nof diagrams by applying two types of moves: Kohnert and ghost moves. Both moves\ncause at most one cell to move to a lower row with ghost moves leaving a new\n\"ghost cell\" in its place. Each diagram formed in this way defines a monomial\nin the associated Lascoux polynomial. Restricting attention to diagrams formed\nby applying sequences of only Kohnert moves in the definition of Lascoux\npolynomials, one obtains the family of key polynomials. Recent articles have\nconsidered a poset structure on the collections of diagrams formed when one\nuses only Kohnert moves. In general, these posets are not \"well-behaved,\" not\nusually having desirable poset properties. Here, as an intermediate step to\nstudying the analogous posets associated with Lascoux polynomials, we consider\nthe posets formed by restricting attention to those diagrams formed by using\nonly ghost moves. Unlike in the case of Kohnert posets, we show that such\n\"ghost Kohnert posets\" are always ranked join semi-lattices. In addition, we\nestablish a necessary condition for when ghost Kohnert posets are bounded and,\nconsequently, lattices."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.15213",
    "c_title":[
      "The dual Cheeger-Buser inequality for graphons"
    ],
    "c_abstract":[
      "We introduce the notion of bipartiteness ratio for graphons. We prove the\ndual Cheeger-Buser inequality for graphons, which relates the gap between $2$\nand the top of the spectrum of the Laplacian of a graphon with its\nbipartiteness ratio. The dual Cheeger-Buser inequality was established by\nTrevisan and Bauer-Jost for graphs. Our result is an analog of that for\ngraphons."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-270",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06068",
    "b_title":[
      "Bi-Hermitian and locally conformally K\\\"ahler surfaces"
    ],
    "b_abstract":[
      "We report on a few interrelations between bi-Hermitian metrics and locally\nconformally K\\\"ahler metrics on complex surfaces."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.18031",
    "c_title":[
      "$\\ast$-$\\eta$-Ricci solitons and Einstein metrics on a weak\n  $\\beta$-Kenmotsu manifold"
    ],
    "c_abstract":[
      "Weak almost contact manifolds, i.e., the complex structure on the contact\ndistribution is replaced by a nonsingular skew-symmetric tensor, defined by the\nauthor and R. Wolak, allowed us to take a new look at the theory of contact\nmanifolds. An important case of such manifolds, which is locally a warped or\ntwisted product, is a weak $\\beta$-Kenmotsu manifold defined by the author and\nD.S. Patra. In this paper, the concept of the $\\ast$-Ricci tensor is adapted to\nweak almost contact manifolds, the interaction of the $\\ast$-$\\eta$-Ricci\nsoliton with the weak $\\beta$-Kenmotsu structure is studied and new\ncharacterics of Einstein metrics are obtained."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-271",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00485",
    "b_title":[
      "Quantitative relations between nearest-neighbor persistence and slow\n  heterogeneous dynamics in supercooled liquids"
    ],
    "b_abstract":[
      "Using molecular dynamics simulations of a binary Lennard-Jones model of\nglass-forming liquids, we examine how the decay of the normalized\nneighbor-persistence function $C_{\\rm B}(t)$, which decays from unity at short\ntimes to zero at long times as particles lose the neighbors that were present\nin their original first coordination shell, compares with those of other, more\nconventionally utilized relaxation metrics. In the strongly-non-Arrhenius\ntemperature regime below the onset temperature $T_{\\rm A}$, we find that\n$C_{\\rm B}(t)$ can be described using the same stretched-exponential functional\nform that is often utilized to fit the self-intermediate scattering function\n$S(q, t)$ of glass-forming liquids in this regime. The ratio of the bond\nlifetime $\\tau_{\\rm bond}$ associated with the terminal decay of $C_{\\rm B}(t)$\nto the $\\alpha$-relaxation time $\\tau_\\alpha$ varies appreciably and\nnon-monotonically with $T$, peaking at $\\tau_{\\rm bond}\/\\tau_\\alpha \\simeq 45$\nat $T \\simeq T_{\\rm x}$, where $T_{\\rm x}$ is a crossover temperature\nseparating the high- and low-temperature regimes of glass-formation. In\ncontrast, $\\tau_{\\rm bond}$ remains on the order of the overlap time $\\tau_{\\rm\nov}$ (the time interval over which a typical particle moves by half its\ndiameter), and the peak time $\\tau_\\chi$ for the susceptibility $\\chi_{\\rm\nB}(t)$ associated with the spatial heterogeneity of $C_{\\rm B}(t)$ remains on\nthe order of $\\tau_{\\rm imm}$ (the characteristic lifetime of immobile-particle\nclusters), even as each of these quantities varies by roughly $5$ orders of\nmagnitude over our studied range of $T$. Thus, we show that $C_{\\rm B}(t)$ and\n$\\chi_{\\rm B}(t)$ provide semi-quantitative spatially-averaged measures of the\nslow heterogeneous dynamics associated with the persistence of\nimmobile-particle clusters."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.13798",
    "c_title":[
      "Exploring the role of hydrodynamic interactions in spherically-confined\n  drying colloidal suspensions"
    ],
    "c_abstract":[
      "We study the distribution of colloidal particles confined in drying spherical\ndroplets using both dynamic density functional theory (DDFT) and particle-based\nsimulations. In particular, we focus on the advection-dominated regime typical\nof aqueous droplets drying at room temperature and systematically investigate\nthe role of hydrodynamic interactions during this nonequilibrium process. In\ngeneral, drying produces transient particle concentration gradients within the\ndroplet in this regime, with a considerable accumulation of particles at the\ndroplet's liquid-vapor interface. We find that these gradients become\nsignificantly larger with pairwise hydrodynamic interactions between colloidal\nparticles instead of a free-draining hydrodynamic approximation; however, the\nsolvent's boundary conditions at the droplet's interface (unbounded, slip, or\nno-slip) do not have a significant effect on the particle distribution. DDFT\ncalculations leveraging radial symmetry of the drying droplet are in excellent\nagreement with particle-based simulations for free-draining hydrodynamics, but\nDDFT unexpectedly fails for pairwise hydrodynamic interactions after the\nparticle concentration increases during drying, manifesting as an ejection of\nparticles from the droplet. We hypothesize that this unphysical behavior\noriginates from an inaccurate approximation of the two-body density\ncorrelations based on the bulk pair correlation function, which we support by\nmeasuring the confined equilibrium two-body density correlations using\nparticle-based simulations. We identify some potential strategies for\naddressing this issue in DDFT."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-272",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16949",
    "b_title":[
      "Frames for source recovery from non-uniform dynamical samples"
    ],
    "b_abstract":[
      "Motivated by the work of Aldroubi et al., we investigate the stability of the\nsource term of the discrete dynamical system indexing over a non-uniform\ndiscrete set arising from spectral pairs in infinite-dimensional separable\nHilbert spaces. Extending results due to Aldroubi et al., firstly, we give a\nnecessary and sufficient condition for the recovery of the source term in\nfinitely many iterations. Afterwards, we derive a necessary condition for the\nstability of the source term in finitely many iterations when it belongs to the\nclosed subspace of an infinite-dimensional separable Hilbert space. Finally, we\ngive a necessary and sufficient condition for the recovery of the source term\nin infinitely many iterations."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.20259",
    "c_title":[
      "Notes on the numerical radius for adjointable operators on Hilbert\n  $C^*$-modules"
    ],
    "c_abstract":[
      "Given a Hilbert module $H$ over a $C^*$-algebra, let $\\mathcal{L}(H)$ be the\nset of all adjointable operators on $H$. For each $T\\in\\mathcal{L}(H)$, its\nnumerical radius is defined by $w(T)=\\sup\\big\\{\\|\\langle Tx, x \\rangle\\|: x\\in\nH, \\|x\\|=1\\big\\}$. It is proved that $w(T)=\\|T\\|$ whenever $T$ is normal.\nExamples are constructed to show that there exist Hilbert module $H$ over\ncertain $C^*$-algebra and $T_1,T_2\\in \\mathcal{L}(H)$ with $T_1^2=0$ such that\n$w(T_1)\\ne \\frac12 \\|T_1\\|$ and $\\sup\\limits_{\\theta\\in\n[0,2\\pi]}\\|\\mbox{Re}(e^{i\\theta}T_2)\\|<w(T_2)$. In addition, a new\ncharacterization of the spatial numerical radius is given, and it is proved\nthat $w\\big(\\pi(T)\\big)\\le w(T)$ for every faithful representation $(\\pi, X)$\nof $\\mathcal{L}(H)$ and every $T\\in\\mathcal{L}(H)$. Some inequalities are\nderived based on the newly obtained results."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-273",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17550",
    "b_title":[
      "An LLM-Powered Clinical Calculator Chatbot Backed by Verifiable Clinical\n  Calculators and their Metadata"
    ],
    "b_abstract":[
      "Clinical calculators are widely used, and large language models (LLMs) make\nit possible to engage them using natural language. We demonstrate a\npurpose-built chatbot that leverages software implementations of verifiable\nclinical calculators via LLM tools and metadata about these calculators via\nretrieval augmented generation (RAG). We compare the chatbot's response\naccuracy to an unassisted off-the-shelf LLM on four natural language\nconversation workloads. Our chatbot achieves 100% accuracy on queries\ninterrogating calculator metadata content and shows a significant increase in\nclinical calculation accuracy vs. the off-the-shelf LLM when prompted with\ncomplete sentences (86.4% vs. 61.8%) or with medical shorthand (79.2% vs.\n62.0%). It eliminates calculation errors when prompted with complete sentences\n(0% vs. 16.8%) and greatly reduces them when prompted with medical shorthand\n(2.4% vs. 18%). While our chatbot is not ready for clinical use, these results\nshow progress in minimizing incorrect calculation results."
    ],
    "b_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2502.14915",
    "c_title":[
      "UNGT: Ultrasound Nasogastric Tube Dataset for Medical Image Analysis"
    ],
    "c_abstract":[
      "We develop a novel ultrasound nasogastric tube (UNGT) dataset to address the\nlack of public nasogastric tube datasets. The UNGT dataset includes 493 images\ngathered from 110 patients with an average image resolution of approximately\n879 $\\times$ 583. Four structures, encompassing the liver, stomach, tube, and\npancreas are precisely annotated. Besides, we propose a semi-supervised\nadaptive-weighting aggregation medical segmenter to address data limitation and\nimbalance concurrently. The introduced adaptive weighting approach tackles the\nsevere unbalanced challenge by regulating the loss across varying categories as\ntraining proceeds. The presented multiscale attention aggregation block\nbolsters the feature representation by integrating local and global contextual\ninformation. With these, the proposed AAMS can emphasize sparse or small\nstructures and feature enhanced representation ability. We perform extensive\nsegmentation experiments on our UNGT dataset, and the results show that AAMS\noutperforms existing state-of-the-art approaches to varying extents. In\naddition, we conduct comprehensive classification experiments across varying\nstate-of-the-art methods and compare their performance. The dataset and code\nwill be available upon publication at https:\/\/github.com\/NUS-Tim\/UNGT."
    ],
    "c_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-274",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08709",
    "b_title":[
      "Kernel EDMD for data-driven nonlinear Koopman MPC with stability\n  guarantees"
    ],
    "b_abstract":[
      "Extended dynamic mode decomposition (EDMD) is a popular data-driven method to\npredict the action of the Koopman operator, i.e., the evolution of an\nobservable function along the flow of a dynamical system. In this paper, we\nleverage a recently-introduced kernel EDMD method for control systems for\ndata-driven model predictive control. Building upon pointwise error bounds\nproportional in the state, we rigorously show practical asymptotic stability of\nthe origin w.r.t. the MPC closed loop without stabilizing terminal conditions.\nThe key novelty is that we avoid restrictive invariance conditions. Last, we\nverify our findings by numerical simulations."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.12357",
    "c_title":[
      "Ensemble control of n-level quantum systems with a scalar control"
    ],
    "c_abstract":[
      "In this paper we discuss how a general bilinear finite-dimensional closed\nquantum system with dispersed parameters can be steered between eigenstates. We\nshow that, under suitable conditions on the separation of spectral gaps and the\nboundedness of parameter dispersion, rotating wave and adiabatic approximations\ncan be employed in cascade to achieve population inversion between arbitrary\neigenstates. We propose an explicit control law and test numerically the\nsharpness of the conditions on several examples."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-275",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13337",
    "b_title":[
      "Generative Multi-Form Bayesian Optimization"
    ],
    "b_abstract":[
      "Many real-world problems, such as airfoil design, involve optimizing a\nblack-box expensive objective function over complex structured input space\n(e.g., discrete space or non-Euclidean space). By mapping the complex\nstructured input space into a latent space of dozens of variables, a two-stage\nprocedure labeled as generative model based optimization (GMO) in this paper,\nshows promise in solving such problems. However, the latent dimension of GMO is\nhard to determine, which may trigger the conflicting issue between desirable\nsolution accuracy and convergence rate. To address the above issue, we propose\na multi-form GMO approach, namely generative multi-form optimization (GMFoO),\nwhich conducts optimization over multiple latent spaces simultaneously to\ncomplement each other. More specifically, we devise a generative model which\npromotes positive correlation between latent spaces to facilitate effective\nknowledge transfer in GMFoO. And further, by using Bayesian optimization (BO)\nas the optimizer, we propose two strategies to exchange information between\nthese latent spaces continuously. Experimental results are presented on airfoil\nand corbel design problems and an area maximization problem as well to\ndemonstrate that our proposed GMFoO converges to better designs on a limited\ncomputational budget."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02670",
    "c_title":[
      "Neural networks meet hyperelasticity: A monotonic approach"
    ],
    "c_abstract":[
      "We apply physics-augmented neural network (PANN) constitutive models to\nexperimental uniaxial tensile data of rubber-like materials whose behavior\ndepends on manufacturing parameters. For this, we conduct experimental\ninvestigations on a 3D printed digital material at different mix ratios and\nconsider several datasets from literature, including Ecoflex at different Shore\nhardness and a photocured 3D printing material at different grayscale values.\nWe introduce a parametrized hyperelastic PANN model which can represent\nmaterial behavior at different manufacturing parameters. The proposed model\nfulfills common mechanical conditions of hyperelasticity. In addition, the\nhyperelastic potential of the proposed model is monotonic in isotropic\nisochoric strain invariants of the right Cauchy-Green tensor. In incompressible\nhyperelasticity, this is a relaxed version of the ellipticity (or rank-one\nconvexity) condition. Using this relaxed ellipticity condition, the PANN model\nhas enough flexibility to be applicable to a wide range of materials while\nhaving enough structure for a stable extrapolation outside the calibration\ndata. The monotonic PANN yields excellent results for all materials studied and\ncan represent a wide range of largely varying qualitative and quantitative\nstress behavior. Although calibrated on uniaxial tensile data only, it leads to\na stable numerical behavior of 3D finite element simulations. The findings of\nour work suggest that monotonicity could play a key role in the formulation of\nvery general yet robust and stable constitutive models applicable to materials\nwith highly nonlinear and parametrized behavior."
    ],
    "c_categories":[
      [
        "cs.CE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-276",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06928",
    "b_title":[
      "Nonrenormalization Theorem for ${\\cal N}=(4,4)$ Interface Entropy"
    ],
    "b_abstract":[
      "We derive a formula for the half-BPS interface entropy between any pair of\n${\\cal N}=(4,4)$ theories on the same conformal manifold. This generalizes the\ndiastasis formula derived in arXiv:1311.2202 for ${\\cal N}=(2,2)$ theories,\nwhich is restricted to the conformal submanifolds generated by either chiral or\ntwisted chiral multiples of ${\\cal N}=(2,2)$ supersymmetry. To derive the\n${\\cal N}=(4,4)$ formula, we use the fact that the conformal manifold of ${\\cal\nN}=(4,4)$ theories is symmetric and quaternionic-K\\\"ahler and that its isotropy\ngroup contains the $SU(2) \\otimes SU(2)$ external automorphism of the ${\\cal\nN}=(4,4)$ superconformal algebra. As an application of the formula, we prove a\nsupersymmetric non-renormalization theorem, which explains the observation in\narXiv:1005.4433 that the interface entropy for half-BPS Janus solutions in type\nIIB supergravity on ${\\it AdS}_3 \\times S^3 \\times T^4$ coincides with the\ncorresponding quantity in their free conformal field limits."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.15714",
    "c_title":[
      "Thermal correlator at null infinity"
    ],
    "c_abstract":[
      "We study the thermal Carrollian correlators at null infinity in the real-time\nformalism. We derive the Feynman rules to calculate these correlators in the\nposition space. We compute the bulk-to-bulk, bulk-to boundary and\nboundary-to-boundary propagators for massless scalar theory. Due to the\ndoubling of the fields degrees of freedom, the number of each propagator is\nquadrupled. The bulk-to-boundary propagators have the form of (extended)\nBose-Einstein distribution in the position space. Utilizing the contour\nintegral of the propagators, we can transform the Feynman rules to momentum\nspace. Interestingly, the external lines and the amplitude in the momentum\nspace depend on the contour while Carrollian correlators in the position space\nare independent of the contour. We show how to compute four point correlators\nat finite temperature. The tree level correlators can be written as the\nsummation of Barnes zeta functions and reduce to the ones in the zero\ntemperature limit."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-277",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02493",
    "b_title":[
      "Bottom-up Background Simulations of the 2016 COSI Balloon Flight"
    ],
    "b_abstract":[
      "The Compton Spectrometer and Imager (COSI) is a Compton telescope designed to\nsurvey the 0.2-5 MeV sky, consisting of a compact array of cross-strip\ngermanium detectors. As part of its development, in 2016 COSI had a successful\n46 day flight on board NASA's Super Pressure Balloon platform. This was a\nprecursor to the COSI Small Explorer (COSI-SMEX) satellite mission that will\nlaunch in 2027 into a equatorial low Earth (530 km) orbit. The observation of\nMeV gamma-rays is dominated by background radiation, especially due to the\nactivation of the detector materials induced by cosmic-ray interactions. Thus,\nbackground simulation and identification are crucial for the data analysis.\nBecause the COSI-SMEX detectors will be similar to the ones used for the\nballoon flight, the balloon measurements provide an important tool for testing\nand cross-checking our background simulations for the upcoming space mission.\nIn this work we perform Monte Carlo simulations of the background emission from\nthe 2016 COSI balloon flight. Including a phenomenological shape correction, we\nobtain an agreement with the data at the 10-20% level for energies between\n0.1-1.6 MeV, and we successfully reproduce most of the activation lines induced\nby cosmic ray interactions."
    ],
    "b_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.01528",
    "c_title":[
      "An Integral Field Unit for the Binospec Spectrograph"
    ],
    "c_abstract":[
      "Binospec is a wide-field optical (360 to 1000 nm) spectrograph commissioned\nat the MMT 6.5m telescope in 2017. In direct imaging mode Binospec addresses\ntwin 8$^\\prime$ (wide) by 15$^\\prime$ (slit length) fields of view. We describe\nan optical fiber based integral field unit (IFU) that remaps a\n12$^{\\prime\\prime}$ x 16$^{\\prime\\prime}$ contiguous region onto two pseudo\nslits, one in each Binospec channel. The IFU, commissioned in 2023, fits into\nthe space of a standard slit mask frame and can be deployed as desired in a\nmixed program of slit masks, long slits, and IFU observations. The IFU fibers\nare illuminated by a hexagonal lenslet array with a 0.6$^{\\prime\\prime}$ pitch.\nA separate bundle of sky fibers consists of close-packed bare fibers arranged\nwithin an 11.8$^{\\prime\\prime}$ circular aperture. The 640 IFU fibers and 80\nsky fibers have a core diameter of 150$\\mu$m, corresponding to\n0.90$^{\\prime\\prime}$. Three gratings are available, 270lpm with R$\\sim$2000,\n600lpm with R$\\sim$5300, and 1000 lpm with R$\\sim$6000."
    ],
    "c_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-278",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15575",
    "b_title":[
      "Double heavy quarkonia production with color-octet channels at Z factory\n  and at the CEPC\/FCC-ee"
    ],
    "b_abstract":[
      "Within the NRQCD framework, we calculate the exclusive production of double\nheavy quarkonium(double charmonium and double bottomonium) at future super $Z$\nfactory and at the CEPC\/FCC-ee. The color-octet(CO) channels in the\n$\\gamma^*\/Z^*$-propagated process are considered along with the\ncolor-singlet(CS) channels. We found that the contributions of CO states to the\ntotal cross section are significant or dominant for many processes within\nenergy region at $Z$ factory and at the CEPC\/FCC-ee. The experimental\nmeasurements will help us to verify the CO mechanism. Among these CO channels,\nthe gluon fragmentation into $^3S_1^{8}$ states is most important. Thus, the\ncomparison between the theoretical results and future data will give a strong\nconstraint to the matrix elements\n$\\langle\\mathcal{O}\\left(^3S_1^{[8]}\\right)\\rangle$. Additionally, we consider\nthe relativistic corrections to both the CS and CO channels which decrease the\ncross sections significantly. Specially, the $K$ factors are about $0.5$ for\nmost charmonium channels. We get estimates of the events for double heavy\nquarkonium production. The final events of $J\/\\psi+\\eta_c$, $J\/\\psi+J\/\\psi$,\n$\\Upsilon+\\eta_b$, $\\Upsilon+\\Upsilon$ production would be (22, 570, 71, 61)\nand (206, 5343, 665, 576) at the CEPC (2-year) and at the FCC-ee (4-year) for\nthe $Z$ factory mode, respectively."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.18707",
    "c_title":[
      "Higher Axion Strings"
    ],
    "c_abstract":[
      "We study the minimal requirements to obtain axion strings for axions with\nexponentially good quality. These ingredients appear in theories where an axion\ncoming from a higher-form gauge field mixes with the phase of a complex scalar\nfield in a situation that resembles higher-groups. The resulting axion is\nperturbatively massless and inherits a high-quality shift symmetry from the\nglobal higher-form symmetry while being compatible with a post-inflationary\naxion scenario. Due to differences and resemblances with both,\nextra-dimensional and field theory axions, we call this field the higher axion.\nTo this end, we study a toy model on a 5-dimensional manifold with boundary.\nThe boundary hosts the complex scalar that provides axion strings through\nstandard mechanisms. In addition, we study how these scenarios may arise in\nheterotic string theory and type II string compactifications."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-279",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.00881",
    "b_title":[
      "Agentic Systems: A Guide to Transforming Industries with Vertical AI\n  Agents"
    ],
    "b_abstract":[
      "The evolution of agentic systems represents a significant milestone in\nartificial intelligence and modern software systems, driven by the demand for\nvertical intelligence tailored to diverse industries. These systems enhance\nbusiness outcomes through adaptability, learning, and interaction with dynamic\nenvironments. At the forefront of this revolution are Large Language Model\n(LLM) agents, which serve as the cognitive backbone of these intelligent\nsystems. In response to the need for consistency and scalability, this work\nattempts to define a level of standardization for Vertical AI agent design\npatterns by identifying core building blocks and proposing a \\textbf{Cognitive\nSkills } Module, which incorporates domain-specific, purpose-built inference\ncapabilities. Building on these foundational concepts, this paper offers a\ncomprehensive introduction to agentic systems, detailing their core components,\noperational patterns, and implementation strategies. It further explores\npractical use cases and examples across various industries, highlighting the\ntransformative potential of LLM agents in driving industry-specific\napplications."
    ],
    "b_categories":[
      [
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14111",
    "c_title":[
      "Collaborating in a competitive world: Heterogeneous Multi-Agent Decision\n  Making in Symbiotic Supply Chain Environments"
    ],
    "c_abstract":[
      "Supply networks require collaboration in a competitive environment. To\nachieve this, nodes in the network often form symbiotic relationships as they\ncan be adversely effected by the closure of companies in the network,\nespecially where products are niche. However, balancing support for other nodes\nin the network against profit is challenging. Agents are increasingly being\nexplored to define optimal strategies in these complex networks. However, to\ndate much of the literature focuses on homogeneous agents where a single policy\ncontrols all of the nodes. This isn't realistic for many supply chains as this\nlevel of information sharing would require an exceptionally close relationship.\nThis paper therefore compares the behaviour of this type of agent to a\nheterogeneous structure, where the agents each have separate polices, to solve\nthe product ordering and pricing problem. An approach to reward sharing is\ndeveloped that doesn't require sharing profit. The homogenous and heterogeneous\nagents exhibit different behaviours, with the homogenous retailer retaining\nhigh inventories and witnessing high levels of backlog while the heterogeneous\nagents show a typical order strategy. This leads to the heterogeneous agents\nmitigating the bullwhip effect whereas the homogenous agents do not. In the\nhigh demand environment, the agent architecture dominates performance with the\nSoft Actor-Critic (SAC) agents outperforming the Proximal Policy Optimisation\n(PPO) agents. Here, the factory controls the supply chain. In the low demand\nenvironment the homogenous agents outperform the heterogeneous agents. Control\nof the supply chain shifts significantly, with the retailer outperforming the\nfactory by a significant margin."
    ],
    "c_categories":[
      [
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-280",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05336",
    "b_title":[
      "Leveraging Order-Theoretic Tournament Graphs for Assessing Internal\n  Consistency in Survey-Based Instruments Across Diverse Scenarios"
    ],
    "b_abstract":[
      "This paper introduces Monotone Delta, an order-theoretic measure designed to\nenhance the reliability assessment of survey-based instruments in human-machine\ninteractions. Traditional reliability measures, such as Cronbach's Alpha and\nMcDonald's Omega, often yield misleading estimates due to their sensitivity to\nredundancy, multidimensional constructs, and assumptions of normality and\nuncorrelated errors. These limitations can compromise decision-making in\nhuman-centric evaluations, where survey instruments inform adaptive interfaces,\ncognitive workload assessments, and human-AI trust models. Monotone Delta\naddresses these issues by quantifying internal consistency through the\nminimization of ordinal contradictions and alignment with a unidimensional\nlatent order using weighted tournaments. Unlike traditional approaches, it\noperates without parametric or model-based assumptions. We conducted\ntheoretical analyses and experimental evaluations on four challenging\nscenarios: tau-equivalence, redundancy, multidimensionality, and non-normal\ndistributions, and proved that Monotone Delta provides more stable reliability\nassessments compared to existing methods. The Monotone Delta is a valuable\nalternative for evaluating questionnaire-based assessments in psychology, human\nfactors, healthcare, and interactive system design, enabling organizations to\noptimize survey instruments, reduce costly redundancies, and enhance confidence\nin human-system interactions."
    ],
    "b_categories":[
      [
        "stat.OT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.06628",
    "c_title":[
      "Random Variables aren't Random"
    ],
    "c_abstract":[
      "This paper examines the foundational concept of random variables in\nprobability theory and statistical inference, demonstrating that their\nmathematical definition requires no reference to randomization or hypothetical\nrepeated sampling. We show how measure-theoretic probability provides a\nframework for modeling populations through distributions, leading to three key\ncontributions. First, we establish that random variables, properly understood\nas measurable functions, can be fully characterized without appealing to\ninfinite hypothetical samples. Second, we demonstrate how this perspective\nenables statistical inference through logical rather than probabilistic\nreasoning, extending the reductio ad absurdum argument from deductive to\ninductive inference. Third, we show how this framework naturally leads to\ninformation-based assessment of statistical procedures, replacing traditional\ninference metrics that emphasize bias and variance with information-based\napproaches that better describe the families of distributions used in\nparametric inference. This reformulation addresses long-standing debates in\nstatistical inference while providing a more coherent theoretical foundation.\nOur approach offers an alternative to traditional frequentist inference that\nmaintains mathematical rigor while avoiding the philosophical complications\ninherent in repeated sampling interpretations."
    ],
    "c_categories":[
      [
        "stat.OT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-281",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11914",
    "b_title":[
      "Positive biorthogonal curvature on $S^2 \\times T^2$ via affine\n  connection"
    ],
    "b_abstract":[
      "We address the long-standing problem of the existence of a Riemannian metric\non $S^2\\times T^2$ with strictly positive biorthogonal curvature ($\nK_{\\text{biort}}(\\sigma) > 0 $), but in a weaker framework, by introducing an\naffine connection with antisymmetric closed torsion, naturally encoded in the\ncohomology of $S^2 \\times T^2$ ($H^3(S^2 \\times T^2; \\mathbb{R}) \\cong\n\\mathbb{R}^2$). This torsion, parametrized by non-trivial cohomology classes,\novercomes topological constraints imposed by the zero Euler characteristic,\nensuring $ K_{\\text{biort}}(\\sigma) > 0$ globally."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.18814",
    "c_title":[
      "Elliptic Harnack inequality and its applications on Finsler metric\n  measure spaces"
    ],
    "c_abstract":[
      "In this paper, we study the elliptic Harnack inequality and its applications\non forward complete Finsler metric measure spaces under the conditions that the\nweighted Ricci curvature ${\\rm Ric}_{\\infty}$ has non-positive lower bound and\nthe distortion $\\tau$ is of linear growth, $|\\tau|\\leq ar+b$, where $a,b$ are\nsome non-negative constants, $r=d(x_0,x)$ is the distance function for some\npoint $x_{0} \\in M$. We obtain an elliptic $p$-Harnack inequality for positive\nharmonic functions from a local uniform Poincar\\'{e} inequality and a mean\nvalue inequality. As applications of the Harnack inequality, we derive the\nH\\\"{o}lder continuity estimate and a Liouville theorem for positive harmonic\nfunctions. Furthermore, we establish a gradient estimate for positive harmonic\nfunctions."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-282",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05988",
    "b_title":[
      "Physics-Informed Generative Approaches for Wireless Channel Modeling"
    ],
    "b_abstract":[
      "In recent years, machine learning (ML) methods have become increasingly\npopular in wireless communication systems for several applications. A critical\nbottleneck for designing ML systems for wireless communications is the\navailability of realistic wireless channel datasets, which are extremely\nresource intensive to produce. To this end, the generation of realistic\nwireless channels plays a key role in the subsequent design of effective ML\nalgorithms for wireless communication systems. Generative models have been\nproposed to synthesize channel matrices, but outputs produced by such methods\nmay not correspond to geometrically viable channels and do not provide any\ninsight into the scenario of interest. In this work, we aim to address both\nthese issues by integrating a parametric, physics-based geometric channel\n(PBGC) modeling framework with generative methods. To address limitations with\ngradient flow through the PBGC model, a linearized reformulation is presented,\nwhich ensures smooth gradient flow during generative model training, while also\ncapturing insights about the underlying physical environment. We evaluate our\nmodel against prior baselines by comparing the generated samples in terms of\nthe 2-Wasserstein distance and through the utility of generated data when used\nfor downstream compression tasks."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08234",
    "c_title":[
      "Reduced-latency DL-based Fractional Channel Estimation in OTFS Receivers"
    ],
    "c_abstract":[
      "In this work, we propose a deep learning (DL)-based approach that integrates\na state-of-the-art algorithm with a time-frequency (TF) learning framework to\nminimize overall latency. Meeting the stringent latency requirements of 6G\northogonal time-frequency space (OTFS) systems necessitates low-latency\ndesigns. The performance of the proposed approach is evaluated under\nchallenging conditions: low delay and Doppler resolutions caused by limited\ntime and frequency resources, and significant interpath interference (IPI) due\nto poor separability of propagation paths in the delay-Doppler (DD) domain.\nSimulation results demonstrate that the proposed method achieves high\nestimation accuracy while reducing latency by approximately 55\\% during the\nmaximization process. However, a performance trade-off is observed, with a\nmaximum loss of 3 dB at high pilot SNR values."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-283",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06966",
    "b_title":[
      "GEMS JWST: Transmission spectroscopy of TOI-5205b reveals significant\n  stellar contamination and a metal-poor atmosphere"
    ],
    "b_abstract":[
      "Recent discoveries of transiting giant exoplanets around M dwarfs (GEMS)\npresent an opportunity to investigate their atmospheric compositions and\nexplore how such massive planets can form around low-mass stars contrary to\ncanonical formation models. Here, we present the first transmission spectra of\nTOI-5205b, a short-period ($P=1.63~\\mathrm{days}$) Jupiter-like planet\n($M_p=1.08~\\mathrm{M_J}$ and $R_p=0.94~\\mathrm{R_J}$) orbiting an M4 dwarf. We\nobtained three transits using the PRISM mode of the JWST Near Infrared\nSpectrograph (NIRSpec) spanning $0.6-5.3$ um. Our data reveal significant\nstellar contamination that is evident in the light curves as spot-crossing\nevents and in the transmission spectra as a larger transit depth at bluer\nwavelengths. Atmospheric retrievals demonstrate that stellar contamination from\nunocculted star spots is the dominant component of the transmission spectrum at\nwavelengths $\\lambda\\lesssim3.0$ um, which reduced the sensitivity to the\npresence of clouds or hazes in our models. The degree of stellar contamination\nalso prevented the definitive detection of any $\\mathrm{H_2O}$, which has\nprimary absorption features at these shorter wavelengths. The broad wavelength\ncoverage of NIRSpec PRISM enabled a robust detection of $\\mathrm{CH_4}$ and\n$\\mathrm{H_2S}$, which have detectable molecular features between $3.0-5.0$ um.\nOur gridded and Bayesian retrievals consistently favored an atmosphere with\nboth sub-solar metallicity ($\\log\\mathrm{[M\/H]}\\sim-2$ for a clear atmosphere)\nand super-solar C\/O ratio ($\\log\\mathrm{[C\/O]}\\sim3$ for a clear or cloudy\natmosphere). This contrasts with estimates from planetary interior models that\npredict a bulk metallicity of 10--20%, which is $\\sim100\\times$ the atmospheric\nmetallicity, and suggests that the planetary interior for TOI-5205b is\ndecoupled from its atmosphere and not well mixed."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05114",
    "c_title":[
      "The ESO SupJup Survey V: Exploring Atmospheric Variability and Orbit of\n  the Super-Jupiter AB Pictoris b with CRIRES+"
    ],
    "c_abstract":[
      "A growing number of directly-imaged companions have been recently\ncharacterised, with robust constraints on carbon-to-oxygen ratios and even\nisotopic ratios. Many companions and isolated targets have also shown spectral\nvariability. In this work we observed the super-Jupiter AB~Pictoris~b across\nfour consecutive nights using VLT\/CRIRES+ as part of the ESO SupJup survey,\nexploring how the constraints on chemical composition and temperature profile\nchange over time using spectral line shape variations between nights. We\nperformed atmospheric retrievals of the high-resolution observations and found\nbroadly consistent results across all four nights, but there were differences\nfor some parameters. We clearly detect H$_2$O, $^{12}$CO and $^{13}$CO in each\nnight, but abundances varied by $\\sim2\\sigma$, which was correlated to the deep\natmosphere temperature profiles. We also found differences in the\n$^{12}$C$\/^{13}$C ratios in each night by up to $\\sim3\\sigma$, which seemed to\nbe correlated with the cloud deck pressure. Our combined retrieval\nsimultaneously analysing all nights together constrained broadly the average of\neach night individually, with the C\/O$=0.59\\pm0.01$, consistent with solar\ncomposition, and $^{12}$C$\/^{13}$C~$ = 102\\pm8$, slightly higher than the ISM\nand Solar System values. We also find a low projected rotational velocity,\nsuggesting that AB~Pictoris~b is either intrinsically a slow rotator due to its\nyoung age or that the spin axis is observed pole-on with a $\\sim90^\\circ$\nmisalignment with its orbit inclination. Future observations will be able to\nfurther explore the variability and orbit of AB~Pictoris~b as well as for other\ncompanions."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-284",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06091",
    "b_title":[
      "Theta Theory: operads and coloring"
    ],
    "b_abstract":[
      "We give an explicit construction of the generating set of a colored operad\nthat implements theta theory in the mathematical model of Minimalism in\ngenerative linguistics, in the form of a coloring algorithm for syntactic\nobjects. We show that the coproduct operation on workspaces allows for a\nrecursive implementation of the theta criterion. We also show that this\nfiltering by coloring rules on structures freely formed by Merge is equivalent\nto a process of structure formation by a colored version of Merge: the form of\nthe generators of the colored operad then implies the dichotomy is semantics\nbetween External and Internal Merge, where Internal Merge only moves to\nnon-theta positions."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17143",
    "c_title":[
      "Sentiment analysis of texts from social networks based on machine\n  learning methods for monitoring public sentiment"
    ],
    "c_abstract":[
      "A sentiment analysis system powered by machine learning was created in this\nstudy to improve real-time social network public opinion monitoring. For\nsophisticated sentiment identification, the suggested approach combines\ncutting-edge transformer-based architectures (DistilBERT, RoBERTa) with\ntraditional machine learning models (Logistic Regression, SVM, Naive Bayes).\nThe system achieved an accuracy of up to 80-85% using transformer models in\nreal-world scenarios after being tested using both deep learning techniques and\nstandard machine learning processes on annotated social media datasets.\nAccording to experimental results, deep learning models perform noticeably\nbetter than lexicon-based and conventional rule-based classifiers, lowering\nmisclassification rates and enhancing the ability to recognize nuances like\nsarcasm. According to feature importance analysis, context tokens,\nsentiment-bearing keywords, and part-of-speech structure are essential for\nprecise categorization. The findings confirm that AI-driven sentiment\nframeworks can provide a more adaptive and efficient approach to modern\nsentiment challenges. Despite the system's impressive performance, issues with\ncomputing overhead, data quality, and domain-specific terminology still exist.\nIn order to monitor opinions on a broad scale, future research will investigate\nimproving computing performance, extending coverage to various languages, and\nintegrating real-time streaming APIs. The results demonstrate that governments,\ncorporations, and social researchers looking for more in-depth understanding of\npublic mood on digital platforms can find a reliable and adaptable answer in\nAI-powered sentiment analysis."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-285",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17655",
    "b_title":[
      "FeatureGS: Eigenvalue-Feature Optimization in 3D Gaussian Splatting for\n  Geometrically Accurate and Artifact-Reduced Reconstruction"
    ],
    "b_abstract":[
      "3D Gaussian Splatting (3DGS) has emerged as a powerful approach for 3D scene\nreconstruction using 3D Gaussians. However, neither the centers nor surfaces of\nthe Gaussians are accurately aligned to the object surface, complicating their\ndirect use in point cloud and mesh reconstruction. Additionally, 3DGS typically\nproduces floater artifacts, increasing the number of Gaussians and storage\nrequirements. To address these issues, we present FeatureGS, which incorporates\nan additional geometric loss term based on an eigenvalue-derived 3D shape\nfeature into the optimization process of 3DGS. The goal is to improve geometric\naccuracy and enhance properties of planar surfaces with reduced structural\nentropy in local 3D neighborhoods.We present four alternative formulations for\nthe geometric loss term based on 'planarity' of Gaussians, as well as\n'planarity', 'omnivariance', and 'eigenentropy' of Gaussian neighborhoods. We\nprovide quantitative and qualitative evaluations on 15 scenes of the DTU\nbenchmark dataset focusing on following key aspects: Geometric accuracy and\nartifact-reduction, measured by the Chamfer distance, and memory efficiency,\nevaluated by the total number of Gaussians. Additionally, rendering quality is\nmonitored by Peak Signal-to-Noise Ratio. FeatureGS achieves a 30 % improvement\nin geometric accuracy, reduces the number of Gaussians by 90 %, and suppresses\nfloater artifacts, while maintaining comparable photometric rendering quality.\nThe geometric loss with 'planarity' from Gaussians provides the highest\ngeometric accuracy, while 'omnivariance' in Gaussian neighborhoods reduces\nfloater artifacts and number of Gaussians the most. This makes FeatureGS a\nstrong method for geometrically accurate, artifact-reduced and memory-efficient\n3D scene reconstruction, enabling the direct use of Gaussian centers for\ngeometric representation."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17053",
    "c_title":[
      "Contextual Self-paced Learning for Weakly Supervised Spatio-Temporal\n  Video Grounding"
    ],
    "c_abstract":[
      "In this work, we focus on Weakly Supervised Spatio-Temporal Video Grounding\n(WSTVG). It is a multimodal task aimed at localizing specific subjects\nspatio-temporally based on textual queries without bounding box supervision.\nMotivated by recent advancements in multi-modal foundation models for grounding\ntasks, we first explore the potential of state-of-the-art object detection\nmodels for WSTVG. Despite their robust zero-shot capabilities, our adaptation\nreveals significant limitations, including inconsistent temporal predictions,\ninadequate understanding of complex queries, and challenges in adapting to\ndifficult scenarios. We propose CoSPaL (Contextual Self-Paced Learning), a\nnovel approach which is designed to overcome these limitations. CoSPaL\nintegrates three core components: (1) Tubelet Phrase Grounding (TPG), which\nintroduces spatio-temporal prediction by linking textual queries to tubelets;\n(2) Contextual Referral Grounding (CRG), which improves comprehension of\ncomplex queries by extracting contextual information to refine object\nidentification over time; and (3) Self-Paced Scene Understanding (SPS), a\ntraining paradigm that progressively increases task difficulty, enabling the\nmodel to adapt to complex scenarios by transitioning from coarse to\nfine-grained understanding."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-286",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11503",
    "b_title":[
      "Impact of the Homology Groups on the Finiteness of the group of\n  Self-Homotopy Equivalences of an Elliptic Space"
    ],
    "b_abstract":[
      "For an elliptic CW-complex $X$, we denote its group of self-homotopy\nequivalences as $\\E(X)$, and its subgroup consisting of elements inducing the\nidentity on the homology groups as $\\E_{*}(X)$. This paper aims to investigate\nhow the homology groups of $X$ influence the finiteness of $\\E(X)$ and\n$\\E_{*}(X)$."
    ],
    "b_categories":[
      [
        "math.AT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.17149",
    "c_title":[
      "A spectrum-level splitting of the $ku_\\mathbb{R}$-cooperations algebra"
    ],
    "c_abstract":[
      "In the 1980's, Mahowald and Kane used integral Brown--Gitler spectra to\ndecompose $ku \\wedge ku$ as a sum of finitely generated $ku$-module spectra.\nThis splitting, along with an analogous decomposition of $ko \\wedge ko$ led to\na great deal of progress in stable homotopy computations and understanding of\n$v_1$-periodicity in the stable homotopy groups of spheres. In this paper, we\nconstruct a $C_2$-equivariant lift of Mahowald and Kane's splitting of $ku\n\\wedge ku$. We also give a description of the resulting $C_2$-equivariant\nsplitting in terms of $C_2$-equivariant Adams covers and record an analogous\nsplitting for $H\\underline{\\mathbb{Z}} \\wedge H \\underline{\\mathbb{Z}}$.\nSimilarly to the nonequivariant story, we expect the techniques of this paper\nto facilitate further $C_2$-equivariant stable homotopy computations and\nunderstanding of $v_1$-periodicity in $C_2$-equivariant stable stems."
    ],
    "c_categories":[
      [
        "math.AT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-287",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11334",
    "b_title":[
      "On partition and almost disjoint properties of combinatorial notions"
    ],
    "b_abstract":[
      "It is known that there are many notions of largeness in a semigroup that own\nrich combinatorial properties. In this paper, we focus on partition and almost\ndisjoint properties of these notions. One of the most remarkable results with\nrespect to this topic is that in an infinite very weakly cancellative semigroup\nof size \\kappa, every central set can be split into \\kappa disjoint central\nsubsets. Moreover, if \\kappa contains \\lambda almost disjoint subsets, then\nevery central set contains a family of \\lambda almost disjoint central subsets.\nAnd many other combinatorial notions are found successively to have analogous\nproperties, among these are thick sets, piecewise syndetic sets, J-sets and\nC-sets. In this paper, we mainly study four other notions: IP sets,\ncombinatorially rich sets, Cp-sets and PP-rich sets. Where the latter two are\nknown in (N, +), related to the polynomial extension of the central sets\ntheorem. We lift them up to commutative cancellative semigroups and obtain an\nuncountable version of the polynomial extension of the central sets theorem\nincidentally. And we finally find that the infinite partition and almost\ndisjoint properties hold for Cp-sets in commutative cancellative semigroups and\nfor other three notions in (N, +)."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.11461",
    "c_title":[
      "Codes with symmetric distances"
    ],
    "c_abstract":[
      "For a code $C$ in a space with maximal distance $n$, we say that $C$ has\nsymmetric distances if its distance set $S(C)$ is symmetric with respect to $n\n\/ 2$. In this paper, we prove that if $C$ is a binary code with length $2n$,\nconstant weight $n$ and symmetric distances, then \\[\n  |C| \\leq \\binom{2 n - 1}{|S(C)|}. \\] This result can be interpreted using the\nlanguage of Johnson association schemes. More generally, we give a framework to\nstudy codes with symmetric distances in Q-bipartite Q-polynomial association\nschemes, and provide upper bounds for such codes. Moreover, we use number\ntheoretic techniques to determine when the equality holds."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-288",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17408",
    "b_title":[
      "Joint Holographic Beamforming and User Scheduling with Individual QoS\n  Constraints"
    ],
    "b_abstract":[
      "Reconfigurable holographic surfaces (RHS) have emerged as a transformative\nmaterial technology, enabling dynamic control of electromagnetic waves to\ngenerate versatile holographic beam patterns. This paper addresses the problem\nof joint hybrid holographic beamforming and user scheduling under per-user\nminimum quality-of-service (QoS) constraints, a critical challenge in\nresource-constrained networks. However, such a problem results in mixed-integer\nnon-convex optimization, making it difficult to identify feasible solutions\nefficiently. To overcome this challenge, we propose a novel iterative\noptimization framework that jointly solves the problem to maximize the\nRHS-assisted network sum-rate, efficiently managing holographic beamforming\npatterns, dynamically scheduling users, and ensuring the minimum QoS\nrequirements for each scheduled user. The proposed framework relies on\nzero-forcing digital beamforming, gradient-ascent-based holographic beamformer\noptimization, and a greedy user selection principle. Our extensive simulation\nresults validate the effectiveness of the proposed scheme, demonstrating their\nsuperior performance compared to the benchmark algorithms in terms of sum-rate\nperformance, while meeting the minimum per-user QoS constraints"
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16169",
    "c_title":[
      "Learning Linear Block Codes with Gradient Quantization"
    ],
    "c_abstract":[
      "This study investigates the problem of learning linear block codes optimized\nfor Belief-Propagation decoders significantly improving performance compared to\nthe state-of-the-art. Our previous research is extended with an enhanced system\ndesign that facilitates a more effective learning process for the parity check\nmatrix. We simplify the input dataset, restrict the number of parameters to\nlearn and improve the gradient back-propagation within the model. We also\nintroduce novel optimizers specifically designed for discrete-valued weights.\nBased on conventional gradient computation, these optimizers provide discrete\nweights updates, enabling finer control and improving explainability of the\nlearning process. Through these changes, we consistently achieve improved code\nperformance, provided appropriately chosen hyper-parameters. To rigorously\nevaluate the performance of learned codes in the context of short to medium\nblock lengths, we propose a comprehensive code performance assessment\nframework. This framework enables a fair comparison between our learning\nmethodology and random search approaches, ensuring statistical significance in\nour results. The proposed model pave the way for a new approach to the\nefficient learning of linear block codes tailored to specific decoder\nstructures."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-289",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14124",
    "b_title":[
      "Data-driven nonlinear modal identification of nonlinear dynamical\n  systems with physics-constrained Normalizing Flows"
    ],
    "b_abstract":[
      "Identifying the intrinsic coordinates or modes of the dynamical systems is\nessential to understand, analyze, and characterize the underlying dynamical\nbehaviors of complex systems. For nonlinear dynamical systems, this presents a\ncritical challenge as the linear modal transformation, which is universal for\nlinear systems, does not apply to nonlinear dynamical systems. As natural\nextensions to linear normal modes,the nonlinear normal modes (NNMs) framework\nprovides a comprehensive representation of nonlinear dynamics. Theoretically,\nNNMs may either be computed numerically or analytically from the closed-form\nmodels or equations of dynamical systems, or experimentally identified from\ncontrollable input-output tests, both of which, however, are typically unknown\nor unavailable practically. In this study, we present a physics-integrated\nNormalizing Flows deep learning-based data-driven approach which identifies the\nNNMs and the nonlinear modal transformation function of NNMs using measured\nresponse data only. Specifically, we leverage the unique features of the\nNormalizing Flows model: 1) the independent latent spaces, naturally spanned by\nthe Normalizing Flows, are exploited to facilitate nonlinear modal\ndecomposition; 2) the invertible transformation through the Normalizing Flows,\nenabling efficient and accurate nonlinear transformation between original and\nmodal coordinates transformation. Therefore, our framework leverages the\nindependency feature and invertibility of Normalizing Flows to create a model\nthat captures the dynamics of unknown nonlinear dynamical systems."
    ],
    "b_categories":[
      [
        "nlin.CD"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.17754",
    "c_title":[
      "A model for dynamical systems with strange attractors"
    ],
    "c_abstract":[
      "We derive a system with one degree of freedom that models a class of\ndynamical systems with strange attractors in three dimensions. This system\nretains all the characteristics of chaotic attractors and is expressed by a\nsecond-order integro-differential equation which mimics a spring-like problem.\nWe determine the potential energy, the rate of change of the kinetic energy of\nthis system, and show that is self-oscillating."
    ],
    "c_categories":[
      [
        "nlin.CD"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-290",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05530",
    "b_title":[
      "User Identification Procedures with Human Mutations: Formal Analysis and\n  Pilot Study (Extended Version)"
    ],
    "b_abstract":[
      "User identification procedures, essential to the information security of\nsystems, enable system-user interactions by exchanging data through\ncommunication links and interfaces to validate and confirm user authenticity.\nHowever, human errors can introduce vulnerabilities that may disrupt the\nintended identification workflow and thus impact system behavior. Therefore,\nensuring the integrity of these procedures requires accounting for such\nerroneous behaviors. We follow a formal, human-centric approach to analyze user\nidentification procedures by modeling them as security ceremonies and apply\nproven techniques for automatically analyzing such ceremonies. The approach\nrelies on mutation rules to model potential human errors that deviate from\nexpected interactions during the identification process, and is implemented as\nthe X-Men tool, an extension of the Tamarin prover, which automatically\ngenerates models with human mutations and implements matching mutations to\nother ceremony participants for analysis. As a proof-of-concept, we consider a\nreal-life pilot study involving an AI-driven, virtual receptionist kiosk for\nauthenticating visitors."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15881",
    "c_title":[
      "Using Data Redundancy Techniques to Detect and Correct Errors in Logical\n  Data"
    ],
    "c_abstract":[
      "Data redundancy techniques have been tested in several different applications\nto provide fault tolerance and performance gains. The use of these techniques\nis mostly seen at the hardware, device driver, or file system level. In\npractice, the use of data integrity techniques with logical data has largely\nbeen limited to verifying the integrity of transferred files using\ncryptographic hashes. In this paper, we study the RAID scheme used with disk\narrays and adapt it for use with logical data. An implementation for such a\nsystem is devised in theory and implemented in software, providing the\nspecifications for the procedures and file formats used. Rigorous\nexperimentation is conducted to test the effectiveness of the developed system\nfor multiple use cases. With computer-generated benchmarks and simulated\nexperiments, the system demonstrates robust performance in recovering arbitrary\nfaults in large archive files only using a small fraction of redundant data.\nThis was achieved by leveraging computing power for the process of data\nrecovery."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-291",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05457",
    "b_title":[
      "Content-based Video Retrieval in Traffic Videos using Latent Dirichlet\n  Allocation Topic Model"
    ],
    "b_abstract":[
      "Content-based video retrieval is one of the most challenging tasks in\nsurveillance systems. In this study, Latent Dirichlet Allocation (LDA) topic\nmodel is used to annotate surveillance videos in an unsupervised manner. In\nscene understanding methods, some of the learned patterns are ambiguous and\nrepresents a mixture of atomic actions. To address the ambiguity issue in the\nproposed method, feature vectors, and the primary model are processed to obtain\na secondary model which describes the scene with primitive patterns that lack\nany ambiguity. Experiments show performance improvement in the retrieval task\ncompared to other topic model-based methods. In terms of false positive and\ntrue positive responses, the proposed method achieves at least 80\\% and 124\\%\nimprovement respectively. Four search strategies are proposed, and users can\ndefine and search for a variety of activities using the proposed query\nformulation which is based on topic models. In addition, the lightweight\ndatabase in our method occupies much fewer storage which in turn speeds up the\nsearch procedure compared to the methods which are based on low-level features."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.01114",
    "c_title":[
      "Generalized Task-Driven Medical Image Quality Enhancement with Gradient\n  Promotion"
    ],
    "c_abstract":[
      "Thanks to the recent achievements in task-driven image quality enhancement\n(IQE) models like ESTR, the image enhancement model and the visual recognition\nmodel can mutually enhance each other's quantitation while producing\nhigh-quality processed images that are perceivable by our human vision systems.\nHowever, existing task-driven IQE models tend to overlook an underlying fact --\ndifferent levels of vision tasks have varying and sometimes conflicting\nrequirements of image features. To address this problem, this paper proposes a\ngeneralized gradient promotion (GradProm) training strategy for task-driven IQE\nof medical images. Specifically, we partition a task-driven IQE system into two\nsub-models, i.e., a mainstream model for image enhancement and an auxiliary\nmodel for visual recognition. During training, GradProm updates only parameters\nof the image enhancement model using gradients of the visual recognition model\nand the image enhancement model, but only when gradients of these two\nsub-models are aligned in the same direction, which is measured by their cosine\nsimilarity. In case gradients of these two sub-models are not in the same\ndirection, GradProm only uses the gradient of the image enhancement model to\nupdate its parameters. Theoretically, we have proved that the optimization\ndirection of the image enhancement model will not be biased by the auxiliary\nvisual recognition model under the implementation of GradProm. Empirically,\nextensive experimental results on four public yet challenging medical image\ndatasets demonstrated the superior performance of GradProm over existing\nstate-of-the-art methods."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-292",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08005",
    "b_title":[
      "CDI3D: Cross-guided Dense-view Interpolation for 3D Reconstruction"
    ],
    "b_abstract":[
      "3D object reconstruction from single-view image is a fundamental task in\ncomputer vision with wide-ranging applications. Recent advancements in Large\nReconstruction Models (LRMs) have shown great promise in leveraging multi-view\nimages generated by 2D diffusion models to extract 3D content. However,\nchallenges remain as 2D diffusion models often struggle to produce dense images\nwith strong multi-view consistency, and LRMs tend to amplify these\ninconsistencies during the 3D reconstruction process. Addressing these issues\nis critical for achieving high-quality and efficient 3D reconstruction. In this\npaper, we present CDI3D, a feed-forward framework designed for efficient,\nhigh-quality image-to-3D generation with view interpolation. To tackle the\naforementioned challenges, we propose to integrate 2D diffusion-based view\ninterpolation into the LRM pipeline to enhance the quality and consistency of\nthe generated mesh. Specifically, our approach introduces a Dense View\nInterpolation (DVI) module, which synthesizes interpolated images between main\nviews generated by the 2D diffusion model, effectively densifying the input\nviews with better multi-view consistency. We also design a tilt camera pose\ntrajectory to capture views with different elevations and perspectives.\nSubsequently, we employ a tri-plane-based mesh reconstruction strategy to\nextract robust tokens from these interpolated and original views, enabling the\ngeneration of high-quality 3D meshes with superior texture and geometry.\nExtensive experiments demonstrate that our method significantly outperforms\nprevious state-of-the-art approaches across various benchmarks, producing 3D\ncontent with enhanced texture fidelity and geometric accuracy."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.17752",
    "c_title":[
      "HiLoTs: High-Low Temporal Sensitive Representation Learning for\n  Semi-Supervised LiDAR Segmentation in Autonomous Driving"
    ],
    "c_abstract":[
      "LiDAR point cloud semantic segmentation plays a crucial role in autonomous\ndriving. In recent years, semi-supervised methods have gained popularity due to\ntheir significant reduction in annotation labor and time costs. Current\nsemi-supervised methods typically focus on point cloud spatial distribution or\nconsider short-term temporal representations, e.g., only two adjacent frames,\noften overlooking the rich long-term temporal properties inherent in autonomous\ndriving scenarios. In driving experience, we observe that nearby objects, such\nas roads and vehicles, remain stable while driving, whereas distant objects\nexhibit greater variability in category and shape. This natural phenomenon is\nalso captured by LiDAR, which reflects lower temporal sensitivity for nearby\nobjects and higher sensitivity for distant ones. To leverage these\ncharacteristics, we propose HiLoTs, which learns high-temporal sensitivity and\nlow-temporal sensitivity representations from continuous LiDAR frames. These\nrepresentations are further enhanced and fused using a cross-attention\nmechanism. Additionally, we employ a teacher-student framework to align the\nrepresentations learned by the labeled and unlabeled branches, effectively\nutilizing the large amounts of unlabeled data. Experimental results on the\nSemanticKITTI and nuScenes datasets demonstrate that our proposed HiLoTs\noutperforms state-of-the-art semi-supervised methods, and achieves performance\nclose to LiDAR+Camera multimodal approaches. Code is available on\nhttps:\/\/github.com\/rdlin118\/HiLoTs"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-293",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16194",
    "b_title":[
      "Improving Autoregressive Image Generation through Coarse-to-Fine Token\n  Prediction"
    ],
    "b_abstract":[
      "Autoregressive models have shown remarkable success in image generation by\nadapting sequential prediction techniques from language modeling. However,\napplying these approaches to images requires discretizing continuous pixel data\nthrough vector quantization methods like VQ-VAE. To alleviate the quantization\nerrors that existed in VQ-VAE, recent works tend to use larger codebooks.\nHowever, this will accordingly expand vocabulary size, complicating the\nautoregressive modeling task. This paper aims to find a way to enjoy the\nbenefits of large codebooks without making autoregressive modeling more\ndifficult. Through empirical investigation, we discover that tokens with\nsimilar codeword representations produce similar effects on the final generated\nimage, revealing significant redundancy in large codebooks. Based on this\ninsight, we propose to predict tokens from coarse to fine (CTF), realized by\nassigning the same coarse label for similar tokens. Our framework consists of\ntwo stages: (1) an autoregressive model that sequentially predicts coarse\nlabels for each token in the sequence, and (2) an auxiliary model that\nsimultaneously predicts fine-grained labels for all tokens conditioned on their\ncoarse labels. Experiments on ImageNet demonstrate our method's superior\nperformance, achieving an average improvement of 59 points in Inception Score\ncompared to baselines. Notably, despite adding an inference step, our approach\nachieves faster sampling speeds."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16854",
    "c_title":[
      "Generative Compositor for Few-Shot Visual Information Extraction"
    ],
    "c_abstract":[
      "Visual Information Extraction (VIE), aiming at extracting structured\ninformation from visually rich document images, plays a pivotal role in\ndocument processing. Considering various layouts, semantic scopes, and\nlanguages, VIE encompasses an extensive range of types, potentially numbering\nin the thousands. However, many of these types suffer from a lack of training\ndata, which poses significant challenges. In this paper, we propose a novel\ngenerative model, named Generative Compositor, to address the challenge of\nfew-shot VIE. The Generative Compositor is a hybrid pointer-generator network\nthat emulates the operations of a compositor by retrieving words from the\nsource text and assembling them based on the provided prompts. Furthermore,\nthree pre-training strategies are employed to enhance the model's perception of\nspatial context information. Besides, a prompt-aware resampler is specially\ndesigned to enable efficient matching by leveraging the entity-semantic prior\ncontained in prompts. The introduction of the prompt-based retrieval mechanism\nand the pre-training strategies enable the model to acquire more effective\nspatial and semantic clues with limited training samples. Experiments\ndemonstrate that the proposed method achieves highly competitive results in the\nfull-sample training, while notably outperforms the baseline in the 1-shot,\n5-shot, and 10-shot settings."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-294",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01606",
    "b_title":[
      "From pre-transit to post-eclipse: investigating the impact of 3D\n  temperature, chemistry, and dynamics on high-resolution emission spectra of\n  the ultra-hot Jupiter WASP-76b"
    ],
    "b_abstract":[
      "High-resolution spectroscopy has provided a wealth of information about the\nclimate and composition of ultra-hot Jupiters. However, the 3D structure of\ntheir atmospheres makes observations more challenging to interpret,\nnecessitating 3D forward-modeling studies. In this work, we model\nphase-dependent thermal emission spectra of the archetype ultra-hot Jupiter\nWASP-76b to understand how the line strengths and Doppler shifts of Fe, CO,\nH$_2$O, and OH evolve throughout the orbit. We post-process outputs of the\nSPARC\/MITgcm global circulation model with the 3D Monte-Carlo radiative\ntransfer code gCMCRT to simulate emission spectra at 36 orbital phases. We then\ncross-correlate the spectra with different templates to obtain CCF and\n$K_{\\text{p}}$$-$$V_{\\text{sys}}$ maps. For each species, our models produce\nconsistently negative $K_{\\text{p}}$ offsets in pre- and post-eclipse, which\nare driven by planet rotation. The size of these offsets is similar to the\nequatorial rotation velocity of the planet. Furthermore, we demonstrate how the\nweak vertical temperature gradient on the nightside of ultra-hot Jupiters mutes\nthe absorption features of CO and H$_2$O, which significantly hampers their\ndetectability in pre- and post-transit. We also show that the $K_{\\text{p}}$\nand $V_{\\text{sys}}$ offsets in pre- and post-transit are not always a measure\nfor the line-of-sight velocities in the atmosphere. This is because the\ncross-correlation signal is a blend of dayside emission and nightside\nabsorption features. Finally, we highlight that the observational uncertainty\nin the known orbital velocity of ultra-hot Jupiters can be multiple km\/s, which\nmakes it hard for certain targets to meaningfully report absolute\n$K_{\\text{p}}$ offsets."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.10847",
    "c_title":[
      "LiDO: Exploring the Stable Plutino Parameter Space"
    ],
    "c_abstract":[
      "We present a publicly available, high-resolution, filled-parameter-space\nsynthetic distribution of the Plutinos, trans-Neptunian Objects (TNOs)\nlibrating in the 3:2 mean-motion resonance with Neptune, with particular focus\non the Plutinos simultaneously Kozai-librating. This synthetic distribution was\nbuilt in preparation for results from the Large inclination Distant Objects\n(LiDO) Survey, which pointed at locations on the sky where Kozai Plutinos are\npredicted to come to pericenter and are thus most easily detected in\nmagnitude-limited surveys. Although we do not expect the full stable\nparameter-space presented here to be populated with real TNOs, it provides a\nuseful starting point for comparison with Neptune migration simulations and\ndebiased observational results. Our new stable parameter space synthetic\ndistribution of fictitious Plutinos is consistent with previous works, and we\nbuild on past results by focusing on the behavior of Kozai Plutinos over 4Gyr\nintegrations. We find that 95% of 4Gyr stable Kozai Plutinos remain in the same\nomega-libration island for the entire integration. This provides an interesting\ndiagnostic opportunity: any asymmetry in the true number of 4Gyr stable Kozai\nPlutinos in the two omega-libration islands must be caused by the details of\nemplacement during giant planet migration. Through analysis of previously\npublished Neptune migration models, we show that the intrinsic fraction of\nPlutinos captured into Kozai depends on Neptune's migration speed and mode.\nCombining the filled-parameter-space synthetic distribution with future\nmigration simulations and the results of the carefully characterized LiDO\nsurvey will enable interpretation of the intrinsic orbital distribution of the\nKozai and non-Kozai Plutinos."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-295",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01173",
    "b_title":[
      "Improving knowledge of the acoustic factors involved in railway noise\n  annoyance: first results of a pilot field survey of sixty-two local residents"
    ],
    "b_abstract":[
      "Railway transportation contributes to the objectives of decarbonization but\nalso generates negative externalities, including noise. Energy noise indicators\nused to characterize population exposure do not adequately reflect the\nrepetitive nature of railway noise peaks. The GENIFER pilot study aims to test\na protocol designed to characterize railway noise events according to the\ninstantaneous perceived annoyance when the train is passing, in order to\nimprove understanding of the influence of acoustic factors on annoyance. The\nfirst phase of the survey was carried out in 2023 among 62 residents of a pilot\nsite. An electronic device was used to collect around 5,000 ratings, ranging\nfrom 1 to 10, assessing the instantaneous annoyance induced by railway noise at\npassing trains. The site instrumentation included sixteen sound level meters\nand two video recording systems, enabling annoyance ratings to be associated\nwith the acoustic characteristics of railway noise events. A questionnaire\naimed at identifying co-determinants of long-term annoyance was also\nadministered to participants. Feedback on the field implementation of this\nsurvey and initial results concerning acoustic measurements, instantaneous\nannoyance ratings and questionnaire responses will be presented."
    ],
    "b_categories":[
      [
        "physics.class-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03768",
    "c_title":[
      "Dispersion equation for H modes of a strip line with a circular\n  cylindrical shield"
    ],
    "c_abstract":[
      "We formulate the dispersion equation for H modes of a circular waveguide with\na perfectly conducting strip of zero thickness placed symmetrically in its\ndiametral plane. The wave number of the lowest mode is calculated with high\naccuracy for various strip widths. Simple asymptotic formulas are derived for\nthe two extreme cases in which the width of the strip is either small or nearly\nequal to the diameter of the waveguide."
    ],
    "c_categories":[
      [
        "physics.class-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-296",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07380",
    "b_title":[
      "Demonstrating Wheeled Lab: Modern Sim2Real for Low-cost, Open-source\n  Wheeled Robotics"
    ],
    "b_abstract":[
      "Simulation has been pivotal in recent robotics milestones and is poised to\nplay a prominent role in the field's future. However, recent robotic advances\noften rely on expensive and high-maintenance platforms, limiting access to\nbroader robotics audiences. This work introduces Wheeled Lab, a framework for\nthe low-cost, open-source wheeled platforms that are already widely established\nin education and research. Through integration with Isaac Lab, Wheeled Lab\nintroduces modern techniques in Sim2Real, such as domain randomization, sensor\nsimulation, and end-to-end learning, to new user communities. To kickstart\neducation and demonstrate the framework's capabilities, we develop three\nstate-of-the-art policies for small-scale RC cars: controlled drifting,\nelevation traversal, and visual navigation, each trained in simulation and\ndeployed in the real world. By bridging the gap between advanced Sim2Real\nmethods and affordable, available robotics, Wheeled Lab aims to democratize\naccess to cutting-edge tools, fostering innovation and education in a broader\nrobotics context. The full stack, from hardware to software, is low cost and\nopen-source."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13787",
    "c_title":[
      "A Systematic Digital Engineering Approach to Verification & Validation\n  of Autonomous Ground Vehicles in Off-Road Environments"
    ],
    "c_abstract":[
      "The engineering community currently encounters significant challenges in the\nsystematic development and validation of autonomy algorithms for off-road\nground vehicles. These challenges are posed by unusually high test parameters\nand algorithmic variants. In order to address these pain points, this work\npresents an optimized digital engineering framework that tightly couples\ndigital twin simulations with model-based systems engineering (MBSE) and\nmodel-based design (MBD) workflows. The efficacy of the proposed framework is\ndemonstrated through an end-to-end case study of an autonomous light tactical\nvehicle (LTV) performing visual servoing to drive along a dirt road and\nreacting to any obstacles or environmental changes. The presented methodology\nallows for traceable requirements engineering, efficient variant management,\ngranular parameter sweep setup, systematic test-case definition, and automated\nexecution of the simulations. The candidate off-road autonomy algorithm is\nevaluated for satisfying requirements against a battery of 128 test cases,\nwhich is procedurally generated based on the test parameters (times of the day\nand weather conditions) and algorithmic variants (perception, planning, and\ncontrol sub-systems). Finally, the test results and key performance indicators\nare logged, and the test report is generated automatically. This then allows\nfor manual as well as automated data analysis with traceability and\ntractability across the digital thread."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-297",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11733",
    "b_title":[
      "Plant in Cupboard, Orange on Table, Book on Shelf. Benchmarking\n  Practical Reasoning and Situation Modelling in a Text-Simulated Situated\n  Environment"
    ],
    "b_abstract":[
      "Large language models (LLMs) have risen to prominence as 'chatbots' for users\nto interact via natural language. However, their abilities to capture\ncommon-sense knowledge make them seem promising as language-based planners of\nsituated or embodied action as well. We have implemented a simple text-based\nenvironment -- similar to others that have before been used for\nreinforcement-learning of agents -- that simulates, very abstractly, a\nhousehold setting. We use this environment and the detailed error-tracking\ncapabilities we implemented for targeted benchmarking of LLMs on the problem of\npractical reasoning: Going from goals and observations to actions. Our findings\nshow that environmental complexity and game restrictions hamper performance,\nand concise action planning is demanding for current LLMs."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11451",
    "c_title":[
      "From Personas to Talks: Revisiting the Impact of Personas on\n  LLM-Synthesized Emotional Support Conversations"
    ],
    "c_abstract":[
      "The rapid advancement of Large Language Models (LLMs) has revolutionized the\ngeneration of emotional support conversations (ESC), offering scalable\nsolutions with reduced costs and enhanced data privacy. This paper explores the\nrole of personas in the creation of ESC by LLMs. Our research utilizes\nestablished psychological frameworks to measure and infuse persona traits into\nLLMs, which then generate dialogues in the emotional support scenario. We\nconduct extensive evaluations to understand the stability of persona traits in\ndialogues, examining shifts in traits post-generation and their impact on\ndialogue quality and strategy distribution. Experimental results reveal several\nnotable findings: 1) LLMs can infer core persona traits, 2) subtle shifts in\nemotionality and extraversion occur, influencing the dialogue dynamics, and 3)\nthe application of persona traits modifies the distribution of emotional\nsupport strategies, enhancing the relevance and empathetic quality of the\nresponses. These findings highlight the potential of persona-driven LLMs in\ncrafting more personalized, empathetic, and effective emotional support\ndialogues, which has significant implications for the future design of\nAI-driven emotional support systems."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-298",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13872",
    "b_title":[
      "Structural determinants of soft memory in recurrent biological networks"
    ],
    "b_abstract":[
      "Recurrent neural networks are frequently studied in terms of their\ninformation-processing capabilities. The structural properties of these\nnetworks are seldom considered, beyond those emerging from the connectivity\ntuning necessary for network training. However, real biological networks have\nnon-contingent architectures that have been shaped by evolution over eons,\nconstrained partly by information-processing criteria, but more generally by\nfitness maximization requirements. Here we examine the topological properties\nof existing biological networks, focusing in particular on gene regulatory\nnetworks in bacteria. We identify structural features, both local and global,\nthat dictate the ability of recurrent networks to store information on the fly\nand process complex time-dependent inputs."
    ],
    "b_categories":[
      [
        "q-bio.MN"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2502.11318",
    "c_title":[
      "Alias4SBML: A Python Package for Generating Alias Nodes in SBML Models"
    ],
    "c_abstract":[
      "Interpreting biological networks becomes challenging when molecular\ncomponents, such as genes or proteins, participate in numerous interactions,\nresulting in densely connected regions and overlapping interactions that\nobscure functional relationships and biological insights. To address this, we\nintroduce Alias4SBML, a Python package that enhances SBML model visualizations\nby generating alias nodes-duplicate representations of highly connected\nmolecular components-to redistribute interactions and reduce visual congestion.\nApplying Alias4SBML to the SBML models, including one with 59 species and 41\nreactions and another with 701 species and 505 reactions, demonstrated\nsignificant improvements in readability, with edge length reductions of up to\n50.88 %. Our approach preserves the structural integrity of the network while\nfacilitating clearer interpretation of complex biological systems, offering a\nflexible and scalable solution for visualizing biological models more\nefficiently."
    ],
    "c_categories":[
      [
        "q-bio.MN"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-299",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06145",
    "b_title":[
      "Animate Anyone 2: High-Fidelity Character Image Animation with\n  Environment Affordance"
    ],
    "b_abstract":[
      "Recent character image animation methods based on diffusion models, such as\nAnimate Anyone, have made significant progress in generating consistent and\ngeneralizable character animations. However, these approaches fail to produce\nreasonable associations between characters and their environments. To address\nthis limitation, we introduce Animate Anyone 2, aiming to animate characters\nwith environment affordance. Beyond extracting motion signals from source\nvideo, we additionally capture environmental representations as conditional\ninputs. The environment is formulated as the region with the exclusion of\ncharacters and our model generates characters to populate these regions while\nmaintaining coherence with the environmental context. We propose a\nshape-agnostic mask strategy that more effectively characterizes the\nrelationship between character and environment. Furthermore, to enhance the\nfidelity of object interactions, we leverage an object guider to extract\nfeatures of interacting objects and employ spatial blending for feature\ninjection. We also introduce a pose modulation strategy that enables the model\nto handle more diverse motion patterns. Experimental results demonstrate the\nsuperior performance of the proposed method."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10294",
    "c_title":[
      "QMaxViT-Unet+: A Query-Based MaxViT-Unet with Edge Enhancement for\n  Scribble-Supervised Segmentation of Medical Images"
    ],
    "c_abstract":[
      "The deployment of advanced deep learning models for medical image\nsegmentation is often constrained by the requirement for extensively annotated\ndatasets. Weakly-supervised learning, which allows less precise labels, has\nbecome a promising solution to this challenge. Building on this approach, we\npropose QMaxViT-Unet+, a novel framework for scribble-supervised medical image\nsegmentation. This framework is built on the U-Net architecture, with the\nencoder and decoder replaced by Multi-Axis Vision Transformer (MaxViT) blocks.\nThese blocks enhance the model's ability to learn local and global features\nefficiently. Additionally, our approach integrates a query-based Transformer\ndecoder to refine features and an edge enhancement module to compensate for the\nlimited boundary information in the scribble label. We evaluate the proposed\nQMaxViT-Unet+ on four public datasets focused on cardiac structures, colorectal\npolyps, and breast cancer: ACDC, MS-CMRSeg, SUN-SEG, and BUSI. Evaluation\nmetrics include the Dice similarity coefficient (DSC) and the 95th percentile\nof Hausdorff distance (HD95). Experimental results show that QMaxViT-Unet+\nachieves 89.1\\% DSC and 1.316mm HD95 on ACDC, 88.4\\% DSC and 2.226mm HD95 on\nMS-CMRSeg, 71.4\\% DSC and 4.996mm HD95 on SUN-SEG, and 69.4\\% DSC and 50.122mm\nHD95 on BUSI. These results demonstrate that our method outperforms existing\napproaches in terms of accuracy, robustness, and efficiency while remaining\ncompetitive with fully-supervised learning approaches. This makes it ideal for\nmedical image analysis, where high-quality annotations are often scarce and\nrequire significant effort and expense. The code is available at:\nhttps:\/\/github.com\/anpc849\/QMaxViT-Unet"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-300",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15069",
    "b_title":[
      "Magnetic Field induced control and Multiple Magnomechanically Induced\n  Transparency in Single Cavity"
    ],
    "b_abstract":[
      "We investigate magnomechanically induced transparency (MMIT) in a microwave\n3D copper cavity with two YIG spheres under varying interaction parameters.\nNumerical simulations show that the steady-state magnon number increases with\nstronger coupling between cavity photons and magnons, and is sensitive to both\nbias and drive magnetic fields. Pronounced peaks in the magnon population near\nresonant fields highlight the importance of the bias field in energy transfer.\nThe transparency windows are tunable, with up to quadruple windows depending on\nthe coupling and magnon-phonon interactions, as seen in the transmission\nspectrum. Dispersion analysis reveals normal and anomalous regions, enabling\nslow and fast light propagation modulated by coupling strength. Phase and group\ndelay variations, influenced by the drive field, further validate the\ntunability of transparency windows. This study demonstrates the potential of\nMMIT for precise control with out any additional non-linearity over\nlight-matter interactions, with applications in quantum information processing\nand optical communications."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11141",
    "c_title":[
      "A Fully Reconfigurable All-Optical Integrated Nonlinear Activator"
    ],
    "c_abstract":[
      "Photonic neural networks have been considered as the promising candidates for\nnext-generation neuromorphic computation, aiming to break both the power\nconsumption wall and processing speed boundary of state-to-date digital\ncomputing architectures. Optics has shown its advantages in parallelism and\nlinear manipulation. However, the lack of low-power and high-speed all-optical\nnonlinear activation neurons limits its revolution in large-scale photonic\nneural networks. Here we demonstrate an all-optical nonlinear activator (AONA)\nbased on Fano-enhanced nonlinear optical effects in intra-cavity field, in\nwhich our device enables reconfigurability both in shape and type of the\nnonlinear functions (NFs) relying on the tuning biases on Fano interference and\ncavity buildup. Experimental results show that our AONA enables nonlinear\noptical computing with low-power continuous-wave light of 0.1 mW threshold,\nwhich can also support the overall processing speed of 13 GHz. The performances\nof the generated reconfigurable NFs are verified in the classification of\nhandwritten digits and image recognition tasks, yielding the converged cost and\nenhanced accuracy compared to the linear-only networks. Our proposed device\nwould pave the way for energy-efficient and accelerated all-optical intelligent\nprocessors with versatile functionalities and large-scale integration."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-301",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16180",
    "b_title":[
      "BaZrS$_\\text{3}$ Lights Up: The Interplay of Electrons, Photons, and\n  Phonons in Strongly Luminescent Single Crystals"
    ],
    "b_abstract":[
      "Chalcogenide perovskites have emerged as a promising class of materials for\nthe next generation of optoelectronic applications, with BaZrS$_\\text{3}$\nattracting significant attention due to its wide bandgap, earth-abundant\ncomposition, and thermal and chemical stability. However, previous studies have\nconsistently reported weak and ambiguous photoluminescence (PL), regardless of\nsynthesis method, raising questions about the intrinsic optoelectronic quality\nof this compound. In this work, we demonstrate strong, band-to-band-dominated\nPL at room temperature in high-quality BaZrS$_\\text{3}$ single crystals.\nDespite the narrow, single-component PL emission band, time-resolved PL\nmeasurements reveal a carrier lifetime of $1.0\\pm0.2$ ns. To understand the\norigin of the strong PL and short carrier lifetime, we perform multiwavelength\nexcitation and polarization-dependent Raman measurements, supported by\nfirst-principles lattice dynamics calculations. We identify all 23\ntheoretically predicted Raman-active modes and their symmetries, providing a\ncomprehensive reference for future studies. Our results indicate that\nphonon-assisted carrier decay and strong electron-phonon coupling contribute to\nthe short carrier lifetimes, as evidenced by Raman spectroscopy and DFT\ncalculations. Further studies on compositional variations or partial\ncation\/anion substitutions could mitigate electron-phonon coupling and enhance\ncarrier lifetimes. By establishing a detailed reference for the intrinsic\nvibrational and optoelectronic properties of BaZrS$_\\text{3}$, this work paves\nthe way for further advancements in chalcogenide perovskites for energy and\noptoelectronic technologies."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.13512",
    "c_title":[
      "Unravelling the influence of shell thickness in organic functionalized\n  Cu2O nanoparticles on C2+ products distribution in electrocatalytic CO2\n  reduction"
    ],
    "c_abstract":[
      "Cu-based electrocatalysts exhibits enormous potential for electrochemical CO2\nconversion to added-value products. However, high selectivity, specially\ntowards C2+ products, remains a critical challenge for its implementation in\ncommercial applications. Herein, we report the preparation of a series of\nelectrocatalysts based on octadecyl amine (ODA) coated Cu2O nanoparticles.\nHRTEM images show ODA coatings with thickness from 1.2 to 4 nm. DFT\ncalculations predict that at low surface coverage, ODA tends to lay on the Cu2O\nsurface, leaving hydrophilic regions. Oppositely, at high surface coverage, the\nODA molecules are densely packed, being detrimental for both mass and charge\ntransfer. These changes in ODA molecular arrangement explain differences in\nproduct selectivity. In situ Raman spectroscopy has revealed that the optimum\nODA thickness contributes to the stabilization of key intermediates in the\nformation of C2+ products, especially ethanol. Electrochemical impedance\nspectroscopy and pulse voltammetry measurements confirm that the thicker ODA\nshells increase charge transfer resistance, while the lowest ODA content\npromotes faster intermediate desorption rates. At the optimum thickness, the\nintermediates desorption rates are the slowest, in agreement with the maximum\nconcentration of intermediates observed by in situ Raman spectroscopy, thereby\nresulting in a Faradaic efficiency to ethanol and ethylene over 73 %."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-302",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18746",
    "b_title":[
      "Model-Adaptive Approach to Dynamic Discrete Choice Models with Large\n  State Spaces"
    ],
    "b_abstract":[
      "Estimating dynamic discrete choice models with large state spaces poses\ncomputational difficulties. This paper develops a novel model-adaptive approach\nto solve the linear system of fixed point equations of the policy valuation\noperator. We propose a model-adaptive sieve space, constructed by iteratively\naugmenting the space with the residual from the previous iteration. We show\nboth theoretically and numerically that model-adaptive sieves dramatically\nimprove performance. In particular, the approximation error decays at a\nsuperlinear rate in the sieve dimension, unlike a linear rate achieved using\nconventional methods. Our method works for both conditional choice probability\nestimators and full-solution estimators with policy iteration. We apply the\nmethod to analyze consumer demand for laundry detergent using Kantar's\nWorldpanel Take Home data. On average, our method is 51.5% faster than the\nconventional methods in solving the dynamic programming problem, making the\nBayesian MCMC estimator computationally feasible. The results confirm the\ncomputational efficiency of our method in practice."
    ],
    "b_categories":[
      [
        "econ.EM"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2502.05353",
    "c_title":[
      "Point-Identifying Semiparametric Sample Selection Models with No\n  Excluded Variable"
    ],
    "c_abstract":[
      "Sample selection is pervasive in applied economic studies. This paper\ndevelops semiparametric selection models that achieve point identification\nwithout relying on exclusion restrictions, an assumption long believed\nnecessary for identification in semiparametric selection models. Our\nidentification conditions require at least one continuously distributed\ncovariate and certain nonlinearity in the selection process. We propose a\ntwo-step plug-in estimator that is root-n-consistent, asymptotically normal,\nand computationally straightforward (readily available in statistical\nsoftware), allowing for heteroskedasticity. Our approach provides a middle\nground between Lee (2009)'s nonparametric bounds and Honor\\'e and Hu (2020)'s\nlinear selection bounds, while ensuring point identification. Simulation\nevidence confirms its excellent finite-sample performance. We apply our method\nto estimate the racial and gender wage disparity using data from the US Current\nPopulation Survey. Our estimates tend to lie outside the Honor\\'e and Hu\nbounds."
    ],
    "c_categories":[
      [
        "econ.EM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-303",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18401",
    "b_title":[
      "The $D_{s1}(2460) \\to D_s \\pi^+ \\pi^- $ decay from a $D_{s1}$ molecular\n  perspective"
    ],
    "b_abstract":[
      "We conduct a theoretical study of the $ D_{s1}(2460) \\to D_s \\pi^+ \\pi^- $\ndecay from the perspective that the $D_{s1}$ is a molecular state, built mostly\nfrom the $D^* K$ and $D_s^* \\eta$ components. The $D^*$ and $D_s^*$ mesons are\nallowed to decay into two pseudoscalars, with one of them merging with the\nother pseudoscalar that forms the $D_{s1}$ state, ultimately leading to the\n$\\pi^+ \\pi^- D_s$ final state. This results in a triangle diagram mechanism\nwhere all theoretical ingredients are well-known, leading to a free parameter\nframework. We evaluate the mass distributions of particle pairs and find good\nagreement with the experimental distributions of a recent LHCb experiment,\nproviding strong support to the molecular picture of the $D_{s1}(2460)$ state.\nWe also discuss the role played by the scalar mesons $f_0(500)$ and $f_0(980)$,\nat odds with the interpretation of the experimental analysis."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04579",
    "c_title":[
      "Flavor Constraints in a Generational Three Higgs Doublet Model"
    ],
    "c_abstract":[
      "We propose a Three Higgs Doublet Model (3HDM) that goes beyond natural flavor\nconservation and in which each of the three Higgs doublets couples mainly to a\nsingle generation of fermions via non-standard Yukawa structures. A hierarchy\nin the vacuum expectation values of the three Higgs doublets can partially\naddress the SM flavor puzzle. In light of the experimentally observed $125$ GeV\nHiggs boson, we primarily work within a 3HDM alignment limit such that a\nStandard Model-like Higgs is recovered. In order to reproduce the observed CKM\nmixing among quarks, the neutral Higgs bosons of the theory necessarily mediate\nflavor changing neutral currents at the tree level. We consider constraints\nfrom neutral kaon, $B$ meson, and $D$ meson mixing as well as from the rare\nleptonic decays $B_s\/B^0\/K_L\\rightarrow\\mu^+\\mu^-\/e^+e^-$. We identify regions\nof parameter space in which the new physics Higgs bosons can be as light as a\nTeV or even lighter."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-304",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04996",
    "b_title":[
      "Newtonian Gravity from a Poissonian Spontaneous Collapse Model"
    ],
    "b_abstract":[
      "The Tilloy-Di\\'osi (TD) prescription allows to turn any Markovian spontaneous\ncollapse model that can be formally regarded as a continuous measurement\nprocess of the mass density into a hybrid classical-quantum theory in which the\ngravitational Newtonian field enters as a classical field. We study the\napplication of a similar idea to the Poissonian Spontaneous Localization (PSL)\nmodel. As in the TD case, the Newtonian classical field is again recovered upon\naveraging, and additional decoherence appears due to the gravitational\nback-reaction. We study general features of this model and investigate the\ndynamics of a single particle and a rigid spherical body. With respect to the\nTD models, the PSL model presents some notable differences such as the absence\nof long-range decoherence due to the gravitational back-reaction noise and the\nabsence of negative mass measurements."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.11245",
    "c_title":[
      "Effect of linear and quadratic coupling on dynamical parameters of an\n  optomechanical oscillator"
    ],
    "c_abstract":[
      "Dynamics of icrocantilevers are of important interest in micro-mechanical\nsystems for enhancing the functionality and applicable range of the cantilevers\nin vibration transducing and highly sensitive measurement. In this study, using\nthe semi-classical Hamiltonian formalism, we study in detail the modification\nof the mechanical frequency and damping rate taking into account both the\nlinear and quadratic coupling between the mechanical oscillator and the laser\nfield in an opto-mechanical system. It has been seen that, the linear coupling\ngreatly enhances the modification of the effective mechanical frequency and the\neffective damping rate while the quadratic coupling reduces these quantities.\nFor a MHz-frequency oscillator, the damping rate could be 10^5 times increased\nand the frequency is several times modified. These results help clarifying the\norigin of the modification of the susceptibility function for cooling of the\nmechanical mode"
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-305",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06317",
    "b_title":[
      "Accurate and Efficient Two-Stage Gun Detection in Video"
    ],
    "b_abstract":[
      "Object detection in videos plays a crucial role in advancing applications\nsuch as public safety and anomaly detection. Existing methods have explored\ndifferent techniques, including CNN, deep learning, and Transformers, for\nobject detection and video classification. However, detecting tiny objects,\ne.g., guns, in videos remains challenging due to their small scale and varying\nappearances in complex scenes. Moreover, existing video analysis models for\nclassification or detection often perform poorly in real-world gun detection\nscenarios due to limited labeled video datasets for training. Thus, developing\nefficient methods for effectively capturing tiny object features and designing\nmodels capable of accurate gun detection in real-world videos is imperative. To\naddress these challenges, we make three original contributions in this paper.\nFirst, we conduct an empirical study of several existing video classification\nand object detection methods to identify guns in videos. Our extensive analysis\nshows that these methods may not accurately detect guns in videos. Second, we\npropose a novel two-stage gun detection method. In stage 1, we train an\nimage-augmented model to effectively classify ``Gun'' videos. To make the\ndetection more precise and efficient, stage 2 employs an object detection model\nto locate the exact region of the gun within video frames for videos classified\nas ``Gun'' by stage 1. Third, our experimental results demonstrate that the\nproposed domain-specific method achieves significant performance improvements\nand enhances efficiency compared with existing techniques. We also discuss\nchallenges and future research directions in gun detection tasks in computer\nvision."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14373",
    "c_title":[
      "CrossVTON: Mimicking the Logic Reasoning on Cross-category Virtual\n  Try-on guided by Tri-zone Priors"
    ],
    "c_abstract":[
      "Despite remarkable progress in image-based virtual try-on systems, generating\nrealistic and robust fitting images for cross-category virtual try-on remains a\nchallenging task. The primary difficulty arises from the absence of human-like\nreasoning, which involves addressing size mismatches between garments and\nmodels while recognizing and leveraging the distinct functionalities of various\nregions within the model images. To address this issue, we draw inspiration\nfrom human cognitive processes and disentangle the complex reasoning required\nfor cross-category try-on into a structured framework. This framework\nsystematically decomposes the model image into three distinct regions: try-on,\nreconstruction, and imagination zones. Each zone plays a specific role in\naccommodating the garment and facilitating realistic synthesis. To endow the\nmodel with robust reasoning capabilities for cross-category scenarios, we\npropose an iterative data constructor. This constructor encompasses diverse\nscenarios, including intra-category try-on, any-to-dress transformations\n(replacing any garment category with a dress), and dress-to-any transformations\n(replacing a dress with another garment category). Utilizing the generated\ndataset, we introduce a tri-zone priors generator that intelligently predicts\nthe try-on, reconstruction, and imagination zones by analyzing how the input\ngarment is expected to align with the model image. Guided by these tri-zone\npriors, our proposed method, CrossVTON, achieves state-of-the-art performance,\nsurpassing existing baselines in both qualitative and quantitative evaluations.\nNotably, it demonstrates superior capability in handling cross-category virtual\ntry-on, meeting the complex demands of real-world applications."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-306",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18149",
    "b_title":[
      "Artinian Gorenstein algebras with binomial Macaulay dual generator"
    ],
    "b_abstract":[
      "This paper initiates a systematic study for key properties of Artinian\nGorenstein \\(K\\)-algebras having binomial Macaulay dual generators. In\ncodimension 3, we demonstrate that all such algebras satisfy the strong\nLefschetz property, can be constructed as a doubling of an appropriate\n0-dimensional scheme in \\(\\mathbb{P}^2\\), and we provide an explicit\ncharacterization of when they form a complete intersection. For arbitrary\ncodimension, we establish sufficient conditions under which the weak Lefschetz\nproperty holds and show that these conditions are optimal."
    ],
    "b_categories":[
      [
        "math.AC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.12241",
    "c_title":[
      "On numerical semigroup elements and the $\\ell_0$- and\n  $\\ell_\\infty$-norms of their factorizations"
    ],
    "c_abstract":[
      "A numerical semigroup $S$ is a cofinite, additively-closed subset of $\\mathbb\nZ_{\\ge 0}$ that contains 0, and a factorization of $x \\in S$ is a $k$-tuple $z\n= (z_1, \\ldots, z_k)$ where $x = z_1a_1 + \\cdots + z_ka_k$ expresses $x$ as a\nsum of generators of $S = \\langle a_1, \\ldots, a_k \\rangle$. Much~of the study\nof non-unique factorization centers on factorization length $z_1 + \\cdots +\nz_k$, which coincies with the $\\ell_1$-norm of $z$ as the $k$-tuple. In this\npaper, we study the $\\ell_\\infty$-norm and $\\ell_0$-norm of factorizations,\nviewed as alternative notions of length, with particular focus on the\ngeneralizations $\\Delta_\\infty(x)$ and $\\Delta_0(x)$ of the delta set\n$\\Delta(x)$ from classical factorization length. We prove that the\n$\\infty$-delta set $\\Delta_\\infty(x)$ is eventually periodic as a function of\n$x \\in S$, classify $\\Delta_\\infty(S)$ and the 0-delta set $\\Delta_0(S)$ for\nseveral well-studied families of numerical semigroups, and identify families of\nnumerical semigroups demonstrating $\\Delta_\\infty(S)$ and $\\Delta_0(S)$ can be\narbitrarily long intervals and can avoid arbitrarily long subintervals."
    ],
    "c_categories":[
      [
        "math.AC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-307",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07073",
    "b_title":[
      "Nonradial stability of self-similar blowup to Keller-Segel equation in\n  three dimensions"
    ],
    "b_abstract":[
      "In three dimensions, the parabolic-elliptic Keller-Segel system exhibits a\nrich variety of singularity formations. Notably, it admits an explicit\nself-similar blow-up solution whose radial stability, conjectured more than two\ndecades ago in [Brenner-Constantin-Kadanoff-Schenkel-Venkataramani, 1999], was\nrecently confirmed by [Glogi\\'c-Sch\\\"orkhuber, 2024]. This paper aims to extend\nthe radial stability to the nonradial setting, building on the\nfinite-codimensional stability analysis in our previous work [Li-Zhou, 2024].\nThe main input is the mode stability of the linearized operator, whose nonlocal\nnature presents challenges for the spectral analysis. Besides a quantitative\nperturbative analysis for the high spherical classes, we adapted in the first\nspherical class the wave operator method of [Li-Wei-Zhang, 2020] for the fluid\nstability to localize the operator and remove the known unstable mode\nsimultaneously. Our method provides localization beyond the partial mass\nvariable and is independent of the explicit formula of the profile, so it\npotentially sheds light on other linear nonlocal problems."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.11013",
    "c_title":[
      "Bifurcation and multiplicity results for critical problems involving the\n  $p$-Grushin operator"
    ],
    "c_abstract":[
      "In this article we prove a bifurcation and multiplicity result for a critical\nproblem involving a degenerate nonlinear operator $\\Delta_\\gamma^p$. We extend\nto a generic $p>1$ a result which was proved only when $p=2$. When $p\\neq 2$,\nthe nonlinear operator $-\\Delta_\\gamma^p$ has no linear eigenspaces, so our\nextension is nontrivial and requires an abstract critical theorem which is not\nbased on linear subspaces. We also prove a new abstract result based on a\npseudo-index related to the $\\mathbf{Z}_2$-cohomological index that is\napplicable here. We provide a version of the Lions' Concentration-Compactness\nPrinciple for our operator."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-308",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18899",
    "b_title":[
      "Investigation on the Spreading Behaviour of Sand Powder Used in Binder\n  Jet 3D Printing"
    ],
    "b_abstract":[
      "The spreading behaviour of cohesive sand powder is modelled by Discrete\nElement Method, and the spreadability and the mechanical jamming are focused.\nThe empty patches and total particle volume of the spread layer are examined,\nfollowed by the analysis of the geometry force and jamming structure. The\nresults show that several empty patches with different size and shapes could be\nobserved within the spread layer along the spreading direction even when the\ngap height increases to 3.0D90. Large particles are more difficult to be spread\nonto the base due to jamming, although their size is smaller than the gap\nheight. Size segregation of particles occurs before particles entering the gap\nbetween the blade and base. There are almost no particles on the smooth base\nwhen the gap height is small, due to the full-slip flow of particles. The\ndifference of the spread layer and spreadability between the cases with rough\nand smooth base is reduced by the increase of the gap height. An interesting\ncorrelation between jamming effect and local defects (empty spaces) in the\npowder layer is identified. The resistance to particle rolling is important for\nthe mechanical jamming reported in this work. The jammed particles with a\nlarger size ratio tend to be more stable."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09337",
    "c_title":[
      "A Novel Simulation Approach for Evaporation Processes in Small Gaps of\n  Industrial Applications"
    ],
    "c_abstract":[
      "Long liquid retention times in industrial gaps, due to capillary effects,\nsignificantly affect product lifetime by facilitating corrosion on solid\nsurfaces. Concentration-driven evaporation plays a major role in mitigating\nthis corrosion. Accurate evaporation rate predictions are crucial for improved\nproduct design. However, simulating capillary-driven flows with evaporation in\ncomplex geometries is challenging, requiring consideration of surface tension,\nwetting, and phase-change effects. Traditional approaches, such as the\nVolume-of-Fluid method, are prone to curvature calculation errors and have long\nsimulation times due to strict time step limitations. This study introduces a\nnovel semi-transient simulation approach for fast evaporation rate prediction\nin arbitrarily shaped cavities. The approach involves a unidirectional coupling\ncircuit, simulating the fluid surface in Surface Evolver and combining it with\na vapor-in-gas diffusion simulation in OpenFOAM. The approach assumes that the\nevaporation rate is calculated solely based on the conditions at a given liquid\nfilling level, without considering the evaporation history. This allows for\nhighly parallelized simulations, achieving simulation runtimes in the order of\n10 minutes to cover up to 150 hours of physical time. Numerical investigations\nare conducted for water evaporation in air at a temperature of 23{\\deg}C and a\nrelative humidity of 17%, for round and polygonal-shaped capillaries with inner\ndiameters ranging from 1 mm to 13 mm. The results are validated using\nexperimental data and show strong agreement. Simulations are also performed for\ncomplex industrial relevant gaps, demonstrating the applicability of the\napproach to a wide range of crevice geometries."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-309",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06311",
    "b_title":[
      "Analog classical simulation of closed quantum systems"
    ],
    "b_abstract":[
      "We develop an analog classical simulation algorithm of noiseless quantum\ndynamics. By formulating the Schr\\\"{o}dinger equation into a linear system of\nreal-valued ordinary differential equations (ODEs), the probability amplitudes\nof a complex state vector can be encoded in the continuous physical variables\nof an analog computer. Our algorithm reveals the full dynamics of complex\nprobability amplitudes. Such real-time simulation is impossible in quantum\nsimulation approaches without collapsing the state vector, and it is relatively\ncomputationally expensive for digital classical computers. For a real symmetric\ntime-independent Hamiltonian, the ODEs may be solved by a simple analog\nmechanical device such as a one-dimensional spring-mass system. Since the\nunderlying dynamics of quantum computers is governed by the Schr\\\"{o}dinger\nequation, our findings imply that analog computers can also perform quantum\nalgorithms. We illustrate how to simulate the Schr\\\"{o}dinger equation in such\na paradigm, with an application to quantum approximate optimization algorithm.\nThis may pave the way to emulate quantum algorithms with physical computing\ndevices, including analog, continuous-time circuits."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.18372",
    "c_title":[
      "Entanglement transitions in a boundary-driven open quantum many-body\n  system"
    ],
    "c_abstract":[
      "We present a numerical framework based on tree tensor operators that enables\nlarge-scale simulation of out-of-equilibrium open quantum many-body systems. By\ndesign, it protects density operator positivity and provides direct access to\nentanglement monotones, such as entanglement of formation and logarithmic\nnegativity. To demonstrate the framework's ability to probe entanglement in\nopen quantum many-body systems and distinguish it from other correlations, we\nstudy a paradigmatic open system problem: the boundary-driven XXZ spin-chain.\nWe uncover entanglement transitions driven by both the coupling to the\nenvironment and the anisotropy parameter. These transitions reveal an immediate\nconnection between entanglement and spin-current, and link the known transport\nregimes of the model to distinct entanglement regimes, i.e., separable,\narea-law, and volume-law. Our work enables the analysis of entanglement in open\nquantum many-body systems out of equilibrium, a necessary step for developing\nscalable quantum technologies."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-310",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03996",
    "b_title":[
      "Power-over-fiber and distributed acoustic sensing hybridization in\n  single fiber channel"
    ],
    "b_abstract":[
      "The efficient and independent operation of power-over-fiber (PoF) and\ndistributed acoustic sensing (DAS) has been demonstrated using standard\nsingle-mode fiber (SSMF). A transmission optical power efficiency (OPTE) of\n6.67% was achieved over an 11.8 km fiber link, supporting both power delivery\nand distributed optical fiber sensing (DOFS). To minimize cross-talk, the\nsystem separates the power and sensing channels by a 40 THz bandwidth. In the\nexperiment, the power and sensing light wavelengths are 1064 nm (continuous)\nand 1550 nm (pulsed), respectively. As the transmitted optical power increased\nfrom 0 W to 2.13 W, the DAS system successfully localized vibration sources and\nreconstructed phase information, confirming its ability to operate under high\noptical power. The reported scheme verifies the possibility of constructing the\nsensing-energy hybrid network based on conventional optical fiber with the\nadvantages of flexibility and low cost."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.03965",
    "c_title":[
      "Thermally Adaptive Surface Microscopy for brain functional imaging"
    ],
    "c_abstract":[
      "Fluorescence microscopes can record the dynamics of living cells with high\nspatio-temporal resolution in a single plane. However, monitoring rapid and dim\nfluorescence fluctuations, e.g induced by neuronal activity in the brain,\nremains challenging for 3D-distributed emitters due to out-of-focus\nfluorescence background, a restricted photon budget, and the speed limit of\nconventional scanning systems. Here, we introduce a Thermally Adaptive Surface\nstrategy, capable of simultaneously recording, at camera framerate, the\nactivity of 3D-distributed objects. This innovative microscope leverages on an\narray of thermally tuneable microlenses that offer low chromatic aberration and\nhigh transmission, and can be combined with patterned illumination to provide\noptical sectioning. We demonstrate its potential in vivo, by simultaneously\nmonitoring fast fluorescent dynamics at different depths in the zebrafish\nlarval brain, at a rate of 0.5 kHz and over a large field of view (360um x\n360um)."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-311",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06933",
    "b_title":[
      "A fast and robust recipe for modeling non-ideal MHD effects in\n  star-formation simulations"
    ],
    "b_abstract":[
      "Non-ideal MHD effects are thought to be a crucial component of the\nstar-formation process. Numerically, several complications render the study of\nnon-ideal MHD effects in 3D simulations extremely challenging and hinder our\nefforts of exploring a large parameter space. We aim to overcome such\nchallenges by proposing a novel, physically-motivated empirical approximation\nto model non-ideal MHD effects. We perform a number of 2D axisymmetric 3-fluid\nnon-ideal MHD simulations of collapsing prestellar cores and clouds with\nnon-equilibrium chemistry and leverage upon previously-published results. We\nutilize these simulations to develop a multivariate interpolating function to\npredict the ionization fraction in each region of the cloud depending on the\nlocal physical conditions. We subsequently use analytically-derived, simplified\nexpressions to calculate the resistivities of the cloud in each grid cell.\nTherefore, in our new approach the resistivities are calculated without the use\nof a chemical network. We benchmark our method against additional 2D\naxisymmetric non-ideal MHD simulations with random initial conditions and a 3D\nnon-ideal MHD simulation with non-equilibrium chemistry. We find excellent\nquantitative and qualitative agreement between our approach and the \"full\"\nnon-ideal MHD simulations both in terms of the spatial structure of the\nsimulated clouds and regarding their time evolution. We achieve a factor of\n100-1000 increase in computational speed. Given that we ignore the contribution\nof grains, our approximation is valid up to number densities of 10^6 cm^(-3)\nand is therefore suitable for pc-scale simulations of molecular clouds. The\ntabulated data required for integrating our method in hydrodynamical codes,\nalong with a fortran implementation of the interpolating function are publicly\navailable at https:\/\/github.com\/manosagian\/Non-Ideal-MHD-Approximate-Code."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.07711",
    "c_title":[
      "Where Have All the Little Red Dots Gone? Supermassive Black Hole Binary\n  Dynamics and its Impact on Galaxy Properties"
    ],
    "c_abstract":[
      "Recent James Webb Space Telescope observations have revealed a peculiar class\nof galaxies at redshifts $z \\gtrsim 6$, characterized by extremely high central\nstellar densities and overmassive central supermassive black holes (SMBHs),\n\"little red dots\" (LRDs). A critical question remains: If LRDs were common at\nhigh redshifts, how would they evolve into local elliptical galaxies with\nsignificantly lower central densities? To address this, we performed direct\n$N$-body simulations of LRD mergers, focusing on the coevolution of host\ngalaxies and central SMBHs. We track the complete evolution of SMBH binaries\ninto the three-body hardening and gravitational-wave (GW) emission phase. Our\nresults demonstrate that during galaxy mergers, the central SMBHs can eject a\nsubstantial amount of mass from the galactic core via the three-body slingshot\neffect, leading to a decrease in central stellar surface density by an order of\nmagnitude. Additionally, GW recoil can further contribute in making the galaxy\ncenters less dense and more in alignment with low-redshift quiescent galaxies.\nThis transformation occurs on a relatively short timescale of a few $\\sim$100\nMyr, implying that LRDs can evolve into lower-redshift elliptical galaxies by\n$z<4$. The timescales for our SMBH mergers vary between 100 Myr and 800 Myr,\ndepending on the initial orbital parameters of the merging galaxies and the\nmass ratio of the SMBHs. Our findings provide a plausible mechanism for the\ntransformation of LRDs into elliptical galaxies while highlighting the\nefficiency of SMBH mergers in such high-density environments, which plays a\ncrucial role in SMBH growth."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-312",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06312",
    "b_title":[
      "Towards Iris Presentation Attack Detection with Foundation Models"
    ],
    "b_abstract":[
      "Foundation models are becoming increasingly popular due to their strong\ngeneralization capabilities resulting from being trained on huge datasets.\nThese generalization capabilities are attractive in areas such as NIR Iris\nPresentation Attack Detection (PAD), in which databases are limited in the\nnumber of subjects and diversity of attack instruments, and there is no\ncorrespondence between the bona fide and attack images because, most of the\ntime, they do not belong to the same subjects. This work explores an iris PAD\napproach based on two foundation models, DinoV2 and VisualOpenClip. The results\nshow that fine-tuning prediction with a small neural network as head overpasses\nthe state-of-the-art performance based on deep learning approaches. However,\nsystems trained from scratch have still reached better results if bona fide and\nattack images are available."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07194",
    "c_title":[
      "VAGeo: View-specific Attention for Cross-View Object Geo-Localization"
    ],
    "c_abstract":[
      "Cross-view object geo-localization (CVOGL) aims to locate an object of\ninterest in a captured ground- or drone-view image within the satellite image.\nHowever, existing works treat ground-view and drone-view query images\nequivalently, overlooking their inherent viewpoint discrepancies and the\nspatial correlation between the query image and the satellite-view reference\nimage. To this end, this paper proposes a novel View-specific Attention\nGeo-localization method (VAGeo) for accurate CVOGL. Specifically, VAGeo\ncontains two key modules: view-specific positional encoding (VSPE) module and\nchannel-spatial hybrid attention (CSHA) module. In object-level, according to\nthe characteristics of different viewpoints of ground and drone query images,\nviewpoint-specific positional codings are designed to more accurately identify\nthe click-point object of the query image in the VSPE module. In feature-level,\na hybrid attention in the CSHA module is introduced by combining channel\nattention and spatial attention mechanisms simultaneously for learning\ndiscriminative features. Extensive experimental results demonstrate that the\nproposed VAGeo gains a significant performance improvement, i.e., improving\nacc@0.25\/acc@0.5 on the CVOGL dataset from 45.43%\/42.24% to 48.21%\/45.22% for\nground-view, and from 61.97%\/57.66% to 66.19%\/61.87% for drone-view."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-313",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00689",
    "b_title":[
      "Leveraging LLMs for Dynamic IoT Systems Generation through\n  Mixed-Initiative Interaction"
    ],
    "b_abstract":[
      "IoT systems face significant challenges in adapting to user needs, which are\noften under-specified and evolve with changing environmental contexts. To\naddress these complexities, users should be able to explore possibilities,\nwhile IoT systems must learn and support users in the process of providing\nproper services, e.g., to serve novel experiences. The IoT-Together paradigm\naims to meet this demand through the Mixed-Initiative Interaction (MII)\nparadigm that facilitates a collaborative synergy between users and IoT\nsystems, enabling the co-creation of intelligent and adaptive solutions that\nare precisely aligned with user-defined goals. This work advances IoT-Together\nby integrating Large Language Models (LLMs) into its architecture. Our approach\nenables intelligent goal interpretation through a multi-pass dialogue framework\nand dynamic service generation at runtime according to user needs. To\ndemonstrate the efficacy of our methodology, we design and implement the system\nin the context of a smart city tourism case study. We evaluate the system's\nperformance using agent-based simulation and user studies. Results indicate\nefficient and accurate service identification and high adaptation quality. The\nempirical evidence indicates that the integration of Large Language Models\n(LLMs) into IoT architectures can significantly enhance the architectural\nadaptability of the system while ensuring real-world usability."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00944",
    "c_title":[
      "B-OCL: An Object Constraint Language Interpreter in Python"
    ],
    "c_abstract":[
      "The Object Constraint Language (OCL) has been widely used in the modeling\ncommunity to complement software models for precisely defining constraints and\nbusiness rules for the modeled systems. There is a limited number of tools\nsupporting the definition and interpretation of OCL constraints, even less for\na Python-based modelling approaches.\n  In this paper, we introduce an OCL interpreter for Python. The interpreter\nhas two components: parser and evaluator. We implement the OCL metamodel as a\nset of Python classes and design the grammar for the parser using the\nstate-of-the-art ANTLR parser generator. The parser generates the syntax tree,\nthat conforms with the OCL metamodel, after parsing each part of the OCL\nconstraint. The evaluator then interprets the constraints using this syntax\ntree and the object diagram. In the end, the interpreter reports the result for\nall the constraints."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-314",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05433",
    "b_title":[
      "Infrared Fluxes and Light Curves of Near-Earth Objects: The full Spitzer\n  Sample"
    ],
    "b_abstract":[
      "The IRAC camera on the Spitzer Space Telescope observed 2175 Near Earth\nObjects (NEOs) during its Warm Mission phase, primarily in three large surveys,\nand also in a small number of a dedicated projects. In this paper we present\nthe final reprocessing of the NEO data and determine fluxes at 3.6 microns\n(where available) and 4.5 microns. The observing windows range from minutes to\nnearly ten hours, which means that for 39 NEOs we observe a complete\nlightcurve, and for these objects we present period and amplitude estimates and\nderive minimum cohesive strengths for the objects with well-determined periods.\nFor an additional 128 objects we detect a significant fraction of a complete\nlightcurve, and present estimated lower limits to their rotation periods. This\npaper presents the final and definitive Spitzer\/IRAC NEO flux catalog."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.02434",
    "c_title":[
      "Activity of comet 7P\/Pons-Winnecke during the 2021 apparition"
    ],
    "c_abstract":[
      "Comet 7P\/Pons-Winnecke was observed from the Calar Alto Observatory (Spain)\nfor four months during the 2021 inbound apparition. Broad-band visible images\nwere taken between 1.71 and 1.25 AU pre-perihelion, while long-slit\nspectrophotometric data were taken at $\\sim$ 1.25 AU pre-perihelion. This\ndataset has been complemented with three $r$-Sloan images observed from Zwicky\nTransient Facility (ZTF) to model the physical properties and loss rate of the\ndust with a forward Monte Carlo dust tail code. The model fits the observed\nisophotes well for most observations. The peak dust production rate was\nmeasured at 83 kg s$^{-1}$, 15 days after perihelion. The particle terminal\nspeed ranges from 3 m s$^{-1}$ for 0.1 m particles to 23 m s$^{-1}$ for 5\n$\\mu$m particles. Regarding the gas production from spectra, CN and C$_2$ show\nasymmetric emission between the sunward and antisunward directions beyond the\ndata uncertainties and error propagation, while a clear asymmetry for C$_3$\ncannot be definitively claimed. Average production rates for CN, C$_2$, and\nC$_3$ near 2021 perihelion are 1.15 $\\times 10^{24}$, 2.32$\\times 10^{24}$, and\n1.69$\\times 10^{23}$ s$^{-1}$, respectively. The dust-to-gas mass ratio value\nis estimated to be around 2, suggesting a dust-rich composition. Based on the\ngas composition and the $Af\\rho$ value, we classify 7P\/Pons-Winnecke as having\na typical composition for Jupiter Family comets, with some C$_3$ depletion.\nGiven the limited previous knowledge, our work contributes to expanding the\nunderstanding of the activity and characteristics of 7P\/Pons-Winnecke."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-315",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07234",
    "b_title":[
      "Enhancing Interaction with Augmented Reality through Mid-Air Haptic\n  Feedback: Architecture Design and User Feedback"
    ],
    "b_abstract":[
      "The integration of haptics within Augmented Reality may help to deliver an\nenriched experience, while facilitating the performance of specific actions\n(e.g. repositioning or resizin ) that are still dependent on the user's skills.\nThis paper gathers the description of a flexible architecture designed to\ndeploy haptically-enabled AR applications. The haptic feedback may be generated\nthrough a variety of devices (e.g., wearable, graspable, or mid-air ones), and\nthe architecture facilitates handling the specificity of each. For this reason,\nit is discussed how to generate a haptic representation of a 3D digital object\ndepending on the application and the target device. Additionally, it is\nincluded an analysis of practical, relevant issues that arise when setting up a\nsystem to work with specific devices like Head-Mounted Displays (e.g.,\nHoloLens) and mid-air haptic devices (e.g., Ultrahaptics UHK), such as the\nalignment between the real world and the virtual one. The architecture\napplicability is demonstrated through the implementation of two applications:\nForm Inspector and Simon Game, built for HoloLens and iOS mobile phones for\nvisualization and for UHK for mid-air haptics delivery. These applications have\nbeen used by nine users to explore the efficiency, meaningfulness, and\nusefulness of mid-air haptics for form perception, object resizing, and push\ninteraction tasks. Results show that, although mobile interaction is preferred\nwhen this option is available, haptics turn out to be more meaningful in\nidentifying shapes when compared to what users initially expect and in\ncontributing to the execution of resizing tasks. Moreover, this preliminary\nuser study reveals that users may be expecting a tailored interface metaphor,\nnot necessarily inspired in natural interaction."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03575",
    "c_title":[
      "Chartist: Task-driven Eye Movement Control for Chart Reading"
    ],
    "c_abstract":[
      "To design data visualizations that are easy to comprehend, we need to\nunderstand how people with different interests read them. Computational models\nof predicting scanpaths on charts could complement empirical studies by\noffering estimates of user performance inexpensively; however, previous models\nhave been limited to gaze patterns and overlooked the effects of tasks. Here,\nwe contribute Chartist, a computational model that simulates how users move\ntheir eyes to extract information from the chart in order to perform analysis\ntasks, including value retrieval, filtering, and finding extremes. The novel\ncontribution lies in a two-level hierarchical control architecture. At the high\nlevel, the model uses LLMs to comprehend the information gained so far and\napplies this representation to select a goal for the lower-level controllers,\nwhich, in turn, move the eyes in accordance with a sampling policy learned via\nreinforcement learning. The model is capable of predicting human-like\ntask-driven scanpaths across various tasks. It can be applied in fields such as\nexplainable AI, visualization design evaluation, and optimization. While it\ndisplays limitations in terms of generalizability and accuracy, it takes\nmodeling in a promising direction, toward understanding human behaviors in\ninteracting with charts."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-316",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02694",
    "b_title":[
      "Temporal Cycle Detection and Acyclic Temporization"
    ],
    "b_abstract":[
      "In directed graphs, a cycle can be seen as a structure that allows its\nvertices to loop back to themselves, or as a structure that allows pairs of\nvertices to reach each other through distinct paths. We extend these concepts\nto temporal graph theory, resulting in multiple interesting definitions of a\n\"temporal cycle\". For each of these, we consider the problems of Cycle\nDetection and Acyclic Temporization. For the former, we are given an input\ntemporal digraph, and we want to decide whether it contains a temporal cycle.\nRegarding the latter, for a given input (static) digraph, we want to time the\narcs such that no temporal cycle exists in the resulting temporal digraph.\nWe're also interested in Acyclic Temporization where we bound the lifetime of\nthe resulting temporal digraph. Multiple results are presented, including\npolynomial and fixed-parameter tractable search algorithms, polynomial-time\nreductions from 3-SAT and Not All Equal 3-SAT, and temporizations resulting\nfrom arbitrary vertex orderings which cover (almost) all cases."
    ],
    "b_categories":[
      [
        "cs.CC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15194",
    "c_title":[
      "On the Hardness of the Drone Delivery Problem"
    ],
    "c_abstract":[
      "Fast shipping and efficient routing are key problems of modern logistics.\nBuilding on previous studies that address package delivery from a source node\nto a destination within a graph using multiple agents (such as vehicles,\ndrones, and ships), we investigate the complexity of this problem in\nspecialized graphs and with restricted agent types, both with and without\npredefined initial positions. Particularly, in this paper, we aim to minimize\nthe delivery time for delivering a package. To achieve this, we utilize a set\nof collaborative agents, each capable of traversing a specific subset of the\ngraph and operating at varying speeds. This challenge is encapsulated in the\nrecently introduced Drone Delivery Problem with respect to delivery time (DDT).\n  In this work, we show that the DDT with predefined initial positions on a\nline is NP-hard, even when considering only agents with two distinct speeds.\nThis refines the results presented by Erlebach, et al.[10], who demonstrated\nthe NP-hardness of DDT on a line with agents of arbitrary speeds. Additionally,\nwe examine DDT in grid graphs without predefined initial positions, where each\ndrone can freely choose its starting position. We show that the problem is\nNP-hard to approximate within a factor of $O(n^{1-\\varepsilon}$), where $n$ is\nthe size of the grid, even when all agents are restricted to two different\nspeeds as well as rectangular movement areas. We conclude by providing an easy\n$O(n)$ approximation algorithm."
    ],
    "c_categories":[
      [
        "cs.CC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-317",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04249",
    "b_title":[
      "IOLBENCH: Benchmarking LLMs on Linguistic Reasoning"
    ],
    "b_abstract":[
      "Despite the remarkable advancements and widespread applications of deep\nneural networks, their ability to perform reasoning tasks remains limited,\nparticularly in domains requiring structured, abstract thought. In this paper,\nwe investigate the linguistic reasoning capabilities of state-of-the-art large\nlanguage models (LLMs) by introducing IOLBENCH, a novel benchmark derived from\nInternational Linguistics Olympiad (IOL) problems. This dataset encompasses\ndiverse problems testing syntax, morphology, phonology, and semantics, all\ncarefully designed to be self-contained and independent of external knowledge.\nThese tasks challenge models to engage in metacognitive linguistic reasoning,\nrequiring the deduction of linguistic rules and patterns from minimal examples.\nThrough extensive benchmarking of leading LLMs, we find that even the most\nadvanced models struggle to handle the intricacies of linguistic complexity,\nparticularly in areas demanding compositional generalization and rule\nabstraction. Our analysis highlights both the strengths and persistent\nlimitations of current models in linguistic problem-solving, offering valuable\ninsights into their reasoning capabilities. By introducing IOLBENCH, we aim to\nfoster further research into developing models capable of human-like reasoning,\nwith broader implications for the fields of computational linguistics and\nartificial intelligence."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05222",
    "c_title":[
      "ParaRev: Building a dataset for Scientific Paragraph Revision annotated\n  with revision instruction"
    ],
    "c_abstract":[
      "Revision is a crucial step in scientific writing, where authors refine their\nwork to improve clarity, structure, and academic quality. Existing approaches\nto automated writing assistance often focus on sentence-level revisions, which\nfail to capture the broader context needed for effective modification. In this\npaper, we explore the impact of shifting from sentence-level to paragraph-level\nscope for the task of scientific text revision. The paragraph level definition\nof the task allows for more meaningful changes, and is guided by detailed\nrevision instructions rather than general ones. To support this task, we\nintroduce ParaRev, the first dataset of revised scientific paragraphs with an\nevaluation subset manually annotated with revision instructions. Our\nexperiments demonstrate that using detailed instructions significantly improves\nthe quality of automated revisions compared to general approaches, no matter\nthe model or the metric considered."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-318",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20009",
    "b_title":[
      "Estimating sample size in dental research"
    ],
    "b_abstract":[
      "Determination of sample size is critical, however not easy to do. Sample size\ndefined as the number of observations in a sample should be big enough to have\na high likelihood of detecting a true difference between groups. Practical\nprocedure for determining sample size, using G*power and previous dental\narticles, is shown in this study. Examples involving independent t-test, paired\nt-test, one-way analysis of variance(ANOVA), and one-way repeated-measures(RM)\nANOVA are used. The purpose of this study is to enable researchers with\nnon-statistical backgrounds to use in practice freely available statistical\nsoftware G*power to determine sample size and power."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.17684",
    "c_title":[
      "High-Dimensional Covariate-Dependent Gaussian Graphical Models"
    ],
    "c_abstract":[
      "Motivated by dynamic biologic network analysis, we propose a\ncovariate-dependent Gaussian graphical model (cdexGGM) for capturing network\nstructure that varies with covariates through a novel parameterization.\nUtilizing a likelihood framework, our methodology jointly estimates all dynamic\nedge and vertex parameters. We further develop statistical inference procedures\nto test the dynamic nature of the underlying network. Concerning large-scale\nnetworks, we perform composite likelihood estimation with an $\\ell_1$ penalty\nto discover sparse dynamic network structures. We establish the estimation\nerror bound in $\\ell_2$ norm and validate the sign consistency in the\nhigh-dimensional context. We apply our method to an influenza vaccine data set\nto model the dynamic gene network that evolves with time. We also investigate a\nDown syndrome data set to model the dynamic protein network which varies under\na factorial experimental design. These applications demonstrate the\napplicability and effectiveness of the proposed model. The supplemental\nmaterials for this article are available online."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-319",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15871",
    "b_title":[
      "MASH-VLM: Mitigating Action-Scene Hallucination in Video-LLMs through\n  Disentangled Spatial-Temporal Representations"
    ],
    "b_abstract":[
      "In this work, we tackle action-scene hallucination in Video Large Language\nModels (Video-LLMs), where models incorrectly predict actions based on the\nscene context or scenes based on observed actions. We observe that existing\nVideo-LLMs often suffer from action-scene hallucination due to two main\nfactors. First, existing Video-LLMs intermingle spatial and temporal features\nby applying an attention operation across all tokens. Second, they use the\nstandard Rotary Position Embedding (RoPE), which causes the text tokens to\noveremphasize certain types of tokens depending on their sequential orders. To\naddress these issues, we introduce MASH-VLM, Mitigating Action-Scene\nHallucination in Video-LLMs through disentangled spatial-temporal\nrepresentations. Our approach includes two key innovations: (1) DST-attention,\na novel attention mechanism that disentangles the spatial and temporal tokens\nwithin the LLM by using masked attention to restrict direct interactions\nbetween the spatial and temporal tokens; (2) Harmonic-RoPE, which extends the\ndimensionality of the positional IDs, allowing the spatial and temporal tokens\nto maintain balanced positions relative to the text tokens. To evaluate the\naction-scene hallucination in Video-LLMs, we introduce the UNSCENE benchmark\nwith 1,320 videos and 4,078 QA pairs. Extensive experiments demonstrate that\nMASH-VLM achieves state-of-the-art results on the UNSCENE benchmark, as well as\non existing video understanding benchmarks."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09951",
    "c_title":[
      "Target-aware Bidirectional Fusion Transformer for Aerial Object Tracking"
    ],
    "c_abstract":[
      "The trackers based on lightweight neural networks have achieved great success\nin the field of aerial remote sensing, most of which aggregate multi-stage deep\nfeatures to lift the tracking quality. However, existing algorithms usually\nonly generate single-stage fusion features for state decision, which ignore\nthat diverse kinds of features are required for identifying and locating the\nobject, limiting the robustness and precision of tracking. In this paper, we\npropose a novel target-aware Bidirectional Fusion transformer (BFTrans) for UAV\ntracking. Specifically, we first present a two-stream fusion network based on\nlinear self and cross attentions, which can combine the shallow and the deep\nfeatures from both forward and backward directions, providing the adjusted\nlocal details for location and global semantics for recognition. Besides, a\ntarget-aware positional encoding strategy is designed for the above fusion\nmodel, which is helpful to perceive the object-related attributes during the\nfusion phase. Finally, the proposed method is evaluated on several popular UAV\nbenchmarks, including UAV-123, UAV20L and UAVTrack112. Massive experimental\nresults demonstrate that our approach can exceed other state-of-the-art\ntrackers and run with an average speed of 30.5 FPS on embedded platform, which\nis appropriate for practical drone deployments."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-320",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15299",
    "b_title":[
      "Inside-Out: Hidden Factual Knowledge in LLMs"
    ],
    "b_abstract":[
      "This work presents a framework for assessing whether large language models\n(LLMs) encode more factual knowledge in their parameters than what they express\nin their outputs. While a few studies hint at this possibility, none has\nclearly defined or demonstrated this phenomenon. We first propose a formal\ndefinition of knowledge, quantifying it for a given question as the fraction of\ncorrect-incorrect answer pairs where the correct one is ranked higher. This\ngives rise to external and internal knowledge, depending on the information\nused to score individual answer candidates: either the model's observable\ntoken-level probabilities or its intermediate computations. Hidden knowledge\narises when internal knowledge exceeds external knowledge. We then present a\ncase study, applying this framework to three popular open-weights LLMs in a\nclosed-book QA setup. Our results indicate that: (1) LLMs consistently encode\nmore factual knowledge internally than what they express externally, with an\naverage relative gap of 40%. (2) Surprisingly, some knowledge is so deeply\nhidden that a model can internally know an answer perfectly, yet fail to\ngenerate it even once, despite large-scale repeated sampling of 1,000 answers.\nThis reveals fundamental limitations in the generation capabilities of LLMs,\nwhich (3) put a practical constraint on scaling test-time compute via repeated\nanswer sampling in closed-book QA: significant performance improvements remain\ninaccessible because some answers are practically never sampled, yet if they\nwere, we would be guaranteed to rank them first."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11707",
    "c_title":[
      "Ad-hoc Concept Forming in the Game Codenames as a Means for Evaluating\n  Large Language Models"
    ],
    "c_abstract":[
      "This study utilizes the game Codenames as a benchmarking tool to evaluate\nlarge language models (LLMs) with respect to specific linguistic and cognitive\nskills. LLMs play each side of the game, where one side generates a clue word\ncovering several target words and the other guesses those target words. We\ndesigned various experiments by controlling the choice of words (abstract vs.\nconcrete words, ambiguous vs. monosemic) or the opponent (programmed to be\nfaster or slower in revealing words). Recent commercial and open-weight models\nwere compared side-by-side to find out factors affecting their performance. The\nevaluation reveals details about their strategies, challenging cases, and\nlimitations of LLMs."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-321",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09708",
    "b_title":[
      "Fractionalized Prethermalization in the One-Dimensional Hubbard Model"
    ],
    "b_abstract":[
      "Prethermalization phenomena in driven systems are generally understood via a\nlocal Floquet Hamiltonian obtained from a high-frequency expansion. Remarkably,\nrecently it has been shown that a driven Kitaev spin liquid with fractionalized\nexcitations can realize a quasi-stationary state that is not captured by this\nparadigm. Instead distinct types of fractionalized excitations are\ncharacterized by vastly different temperatures-a phenomenon dubbed\n\"fractionalized prethermalization\". In our work, we analyze fractionalized\nprethermalization in a driven one-dimensional Hubbard model at strong coupling\nwhich hosts spin-charge fractionalization. At intermediate frequencies\nquasi-steady states emerge which are characterized by a low spin and high\ncharge temperature with lifetimes set by two competing processes: the lifetime\nof the quasiparticles determined by Fermi's Golden rule and the exponential\nlifetime of the Floquet prethermal plateau. We classify drives into three\ncategories, each giving rise to distinct (fractional) prethermalization\ndynamics. Resorting to a time-dependent variant of the Schrieffer-Wolff\ntransformation, we systematically analyze how these drive categories are linked\nto the underlying driven Hubbard model, thereby providing a general\nunderstanding of the emergent thermalization dynamics. We discuss routes\ntowards an experimental realization of this phenomenon in quantum simulation\nplatforms."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.00130",
    "c_title":[
      "Spin dynamics in the Dirac $U(1)$ spin liquid YbZn$_2$GaO$_5$"
    ],
    "c_abstract":[
      "YbZn$_2$GaO$_5$ is a promising candidate for realizing a quantum spin liquid\n(QSL) state, particularly owing to its lack of significant site disorder.\nPulsed-field magnetometry at 0.5 K shows magnetization saturating near 15 T,\nwith a corrected saturation moment of 2.1(1) $\\mu_\\mathrm{B}$ after subtracting\nthe van Vleck contribution. Our zero-field $\\mu$SR measurements down to\nmilliKelvin temperatures provide evidence for a dynamic ground state and the\nabsence of magnetic order. To probe fluctuations in the local magnetic field at\nthe muon site, we performed longitudinal field $\\mu$SR experiments. These\nresults provide evidence for spin dynamics with a field dependence that is\nconsistent with a U1A01 Dirac QSL as a plausible description of the ground\nstate."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-322",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04359",
    "b_title":[
      "LONGCODEU: Benchmarking Long-Context Language Models on Long Code\n  Understanding"
    ],
    "b_abstract":[
      "Current advanced long-context language models offer great potential for\nreal-world software engineering applications. However, progress in this\ncritical domain remains hampered by a fundamental limitation: the absence of a\nrigorous evaluation framework for long code understanding. To gap this\nobstacle, we propose a long code understanding benchmark LONGCODEU from four\naspects (8 tasks) to evaluate LCLMs' long code understanding ability required\nfor practical applications, including code unit perception, intra-code unit\nunderstanding, inter-code unit relation understanding, and long code\ndocumentation understanding. We evaluate 9 popular LCLMs on LONGCODEU (i.e., 6\ngeneral models and 3 code models). Our experimental results reveal key\nlimitations in current LCLMs' capabilities for long code understanding.\nParticularly, the performance of LCLMs drops dramatically when the long code\nlength is greater than 32K, falling far short of their claimed 128K-1M context\nwindows. In the four aspects, inter-code unit relation understanding is the\nmost challenging for LCLMs. Our study provides valuable insights for optimizing\nLCLMs and driving advancements in software engineering."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.12483",
    "c_title":[
      "Modularization is Better: Effective Code Generation with Modular\n  Prompting"
    ],
    "c_abstract":[
      "Large Language Models are transforming software development by automatically\ngenerating code. Current prompting techniques such as Chain-of-Thought (CoT)\nsuggest tasks step by step and the reasoning process follows a linear\nstructure, which hampers the understanding of complex programming problems,\nparticularly those requiring hierarchical solutions. Inspired by the principle\nof modularization in software development, in this work, we propose a novel\nprompting technique, called MoT, to enhance the code generation performance of\nLLMs. At first, MoT exploits modularization principles to decompose complex\nprogramming problems into smaller, independent reasoning steps, enabling a more\nstructured and interpretable problem-solving process. This hierarchical\nstructure improves the LLM's ability to comprehend complex programming\nproblems. Then, it structures the reasoning process using an MLR Graph\n(Multi-Level Reasoning Graph), which hierarchically organizes reasoning steps.\nThis approach enhances modular understanding and ensures better alignment\nbetween reasoning steps and the generated code, significantly improving code\ngeneration performance. Our experiments on two advanced LLMs (GPT-4o-mini and\nDeepSeek-R1), comparing MoT to six baseline prompting techniques across six\nwidely used datasets, HumanEval, HumanEval-ET, HumanEval+, MBPP, MBPP-ET, and\nMBPP+, demonstrate that MoT significantly outperforms existing baselines (e.g.,\nCoT and SCoT), achieving Pass@1 scores ranging from 58.1% to 95.1%. The\nexperimental results confirm that MoT significantly enhances the performance of\nLLM-based code generation."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-323",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11130",
    "b_title":[
      "Advanced 3D-Printed Multiphasic Scaffold with Optimal PRP Dosage for\n  Chondrogenesis of BM-MSCs in Osteochondral Tissue Engineering"
    ],
    "b_abstract":[
      "In osteochondral tissue engineering (OCTE), simultaneously regenerating\nsubchondral bone and cartilage tissue presents a significant challenge.\nMultiphasic scaffolds were created and manufactured using 3D printing to\naddress this issue. Excellent interfacial mechanical properties and\nbiocompatibility enhance the growth and chondrogenic differentiation of bone\nmarrow mesenchymal stem cells (BM-MSCs). The subchondral bone bottom layer is\nmimicked by incorporating varying concentrations of graphene oxide (GO) (0%,\n1%, and 2% w\/v) into a bioink composed of alginate (Alg) and gelatin (Gel).\nBased on evaluations of mechanical and biocompatibility properties, 1% GO is\nselected for further studies. Subsequently, the GO concentration is kept\nconstant while varying the platelet-rich plasma (PRP) dosage in the multiphasic\nscaffolds. Different PRP dosages (0%, 1%, 2%, and 3% w\/v) are integrated into\nthe Alg-Gel bioink to simulate cartilage tissues. Results indicate that\n3D-printed scaffolds containing 1% or 2% PRP exhibit favorable biomechanical\nproperties, with no significant differences observed. However, BM-MSCs exposed\nto 2% PRP demonstrate enhanced adhesion, growth, and viability. Additionally,\nreal-time PCR and Alcian blue staining confirm increased chondrogenic\nexpression and glycosaminoglycans (GAGs) synthesis. This work highlights the\npromising potential of 3D-printed multiphasic frameworks in the development of\nOCTE."
    ],
    "b_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2503.13516",
    "c_title":[
      "A tumor-immune model of chronic myeloid leukemia with optimal\n  immunotherapeutic protocols"
    ],
    "c_abstract":[
      "The interactions between tumor cells and the immune system play a crucial\nrole in cancer evolution. In this study, we explore how these interactions\ninfluence cancer progression by modeling the relationships among naive T cells,\neffector T cells, and chronic myeloid leukemia cells. We examine the existence\nof equilibria, the asymptotic stability of the positive steady state, and the\nglobal stability of the tumor-free equilibrium. Additionally, we develop a\npartial differential equation to describe the conditions under which the\nconcentration of cancer cells reaches a level that allows for effective control\nof cancer evolution. Finally, we apply our proposed model to investigate\noptimal treatment strategies that aim to minimize both the concentration of\ncancer cells at the end of treatment and the accumulation of tumor burden, as\nwell as the cost associated with treatment during the intervention period. Our\nstudy reveals an optimal therapeutic protocol using optimal control theory. We\nperform numerical simulations to illustrate our theoretical results and to\nexplore the dynamic behavior of the system and optimal therapeutic protocols.\nThe simulations indicate that the optimal treatment strategy can be more\neffective than a constant treatment approach, even when applying the same\ntreatment interval and total drug input."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-324",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08331",
    "b_title":[
      "Orbiting, colliding and merging droplets on a soap film: toward\n  gravitational analogues"
    ],
    "b_abstract":[
      "Modern telescopes provide breathtaking images of nebulae, clouds and galaxies\nshaped by gravity-driven interactions between complex bodies. While such\nstructures are prevalent on an astrophysical scale, they are rarely observed at\nthe human scale. In this letter, we report the observations of the complex\norbits, collision, and coalescence of droplets on a soap film, forming\nstructures such as bridges and spiral arms, reminiscent of their astrophysical\ncounterparts. These dynamics emerge from attractive forces caused by\ngravito-capillary-driven distortions of the supporting soap film. Long orbits\nand intricate coalescence mechanisms are enabled by the small dissipation in\nthe soap film and the fluidic nature of the droplets and supporting film,\nrespectively. The existence of stable droplets within the soap film featuring a\nuniversal radius, as well as the attractive potentials, are explained through a\ncareful comparison of experimental data with models computing the distortions\nof the supporting soap film. This work opens perspectives to"
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.09586",
    "c_title":[
      "Second-order theory for multi-hinged directional wavemakers"
    ],
    "c_abstract":[
      "The second-order directional wavemaker theory for regular and irregular waves\nis extended to multi-hinged wavemakers and combined piston--flap wavemaker\nsystems. Derived expressions enable second-order signal correction, common in\nsingle-hinged wavemakers, to be applied to multi-hinged systems. Multi-hinged\nwavemakers offer additional degrees of freedom, with different combinations of\npaddle motion producing the same progressive wave. This is here exploited to\nbetter understand wavemaker behaviour. Single-harmonic signals are computed for\ndouble-hinged wavemakers that suppress spurious waves without introducing\ndouble-harmonic motions. Surprisingly, these flap motions are almost always in\nopposite phase, with the larger draft found underneath the water surface.\n%contradicting to assumptions from earlier studies. Due to the opposing paddle\nphase, the double-hinged wavemaker draft is usually smaller than the\ncorresponding single-hinged draft. The ability of thsee systems to suppress\nspurious waves with single-harmonic motion is verified experimentally. The\nwavemaker theory further supports an arbitrary number of flap hinges, enabling\nthe approximation of a fully flexible wavemaker through piecewise-linear\nsegments. This is demonstrated with an exponential wavemaker profile that does\nnot generate any evanescent waves at linear order. Such a wavemaker is likely\nto limit wave breaking and cross-modes, but is found to produce spurious\nsecond-order waves of a magnitude comparable to a single flap. The presented\nsolution is complete, intrinsically including return flow through the\nsecond-order zero mode. This return flow is found to precisely match the Stokes\ndrift."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-325",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01402",
    "b_title":[
      "Best Transition Matrix Esitimation or Best Label Noise Robustness\n  Classifier? Two Possible Methods to Enhance the Performance of T-revision"
    ],
    "b_abstract":[
      "Label noise refers to incorrect labels in a dataset caused by human errors or\ncollection defects, which is common in real-world applications and can\nsignificantly reduce the accuracy of models. This report explores how to\nestimate noise transition matrices and construct deep learning classifiers that\nare robust against label noise. In cases where the transition matrix is known,\nwe apply forward correction and importance reweighting methods to correct the\nimpact of label noise using the transition matrix. When the transition matrix\nis unknown or inaccurate, we use the anchor point assumption and T-Revision\nseries methods to estimate or correct the noise matrix. In this study, we\nfurther improved the T-Revision method by developing T-Revision-Alpha and\nT-Revision-Softmax to enhance stability and robustness. Additionally, we\ndesigned and implemented two baseline classifiers, a Multi-Layer Perceptron\n(MLP) and ResNet-18, based on the cross-entropy loss function. We compared the\nperformance of these methods on predicting clean labels and estimating\ntransition matrices using the FashionMINIST dataset with known noise transition\nmatrices. For the CIFAR-10 dataset, where the noise transition matrix is\nunknown, we estimated the noise matrix and evaluated the ability of the methods\nto predict clean labels."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11927",
    "c_title":[
      "Continual Learning Should Move Beyond Incremental Classification"
    ],
    "c_abstract":[
      "Continual learning (CL) is the sub-field of machine learning concerned with\naccumulating knowledge in dynamic environments. So far, CL research has mainly\nfocused on incremental classification tasks, where models learn to classify new\ncategories while retaining knowledge of previously learned ones. Here, we argue\nthat maintaining such a focus limits both theoretical development and practical\napplicability of CL methods. Through a detailed analysis of concrete examples -\nincluding multi-target classification, robotics with constrained output spaces,\nlearning in continuous task domains, and higher-level concept memorization - we\ndemonstrate how current CL approaches often fail when applied beyond standard\nclassification. We identify three fundamental challenges: (C1) the nature of\ncontinuity in learning problems, (C2) the choice of appropriate spaces and\nmetrics for measuring similarity, and (C3) the role of learning objectives\nbeyond classification. For each challenge, we provide specific recommendations\nto help move the field forward, including formalizing temporal dynamics through\ndistribution processes, developing principled approaches for continuous task\nspaces, and incorporating density estimation and generative objectives. In so\ndoing, this position paper aims to broaden the scope of CL research while\nstrengthening its theoretical foundations, making it more applicable to\nreal-world problems."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-326",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07500",
    "b_title":[
      "Dynamics in an emergent quantum-like state space generated by a\n  nonlinear classical network"
    ],
    "b_abstract":[
      "This work exploits a framework whereby a graph (in the mathematical sense)\nserves to connect a classical system to a state space that we call\n`quantum-like' (QL). The QL states comprise arbitrary superpositions of states\nin a tensor product basis. The graph plays a special dual role by directing\ndesign of the classical system and defining the state space. We study a\nspecific example of a large, dynamical classical system -- a system of coupled\nphase oscillators -- that maps, via a graph, to the QL state space. We\ninvestigate how mixedness of the state diminishes or increases as the\nunderlying classical system synchronizes or de-synchronizes respectively. This\nshows the interplay between the nonlinear dynamics of the variables of the\nclassical system and the QL state space. We prove that maps from one time point\nto another in the state space are linear maps. In the limit of a strongly\nphase-locked classical network -- that is, where couplings between phase\noscillators are very large -- the state space evolves according to unitary\ndynamics, whereas in the cases of weaker synchronization, the classical\nvariables act as a hidden environment that promotes decoherence of\nsuperpositions."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12694",
    "c_title":[
      "Noisy dynamics of Gaussian entanglement: a transient bound entangled\n  phase before separability"
    ],
    "c_abstract":[
      "We discover a new class of Gaussian bound entangled states of four-mode\ncontinuous-variable systems. These states appear as a transient phase when\ncertain NPT-entangled Gaussian states are evolved under a noisy environment. A\nthermal bath comprising of harmonic oscillators is allowed to interact with one\nor modes of the system and a wide variety of initial Gaussian entangled (NPT as\nwell as PPT) states are studied. The robustness of entanglement is defined as\nthe time duration for which the entanglement of the initial state is preserved\nunder the noisy dynamics. We access the separability by utilizing standard\nsemi-definite programming techniques. While most states lose their entanglement\nafter a certain time across all bi-partitions, an exception is observed for a\nthree-parameter family of states which we call the generalized four-mode\nsqueezed vacuum (gFMSV) states, which transitions to a bound entangled state,\nand remains so for a finite window of time. This dynamical onset of bound\nentanglement in continuous-variable systems is the central observation of our\nwork. We carry out the analysis for Haar-random four-mode states (both pure and\nmixed) to scan the state space for transient bound entangled phase"
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-327",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02000",
    "b_title":[
      "At extreme strain rates, pure metals thermally harden while alloys\n  thermally soften"
    ],
    "b_abstract":[
      "When materials are deformed at extreme strain rates, greater than $10^6\n\\text{ s}^{-1}$, a counterintuitive mechanical response is seen where the\nstrength and hardness of pure metals increases with increasing temperature. The\nanti-thermal hardening is due to defects in the material becoming pinned by\nphonons in the crystal lattice. However, here, using optically driven\nmicroballistic impact testing to measure the dynamic strength and hardness, we\nshow that when the composition is systematically varied away from high purity,\nthe mechanical response of metals transitions from ballistic transport of\ndislocations back to thermally activated pinning of dislocations, even at the\nhighest strain rates. This boundary from \"hotter-is-stronger\" to\n\"hotter-is-softer\" is observed and mapped for nickel, titanium, and gold. The\nability to tune between deformation mechanisms with very different temperature\ndependencies speaks to new directions for alloy design in extreme conditions."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.14077",
    "c_title":[
      "The effect of a band gap gradient on the radiative losses in the open\n  circuit voltage of solar cells"
    ],
    "c_abstract":[
      "The radiative open circuit voltage loss in a solar cell occurs because the\nabsorptance spectrum near the band gap shows gradual increase rather than sharp\nstep function like transition. This broadening effect has been attributed to\nband gap fluctuations and or to Urbach tails. In this report, we use modelling\nbased on Planck s generalized law to distinguish between these two effects. Our\nresults demonstrate that Urbach tails have only a minimal effect on the\nabsorptance edge broadening and clarify that even an ideal direct semiconductor\nwith no band gap fluctuations shows broadening at the absorptance onset.\nFurthermore, state of the art inorganic thin film solar cells often incorporate\na band gap gradient across their thickness, which can further contribute to\nabsorptance broadening. Using Cu(In,Ga)Se2 (CIGSe) absorbers as a case study,\nwe perform a comprehensive analysis of voltage losses through absolute\nphotoluminescence and electroluminescence spectroscopy, combined with\nphotospectrometry and high-spatial-resolution cathodoluminescence measurements.\nWe find that the loss analysis based on the combination of radiative,\ngeneration and non-radiative losses is complete. Samples with a graded band gap\nprofile show more pronounced broadening of the absorptance onset and up to 16\nmV higher radiative losses compared to the samples with uniform band gap. There\nis indication, that band gap-graded samples also have larger lateral band gap\ninhomogeneity."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-328",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06544",
    "b_title":[
      "Around the Quantum Lenard-Balescu equation"
    ],
    "b_abstract":[
      "In the mean-field regime, a gas of quantum particles with Boltzmann\nstatistics can be described by the Hartree-Fock equation. This dynamics becomes\ntrivial if the initial distribution of particle is invariant by translation.\nHowever, the first correction is given on time of order $O(N)$ by the quantum\nLenard--Balescu equation. In the first part of the present article, we justify\nthis equation until time of order $O((\\log N)^{1-\\delta})$ (for any\n$\\delta\\in(0,1)$).\n  A similar phenomenon exists in the classical setting (with a similar validity\ntime obtained by Duerinckx \\cite{Duerinckx}). In a second time, we prove the\nconvergence for dimension $d\\geq 2$ of the solutions of the quantum\nLenard--Balescu equation to the solutions of its classical counterpart in the\nsemi-classical limit. This problem can be interpreted as a grazing collision\nlimit: the quantum Lenard--Balescu equation looks like a cut-off Boltzmann\nequation, when the classical one looks like the Landau equation."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.18273",
    "c_title":[
      "Bounding Radial Variation of positive harmonic Functions on Lipschitz\n  Domains"
    ],
    "c_abstract":[
      "We provide radial variational estimates for positive harmonic functions on\nLipschitz domains in higher dimensions. The intention of this paper is to\ndocument an updated and refined version of arXiv:2003.07176 which modifies the\nproof of Mozolyako and Havin for Lipschitz domains."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-329",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05733",
    "b_title":[
      "TB-Bench: Training and Testing Multi-Modal AI for Understanding\n  Spatio-Temporal Traffic Behaviors from Dashcam Images\/Videos"
    ],
    "b_abstract":[
      "The application of Multi-modal Large Language Models (MLLMs) in Autonomous\nDriving (AD) faces significant challenges due to their limited training on\ntraffic-specific data and the absence of dedicated benchmarks for\nspatiotemporal understanding. This study addresses these issues by proposing\nTB-Bench, a comprehensive benchmark designed to evaluate MLLMs on understanding\ntraffic behaviors across eight perception tasks from ego-centric views. We also\nintroduce vision-language instruction tuning datasets, TB-100k and TB-250k,\nalong with simple yet effective baselines for the tasks. Through extensive\nexperiments, we show that existing MLLMs underperform in these tasks, with even\na powerful model like GPT-4o achieving less than 35% accuracy on average. In\ncontrast, when fine-tuned with TB-100k or TB-250k, our baseline models achieve\naverage accuracy up to 85%, significantly enhancing performance on the tasks.\nAdditionally, we demonstrate performance transfer by co-training TB-100k with\nanother traffic dataset, leading to improved performance on the latter.\nOverall, this study represents a step forward by introducing a comprehensive\nbenchmark, high-quality datasets, and baselines, thus supporting the gradual\nintegration of MLLMs into the perception, prediction, and planning stages of\nAD."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14863",
    "c_title":[
      "Temporal-Consistent Video Restoration with Pre-trained Diffusion Models"
    ],
    "c_abstract":[
      "Video restoration (VR) aims to recover high-quality videos from degraded\nones. Although recent zero-shot VR methods using pre-trained diffusion models\n(DMs) show good promise, they suffer from approximation errors during reverse\ndiffusion and insufficient temporal consistency. Moreover, dealing with 3D\nvideo data, VR is inherently computationally intensive. In this paper, we\nadvocate viewing the reverse process in DMs as a function and present a novel\nMaximum a Posterior (MAP) framework that directly parameterizes video frames in\nthe seed space of DMs, eliminating approximation errors. We also introduce\nstrategies to promote bilevel temporal consistency: semantic consistency by\nleveraging clustering structures in the seed space, and pixel-level consistency\nby progressive warping with optical flow refinements. Extensive experiments on\nmultiple virtual reality tasks demonstrate superior visual quality and temporal\nconsistency achieved by our method compared to the state-of-the-art."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-330",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02745",
    "b_title":[
      "Concentration on the Boundary and Sign-Changing Solutions for a Slightly\n  Subcritical Biharmonic Problem"
    ],
    "b_abstract":[
      "We consider the fourth-order nonlinear elliptic problem: \\begin{equation*}\n\\begin{array}{ll}\n  \\Delta(a(x)\\Delta u) = a(x) \\left\\vert u \\right\\vert^{p-2-\\epsilon} u \\\n\\text{ in } \\ \\Omega,\n  \\hspace{0.6cm} u = 0 \\ \\text{ on } \\ \\partial \\Omega,\n  \\hspace{0.6cm} \\Delta u = 0 \\ \\text{ on } \\ \\partial \\Omega,\n  \\end{array}\\end{equation*} where $\\Omega$ is a smooth, bounded domain in\n$\\mathbb{R}^N$ with $N \\geq 5$. Here, $p := \\frac{2N}{N-4}$ is the Sobolev\ncritical exponent for the embedding $H^2 \\cap H_0^1(\\Omega) \\hookrightarrow\nL^p(\\Omega)$, and $a \\in C^2(\\overline{\\Omega})$ is a strictly positive\nfunction on $\\overline{\\Omega}$.\n  We establish sufficient conditions on the function $a$ and the domain\n$\\Omega$ for this problem to admit both positive and sign-changing solutions\nwith an explicit asymptotic profile. These solutions concentrate and blow up at\na point on the boundary $\\partial \\Omega$ as $\\epsilon \\to 0$. The proofs of\nthe main results rely on the Lyapunov-Schmidt finite-dimensional reduction\nmethod."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.16809",
    "c_title":[
      "Propagation of coherent states in the logarithmic Schrodinger equation"
    ],
    "c_abstract":[
      "We consider the logarithmic Schr{\\\"o}dinger equation in a semiclassical\nscaling, in the presence of a smooth, at most quadratic, external potential.\nFor initial data under the form of a single coherent state, we identify the\nnotion of criticality as far as the nonlinear coupling constant is concerned,\nin the semiclassical limit. In the critical case, we prove a general error\nestimate, and improve it in the case of initial Gaussian profiles. In this\ncritical case, when the initial datum is the sum of two Gaussian coherent\nstates with different centers in phase space, we prove a nonlinear\nsuperposition principle."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-331",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06363",
    "b_title":[
      "Limitations of Gaussian measurements in quantum imaging"
    ],
    "b_abstract":[
      "Imaging thermal sources naturally yields Gaussian states at the receiver,\nraising the question of whether Gaussian measurements can perform optimally in\nquantum imaging. In this work, we establish no-go theorems on the performance\nof Gaussian measurements when imaging thermal sources with mean photon number\nper temporal mode $\\epsilon \\rightarrow 0$ or when solving two sources with the\nseparation $L \\rightarrow 0$. Our results show that non-Gaussian measurements\ncan outperform any Gaussian measurement by a factor of $\\epsilon$ (or $L^2$) in\nterms of the estimation variance, for both interferometric and single-lens\nimaging. We also present several examples to illustrate the no-go results."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04955",
    "c_title":[
      "Experimental Realization of Criticality-Enhanced Global Quantum Sensing\n  via Non-Equilibrium Dynamics"
    ],
    "c_abstract":[
      "Quantum critical systems offer promising advancements in quantum sensing and\nmetrology, yet face limitations like critical slowing down and a restricted\ncriticality-enhanced region. Here, we introduce a critical sensing scheme that\nmitigate critical slowing down by leveraging the non-equilibrium dynamics of a\nperturbed Ising spin model, coupled with an adaptive strategy to enlarge its\nsensing interval. We validate the proposed scheme on a superconducting quantum\nprocessor and demonstrate that our scheme achieves a Heisenberg scaling with\nrespect to the encoding duration. Additionally, the adaptive strategy tunes the\nmodel to operate near its critical point with limited prior information about\nthe parameter, enabling what is known as global sensing. Our work showcases the\nmetrological applications empowered by non-equilibrium critical dynamics and\nhence opens up a pathway for devising critical quantum sensors."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-332",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08949",
    "b_title":[
      "Self-Supervised Graph Contrastive Pretraining for Device-level\n  Integrated Circuits"
    ],
    "b_abstract":[
      "Self-supervised graph representation learning has driven significant\nadvancements in domains such as social network analysis, molecular design, and\nelectronics design automation (EDA). However, prior works in EDA have mainly\nfocused on the representation of gate-level digital circuits, failing to\ncapture analog and mixed-signal circuits. To address this gap, we introduce\nDICE: Device-level Integrated Circuits Encoder, the first self-supervised\npretrained graph neural network (GNN) model for any circuit expressed at the\ndevice level. DICE is a message-passing neural network (MPNN) trained through\ngraph contrastive learning, and its pretraining process is simulation-free,\nincorporating two novel data augmentation techniques. Experimental results\ndemonstrate that DICE achieves substantial performance gains across three\ndownstream tasks, underscoring its effectiveness for both analog and digital\ncircuits."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02825",
    "c_title":[
      "Randomly Sampled Language Reasoning Problems Reveal Limits of LLMs"
    ],
    "c_abstract":[
      "Can LLMs pick up language structure from examples? Evidence in prior work\nseems to indicate yes, as pretrained models repeatedly demonstrate the ability\nto adapt to new language structures and vocabularies. However, this line of\nresearch typically considers languages that are present within common\npretraining datasets, or otherwise share notable similarities with these seen\nlanguages. In contrast, in this work we attempt to measure models' language\nunderstanding capacity while circumventing the risk of dataset recall. We\nparameterize large families of language tasks recognized by deterministic\nfinite automata (DFAs), and can thus sample novel language reasoning problems\nto fairly evaulate LLMs regardless of training data. We find that, even in the\nstrikingly simple setting of 3-state DFAs, LLMs underperform unparameterized\nngram models on both language recognition and synthesis tasks. These results\nsuggest that LLMs struggle to match the ability of basic language models in\nrecognizing and reasoning over languages that are sufficiently distinct from\nthe ones they see at training time, underscoring the distinction between\nlearning individual languages and possessing a general theory of language."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-333",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06008",
    "b_title":[
      "Enumeration of Colored Tilings on Graphs via Generating Functions"
    ],
    "b_abstract":[
      "In this paper, we study the problem of partitioning a graph into connected\nand colored components called blocks. Using bivariate generating functions and\ncombinatorial techniques, we determine the expected number of blocks when the\nvertices of a graph $G$, for $G$ in certain families of graphs, are colored\nuniformly and independently. Special emphasis is placed on graphs of the form\n$G \\times P_n$, where $P_n$ is the path graph on $n$ vertices. This case serves\nas a generalization of the problem of enumerating the number of tilings of an\n$m \\times n$ grid using colored polyominoes."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.06083",
    "c_title":[
      "Refined Brill-Noether Theory for Complete Graphs"
    ],
    "c_abstract":[
      "The divisor theory of the complete graph $K_n$ is in many ways similar to\nthat of a plane curve of degree $n$. We compute the splitting types of all\ndivisors on the complete graph $K_n$. We see that the possible splitting types\nof divisors on $K_n$ exactly match the possible splitting types of line bundles\non a smooth plane curve of degree $n$. This generalizes the earlier result of\nCori and Le Borgne computing the ranks of all divisors on $K_n$, and the\nearlier work of Cools and Panizzut analyzing the possible ranks of divisors of\nfixed degree on $K_n$."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-334",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01351",
    "b_title":[
      "A central limit theorem for the giant in a stochastic block model"
    ],
    "b_abstract":[
      "We provide a simple proof for of the central limit theorem for the number of\nvertices in the giant for super-critical stochastic block model using the\nbreadth-first walk of Konarovskyi, Limic and the author (2024). Our approach\nfollows the recent work of Corujo, Limic and Lemaire (2024) and reduces to the\nclassic central limit theorem for the Erd\\H{o}s-R\\'{e}nyi model obtained by\nStepanov (1970)."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02930",
    "c_title":[
      "Homogenization of the stochastic non-homogeneous incompressible\n  Navier-Stokes equations with multiplicative noise"
    ],
    "c_abstract":[
      "In this contributions we are interested in the homogenization property of\nstochastic non-homogeneous incompressible Navier-Stokes equations with fast\noscillation in a smooth bounded domain of $\\mathbb{R}^d$, $d=2,3$, and driven\nby multiplicative cylindrical Wiener noise. Using two-scale convergence,\nstochastic compactness and the martingale representative theory, we show the\nsolutions of original equations converge to a solution of stochastic\nnon-homogeneous incompressible version with constant coefficients. The paper\nalso includes a corrector result which improves the two-scale convergence in\nthe weak sense to strong one in regularity space. The main obstacles arise from\nthe random effect and the lower regularity caused by density function."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-335",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14680",
    "b_title":[
      "Nonlinear approximation of harmonic functions from shifts of the\n  Newtonian kernel in BMO"
    ],
    "b_abstract":[
      "We study nonlinear n-term approximation of harmonic functions on the unit\nball in $R^d$ from linear combinations of shifts of the Newtonian kernel\n(fundamental solution of the Laplace equation) in BMO. A sharp Jackson estimate\nis established that naturally involves certain Besov spaces. The method for\nobtaining this result is based on the construction of highly localized frames\nfor Besov spaces and VMO on the sphere whose elements are linear combinations\nof a fixed number of shifts of the Newtonian kernel."
    ],
    "b_categories":[
      [
        "math.CA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11498",
    "c_title":[
      "Direct and inverse problems for a third-order self-adjoint differential\n  operator with non-local potential functions"
    ],
    "c_abstract":[
      "The direct and inverse problems for a third-order self-adjoint differential\noperator with non-local potential functions are considered. Firstly, the\nmultiplicity for eigenvalues of the operator is analyzed, and it is proved that\nthe differential operator has simple eigenvalues, except for finitely many\neigenvalues of multiplicity two or three. Then the expressions of\neigenfunctions and resolvent are obtained. Finally, the inverse problem for\nrecovering non-local potential functions is solved."
    ],
    "c_categories":[
      [
        "math.CA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-336",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17186",
    "b_title":[
      "Searches for direct slepton production in the compressed-mass corridor\n  in $\\sqrt{s}=13$ TeV $pp$ collisions with the ATLAS detector"
    ],
    "b_abstract":[
      "This paper presents searches for the direct pair production of charged\nlight-flavour sleptons, each decaying into a stable neutralino and an\nassociated Standard Model lepton. The analyses focus on the challenging\n\"corridor\" region, where the mass difference, $\\Delta m$, between the slepton\n($\\tilde{e}$ or $\\tilde{\\mu}$) and the lightest neutralino\n($\\tilde{\\chi}^{0}_{1}$) is less or similar to the mass of the $W$ boson,\n$m(W)$, with the aim to close a persistent gap in sensitivity to models with\n$\\Delta m \\lesssim m(W)$. Events are required to contain a high-energy jet,\nsignificant missing transverse momentum, and two same-flavour opposite-sign\nleptons ($e$ or $\\mu$). The analysis uses $pp$ collision data at $\\sqrt{s} =\n13$ TeV recorded by the ATLAS detector, corresponding to an integrated\nluminosity of 140 fb$^{-1}$. Several kinematic selections are applied,\nincluding a set of boosted decision trees. These are each optimised for\ndifferent $\\Delta m$ to provide expected sensitivity for the first time across\nthe full $\\Delta m$ corridor. The results are generally consistent with the\nStandard Model, with the most significant deviations observed with a local\nsignificance of 2.0 $\\sigma$ in the selectron search, and 2.4 $\\sigma$ in the\nsmuon search. While these deviations weaken the observed exclusion reach in\nsome parts of the signal parameter space, the previously present sensitivity\ngap to this corridor is largely reduced. Constraints at the 95% confidence\nlevel are set on simplified models of selectron and smuon pair production,\nwhere selectrons (smuons) with masses up to 300 (350) GeV can be excluded for\n$\\Delta m$ between 2 GeV and 100 GeV."
    ],
    "b_categories":[
      [
        "hep-ex"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11383",
    "c_title":[
      "Study of $\\phi\\to K\\bar{K}$ and $K_{S}^{0}-K_{L}^{0}$ asymmetry in the\n  amplitude analysis of $D_{s}^{+} \\to K_{S}^{0}K_{L}^{0}\\pi^{+}$ decay"
    ],
    "c_abstract":[
      "Using $e^+e^-$ annihilation data corresponding to a total integrated\nluminosity of 7.33 $\\rm fb^{-1}$ collected at center-of-mass energies between\n4.128 and 4.226~GeV with the BESIII detector, we provide the first amplitude\nanalysis and absolute branching fraction measurement of the hadronic decay\n$D_{s}^{+} \\to K_{S}^{0}K_{L}^{0}\\pi^{+}$. The branching fraction of $D_{s}^{+}\n\\to K_{S}^{0}K_{L}^{0}\\pi^{+}$ is determined to be $(1.86\\pm0.06_{\\rm\nstat}\\pm0.03_{\\rm syst})\\%$.\n  Combining the $\\mathcal{B}(D_{s}^{+} \\to \\phi(\\to K_{S}^0K_{L}^0) \\pi^+)$\nobtained in this work and the world average of $\\mathcal{B}(D_{s}^{+} \\to\n\\phi(\\to K^+K^-) \\pi^+)$, we measure the relative branching fraction\n$\\mathcal{B}(\\phi \\to K_S^0K_L^0)\/\\mathcal{B}(\\phi \\to K^+K^-)$=($0.597 \\pm\n0.023_{\\rm stat} \\pm 0.018_{\\rm syst} \\pm 0.016_{\\rm PDG}$), which deviates\nfrom the PDG value by more than 3$\\sigma$. Furthermore, the asymmetry of the\nbranching fractions of $D^+_s\\to K_{S}^0K^{*}(892)^{+}$ and $D^+_s\\to\nK_{L}^0K^{*}(892)^{+}$, $\\frac{\\mathcal{B}(D_{s}^{+} \\to\nK_{S}^0K^{*}(892)^{+})-\\mathcal{B}(D_{s}^{+} \\to\nK_{L}^0K^{*}(892)^{+})}{\\mathcal{B}(D_{s}^{+} \\to\nK_{S}^0K^{*}(892)^{+})+\\mathcal{B}(D_{s}^{+} \\to K_{L}^0K^{*}(892)^{+})}$, is\ndetermined to be $(-13.4\\pm5.0_{\\rm stat}\\pm3.4_{\\rm syst})\\%$."
    ],
    "c_categories":[
      [
        "hep-ex"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-337",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12211",
    "b_title":[
      "Bilateral Bailey pairs and Rogers-Ramanujan type identities"
    ],
    "b_abstract":[
      "Rogers-Ramanujan type identities occur in various branches of mathematics and\nphysics. As a classic and powerful tool to deal with Rogers-Ramanujan type\nidentities, the theory of Bailey's lemma has been extensively studied and\ngeneralized. In this paper, we found a bilateral Bailey pair that naturally\narises from the q-binomial theorem. By applying the bilateral versions of\nBailey lemmas, Bailey chains and Bailey lattices, we derive a number of\nRogers-Ramanujan type identities, which unify many known identities as special\ncases. Further combined with the bilateral Bailey chains due to Berkovich,\nMcCoy and Schilling and the bilateral Bailey lattices due to Jouhet et al., we\nalso obtain identities on Appell-Lerch series and identities of Andrews-Gordon\ntype. Moreover, by applying Andrews and Warnaar's bilateral Bailey lemmas, we\nderive identities on Hecke-type series."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.20628",
    "c_title":[
      "Locally connected graphs: metric properties"
    ],
    "c_abstract":[
      "In this work we show that any connected locally connected graph defines a\nmetric space having at least as many lines as vertices with only three\nexception: the complete multipartite graphs $K_{1,2,2}$, $K_{2,2,2}$ and\n$K_{2,2,2,2}$. This proves that this class fulfills a conjecture, proposed by\nChen and Chv\\'atal, saying that any metric space on n points has at least n\nlines or a line containing all the points."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-338",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12867",
    "b_title":[
      "Assortative Marriage and Geographic Sorting"
    ],
    "b_abstract":[
      "Between 1980 and 2000, the U.S. experienced a significant rise in geographic\nsorting and educational homogamy, with college graduates increasingly\nconcentrating in high-skill cities and marrying similarly educated spouses. We\ndevelop and estimate a spatial equilibrium model with local labor, housing, and\nmarriage markets, incorporating a marriage matching framework with transferable\nutility. Using the model, we estimate trends in assortative preferences,\nquantify the interplay between marital and geographic sorting, and assess their\ncombined impact on household inequality. Welfare analyses show that after\naccounting for marriage, the college well-being gap grew substantially more\nthan the college wage gap."
    ],
    "b_categories":[
      [
        "econ.EM"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2501.04607",
    "c_title":[
      "Monthly GDP Growth Estimates for the U.S. States"
    ],
    "c_abstract":[
      "This paper develops a mixed frequency vector autoregressive (MF-VAR) model to\nproduce nowcasts and historical estimates of monthly real state-level GDP for\nthe 50 U.S. states, plus Washington DC, from 1964 through the present day. The\nMF-VAR model incorporates state and U.S. data at the monthly, quarterly, and\nannual frequencies. Temporal and cross-sectional constraints are imposed to\nensure that the monthly state-level estimates are consistent with official\nestimates of quarterly GDP at the U.S. and state-levels. We illustrate the\nutility of the historical estimates in better understanding state business\ncycles and cross-state dependencies. We show how the model produces accurate\nnowcasts of state GDP three months ahead of the BEA's quarterly estimates,\nafter conditioning on the latest estimates of U.S. GDP."
    ],
    "c_categories":[
      [
        "econ.EM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-339",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09888",
    "b_title":[
      "Understanding the Effectiveness of LLMs in Automated Self-Admitted\n  Technical Debt Repayment"
    ],
    "b_abstract":[
      "Self-Admitted Technical Debt (SATD), cases where developers intentionally\nacknowledge suboptimal solutions in code through comments, poses a significant\nchallenge to software maintainability. Left unresolved, SATD can degrade code\nquality and increase maintenance costs. While Large Language Models (LLMs) have\nshown promise in tasks like code generation and program repair, their potential\nin automated SATD repayment remains underexplored.\n  In this paper, we identify three key challenges in training and evaluating\nLLMs for SATD repayment: (1) dataset representativeness and scalability, (2)\nremoval of irrelevant SATD repayments, and (3) limitations of existing\nevaluation metrics. To address the first two dataset-related challenges, we\nadopt a language-independent SATD tracing tool and design a 10-step filtering\npipeline to extract SATD repayments from repositories, resulting two\nlarge-scale datasets: 58,722 items for Python and 97,347 items for Java. To\nimprove evaluation, we introduce two diff-based metrics, BLEU-diff and\nCrystalBLEU-diff, which measure code changes rather than whole code.\nAdditionally, we propose another new metric, LEMOD, which is both interpretable\nand informative. Using our new benchmarks and evaluation metrics, we evaluate\ntwo types of automated SATD repayment methods: fine-tuning smaller models, and\nprompt engineering with five large-scale models. Our results reveal that\nfine-tuned small models achieve comparable Exact Match (EM) scores to\nprompt-based approaches but underperform on BLEU-based metrics and LEMOD.\nNotably, Gemma-2-9B leads in EM, addressing 10.1% of Python and 8.1% of Java\nSATDs, while Llama-3.1-70B-Instruct and GPT-4o-mini excel on BLEU-diff,\nCrystalBLEU-diff, and LEMOD metrics. Our work contributes a robust benchmark,\nimproved evaluation metrics, and a comprehensive evaluation of LLMs, advancing\nresearch on automated SATD repayment."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09466",
    "c_title":[
      "Validity in Design Science"
    ],
    "c_abstract":[
      "Researchers must ensure that the claims about the knowledge produced by their\nwork are valid. However, validity is neither well-understood nor consistently\nestablished in design science, which involves the development and evaluation of\nartifacts (models, methods, instantiations, and theories) to solve problems. As\na result, it is challenging to demonstrate and communicate the validity of\nknowledge claims about artifacts. This paper defines validity in design science\nand derives the Design Science Validity Framework and a process model for\napplying it. The framework comprises three high-level claim and validity\ntypes-criterion, causal, and context-as well as validity subtypes. The\nframework guides researchers in integrating validity considerations into\nprojects employing design science and contributes to the growing body of\nresearch on design science methodology. It also provides a systematic way to\narticulate and validate the knowledge claims of design science projects. We\napply the framework to examples from existing research and then use it to\ndemonstrate the validity of knowledge claims about the framework itself."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-340",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07917",
    "b_title":[
      "Hyperoctant Search Clustering: A Method for Clustering Data in\n  High-Dimensional Hyperspheres"
    ],
    "b_abstract":[
      "Clustering of high-dimensional data sets is a growing need in artificial\nintelligence, machine learning and pattern recognition. In this paper, we\npropose a new clustering method based on a combinatorial-topological approach\napplied to regions of space defined by signs of coordinates (hyperoctants). In\nhigh-dimensional spaces, this approach often reduces the size of the dataset\nwhile preserving sufficient topological features. According to a density\ncriterion, the method builds clusters of data points based on the partitioning\nof a graph, whose vertices represent hyperoctants, and whose edges connect\nneighboring hyperoctants under the Levenshtein distance. We call this method\nHyperOctant Search Clustering. We prove some mathematical properties of the\nmethod. In order to as assess its performance, we choose the application of\ntopic detection, which is an important task in text mining. Our results suggest\nthat our method is more stable under variations of the main hyperparameter, and\nremarkably, it is not only a clustering method, but also a tool to explore the\ndataset from a topological perspective, as it directly provides information\nabout the number of hyperoctants where there are data points. We also discuss\nthe possible connections between our clustering method and other research\nfields."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04054",
    "c_title":[
      "Precision Agriculture Revolution: Integrating Digital Twins and Advanced\n  Crop Recommendation for Optimal Yield"
    ],
    "c_abstract":[
      "With the help of a digital twin structure, Agriculture 4.0 technologies like\nweather APIs (Application programming interface), GPS (Global Positioning\nSystem) modules, and NPK (Nitrogen, Phosphorus and Potassium) soil sensors and\nmachine learning recommendation models, we seek to revolutionize agricultural\nproduction through this concept. In addition to providing precise crop growth\nforecasts, the combination of real-time data on soil composition,\nmeteorological dynamics, and geographic coordinates aims to support crop\nrecommendation models and simulate predictive scenarios for improved water and\npesticide management."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-341",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11532",
    "b_title":[
      "Control-CLIP: Decoupling Category and Style Guidance in CLIP for\n  Specific-Domain Generation"
    ],
    "b_abstract":[
      "Text-to-image diffusion models have shown remarkable capabilities of\ngenerating high-quality images closely aligned with textual inputs. However,\nthe effectiveness of text guidance heavily relies on the CLIP text encoder,\nwhich is trained to pay more attention to general content but struggles to\ncapture semantics in specific domains like styles. As a result, generation\nmodels tend to fail on prompts like \"a photo of a cat in Pokemon style\" in\nterms of simply producing images depicting \"a photo of a cat\". To fill this\ngap, we propose Control-CLIP, a novel decoupled CLIP fine-tuning framework that\nenables the CLIP model to learn the meaning of category and style in a\ncomplement manner. With specially designed fine-tuning tasks on minimal data\nand a modified cross-attention mechanism, Control-CLIP can precisely guide the\ndiffusion model to a specific domain. Moreover, the parameters of the diffusion\nmodel remain unchanged at all, preserving the original generation performance\nand diversity. Experiments across multiple domains confirm the effectiveness of\nour approach, particularly highlighting its robust plug-and-play capability in\ngenerating content with various specific styles."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19515",
    "c_title":[
      "Evaluating the Suitability of Different Intraoral Scan Resolutions for\n  Deep Learning-Based Tooth Segmentation"
    ],
    "c_abstract":[
      "Intraoral scans are widely used in digital dentistry for tasks such as dental\nrestoration, treatment planning, and orthodontic procedures. These scans\ncontain detailed topological information, but manual annotation of these scans\nremains a time-consuming task. Deep learning-based methods have been developed\nto automate tasks such as tooth segmentation. A typical intraoral scan contains\nover 200,000 mesh cells, making direct processing computationally expensive.\nModels are often trained on downsampled versions, typically with 10,000 or\n16,000 cells. Previous studies suggest that downsampling may degrade\nsegmentation accuracy, but the extent of this degradation remains unclear.\nUnderstanding the extent of degradation is crucial for deploying ML models on\nedge devices. This study evaluates the extent of performance degradation with\ndecreasing resolution. We train a deep learning model (PointMLP) on intraoral\nscans decimated to 16K, 10K, 8K, 6K, 4K, and 2K mesh cells. Models trained at\nlower resolutions are tested on high-resolution scans to assess performance.\nOur goal is to identify a resolution that balances computational efficiency and\nsegmentation accuracy."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-342",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15961",
    "b_title":[
      "IA-TIGRIS: An Incremental and Adaptive Sampling-Based Planner for Online\n  Informative Path Planning"
    ],
    "b_abstract":[
      "Planning paths that maximize information gain for robotic platforms has\nwide-ranging applications and significant potential impact. To effectively\nadapt to real-time data collection, informative path planning must be computed\nonline and be responsive to new observations. In this work, we present\nIA-TIGRIS, an incremental and adaptive sampling-based informative path planner\nthat can be run efficiently with onboard computation. Our approach leverages\npast planning efforts through incremental refinement while continuously\nadapting to updated world beliefs. We additionally present detailed\nimplementation and optimization insights to facilitate real-world deployment,\nalong with an array of reward functions tailored to specific missions and\nbehaviors. Extensive simulation results demonstrate IA-TIGRIS generates\nhigher-quality paths compared to baseline methods. We validate our planner on\ntwo distinct hardware platforms: a hexarotor UAV and a fixed-wing UAV, each\nhaving unique motion models and configuration spaces. Our results show up to a\n41% improvement in information gain compared to baseline methods, suggesting\nsignificant potential for deployment in real-world applications."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07360",
    "c_title":[
      "AffordDexGrasp: Open-set Language-guided Dexterous Grasp with\n  Generalizable-Instructive Affordance"
    ],
    "c_abstract":[
      "Language-guided robot dexterous generation enables robots to grasp and\nmanipulate objects based on human commands. However, previous data-driven\nmethods are hard to understand intention and execute grasping with unseen\ncategories in the open set. In this work, we explore a new task, Open-set\nLanguage-guided Dexterous Grasp, and find that the main challenge is the huge\ngap between high-level human language semantics and low-level robot actions. To\nsolve this problem, we propose an Affordance Dexterous Grasp (AffordDexGrasp)\nframework, with the insight of bridging the gap with a new\ngeneralizable-instructive affordance representation. This affordance can\ngeneralize to unseen categories by leveraging the object's local structure and\ncategory-agnostic semantic attributes, thereby effectively guiding dexterous\ngrasp generation. Built upon the affordance, our framework introduces\nAffordacne Flow Matching (AFM) for affordance generation with language as\ninput, and Grasp Flow Matching (GFM) for generating dexterous grasp with\naffordance as input. To evaluate our framework, we build an open-set table-top\nlanguage-guided dexterous grasp dataset. Extensive experiments in the\nsimulation and real worlds show that our framework surpasses all previous\nmethods in open-set generalization."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-343",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06197",
    "b_title":[
      "Timing Matters: How Using LLMs at Different Timings Influences Writers'\n  Perceptions and Ideation Outcomes in AI-Assisted Ideation"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) have been widely used to support ideation in the\nwriting process. However, whether generating ideas with the help of LLMs leads\nto idea fixation or idea expansion is unclear. This study examines how\ndifferent timings of LLM usage - either at the beginning or after independent\nideation - affect people's perceptions and ideation outcomes in a writing task.\nIn a controlled experiment with 60 participants, we found that using LLMs from\nthe beginning reduced the number of original ideas and lowered creative\nself-efficacy and self-credit, mediated by changes in autonomy and ownership.\nWe discuss the challenges and opportunities associated with using LLMs to\nassist in idea generation. We propose delaying the use of LLMs to support\nideation while considering users' self-efficacy, autonomy, and ownership of the\nideation outcomes."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06659",
    "c_title":[
      "PANDA: Parkinson's Assistance and Notification Driving Aid"
    ],
    "c_abstract":[
      "Parkinson's Disease (PD) significantly impacts driving abilities, often\nleading to early driving cessation or accidents due to reduced motor control\nand increasing reaction times. To diminish the impact of these symptoms, we\ndeveloped PANDA (Parkinson's Assistance and Notification Driving Aid), a\nmulti-modality real-time alert system designed to monitor driving patterns\ncontinuously and provide immediate alerts for irregular driving behaviors,\nenhancing driver safety of individuals with PD. The system was developed\nthrough a participatory design process with 9 people with PD and 13 non-PD\nindividuals using a driving simulator, which allowed us to identify critical\ndesign characteristics and collect detailed data on driving behavior. A user\nstudy involving individuals with PD evaluated the effectiveness of PANDA,\nexploring optimal strategies for delivering alerts and ensuring they are timely\nand helpful. Our findings demonstrate that PANDA has the potential to enhance\nthe driving safety of individuals with PD, offering a valuable tool for\nmaintaining independence and confidence behind the wheel."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-344",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07459",
    "b_title":[
      "SynthSoM: A synthetic intelligent multi-modal sensing-communication\n  dataset for Synesthesia of Machines (SoM)"
    ],
    "b_abstract":[
      "Given the importance of datasets for sensing-communication integration\nresearch, a novel simulation platform for constructing communication and\nmulti-modal sensory dataset is developed. The developed platform integrates\nthree high-precision software, i.e., AirSim, WaveFarer, and Wireless InSite,\nand further achieves in-depth integration and precise alignment of them. Based\non the developed platform, a new synthetic intelligent multi-modal\nsensing-communication dataset for Synesthesia of Machines (SoM), named\nSynthSoM, is proposed. The SynthSoM dataset contains various air-ground\nmulti-link cooperative scenarios with comprehensive conditions, including\nmultiple weather conditions, times of the day, intelligent agent densities,\nfrequency bands, and antenna types. The SynthSoM dataset encompasses multiple\ndata modalities, including radio-frequency (RF) channel large-scale and\nsmall-scale fading data, RF millimeter wave (mmWave) radar sensory data, and\nnon-RF sensory data, e.g., RGB images, depth maps, and light detection and\nranging (LiDAR) point clouds. The quality of SynthSoM dataset is validated via\nstatistics-based qualitative inspection and evaluation metrics through machine\nlearning (ML) via real-world measurements. The SynthSoM dataset is open-sourced\nand provides consistent data for cross-comparing SoM-related algorithms."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00486",
    "c_title":[
      "Conformal Lyapunov Optimization: Optimal Resource Allocation under\n  Deterministic Reliability Constraints"
    ],
    "c_abstract":[
      "This paper introduces conformal Lyapunov optimization (CLO), a novel resource\nallocation framework for networked systems that optimizes average long-term\nobjectives, while satisfying deterministic long-term reliability constraints.\nUnlike traditional Lyapunov optimization (LO), which addresses resource\nallocation tasks under average long-term constraints, CLO provides formal\nworst-case deterministic reliability guarantees. This is achieved by\nintegrating the standard LO optimization framework with online conformal risk\ncontrol (O-CRC), an adaptive update mechanism controlling long-term risks. The\neffectiveness of CLO is verified via experiments for hierarchal edge inference\ntargeting image segmentation tasks in a networked computing architecture.\nSpecifically, simulation results confirm that CLO can control reliability\nconstraints, measured via the false negative rate of all the segmentation\ndecisions made in the network, while at the same time minimizing the weighted\nsum of energy consumption and imprecision, with the latter accounting for the\nrate of false positives."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-345",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10115",
    "b_title":[
      "Reconsidering Feature Structure Information and Latent Space Alignment\n  in Partial Multi-label Feature Selection"
    ],
    "b_abstract":[
      "The purpose of partial multi-label feature selection is to select the most\nrepresentative feature subset, where the data comes from partial multi-label\ndatasets that have label ambiguity issues. For label disambiguation, previous\nmethods mainly focus on utilizing the information inside the labels and the\nrelationship between the labels and features. However, the information existing\nin the feature space is rarely considered, especially in partial multi-label\nscenarios where the noises is considered to be concentrated in the label space\nwhile the feature information is correct. This paper proposes a method based on\nlatent space alignment, which uses the information mined in feature space to\ndisambiguate in latent space through the structural consistency between labels\nand features. In addition, previous methods overestimate the consistency of\nfeatures and labels in the latent space after convergence. We comprehensively\nconsider the similarity of latent space projections to feature space and label\nspace, and propose new feature selection term. This method also significantly\nimproves the positive label identification ability of the selected features.\nComprehensive experiments demonstrate the superiority of the proposed method."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02125",
    "c_title":[
      "AVG-DICE: Stationary Distribution Correction by Regression"
    ],
    "c_abstract":[
      "Off-policy policy evaluation (OPE), an essential component of reinforcement\nlearning, has long suffered from stationary state distribution mismatch,\nundermining both stability and accuracy of OPE estimates. While existing\nmethods correct distribution shifts by estimating density ratios, they often\nrely on expensive optimization or backward Bellman-based updates and struggle\nto outperform simpler baselines. We introduce AVG-DICE, a computationally\nsimple Monte Carlo estimator for the density ratio that averages discounted\nimportance sampling ratios, providing an unbiased and consistent correction.\nAVG-DICE extends naturally to nonlinear function approximation using\nregression, which we roughly tune and test on OPE tasks based on Mujoco Gym\nenvironments and compare with state-of-the-art density-ratio estimators using\ntheir reported hyperparameters. In our experiments, AVG-DICE is at least as\naccurate as state-of-the-art estimators and sometimes offers\norders-of-magnitude improvements. However, a sensitivity analysis shows that\nbest-performing hyperparameters may vary substantially across different\ndiscount factors, so a re-tuning is suggested."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-346",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02157",
    "b_title":[
      "Personalized Graph-Based Retrieval for Large Language Models"
    ],
    "b_abstract":[
      "As large language models (LLMs) evolve, their ability to deliver personalized\nand context-aware responses offers transformative potential for improving user\nexperiences. Existing personalization approaches, however, often rely solely on\nuser history to augment the prompt, limiting their effectiveness in generating\ntailored outputs, especially in cold-start scenarios with sparse data. To\naddress these limitations, we propose Personalized Graph-based\nRetrieval-Augmented Generation (PGraphRAG), a framework that leverages\nuser-centric knowledge graphs to enrich personalization. By directly\nintegrating structured user knowledge into the retrieval process and augmenting\nprompts with user-relevant context, PGraphRAG enhances contextual understanding\nand output quality. We also introduce the Personalized Graph-based Benchmark\nfor Text Generation, designed to evaluate personalized text generation tasks in\nreal-world settings where user history is sparse or unavailable. Experimental\nresults show that PGraphRAG significantly outperforms state-of-the-art\npersonalization methods across diverse tasks, demonstrating the unique\nadvantages of graph-based retrieval for personalization."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.20082",
    "c_title":[
      "LongRoPE2: Near-Lossless LLM Context Window Scaling"
    ],
    "c_abstract":[
      "LongRoPE2 is a novel approach that extends the effective context window of\npre-trained large language models (LLMs) to the target length, while preserving\nthe performance on the original shorter context window. This is achieved by\nthree contributions: (1) a hypothesis that insufficient training in higher RoPE\ndimensions contributes to the persistent out-of-distribution (OOD) issues\nobserved in existing methods; (2) an effective RoPE rescaling algorithm that\nadopts evolutionary search guided by \"needle-driven\" perplexity to address the\ninsufficient training problem; (3) a mixed context window training approach\nthat fine-tunes model weights to adopt rescaled RoPE for long-context sequences\nwhile preserving the short-context performance with the original RoPE.\nExtensive experiments on LLaMA3-8B and Phi3-mini-3.8B across various benchmarks\nvalidate the hypothesis and demonstrate the effectiveness of LongRoPE2.\nRemarkably, LongRoPE2 extends LLaMA3-8B to achieve a 128K effective context\nlength while retaining over 98.5% of short-context performance, using only 10B\ntokens -- 80x fewer than Meta's approach, which fails to reach the target\neffective context length. Code will be available at\nhttps:\/\/github.com\/microsoft\/LongRoPE."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-347",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17689",
    "b_title":[
      "Possible Existence of Ghost Stars in the context of Electromagnetic\n  Field"
    ],
    "b_abstract":[
      "In this paper, we discuss the existence of ghost star models in the\nEinstein-Maxwell framework. In order to explore these objects, we put forward\nthe idea of Zeldovich and Novikov by keeping in mind that the energy density of\nsuch models lie in the negative range in some regions of the spacetime\ngeometry. We proceed by taking into account a static sphere and develop the\nfield equations for a charged anisotropic fluid configuration. The two\ngenerating functions are then considered and we rewrite the field equations in\nterms of the mass and these physical quantities. Afterwards, we formulate two\ndifferent models using the conformally flatness condition along with the\nconsidered generating functions. Further, we adopt the vanishing complexity\nconstraint as well as null active gravitational mass to find two more\nsolutions. The energy density for all developed models is also graphically\nshown. We conclude that the ghost stars exist in the presence of charge as the\nenergy density for all the resulting solutions lie in the negative region for a\nparticular range of the radial coordinate."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.13267",
    "c_title":[
      "Rotating black holes in a class of scalar-Gauss-Bonnet gravity"
    ],
    "c_abstract":[
      "In this study, we investigate rotating black hole solutions within a scalar\nGauss Bonnet gravity framework that incorporates a quadratic Gauss Bonnet term.\nBy employing a quadratic exponential coupling function between the scalar field\nand the Gauss Bonnet invariant, we derive both the standard General Relativity\nsolutions and novel scalarized black hole configurations. Utilizing a pseudo\nspectral method to solve the coupled field equations, we examine how black hole\nspin and coupling constants influence the existence and properties of these\nsolutions. Our findings reveal that both the rotation of the black hole and the\nquadratic coupling term effectively constrain the parameter space available for\nscalarization. Moreover, we demonstrate that, over a wide range of parameters,\nscalarized black holes exhibit higher entropy than Kerr black holes of\nequivalent mass and spin, indicating that they are thermodynamically favored.\nThese results significantly expand the phase space of black holes in modified\ngravity theories."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-348",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07235",
    "b_title":[
      "The Sand Atlas"
    ],
    "b_abstract":[
      "The Sand Atlas is a publicly accessible repository dedicated to the\ncollection, processing, and sharing of high-resolution 3D models of sand-sized\nparticles. This dataset offers valuable insights into the morphology of a wide\nvariety of natural and synthetic sand-sized particles from different regions,\nwith varying mineralogy and history. The primary goal of The Sand Atlas is to\nsupport researchers, educators, and industry professionals by providing\ndetailed, easily accessible and uniformly produced surface meshes and level-set\ndata. The underlying code that converts volumetric data to meshes is also\navailable via the sand-atlas python package. This platform encourages community\nparticipation, inviting contributors to share their own data and enrich the\ncollective understanding of granular materials."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.09603",
    "c_title":[
      "Effects of oblique collimated irradiation on the onset of\n  phototaxis-driven bioconvection in an isotropic porous medium"
    ],
    "c_abstract":[
      "In this study, we investigate the effects of oblique collimated irradiation\non the onset of phototaxis-driven bioconvection in an isotropic porous medium.\nA linear stability analysis is conducted to assess the system's stability under\nfixed parameter values. The resulting eigenvalue problem is numerically solved\nusing a fourth-order accurate finite difference scheme combined with\nNewton-Raphson-Kantorovich iterations. The results indicate that the system\nexhibits increased instability as the angle of incidence rises for a given\nDarcy number. Additionally, the critical Rayleigh number is found to be higher\nwhen a rigid top wall is considered compared to a stress-free top wall,\nsuggesting that the suspension attains greater stability in the presence of a\nrigid top boundary."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-349",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08690",
    "b_title":[
      "F-Inverse Monoids as Weakly Schreier Extensions"
    ],
    "b_abstract":[
      "It is known that an inverse monoid $M$ is E-unitary if and only if the\nfollowing diagram is an extension: $E(M) \\to M \\to M\/\\sigma$, where $E(M)$ is\nthe semilattice of idempotents and $M\/\\sigma$ is the minimal group quotient.\nF-inverse monoids are another fundamental class of inverse semigroup and all\nF-inverse monoids are E-unitary. Thus given that F-inverse monoids have an\nassociated extension it is natural to ask if these extensions satisfy any\nspecial properties. Indeed we show that $M$ is F-inverse if and only if the\naforementioned extension is weakly Schreier. This latter result allows us to\nmake use of relaxed factor systems to provide a new characterization of\nF-inverse monoids. We end by restricting to the Clifford case and find a new\ncharacterization of these with much in common with Artin gluings of frames."
    ],
    "b_categories":[
      [
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.05619",
    "c_title":[
      "On the subalgebra lattice of solvable evolution algebras"
    ],
    "c_abstract":[
      "The main objective of this paper is to study the relationship between a\nsolvable evolution algebra and its subalgebra lattice, emphasizing two of its\nmain properties: distributivity and modularity. First, we will focus on the\nnilpotent case, where distributivity is characterised, and a necessary\ncondition for modularity is deduced. Subsequently, we comment on some results\nfor solvable non-nilpotent evolution algebras, finding that the ones with\nmaximum index of solvability have the best properties. Finally, we characterise\nmodularity in this particular case by introducing supersolvable evolution\nalgebras and computing the terms of the derived series."
    ],
    "c_categories":[
      [
        "math.RA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-350",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09882",
    "b_title":[
      "Large Spin Nernst Effect in Ni70Cu30 Alloy"
    ],
    "b_abstract":[
      "The interplay among heat, spin, and charge is the central focus in spin\ncaloritronic research. While the longitudinal heat-to-spin conversion via the\nspin Seebeck effect has been intensively studied, the transverse heat-to-spin\nconversion via the spin Nernst effect (SNE) has not been equally explored. One\nmajor challenge is the minuscule signals generated by the SNE, which are often\nmixed with the background noises. In this work, we overcome this difficulty by\nstudying the thin films of Ni70Cu30 alloy with not only a sizable spin Hall\nangle but also a large Seebeck coefficient. We observe in the Ni70Cu30 alloy a\nlarge spin Nernst effect with an estimated spin Nernst angle ranging from -28%\nto -72%. In comparison, the spin Nernst angle for Pt is -8.2%. Our ab initio\ncalculation reveals that the large spin Nernst conductivity in Ni70Cu30 is\ncaused by the Fermi energy shift to the steepest slope of the spin Hall\nconductivity curve due to electron doping from 30% Cu. Our study provides\ncritical directions in searching for materials with a large spin Nernst effect."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.15334",
    "c_title":[
      "Resolving Contradictory Estimates of Band Gaps of Bulk PdSe$_2$: A\n  Wannier-Localized Optimally-Tuned Screened Range-Separated Hybrid Density\n  Functional Theory Study"
    ],
    "c_abstract":[
      "Palladium diselenide (PdSe$_2$) -- a layered van der Waals material -- is\nattracting significant attention for optoelectronics due to the wide tunability\nof its band gap from the infrared through the visible range as a function of\nthe number of layers. However, there continues to be disagreement over the\nprecise nature and value of the optical band gap of bulk PdSe$_2$, owing to the\nrather small value of this gap that complicates experimental measurements and\ntheir interpretation. Here, we design and employ a Wannier-localized\noptimally-tuned screened range-separated hybrid (WOT-SRSH) functional to\ninvestigate the electronic bandstructures and optical absorption spectra of\nbulk and monolayer PdSe$_2$. In particular, we account carefully for the finite\nexciton center-of-mass momentum within a time-dependent WOT-SRSH framework to\ncalculate the \\emph{indirect} optical gap and absorption onset accurately. Our\nresults agree well with the best available photoconductivity measurements, as\nwell as with state-of-the-art many-body perturbation theory calculations,\nconfirming that bulk PdSe$_2$ has an optical gap in the mid-infrared\n(upper-bound of 0.44 eV). More generally, this work further bolsters the\nutility of the WOT-SRSH approach for predictive modeling of layered\nsemiconductors."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-351",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02512",
    "b_title":[
      "Hybrid Fingerprint-based Positioning in Cell-Free Massive MIMO Systems"
    ],
    "b_abstract":[
      "Recently, there has been an increasing interest in 6G technology for\nintegrated sensing and communications, where positioning stands out as a key\napplication. In the realm of 6G, cell-free massive multiple-input\nmultiple-output (MIMO) systems, featuring distributed base stations equipped\nwith a large number of antennas, present an abundant source of angle-of-arrival\n(AOA) information that could be exploited for positioning applications. In this\npaper we leverage this AOA information at the base stations using the multiple\nsignal classification (MUSIC) algorithm, in conjunction with received signal\nstrength (RSS) for positioning through Gaussian process regression (GPR). An\nAOA fingerprint database is constructed by capturing the angle data from\nmultiple locations across the network area and is combined with RSS data from\nthe same locations to form a hybrid fingerprint which is then used to train a\nGPR model employing a squared exponential kernel. The trained regression model\nis subsequently utilized to estimate the location of a user equipment.\nSimulations demonstrate that the GPR model with hybrid input achieves better\npositioning accuracy than traditional GPR models utilizing RSS-only and\nAOA-only inputs."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08557",
    "c_title":[
      "Integrated Sensing, Communication, and Powering (ISCAP) for IoT: A Joint\n  Beamforming Design"
    ],
    "c_abstract":[
      "This paper studies Integrated Sensing, Communication, and Powering (ISCAP) as\na novel framework designed to enhance Internet of Things (IoT) applications\nwithin sixth-generation wireless networks. In these applications, in addition\nto IoT devices requiring an energy supply and receiving information or control\ndata to perform their tasks, the base station serving them must sense the\ndevices and their environment to localize them, thereby improving data\ntransmission and enabling simultaneous power delivery. In our multi-node ISCAP\nIoT system, we optimize base station beamforming alongside the receiver's\npower-splitting factor to maximize energy harvesting while adhering to strict\ncommunication and sensing constraints. To effectively tackle this non-convex\noptimization problem, we decompose it into three manageable subproblems and\nemploy several techniques such as semidefinite relaxation and Rayleigh quotient\nmethods to find an efficient solution. Simulation results demonstrate the\neffectiveness of the proposed design, highlighting performance trade-offs among\nsensing accuracy, communication reliability, and power transfer efficiency."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-352",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19774",
    "b_title":[
      "Effective range expansion with the left-hand cut and its application to\n  the $T_{cc}(3875)$"
    ],
    "b_abstract":[
      "The validity range of the widely used traditional effective range expansion\ncan be severely limited by the presence of a left-hand cut near the\ntwo-particle threshold. Such a left-hand cut emerges in two-particle scattering\nprocesses involving either a light particle exchange in the $t$-channel or a\nparticle exchange with a mass slightly heavier than the mass difference of the\ntwo particles in the $u$-channel, which occurs in a wide range of physical\nsystems. We propose a new parameterization for the low-energy scattering\namplitude that incorporates these left-hand cuts arising from particle exchange\ndiagrams. This parameterization extends the convergence radius of the effective\nrange expansion beyond the branch point of the left-hand cut and is applicable\nto a broad range of systems. The parameterization enables the extraction of\ncoupling strengths between the exchange particle and the scattering particles,\nand reveals amplitude zeros resulting from the interplay between short- and\nlong-range interactions. We demonstrate the effectiveness of this new\nparameterization through its application to $DD^*$ scattering with meson masses\nobtained in a lattice QCD calculation."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.10342",
    "c_title":[
      "Searching for the $2^+$ partner of the $T_{cs0}(2870)$ in the $B^- \\to\n  D^- D^0 K^0_S$ reaction"
    ],
    "c_abstract":[
      "We study the $B^- \\to D^- D^0 K^0_S$ reaction, recently analyzed by the LHCb\ncollaboration, where a clear signal for the exotic $T_{cs0}(2870)$ state has\nbeen reported. We call the attention to a small peak in the $D^0 K^0_S$ mass\ndistribution that could correspond to a state of the same nature as the\n$T_{cs0}(2870)$ ($D^* \\bar K^*$ nature in the molecular picture) but with $J^P=\n2^+$. In order to magnify the signal for the state, we calculate the moments of\nthe angle-mass distribution, which are linear in the resonance signal, rather\nthan quadratic for the angle integrated mass distribution. We find spectra for\nthe moments with a strength far bigger than that for the angle integrated mass\ndistribution, which should encourage the evaluation of these moments from the\npresent measurements of the reaction."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-353",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09591",
    "b_title":[
      "Metrics for Inter-Dataset Similarity with Example Applications in\n  Synthetic Data and Feature Selection Evaluation -- Extended Version"
    ],
    "b_abstract":[
      "Measuring inter-dataset similarity is an important task in machine learning\nand data mining with various use cases and applications. Existing methods for\nmeasuring inter-dataset similarity are computationally expensive, limited, or\nsensitive to different entities and non-trivial choices for parameters. They\nalso lack a holistic perspective on the entire dataset. In this paper, we\npropose two novel metrics for measuring inter-dataset similarity. We discuss\nthe mathematical foundation and the theoretical basis of our proposed metrics.\nWe demonstrate the effectiveness of the proposed metrics by investigating two\napplications in the evaluation of synthetic data and in the evaluation of\nfeature selection methods. The theoretical and empirical studies conducted in\nthis paper illustrate the effectiveness of the proposed metrics."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00921",
    "c_title":[
      "Blink of an eye: a simple theory for feature localization in generative\n  models"
    ],
    "c_abstract":[
      "Large language models (LLMs) can exhibit undesirable and unexpected behavior\nin the blink of an eye. In a recent Anthropic demo, Claude switched from coding\nto Googling pictures of Yellowstone, and these sudden shifts in behavior have\nalso been observed in reasoning patterns and jailbreaks. This phenomenon is not\nunique to autoregressive models: in diffusion models, key features of the final\noutput are decided in narrow ``critical windows'' of the generation process. In\nthis work we develop a simple, unifying theory to explain this phenomenon. We\nshow that it emerges generically as the generation process localizes to a\nsub-population of the distribution it models. While critical windows have been\nstudied at length in diffusion models, existing theory heavily relies on strong\ndistributional assumptions and the particulars of Gaussian diffusion. In\ncontrast to existing work our theory (1) applies to autoregressive and\ndiffusion models; (2) makes no distributional assumptions; (3) quantitatively\nimproves previous bounds even when specialized to diffusions; and (4) requires\nbasic tools and no stochastic calculus or statistical physics-based machinery.\nWe also identify an intriguing connection to the all-or-nothing phenomenon from\nstatistical inference. Finally, we validate our predictions empirically for\nLLMs and find that critical windows often coincide with failures in problem\nsolving for various math and reasoning benchmarks."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-354",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12495",
    "b_title":[
      "The planar projectivity of PG(2, $q^3$) of order 3 under field reduction"
    ],
    "b_abstract":[
      "Let $\\phi$ be a collineation of $\\mathrm{PG}\\left(2, q^{3}\\right)$ of order 3\nwhich fixes a plane of order $q$ pointwise. The points of $\\mathrm{PG}\\left(2,\nq^{3}\\right)$ can be partitioned into three types with respect to orbits of\n$\\phi$ : fixed points; points $P$ with $P, P^{\\phi}, P^{\\phi^{2}}$ distinct and\ncollinear; and points $P$ with $P, P^{\\phi}, P^{\\phi^{2}}$ not collinear. Under\nfield reduction, the collineation $\\phi$ corresponds to a projectivity $\\sigma$\nof $\\operatorname{PG}(8, q)$ of order 3 . With respect to the field reduction\nand the orbits of $\\sigma$, the points of $\\mathrm{PG}(8, q)$ can be\npartitioned into six types. This article looks at the projectivity $\\sigma$ in\ndetail, and classifies and counts the fixed points, fixed lines and fixed\nplanes. The motivation is to give a description of the lines of the Figueroa\nprojective plane in the $\\mathrm{PG}(8, q)$ field reduction setting."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.01538",
    "c_title":[
      "Bounds and Optimal Results for the Total Irregularity Measure"
    ],
    "c_abstract":[
      "A (molecular) graph in which all vertices have the same degree is known as a\nregular graph. According to Gutman, Hansen, and M\\'elot [J. Chem. Inf. Model.\n45 (2005) 222-230], it is of interest to measure the irregularity of nonregular\nmolecular graphs both for descriptive purposes and for QSAR\/QSPR studies. The\ngraph invariants that can be used to measure the irregularity of graphs are\nreferred to as irregularity measures. One of the well-studied irregularity\nmeasures is the ``total irregularity'' measure, which was introduced about a\ndecade ago. Bounds and optimization problems for this measure have already been\nextensively studied. A considerable number of existing results (concerning this\nmeasure) also hold for molecular graphs; particularly, the ones regarding lower\nbounds and minimum values of the mentioned measure. The primary objective of\nthe present review article is to collect the existing bounds and optimal\nresults concerning the total irregularity measure. Several open problems\nrelated to the existing results on the total irregularity measure are also\ngiven."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-355",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15885",
    "b_title":[
      "A Low-Cost, High-Precision Human-Machine Interaction Solution Based on\n  Multi-Coil Wireless Charging Pads"
    ],
    "b_abstract":[
      "Wireless charging pads are common, yet their functionality is mainly\nrestricted to charging. Existing gesture recognition techniques, such as those\nbased on machine vision and WiFi, have drawbacks like high costs and poor\nprecision. This paper presents a new human machine interaction solution using\nmulticoil wireless charging pads. The proposed approach leverages the pads\nexisting modules without additional wearable sensors. It determines gestures by\nmonitoring current and power changes in different coils. The data processing\nincludes noise removal, sorting, highpass filtering, and slicing. A Bayesian\nnetwork and particle filtering are employed for motion tracking. Through\nexperiments, this solution proves to have wide applications, high recognition\naccuracy, and low cost. It can effectively identify diverse gestures,\nincreasing the value of wireless charging pads. It outperforms traditional\nmethods, with a 0.73 improvement in recognition accuracy and better\nenvironmental adaptability."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12001",
    "c_title":[
      "Conversation Progress Guide : UI System for Enhancing Self-Efficacy in\n  Conversational AI"
    ],
    "c_abstract":[
      "In this study, we introduce the Conversation Progress Guide (CPG), a system\ndesigned for text-based conversational AI interactions that provides a visual\ninterface to represent progress. Users often encounter failures when\ninteracting with conversational AI, which can negatively affect their\nself-efficacy-an individual's belief in their capabilities, reducing their\nwillingness to engage with these services. The CPG offers visual feedback on\ntask progress, providing users with mastery experiences, a key source of\nself-efficacy. To evaluate the system's effectiveness, we conducted a user\nstudy assessing how the integration of the CPG influences user engagement and\nself-efficacy. Results demonstrate that users interacting with a conversational\nAI enhanced by the CPG showed significant improvements in self-efficacy\nmeasures compared to those using a conventional conversational AI."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-356",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03390",
    "b_title":[
      "Infinity Branches and Asymptotic Analysis of Algebraic Space Curves: New\n  Techniques and Applications"
    ],
    "b_abstract":[
      "Let C represent an irreducible algebraic space curve defined by the real\npolynomials fi(x1, x2, x3) for i = 1, 2. It is a recognized fact that a\nbirational relationship invariably exists between the points on C and those on\nan associated irreducible plane curve, denoted as Cp. In this work, we leverage\nthis established relationship to delineate the asymptotic behavior of C by\nexamining the asymptotes of Cp. Building on this foundation, we introduce a\nnovel and practical algorithm designed to efficiently compute the asymptotes of\nC, given that the asymptotes of Cp have been ascertained."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.03422",
    "c_title":[
      "Hecke modifications of vector bundles"
    ],
    "c_abstract":[
      "Hecke modifications of vector bundles have played a significant role in\nseveral areas of mathematics. They appear in subjects ranging from number\ntheory to complex geometry. This article intends to be a friendly introduction\nto the subject. We give an overview of how Hecke modifications appear in the\nliterature, explain their origin and their importance in number theory and\nclassical algebraic geometry. Moreover, we report the progress made in\ndescribing Hecke modifications explicitly and why these explicit descriptions\nare important. We describe all the Hecke modifications of the trivial rank $2$\nvector bundle over a closed point of degree $5$ in the projective line, as well\nas all the vector bundles over a certain elliptic curve, which admit a rank $2$\nand degree $0$ trace bundle as a Hecke modification. This result is not present\nin existing literature."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-357",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08168",
    "b_title":[
      "LeapVAD: A Leap in Autonomous Driving via Cognitive Perception and\n  Dual-Process Thinking"
    ],
    "b_abstract":[
      "While autonomous driving technology has made remarkable strides, data-driven\napproaches still struggle with complex scenarios due to their limited reasoning\ncapabilities. Meanwhile, knowledge-driven autonomous driving systems have\nevolved considerably with the popularization of visual language models. In this\npaper, we propose LeapVAD, a novel method based on cognitive perception and\ndual-process thinking. Our approach implements a human-attentional mechanism to\nidentify and focus on critical traffic elements that influence driving\ndecisions. By characterizing these objects through comprehensive attributes -\nincluding appearance, motion patterns, and associated risks - LeapVAD achieves\nmore effective environmental representation and streamlines the decision-making\nprocess. Furthermore, LeapVAD incorporates an innovative dual-process\ndecision-making module miming the human-driving learning process. The system\nconsists of an Analytic Process (System-II) that accumulates driving experience\nthrough logical reasoning and a Heuristic Process (System-I) that refines this\nknowledge via fine-tuning and few-shot learning. LeapVAD also includes\nreflective mechanisms and a growing memory bank, enabling it to learn from past\nmistakes and continuously improve its performance in a closed-loop environment.\nTo enhance efficiency, we develop a scene encoder network that generates\ncompact scene representations for rapid retrieval of relevant driving\nexperiences. Extensive evaluations conducted on two leading autonomous driving\nsimulators, CARLA and DriveArena, demonstrate that LeapVAD achieves superior\nperformance compared to camera-only approaches despite limited training data.\nComprehensive ablation studies further emphasize its effectiveness in\ncontinuous learning and domain adaptation. Project page:\nhttps:\/\/pjlab-adg.github.io\/LeapVAD\/."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14102",
    "c_title":[
      "Explainable Distributed Constraint Optimization Problems"
    ],
    "c_abstract":[
      "The Distributed Constraint Optimization Problem (DCOP) formulation is a\npowerful tool to model cooperative multi-agent problems that need to be solved\ndistributively. A core assumption of existing approaches is that DCOP solutions\ncan be easily understood, accepted, and adopted, which may not hold, as\nevidenced by the large body of literature on Explainable AI. In this paper, we\npropose the Explainable DCOP (X-DCOP) model, which extends a DCOP to include\nits solution and a contrastive query for that solution. We formally define some\nkey properties that contrastive explanations must satisfy for them to be\nconsidered as valid solutions to X-DCOPs as well as theoretical results on the\nexistence of such valid explanations. To solve X-DCOPs, we propose a\ndistributed framework as well as several optimizations and suboptimal variants\nto find valid explanations. We also include a human user study that showed that\nusers, not surprisingly, prefer shorter explanations over longer ones. Our\nempirical evaluations showed that our approach can scale to large problems, and\nthe different variants provide different options for trading off explanation\nlengths for smaller runtimes. Thus, our model and algorithmic contributions\nextend the state of the art by reducing the barrier for users to understand\nDCOP solutions, facilitating their adoption in more real-world applications."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-358",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06180",
    "b_title":[
      "Probabilistic Forecasts of Load, Solar and Wind for Electricity Price\n  Forecasting"
    ],
    "b_abstract":[
      "Electricity price forecasting is a critical tool for the efficient operation\nof power systems and for supporting informed decision-making by market\nparticipants. This paper explores a novel methodology aimed at improving the\naccuracy of electricity price forecasts by incorporating probabilistic inputs\nof fundamental variables. Traditional approaches often rely on point forecasts\nof exogenous variables such as load, solar, and wind generation. Our method\nproposes the integration of quantile forecasts of these fundamental variables,\nproviding a new set of exogenous variables that account for a more\ncomprehensive representation of uncertainty. We conducted empirical tests on\nthe German electricity market using recent data to evaluate the effectiveness\nof this approach. The findings indicate that incorporating probabilistic\nforecasts of load and renewable energy source generation significantly improves\nthe accuracy of point forecasts of electricity prices. Furthermore, the results\nclearly show that the highest improvement in forecast accuracy can be achieved\nwith full probabilistic forecast information. This highlights the importance of\nprobabilistic forecasting in research and practice, particularly that the\ncurrent state-of-the-art in reporting load, wind and solar forecast is\ninsufficient."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.14763",
    "c_title":[
      "Estimation and Evaluation of the Resource-Constrained Optimal Dynamic\n  Treatment Rule: An Application to HIV Care Retention"
    ],
    "c_abstract":[
      "The optimal strategy for deploying a treatment in a population may recommend\ngiving all in the population that treatment. Such a strategy may not be\nfeasible, especially in resource-limited settings. One approach for determining\nhow to allocate a treatment in such settings is the resource-constrained\noptimal dynamic treatment rule (RC ODTR) SuperLearner algorithm, developed by\nLuedtke and van der Laan. In this paper, we describe this algorithm, offer\nvarious novel approaches for presenting the RC ODTR and its value in terms of\nbenefit and cost, and provide practical guidance on implementing the algorithm\n(including software). In particular, we apply this method to the Adaptive\nStrategies for Preventing and Treating Lapses of Retention in HIV care\n(NCT02338739) trial to determine how to best allocate conditional cash\ntransfers (CCTs) for increasing HIV care adherence given varying constraints on\nthe proportion of people who can receive CCTs in the population, providing one\nof the few applied illustrations of this method and novel substantive findings.\nWe find that there are clinical and monetary benefits to deploying CCTs to a\nsmall percent (e.g., 10\\%) of the population compared to administering the care\nstandard for all; however, results suggest that these incremental benefits are\nonly due to the loosening of constraints, rather than a presence of treatment\neffect heterogeneity strong enough to drive a more efficient and effective\nconstrained allocation approach."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-359",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08836",
    "b_title":[
      "Survey on Single-Image Reflection Removal using Deep Learning Techniques"
    ],
    "b_abstract":[
      "The phenomenon of reflection is quite common in digital images, posing\nsignificant challenges for various applications such as computer vision,\nphotography, and image processing. Traditional methods for reflection removal\noften struggle to achieve clean results while maintaining high fidelity and\nrobustness, particularly in real-world scenarios. Over the past few decades,\nnumerous deep learning-based approaches for reflection removal have emerged,\nyielding impressive results. In this survey, we conduct a comprehensive review\nof the current literature by focusing on key venues such as ICCV, ECCV, CVPR,\nNeurIPS, etc., as these conferences and journals have been central to advances\nin the field. Our review follows a structured paper selection process, and we\ncritically assess both single-stage and two-stage deep learning methods for\nreflection removal. The contribution of this survey is three-fold: first, we\nprovide a comprehensive summary of the most recent work on single-image\nreflection removal; second, we outline task hypotheses, current deep learning\ntechniques, publicly available datasets, and relevant evaluation metrics; and\nthird, we identify key challenges and opportunities in deep learning-based\nreflection removal, highlighting the potential of this rapidly evolving\nresearch area."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07592",
    "c_title":[
      "YOLO Network For Defect Detection In Optical lenses"
    ],
    "c_abstract":[
      "Mass-produced optical lenses often exhibit defects that alter their\nscattering properties and compromise quality standards. Manual inspection is\nusually adopted to detect defects, but it is not recommended due to low\naccuracy, high error rate and limited scalability. To address these challenges,\nthis study presents an automated defect detection system based on the YOLOv8\ndeep learning model. A custom dataset of optical lenses, annotated with defect\nand lens regions, was created to train the model. Experimental results obtained\nin this study reveal that the system can be used to efficiently and accurately\ndetect defects in optical lenses. The proposed system can be utilized in\nreal-time industrial environments to enhance quality control processes by\nenabling reliable and scalable defect detection in optical lens manufacturing."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-360",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05496",
    "b_title":[
      "Feature Explosion: a generic optimization strategy for outlier detection\n  algorithms"
    ],
    "b_abstract":[
      "Outlier detection tasks aim at discovering potential issues or opportunities\nand are widely used in cybersecurity, financial security, industrial\ninspection, etc. To date, thousands of outlier detection algorithms have been\nproposed. Clearly, in real-world scenarios, such a large number of algorithms\nis unnecessary. In other words, a large number of outlier detection algorithms\nare redundant. We believe the root cause of this redundancy lies in the current\nhighly customized (i.e., non-generic) optimization strategies. Specifically,\nwhen researchers seek to improve the performance of existing outlier detection\nalgorithms, they have to design separate optimized versions tailored to the\nprinciples of each algorithm, leading to an ever-growing number of outlier\ndetection algorithms. To address this issue, in this paper, we introduce the\nexplosion from physics into the outlier detection task and propose a generic\noptimization strategy based on feature explosion, called OSD (Optimization\nStrategy for outlier Detection algorithms). In the future, when improving the\nperformance of existing outlier detection algorithms, it will be sufficient to\ninvoke the OSD plugin without the need to design customized optimized versions\nfor them. We compared the performances of 14 outlier detection algorithms on 24\ndatasets before and after invoking the OSD plugin. The experimental results\nshow that the performances of all outlier detection algorithms are improved on\nalmost all datasets. In terms of average accuracy, OSD make these outlier\ndetection algorithms improve by 15% (AUC), 63.7% (AP)."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13308",
    "c_title":[
      "A Label-Free Heterophily-Guided Approach for Unsupervised Graph Fraud\n  Detection"
    ],
    "c_abstract":[
      "Graph fraud detection (GFD) has rapidly advanced in protecting online\nservices by identifying malicious fraudsters. Recent supervised GFD research\nhighlights that heterophilic connections between fraudsters and users can\ngreatly impact detection performance, since fraudsters tend to camouflage\nthemselves by building more connections to benign users. Despite the promising\nperformance of supervised GFD methods, the reliance on labels limits their\napplications to unsupervised scenarios; Additionally, accurately capturing\ncomplex and diverse heterophily patterns without labels poses a further\nchallenge. To fill the gap, we propose a Heterophily-guided Unsupervised Graph\nfraud dEtection approach (HUGE) for unsupervised GFD, which contains two\nessential components: a heterophily estimation module and an alignment-based\nfraud detection module. In the heterophily estimation module, we design a novel\nlabel-free heterophily metric called HALO, which captures the critical graph\nproperties for GFD, enabling its outstanding ability to estimate heterophily\nfrom node attributes. In the alignment-based fraud detection module, we develop\na joint MLP-GNN architecture with ranking loss and asymmetric alignment loss.\nThe ranking loss aligns the predicted fraud score with the relative order of\nHALO, providing an extra robustness guarantee by comparing heterophily among\nnon-adjacent nodes. Moreover, the asymmetric alignment loss effectively\nutilizes structural information while alleviating the feature-smooth effects of\nGNNs. Extensive experiments on 6 datasets demonstrate that HUGE significantly\noutperforms competitors, showcasing its effectiveness and robustness."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-361",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11793",
    "b_title":[
      "Self-Calibrated Epipolar Reconstruction for Assessment of Aneurysms in\n  the Internal Carotid Artery Using In-Silico Biplane Angiograms"
    ],
    "b_abstract":[
      "The treatment of intracranial aneurysms (IA) relies on angiography guidance\nusing biplane views. However, accurate flow estimation and device sizing for\ntreatment are often compromised by vessel overlap and foreshortening, which can\nobscure critical details. This study introduces an epipolar reconstruction\napproach to enhance 3D rendering of the internal carotid artery (ICA) and\naneurysm dome using routinely acquired biplane angiographic data. Our method\naims to improve procedural guidance by overcoming the limitations of\ntraditional two-dimensional imaging techniques. This study employed three 3D\ngeometries of ICA aneurysms to simulate virtual angiograms. These angiograms\nwere generated using a computational fluid dynamics (CFD) solver, followed by\nthe simulation of biplane angiography using a cone-beam geometry.\nSelf-calibration was accomplished by matching contrast media position as a\nfunction of time between biplane views. Feature-matching was used to\ntriangulate and reconstruct vascular structures in 3D. The projection data was\nutilized to refine the 3D estimation, including elimination of erroneous\nstructures and ellipse-fitting. The accuracy of the reconstructions was\nevaluated using the Dice-Sorensen coefficient, comparing the 3D reconstructions\nto the original models. The proposed epipolar reconstruction method generalized\nwell across the three tested aneurysm models, with respective Dice-Sorensen\ncoefficients of 0.745, 0.759, and 0.654. Errors were primarily due to partial\nvessel overlap. The average reconstruction time for all three volumes was\napproximately 10 seconds. The proposed epipolar reconstruction method enhanced\n3D visualization, addressing challenges such as projection-induced vessel\nforeshortening. This method provides a solution to the complexity of IA\nvisualization, with the potential to provide more accurate analysis and device\nsizing for treatment."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.12349",
    "c_title":[
      "Quantitative diagnosis of amyloid without Congo red staining using\n  polarized light microscopy"
    ],
    "c_abstract":[
      "Amyloidosis is a protein misfolding disease caused by the deposition of\nlarge, insoluble aggregates (amyloid fibrils) of protein in a tissue, which has\nbeen associated with various conditions, such as lymphoid disorders,\nAlzheimer's disease, diabetes mellitus type 2, chronic inflammatory processes,\nand cancers. Amyloid fibrils are commonly diagnosed by qualitative observation\nof green birefringence from Congo red stained biopsy tissue samples under\npolarized light, a technique that is limited by lack of specificity, dependence\non subjective interpretation, and technical constraints. Studies emphasize the\nutility of quantitative polarized light microscopy (PLM) methodology to\ndiagnose amyloid fibrils in Congo red stained tissues. However, while Congo red\nenhances the intrinsic birefringence of amyloid fibrillar structures, there are\nsignificant disadvantages such as the appearance of multiple non-green colors\nunder polarized light and binding to other structures, which may result in\nmisdiagnoses with Congo red dye and inconclusive explanations. In this work, we\npresent an improved PLM methodology for quantitative detection of amyloid\nfibrils without requiring Congo red staining. We perform PLM measurements on\nfour tissues: abdominal subcutaneous tissue biopsy, duodenal biopsy, thyroid\nbiopsy, and breast biopsy, both with Congo red stain and H\\&E stain, and\nthrough Fourier analysis quantify birefringence, birefringent axis orientation,\ndichroism, optical activity, and relative amyloid density. These results\nemphasize a quantitative analysis for amyloid diagnosis rooted in Fourier\nsignal harmonics that does not require Congo red dye and paves the way for\nrapid, simple, and accurate diagnosis of amyloid fibrils."
    ],
    "c_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-362",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10664",
    "b_title":[
      "Multi-Carrier Thermal Transport in Electronic and Energy Conversion\n  Devices"
    ],
    "b_abstract":[
      "Nonequilibrium multi-carrier thermal transport is essential for both\nscientific research and technological applications in electronic, spintronic,\nand energy conversion devices. This article reviews the fundamentals of phonon,\nelectron, spin, and ion transport driven by temperature gradients in\nsolid-state and soft condensed matters, and the microscopic interactions\nbetween energy\/charge carriers that can be leveraged for manipulating\nelectrical and thermal transport in energy conversion devices, such as\nelectron-phonon coupling, spin-phonon interaction, and ion-solvent\ninteractions, etc. In coupled electron-phonon transport, we discuss the basics\nof electron-phonon interactions and their effects on phonon dynamics,\nthermalization, and nonequilibrium thermal transport. For the phonon-spin\ninteraction, nonequilibrium transport formulation is introduced first, followed\nby the physics of spin thermoelectric effect and strategies to manipulate them.\nContributions to thermal conductivity from magnons as heat carriers are also\nreviewed. For coupled transport of heat and ions\/molecules, we highlight the\nimportance of local molecular configurations that determine the magnitude of\nthe electrochemical gradient, which is the key to improving the efficiency of\nlow-grade heat energy conversion."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12325",
    "c_title":[
      "Reduction of current for magnetization switching in a nanomagnet with\n  perpendicular anisotropy by spin-splitter torque"
    ],
    "c_abstract":[
      "Recently, spin-transfer torque (STT) based magnetization switching has been\nwidely utilized in magnetic resistance-based memories, which have broad\napplications in microcontroller units and other devices. This study utilizes a\nmacrospin model to simulate magnetization switching in nanoscale magnets with\nperpendicular anisotropy through spin-splitter torque (SST). The study\nprimarily addresses minimizing the current for magnetization switching and\nidentifying the conditions necessary for achieving high switching\nprobabilities. Notably, the threshold current density for SST-induced\nmagnetization switching is reduced by approximately 75-80% compared to\nconventional STT and spin-orbit torque mechanisms, provided the spin torque\npolar angle is optimized. For practical implementation in magnetic\nrandom-access memory (MRAM), a polar angle exceeding roughly 128 degrees must\nbe maintained to ensure sufficient switching probability. Additionally,\noptimizing the shape of the applied current pulse significantly lowers the\nswitching per rate by approximately 18 times. These findings underscore the\neffectiveness of SST in reducing magnetization switching currents and offer\nvaluable insights into its potential application in SST-MRAM technology."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-363",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16355",
    "b_title":[
      "DEMNUni: the Sunyaev-Zel'dovich effect in the presence of massive\n  neutrinos and dynamical dark energy"
    ],
    "b_abstract":[
      "In recent years, the study of secondary anisotropies in the Cosmic Microwave\nBackground has become a fundamental instrument to test our understanding of\nCosmology and Astrophysics. Using a set of lightcones produced with the ``Dark\nEnergy and Massive Neutrino Universe'' $N$-body simulations we study how\ndifferent dark energy models and neutrino masses impact the properties of the\nSunyaev-Zel'dovich (SZ) effects, focusing on the signal arising from galaxy\nclusters and groups. We analyse the distribution of values, Compton-$y$\nparameter for the thermal SZ effect and $\\Delta T\/T$ for the kinematic SZ\neffect, and study their angular power spectra. We find that the distribution of\nlogarithmic Compton parameter can be fitted with a skewed Gaussian, with a mean\nthat, at fixed dark energy model, decreases linearly with an approximate slope\nof $10 f_\\nu$. Regarding the power spectrum of the thermal SZ effect, we find\nthat an increase in $\\sum {m_\\nu}$ is observed as a power-law scaling with\nrespect to $\\sigma_8^{\\mathrm{cb}}$, with exponents ranging from 7.2 to 8.2. We\nalso find that four cosmological models, one with $\\sum {m_\\nu} = 0.16$ eV and\nthree with $\\sum {m_\\nu} = 0.32$ eV, fit equally well the Planck data for the\nCompton-$y$. For all the \\texttt{DEMNUni} models we forecast the cumulative\nsignal-to-noise for thermal SZ observations with the LAT instrument of Simons\nObservatory; furthermore, we compute a tailored $\\chi_\\mathrm{SNR}^2$ estimator\nto infer if they can be distinguished from the reference $\\Lambda$CDM. We also\nprovide estimates for the power spectrum of the cluster component of the\nkinematic SZ effect, in all the different cosmological scenarios."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.00126",
    "c_title":[
      "Impacts of Dynamical Dark Energy on the Neutrino Mass Constraints"
    ],
    "c_abstract":[
      "The difference between the total neutrino mass estimates ($\\sum m_\\nu$)\nderived from cosmological data within the standard $\\Lambda$CDM model and those\nobtained from terrestrial particle physics experiments underscores the need to\nexplore alternative scenarios. Recent analyses have shown that a dynamic dark\nenergy modeled by the CPL parameterization of the dark energy equation of state\n(EoS) can ease the constraints on $\\sum m_\\nu$, thus alleviating this tension.\nThis study investigates the robustness of this discrepancy by assessing the\nextent to which the CPL assumption influences the results. We examine how other\nEoS parameterizations, such as the Barboza-Alcaniz (BA) and\nJassal-Bagla-Padmanabhan (JBP) parameterizations, affect $\\sum m_\\nu$\nestimates. We perform a Markov Chain Monte Carlo (MCMC) analysis combining the\nlatest baryon acoustic oscillation data from DESI with the Planck 2018 cosmic\nmicrowave background data, which includes information on temperature,\npolarization, and lensing, as well as the Pantheon+ Type Ia supernovae\nobservations. While both the BA and JBP parameterizations can also resolve the\ntension, our results show a correlation between the dark energy EoS and the\nconstraints on neutrino mass."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-364",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15401",
    "b_title":[
      "Problem-Solving Logic Guided Curriculum In-Context Learning for LLMs\n  Complex Reasoning"
    ],
    "b_abstract":[
      "In-context learning (ICL) can significantly enhance the complex reasoning\ncapabilities of large language models (LLMs), with the key lying in the\nselection and ordering of demonstration examples. Previous methods typically\nrelied on simple features to measure the relevance between examples. We argue\nthat these features are not sufficient to reflect the intrinsic connections\nbetween examples. In this study, we propose a curriculum ICL strategy guided by\nproblem-solving logic. We select demonstration examples by analyzing the\nproblem-solving logic and order them based on curriculum learning.\nSpecifically, we constructed a problem-solving logic instruction set based on\nthe BREAK dataset and fine-tuned a language model to analyze the\nproblem-solving logic of examples. Subsequently, we selected appropriate\ndemonstration examples based on problem-solving logic and assessed their\ndifficulty according to the number of problem-solving steps. In accordance with\nthe principles of curriculum learning, we ordered the examples from easy to\nhard to serve as contextual prompts. Experimental results on multiple\nbenchmarks indicate that our method outperforms previous ICL approaches in\nterms of performance and efficiency, effectively enhancing the complex\nreasoning capabilities of LLMs. Our project will be publicly available\nsubsequently."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04662",
    "c_title":[
      "On The Origin of Cultural Biases in Language Models: From Pre-training\n  Data to Linguistic Phenomena"
    ],
    "c_abstract":[
      "Language Models (LMs) have been shown to exhibit a strong preference towards\nentities associated with Western culture when operating in non-Western\nlanguages. In this paper, we aim to uncover the origins of entity-related\ncultural biases in LMs by analyzing several contributing factors, including the\nrepresentation of entities in pre-training data and the impact of variations in\nlinguistic phenomena across languages. We introduce CAMeL-2, a parallel\nArabic-English benchmark of 58,086 entities associated with Arab and Western\ncultures and 367 masked natural contexts for entities. Our evaluations using\nCAMeL-2 reveal reduced performance gaps between cultures by LMs when tested in\nEnglish compared to Arabic. We find that LMs struggle in Arabic with entities\nthat appear at high frequencies in pre-training, where entities can hold\nmultiple word senses. This also extends to entities that exhibit high lexical\noverlap with languages that are not Arabic but use the Arabic script. Further,\nwe show how frequency-based tokenization leads to this issue in LMs, which gets\nworse with larger Arabic vocabularies. We will make CAMeL-2 available at:\nhttps:\/\/github.com\/tareknaous\/camel2"
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-365",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15737",
    "b_title":[
      "KoGNER: A Novel Framework for Knowledge Graph Distillation on Biomedical\n  Named Entity Recognition"
    ],
    "b_abstract":[
      "Named Entity Recognition (NER) is a fundamental task in Natural Language\nProcessing (NLP) that plays a crucial role in information extraction, question\nanswering, and knowledge-based systems. Traditional deep learning-based NER\nmodels often struggle with domain-specific generalization and suffer from data\nsparsity issues. In this work, we introduce Knowledge Graph distilled for Named\nEntity Recognition (KoGNER), a novel approach that integrates Knowledge Graph\n(KG) distillation into NER models to enhance entity recognition performance.\nOur framework leverages structured knowledge representations from KGs to enrich\ncontextual embeddings, thereby improving entity classification and reducing\nambiguity in entity detection. KoGNER employs a two-step process: (1) Knowledge\nDistillation, where external knowledge sources are distilled into a lightweight\nrepresentation for seamless integration with NER models, and (2) Entity-Aware\nAugmentation, which integrates contextual embeddings that have been enriched\nwith knowledge graph information directly into GNN, thereby improving the\nmodel's ability to understand and represent entity relationships. Experimental\nresults on benchmark datasets demonstrate that KoGNER achieves state-of-the-art\nperformance, outperforming finetuned NER models and LLMs by a significant\nmargin. These findings suggest that leveraging knowledge graphs as auxiliary\ninformation can significantly improve NER accuracy, making KoGNER a promising\ndirection for future research in knowledge-aware NLP."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07086",
    "c_title":[
      "Boosting Text-To-Image Generation via Multilingual Prompting in Large\n  Multimodal Models"
    ],
    "c_abstract":[
      "Previous work on augmenting large multimodal models (LMMs) for text-to-image\n(T2I) generation has focused on enriching the input space of in-context\nlearning (ICL). This includes providing a few demonstrations and optimizing\nimage descriptions to be more detailed and logical. However, as demand for more\ncomplex and flexible image descriptions grows, enhancing comprehension of input\ntext within the ICL paradigm remains a critical yet underexplored area. In this\nwork, we extend this line of research by constructing parallel multilingual\nprompts aimed at harnessing the multilingual capabilities of LMMs. More\nspecifically, we translate the input text into several languages and provide\nthe models with both the original text and the translations. Experiments on two\nLMMs across 3 benchmarks show that our method, PMT2I, achieves superior\nperformance in general, compositional, and fine-grained assessments, especially\nin human preference alignment. Additionally, with its advantage of generating\nmore diverse images, PMT2I significantly outperforms baseline prompts when\nincorporated with reranking methods. Our code and parallel multilingual data\ncan be found at https:\/\/github.com\/takagi97\/PMT2I."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-366",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17898",
    "b_title":[
      "Matrix approach to generalized ensemble theory"
    ],
    "b_abstract":[
      "We provide a concise framework for generalized ensemble theory through a\nmatrix-based approach. By introducing an observation matrix, any discrete\nprobability distribution, including those for non-equilibrium steady states,\ncan be expressed as a generalized Boltzmann distribution, with observables and\nconjugate variables as the basis and coordinates in a linear space. In this\nframework, we identify the minimal sufficient statistics required for inferring\nthe Boltzmann distribution. Furthermore, we show that the Hadamard and\nVandermonde matrices are suitable observation matrices for spin systems and\nrandom walks. In master equation systems, the probability flux observation\nmatrix facilitates the identification of detailed balance violations. Our\nfindings provide a new approach to developing generalized ensemble theory for\nnon-equilibrium steady-state systems."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04461",
    "c_title":[
      "Infinite-temperature thermostats by energy localization in a\n  nonequilibrium setup"
    ],
    "c_abstract":[
      "Some lattice models having two conservation laws may display an equilibrium\nphase transition from a homogeneous (positive temperature - PT) to a condensed\n(negative temperature) phase, where a finite fraction of the energy is\nlocalized in a few sites. We study one such stochastic model in an\nout-of-equilibrium setup, where the ends of the lattice chain are attached to\ntwo PT baths. We show that localized peaks may spontaneously emerge, acting as\ninfinite-temperature heat baths. The number $N_b$ of peaks is expected to grow\nin time $t$ as $N_b \\sim \\sqrt{\\ln t}$, as a consequence of an effective\nfreezing of the dynamics. Asymptotically, the chain spontaneously subdivides\ninto three intervals: the two external ones lying inside the PT region; the\nmiddle one characterized by peaks superposed to a background lying along the\ninfinite-temperature line. In the thermodynamic limit, the Onsager formalism\nallows determining the shape of the whole profile."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-367",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03891",
    "b_title":[
      "Counterfactual Query Rewriting to Use Historical Relevance Feedback"
    ],
    "b_abstract":[
      "When a retrieval system receives a query it has encountered before, previous\nrelevance feedback, such as clicks or explicit judgments can help to improve\nretrieval results. However, the content of a previously relevant document may\nhave changed, or the document might not be available anymore. Despite this\nevolved corpus, we counterfactually use these previously relevant documents as\nrelevance signals. In this paper we proposed approaches to rewrite user queries\nand compare them against a system that directly uses the previous qrels for the\nranking. We expand queries with terms extracted from the previously relevant\ndocuments or derive so-called keyqueries that rank the previously relevant\ndocuments to the top of the current corpus. Our evaluation in the CLEF LongEval\nscenario shows that rewriting queries with historical relevance feedback\nimproves the retrieval effectiveness and even outperforms computationally\nexpensive transformer-based approaches."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16125",
    "c_title":[
      "SampleLLM: Optimizing Tabular Data Synthesis in Recommendations"
    ],
    "c_abstract":[
      "Tabular data synthesis is crucial in machine learning, yet existing general\nmethods-primarily based on statistical or deep learning models-are highly\ndata-dependent and often fall short in recommender systems. This limitation\narises from their difficulty in capturing complex distributions and\nunderstanding feature relationships from sparse and limited data, along with\ntheir inability to grasp semantic feature relations. Recently, Large Language\nModels (LLMs) have shown potential in generating synthetic data samples through\nfew-shot learning and semantic understanding. However, they often suffer from\ninconsistent distribution and lack of diversity due to their inherent\ndistribution disparity with the target dataset. To address these challenges and\nenhance tabular data synthesis for recommendation tasks, we propose a novel\ntwo-stage framework named SampleLLM to improve the quality of LLM-based tabular\ndata synthesis for recommendations by ensuring better distribution alignment.\nIn the first stage, SampleLLM employs LLMs with Chain-of-Thought prompts and\ndiverse exemplars to generate data that closely aligns with the target dataset\ndistribution, even when input samples are limited. The second stage uses an\nadvanced feature attribution-based importance sampling method to refine feature\nrelationships within the synthesized data, reducing any distribution biases\nintroduced by the LLM. Experimental results on three recommendation datasets,\ntwo general datasets, and online deployment illustrate that SampleLLM\nsignificantly surpasses existing methods for recommendation tasks and holds\npromise for a broader range of tabular data scenarios."
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-368",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04984",
    "b_title":[
      "Reduction properties of the KP-mKP hierarchy"
    ],
    "b_abstract":[
      "The so-called KP-mKP hierarchy, which was introduced recently via\npseudo-differential operators with two derivations, can be reduced to the\nKadomtsev-Petviashvili (KP), the modified KP (mKP) and the two-component BKP\nhierarchies. In this note, we continue to study reductions properties of the\nKP-mKP hierarchy, including its $(n,m)$-reduction and its reduction to a\ncertain extended $r$-reduced KP hierarchy (the $r$-th Gelfand-Dickey together\nwith its wave function). As a byproduct, we show that the Hirota equations of\nthe extended $r$-reduced KP hierarchy follow from those of the mKP hierarchy,\nwhich confirms a conjecture of Alexandrov on the open KdV hierarchy in [ J.\nHigh Energy Phys. 2015 ]."
    ],
    "b_categories":[
      [
        "nlin.SI"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.00889",
    "c_title":[
      "Algebro-geometric integration to the discrete Chen-Lee-Liu system"
    ],
    "c_abstract":[
      "Algebro-geometric solutions for the discrete Chen-Lee-Liu (CLL) system are\nderived in this paper. We construct a nonlinear integrable symplectic map which\nis used to define discrete phase flows. Compatibility of the maps with\ndifferent parameters gives rise to the discrete CLL system whose solutions\n(discrete potentials) can be formulated through the discrete phase flows.\nBaker-Akhiezer functions are introduced and their asymptotic behaviors are\nanalyzed. Consequently, we are able to reconstruct the discrete potentials in\nterms of the Riemann theta functions. These results can be extended to\n3-dimensional case and algebro-geometric solutions of the discrete modified\nKadomtsev-Petviashvili equation are obtained. Some solutions of genus one case\nare illustrated."
    ],
    "c_categories":[
      [
        "nlin.SI"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-369",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14734",
    "b_title":[
      "Sentence Smith: Formally Controllable Text Transformation and its\n  Application to Evaluation of Text Embedding Models"
    ],
    "b_abstract":[
      "We propose the Sentence Smith framework that enables controlled and specified\nmanipulation of text meaning. It consists of three main steps: 1. Parsing a\nsentence into a semantic graph, 2. Applying human-designed semantic\nmanipulation rules, and 3. Generating text from the manipulated graph. A final\nfiltering step (4.) ensures the validity of the applied transformation. To\ndemonstrate the utility of Sentence Smith in an application study, we use it to\ngenerate hard negative pairs that challenge text embedding models. Since the\ncontrollable generation makes it possible to clearly isolate different types of\nsemantic shifts, we can gain deeper insights into the specific strengths and\nweaknesses of widely used text embedding models, also addressing an issue in\ncurrent benchmarking where linguistic phenomena remain opaque. Human validation\nconfirms that the generations produced by Sentence Smith are highly accurate."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11493",
    "c_title":[
      "DAST: Context-Aware Compression in LLMs via Dynamic Allocation of Soft\n  Tokens"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) face computational inefficiencies and redundant\nprocessing when handling long context inputs, prompting a focus on compression\ntechniques. While existing semantic vector-based compression methods achieve\npromising performance, these methods fail to account for the intrinsic\ninformation density variations between context chunks, instead allocating soft\ntokens uniformly across context chunks. This uniform distribution inevitably\ndiminishes allocation to information-critical regions. To address this, we\npropose Dynamic Allocation of Soft Tokens (DAST), a simple yet effective method\nthat leverages the LLM's intrinsic understanding of contextual relevance to\nguide compression. DAST combines perplexity-based local information with\nattention-driven global information to dynamically allocate soft tokens to the\ninformative-rich chunks, enabling effective, context-aware compression.\nExperimental results across multiple benchmarks demonstrate that DAST surpasses\nstate-of-the-art methods."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-370",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19814",
    "b_title":[
      "Explicit solution of second-order delayed discrete equations"
    ],
    "b_abstract":[
      "A system of inhomogeneous second-order difference equations with linear parts\ngiven by noncommutative matrix coefficients are considered. Closed form of its\nsolution is derived by means of newly defined delayed matrix sine\/cosine using\nthe Z-transform and determining function."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.16041",
    "c_title":[
      "Spillover-Free Control of the Semilinear Heat Equation via the $L^2$\n  Residue Separation and Harmonic Inequality"
    ],
    "c_abstract":[
      "We present a new method for designing spillover-free finite-dimensional\noutput-feedback controllers for systems governed by parabolic partial\ndifferential equations (PDEs). Building on the recently developed $L^2$ residue\nseparation for state-feedback control, we extend this concept to\noutput-feedback using a novel harmonic inequality, which provides an optimal\nbound on the residue in terms of the weighted $l^2$ norm of its Fourier\ncoefficients. We apply this approach to a 1D semilinear heat equation, where\nthe measured output and unknown nonlinearity link the dominant and residual\nmodes, leading to spillover if the residual modes are neglected in the\ncontroller design. We demonstrate how to compute the input-to-residue $L^2$\ngain and utilize it to design a spillover-free controller. Additionally, we\nshow how the refined approach eliminates the need for the lifting\ntransformation, enabling a sample-and-hold implementation of the control\nsignal."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-371",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02148",
    "b_title":[
      "Bit-bit encoding, optimizer-free training and sub-net initialization:\n  techniques for scalable quantum machine learning"
    ],
    "b_abstract":[
      "Quantum machine learning for classical data is currently perceived to have a\nscalability problem due to (i) a bottleneck at the point of loading data into\nquantum states, (ii) the lack of clarity around good optimization strategies,\nand (iii) barren plateaus that occur when the model parameters are randomly\ninitialized. In this work, we propose techniques to address all of these\nissues. First, we present a quantum classifier that encodes both the input and\nthe output as binary strings which results in a model that has no restrictions\non expressivity over the encoded data but requires fast classical compression\nof typical high-dimensional datasets to only the most predictive degrees of\nfreedom. Second, we show that if one parameter is updated at a time, quantum\nmodels can be trained without using a classical optimizer in a way that\nguarantees convergence to a local minimum, something not possible for classical\ndeep learning models. Third, we propose a parameter initialization strategy\ncalled sub-net initialization to avoid barren plateaus where smaller models,\ntrained on more compactly encoded data with fewer qubits, are used to\ninitialize models that utilize more qubits. Along with theoretical arguments on\nefficacy, we demonstrate the combined performance of these methods on subsets\nof the MNIST dataset for models with an all-to-all connected architecture that\nuse up to 16 qubits in simulation. This allows us to conclude that the loss\nfunction consistently decreases as the capability of the model, measured by the\nnumber of parameters and qubits, increases, and this behavior is maintained for\ndatasets of varying complexity. Together, these techniques offer a coherent\nframework for scalable quantum machine learning."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.16654",
    "c_title":[
      "Local models and Bell inequalities for the minimal triangle network"
    ],
    "c_abstract":[
      "Nonlocal correlations created in networks with multiple independent sources\nenable surprising phenomena in quantum information and quantum foundations. The\npresence of independent sources, however, makes the analysis of network\nnonlocality challenging, and even in the simplest nontrivial scenarios a\ncomplete characterization is lacking. In this work we study one of the simplest\nof these scenarios, namely that of distributions invariant under permutations\nof parties in the minimal triangle network, which features no inputs and binary\noutcomes. We perform an exhaustive search for triangle-local models, and from\nit we infer analytic expressions for the boundaries of the set of distributions\nthat admit such models, which we conjecture to be all the tight Bell\ninequalities for the scenario. Armed with them and with improved outer\napproximations of the set, we provide new insights on the existence of a\nclassical-quantum gap in the triangle network with binary outcomes."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-372",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16870",
    "b_title":[
      "Experimenting with Affective Computing Models in Video Interviews with\n  Spanish-speaking Older Adults"
    ],
    "b_abstract":[
      "Understanding emotional signals in older adults is crucial for designing\nvirtual assistants that support their well-being. However, existing affective\ncomputing models often face significant limitations: (1) limited availability\nof datasets representing older adults, especially in non-English-speaking\npopulations, and (2) poor generalization of models trained on younger or\nhomogeneous demographics. To address these gaps, this study evaluates\nstate-of-the-art affective computing models -- including facial expression\nrecognition, text sentiment analysis, and smile detection -- using videos of\nolder adults interacting with either a person or a virtual avatar. As part of\nthis effort, we introduce a novel dataset featuring Spanish-speaking older\nadults engaged in human-to-human video interviews. Through three comprehensive\nanalyses, we investigate (1) the alignment between human-annotated labels and\nautomatic model outputs, (2) the relationships between model outputs across\ndifferent modalities, and (3) individual variations in emotional signals. Using\nboth the Wizard of Oz (WoZ) dataset and our newly collected dataset, we uncover\nlimited agreement between human annotations and model predictions, weak\nconsistency across modalities, and significant variability among individuals.\nThese findings highlight the shortcomings of generalized emotion perception\nmodels and emphasize the need of incorporating personal variability and\ncultural nuances into future systems."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07307",
    "c_title":[
      "AttenST: A Training-Free Attention-Driven Style Transfer Framework with\n  Pre-Trained Diffusion Models"
    ],
    "c_abstract":[
      "While diffusion models have achieved remarkable progress in style transfer\ntasks, existing methods typically rely on fine-tuning or optimizing pre-trained\nmodels during inference, leading to high computational costs and challenges in\nbalancing content preservation with style integration. To address these\nlimitations, we introduce AttenST, a training-free attention-driven style\ntransfer framework. Specifically, we propose a style-guided self-attention\nmechanism that conditions self-attention on the reference style by retaining\nthe query of the content image while substituting its key and value with those\nfrom the style image, enabling effective style feature integration. To mitigate\nstyle information loss during inversion, we introduce a style-preserving\ninversion strategy that refines inversion accuracy through multiple resampling\nsteps. Additionally, we propose a content-aware adaptive instance\nnormalization, which integrates content statistics into the normalization\nprocess to optimize style fusion while mitigating the content degradation.\nFurthermore, we introduce a dual-feature cross-attention mechanism to fuse\ncontent and style features, ensuring a harmonious synthesis of structural\nfidelity and stylistic expression. Extensive experiments demonstrate that\nAttenST outperforms existing methods, achieving state-of-the-art performance in\nstyle transfer dataset."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-373",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07077",
    "b_title":[
      "Rule-Based Conflict-Free Decision Framework in Swarm Confrontation"
    ],
    "b_abstract":[
      "Traditional rule-based decision-making methods with interpretable advantage,\nsuch as finite state machine, suffer from the jitter or deadlock(JoD) problems\nin extremely dynamic scenarios. To realize agent swarm confrontation, decision\nconflicts causing many JoD problems are a key issue to be solved. Here, we\npropose a novel decision-making framework that integrates probabilistic finite\nstate machine, deep convolutional networks, and reinforcement learning to\nimplement interpretable intelligence into agents. Our framework overcomes state\nmachine instability and JoD problems, ensuring reliable and adaptable decisions\nin swarm confrontation. The proposed approach demonstrates effective\nperformance via enhanced human-like cooperation and competitive strategies in\nthe rigorous evaluation of real experiments, outperforming other methods."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00019",
    "c_title":[
      "Growth Patterns of Inference"
    ],
    "c_abstract":[
      "What properties of a first-order search space support\/hinder inference? What\nkinds of facts would be most effective to learn? Answering these questions is\nessential for understanding the dynamics of deductive reasoning and creating\nlarge-scale knowledge-based learning systems that support efficient inference.\nWe address these questions by developing a model of how the distribution of\nground facts affects inference performance in search spaces. Experiments\nsuggest that uniform search spaces are suitable for larger KBs whereas search\nspaces with skewed degree distribution show better performance in smaller KBs.\nA sharp transition in Q\/A performance is seen in some cases, suggesting that\nanalysis of the structure of search spaces with existing knowledge should be\nused to guide the acquisition of new ground facts in learning systems."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-374",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00559",
    "b_title":[
      "Modelling the non-linear viscoelastic behaviour of brain tissue in\n  torsion"
    ],
    "b_abstract":[
      "Brain tissue accommodates non-linear deformations and exhibits time-dependent\nmechanical behaviour. The latter is one of the most pronounced features of\nbrain tissue, manifesting itself primarily through viscoelastic effects such as\nstress relaxation. To investigate its viscoelastic behaviour, we performed\nramp-and-hold relaxation tests in torsion on freshly slaughtered cylindrical\novine brain samples ($25\\,\\,\\text{mm}$ diameter and $\\sim 10\\,\\,\\text{mm}$\nheight). The tests were conducted using a commercial rheometer at varying twist\nrates of $\\{40,240,400\\}\\,\\,\\text{rad}\\,\\,\\text{m}^{-1}\\,\\,\\text{s}^{-1}$, with\nthe twist remaining fixed at $\\sim 88\\,\\,\\text{rad}\\,\\,\\text{m}^{-1}$, which\ngenerated two independent datasets for torque and normal force. The complete\nset of viscoelastic material parameters was estimated via a simultaneous fit to\nthe analytical expressions for the torque and normal force predicted by the\nmodified quasi-linear viscoelastic model. The model's predictions were further\nvalidated through finite element simulations in FEniCS. Our results show that\nthe modified quasi-linear viscoelastic model - recently reappraised and largely\nunexploited - accurately fits the experimental data. Moreover, the estimated\nmaterial parameters are in line with those obtained in previous studies on\nbrain samples under torsion. When coupled with bespoke finite element models,\nthese material parameters could enhance our understanding of the forces and\ndeformations involved in traumatic brain injury and contribute to the design of\nimproved headgear for sports such as boxing and motorsports. On the other hand,\nour novel testing protocol offers new insights into the mechanical behaviour of\nsoft tissues other than the brain."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12327",
    "c_title":[
      "Non-reciprocity and multibody interactions in acoustically levitated\n  particle systems: A three body problem"
    ],
    "c_abstract":[
      "In active fluids and active solids the constituents individually generate\nmovement by each extracting energy from their environment or from their own\nsource. Non-reciprocal interactions among these active constituents then enable\nnovel collective behavior that often can be strikingly counterintuitive.\nHowever, non-reciprocity in these cases typically requires that the interacting\nbodies have different physical properties or it needs to be programmed\nexplicitly into all pairwise interactions. Here we show that collective\nactivity in a driven system can emerge spontaneously through multibody\nnonreciprocal forces, even if all bodies are individually non-active and have\nidentical properties. We demonstrate this with as few as three identical\nspheres, acoustically levitated in air, which exhibit collective activity as\nthey interact through non-pairwise forces: similar to the classic gravitational\nthree-body problem, the interaction between two spheres depends sensitively on\nthe relative position of the third sphere. Non-reciprocity arises naturally\nfrom both near-field sound scattering and microstreaming forces among the\nspheres. The underdamped dynamics in air furthermore make it possible to go\nbeyond collective center-of-mass propulsion or rotation and observe internal,\nengine-like reconfigurations that follow limit cycles. These findings open up\nnew possibilities for self-assembly, where now multibody interactions not only\ndetermine the resulting structure but also drive the spontaneously emerging\ndynamics."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-375",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00227",
    "b_title":[
      "AK-SLRL: Adaptive Krylov Subspace Exploration Using Single-Life\n  Reinforcement Learning for Sparse Linear System"
    ],
    "b_abstract":[
      "This paper presents a single-life reinforcement learning (SLRL) approach to\nadaptively select the dimension of the Krylov subspace during the generalized\nminimal residual (GMRES) iteration. GMRES is an iterative algorithm for solving\nlarge and sparse linear systems of equations in the form of \\(Ax = b\\) which\nare mainly derived from partial differential equations (PDEs). The proposed\nframework uses RL to adjust the Krylov subspace dimension (m) in the GMRES (m)\nalgorithm. This research demonstrates that altering the dimension of the Krylov\nsubspace in an online setup using SLRL can accelerate the convergence of the\nGMRES algorithm by more than an order of magnitude. A comparison of different\nmatrix sizes and sparsity levels is performed to demonstrate the effectiveness\nof adaptive Krylov subspace exploration using single-life RL (AK-SLRL). We\ncompare AK-SLRL with constant-restart GMRES by applying the highest restart\nvalue used in AK-SLRL to the GMRES method. The results show that using an\nadjustable restart parameter with single-life soft-actor critic (SLSAC) and an\nexperience replay buffer sized to half the matrix dimension converges\nsignificantly faster than the constant restart GMRES with higher values. Higher\nvalues of the restart parameter are equivalent to a higher number of Arnoldi\niterations to construct an orthonormal basis for the Krylov subspace $ K_m(A,\nr_0) $. This process includes constructing $m$ orthonormal vectors and updating\nthe Hessenberg matrix $H$. Therefore, lower values of $m$ result in reduced\ncomputation needed in GMRES minimization to solve the least-squares problem in\nthe smaller Hessenberg matrix. The robustness of the result is validated\nthrough a wide range of matrix dimensions and sparsity. This paper contributes\nto the series of RL combinations with numerical solvers to achieve accelerated\nscientific computing."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10185",
    "c_title":[
      "Modeling the drying process in hard carbon electrodes based on the\n  phase-field method"
    ],
    "c_abstract":[
      "The present work addresses the simulation of pore emptying during the drying\nof battery electrodes. For this purpose, a model based on the multiphase-field\nmethod (MPF) is used, since it is an established approach for modeling and\nsimulating multiphysical problems. A model based on phase fields is introduced\nthat takes into account fluid flow, capillary effects, and wetting behavior,\nall of which play an important role in drying. In addition, the MPF makes it\npossible to track the movement of the liquid-air interface without\ncomputationally expensive adaptive mesh generation. The presented model is used\nfor the first time to investigate pore emptying in real hard carbon\nmicrostructures. For this purpose, the microstructures of real dried electrodes\nare used as input for the simulations. The simulations performed here\ndemonstrate the importance of considering the resolved microstructural\ninformation compared to models that rely only on statistical geometry\nparameters such as pore size distributions. The influence of various parameters\nsuch as different microstructures, fluid viscosity, and the contact angle on\npore emptying are investigated. In addition, this work establishes a\ncorrelation between the capillary number and the breakthrough time of the\nsolvent as well as the height difference of the solvent front at the time of\nbreakthrough. The results indicate that the drying process can be optimized by\ndoping the particle surface, which changes the contact angle between the fluids\nand the particles."
    ],
    "c_categories":[
      [
        "cs.CE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-376",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04966",
    "b_title":[
      "Hitchin fibrations are Ng\\^{o} fibrations"
    ],
    "b_abstract":[
      "We study the geometry of the Hitchin fibration for $\\mathcal{L}$-valued\n$G$-Higgs bundles over a smooth projective curve of genus $g$, where $G$ is a\nreductive group and $\\mathcal{L}$ is a suitably positive line bundle. We show\nthat the Hitchin fibration admits the structure of a weak Abelian fibration. In\nthe case when the line bundle $\\mathcal{L}$ is a twist of the canonical bundle\nof the curve by a (possibly empty) reduced effective divisor, we prove a\ncohomological bound and $\\delta$-regularity of the weak Abelian fibration."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.19223",
    "c_title":[
      "On a theorem of Harder"
    ],
    "c_abstract":[
      "We prove that for any simply connected isotropic reductive group G over a\nDedekind domain D, any Zariski-locally trivial principal G-bundle over D is\ntrivial. The corresponding result for quasi-split groups was proved in 1967 by\nG. Harder."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-377",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16210",
    "b_title":[
      "New Frontiers in Fighting Misinformation"
    ],
    "b_abstract":[
      "Despite extensive research and development of tools and technologies for\nmisinformation tracking and detection, we often find ourselves largely on the\nlosing side of the battle against misinformation. In an era where\nmisinformation poses a substantial threat to public discourse, trust in\ninformation sources, and societal and political stability, it is imperative\nthat we regularly revisit and reorient our work strategies. While we have made\nsignificant strides in understanding how and why misinformation spreads, we\nmust now broaden our focus and explore how technology can help realise new\napproaches to address this complex challenge more efficiently."
    ],
    "b_categories":[
      [
        "cs.SI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01038",
    "c_title":[
      "Analyzing Social Media Engagement of Computer Science Conferences"
    ],
    "c_abstract":[
      "Context: X, formerly known as Twitter, is one of the largest social media\nplatforms and has been widely used for communication during research\nconferences. While previous studies have examined how users engage with X\nduring these events, limited research has focused on analyzing the content\nposted by computer science conferences. Objective: This study investigates how\nconferences from different areas of computer science perform on social media by\nanalyzing their activity, follower engagement, and the content posted on X.\nMethod: We collect posts from 22 computer science conferences and conduct\nstatistical experiments to identify variations in content. Additionally, we\nperform a manual analysis of the top five posts for each engagement metric.\nResults: Our findings indicate statistically significant differences in\ncategory, sentiment, and post length across computer science conference posts.\nAmong all engagement metrics, likes were the most common way users interacted\nwith conference content. Conclusion: This study provides insights into the\nsocial media presence of computer science conferences, highlighting key\ndifferences in content, sentiment, and engagement patterns across different\nvenues."
    ],
    "c_categories":[
      [
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-378",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12234",
    "b_title":[
      "Multi-Agent Feedback Motion Planning using Probably Approximately\n  Correct Nonlinear Model Predictive Control"
    ],
    "b_abstract":[
      "For many tasks, multi-robot teams often provide greater efficiency,\nrobustness, and resiliency. However, multi-robot collaboration in real-world\nscenarios poses a number of major challenges, especially when dynamic robots\nmust balance competing objectives like formation control and obstacle avoidance\nin the presence of stochastic dynamics and sensor uncertainty. In this paper,\nwe propose a distributed, multi-agent receding-horizon feedback motion planning\napproach using Probably Approximately Correct Nonlinear Model Predictive\nControl (PAC-NMPC) that is able to reason about both model and measurement\nuncertainty to achieve robust multi-agent formation control while navigating\ncluttered obstacle fields and avoiding inter-robot collisions. Our approach\nrelies not only on the underlying PAC-NMPC algorithm but also on a terminal\ncost-function derived from gyroscopic obstacle avoidance. Through numerical\nsimulation, we show that our distributed approach performs on par with a\ncentralized formulation, that it offers improved performance in the case of\nsignificant measurement noise, and that it can scale to more complex dynamical\nsystems."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01251",
    "c_title":[
      "Catching Spinning Table Tennis Balls in Simulation with End-to-End\n  Curriculum Reinforcement Learning"
    ],
    "c_abstract":[
      "The game of table tennis is renowned for its extremely high spin rate, but\nmost table tennis robots today struggle to handle balls with such rapid spin.\nTo address this issue, we have contributed a series of methods, including: 1.\nCurriculum Reinforcement Learning (RL): This method helps the table tennis\nrobot learn to play table tennis progressively from easy to difficult tasks. 2.\nAnalysis of Spinning Table Tennis Ball Collisions: We have conducted a\nphysics-based analysis to generate more realistic trajectories of spinning\ntable tennis balls after collision. 3. Definition of Trajectory States: The\ndefinition of trajectory states aids in setting up the reward function. 4.\nSelection of Valid Rally Trajectories: We have introduced a valid rally\ntrajectory selection scheme to ensure that the robot's training is not\ninfluenced by abnormal trajectories. 5. Reality-to-Simulation (Real2Sim)\nTransfer: This scheme is employed to validate the trained robot's ability to\nhandle spinning balls in real-world scenarios. With Real2Sim, the deployment\ncosts for robotic reinforcement learning can be further reduced. Moreover, the\ntrajectory-state-based reward function is not limited to table tennis robots;\nit can be generalized to a wide range of cyclical tasks. To validate our\nrobot's ability to handle spinning balls, the Real2Sim experiments were\nconducted. For the specific video link of the experiment, please refer to the\nsupplementary materials."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-379",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16014",
    "b_title":[
      "Spatial-Angular Representation Learning for High-Fidelity Continuous\n  Super-Resolution in Diffusion MRI"
    ],
    "b_abstract":[
      "Diffusion magnetic resonance imaging (dMRI) often suffers from low spatial\nand angular resolution due to inherent limitations in imaging hardware and\nsystem noise, adversely affecting the accurate estimation of microstructural\nparameters with fine anatomical details. Deep learning-based super-resolution\ntechniques have shown promise in enhancing dMRI resolution without increasing\nacquisition time. However, most existing methods are confined to either spatial\nor angular super-resolution, limiting their effectiveness in capturing detailed\nmicrostructural features. Furthermore, traditional pixel-wise loss functions\nstruggle to recover intricate image details essential for high-resolution\nreconstruction. To address these challenges, we propose SARL-dMRI, a novel\nSpatial-Angular Representation Learning framework for high-fidelity, continuous\nsuper-resolution in dMRI. SARL-dMRI explores implicit neural representations\nand spherical harmonics to model continuous spatial and angular\nrepresentations, simultaneously enhancing both spatial and angular resolution\nwhile improving microstructural parameter estimation accuracy. To further\npreserve image fidelity, a data-fidelity module and wavelet-based frequency\nloss are introduced, ensuring the super-resolved images remain consistent with\nthe original input and retain fine details. Extensive experiments demonstrate\nthat, compared to five other state-of-the-art methods, our method significantly\nenhances dMRI data resolution, improves the accuracy of microstructural\nparameter estimation, and provides better generalization capabilities. It\nmaintains stable performance even under a 45$\\times$ downsampling factor."
    ],
    "b_categories":[
      [
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13989",
    "c_title":[
      "Erasing with Precision: Evaluating Specific Concept Erasure from\n  Text-to-Image Generative Models"
    ],
    "c_abstract":[
      "Studies have been conducted to prevent specific concepts from being generated\nfrom pretrained text-to-image generative models, achieving concept erasure in\nvarious ways. However, the performance evaluation of these studies is still\nlargely reliant on visualization, with the superiority of studies often\ndetermined by human subjectivity. The metrics of quantitative evaluation also\nvary, making comprehensive comparisons difficult. We propose EraseEval, an\nevaluation method that differs from previous evaluation methods in that it\ninvolves three fundamental evaluation criteria: (1) How well does the prompt\ncontaining the target concept be reflected, (2) To what extent the concepts\nrelated to the erased concept can reduce the impact of the erased concept, and\n(3) Whether other concepts are preserved. These criteria are evaluated and\nintegrated into a single metric, such that a lower score is given if any of the\nevaluations are low, leading to a more robust assessment. We experimentally\nevaluated baseline concept erasure methods, organized their characteristics,\nand identified challenges with them. Despite being fundamental evaluation\ncriteria, some concept erasure methods failed to achieve high scores, which\npoint toward future research directions for concept erasure methods. Our code\nis available at https:\/\/github.com\/fmp453\/erase-eval."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-380",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08052",
    "b_title":[
      "Search for the production of Higgs-portal scalar bosons in the NuMI beam\n  using the MicroBooNE detector"
    ],
    "b_abstract":[
      "We present the strongest limits to date on the mixing angle, $\\theta$, with\nwhich a new scalar particle, $S$, mixes with the Higgs field in the mass range\n$100$ $MeV<m_S<155$ MeV. This result uses the MicroBooNE liquid argon time\nprojection chamber to search for decays of these Higgs-portal scalar particles\nthrough the $S\\rightarrow e^+e^-$ channel with the decays of kaons in the NuMI\nneutrino beam acting as the source of the scalar particles. The analysis uses\nan exposure of $7.01\\times 10^{20}$ protons on target of NuMI beam data\nincluding a period when the beam focusing system was configured to focus\npositively charged hadrons and a separate period when negatively charged\nhadrons were focused. The analysis searches for scalar particles produced from\nkaons decaying in flight in the beam's decay volume and at rest in the target\nand absorber. At $m_S=125$ MeV ($m_S=150$ MeV$)$ we set a limit of\n$\\theta<2.65\\times 10^{-4}$ ($\\theta<1.72\\times 10^{-4}$) at the 95$\\%$\nconfidence level."
    ],
    "b_categories":[
      [
        "hep-ex"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.15464",
    "c_title":[
      "The 200 Gbps Challenge: Imagining HL-LHC analysis facilities"
    ],
    "c_abstract":[
      "The IRIS-HEP software institute, as a contributor to the broader HEP Python\necosystem, is developing scalable analysis infrastructure and software tools to\naddress the upcoming HL-LHC computing challenges with new approaches and\nparadigms, driven by our vision of what HL-LHC analysis will require. The\ninstitute uses a \"Grand Challenge\" format, constructing a series of\nincreasingly large, complex, and realistic exercises to show the vision of\nHL-LHC analysis. Recently, the focus has been demonstrating the IRIS-HEP\nanalysis infrastructure at scale and evaluating technology readiness for\nproduction.\n  As a part of the Analysis Grand Challenge activities, the institute executed\na \"200 Gbps Challenge\", aiming to show sustained data rates into the event\nprocessing of multiple analysis pipelines. The challenge integrated teams\ninternal and external to the institute, including operations and facilities,\nanalysis software tools, innovative data delivery and management services, and\nscalable analysis infrastructure. The challenge showcases the prototypes -\nincluding software, services, and facilities - built to process around 200 TB\nof data in both the CMS NanoAOD and ATLAS PHYSLITE data formats with test\npipelines.\n  The teams were able to sustain the 200 Gbps target across multiple pipelines.\nThe pipelines focusing on event rate were able to process at over 30 MHz. These\ntarget rates are demanding; the activity revealed considerations for future\ntesting at this scale and changes necessary for physicists to work at this\nscale in the future. The 200 Gbps Challenge has established a baseline on\ntoday's facilities, setting the stage for the next exercise at twice the scale."
    ],
    "c_categories":[
      [
        "hep-ex"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-381",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01310",
    "b_title":[
      "Systematic Search for Long-Term Trends in Fermi-LAT Jetted Active\n  Galactic Nuclei"
    ],
    "b_abstract":[
      "Jetted Active Galactic Nuclei (AGN) exhibit variability across a wide range\nof time scales. Traditionally, this variability can often be modeled well as a\nstochastic process. However, in certain cases, jetted AGN variability displays\nregular patterns, enabling us to conduct investigations aimed at understanding\nits origins. Additionally, a novel type of variability has emerged in jetted\nAGN lightcurves, specifically, the observation of a long-term trend\ncharacterized by a linear increase of the flux with time in blazars such as PG\n1553+113, which is among the objects most likely to display periodic behavior.\nIn this paper, we present the results of a systematic search for long-term\ntrends, spanning $\\approx$10\\, years, utilizing 12 years of Fermi-LAT\nobservations. The study is focused on detecting the presence of linear or\nquadratic long-term trends in a sample of 3308 jetted AGN. Our analysis has\nidentified 40 jetted AGN that exhibit long-term trends, each with distinct\nproperties, which we also characterize in this study. These long-term trends\nmay originate from the dynamics of a supermassive black hole binary system, or\nthey could be the result of intrinsic phenomena within the jet itself. Our\nfindings can help in addressing questions pertaining to the astrophysical\norigins of variability and periodicity within jetted AGN."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07450",
    "c_title":[
      "Probing Dark Photons through Gravitational Decoupling of Mass-State\n  Oscillations in Interstellar Media"
    ],
    "c_abstract":[
      "We propose a novel mechanism for photon-dark photon mass state oscillations\nmediated by gravitational separation during propagation through the\ninterstellar medium. This phenomenon establishes a new avenue for the detection\nof dark matter. By analyzing gravitational lensing data from quasars, we\ninvestigate the sensitivity of this approach to dark photons. Our analysis\ndemonstrates constraints of$\\epsilon<10^-2$ in the dark photon mass range of\n$10^{-14}eV$. Furthermore, we propose potential applications of this mechanism\nto astrophysical systems with strong gravitational fields, such as neutron\nstars and black hole accretion disks."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-382",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12140",
    "b_title":[
      "Decay estimate for subcritical semilinear damped wave equations with\n  slowly decreasing data"
    ],
    "b_abstract":[
      "We study the decay properties of non-negative solutions to the\none-dimensional defocusing damped wave equation in the Fujita subcritical case\nunder a specific initial condition. Specifically, we assume that the initial\ndata are positive, satisfy a condition ensuring the positiveness of solutions,\nand exhibit polynomial decay at infinity.\n  To show the decay properties of the solution, we construct suitable\nsupersolutions composed of an explicit function satisfying an ordinary\ndifferential inequality and the solution of the linear damped wave equation.\nOur estimates correspond to the optimal ones inferred from the analysis of the\nheat equation."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.05579",
    "c_title":[
      "On stabilization at a soliton for generalized Korteweg--De Vries pure\n  power equation for any power $p\\in (1,5)$"
    ],
    "c_abstract":[
      "We apply our idea, which previously we used in the analysis of the pure power\nNLS, consisting in spitting the virial inequality method into a large energy\ninequality combined with Kato smoothing, to the case of generalized\nKorteweg--De Vries pure power equations. We assume that a solution remains for\nall positive times very close to a soliton and then we prove an asymptotic\nstability result for $t\\to +\\infty$."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-383",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04306",
    "b_title":[
      "EP240801a\/XRF 240801B: An X-ray Flash Detected by the Einstein Probe and\n  Implications of its Multiband Afterglow"
    ],
    "b_abstract":[
      "We present multiband observations and analysis of EP240801a, a low-energy,\nextremely soft gamma-ray burst (GRB) discovered on August 1, 2024 by the\nEinstein Probe (EP) satellite, with a weak contemporaneous signal also detected\nby Fermi\/GBM. Optical spectroscopy of the afterglow, obtained by GTC and Keck,\nidentified the redshift of $z = 1.6734$. EP240801a exhibits a burst duration of\n148 s in X-rays and 22.3 s in gamma-rays, with X-rays leading by 80.61 s.\nSpectral lag analysis indicates the gamma-ray signal arrived 8.3 s earlier than\nthe X-rays. Joint spectral fitting of EP\/WXT and Fermi\/GBM data yields an\nisotropic energy $E_{\\gamma,\\rm{iso}} = (5.57^{+0.54}_{-0.50})\\times\n10^{51}\\,\\rm{erg}$, a peak energy $E_{\\rm{peak}} =\n14.90^{+7.08}_{-4.71}\\,\\rm{keV}$, a fluence ratio $\\rm\nS(25-50\\,\\rm{keV})\/S(50-100\\,\\rm{keV}) = 1.67^{+0.74}_{-0.46}$, classifying\nEP240801a as an X-ray flash (XRF). The host-galaxy continuum spectrum, inferred\nusing Prospector, was used to correct its contribution for the observed\noutburst optical data. Unusual early $R$-band behavior and EP\/FXT observations\nsuggest multiple components in the afterglow. Three models are considered:\ntwo-component jet model, forward-reverse shock model and forward-shock model\nwith energy injection. Both three provide reasonable explanations. The\ntwo-component jet model and the energy injection model imply a relatively small\ninitial energy and velocity of the jet in the line of sight, while the\nforward-reverse shock model remains typical. Under the two-component jet model,\nEP240801a may resemble GRB 221009A (BOAT) if the bright narrow beam is viewed\non-axis. Therefore, EP240801a can be interpreted as an off-beam (narrow) jet or\nan intrinsically weak GRB jet. Our findings provide crucial clues for\nuncovering the origin of XRFs."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.01150",
    "c_title":[
      "Deciphering the Multi-Wavelength Flares of the Most Distant Very\n  High-Energy (>100 GeV) Gamma-ray Emitting Blazar"
    ],
    "c_abstract":[
      "This study analyzes the multi-wavelength flaring activity of the distant flat\nspectrum radio quasar (FSRQ) OP 313 (z=0.997) during November 2023 to March\n2024, using data from Fermi-Large Area Telescope, Swift X-ray Telescope, and\nUltraviolet and Optical Telescope. The analysis highlights two significant very\nhigh energy(VHE) detection epochs and GeV gamma-ray flaring episodes, providing\ninsight into jet emission processes and radiative mechanisms. Key findings\ninclude broadband spectral energy distribution (SED) evolution, including\nenigmatic X-ray spectral changes. Modeling of the multi-wavelength SED with a\none-zone leptonic radiative processes attributes the emissions to synchrotron\nradiation, Synchrotron Self-Compton (SSC), and External Compton (EC)\nmechanisms, with torus photons as the primary source for EC processes. The\nresults suggest that the gamma-ray emitting region lies outside the broad-line\nregion but within the dusty torus. Furthermore, we find that the radiated power\nis significantly smaller than the total jet power, suggesting that most of the\nbulk energy remains within the jet even after passing through the blazar\nemission zone. These findings advance our understanding of particle\nacceleration, jet dynamics, and photon field interactions in FSRQs."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-384",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01975",
    "b_title":[
      "Pseudo-Cartan Inclusions"
    ],
    "b_abstract":[
      "We define a new class of regular inclusions, the pseudo-Cartan inclusions. We\nshow this class coincides with the class of regular inclusions having a Cartan\nenvelope and also with the class of regular inclusions with the faithful unique\npseudo-expectation property. We describe the twisted groupoid associated with\nthe Cartan envelope of a pseudo-Cartan inclusion. These results significantly\nextend previous results obtained for the unital setting.\n  We explore properties of pseudo-Cartan inclusions and the relationship\nbetween a pseudo-Cartan inclusion and its Cartan envelope. For example, if $D\n\\subseteq C$ is a pseudo-Cartan inclusion with Cartan envelope $B \\subseteq A$,\nthen $C$ is simple if and only if $A$ is simple. We show how to construct\npseudo-Cartan inclusions from a given Cartan inclusion, that the inductive\nlimit of pseudo-Cartan inclusions with suitable connecting maps is a\npseudo-Cartan inclusion, and the minimal tensor product of pseudo-Cartan\ninclusions is a pseudo-Cartan inclusion. Further, we describe the Cartan\nenvelope of pseudo-Cartan inclusions arising from these constructions. We give\nsome applications and conclude with a few open questions."
    ],
    "b_categories":[
      [
        "math.OA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.07756",
    "c_title":[
      "A Pile of Shifts II: Structure and K-Theory"
    ],
    "c_abstract":[
      "We discuss C$^*$-algebras associated with several different natural shifts on\nthe Hilbert space of the $s$-adic tree, continuing the analysis from\n\\cite{HKMP3} and in particular we describe their structure and compute the\n$K$-Theory groups."
    ],
    "c_categories":[
      [
        "math.OA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-385",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03475",
    "b_title":[
      "Calculation of a force effect from muscle action to a quaternion-based\n  musculoskeletal model"
    ],
    "b_abstract":[
      "Euler angle representation in biomechanical analysis allows straightforward\ndescription of joints rotations. However, application of Euler angles could be\nlimited due to singularity called gimbal lock. Quaternions offer an alternative\nway to describe rotations but they have been mostly avoided in biomechanics as\nthey are complex and not inherently intuitive, specifically in dynamic models\nactuated by muscles. This study introduces a mathematical framework for\ndescribing muscle actions in dynamic quaternion-based musculoskeletal\nsimulations. The proposed method estimates muscle torques in quaternion-based\nmusculoskeletal model. Its application is shown on three-dimensional\ndouble-pendulum system actuated by muscle elements. Furthermore, transformation\nof muscle moment arms obtained from muscle paths based on Euler angles into\nquaternions description is presented. The proposed method is advantageous for\ndynamic modeling of musculoskeletal models with complex kinematics and large\nrange of motion like the shoulder joint."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.11171",
    "c_title":[
      "Design and Fabrication of Low Cost Cardiopulmonary Resuscitaion Device |\n  A Novel Mechatronics System"
    ],
    "c_abstract":[
      "Cardiac arrest is very common nowadays. Sudden heart attack is a condition\nwhere the heart suddenly stops beating causing a significant decrease in blood\nflow to the brain. The first step in medical point of view is for a patient\nexperiencing sudden heart attack is Cardiopulmonary Resuscitation\n(CPR).Moreover, compression rate needed for CPR process is far beyond for\nhumans to provide manually. So, there is intense need of mechanical device\nwhich can perform resuscitation. Cardiopulmonary resuscitation device is used\nto augment the blood flow and maintain hemodynamic cycle of human body. CPR\ndevice is proposed to meet the effective and unique blood flow mechanism,\nfeedback system. In term of effective and unique blood flow mechanism design\nand fabrication of low cost cardiopulmonary resuscitation device based on\nprinciple of CPR and two concepts. It is combined Sterno-Thoracic\nCardiopulmonary Resuscitation. The \"cardiac pump\" generates blood flow by\nsqueezing blood out of the heart as the sternum is depressed. The \"thoracic\npump\" increases intrathoracic pressure due to elastic recoil of ribs. In order\nto meet the American Heart Association standard guidelines a feedback system\nhas established through closed loop control system, and integration of\nprocessing controllers. Specifically, a small HMI (Human machine interface)\ndevice has been established to control the whole mechanism which would be used\nfor child, Adults and Senior citizens as a manual intelligence system.\nHenceforth, feedback system act as backbone for this device."
    ],
    "c_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-386",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07801",
    "b_title":[
      "Field-enhancement and nonlocal effects in epsilon-near-zero photonic gap\n  antennas"
    ],
    "b_abstract":[
      "In recent years, the large electric field enhancement and tight spatial\nconfinement supported by the so-called epsilon near-zero (ENZ) mode has\nattracted significant attention for the realization of efficient nonlinear\noptical devices. Here, we experimentally demonstrate ENZ photonic gap antennas\n(PGAs), which consist of a dielectric pillar within which a thin slab of indium\ntin oxide (ITO) material is embedded. In ENZ PGAs, hybrid dielectric-ENZ modes\nemerge from strong coupling between the dielectric antenna modes and the ENZ\nbulk plasmon resonance. These hybrid modes efficiently couple to free space and\nallow for large enhancements of the incident electric field over nearly an\noctave bandwidth, without the stringent lateral nanofabrication requirements of\nconventional plasmonic or dielectric nanoantennas. To understand the modal\nfeatures, we probe the linear response of single ENZ PGAs with dark field\nscattering and interpret the results in terms of a simple coupled oscillator\nframework. Third harmonic generation (THG) is used to probe the ITO local\nfields and large enhancements are observed in the THG efficiency over a broad\nspectral range. Surprisingly, sharp peaks emerge on top of the nonlinear\nresponse, which were not predicted by full wave calculations. These peaks are\nattributed to the ENZ material's nonlocal response, which once included using a\nhydrodynamic model for the ITO permittivity improves the agreement of our\ncalculations for both the linear and nonlinear response. This proof of concept\ndemonstrates the potential of ENZ PGAs, which we have previously shown can\nsupport electric field enhancements of up to 100--200X, and the importance of\nincluding nonlocal effects when describing the response of thin ENZ layers.\nImportantly, inclusion of the ITO nonlocality leads to increases in the\npredicted field enhancement, as compared to the local calculation."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12723",
    "c_title":[
      "Energy stability of supercontinuum via femtosecond filamentation in\n  sapphire"
    ],
    "c_abstract":[
      "The energy stability of supercontinuum (SC) significantly impacts its\napplications. To achieve the most stable SC, we systematically investigated how\ninput pulse energy, numerical aperture (NA), and crystal thickness affect the\nenergy stability of SC generated by femtosecond filamentation in sapphire. Our\nfindings reveal that the SC energy does not always increase monotonically with\ninput energy for different NA and thicknesses. This phenomenon occurs because,\nwhen the input pulse energy just exceeds the filamentation threshold, the pulse\nsplitting structure and spectrum are still rapidly evolving. To generate a more\nstable SC, the numerical aperture and crystal thickness must be carefully\ncoordinated to prevent this rapid evolution from occurring within the crystal."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-387",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13786",
    "b_title":[
      "Uncertainty Principle, annihilating pairs and Fourier restriction"
    ],
    "b_abstract":[
      "Let $G$ be a locally compact abelian group, and let $\\widehat{G}$ denote its\ndual group, equipped with a Haar measure. A variant of the uncertainty\nprinciple states that for any $S \\subset G$ and $\\Sigma \\subset \\widehat{G}$,\nthere exists a constant $C(S, \\Sigma)$ such that for any $f \\in L^2(G)$, the\nfollowing inequality holds: \\[\\|f\\|_{L^2(G)} \\leq C(S, \\Sigma) \\bigl(\n\\|f\\|_{L^2(G \\setminus S)} + \\|\\widehat{f}\\|_{L^2(\\widehat{G} \\setminus\n\\Sigma)} \\bigr),\\] where $\\widehat{f}$ denotes the Fourier transform of $f$.\nThis variant of the uncertainty principle is particularly useful in\napplications such as signal processing and control theory.The purpose of this\npaper is to show that such estimates can be strengthened when $S$ or $\\Sigma$\nsatisfies a restriction theorem and to provide an estimate for the constant\n$C(S, \\Sigma)$. This result serves as a quantitative counterpart to a recent\nfinding by the first and last author. In the setting of finite groups, the\nresults also extend those of Matolcsi-Sz\\\"ucs and Donoho-Stark."
    ],
    "b_categories":[
      [
        "math.CA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.17448",
    "c_title":[
      "Meyer wavelets for rational dilations"
    ],
    "c_abstract":[
      "We show the existence of smooth band-limited multiresolution analysis (MRA)\nfor any expansive dilation with real entries in any spatial dimension. We then\nprove the existence of orthonormal Meyer wavelets, which have smooth and\ncompactly supported Fourier transform, for any expansive dilation with rational\nentries and any spatial dimension. This extends one dimensional results of\nAuscher. In a converse direction, we show that well-localized orthogonal MRA\nwavelets, such as Meyer wavelets, can only exist for expansive dilations with\nrational entries. This shows the optimality of our existence result and extends\none dimensional result of Lemari\\'e-Rieusset."
    ],
    "c_categories":[
      [
        "math.CA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-388",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11008",
    "b_title":[
      "CounterBench: A Benchmark for Counterfactuals Reasoning in Large\n  Language Models"
    ],
    "b_abstract":[
      "Counterfactual reasoning is widely recognized as one of the most challenging\nand intricate aspects of causality in artificial intelligence. In this paper,\nwe evaluate the performance of large language models (LLMs) in counterfactual\nreasoning. In contrast to previous studies that primarily focus on commonsense\ncausal reasoning, where LLMs often rely on prior knowledge for inference, we\nspecifically assess their ability to perform counterfactual inference using a\nset of formal rules. To support this evaluation, we introduce a new benchmark\ndataset, CounterBench, comprising 1K counterfactual reasoning questions. The\ndataset is designed with varying levels of difficulty, diverse causal graph\nstructures, distinct types of counterfactual questions, and multiple\nnonsensical name variants. Our experiments demonstrate that counterfactual\nreasoning poses a significant challenge for LLMs, with most models performing\nat levels comparable to random guessing. To enhance LLM's counterfactual\nreasoning ability, we propose a novel reasoning paradigm, CoIn, which guides\nLLMs through iterative reasoning and backtracking to systematically explore\ncounterfactual solutions. Experimental results show that our method\nsignificantly improves LLM performance on counterfactual reasoning tasks and\nconsistently enhances performance across different LLMs.Our dataset is\navailable at https:\/\/huggingface.co\/datasets\/CounterBench\/CounterBench."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11177",
    "c_title":[
      "The Mirage of Model Editing: Revisiting Evaluation in the Wild"
    ],
    "c_abstract":[
      "Despite near-perfect results in artificial evaluations, the effectiveness of\nmodel editing in real-world applications remains unexplored. To bridge this\ngap, we propose to study model editing in question answering (QA) by\nestablishing a rigorous evaluation practice to assess the effectiveness of\nediting methods in correcting LLMs' errors. It consists of QAEdit, a new\nbenchmark derived from popular QA datasets, and a standardized evaluation\nframework. Our single editing experiments indicate that current editing methods\nperform substantially worse than previously reported (38.5% vs. ~96%). Through\nmodule analysis and controlled experiments, we demonstrate that this\nperformance decline stems from issues in evaluation practices of prior editing\nresearch. One key issue is the inappropriate use of teacher forcing in testing\nprevents error propagation by feeding ground truth tokens (inaccessible in\nreal-world scenarios) as input. Furthermore, we simulate real-world deployment\nby sequential editing, revealing that current approaches fail drastically with\nonly 1000 edits. Our analysis provides a fundamental reexamination of both the\nreal-world applicability of existing model editing methods and their evaluation\npractices, and establishes a rigorous evaluation framework with key insights to\nadvance reliable and practical model editing research."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-389",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12853",
    "b_title":[
      "Data-and-Semantic Dual-Driven Spectrum Map Construction for 6G Spectrum\n  Management"
    ],
    "b_abstract":[
      "Spectrum maps reflect the utilization and distribution of spectrum resources\nin the electromagnetic environment, serving as an effective approach to support\nspectrum management. However, the construction of spectrum maps in urban\nenvironments is challenging because of high-density connection and complex\nterrain. Moreover, the existing spectrum map construction methods are typically\napplied to a fixed frequency, which cannot cover the entire frequency band. To\naddress the aforementioned challenges, a UNet-based data-and-semantic\ndual-driven method is proposed by introducing the semantic knowledge of binary\ncity maps and binary sampling location maps to enhance the accuracy of spectrum\nmap construction in complex urban environments with dense communications.\nMoreover, a joint frequency-space reasoning model is exploited to capture the\ncorrelation of spectrum data in terms of space and frequency, enabling the\nrealization of complete spectrum map construction without sampling all\nfrequencies of spectrum data. The simulation results demonstrate that the\nproposed method can infer the spectrum utilization status of missing\nfrequencies and improve the completeness of the spectrum map construction.\nFurthermore, the accuracy of spectrum map construction achieved by the proposed\ndata-and-semantic dual-driven method outperforms the benchmark schemes,\nespecially in scenarios with low sampling density."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17727",
    "c_title":[
      "Sparse Autoencoders Can Interpret Randomly Initialized Transformers"
    ],
    "c_abstract":[
      "Sparse autoencoders (SAEs) are an increasingly popular technique for\ninterpreting the internal representations of transformers. In this paper, we\napply SAEs to 'interpret' random transformers, i.e., transformers where the\nparameters are sampled IID from a Gaussian rather than trained on text data. We\nfind that random and trained transformers produce similarly interpretable SAE\nlatents, and we confirm this finding quantitatively using an open-source\nauto-interpretability pipeline. Further, we find that SAE quality metrics are\nbroadly similar for random and trained transformers. We find that these results\nhold across model sizes and layers. We discuss a number of number interesting\nquestions that this work raises for the use of SAEs and auto-interpretability\nin the context of mechanistic interpretability."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-390",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07104",
    "b_title":[
      "Uncertainty Quantification for Misspecified Machine Learned Interatomic\n  Potentials"
    ],
    "b_abstract":[
      "The use of high-dimensional regression techniques from machine learning has\nsignificantly improved the quantitative accuracy of interatomic potentials.\nAtomic simulations can now plausibly target quantitative predictions in a\nvariety of settings, which has brought renewed interest in robust means to\nquantify uncertainties on simulation results. In many practical settings,\nencompassing both classical and a large class of machine learning potentials,\nthe dominant form of uncertainty is currently not due to lack of training data\nbut to misspecification, namely the inability of any one choice of model\nparameters to exactly match all ab initio training data. However, Bayesian\ninference, the most common formal tool used to quantify uncertainty, is known\nto ignore misspecification and thus significantly underestimates parameter\nuncertainties. Here, we employ a recent misspecification-aware regression\ntechnique to quantify parameter uncertainties, which is then propagated to a\nbroad range of phase and defect properties in tungsten via brute force\nresampling or implicit differentiation. The propagated misspecification\nuncertainties robustly envelope errors to direct \\textit{ab initio} calculation\nof material properties outside of the training dataset, an essential\nrequirement for any quantitative multi-scale modeling scheme. Finally, we\ndemonstrate application to recent foundational machine learning interatomic\npotentials, accurately predicting and bounding errors in MACE-MPA-0 energy\npredictions across the diverse materials project database. Perspectives for the\napproach in multiscale simulation workflows are discussed."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07515",
    "c_title":[
      "Magnetic Domain Suppression in Fe\/Si Multilayers with 11B4C Integration\n  for Polarizing Neutron Optics"
    ],
    "c_abstract":[
      "This study explores the impact of boron carbide (B4C) addition on magnetic\ndomains within Fe\/Si multilayers through off-specular neutron scattering with\npolarization analysis. The incorporation of B4C induces amorphization in\nlayers, disrupting magnetic domain structures. Analysis of the scattering\npatterns reveals that magnetic domains in pure Fe\/Si multilayers exhibit no\nsignificant correlation between layers, resulting in a specific diffuse\noff-specular scattering signal, while the B4C incorporated Fe\/Si multilayers\nrevealed no diffuse off-specular scattering. We offer a qualitative\ninterpretation of these scattering phenomena and accurately model the observed\ndiffuse patterns using the distorted wave Born approximation. Low-energy\n{\\mu}+SR measurements further reveal that local magnetic fields in Fe\/Si and\nFe\/Si + B4C multilayers are more easily manipulated by external fields in\nB4C-containing layers, with enhanced field uniformity in the muon length-scale.\nOur findings provide insights into the role of B4C in altering magnetic domain\narrangements within Fe\/Si multilayers, contributing to advances in the design\nof magnetic materials and neutron polarization coatings."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-391",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10529",
    "b_title":[
      "A Fractal Dirac Eigenvalue Problem: Spectral Properties and Numerical\n  Examples"
    ],
    "b_abstract":[
      "In this paper, we study a Dirac boundary value problem where the operator is\nconsidered with a derivative of order $\\alpha \\in (0, 1]$, known as the\n$F^{\\alpha}$-derivative. We prove some spectral properties of eigenvalues and\neigenfunctions and present numerical examples to demonstrate the practical\nimplications of our approach."
    ],
    "b_categories":[
      [
        "math.SP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.19914",
    "c_title":[
      "On the Spectral Analysis of Power Graph of Dihedral Groups"
    ],
    "c_abstract":[
      "The power graph \\( \\mathcal{G}_G \\) of a group \\( G \\) is a graph whose\nvertex set is \\( G \\), and two elements \\( x, y \\in G \\) are adjacent if one is\nan integral power of the other. In this paper, we determine the adjacency,\nLaplacian, and signless Laplacian spectra of the power graph of the dihedral\ngroup \\( D_{2pq} \\), where \\( p \\) and \\( q \\) are distinct primes. Our\nfindings demonstrate that the results of Romdhini et al. [2024], published in\nthe \\textit{European Journal of Pure and Applied Mathematics}, do not hold\nuniversally for all \\( n \\geq 3 \\). Our analysis demonstrates that their\nresults hold true exclusively when \\( n = p^m \\) where \\( p \\) is a prime\nnumber and \\( m \\) is a positive integer. The research examines their\nmethodology via explicit counterexamples to expose its boundaries and establish\ncorrected results. This study improves past research by expanding the spectrum\nevaluation of power graphs linked to dihedral groups."
    ],
    "c_categories":[
      [
        "math.SP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-392",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08132",
    "b_title":[
      "Probing Electron Localization and Delocalization in the Selective\n  Long-Range Tight-Binding Model"
    ],
    "b_abstract":[
      "In this study, we perform a detailed investigation into the interplay between\ndisorder-induced electron localization and long-range hopping amplitudes within\nthe Selective Long-Range Tight-Binding Model (SLRTB). Through numerical\nsimulations, we analyze the electronic properties of the system, with a focus\non the participation ratio (PR), entanglement entropy (EE), energy spectrum,\nand the ratio of level spacings ($r_n$). Our results reveal a marked\ndistinction between negative and positive long-range hopping amplitudes,\nmanifesting in different electronic behaviors and transitions. Notably, we\ncarry out a finite-size scaling analysis, identifying the critical point and\nexponents that characterize the system's behavior near the transition. The\ninvestigation highlights the role of gapless regions in shaping the system's\nPR, $r_n$, and EE, and the influence of disorder on these properties. The SLRTB\nmodel proves to be an effective framework for understanding the effects of\ndisorder and long-range hopping on electron dynamics, offering valuable\ninsights into localization and delocalization phenomena."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.12187",
    "c_title":[
      "Magnetism in symmetry-enforced nodal-line semimetals"
    ],
    "c_abstract":[
      "Nodal-line semimetals (NLSMs) harbor a variety of novel physical properties\nowing to the particularities of the band degeneracies that characterize the\nspectrum of these materials. In symmetry-enforced NLSMs, band degeneracies,\nbeing imposed by symmetries, are robust to arbitrarily strong perturbations\nthat preserve the symmetries. We investigate the effects of electron-electron\ninteractions on a recently proposed vacancy-engineered NLSM known as holey\ngraphene. Using mean-field calculations and quantum Monte Carlo simulation, we\nshow that the Hubbard model on the depleted holey-graphene lattice at\nhalf-filling exhibits a transition from a NLSM to an insulating\nantiferromagnetic phase for an arbitrarily weak repulsive interaction $U$. In\ncontrast to the semi-metal-insulator transition in the pristine honeycomb\nlattice, which occurs at a finite critical value of $U$, in the depleted\nlattice, the transition at $U=0$ is associated with a van Hove singularity\narising from the crossing of accidental nodal lines enforced by symmetry. We\nalso employ linear spin wave theory (LSWT) to the effective Heisenberg model in\nthe strong-coupling limit and obtain the global antiferromagnetic order\nparameter $m_{\\rm AFM} \\approx 0.146$. The order parameters from both QMC and\nLSWT agree quantitatively. Our findings indicate that vacancy engineering\noffers an effective way to tailor the magnetic properties of quantum materials."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-393",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13107",
    "b_title":[
      "Accelerate High-Quality Diffusion Models with Inner Loop Feedback"
    ],
    "b_abstract":[
      "We propose Inner Loop Feedback (ILF), a novel approach to accelerate\ndiffusion models' inference. ILF trains a lightweight module to predict future\nfeatures in the denoising process by leveraging the outputs from a chosen\ndiffusion backbone block at a given time step. This approach exploits two key\nintuitions; (1) the outputs of a given block at adjacent time steps are\nsimilar, and (2) performing partial computations for a step imposes a lower\nburden on the model than skipping the step entirely. Our method is highly\nflexible, since we find that the feedback module itself can simply be a block\nfrom the diffusion backbone, with all settings copied. Its influence on the\ndiffusion forward can be tempered with a learnable scaling factor from zero\ninitialization. We train this module using distillation losses; however, unlike\nsome prior work where a full diffusion backbone serves as the student, our\nmodel freezes the backbone, training only the feedback module. While many\nefforts to optimize diffusion models focus on achieving acceptable image\nquality in extremely few steps (1-4 steps), our emphasis is on matching best\ncase results (typically achieved in 20 steps) while significantly reducing\nruntime. ILF achieves this balance effectively, demonstrating strong\nperformance for both class-to-image generation with diffusion transformer (DiT)\nand text-to-image generation with DiT-based PixArt-alpha and PixArt-sigma. The\nquality of ILF's 1.7x-1.8x speedups are confirmed by FID, CLIP score, CLIP\nImage Quality Assessment, ImageReward, and qualitative comparisons. Project\ninformation is available at https:\/\/mgwillia.github.io\/ilf."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.21242",
    "c_title":[
      "Towards long-term player tracking with graph hierarchies and\n  domain-specific features"
    ],
    "c_abstract":[
      "In team sports analytics, long-term player tracking remains a challenging\ntask due to player appearance similarity, occlusion, and dynamic motion\npatterns. Accurately re-identifying players and reconnecting tracklets after\nextended absences from the field of view or prolonged occlusions is crucial for\nrobust analysis. We introduce SportsSUSHI, a hierarchical graph-based approach\nthat leverages domain-specific features, including jersey numbers, team IDs,\nand field coordinates, to enhance tracking accuracy. SportsSUSHI achieves high\nperformance on the SoccerNet dataset and a newly proposed hockey tracking\ndataset. Our hockey dataset, recorded using a stationary camera capturing the\nentire playing surface, contains long sequences and annotations for team IDs\nand jersey numbers, making it well-suited for evaluating long-term tracking\ncapabilities. The inclusion of domain-specific features in our approach\nsignificantly improves association accuracy, as demonstrated in our\nexperiments. The dataset and code are available at\nhttps:\/\/github.com\/mkoshkina\/sports-SUSHI."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-394",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11383",
    "b_title":[
      "Study of $\\phi\\to K\\bar{K}$ and $K_{S}^{0}-K_{L}^{0}$ asymmetry in the\n  amplitude analysis of $D_{s}^{+} \\to K_{S}^{0}K_{L}^{0}\\pi^{+}$ decay"
    ],
    "b_abstract":[
      "Using $e^+e^-$ annihilation data corresponding to a total integrated\nluminosity of 7.33 $\\rm fb^{-1}$ collected at center-of-mass energies between\n4.128 and 4.226~GeV with the BESIII detector, we provide the first amplitude\nanalysis and absolute branching fraction measurement of the hadronic decay\n$D_{s}^{+} \\to K_{S}^{0}K_{L}^{0}\\pi^{+}$. The branching fraction of $D_{s}^{+}\n\\to K_{S}^{0}K_{L}^{0}\\pi^{+}$ is determined to be $(1.86\\pm0.06_{\\rm\nstat}\\pm0.03_{\\rm syst})\\%$.\n  Combining the $\\mathcal{B}(D_{s}^{+} \\to \\phi(\\to K_{S}^0K_{L}^0) \\pi^+)$\nobtained in this work and the world average of $\\mathcal{B}(D_{s}^{+} \\to\n\\phi(\\to K^+K^-) \\pi^+)$, we measure the relative branching fraction\n$\\mathcal{B}(\\phi \\to K_S^0K_L^0)\/\\mathcal{B}(\\phi \\to K^+K^-)$=($0.597 \\pm\n0.023_{\\rm stat} \\pm 0.018_{\\rm syst} \\pm 0.016_{\\rm PDG}$), which deviates\nfrom the PDG value by more than 3$\\sigma$. Furthermore, the asymmetry of the\nbranching fractions of $D^+_s\\to K_{S}^0K^{*}(892)^{+}$ and $D^+_s\\to\nK_{L}^0K^{*}(892)^{+}$, $\\frac{\\mathcal{B}(D_{s}^{+} \\to\nK_{S}^0K^{*}(892)^{+})-\\mathcal{B}(D_{s}^{+} \\to\nK_{L}^0K^{*}(892)^{+})}{\\mathcal{B}(D_{s}^{+} \\to\nK_{S}^0K^{*}(892)^{+})+\\mathcal{B}(D_{s}^{+} \\to K_{L}^0K^{*}(892)^{+})}$, is\ndetermined to be $(-13.4\\pm5.0_{\\rm stat}\\pm3.4_{\\rm syst})\\%$."
    ],
    "b_categories":[
      [
        "hep-ex"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.18667",
    "c_title":[
      "Sterile-neutrino search based on 259 days of KATRIN data"
    ],
    "c_abstract":[
      "Neutrinos are the most abundant fundamental matter particles in the Universe\nand play a crucial role in particle physics and cosmology. Neutrino\noscillation, discovered about 25 years ago, reveals that the three known\nspecies mix with each other. Anomalous results from reactor and\nradioactive-source experiments suggest a possible fourth neutrino state, the\nsterile neutrino, which does not interact via the weak force. The KATRIN\nexperiment, primarily designed to measure the neutrino mass via tritium\n$\\beta$-decay, also searches for sterile neutrinos suggested by these\nanomalies. A sterile-neutrino signal would appear as a distortion in the\n$\\beta$-decay energy spectrum, characterized by a discontinuity in curvature\n(kink) related to the sterile-neutrino mass. This signature, which depends only\non the shape of the spectrum rather than its absolute normalization, offers a\nrobust, complementary approach to reactor experiments. KATRIN examined the\nenergy spectrum of 36 million tritium $\\beta$-decay electrons recorded in 259\nmeasurement days within the last 40 electronvolt below the endpoint. The\nresults exclude a substantial part of the parameter space suggested by the\ngallium anomaly and challenge the Neutrino-4 claim. Together with other\nneutrino-disappearance experiments, KATRIN probes sterile-to-active mass\nsplittings from a fraction of an electron-volt squared to several hundred\nelectron-volts squared, excluding light sterile neutrinos with mixing angles\nabove a few percent."
    ],
    "c_categories":[
      [
        "hep-ex"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-395",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07822",
    "b_title":[
      "Orbital Longitudinal Magneto-electric Coupling in Multilayer Graphene"
    ],
    "b_abstract":[
      "Magneto-electric coupling enables the manipulation of magnetization by\nelectric fields and vice versa. While typically found in heavy element\nmaterials with large spin-orbit coupling, recent experiments on\nrhombohedral-stacked pentalayer graphene (RPG) have demonstrated a {\\it\nlongitudinal magneto-electric coupling} (LMC) without spin-orbit coupling. Here\nwe present a microscopic theory of LMC in multilayer graphene and identify how\nit is controlled by a ``layer-space'' quantum geometry and interaction-driven\nvalley polarization. Strikingly, we find that the interplay between\nvalley-polarized order and LMC produces a butterfly shaped magnetic hysteresis\ncontrolled by out-of-plane electric field: a signature of LMC and a\nmultiferroic valley order. Furthermore, we identify a nonlinear LMC in\nmultilayer graphene under time-reversal symmetry, while the absence of\ncentrosymmetry enables the generation of a second-order nonlinear electric\ndipole moment in response to an out-of-plane magnetic field. Our theoretical\nframework provides a quantitative understanding of LMC, as well as the emergent\nmagneto-electric properties of multilayer graphene."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20270",
    "c_title":[
      "Chaotic quantum transport through spatially symmetric microstructures in\n  the symplectic ensemble"
    ],
    "c_abstract":[
      "Quantum transport through left-right symmetric chaotic cavities in the\npresence of the symplectic symmetry, is studied through the statistical\ndistribution of the dimensionless conductance. With this particular point\nsymmetry, their associated scattering matrices are blocky diagonalized by a\nrotation by an angle of $\\pi\/4$. Although the formulation is established for an\narbitrary number channels N, we present explicit calculations for N=1 and N=2,\nthe last one showing the weak anti-localization phenomenon due to the\nsymplectic symmetry."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-396",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01134",
    "b_title":[
      "Incomplete crossing and semi-topological horseshoes"
    ],
    "b_abstract":[
      "This paper enriches the topological horseshoe theory using finite subshift\ntheory in symbolic dynamical systems, and develops an elementary framework\naddressing incomplete crossing and semi-horseshoes. Two illustrative examples\nare provided: one from the perturbed Duffing system and another from a\npolynomial system proposed by Chen, demonstrating the prevalence of\nsemi-horseshoes in chaotic systems. Moreover, the semi-topological horseshoe\ntheory enhances the detection of chaos and improves the accuracy of topological\nentropy estimation."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.10584",
    "c_title":[
      "On the dimension theory of Okamoto's function"
    ],
    "c_abstract":[
      "In this paper, we investigate the dimension theory of the one parameter\nfamily of Okamoto's function. We compute the Hausdorff, box-counting and\nAssouad dimensions of the graph for a typical choice of parameter. Furthermore,\nwe study the dimension of the level sets. We give an upper bound on the\ndimension of every level set and we show that for a typical choice of\nparameters this value is attained for Lebesgue almost every level sets."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-397",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02992",
    "b_title":[
      "Higgs boson precision analysis of two Higgs doublet models: Full LHC Run\n  1 and Run 2 data"
    ],
    "b_abstract":[
      "We present the results obtained by performing global fits of\ntwo-Higgs-doublet models (2HDMs) using the full Run 1 and Run 2 Higgs datasets\ncollected at the LHC. Avoiding unwanted tree-level flavor-changing neutral\ncurrents and including the wrong-sign cases, we consider 12 scenarios across\nsix types of 2HDMs: Inert, type I, type II, type III, type IV, and Aligned\n2HDMs. Our main results are presented in Table 3 and Fig. 1. We find that the\ntype-I 2HDM provides the best fit, while the wrong-sign scenarios of the\ntype-II and type-IV 2HDMs, where the normalized Yukawa coupling to down-type\nquarks is opposite in sign to the Standard Model (SM), are disfavored. We also\nobserve that the Aligned 2HDM gives the second-best fit when the Yukawa\ncouplings to down-type quarks take the same sign as in the SM, regardless of\nthe sign of the Yukawa couplings to the charged leptons."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.11017",
    "c_title":[
      "Strange quark stars in modified vector MIT bag model: role of $\\rho$ and\n  $\\phi$ mesons"
    ],
    "c_abstract":[
      "In the present work, we study the properties of strange quark stars (SQSs)\nusing the vector MIT bag model with modification in vector channels. Unlike\nrecent studies which only consider interactions through $\\omega$ mesons, we\nanalyze the possibility of $\\rho$ and $\\phi$ vector channels. We consider two\ntypes of higher order non-linear self-interaction terms for the vector mesons.\nWith these modifications, we computed the equation of state (EoS) and\nmass-radius of strange stars for different values of vector coupling strength.\nWe also calculate the tidal deformability, the Love number $k_2$ and the\ngravitational redshift of SQSs."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-398",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12455",
    "b_title":[
      "Self-assembling of Ge quantum dots in an alumina matrix"
    ],
    "b_abstract":[
      "In this work we report on a self-assembled growth of a Ge quantum dot lattice\nin a single 600-nm-thick Ge+Al2O3 layer during magnetron sputtering deposition\nof a Ge+Al2O3 mixture at an elevated substrate temperature. The self-assembly\nresults in the formation of a well-ordered threedimensional body-centered\ntetragonal quantum dot lattice within the whole deposited volume. The quantum\ndots formed are very small in size less than 4.0 nm, have a narrow size\ndistribution and a large packing density. The parameters of the quantum dot\nlattice can be tuned by changing the deposition parameters. The self-ordering\nof the quantum dots is explained by diffusionmediated nucleation and\nsurface-morphology effects and simulated by a kinetic Monte Carlo model."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.12335",
    "c_title":[
      "Robust Super-Moir\\'e in Large Angle Single-Twist Bilayers"
    ],
    "c_abstract":[
      "Forming long wavelength moir\\'e superlattices (MSL) at small-angle twist van\nder Waals (vdW) bilayers has been a key approach to creating moir\\'e flat\nbands. The small-angle twist, however, leads to strong lattice reconstruction,\ncausing domain walls and moir\\'e disorders, which pose considerable challenges\nin engineering such platforms. At large twist angles, the rigid lattices render\na more robust, but shorter wavelength MSL, making it difficult to engineer flat\nbands. Here, we depict a novel approach to tailoring robust super-moir\\'e (SM)\nstructures that combines the advantages of both small-twist and large-twist\ntransition metal dichalcogenides (TMDs) bilayers using only a single twist\nangle near a commensurate angle. Structurally, we unveil the spontaneous\nformation of a periodic arrangement of three inequivalent commensurate moir\\'e\n(CM) stacking, where the angle deviation from the commensurate angle can tune\nthe periodicity. Electronically, we reveal a large set of van Hove\nsingularities (VHSs) that indicate strong band hybridization, leading to flat\nbands near the valence band maximum. Our study paves the way for a new platform\nof robust SM bilayers with structural rigidity and controllable wavelength,\nextending the investigation of the interplay among band topology, quantum\ngeometry, and moir\\'e superconductivity to the large twist angle regime."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-399",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09104",
    "b_title":[
      "Dark matter distributions around Schwarzschild-like black holes in\n  bumblebee and Kalb-Ramond models"
    ],
    "b_abstract":[
      "A central black hole can attract a dark matter cluster and generate a spike\nin the density profile, as demonstrated by detailed analysis of Schwarzschild\nand Kerr black holes in the past. Do different black holes attract dark matter\ndifferently? To get a fair answer to this question, we customize a relativistic\nframework to grow general static spherical black holes in dark matter halos and\ninvestigate how deviations from the Schwarzschild geometry modify the dark\nmatter spike for the first time. The framework is applied to a class of\nSchwarzschild-like black hole solutions in Lorentz-violated gravity models --\none in the bumblebee model and two in the Kalb-Ramond model. For these black\nholes, the answer is no if initially the dark matter has a constant\ndistribution, but the answer is yes if it has a Hernquist profile initially."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.01174",
    "c_title":[
      "On Geometrization of Classical Fields (Model of Embedded Spaces)"
    ],
    "c_abstract":[
      "The possibility of geometrization of the gravitational and electro magnetic\nfields in 4D Finsler space (the Model of Embedded Spaces -- MES) is\ninvestigated. The model postulates a proper metric set of an element of\ndistributed matter and asserts that space-time is a mutual physical embedding\nof such sets. The simplest MES geometry is constructed (its relativistic\nFinsler version) with a connection that depends of the properties of matter and\nits fields (torsion and nonmetricity are absent). The field hypothesis and the\nLeast Action Principle of the matter-field system lead to Einstein-type and\nMaxwell-type equations, and their nonlinearity -- to the anisotropic field\ncontribution to the seed mass of matter. It is shown that the seed matter plays\nthe role of a physical vacuum of the Embedding determines the cosmological\nconstant. In the special case of a conformal metric, the Maxwell-type equations\nreduce to the Maxwell equations themselves and a negative electromagnetic\ncontribution. A possible experimental verification of this result is evaluated.\nThe \"redshift\" effect in an electric field is also mentioned as a method for\nstudying the vacuum and relic electric charge. A study of the gauge structure\nof the presented theory is postponed to the future."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-400",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07196",
    "b_title":[
      "QKD-KEM: Hybrid QKD Integration into TLS with OpenSSL Providers"
    ],
    "b_abstract":[
      "Quantum Key Distribution (QKD) promises information-theoretic security, yet\nintegrating QKD into existing protocols like TLS remains challenging due to its\nfundamentally different operational model. In this paper, we propose a hybrid\nQKD-KEM protocol with two distinct integration approaches: a client-initiated\nflow compatible with both ETSI 004 and 014 specifications, and a\nserver-initiated flow similar to existing work but limited to stateless ETSI\n014 APIs. Unlike previous implementations, our work specifically addresses the\nintegration of stateful QKD key exchange protocols (ETSI 004) which is\nessential for production QKD networks but has remained largely unexplored. By\nadapting OpenSSL's provider infrastructure to accommodate QKD's pre-distributed\nkey model, we maintain compatibility with current TLS implementations while\noffering dual layers of security. Performance evaluations demonstrate the\nfeasibility of our hybrid scheme with acceptable overhead, showing that robust\nsecurity against quantum threats is achievable while addressing the unique\nrequirements of different QKD API specifications."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09535",
    "c_title":[
      "Entropy Collapse in Mobile Sensors: The Hidden Risks of Sensor-Based\n  Security"
    ],
    "c_abstract":[
      "Mobile sensor data has been proposed for security-critical applications such\nas device pairing, proximity detection, and continuous authentication. However,\nthe foundational assumption that these signals provide sufficient entropy\nremains under-explored. In this work, we systematically analyse the entropy of\nmobile sensor data across four diverse datasets spanning multiple application\ncontexts. Our findings reveal pervasive biases, with single-sensor mean\nmin-entropy values ranging from 3.408-4.483 bits (S.D.=1.018-1.574) despite\nShannon entropy being several multiples higher. We further demonstrate that\ncorrelations between sensor modalities reduce the worst-case entropy of using\nmultiple sensors by up to approx. 75% compared to average-case Shannon entropy.\nThis brings joint min-entropy well below 10 bits in many cases and, in the best\ncase, yielding only approx. 24 bits of min-entropy when combining 20 sensor\nmodalities. These results call into question the widely held assumption that\nadding more sensors inherently yields higher security. We ultimately caution\nagainst relying on raw sensor data as a primary source of randomness."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-401",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09598",
    "b_title":[
      "GAIA: A Global, Multi-modal, Multi-scale Vision-Language Dataset for\n  Remote Sensing Image Analysis"
    ],
    "b_abstract":[
      "The continuous operation of Earth-orbiting satellites generates vast and\never-growing archives of Remote Sensing (RS) images. Natural language presents\nan intuitive interface for accessing, querying, and interpreting the data from\nsuch archives. However, existing Vision-Language Models (VLMs) are\npredominantly trained on web-scraped, noisy image-text data, exhibiting limited\nexposure to the specialized domain of RS. This deficiency results in poor\nperformance on RS-specific tasks, as commonly used datasets often lack\ndetailed, scientifically accurate textual descriptions and instead emphasize\nsolely on attributes like date and location. To bridge this critical gap, we\nintroduce GAIA, a novel dataset designed for multi-scale, multi-sensor, and\nmulti-modal RS image analysis. GAIA comprises of 205,150 meticulously curated\nRS image-text pairs, representing a diverse range of RS modalities associated\nto different spatial resolutions. Unlike existing vision-language datasets in\nRS, GAIA specifically focuses on capturing a diverse range of RS applications,\nproviding unique information about environmental changes, natural disasters,\nand various other dynamic phenomena. The dataset provides a spatially and\ntemporally balanced distribution, spanning across the globe, covering the last\n25 years with a balanced temporal distribution of observations. GAIA's\nconstruction involved a two-stage process: (1) targeted web-scraping of images\nand accompanying text from reputable RS-related sources, and (2) generation of\nfive high-quality, scientifically grounded synthetic captions for each image\nusing carefully crafted prompts that leverage the advanced vision-language\ncapabilities of GPT-4o. Our extensive experiments, including fine-tuning of\nCLIP and BLIP2 models, demonstrate that GAIA significantly improves performance\non RS image classification, cross-modal retrieval and image captioning tasks."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14605",
    "c_title":[
      "3DLabelProp: Geometric-Driven Domain Generalization for LiDAR Semantic\n  Segmentation in Autonomous Driving"
    ],
    "c_abstract":[
      "Domain generalization aims to find ways for deep learning models to maintain\ntheir performance despite significant domain shifts between training and\ninference datasets. This is particularly important for models that need to be\nrobust or are costly to train. LiDAR perception in autonomous driving is\nimpacted by both of these concerns, leading to the emergence of various\napproaches. This work addresses the challenge by proposing a geometry-based\napproach, leveraging the sequential structure of LiDAR sensors, which sets it\napart from the learning-based methods commonly found in the literature. The\nproposed method, called 3DLabelProp, is applied on the task of LiDAR Semantic\nSegmentation (LSS). Through extensive experimentation on seven datasets, it is\ndemonstrated to be a state-of-the-art approach, outperforming both naive and\nother domain generalization methods."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-402",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07709",
    "b_title":[
      "MAGELLAN: Metacognitive predictions of learning progress guide autotelic\n  LLM agents in large goal spaces"
    ],
    "b_abstract":[
      "Open-ended learning agents must efficiently prioritize goals in vast\npossibility spaces, focusing on those that maximize learning progress (LP).\nWhen such autotelic exploration is achieved by LLM agents trained with online\nRL in high-dimensional and evolving goal spaces, a key challenge for LP\nprediction is modeling one's own competence, a form of metacognitive\nmonitoring. Traditional approaches either require extensive sampling or rely on\nbrittle expert-defined goal groupings. We introduce MAGELLAN, a metacognitive\nframework that lets LLM agents learn to predict their competence and LP online.\nBy capturing semantic relationships between goals, MAGELLAN enables\nsample-efficient LP estimation and dynamic adaptation to evolving goal spaces\nthrough generalization. In an interactive learning environment, we show that\nMAGELLAN improves LP prediction efficiency and goal prioritization, being the\nonly method allowing the agent to fully master a large and evolving goal space.\nThese results demonstrate how augmenting LLM agents with a metacognitive\nability for LP predictions can effectively scale curriculum learning to\nopen-ended goal spaces."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11448",
    "c_title":[
      "AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety\n  Detection"
    ],
    "c_abstract":[
      "The rapid advancements in Large Language Models (LLMs) have enabled their\ndeployment as autonomous agents for handling complex tasks in dynamic\nenvironments. These LLMs demonstrate strong problem-solving capabilities and\nadaptability to multifaceted scenarios. However, their use as agents also\nintroduces significant risks, including task-specific risks, which are\nidentified by the agent administrator based on the specific task requirements\nand constraints, and systemic risks, which stem from vulnerabilities in their\ndesign or interactions, potentially compromising confidentiality, integrity, or\navailability (CIA) of information and triggering security risks. Existing\ndefense agencies fail to adaptively and effectively mitigate these risks. In\nthis paper, we propose AGrail, a lifelong agent guardrail to enhance LLM agent\nsafety, which features adaptive safety check generation, effective safety check\noptimization, and tool compatibility and flexibility. Extensive experiments\ndemonstrate that AGrail not only achieves strong performance against\ntask-specific and system risks but also exhibits transferability across\ndifferent LLM agents' tasks."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-403",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02939",
    "b_title":[
      "Towards Quantitative Interpretation of 3D Atomic Force Microscopy at\n  Solid-Liquid Interfaces"
    ],
    "b_abstract":[
      "Three-dimensional atomic force microscopy (3D-AFM) has been a powerful tool\nto probe the atomic-scale structure of solid-liquid interfaces. As a nanoprobe\nmoves along the 3D volume of interfacial liquid, the probe-sample interaction\nforce is sensed and mapped, providing information on not only the solid\nmorphology, but also the liquid density distribution. To date 3D-AFM force maps\nof a diverse set of solid-liquid interfaces have been recorded, revealing\nremarkable force oscillations that are typically attributed to solvation layers\nor electrical double layers. However, despite the high resolution down to\nsub-angstrom level, quantitative interpretation of the 3D force maps has been\nan outstanding challenge. Here we will review the technical details of 3D-AFM\nand the existing approaches for quantitative data interpretation. Based on\nevidences in recent literature, we conclude that the perturbation-induced AFM\nforce paradoxically represents the intrinsic, unperturbed liquid density\nprofile. We will further discuss how the oscillatory force profiles can be\nattributed to the probe-modulation of the liquid configurational entropy, and\nhow the quantitative, atomic-scale liquid density distribution can be derived\nfrom the force maps."
    ],
    "b_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.12726",
    "c_title":[
      "Mechanism of Heteroepitaxial Growth of Boron Carbide on the Si-Face of\n  4H-SiC"
    ],
    "c_abstract":[
      "Heteroepitaxial boron carbide (BxC) can be grown on Si face 4H-SiC(0001)\nusing a two-step process involving substrate boridation at 1200$^\\circ$C under\nBCl3 + H2 followed by a chemical vapor deposition (CVD) growth step at\n1600$^\\circ$C by adding C3H8 precursor. However, in-depth investigation of the\nearly growth stages revealed that complex reactions occur before starting the\nCVD at high temperature. Indeed, after boridation, the 35 nm BxC buffer layer\nis covered by an amorphous B-containing layer which evolves and reacts during\nthe temperature ramp up between 1200 to 1600$^\\circ$C. Despite the formation of\nnew phases (Si, SiB6), which could be explained by significant solid-state\ndiffusion of Si, C and B elements through the thin BxC layer, the CVD epitaxial\nre-growth upon reaching 1600$^\\circ$C does not seems to be affected by these\nphases. The resulting single crystalline BxC layers display the epitaxial\nrelationships [1010]BxC(0001)||[1010]4H-SiC(0001). The layers exhibit a B4C\ncomposition, e.g. the highest possible C content for the BxC solid solution."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-404",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01257",
    "b_title":[
      "SVDC: Consistent Direct Time-of-Flight Video Depth Completion with\n  Frequency Selective Fusion"
    ],
    "b_abstract":[
      "Lightweight direct Time-of-Flight (dToF) sensors are ideal for 3D sensing on\nmobile devices. However, due to the manufacturing constraints of compact\ndevices and the inherent physical principles of imaging, dToF depth maps are\nsparse and noisy. In this paper, we propose a novel video depth completion\nmethod, called SVDC, by fusing the sparse dToF data with the corresponding RGB\nguidance. Our method employs a multi-frame fusion scheme to mitigate the\nspatial ambiguity resulting from the sparse dToF imaging. Misalignment between\nconsecutive frames during multi-frame fusion could cause blending between\nobject edges and the background, which results in a loss of detail. To address\nthis, we introduce an adaptive frequency selective fusion (AFSF) module, which\nautomatically selects convolution kernel sizes to fuse multi-frame features.\nOur AFSF utilizes a channel-spatial enhancement attention (CSEA) module to\nenhance features and generates an attention map as fusion weights. The AFSF\nensures edge detail recovery while suppressing high-frequency noise in smooth\nregions. To further enhance temporal consistency, We propose a cross-window\nconsistency loss to ensure consistent predictions across different windows,\neffectively reducing flickering. Our proposed SVDC achieves optimal accuracy\nand consistency on the TartanAir and Dynamic Replica datasets. Code is\navailable at https:\/\/github.com\/Lan1eve\/SVDC."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02063",
    "c_title":[
      "V$^2$Dial: Unification of Video and Visual Dialog via Multimodal Experts"
    ],
    "c_abstract":[
      "We present V$^2$Dial - a novel expert-based model specifically geared towards\nsimultaneously handling image and video input data for multimodal\nconversational tasks. Current multimodal models primarily focus on simpler\ntasks (e.g., VQA, VideoQA, video-text retrieval) and often neglect the more\nchallenging conversational counterparts, such as video and visual\/image dialog.\nMoreover, works on both conversational tasks evolved separately from each other\ndespite their apparent similarities limiting their applicability potential. To\nthis end, we propose to unify both tasks using a single model that for the\nfirst time jointly learns the spatial and temporal features of images and\nvideos by routing them through dedicated experts and aligns them using matching\nand contrastive learning techniques. Furthermore, we systemically study the\ndomain shift between the two tasks by investigating whether and to what extent\nthese seemingly related tasks can mutually benefit from their respective\ntraining data. Extensive evaluations on the widely used video and visual dialog\ndatasets of AVSD and VisDial show that our model achieves new state-of-the-art\nresults across four benchmarks both in zero-shot and fine-tuning settings."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-405",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03192",
    "b_title":[
      "Distributed Certifiably Correct Range-Aided SLAM"
    ],
    "b_abstract":[
      "Reliable simultaneous localization and mapping (SLAM) algorithms are\nnecessary for safety-critical autonomous navigation. In the\ncommunication-constrained multi-agent setting, navigation systems increasingly\nuse point-to-point range sensors as they afford measurements with low bandwidth\nrequirements and known data association. The state estimation problem for these\nsystems takes the form of range-aided (RA) SLAM. However, distributed\nalgorithms for solving the RA-SLAM problem lack formal guarantees on the\nquality of the returned estimate. To this end, we present the first distributed\nalgorithm for RA-SLAM that can efficiently recover certifiably globally optimal\nsolutions. Our algorithm, distributed certifiably correct RA-SLAM (DCORA),\nachieves this via the Riemannian Staircase method, where computational\nprocedures developed for distributed certifiably correct pose graph\noptimization are generalized to the RA-SLAM problem. We demonstrate DCORA's\nefficacy on real-world multi-agent datasets by achieving absolute trajectory\nerrors comparable to those of a state-of-the-art centralized certifiably\ncorrect RA-SLAM algorithm. Additionally, we perform a parametric study on the\nstructure of the RA-SLAM problem using synthetic data, revealing how common\nparameters affect DCORA's performance."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19169",
    "c_title":[
      "Increasing the Task Flexibility of Heavy-Duty Manipulators Using Visual\n  6D Pose Estimation of Objects"
    ],
    "c_abstract":[
      "Recent advances in visual 6D pose estimation of objects using deep neural\nnetworks have enabled novel ways of vision-based control for heavy-duty robotic\napplications. In this study, we present a pipeline for the precise tool\npositioning of heavy-duty, long-reach (HDLR) manipulators using advanced\nmachine vision. A camera is utilized in the so-called eye-in-hand configuration\nto estimate directly the poses of a tool and a target object of interest (OOI).\nBased on the pose error between the tool and the target, along with\nmotion-based calibration between the camera and the robot, precise tool\npositioning can be reliably achieved using conventional robotic modeling and\ncontrol methods prevalent in the industry. The proposed methodology comprises\norientation and position alignment based on the visually estimated OOI poses,\nwhereas camera-to-robot calibration is conducted based on motion utilizing\nvisual SLAM. The methods seek to avert the inaccuracies resulting from\nrigid-body--based kinematics of structurally flexible HDLR manipulators via\nimage-based algorithms. To train deep neural networks for OOI pose estimation,\nonly synthetic data are utilized. The methods are validated in a real-world\nsetting using an HDLR manipulator with a 5 m reach. The experimental results\ndemonstrate that an image-based average tool positioning error of less than 2\nmm along the non-depth axes is achieved, which facilitates a new way to\nincrease the task flexibility and automation level of non-rigid HDLR\nmanipulators."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-406",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17118",
    "b_title":[
      "The Fourier transform with Henstock--Kurzweil and continuous primitive\n  integrals"
    ],
    "b_abstract":[
      "For each $f\\!:\\!\\mathbb{R}\\to\\mathbb{C}$ that is Henstock--Kurzweil\nintegrable on the real line, or is a distribution in the completion of the\nspace of Henstock--Kurzweil integrable functions in the Alexiewicz norm, it is\nshown that the Fourier transform is the second distributional derivative of a\nH\\\"older continuous function. The space of such Fourier transforms is\nisometrically isomorphic to the completion of the Henstock--Kurzweil integrable\nfunctions. There is an exchange theorem, inversion in norm and convolution\nresults. Sufficient conditions are given for an $L^1$ function to have a\nFourier transform that is of bounded variation. Pointwise inversion of the\nFourier transform is proved for functions in $L^p$ spaces for $1<p<\\infty$. The\nexchange theorem is used to evaluate an integral that does not appear in\npublished tables."
    ],
    "b_categories":[
      [
        "math.CA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03554",
    "c_title":[
      "A positive product formula of integral kernels of $k$-Hankel transforms"
    ],
    "c_abstract":[
      "Let $R$ be a root system in $\\mathbb R^N$ and $G$ be the finite subgroup\ngenerated by the reflections associated to the root system. We establish a\npositive radial product formula for the integral kernels $B_{k,1}(x,y)$ of\n$(k,1)$-generalized Fourier transforms (or the $k$-Hankel transforms) $F_{k,1}$\n$$B_{k,1}(x,z)j_{2\\left\\langle\nk\\right\\rangle+N-2}\\left(2\\sqrt{t\\left|z\\right|}\\right)=\\int_{\\mathbb R^N}\nB_{k,1}(\\xi,z)\\,d\\sigma_{x,t}^{k,1}(\\xi),$$ where $j_{\\lambda}$ is the\nnormalized Bessel function, and $\\sigma_{x,t}^{k,1}(\\xi)$ is the unique\nprobability measure. Such a product formula is equivalent to the following\nrepresentation of the generalized spherical mean operator $f\\mapsto M_f,\\;f\\in\nC_b(\\mathbb{R}^N)$ in $(k,1)$-generalized Fourier analysis \\begin{align*}\nM_f(x,t)=\\int_{\\mathbb{R}^N}f\\,d\\sigma_{x,t}^{k,1},\\;(x,t)\\in\\mathbb{R}^N\\times{\\mathbb{R}}_+.\\end{align*}\nWe will then analyze the representing measure $\\sigma_{x,t}^{k,1}(\\xi)$ and\nshow that the support of the measure is contained in\n$$\\left\\{\\xi\\in\\mathbb{R}^N:\\sqrt{\\vert\\xi\\vert}\\geq\\vert\\sqrt{\\vert\nx\\vert}-\\sqrt t\\vert\\right\\}\\cap\\left(\\bigcup_{g\\in\nG}\\{\\xi\\in\\mathbb{R}^N:d(\\xi,gx)\\leq\\sqrt t\\}\\right),$$ where\n$d\\left(x,y\\right)=\\sqrt{\\left|x\\right|+\\left|y\\right|-\\sqrt{2\\left(\\left|x\\right|\\left|y\\right|+\\left\\langle\nx,y\\right\\rangle\\right)}}$. Based on the support of the representing measure\n$\\sigma_{x,t}^{k,1}$, we will get a weak Huygens's principle for the deformed\nwave equation in $(k,1)$-generalized Fourier analysis. Moreover, for $N\\geq 2$,\nif we assume that $F_{k,1}\\left(\\mathcal S(\\mathbb{R}^N)\\right)$ consists of\nrapidly decreasing functions at infinity, then we get two different results on\n$\\text{supp}\\sigma_{x,t}^{k,1}$, which indirectly denies such assumption."
    ],
    "c_categories":[
      [
        "math.CA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-407",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17147",
    "b_title":[
      "Suppression of coherent errors during entangling operations in NV\n  centers in diamond"
    ],
    "b_abstract":[
      "We consider entangling operations in a single nitrogen-vacancy (NV) center in\ndiamond where the hyperfine-coupled nuclear spin qubits are addressed with\nradio-frequency (rf) pulses conditioned on the state of the central electron\nspin. Limiting factors for the gate fidelity are coherent errors due to\noff-resonant driving of neighboring transitions in the dense, hyperfine-split\nenergy spectrum of the defect and non-negligible perpendicular hyperfine tensor\ncomponents that narrow the choice of $^{13}\\rm C$ nuclear spin qubits. We\naddress these issues by presenting protocols based on synchronization effects\nthat allow for a complete suppression of both error sources in state-of-the-art\nCNOT gate schemes. This is possible by a suitable choice of parameter sets that\nincorporate the error into the scheme instead of avoiding it. These results\ncontribute to the recent progress toward scalable quantum computation with\ndefects in solids."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.09169",
    "c_title":[
      "Two-party entanglement distribution in XXZ spin chains with the\n  exponential and power-law long-range interactions"
    ],
    "c_abstract":[
      "Entanglement distribution is a fundamental property in quantum many-body\nphysics, but the effect of long-range interactions on the distribution has not\nbeen fully understood. Here, we study long-range two-party entanglement (TPE)\nand explore its distribution properties in XXZ spin chains with the exponential\nand power-law long-range interactions(ELRIs and PLRIs). In the thermodynamic\nlimit case with the ELRIs, the TPE quantified by two-qubit concurrence decays\nexponentially along with two-site distance and the long-range concurrences can\nindicate the paramagnetic-ferromagnetic phase transition. We present a\nfine-grained entanglement distribution relations among the entanglement\ntruncation length, total concurrences and two-tangles in the infinite spin\nchains. Moreover, in the finite XXZ chain with the more common PLRIs, the TPE\ndecays algebraically along with the two-spin distance, and the total\nconcurrence can exhibit a piecewise function with respect to total two-tangles.\nThese new presented TPE distribution relations can be regarded as the\ngeneralization of Koashi-Bu\\v{z}ek-and-Imoto bound for the long-range quantum\nmodels, and have potential applications in quantum information processing."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-408",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02441",
    "b_title":[
      "Through the Static: Demystifying Malware Visualization via\n  Explainability"
    ],
    "b_abstract":[
      "Security researchers grapple with the surge of malicious files, necessitating\nswift identification and classification of malware strains for effective\nprotection. Visual classifiers and in particular Convolutional Neural Networks\n(CNNs) have emerged as vital tools for this task. However, issues of robustness\nand explainability, common in other high risk domain like medicine and\nautonomous vehicles, remain understudied in current literature. Although deep\nlearning visualization classifiers presented in research obtain great results\nwithout the need for expert feature extraction, they have not been properly\nstudied in terms of their replicability. Additionally, the literature is not\nclear on how these types of classifiers arrive to their answers. Our study\naddresses these gaps by replicating six CNN models and exploring their\npitfalls. We employ Class Activation Maps (CAMs), like GradCAM and HiResCAM, to\nassess model explainability. We evaluate the CNNs' performance and\ninterpretability on two standard datasets, MalImg and Big2015, and a newly\ncreated called VX-Zoo. We employ these different CAM techniques to gauge the\nexplainability of each of the models. With these tools, we investigate the\nunderlying factors contributing to different interpretations of inputs across\nthe different models, empowering human researchers to discern patterns crucial\nfor identifying distinct malware families and explain why CNN models arrive at\ntheir conclusions. Other then highlighting the patterns found in the\ninterpretability study, we employ the extracted heatmpas to enhance Visual\nTransformers classifiers' performance and explanation quality. This approach\nyields substantial improvements in F1 score, ranging from 2% to 8%, across the\ndatasets compared to benchmark values."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11920",
    "c_title":[
      "A limited technical background is sufficient for attack-defense tree\n  acceptability"
    ],
    "c_abstract":[
      "Attack-defense trees (ADTs) are a prominent graphical threat modeling method\nthat is highly recommended for analyzing and communicating security-related\ninformation. Despite this, existing empirical studies of attack trees have\nestablished their acceptability only for users with highly technical (computer\nscience) backgrounds while raising questions about their suitability for threat\nmodeling stakeholders with a limited technical background. Our research\naddresses this gap by investigating the impact of the users' technical\nbackground on ADT acceptability in an empirical study.\n  Our Method Evaluation Model-based study consisted of n = 102 participants (53\nwith a strong computer science background and 49 with a limited computer\nscience background) who were asked to complete a series of ADT-related tasks.\nBy analyzing their responses and comparing the results, we reveal that a very\nlimited technical background is sufficient for ADT acceptability. This finding\nunderscores attack trees' viability as a threat modeling method."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-409",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17820",
    "b_title":[
      "RefCut: Interactive Segmentation with Reference Guidance"
    ],
    "b_abstract":[
      "Interactive segmentation aims to segment the specified target on the image\nwith positive and negative clicks from users. Interactive ambiguity is a\ncrucial issue in this field, which refers to the possibility of multiple\ncompliant outcomes with the same clicks, such as selecting a part of an object\nversus the entire object, a single object versus a combination of multiple\nobjects, and so on. The existing methods cannot provide intuitive guidance to\nthe model, which leads to unstable output results and makes it difficult to\nmeet the large-scale and efficient annotation requirements for specific targets\nin some scenarios. To bridge this gap, we introduce RefCut, a reference-based\ninteractive segmentation framework designed to address part ambiguity and\nobject ambiguity in segmenting specific targets. Users only need to provide a\nreference image and corresponding reference masks, and the model will be\noptimized based on them, which greatly reduces the interactive burden on users\nwhen annotating a large number of such targets. In addition, to enrich these\ntwo kinds of ambiguous data, we propose a new Target Disassembly Dataset which\ncontains two subsets of part disassembly and object disassembly for evaluation.\nIn the combination evaluation of multiple datasets, our RefCut achieved\nstate-of-the-art performance. Extensive experiments and visualized results\ndemonstrate that RefCut advances the field of intuitive and controllable\ninteractive segmentation. Our code will be publicly available and the demo\nvideo is in https:\/\/www.lin-zheng.com\/refcut."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08650",
    "c_title":[
      "MF-VITON: High-Fidelity Mask-Free Virtual Try-On with Minimal Input"
    ],
    "c_abstract":[
      "Recent advancements in Virtual Try-On (VITON) have significantly improved\nimage realism and garment detail preservation, driven by powerful text-to-image\n(T2I) diffusion models. However, existing methods often rely on user-provided\nmasks, introducing complexity and performance degradation due to imperfect\ninputs, as shown in Fig.1(a). To address this, we propose a Mask-Free VITON\n(MF-VITON) framework that achieves realistic VITON using only a single person\nimage and a target garment, eliminating the requirement for auxiliary masks.\nOur approach introduces a novel two-stage pipeline: (1) We leverage existing\nMask-based VITON models to synthesize a high-quality dataset. This dataset\ncontains diverse, realistic pairs of person images and corresponding garments,\naugmented with varied backgrounds to mimic real-world scenarios. (2) The\npre-trained Mask-based model is fine-tuned on the generated dataset, enabling\ngarment transfer without mask dependencies. This stage simplifies the input\nrequirements while preserving garment texture and shape fidelity. Our framework\nachieves state-of-the-art (SOTA) performance regarding garment transfer\naccuracy and visual realism. Notably, the proposed Mask-Free model\nsignificantly outperforms existing Mask-based approaches, setting a new\nbenchmark and demonstrating a substantial lead over previous approaches. For\nmore details, visit our project page: https:\/\/zhenchenwan.github.io\/MF-VITON\/."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-410",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05131",
    "b_title":[
      "The bound and resonant states of $D^{(*)}D^{(*)}$ and\n  $D^{(*)}\\bar{D}^{(*)}$ with the complex scaling method"
    ],
    "b_abstract":[
      "We perform a systematic study of the possible molecular states composed of a\npair of heavy mesons such as $D^{(*)}D^{(*)}$, $D^{(*)}\\bar{D}^{(*)}$ in the\nframework of the one-boson-exchange model. The exchanged bosons include the\npseudoscalar, scalar and vector mesons($\\pi$, $\\sigma$, $\\rho$, $\\omega$). We\nuse the Bonn approximation to get the interaction potential of\none-boson-exchange model, then apply the complex scaling method to calculate\nthe bound and resonant states. The results indicate that the $D^{(*)}D^{(*)}$\nand $D^{(*)}\\bar{D}^{(*)}$ system can not only form several bound states, but\nalso a P-wave resonant state. The hadron molecular state model can explain the\nstructure of $T_{cc}^+$ as a bound state $DD^{*}$ with quantum number $I(J^P) =\n0(1^+)$. In addition, we also discovered other bound and resonant states, which\nhave the potential to be observed experimentally."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.02619",
    "c_title":[
      "Hybrid high-energy factorization and evolution at NLO from the\n  high-energy limit of collinear factorization"
    ],
    "c_abstract":[
      "We derive the scheme of NLO computations of generic observables in\nhigh-energy hadron-hadron collisions within the framework of high-energy\nfactorization (HEF) with one off-shell initial-state parton, by taking a\nhigh-energy limit of the NLO computation in collinear factorization (CF). The\nNLO terms belonging to the projectile and target are identified and the\nambiguity of projectile-target separation is related with the Collins-Soper\nscale ($\\mu_Y$). The NLO unintegrated PDF(UPDF) is constructed in terms of the\nusual PDFs, and its $\\mu_Y$-evolution reproduces the Collins-Soper-Sterman\nequation in the TMD limit ($|k_\\perp|\\ll \\mu_Y$). The resummation of\nhigh-energy logarithms is taken care of by the BFKL-Collins-Ellis evolution of\nthe Green's function in the UPDF."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-411",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13771",
    "b_title":[
      "Towards AI-assisted Academic Writing"
    ],
    "b_abstract":[
      "We present components of an AI-assisted academic writing system including\ncitation recommendation and introduction writing. The system recommends\ncitations by considering the user's current document context to provide\nrelevant suggestions. It generates introductions in a structured fashion,\nsituating the contributions of the research relative to prior work. We\ndemonstrate the effectiveness of the components through quantitative\nevaluations. Finally, the paper presents qualitative research exploring how\nresearchers incorporate citations into their writing workflows. Our findings\nindicate that there is demand for precise AI-assisted writing systems and\nsimple, effective methods for meeting those needs."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19532",
    "c_title":[
      "Opus: A Workflow Intention Framework for Complex Workflow Generation"
    ],
    "c_abstract":[
      "This paper introduces Workflow Intention, a novel framework for identifying\nand encoding process objectives within complex business environments. Workflow\nIntention is the alignment of Input, Process and Output elements defining a\nWorkflow's transformation objective interpreted from Workflow Signal inside\nBusiness Artefacts. It specifies how Input is processed to achieve desired\nOutput, incorporating quality standards, business rules, compliance\nrequirements and constraints. We adopt an end-to-end Business Artefact Encoder\nand Workflow Signal interpretation methodology involving four steps:\nModality-Specific Encoding, Intra-Modality Attention, Inter-Modality Fusion\nAttention then Intention Decoding. We provide training procedures and critical\nloss function definitions. In this paper we introduce the concepts of Workflow\nSignal and Workflow Intention, where Workflow Signal decomposed into Input,\nProcess and Output elements is interpreted from Business Artefacts, and\nWorkflow Intention is a complete triple of these elements. We introduce a\nmathematical framework for representing Workflow Signal as a vector and\nWorkflow Intention as a tensor, formalizing properties of these objects.\nFinally, we propose a modular, scalable, trainable, attention-based multimodal\ngenerative system to resolve Workflow Intention from Business Artefacts."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-412",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08894",
    "b_title":[
      "Modeling and computation of the effective elastic behavior of\n  parallelogram origami metamaterials"
    ],
    "b_abstract":[
      "Origami metamaterials made of repeating unit cells of parallelogram panels\njoined at folds dramatically change their shape through a collective motion of\ntheir cells. Here we develop an effective elastic model and numerical method to\nstudy the large deformation response of these metamaterials under a broad class\nof loads. The model builds on an effective plate theory derived in our prior\nwork [64]. The theory captures the overall shape change of all slightly\nstressed parallelogram origami deformations through nonlinear geometric\ncompatibility constraints that couple the origami's (cell averaged) effective\ndeformation to an auxiliary angle field quantifying its cell-by-cell actuation.\nIt also assigns to each such origami deformation a plate energy associated to\nthese effective fields. Seeking a constitutive model that is faithful to the\ntheory but also practical to simulate, we relax the geometric constraints via\ncorresponding elastic energy penalties; we also simplify the plate energy\ndensity to embrace its essential character as a regularization to the geometric\npenalties. The resulting model for parallelogram origami is a generalized\nelastic continuum that is nonlinear in the effective deformation gradient and\nangle field and regularized by high-order gradients thereof. We provide a\nfinite element formulation of this model using the $C^0$ interior penalty\nmethod to handle second gradients of deformation, and implement it using the\nopen source computing platform Firedrake. We end by using the model and\nnumerical method to study two canonical parallelogram origami patterns, in\nMiura and Eggbox origami, under a variety of loading conditions."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07235",
    "c_title":[
      "The Sand Atlas"
    ],
    "c_abstract":[
      "The Sand Atlas is a publicly accessible repository dedicated to the\ncollection, processing, and sharing of high-resolution 3D models of sand-sized\nparticles. This dataset offers valuable insights into the morphology of a wide\nvariety of natural and synthetic sand-sized particles from different regions,\nwith varying mineralogy and history. The primary goal of The Sand Atlas is to\nsupport researchers, educators, and industry professionals by providing\ndetailed, easily accessible and uniformly produced surface meshes and level-set\ndata. The underlying code that converts volumetric data to meshes is also\navailable via the sand-atlas python package. This platform encourages community\nparticipation, inviting contributors to share their own data and enrich the\ncollective understanding of granular materials."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-413",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14766",
    "b_title":[
      "Multi-Layer Deep xVA: Structural Credit Models, Measure Changes and\n  Convergence Analysis"
    ],
    "b_abstract":[
      "We propose a structural default model for portfolio-wide valuation\nadjustments (xVAs) and represent it as a system of coupled backward stochastic\ndifferential equations. The framework is divided into four layers, each\ncapturing a key component: (i) clean values, (ii) initial margin and Collateral\nValuation Adjustment (ColVA), (iii) Credit\/Debit Valuation Adjustments\n(CVA\/DVA) together with Margin Valuation Adjustment (MVA), and (iv) Funding\nValuation Adjustment (FVA). Because these layers depend on one another through\ncollateral and default effects, a naive Monte Carlo approach would require\ndeeply nested simulations, making the problem computationally intractable.\n  To address this challenge, we use an iterative deep BSDE approach, handling\neach layer sequentially so that earlier outputs serve as inputs to the\nsubsequent layers. Initial margin is computed via deep quantile regression to\nreflect margin requirements over the Margin Period of Risk. We also adopt a\nchange-of-measure method that highlights rare but significant defaults of the\nbank or counterparty, ensuring that these events are accurately captured in the\ntraining process.\n  We further extend Han and Long's (2020) a posteriori error analysis to BSDEs\non bounded domains. Due to the random exit from the domain, we obtain an order\nof convergence of $\\mathcal{O}(h^{1\/4-\\epsilon})$ rather than the usual\n$\\mathcal{O}(h^{1\/2})$.\n  Numerical experiments illustrate that this method drastically reduces\ncomputational demands and successfully scales to high-dimensional,\nnon-symmetric portfolios. The results confirm its effectiveness and accuracy,\noffering a practical alternative to nested Monte Carlo simulations in\nmulti-counterparty xVA analyses."
    ],
    "b_categories":[
      [
        "q-fin.CP"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2503.04164",
    "c_title":[
      "CoFinDiff: Controllable Financial Diffusion Model for Time Series\n  Generation"
    ],
    "c_abstract":[
      "The generation of synthetic financial data is a critical technology in the\nfinancial domain, addressing challenges posed by limited data availability.\nTraditionally, statistical models have been employed to generate synthetic\ndata. However, these models fail to capture the stylized facts commonly\nobserved in financial data, limiting their practical applicability. Recently,\nmachine learning models have been introduced to address the limitations of\nstatistical models; however, controlling synthetic data generation remains\nchallenging. We propose CoFinDiff (Controllable Financial Diffusion model), a\nsynthetic financial data generation model based on conditional diffusion models\nthat accept conditions about the synthetic time series. By incorporating\nconditions derived from price data into the conditional diffusion model via\ncross-attention, CoFinDiff learns the relationships between the conditions and\nthe data, generating synthetic data that align with arbitrary conditions.\nExperimental results demonstrate that: (i) synthetic data generated by\nCoFinDiff capture stylized facts; (ii) the generated data accurately meet\nspecified conditions for trends and volatility; (iii) the diversity of the\ngenerated data surpasses that of the baseline models; and (iv) models trained\non CoFinDiff-generated data achieve improved performance in deep hedging task."
    ],
    "c_categories":[
      [
        "q-fin.CP"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-414",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10591",
    "b_title":[
      "Evolution of LISA Observables for Binary Black Holes Lensed by an SMBH"
    ],
    "b_abstract":[
      "Binary black holes (BBH) are expected to form and merge in active galactic\nnuclei (AGN), deep in the potential well of a supermassive black hole (SMBH),\nfrom populations that exist in a nuclear star cluster (NSC). Here we\ninvestigate the gravitational wave (GW) signature of a BBH lensed by a nearby\nSMBH. For a fiducial GW150914-like BBH orbiting close to a $10^{8}M_{\\odot}$\nSMBH located at $z=0.1$, the lensed GW signal varies in a predictable manner in\nand out of the LISA detectability band and across frequencies. The occurrence\nof such signatures has the potential to confound LISA global fit models if they\nare not modelled. Detection of these sources provide an independent measure of\nAGN inclination angles, along with detecting warping of the inner disk, and\nmeasuring the SMBH spin."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09998",
    "c_title":[
      "An in-depth study of Gamma rays from the Starburst Galaxy M 82 with\n  VERITAS"
    ],
    "c_abstract":[
      "Assuming Galactic cosmic rays originate in supernovae and the winds of\nmassive stars, starburst galaxies should produce very-high-energy (VHE; E$>$100\nGeV) gamma-ray emission via the interaction of their copious quantities of\ncosmic rays with the large reservoirs of dense gas within the galaxies. Such\nVHE emission was detected by VERITAS from the starburst galaxy M 82 in 2008-09.\nAn extensive, multi-year campaign followed these initial observations, yielding\na total of 254 h of good quality VERITAS data on M 82. Leveraging modern\nanalysis techniques and the larger exposure, these VERITAS data show a more\nstatistically significant VHE signal ($\\sim$6.5 standard deviations\n($\\sigma$)). The corresponding photon spectrum is well fit by a power law\n($\\Gamma = 2.3 \\pm 0.3_{stat} \\pm0.2_{sys}$) and the observed integral flux is\nF($>$450 GeV) = $(3.2 \\pm0.6_{stat} \\pm 0.6_{sys}) \\times\n10^{-13}~\\mathrm{cm^{-2}~s}^{-1}$, or $\\sim$0.4\\% of the Crab Nebula flux above\nthe same energy threshold. The improved VERITAS measurements, when combined\nwith various multi-wavelength data, enable modeling of the underlying emission\nand transport processes. A purely leptonic scenario is found to be a poor\nrepresentation of the gamma-ray spectral energy distribution (SED). A\nlepto-hadronic scenario with cosmic rays following a power-law spectrum in\nmomentum (index $s\\simeq 2.25$), and with significant bremsstrahlung below\n$1$~GeV, provides a good match to the observed SED. The synchrotron emission\nfrom the secondary electrons indicates that efficient non-radiative losses of\ncosmic-ray electrons may be related to advective escape from the starburst\ncore."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-415",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10964",
    "b_title":[
      "Revisiting Strong Duality, Hidden Convexity, and Gradient Dominance in\n  the Linear Quadratic Regulator"
    ],
    "b_abstract":[
      "The Linear Quadratic Regulator (LQR) is a cornerstone of optimal control\ntheory, widely studied in both model-based and model-free approaches. Despite\nits well-established nature, certain foundational aspects remain subtle. In\nthis paper, we revisit three key properties of policy optimization in LQR: (i)\nstrong duality in the nonconvex policy optimization formulation, (ii) the\ngradient dominance property, examining when it holds and when it fails, and\n(iii) the global optimality of linear static policies. Using primal-dual\nanalysis and convex reformulation, we refine and clarify existing results by\nleveraging Riccati equations\/inequalities, semidefinite programming (SDP)\nduality, and a recent framework of Extended Convex Lifting (\\texttt{ECL}). Our\nanalysis confirms that LQR 1) behaves almost like a convex problem (e.g.,\nstrong duality) under the standard assumptions of stabilizability and\ndetectability and 2) exhibits strong convexity-like properties (e.g., gradient\ndominance) under slightly stronger conditions. In particular, we establish a\nbroader characterization under which gradient dominance holds using\n\\texttt{ECL} and the notion of Cauchy directions. By clarifying and refining\nthese theoretical insights, we hope this work contributes to a deeper\nunderstanding of LQR and may inspire further developments beyond LQR."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.00311",
    "c_title":[
      "Solution of Uncertain Multiobjective Optimization Problems by Using\n  Nonlinear Conjugate Gradient Method"
    ],
    "c_abstract":[
      "This paper introduces a nonlinear conjugate gradient method (NCGM) for\naddressing the robust counterpart of uncertain multiobjective optimization\nproblems (UMOPs). Here, the robust counterpart is defined as the minimum across\nobjective-wise worst-case scenarios. There are some drawbacks to using\nscalarization techniques to solve the robust counterparts of UMOPs, such as the\npre-specification and restrictions of weights, and function importance that is\nunknown beforehand. NCGM is free from any kind of priori chosen scalars or\nordering information of objective functions as accepted in scalarization\nmethods. With the help of NCGM, we determine the critical point for the robust\ncounterpart of UMOP, which is the robust critical point for UMOP. To tackle\nthis robust counterpart using the NCGM, the approach involves constructing and\nsolving a subproblem to determine a descent direction. Subsequently, a new\ndirection is derived based on parameter selection methods such as\nFletcher-Reeves, conjugate descent, Dai-Yuan, Polak-Ribi$\\grave{e}$re-Polyak,\nand Hestenes-Stiefel. An Armijo-type inexact line search is employed to\nidentify an appropriate step length. Utilizing descent direction and step\nlength, a sequence is generated, and convergence of the proposed method is\nestablished. The effectiveness of the proposed method is verified and compared\nagainst an existing method using a set of test problems."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-416",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12069",
    "b_title":[
      "Tikhonov-Fenichel Reductions and their Application to a Novel Modelling\n  Approach for Mutualism"
    ],
    "b_abstract":[
      "When formulating a model there is a trade-off between model complexity and\n(biological) realism. In the present paper we demonstrate how model reduction\nfrom a precise mechanistic \"super model\" to simpler conceptual models using\nTikhonov-Fenichel reductions, an algebraic approach to singular perturbation\ntheory, can mitigate this problem. Compared to traditional methods for time\nscale separations (Tikhonov's theorem, quasi-steady state assumption),\nTikhonov-Fenichel reductions have the advantage that we can compute a reduction\ndirectly for a separation of rates into slow and fast ones instead of a\nseparation of components of the system. Moreover, we can find all such\nreductions algorithmically.\n  In the present paper we use Tikhonov-Fenichel reductions to analyse a\nmutualism model tailored towards lichens with an explicit description of the\ninteraction. We find that (1) the implicit description of the interaction given\nin the reductions by interaction terms (functional responses) varies depending\non the scenario, (2) there is a tendency for the mycobiont, an obligate\nmutualist, to always benefit from the interaction while it can be detrimental\nfor the photobiont, a facultative mutualist, depending on the parameters, (3)\nour model is capable of describing the shift from mutualism to parasitism, (4)\nour model can produce bistability with multiple stable fixed points in the\ninterior of the first orthant. To analyse the reductions we formalize and\ndiscuss a mathematical criterion that categorizes two-species interactions.\nThroughout the paper we focus on the relation between the mathematics behind\nTikhonov-Fenichel reductions and their biological interpretation."
    ],
    "b_categories":[
      [
        "q-bio.PE"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2501.17971",
    "c_title":[
      "Ancestral process for infectious disease outbreaks with superspreading"
    ],
    "c_abstract":[
      "When an infectious disease outbreak is of a relatively small size, describing\nthe ancestry of a sample of infected individuals is difficult because most\nancestral models assume large population sizes. Given a set of infected\nindividuals, we show that it is possible to express exactly the probability\nthat they have the same infector, either inclusively (so that other individuals\nmay have the same infector too) or exclusively (so that they may not). To\ncompute these probabilities requires knowledge of the offspring distribution,\nwhich determines how many infections each infected individual causes. We\nconsider transmission both without and with superspreading, in the form of a\nPoisson and a Negative-Binomial offspring distribution, respectively. We show\nhow our results can be incorporated into a new lambda-coalescent model which\nallows multiple lineages to coalesce together. We call this new model the\nomega-coalescent, we compare it with previously proposed alternatives, and\nadvocate its use in future studies of infectious disease outbreaks."
    ],
    "c_categories":[
      [
        "q-bio.PE"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-417",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06341",
    "b_title":[
      "Monolayer-Defined Flat Colloidal PbSe Quantum Dots in Extreme\n  Confinement"
    ],
    "b_abstract":[
      "Colloidal two-dimensional lead chalcogenide nanocrystals represent an\nintriguing new class of materials that push the boundaries of quantum\nconfinement by combining a crystal thickness down to the monolayer with\nconfinement in the lateral dimension. In particular flat PbSe quantum dots\nexhibit efficient telecommunication band-friendly photoluminescence (1.43 -\n0.83 eV with up to 61% quantum yield) that is highly interesting for\nfiber-optics information processing. By using cryogenic scanning tunneling\nmicroscopy and spectroscopy, we probe distinct single layer-defined PbSe\nquantum dot populations down to a monolayer with in-gap state free quantum\ndot-like density of states, in agreement with theoretical tight binding\ncalculations. Cryogenic ensemble photoluminescence spectra reveal mono-, bi-,\nand trilayer contribution, confirming the structural, electronic and\ntheoretical results. From larger timescale shifts and ratio changes in the\noptical spectra we infer Ostwald ripening in solution and fusing in deposited\nsamples of thinner flat PbSe quantum dots, which can be slowed down by surface\npassivation with PbI2. By uncovering the interplay between thickness, lateral\nsize and density of states, as well as the synthetic conditions and\npost-synthetic handling, our findings enable the target-oriented synthesis of\ntwo-dimensional PbSe quantum dots with precisely tailored optical properties at\ntelecom wavelengths."
    ],
    "b_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02073",
    "c_title":[
      "Two-dimensional fluorescence spectroscopy with quantum entangled photons\n  and time- and frequency-resolved two-photon coincidence detection"
    ],
    "c_abstract":[
      "Recent theoretical studies in quantum spectroscopy have emphasized the\npotential of non-classical correlations in entangled photon pairs for\nselectively targeting specific nonlinear optical processes in nonlinear optical\nresponses. However, because of the extremely low intensity of the nonlinear\noptical signal generated by irradiating molecules with entangled photon pairs,\ntime-resolved spectroscopic measurements using entangled photons have yet to be\nexperimentally implemented. In this paper, we theoretically propose a quantum\nspectroscopy measurement employing a time-resolved fluorescence approach that\naligns with the capabilities of current photon detection technologies. The\nproposed quantum spectroscopy affords two remarkable advantages over\nconventional two-dimensional electronic spectroscopy. First, it enables the\nacquisition of two-dimensional spectra without requiring control over multiple\npulsed lasers. Second, it reduces the complexity of the spectra because the\nspectroscopic signal is contingent upon the nonlinear optical process of\nspontaneous emission. These advantages are similar to those achieved in a\nprevious study [Fujihashi et al., J. Chem. Phys. 160, 104201 (2024)]. However,\nour approach achieves sufficient signal intensities that can be readily\ndetected using existing photon detection technologies, thereby rendering it a\npracticable. Our findings will potentially facilitate the first experimental\nreal-time observation of dynamic processes in molecular systems using quantum\nentangled photon pairs."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-418",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03892",
    "b_title":[
      "Predicting Cislunar Orbit Lifetimes from Initial Orbital Elements"
    ],
    "b_abstract":[
      "Cislunar space is the volume between Earth's geosynchronous orbit and beyond\nthe Moon, including the lunar Lagrange points. Understanding the stability of\norbits within this space is crucial for the successful planning and execution\nof space missions. Orbits in cislunar space are influenced by the gravitational\nforces of the Sun, Earth, Moon, and other Solar System planets leading to\ntypically unpredictable and chaotic behavior. It is therefore difficult to\npredict the stability of an orbit from a set of initial orbital elements. We\nsimulate one million cislunar orbits and use a self-organizing map (SOM) to\ncluster the orbits into families based on how long they remain stable within\nthe cislunar regime. Utilizing Lawrence Livermore National Laboratory's (LLNL)\nHigh Performance Computers (HPC) we develop a highly adaptable SOM capable of\nefficiently characterizing observations from individual events. We are able to\npredict the lifetime from the initial three line element (TLE) to within 10\npercent for 8 percent of the test dataset, within 50 percent for 43 percent of\nthe dataset, and within 100 percent for 75 percent of the dataset. The\nfractional absolute deviation peaks at 1 for all lifetimes. Multi-modal\nclustering in the SOM suggests that a variety of orbital morphologies have\nsimilar lifetimes. The trained SOMs use an average of 2.73 milliseconds of\ncomputational time to produce an orbital stability prediction. The outcomes of\nthis research enhance our understanding of cislunar orbital dynamics and also\nprovide insights for mission planning, enabling the rapid identification of\nstable orbital regions and pathways for future space exploration. As\ndemonstrated in this study, an SOM can generate orbital lifetime estimates from\nminimal observational data, such as a single TLE, making it essential for early\nwarning systems and large-scale sensor network operations."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.08191",
    "c_title":[
      "Architecture Classification for Extrasolar Planetary Systems"
    ],
    "c_abstract":[
      "This paper presents a classification framework for the architectures of\nplanetary systems based on a complete survey of the confirmed exoplanet\npopulation. With nearly 6000 confirmed exoplanets discovered, including more\nthan 300 multiplanet systems with three or more planets, the current\nobservational sample has reached the point where it is both feasible and useful\nto build a classification system that divides the observed population into\nmeaningful categories. This framework provides a criterion to split planetary\nsystems into inner and outer regimes, and then further divides inner systems\ninto dynamical classes. The resulting categories include \"peas-in-a-pod\nsystems\" with uniformly small planets and \"warm Jupiter systems\" with a mix of\nlarge and small planets, as well as \"closely-spaced systems\" and \"gapped\nsystems,\" with further subdivisions based on the locations of gaps and other\nfeatures. These categories can classify nearly all of the confirmed systems\nwith three or more planets with minimal ambiguity. We qualitatively examine the\nrelative prevalence of each type of system, subject to observational selection\neffects, as well as other notable features such as the presence of hot\nJupiters. A small number of outlier systems are also discussed. Potential\nadditional classes of systems yet to be discovered are proposed."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-419",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02364",
    "b_title":[
      "Singularity confinement and proliferation of tau functions for a general\n  differential-difference Sawada-Kotera equation"
    ],
    "b_abstract":[
      "Blending Painlev\\'e property with singularity confinement for a general\narbitrary order Sawada-Kotera differential-difference equation, we find a\nproliferation of ``tau-functions'' (coming from strictly confined patterns).\nHowever only one of these function enters into the Hirota bilinear form (the\nothers give multi-linear expressions) but has specific relations with all\nothers. We also discuss the case of two modifications of Sawada-Kotera showing\nthat periodic patterns appear in addition to strictly confined ones. Fully\ndiscretisations and express method for computing algebraic entropy are\ndiscussed."
    ],
    "b_categories":[
      [
        "nlin.SI"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04984",
    "c_title":[
      "Reduction properties of the KP-mKP hierarchy"
    ],
    "c_abstract":[
      "The so-called KP-mKP hierarchy, which was introduced recently via\npseudo-differential operators with two derivations, can be reduced to the\nKadomtsev-Petviashvili (KP), the modified KP (mKP) and the two-component BKP\nhierarchies. In this note, we continue to study reductions properties of the\nKP-mKP hierarchy, including its $(n,m)$-reduction and its reduction to a\ncertain extended $r$-reduced KP hierarchy (the $r$-th Gelfand-Dickey together\nwith its wave function). As a byproduct, we show that the Hirota equations of\nthe extended $r$-reduced KP hierarchy follow from those of the mKP hierarchy,\nwhich confirms a conjecture of Alexandrov on the open KdV hierarchy in [ J.\nHigh Energy Phys. 2015 ]."
    ],
    "c_categories":[
      [
        "nlin.SI"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-420",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13537",
    "b_title":[
      "Precision determination of the excited-state hyperfine splitting of\n  Cadmium ions"
    ],
    "b_abstract":[
      "Precision determination of the hyperfine splitting of cadmium ions is\nessential to study space-time variation of fundamental physical constants and\nisotope shifts. In this work, we present the precision frequency measurement of\nthe excited-state $^2{P}_{3\/2}$ hyperfine splitting of\n$^{111,113}\\mathrm{Cd}^+$ ions using the laser-induced fluorescence technique.\nBy introducing the technology of sympathetic cooling and setting up free-space\nbeat detection unit based on the optical comb, the uncertainties are improved\nto 14.8 kHz and 10.0 kHz, respectively, two orders of magnitude higher than the\nreported results from the linear transformation of isotope shifts. The magnetic\ndipole constants $A_{P_{3\/2}}$ of $^{111}\\mathrm{Cd}^+$ and\n$^{113}\\mathrm{Cd}^+$ are estimated to be 395 938.8(7.4) kHz and 411 276.0(5.0)\nkHz, respectively. The difference between the measured and theoretical\nhyperfine structure constants indicates that more physical effects are required\nto be considered in the theoretical calculation, and provides critical data for\nthe examination of deviation from King-plot linearity in isotope shifts."
    ],
    "b_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.02736",
    "c_title":[
      "Precision measurements of muonium and muonic helium hyperfine structure\n  at J-PARC"
    ],
    "c_abstract":[
      "At the J-PARC Muon Science Facility (MUSE), the MuSEUM collaboration is now\nperforming new precision measurements of the ground state hyperfine structure\n(HFS) of both muonium and muonic helium atoms. High-precision measurements of\nthe muonium ground-state HFS are recognized as one of the most sensitive tools\nfor testing bound-state quantum electrodynamics theory to precisely probe the\nstandard model and determine fundamental constants of the positive muon\nmagnetic moment and mass. The same technique can also be employed to measure\nmuonic helium HFS, obtain the negative muon magnetic moment and mass, and test\nand improve the theory of the three-body atomic system. Measurements at zero\nmagnetic field have already yielded more accurate results than previous\nexperiments for both muonium and muonic helium atoms. High-field measurements\nare now ready to start collecting data using the world's most intense pulsed\nmuon beam at the MUSE H-line. We aim to improve the precision of previous\nmeasurements ten times for muonium and a hundred times or more for muonic\nhelium. We review all the key developments for these new measurements, focusing\non the high-field experiment, and report the latest results and prospects."
    ],
    "c_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-421",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08112",
    "b_title":[
      "What causes the ultraviolet extinction bump at the cosmic dawn?"
    ],
    "b_abstract":[
      "The enigmatic ultraviolet (UV) extinction bump at 2175 Angstrom, the\nstrongest spectroscopic absorption feature superimposed on the interstellar\nextinction curve, has recently been detected at the cosmic dawn by the James\nWebb Space Telescope (JWST) in JADES-GS-z6-0, a distant galaxy at redshift\nz=6.71, corresponding to a cosmic age of just 800 million years after the Big\nBang. Although small graphite grains have historically long been suggested as\nthe carrier of the 2175 Angstrom extinction bump and graphite grains are\nexpected to have already been pervasive in the early Universe, in this work we\ndemonstrate that small graphite grains are not responsible for the UV\nextinction bump seen at the cosmic dawn in JADES-GS-z6-0, as the extinction\nbump arising from small graphite grains is too broad and peaks at wavelengths\nthat are too short to be consistent with what is seen in JADES-GS-z6-0."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03824",
    "c_title":[
      "Disentangling the galactic and intergalactic components in 313 observed\n  Lyman-alpha line profiles between redshift 0 and 5"
    ],
    "c_abstract":[
      "Lyman-Alpha (Lya) photons emitted in star-forming regions inside galaxies\nexperience a complex radiative transfer process until they reach the observer.\nThe Lya line profile that we measured on Earth is, thus, the convolution of the\ngas properties in the interstellar (ISM), circumgalactic (CGM), and\nintergalactic medium (IGM). We make use of the open source package zELDA\n(redshift Estimator for Line profiles of Distant Lyman-Alpha emitters) to\ndisentangle the galactic and IGM components of the Lya profiles to study both\nthe evolution of the intrinsic galactic emission and the IGM transmission\nacross cosmic time. zELDA includes different artificial neural networks that\nreconstruct IGM attenuated Lya line profiles. These models are trained using\nmock Lya line profiles. A Monte Carlo radiative transfer code computes the\ngalactic component for the so-called thin shell model. Moreover, the IGM\ncomponent is included through the IGM transmission curves generated from the\nIllustrisTNG100 cosmological galaxy formation simulation. We recover their\nintrinsic galactic spectra by applying the zELDA to 313 Lya line profiles\nobserved with HST\/COS and MUSE. Sources at z < 0.5 show weak IGM attenuation,\nwhile at z > 3, ZELDA reveals significant IGM suppression of the blue peak in\nseveral sources. After separating the IGM effects, the stacked intrinsic\ngalactic Lya profiles show a minimal evolution from z = 0 to 6. The mean IGM\ntransmission for z < 0.5 in HST\/COS data exceeds 90%, while the MUSE data show\nan evolution from 0.85 at z = 3.0 to 0.55 at z = 5.0."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-422",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11237",
    "b_title":[
      "Modeling the Solar Transition Region: Effects of Spatial Resolution on\n  the Atmospheric Structure, Emission and Non-Equilibrium Ionization"
    ],
    "b_abstract":[
      "The solar transition region (TR) is a narrow interface between the\nchromosphere and corona, where emitted radiation contains critical information\npertinent to coronal heating processes. We conducted 2-dimensional radiation\nmagnetohydrodynamics simulations using adaptive mesh refinement to spatially\nresolve the fine structure of the TR while simultaneously capturing the\nlarger-scale dynamics originating from surface convection. The time evolution\nof ionization fractions for oxygen ions is computed alongside the simulations.\nA minimum grid size of 1.25 km is achieved in the TR, enabling adequate\nresolution of the upper TR (log$_{10}T \\gtrsim$ 5), although the lower TR\n(log$_{10}T \\lesssim$ 5) remains under-resolved. Doppler shifts and nonthermal\nwidths synthesized from TR lines exhibit convergence with grid sizes as coarse\nas 40 km, though some discrepancies persist between our results and observed TR\nline properties. A notable enhancement in emission from \\ion{O}{6} lines,\nconverging at a grid size of 2.5 km, shows an intensity 1.2 times that expected\nunder ionization equilibrium, attributable to shock interactions with the TR.\nWhile model refinements are still required, our ability to resolve the TR\noffers critical insights into TR line characteristics arising from\nnon-equilibrium ionization states, advancing our understanding of the coronal\nheating problem."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.17612",
    "c_title":[
      "Evolution of Photospheric Magnetic Field and Electric Currents during\n  the X1.6 Flare in Active Region NOAA 12192"
    ],
    "c_abstract":[
      "The dynamics of magnetic fields in the Sun's active regions plays a key role\nin triggering solar eruptions. Studies have shown that changes in the\nphotosphere's magnetic field can destabilize large-scale structure of the\ncorona, leading to explosive events such as flares and coronal mass ejections\n(CMEs). This paper delves into the magnetic field evolution associated with a\npowerful X1.6 class flare that erupted on October 22nd, 2014, from the\nflare-rich active region NOAA 12192. We utilized high-resolution vector\nmagnetograms from the Helioseismic and Magnetic Imager (HMI) on NASA's Solar\nDynamic Observatory (SDO) to track these changes. Our analysis reveals that a\nbrightening, a precursor to the flare, began near the newly emerged,\nsmall-scale bipolar flux regions. During the X1.6 flare, the magnetic flux in\nboth polarities displayed emergence and cancellation. The total current within\nthe active region peaked during the flare. But, it is a non CME event and the\nratio of direct to return current value remain close to 1. The large flare in\nthis active region occured when the net current in both polarities attain the\nsame sign. This implies that the Lorentz force, a consequence of the\ninteraction between currents and magnetic fields, would have pushed the field\nlines together in this scenario. This reconnection of opposing magnetic fields\nis believed to be the driving force behind major flare occurred in this active\nregion."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-423",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01963",
    "b_title":[
      "Projection-angle effects when \"observing\" a turbulent magnetized\n  collapsing molecular cloud. I. Chemistry and line transfer"
    ],
    "b_abstract":[
      "Most of our knowledge regarding molecular clouds and the early stages of star\nformation stems from molecular spectral-line observations. However, the various\nchemical and radiative-transfer effects, in combination with projection\neffects, can lead to a distorted view of molecular clouds. Our objective is to\nsimultaneously study all of these effects by creating synthetic spectral-line\nobservations based on a chemo-dynamical simulation of a collapsing molecular\ncloud. We performed a 3D ideal MHD simulation of a supercritical turbulent\ncollapsing molecular cloud where the dynamical evolution was coupled to a\nnonequilibrium gas-grain chemical network consisting of 115 species, the\nevolution of which was governed by >1600 chemical reactions. We post-processed\nthis simulation with a multilevel non-LTE radiative-transfer code to produce\nsynthetic PPV data cubes of the CO, HCO+, HCN, and N2H+ (J = 1-0) transitions\nunder various projection angles with respect to the mean component of the\nmagnetic field. We find that the chemical abundances of various species in our\nsimulated cloud tend to be over-predicted in comparison to observationally\nderived abundances and attribute this discrepancy to the fact that the cloud\ncollapses rapidly and therefore the various species do not have enough time to\ndeplete onto dust grains. This suggests that our initial conditions may not\ncorrespond to the initial conditions of real molecular clouds and cores. We\nshow that the projection angle has a notable effect on the moment maps of the\nspecies for which we produced synthetic observations. Specifically, the\nintegrated emission and velocity dispersion of CO, HCO+, and HCN are higher\nwhen the cloud is observed \"face on\" compared to \"edge on,\" whereas column\ndensity maps exhibit an opposite trend. Finally, we show that only N2H+ is an\naccurate tracer of the column density of the cloud across all projection\nangles."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.07510",
    "c_title":[
      "Deriving the abundance distribution of HII galaxies using sulphur as\n  tracer: Exploring the high-metallicity end"
    ],
    "c_abstract":[
      "The main objective of this work is to derive the distribution of the the\nmetal content of HII galaxies using sulphur as an abundance tracer. This\nincreases the metallicity range that can safely be reached. We selected a\nsample of emission-line galaxies that we extracted from the SDSS-DR16. These\nobjects have a redshift of z less than 0.04 so that the [SIII] 9069 A emission\nline and H beta equivalent widths that are higher than 10 A in emission were\nincluded, and they are compact in appearance. We used the so-called direct\nmethod for objects with the electron-temperature-sensitive [SIII] 6312 A\nemission line, and an empirical method based on the S23 parameter. The last\nprovided an abundance calibration that monotonically increased up to at least\nthe solar value, and can be applied based on the spectral range from 6000 to\n9500 A alone. We show that the bias that is introduced when the [OIII] 4363 A\nline is required restricts the sample to objects with an [OIII] electron\ntemperature higher than 10,000K, and their temperature distribution is then\nrather narrow. For objects with determinations of te [SIII], the distribution\nis flatter and wider, which fits a more realistic scenario better. For the\nobjects in the sample that required the detection of the [OIII] 4363 A line and\n[SIII] 6312 A, the distribution abundances as traced directly by oxygen and\nsulphur appear to be very similar to each other. However, when the restriction\nfor weak temperature-sensitive lines is relaxed, the abundance distribution is\nwider . In summary, the abundance distributions traced by sulphur can reach\nreliable abundances up to the solar value at least and provide a more complete\npicture of the metallicity distribution of HII galaxies."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-424",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16832",
    "b_title":[
      "Joint Self-Supervised Video Alignment and Action Segmentation"
    ],
    "b_abstract":[
      "We introduce a novel approach for simultaneous self-supervised video\nalignment and action segmentation based on a unified optimal transport\nframework. In particular, we first tackle self-supervised video alignment by\ndeveloping a fused Gromov-Wasserstein optimal transport formulation with a\nstructural prior, which trains efficiently on GPUs and needs only a few\niterations for solving the optimal transport problem. Our single-task method\nachieves the state-of-the-art performance on multiple video alignment\nbenchmarks and outperforms VAVA, which relies on a traditional Kantorovich\noptimal transport formulation with an optimality prior. Furthermore, we extend\nour approach by proposing a unified optimal transport framework for joint\nself-supervised video alignment and action segmentation, which requires\ntraining and storing a single model and saves both time and memory consumption\nas compared to two different single-task models. Extensive evaluations on\nseveral video alignment and action segmentation datasets demonstrate that our\nmulti-task method achieves comparable video alignment yet superior action\nsegmentation results over previous methods in video alignment and action\nsegmentation respectively. Finally, to the best of our knowledge, this is the\nfirst work to unify video alignment and action segmentation into a single\nmodel."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16872",
    "c_title":[
      "Mitigating Hallucinations in Diffusion Models through Adaptive Attention\n  Modulation"
    ],
    "c_abstract":[
      "Diffusion models, while increasingly adept at generating realistic images,\nare notably hindered by hallucinations -- unrealistic or incorrect features\ninconsistent with the trained data distribution. In this work, we propose\nAdaptive Attention Modulation (AAM), a novel approach to mitigate\nhallucinations by analyzing and modulating the self-attention mechanism in\ndiffusion models. We hypothesize that self-attention during early denoising\nsteps may inadvertently amplify or suppress features, contributing to\nhallucinations. To counter this, AAM introduces a temperature scaling mechanism\nwithin the softmax operation of the self-attention layers, dynamically\nmodulating the attention distribution during inference. Additionally, AAM\nemploys a masked perturbation technique to disrupt early-stage noise that may\notherwise propagate into later stages as hallucinations. Extensive experiments\ndemonstrate that AAM effectively reduces hallucinatory artifacts, enhancing\nboth the fidelity and reliability of generated images. For instance, the\nproposed approach improves the FID score by 20.8% and reduces the percentage of\nhallucinated images by 12.9% (in absolute terms) on the Hands dataset."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-425",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05296",
    "b_title":[
      "Speejis: Enhancing User Experience of Mobile Voice Messaging with\n  Automatic Visual Speech Emotion Cues"
    ],
    "b_abstract":[
      "Mobile messaging apps offer an increasing range of emotional expressions,\nsuch as emojis to help users manually augment their texting experiences.\nAccessibility of such augmentations is limited in voice messaging. With the\nterm \"speejis\" we refer to accessible emojis and other visual speech emotion\ncues that are created automatically from speech input alone. The paper presents\nan implementation of speejis and reports on a user study (N=12) comparing the\nUX of voice messaging with and without speejis. Results show significant\ndifferences in measures such as attractiveness and stimulation and a clear\npreference of all participants for messaging with speejis. We highlight the\nbenefits of using paralinguistic speech processing and continuous emotion\nmodels to enable finer grained augmentations of emotion changes and transitions\nwithin a single message in addition to augmentations of the overall tone of the\nmessage."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16501",
    "c_title":[
      "Virtual Reality in Social Media: A New Era of Immersive Social\n  Interactions"
    ],
    "c_abstract":[
      "Human communication has been profoundly changed by social media, which allows\nusers to engage in previously unheard-of ways, such as text-based\nconversations, video chats, and live streaming. The digital landscape has\nstarted to change in recent years as a result of the introduction of Virtual\nReality (VR) to these platforms. Instead of using conventional 2D screens, VR\noffers a completely immersive experience that lets users interact with content\nand one another in 3D spaces. This study examines the integration of virtual\nreality (VR) technology into social media applications, evaluating their\npotential to provide more dynamic and captivating digital spaces. Globally,\nsocial media sites like Facebook, Instagram, and Twitter have already changed\nthe nature of communication. Immersion technologies like virtual reality (VR)\nrepresent the next stage, though, as they have the ability to change how we\ninteract, connect, and share in social settings in addition to improving user\nexperience."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-426",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09831",
    "b_title":[
      "Strong normalization through idempotent intersection types: a new\n  syntactical approach"
    ],
    "b_abstract":[
      "It is well-known that intersection type assignment systems can be used to\ncharacterize strong normalization (SN). Typical proofs that typable\nlambda-terms are SN in these systems rely on semantical techniques. In this\nwork, we study $\\Lambda_\\cap^e$, a variant of Coppo and Dezani's (Curry-style)\nintersection type system, and we propose a syntactical proof of strong\nnormalization for it. We first design $\\Lambda_\\cap^i$, a Church-style version,\nin which terms closely correspond to typing derivations. Then we prove that\ntypability in $\\Lambda_\\cap^i$ implies SN through a measure that, given a term,\nproduces a natural number that decreases along with reduction. Finally, the\nresult is extended to $\\Lambda_\\cap^e$, since the two systems simulate each\nother."
    ],
    "b_categories":[
      [
        "cs.LO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19963",
    "c_title":[
      "Exploiting Partial Assignments in Optimization Modulo Theories"
    ],
    "c_abstract":[
      "Optimization Modulo Theories (OMT) extends Satisfiability Modulo Theories\n(SMT) with the task of optimizing some objective function(s). In OMT solvers, a\nCDCL-based SMT solver enumerates theory-satisfiable total truth assignments,\nand a theory-specific procedure finds an optimum model for each of them; the\ncurrent optimum is then used to tighten the search space for the next\nassignments, until no better solution is found.\n  In this paper, we analyze the role of truth-assignment enumeration in OMT.\nFirst, we spotlight that the enumeration of total truth assignments is\nsuboptimal, since they may over-restrict the search space for the optimization\nprocedure, whereas using partial truth assignments instead can improve the\neffectiveness of the optimization. Second, we propose some reduction techniques\nfor better exploiting partial assignments in the OMT context. We implemented\nthese techniques in the OPTIMATHSAT solver, and conducted an experimental\nevaluation on OMT(LRA) benchmarks. The results support the efficiency and\neffectiveness of our approach."
    ],
    "c_categories":[
      [
        "cs.LO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-427",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09771",
    "b_title":[
      "Knowledge-Enhanced Program Repair for Data Science Code"
    ],
    "b_abstract":[
      "This paper introduces DSrepair, a knowledge-enhanced program repair method\ndesigned to repair the buggy code generated by LLMs in the data science domain.\nDSrepair uses knowledge graph based RAG for API knowledge retrieval as well as\nbug knowledge enrichment to construct repair prompts for LLMs. Specifically, to\nenable knowledge graph based API retrieval, we construct DS-KG (Data Science\nKnowledge Graph) for widely used data science libraries. For bug knowledge\nenrichment, we employ an abstract syntax tree (AST) to localize errors at the\nAST node level. DSrepair's effectiveness is evaluated against five\nstate-of-the-art LLM-based repair baselines using four advanced LLMs on the\nDS-1000 dataset. The results show that DSrepair surpasses all five baselines.\nSpecifically, when compared to the second-best baseline, DSrepair demonstrates\nsignificant improvements, fixing 44.4%, 14.2%, 20.6%, and 32.1% more buggy code\nsnippets for each of the four evaluated LLMs, respectively. Additionally, it\nachieves greater efficiency, reducing the number of tokens required per code\ntask by 17.49%, 34.24%, 24.71%, and 17.59%, respectively."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10696",
    "c_title":[
      "Improving Retrieval-Augmented Deep Assertion Generation via Joint\n  Training"
    ],
    "c_abstract":[
      "Unit testing attempts to validate the correctness of basic units of the\nsoftware system under test and has a crucial role in software development and\ntesting. Very recent work proposes a retrieve-and-edit approach to generate\nunit test oracles, i.e., assertions. Despite being promising, it is still far\nfrom perfect due to some limitations, such as splitting assertion retrieval and\ngeneration into two separate components without benefiting each other. In this\npaper, we propose AG-RAG, a retrieval-augmented automated assertion generation\napproach that leverages external codebases and joint training to address\nvarious technical limitations of prior work. Inspired by the plastic surgery\nhypothesis, AG-RAG attempts to combine relevant unit tests and advanced\npre-trained language models (PLMs) with retrieval-augmented fine-tuning. AG-RAG\nbuilds a dense retriever to search for relevant test-assert pairs (TAPs) with\nsemantic matching and a retrieval-augmented generator to synthesize accurate\nassertions with the focal-test and retrieved TAPs as input. Besides, AG-RAG\nleverages a code-aware language model CodeT5 as the cornerstone to facilitate\nboth assertion retrieval and generation tasks. Furthermore, the retriever is\noptimized in conjunction with the generator as a whole pipeline with a joint\ntraining strategy. This unified design fully adapts both components\nspecifically for retrieving more useful TAPs, thereby generating accurate\nassertions. We extensively evaluate AG-RAG against six state-of-the-art AG\napproaches on two benchmarks and three metrics. Experimental results show that\nAG-RAG significantly outperforms previous AG approaches on all benchmarks and\nmetrics, e.g., improving the most recent baseline EditAS by 20.82% and 26.98%\nin terms of accuracy. AG-RAG also correctly generates 1739 and 2866 unique\nassertions that all baselines fail to generate, 3.45X and 9.20X more than\nEditAS."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-428",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05468",
    "b_title":[
      "LatteReview: A Multi-Agent Framework for Systematic Review Automation\n  Using Large Language Models"
    ],
    "b_abstract":[
      "Systematic literature reviews and meta-analyses are essential for\nsynthesizing research insights, but they remain time-intensive and\nlabor-intensive due to the iterative processes of screening, evaluation, and\ndata extraction. This paper introduces and evaluates LatteReview, a\nPython-based framework that leverages large language models (LLMs) and\nmulti-agent systems to automate key elements of the systematic review process.\nDesigned to streamline workflows while maintaining rigor, LatteReview utilizes\nmodular agents for tasks such as title and abstract screening, relevance\nscoring, and structured data extraction. These agents operate within\norchestrated workflows, supporting sequential and parallel review rounds,\ndynamic decision-making, and iterative refinement based on user feedback.\nLatteReview's architecture integrates LLM providers, enabling compatibility\nwith both cloud-based and locally hosted models. The framework supports\nfeatures such as Retrieval-Augmented Generation (RAG) for incorporating\nexternal context, multimodal reviews, Pydantic-based validation for structured\ninputs and outputs, and asynchronous programming for handling large-scale\ndatasets. The framework is available on the GitHub repository, with detailed\ndocumentation and an installable package."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14095",
    "c_title":[
      "Retrieving Versus Understanding Extractive Evidence in Few-Shot Learning"
    ],
    "c_abstract":[
      "A key aspect of alignment is the proper use of within-document evidence to\nconstruct document-level decisions. We analyze the relationship between the\nretrieval and interpretation of within-document evidence for large language\nmodel in a few-shot setting. Specifically, we measure the extent to which model\nprediction errors are associated with evidence retrieval errors with respect to\ngold-standard human-annotated extractive evidence for five datasets, using two\npopular closed proprietary models. We perform two ablation studies to\ninvestigate when both label prediction and evidence retrieval errors can be\nattributed to qualities of the relevant evidence. We find that there is a\nstrong empirical relationship between model prediction and evidence retrieval\nerror, but that evidence retrieval error is mostly not associated with evidence\ninterpretation error--a hopeful sign for downstream applications built on this\nmechanism."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-429",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19051",
    "b_title":[
      "Swift: Rethinking RDMA Control Plane for Elastic Computing"
    ],
    "b_abstract":[
      "Elastic computing enables dynamic scaling to meet workload demands, and\nRemote Direct Memory Access (RDMA) enhances this by providing high-throughput,\nlow-latency network communication. However, integrating RDMA into elastic\ncomputing remains a challenge, particularly in control plane operations for\nRDMA connection setup.\n  This paper revisits the assumptions of prior work on high-performance RDMA\nfor elastic computing, and reveals that extreme microsecond-level control plane\noptimizations are often unnecessary. By challenging the conventional beliefs on\nthe slowness of user-space RDMA control plane and the difficulty of user-space\nRDMA resource sharing, we uncover new design opportunities. Our key insight is\nthat user-space RDMA connection setup can be significantly improved with\ncaching, while RDMA resources can be efficiently shared among processes using\nfork. In light of this, we propose Swift, a simple yet effective solution that\nco-designs RDMA with a serverless framework to optimize performance for elastic\ncomputing. At its very core, Swift handles cold and warm serverless requests by\nswiftly initializing the RDMA control plane with cache-optimized libibverbs,\nand manages fork requests by leveraging the RDMA's fork capability. Implemented\nwith OpenWhisk, Swift delivers 30.56-46.50% higher average throughput and\n18.55-37.21% lower latency, at a cost of 6.5% control plane overhead, compared\nto prior solutions."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.08751",
    "c_title":[
      "Can Millimeter-Wave Support Interactive Extended Reality Under Rapid\n  Rotational Motion?"
    ],
    "c_abstract":[
      "Using Millimeter-Wave (mmWave) wireless communications is often named as the\nprime enabler for mobile interactive Extended Reality (XR), as it offers\nmulti-gigabit data rates at millisecond-range latency. To achieve this, mmWave\nnodes must focus their energy towards each other, which is especially\nchallenging in XR scenarios, where the transceiver on the user's XR device may\nrotate rapidly. To evaluate the feasibility of mmWave XR, we present the first\nthroughput and latency evaluation of state-of-the-art mmWave hardware under\nrapid rotational motion, for different PHY and MAC-layer parameter\nconfigurations. We show that this parameter configuration has a significant\nimpact on performance, and that specialized beamforming approaches for rapid\nrotational motion may be necessary to enable uninterrupted, high-quality mobile\ninteractive XR experiences."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-430",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14282",
    "b_title":[
      "PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex\n  Task Automation on PC"
    ],
    "b_abstract":[
      "In the field of MLLM-based GUI agents, compared to smartphones, the PC\nscenario not only features a more complex interactive environment, but also\ninvolves more intricate intra- and inter-app workflows. To address these\nissues, we propose a hierarchical agent framework named PC-Agent. Specifically,\nfrom the perception perspective, we devise an Active Perception Module (APM) to\novercome the inadequate abilities of current MLLMs in perceiving screenshot\ncontent. From the decision-making perspective, to handle complex user\ninstructions and interdependent subtasks more effectively, we propose a\nhierarchical multi-agent collaboration architecture that decomposes\ndecision-making processes into Instruction-Subtask-Action levels. Within this\narchitecture, three agents (i.e., Manager, Progress and Decision) are set up\nfor instruction decomposition, progress tracking and step-by-step\ndecision-making respectively. Additionally, a Reflection agent is adopted to\nenable timely bottom-up error feedback and adjustment. We also introduce a new\nbenchmark PC-Eval with 25 real-world complex instructions. Empirical results on\nPC-Eval show that our PC-Agent achieves a 32% absolute improvement of task\nsuccess rate over previous state-of-the-art methods. The code is available at\nhttps:\/\/github.com\/X-PLUG\/MobileAgent\/tree\/main\/PC-Agent."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.17699",
    "c_title":[
      "MUST: The First Dataset and Unified Framework for Multispectral UAV\n  Single Object Tracking"
    ],
    "c_abstract":[
      "UAV tracking faces significant challenges in real-world scenarios, such as\nsmall-size targets and occlusions, which limit the performance of RGB-based\ntrackers. Multispectral images (MSI), which capture additional spectral\ninformation, offer a promising solution to these challenges. However, progress\nin this field has been hindered by the lack of relevant datasets. To address\nthis gap, we introduce the first large-scale Multispectral UAV Single Object\nTracking dataset (MUST), which includes 250 video sequences spanning diverse\nenvironments and challenges, providing a comprehensive data foundation for\nmultispectral UAV tracking. We also propose a novel tracking framework,\nUNTrack, which encodes unified spectral, spatial, and temporal features from\nspectrum prompts, initial templates, and sequential searches. UNTrack employs\nan asymmetric transformer with a spectral background eliminate mechanism for\noptimal relationship modeling and an encoder that continuously updates the\nspectrum prompt to refine tracking, improving both accuracy and efficiency.\nExtensive experiments show that our proposed UNTrack outperforms\nstate-of-the-art UAV trackers. We believe our dataset and framework will drive\nfuture research in this area. The dataset is available on\nhttps:\/\/github.com\/q2479036243\/MUST-Multispectral-UAV-Single-Object-Tracking."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-431",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15158",
    "b_title":[
      "Waveform and Filter Design for Integrated Sensing and Communication\n  Against Signal-dependent Modulated Jamming"
    ],
    "b_abstract":[
      "This paper focuses on an integrated sensing and communication (ISAC) system\nin the presence of signal-dependent modulated jamming (SDMJ). Our goal is to\nsuppress jamming while carrying out simultaneous communications and sensing. We\nminimize the integrated sidelobe level (ISL) of the mismatch filter output for\nthe transmitted waveform and the integrated level (IL) of the mismatch filter\noutput for the jamming, under the constraints of the loss in-processing gain\n(LPG) and the peak-to-average power ratio (PAPR) of the transmitted waveform.\nMeanwhile, the similarity constraint is introduced for information-bearing\ntransmit waveform. We develop a decoupled majorization minimization (DMM)\nalgorithm to solve the proposed multi-constrained optimization problem. In\ncontrast to the existing approaches, the proposed algorithm transforms the\ndifficult optimization problem involving two variables into two parallel\nsub-problems with one variable, thus significantly speeding up the convergence\nrate. Furthermore, fast Fourier transform (FFT) is introduced to compute the\nclosed-form solution of each sub-problem, giving rise to a greatly reduced\ncomputation complexity. Simulation results demonstrate the capabilities of the\nproposed ISAC system which strikes a proper trade-off among sensing and jamming\nsuppression."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12209",
    "c_title":[
      "Machine Learning Based Probe Skew Correction for High-frequency BH Loop\n  Measurements"
    ],
    "c_abstract":[
      "Experimental characterization of magnetic components has grown to be\nincreasingly important to understand and model their behaviours in\nhigh-frequency PWM converters. The BH loop measurement is the only available\napproach to separate the core loss as an electrical method, which, however, is\nsuspective to the probe phase skew. As an alternative to the regular de-skew\napproaches based on hardware, this work proposes a novel machine-learning-based\nmethod to identify and correct the probe skew, which builds on the newly\ndiscovered correlation between the skew and the shape\/trajectory of the\nmeasured BH loop. A special technique is proposed to artificially generate the\nskewed images from measured waveforms as augmented training sets. A machine\nlearning pipeline is developed with the Convolutional Neural Network (CNN) to\ntreat the problem as an image-based prediction task. The trained model has\ndemonstrated a high accuracy in identifying the skew value from a BH loop\nunseen by the model, which enables the compensation of the skew to yield the\ncorrected core loss value and BH loop."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-432",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10189",
    "b_title":[
      "Optimizing Structured-Sparse Matrix Multiplication in RISC-V Vector\n  Processors"
    ],
    "b_abstract":[
      "Structured sparsity has been proposed as an efficient way to prune the\ncomplexity of Machine Learning (ML) applications and to simplify the handling\nof sparse data in hardware. Accelerating ML models, whether for training, or\ninference, heavily relies on matrix multiplications that can be efficiently\nexecuted on vector processors, or custom matrix engines. This work aims to\nintegrate the simplicity of structured sparsity into vector execution to speed\nup the corresponding matrix multiplications. Initially, the implementation of\nstructured-sparse matrix multiplication using the current RISC-V instruction\nset vector extension is comprehensively explored. Critical parameters that\naffect performance, such as the impact of data distribution across the scalar\nand vector register files, data locality, and the effectiveness of loop\nunrolling are analyzed both qualitatively and quantitatively. Furthermore, it\nis demonstrated that the addition of a single new instruction would reap even\nhigher performance. The newly proposed instruction is called vindexmac, i.e.,\nvector index-multiply-accumulate. It allows for indirect reads from the vector\nregister file and it reduces the number of instructions executed per matrix\nmultiplication iteration, without introducing additional dependencies that\nwould limit loop unrolling. The proposed new instruction was integrated in a\ndecoupled RISC-V vector processor with negligible hardware cost. Experimental\nresults demonstrate the runtime efficiency and the scalability offered by the\nintroduced optimizations and the new instruction for the execution of\nstate-of-the-art Convolutional Neural Networks. More particularly, the addition\nof a custom instruction improves runtime by 25% and 33% when compared with\nhighly-optimized vectorized kernels that use only the currently defined RISC-V\ninstructions."
    ],
    "b_categories":[
      [
        "cs.AR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.20965",
    "c_title":[
      "Understanding intra-node communication in HPC systems and Datacenters"
    ],
    "c_abstract":[
      "Over the past decade, specialized computing and storage devices, such as\nGPUs, TPUs, and high-speed storage, have been increasingly integrated into\nserver nodes within Supercomputers and Data Centers. The advent of\nhigh-bandwidth memory (HBM) has facilitated a more compact design for these\ncomponents, enabling multiple units to be interconnected within a single server\nnode through intra-node networks like PCIe, NVLink, or Ethernet. These networks\nallow for scaling up the number of dedicated computing and storage devices per\nnode. Additionally, inter-node networks link these devices across thousands of\nserver nodes in large-scale computing systems. However, as communication\ndemands among accelerators grow-especially in workloads like generative AI-both\nintra- and inter-node networks risk becoming critical bottlenecks. Although\nmodern intra-node network architectures attempt to mitigate this issue by\nboosting bandwidth, we demonstrate in this paper that such an approach can\ninadvertently degrade inter-node communication. This occurs when high-bandwidth\nintra-node traffic interferes with incoming traffic from external nodes,\nleading to congestion. To evaluate this phenomenon, we analyze the\ncommunication behavior of realistic traffic patterns commonly found in\ngenerative AI applications. Using OMNeT++, we developed a general simulation\nmodel that captures both intra- and inter-node network interactions. Through\nextensive simulations, our findings reveal that increasing intra-node bandwidth\nand the number of accelerators per node can actually hinder overall inter-node\ncommunication performance rather than improve it."
    ],
    "c_categories":[
      [
        "cs.AR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-433",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05862",
    "b_title":[
      "Language-Inspired Relation Transfer for Few-shot Class-Incremental\n  Learning"
    ],
    "b_abstract":[
      "Depicting novel classes with language descriptions by observing few-shot\nsamples is inherent in human-learning systems. This lifelong learning\ncapability helps to distinguish new knowledge from old ones through the\nincrease of open-world learning, namely Few-Shot Class-Incremental Learning\n(FSCIL). Existing works to solve this problem mainly rely on the careful tuning\nof visual encoders, which shows an evident trade-off between the base knowledge\nand incremental ones. Motivated by human learning systems, we propose a new\nLanguage-inspired Relation Transfer (LRT) paradigm to understand objects by\njoint visual clues and text depictions, composed of two major steps. We first\ntransfer the pretrained text knowledge to the visual domains by proposing a\ngraph relation transformation module and then fuse the visual and language\nembedding by a text-vision prototypical fusion module. Second, to mitigate the\ndomain gap caused by visual finetuning, we propose context prompt learning for\nfast domain alignment and imagined contrastive learning to alleviate the\ninsufficient text data during alignment. With collaborative learning of domain\nalignments and text-image transfer, our proposed LRT outperforms the\nstate-of-the-art models by over $13\\%$ and $7\\%$ on the final session of\nmini-ImageNet and CIFAR-100 FSCIL benchmarks."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09411",
    "c_title":[
      "Towards Robust and Realistic Human Pose Estimation via WiFi Signals"
    ],
    "c_abstract":[
      "Robust WiFi-based human pose estimation is a challenging task that bridges\ndiscrete and subtle WiFi signals to human skeletons. This paper revisits this\nproblem and reveals two critical yet overlooked issues: 1) cross-domain gap,\ni.e., due to significant variations between source-target domain pose\ndistributions; and 2) structural fidelity gap, i.e., predicted skeletal poses\nmanifest distorted topology, usually with misplaced joints and disproportionate\nbone lengths. This paper fills these gaps by reformulating the task into a\nnovel two-phase framework dubbed DT-Pose: Domain-consistent representation\nlearning and Topology-constrained Pose decoding. Concretely, we first propose a\ntemporal-consistent contrastive learning strategy with uniformity\nregularization, coupled with self-supervised masking-reconstruction operations,\nto enable robust learning of domain-consistent and motion-discriminative\nWiFi-specific representations. Beyond this, we introduce a simple yet effective\npose decoder with task prompts, which integrates Graph Convolution Network\n(GCN) and Transformer layers to constrain the topology structure of the\ngenerated skeleton by exploring the adjacent-overarching relationships among\nhuman joints. Extensive experiments conducted on various benchmark datasets\nhighlight the superior performance of our method in tackling these fundamental\nchallenges in both 2D\/3D human pose estimation tasks."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-434",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14015",
    "b_title":[
      "Apples to Apples in Jet Quenching: robustness of Machine Learning\n  classification of quenched jets to Underlying Event contamination"
    ],
    "b_abstract":[
      "Progress in the theoretical understanding of parton branching dynamics within\nan expanding Quark Gluon Plasma relies on detailed and fair comparisons with\nexperimental data for reconstructed jets. Such comparisons are only meaningful\nwhen the computed jet, be it analytically or via event generation, accounts for\nthe complexity of jets reconstructed in the challenging environment of\nheavy-ion collisions. Jet reconstruction in heavy ion collisions involves a\nnecessarily imperfect subtraction of the large and fluctuating underlying\nevent: reconstructed jets always include underlying event contamination. To\nidentify true jet quenching effects, modifications due to the interaction of\nthe branching partonic system with the Quark Gluon Plasma, we establish a\nbaseline that accounts for possible background contamination on unmodified\njets. In practical terms, jet quenching effects are only those not present in\njets produced in proton-proton collisions that have been embedded in a\nrealistic heavy-ion background and where subtraction has been carried out\nanalogously to that in the heavy ion case. With this setup, we assess the\nsensitivity to underlying event of commonly discussed jet quenching observables\nand its impact on the robustness of Machine Learning studies, aimed at\nclassifying jets according to their degree of modification by the Quark Gluon\nPlasma, that rely on those observables. We find the discrimination power of a\nsimple Boosted Decision Tree to be robust in the realistic scenario where both\nmedium response and underlying event are present, giving support to portability\nto the experimental context."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17573",
    "c_title":[
      "Multi-Lepton Jets from Quadruple $Z'$ via the Higgs Decay at LHC"
    ],
    "c_abstract":[
      "We investigate multi-lepton jet events from the decay of the 125 GeV Higgs\nboson ($h$) into quadruple new gauge bosons $(Z')$ at the LHC. Such an exotic\ndecay is realized via the process of $h \\to \\phi \\phi \\to Z'Z'Z'Z'$ with new\nscalar boson $\\phi$ in models with an additional $U(1)$ gauge symmetry. Charged\nleptons coming from the $Z'$ decay tend to be observed as lepton-jets rather\nthan isolated leptons when the masses of $Z'$ and $\\phi$ are smaller than\n${\\cal O}$(10) GeV, because of the highly-boosted effects. Performing the\nsignal and background analyses, we find that the branching ratio of $h \\to 4Z'$\nis maximally constrained to be smaller than of order $10^{-6}$ ($10^{-7}$) by\nusing the muonic-lepton jets assuming the integrated luminosity of 140\nfb$^{-1}$ (3000 fb$^{-1}$) at LHC. For lighter $Z'$ ($< 2m_\\mu$), we can use\nthe electronic-lepton jets instead of the muon-jets, by which the upper limit\non the branching ratio is obtained to be of order $10^{-6}$-$10^{-5}$. These\nbounds can be converted into the constraint on model parameters such as a\nmixing angle between $h$ and $\\phi$. It is shown that stronger bounds on the\nmixing angle are obtained in the dark photon case as compared with the previous\nconstraints given by flavor experiments and the Higgs decay $h \\to Z'Z'$ in the\nmass range of $m_{Z'}\\lesssim 10$ GeV."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-435",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17258",
    "b_title":[
      "Controlling AI Agent Participation in Group Conversations: A\n  Human-Centered Approach"
    ],
    "b_abstract":[
      "Conversational AI agents are commonly applied within single-user, turn-taking\nscenarios. The interaction mechanics of these scenarios are trivial: when the\nuser enters a message, the AI agent produces a response. However, the\ninteraction dynamics are more complex within group settings. How should an\nagent behave in these settings? We report on two experiments aimed at\nuncovering users' experiences of an AI agent's participation within a group, in\nthe context of group ideation (brainstorming). In the first study, participants\nbenefited from and preferred having the AI agent in the group, but participants\ndisliked when the agent seemed to dominate the conversation and they desired\nvarious controls over its interactive behaviors. In the second study, we\ncreated functional controls over the agent's behavior, operable by group\nmembers, to validate their utility and probe for additional requirements.\nIntegrating our findings across both studies, we developed a taxonomy of\ncontrols for when, what, and where a conversational AI agent in a group should\nrespond, who can control its behavior, and how those controls are specified and\nimplemented. Our taxonomy is intended to aid AI creators to think through\nimportant considerations in the design of mixed-initiative conversational\nagents."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13779",
    "c_title":[
      "User Agency and System Automation in Interactive Intelligent Systems"
    ],
    "c_abstract":[
      "Balancing user agency and system automation is essential for effective\nhuman-AI interactions. Fully automated systems can deliver efficiency but risk\nundermining usability and user autonomy, while purely manual tools are often\ninefficient and fail to enhance user capabilities. This dissertation addresses\nthe question: \"How can we balance user agency and system automation for\ninteractions with intelligent systems?\"\n  We present four main contributions. First, we develop a spherical\nelectromagnet that provides adjustable forces on an untethered tool, allowing\nhaptic feedback while preserving user agency. Second, we create an integrated\nsensing and actuation system that tracks a passive magnetic tool in 3D and\ndelivers haptic feedback without external tracking. Third, we propose an\noptimal control method for electromagnetic haptic guidance that balances user\ninput with system control, enabling users to adjust trajectories and speed.\nFinally, we introduce a model-free reinforcement learning approach for adaptive\ninterfaces that learns interface adaptations without heuristics or real user\ndata. Our simulations and user studies show that shared control significantly\noutperforms naive strategies. By incorporating explicit or implicit models of\nhuman behavior into control strategies, intelligent systems can better account\nfor user agency. We demonstrate that the trade-off between agency and\nautomation is both an algorithmic challenge and an engineering concern, shaped\nby the design of physical devices and user interfaces. We advocate an\nintegrated, end-to-end approach-combining algorithmic, engineering, and design\nperspectives-to enable more intuitive and effective interactions with\nintelligent systems."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-436",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11940",
    "b_title":[
      "The Dynamic Model of the UR10 Robot and its ROS2 Integration"
    ],
    "b_abstract":[
      "This paper presents the full dynamic model of the UR10 industrial robot. A\ntriple-stage identification approach is adopted to estimate the manipulator's\ndynamic coefficients. First, linear parameters are computed using a standard\nlinear regression algorithm. Subsequently, nonlinear friction parameters are\nestimated according to a sigmoidal model. Lastly, motor drive gains are devised\nto map estimated joint currents to torques. The overall identified model can be\nused for both control and planning purposes, as the accompanied ROS2 software\ncan be easily reconfigured to account for a generic payload. The estimated\nrobot model is experimentally validated against a set of exciting trajectories\nand compared to the state-of-the-art model for the same manipulator, achieving\nhigher current prediction accuracy (up to a factor of 4.43) and more precise\nmotor gains. The related software is available at\nhttps:\/\/codeocean.com\/capsule\/8515919\/tree\/v2."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03356",
    "c_title":[
      "Inverse Mixed Strategy Games with Generative Trajectory Models"
    ],
    "c_abstract":[
      "Game-theoretic models are effective tools for modeling multi-agent\ninteractions, especially when robots need to coordinate with humans. However,\napplying these models requires inferring their specifications from observed\nbehaviors -- a challenging task known as the inverse game problem. Existing\ninverse game approaches often struggle to account for behavioral uncertainty\nand measurement noise, and leverage both offline and online data. To address\nthese limitations, we propose an inverse game method that integrates a\ngenerative trajectory model into a differentiable mixed-strategy game\nframework. By representing the mixed strategy with a conditional variational\nautoencoder (CVAE), our method can infer high-dimensional, multi-modal behavior\ndistributions from noisy measurements while adapting in real-time to new\nobservations. We extensively evaluate our method in a simulated navigation\nbenchmark, where the observations are generated by an unknown game model.\nDespite the model mismatch, our method can infer Nash-optimal actions\ncomparable to those of the ground-truth model and the oracle inverse game\nbaseline, even in the presence of uncertain agent objectives and noisy\nmeasurements."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-437",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08666",
    "b_title":[
      "Modeling Stock Return Distributions and Pricing Options"
    ],
    "b_abstract":[
      "This paper provides evidence that stock returns, after truncation, might be\nmodeled by a special type of continuous mixtures or normals, so-called\n$q$-Gaussians. Negative binomial distributions might model the counts for\nextreme returns. A generalized jump-diffusion model is proposed, and an\nexplicit option pricing formula is obtained."
    ],
    "b_categories":[
      [
        "q-fin.MF"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2503.18165",
    "c_title":[
      "Agent-Based Models for Two Stocks with Superhedging"
    ],
    "c_abstract":[
      "An agent-based modelling methodology for the joint price evolution of two\nstocks is put forward. The method models future multidimensional price\ntrajectories reflecting how a class of agents rebalance their portfolios in an\noperational way by reacting to how stocks' charts unfold. Prices are expressed\nin units of a third stock that acts as numeraire. The methodology is robust, in\nparticular, it does not depend on any prior probability or analytical\nassumptions and it is based on constructing scenarios\/trajectories. A main\ningredient is a superhedging interpretation that provides relative superhedging\nprices between the two modelled stocks. The operational nature of the\nmethodology gives objective conditions for the validity of the model and so\nimplies realistic risk-rewards profiles for the agent's operations.\nSuperhedging computations are performed with a dynamic programming algorithm\ndeployed on a graph data structure. Null subsets of the trajectory space are\ndirectly related to arbitrage opportunities (i.e. there is no need for\nprobabilistic considerations) that may emerge during the trajectory set\nconstruction. It follows that the superhedging algorithm handles null sets in a\nrigorous and intuitive way. Superhedging and underhedging bounds are kept\nrelevant to the investor by means of a worst case pruning method and, as an\nalternative, a theory supported pruning that relies on a new notion of small\narbitrage."
    ],
    "c_categories":[
      [
        "q-fin.MF"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-438",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10256",
    "b_title":[
      "On the use of an advanced Kirchhoff rod model to study mooring lines"
    ],
    "b_abstract":[
      "In this work, we investigate the application of an advanced nonlinear\ntorsion- and shear-free Kirchhoff rod model, enhanced with a penalty-based\nbarrier function (to simulate the seabed contact), intended for studying the\nstatic and dynamic behavior of mooring lines. The formulation incorporates\nconservative and non-conservative external loads, including those coming from\nthe surrounding flow (added mass, tangential drag, and normal drag). To\nillustrate the favorable features of this model, we consider some key scenarios\nsuch as static configurations, pulsating force applications at the fairlead,\nand fluid-structure interaction between mooring lines and the surrounding flow.\nVerification against well-established solutions, including catenary\nconfigurations and OpenFAST simulations, shows excellent accuracy in predicting\nmooring line responses for a floating offshore wind turbine. Among the most\nimportant results, we can mention that under normal pulsating loads at the\nfairlead, the mooring line exhibits a transition from a drag-dominated regime\nat low frequencies to an added-mass-dominated regime at higher frequencies.\nFurthermore, tangential forcing at the fairlead reveals a strong coupling\nbetween axial and bending dynamics, contrasting with normal forcing scenarios\nwhere axial dynamics remain largely unaffected. These findings underscore the\npotential of the proposed approach for advanced mooring line simulations."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.06373",
    "c_title":[
      "Stress field in the vicinity of a bubble\/sphere moving in a dilute\n  surfactant solution"
    ],
    "c_abstract":[
      "In this study, we experimentally investigate the stress field around a bubble\nrising in a dilute surfactant solution (20 < Re < 220, high Peclet numbers)\nwhose surface gradually becomes contaminated, and compare it with that around a\nsphere free from surface contamination. We employ a newly developed\npolarization measurement technique, highly sensitive to stress fields near\ninterfaces. First, we validate this method by measuring the flow around a solid\nsphere settling at Re = 120 and comparing results with numerical predictions,\nconfirming its accuracy. We then measure the stress field around a bubble whose\ndrag force transitions from that of a clean interface to that of a rigid\ninterface within the observation region. The stress near the bubble's front\nresembles that of a clean bubble, while the rear behaves like a solid sphere.\nBetween these regions, a discontinuous phase retardation near the cap angle\nindicates a transition from slip to no-slip boundary conditions. Axisymmetric\nstress reconstruction reveals localized stress spike at the cap angle, which\nshifts as surfactant accumulates and increases the drag. Remarkably, the\nmeasured cap angle versus normalized drag coefficient agrees well with\nnumerical simulations at Re = 100 (Cuenot et al. 1997) and shows only a slight\ndeviation from the creeping-flow stagnant cap model (Sadhal and Johnson 1983).\nThis work demonstrates that polarization-based stress field measurements\neffectively capture the interplay between surface contamination and\nhydrodynamics at intermediate Reynolds numbers."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-439",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03209",
    "b_title":[
      "Global perturbation of isolated equivariant chiral skyrmions from the\n  harmonic maps"
    ],
    "b_abstract":[
      "Isolated skyrmion solutions to the 2D Landau-Lifshitz equation with the\nDzyaloshinskii-Moriya interaction, Zeeman interaction, and easy-plane\nanisotropy are considered. In a wide range of parameters illustrating the\nvarious interaction strengths, we construct exact solutions and examine their\nmonotonicity, exponential decay, and stability using a careful mathematical\nanalysis. We also estimate the distance between the constructed solutions and\nthe harmonic maps by exploiting the structure of the linearized equation and by\nproving a resolvent estimate for the linearized operator that is uniform in\nextra implicit potentials."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.08351",
    "c_title":[
      "Existence of Solutions of Nonconvex Multivalued Navier Stokes Equations"
    ],
    "c_abstract":[
      "In this paper, we discuss the existence of local strong solutions for the\nmultivalued version of three-dimensional nonstationary Navier-Stokes equation\nin Banach spaces. Also, we considered a more general inclusion problem and\nstudied the existence of solutions using the fixed point technique approach. We\nassume that the multivalued map possesses closed values (not necessarily convex\nvalues) and apply the Schauder Fixed Point Theorem in order to deduce the\nexistence of fixed points."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-440",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00484",
    "b_title":[
      "Magnetic order and spin dynamics across the ferromagnetic quantum\n  critical point in Ni\\boldmath{$_{1-x}$}Mo\\boldmath{$_{x}$}"
    ],
    "b_abstract":[
      "Realizing a quantum critical point (QCP) in clean ferromagnetic (FM) metals\nhas remained elusive due to the coupling of magnetization to the electronic\nsoft modes that drive the transition to be of first order. However, by\nintroducing a suitable amount of quenched disorder, one can still establish a\nQCP in ferromagnets. In this study, we ascertain that the itinerant ferromagnet\nNi$_{1-x}$Mo$_{x}$ exhibits a FM QCP at a critical doping of $x_c \\simeq\n0.125$. Through magnetization and muon-spin relaxation measurements, we\ndemonstrate that the FM ordering temperature is suppressed continuously to zero\nat $x_c$, while the magnetic volume fraction remains $100\\%$ up to $x_c$,\nindicating a second-order phase transition. The QCP is accompanied by a\nnon-Fermi liquid behavior, as evidenced by the logarithmic divergence of the\nspecific heat and the linear temperature dependence of the low-temperature\nresistivity. Our findings reveal a minimal effect of disorder on the critical\nspin dynamics of Ni$_{1-x}$Mo$_{x}$ at $x_c$, highlighting it as one of the\nrare systems to exhibit a clean FM QCP."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04658",
    "c_title":[
      "Quench of the electronic order in a strongly-coupled charge-density-wave\n  system by enhanced lattice fluctuations"
    ],
    "c_abstract":[
      "Charge-density-wave (CDW) materials having a strong electron-phonon coupling\nprovide a powerful platform for investigating the intricate interplay between\nlattice fluctuations and a macroscopic quantum order. Using time- and\nangle-resolved photoemission spectroscopy (TR-ARPES), we reveal that the CDW\ngap closure in VTe2 is dominated by an incoherent process evolving on a\nsub-picosecond timescale, challenging the conventional view that the gap\ndynamics is primarily governed by the excitation of the CDW amplitude modes.\nOur findings, supported by a three-temperature model, show that the CDW gap\nevolution can be described by considering the population of a subset of\nstrongly-coupled optical phonon modes, which leads to an increase in the\nlattice fluctuations. This microscopic framework extends beyond VTe2, offering\na universal perspective for understanding the light-induced phase transition in\nstrongly-coupled CDW systems."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-441",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06569",
    "b_title":[
      "The palette index of the Cartesian product of paths, cycles and regular\n  graphs"
    ],
    "b_abstract":[
      "The palette of a vertex v in a graph G is the set of colors assigned to the\nedges incident to v. The palette index of G is the minimum number of distinct\npalettes among the vertices, taken over all proper edge colorings of G. This\npaper presents results on the palette index of the Cartesian product $G \\Box\nH$, where one of the factor graphs is a path or a cycle. Additionally, it\nprovides exact results and bounds on the palette index of the Cartesian product\nof two graphs, where one factor graph is isomorphic to a regular or class 1\nnearly regular graph."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.06372",
    "c_title":[
      "A note on Puder's generalised co-growth formula for trees"
    ],
    "c_abstract":[
      "In this note, we prove a conjecture of Puder on an extension of the co-growth\nformula to any non-negative function defined on a bi-regular tree. A key\ncomponent of our proof is the establishment of a resolvent identity, which\nserves as an operator version of the co-growth formula. We also provide a\nsimpler proof of Puder's generalised co-growth formula for the regular tree."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-442",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06599",
    "b_title":[
      "Curvature of Measure-Preserving Diffeomorphism Groups of Non-Orientable\n  Surfaces"
    ],
    "b_abstract":[
      "We study curvatures of the groups of measure-preserving diffeomorphisms of\nnon-orientable compact surfaces. For the cases of the Klein bottle and the real\nprojective plane we compute curvatures, their asymptotics and the normalized\nRicci curvatures in many directions. Extending the approach of V. Arnold, and\nA. Lukatskii we provide estimates of weather unpredictability for natural\nmodels of trade wind currents on the Klein bottle and the projective plane."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11739",
    "c_title":[
      "The structure of weakly stable CMC hypersurfaces with free boundary"
    ],
    "c_abstract":[
      "In this paper, we prove that a complete noncompact weakly stable free\nboundary CMC $H$-hypersurface $(M^{n},\\partial M)$ properly immersed in $(N^\n{n+1},\\partial N)$ must have one end, provided that $N$ has bounded geometry\nand weakly convex boundary, satisfies $\\inf\\Ric_{N}>-\\frac{1}{n}H^2$ and\n$\\biRic_{N}\\geq \\frac{(n-5)}{4}H^2$. Secondly, we establish a non-existence\nresult for noncompact free boundary CMC hypersurfaces under certain conditions,\nas detailed in Theorem \\ref{thm 4}. Finally, we give a rigidity theorem for\nfree boundary minimal hypersurfaces in $5$-manifolds."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-443",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08389",
    "b_title":[
      "Kitaev-Ising-$J_1$-$J_2$ model: a density matrix renormalization group\n  study"
    ],
    "b_abstract":[
      "We numerically study the Kitaev honeycomb model with the additional XX Ising\ninteraction between the nearest and the next nearest neighbors\n(Kitaev-Ising-$J_1$-$J_2$ model), by using the density matrix renormalization\ngroup (DMRG) method. Such additional interaction correspond to the nearest and\ndiagonal interactions on the square lattice. Phase diagram of the bare Kitaev\nmodel consist of low entangled commensurate magnetic phases and entagled Kitaev\nspin liquid. Anisotropic Ising interaction allows the entangled incommensurate\nmagnetic phases in the phase diagram, which previously was predicted only for\nmore complex type of interactions. We study the scaling law of the entanglement\nentropy and the bond dimension of the matrix product state with the size of the\nsystem. In addition, we propose an optimization algorithm to prevent DMRG from\ngetting stuck in the low-entangled phases."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.16805",
    "c_title":[
      "Nuclear magnetic resonance investigation of strain-tuned iron-based\n  superconductors (Druckabh\\\"{a}ngige Untersuchung eisenbasierter Supraleiter\n  mittels Kernspinresonanz)"
    ],
    "c_abstract":[
      "Final report for a Deutsche Forschungsgemeinschaft, Eigenestelle Grant,\nsummarizing work mainly on uniaxial-pressure-dependent nuclear magnetic\nresonance (NMR) investigations of BaFe$_2$As$_2$. We have conducted systematic\n$^{75}$As NMR experiments in BaFe$_2$As$_2$ under in-situ controlled conditions\nof uniaxial pressure. We find that the electric field gradient (EFG),\nspin--lattice relaxation rate T$_1^{-1}$, spin--spin relaxation rate\nT$_2^{-1}$, and Knight shift $K$ at the As site are sensitive to applied\nuniaxial pressure. These properties allow us to locally probe the nematic\nsusceptibility, as well as orbital and spin degrees of freedom. Our spectral\nmeasurements in the magnetic state provide no evidence for spin reorientation\nbelow the T$_N$ for both positive and negative applied uniaxial pressure up to\nthe point of sample failure."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-444",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08487",
    "b_title":[
      "Physics of Pair Producing Gaps in Black Hole Magnetospheres: Two\n  Dimensional General Relativistic Particle-in-cell Simulations"
    ],
    "b_abstract":[
      "Black holes can launch powerful jets through the Blandford-Znajek process.\nThis relies on enough plasma in the jet funnel to conduct the necessary\ncurrent. However, in some low luminosity active galactic nuclei, the plasma\nsupply near the jet base may be an issue. It has been proposed that spark gaps\n-- local regions with unscreened electric field -- can form in the\nmagnetosphere, accelerating particles to initiate pair cascades, thus filling\nthe jet funnel with plasma. In this paper, we carry out 2D general relativistic\nparticle-in-cell (GRPIC) simulations of the gap, including self-consistent\ntreatment of inverse Compton scattering and pair production. We observe gap\ndynamics that is fully consistent with our earlier 1D GRPIC simulations. We\nfind strong dependence of the gap power on the soft photon spectrum and energy\ndensity, as well as the strength of the horizon magnetic field. We derive\nphysically motivated scaling relations, and applying to M87, we find that the\ngap may be energetically viable for the observed TeV flares. For Sgr A$^*$, the\nenergy dissipated in the gap may also be sufficient to power the X-ray flares."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04800",
    "c_title":[
      "Effective resistivity in relativistic reconnection: a prescription based\n  on fully kinetic simulations"
    ],
    "c_abstract":[
      "A variety of high-energy astrophysical phenomena are powered by the release\n-- via magnetic reconnection -- of the energy stored in oppositely directed\nfields. Single-fluid resistive magnetohydrodynamic (MHD) simulations with\nuniform resistivity yield dissipation rates that are much lower (by nearly one\norder of magnitude) than equivalent kinetic calculations. Reconnection-driven\nphenomena could be accordingly modeled in resistive MHD employing a\nnon-uniform, ``effective'' resistivity informed by kinetic calculations. In\nthis work, we analyze a suite of fully kinetic particle-in-cell (PIC)\nsimulations of relativistic pair-plasma reconnection -- where the magnetic\nenergy is greater than the rest mass energy -- for different strengths of the\nguide field orthogonal to the alternating component. We extract an empirical\nprescription for the effective resistivity, $\\eta_{\\mathrm{eff}} = \\alpha B_0\n\\mathbf{|J|}^p \/ \\left(|\\mathbf{J}|^{p+1}+\\left(e n_t c\\right)^{p+1}\\right)$,\nwhere $B_0$ is the reconnecting magnetic field strength, $\\bf J$ is the current\ndensity, $n_t$ the lab-frame total number density, $e$ the elementary charge,\nand $c$ the speed of light. The guide field dependence is encoded in $\\alpha$\nand $p$, which we fit to PIC data. This resistivity formulation -- which relies\nonly on single-fluid MHD quantities -- successfully reproduces the spatial\nstructure and strength of nonideal electric fields, and thus provides a\npromising strategy for enhancing the reconnection rate in resistive MHD\nsimulations."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-445",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15386",
    "b_title":[
      "From Snaking to Isolas: A One-Active-Site Approximation in Discrete\n  Optical Cavities"
    ],
    "b_abstract":[
      "We investigate time-independent solutions of a discrete optical cavity model\nfeaturing saturable Kerr nonlinearity, a discrete version of the\nLugiato-Lefever equation. This model supports continuous wave (uniform) and\nlocalized (discrete soliton) solutions. Stationary bright solitons arise\nthrough the interaction of dark and bright uniform states, forming a homoclinic\nsnaking bifurcation diagram within the Pomeau pinning region. As the system\napproaches the anti-continuum limit (weak coupling), this snaking bifurcation\nwidens and transitions into $\\subset$-shaped isolas. We propose a\none-active-site approximation that effectively captures the system's behavior\nin this regime. The approximation also provides insight into the stability\nproperties of soliton states. Numerical continuation and spectral analysis\nconfirm the accuracy of this semianalytical method, showing excellent agreement\nwith the full model."
    ],
    "b_categories":[
      [
        "nlin.PS"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.09264",
    "c_title":[
      "Defects, parcellation, and renormalized negative diffusivities in\n  non-homogeneous oscillatory media"
    ],
    "c_abstract":[
      "Coupling among oscillators in spatially-extended systems tends to lock their\nfrequency at a common value. In the presence of spatial non-homogeneities,\nlocking of different regions at different frequencies leads to parcellation,\ni.e., a series of synchronized clusters (plateaus). Motivated by rhythmic\ndynamics in physiological systems, we consider a Ginzburg-Landau (GL) model\nwith a gradient of natural frequencies. We determine the scaling of the number\nof plateaus and their typical length {\\it vs} dynamical parameters. Plateaus\nare separated by defects, where the amplitude of the GL field vanishes and\nphase differences are reset. For Dirichlet boundary conditions, we use\nasymptotic methods to determine the field profile around defects. For Neumann\nboundary conditions, we relate the stability phase diagram and defects'\nprecursors to the spectrum of the non-Hermitian Bloch-Torrey equation,\noriginally introduced for nuclear magnetic resonance. In the non-linear regime,\nwe trace the formation of defects to a non-linear renormalization of the\ndiffusivity, which leads to spatially-modulated negative values and an\ninstability that drives amplitude modulation."
    ],
    "c_categories":[
      [
        "nlin.PS"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-446",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17226",
    "b_title":[
      "Leveraging Text-to-Image Generation for Handling Spurious Correlation"
    ],
    "b_abstract":[
      "Deep neural networks trained with Empirical Risk Minimization (ERM) perform\nwell when both training and test data come from the same domain, but they often\nfail to generalize to out-of-distribution samples. In image classification,\nthese models may rely on spurious correlations that often exist between labels\nand irrelevant features of images, making predictions unreliable when those\nfeatures do not exist. We propose a technique to generate training samples with\ntext-to-image (T2I) diffusion models for addressing the spurious correlation\nproblem. First, we compute the best describing token for the visual features\npertaining to the causal components of samples by a textual inversion\nmechanism. Then, leveraging a language segmentation method and a diffusion\nmodel, we generate new samples by combining the causal component with the\nelements from other classes. We also meticulously prune the generated samples\nbased on the prediction probabilities and attribution scores of the ERM model\nto ensure their correct composition for our objective. Finally, we retrain the\nERM model on our augmented dataset. This process reduces the model's reliance\non spurious correlations by learning from carefully crafted samples for in\nwhich this correlation does not exist. Our experiments show that across\ndifferent benchmarks, our technique achieves better worst-group accuracy than\nthe existing state-of-the-art methods."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00315",
    "c_title":[
      "MonoDINO-DETR: Depth-Enhanced Monocular 3D Object Detection Using a\n  Vision Foundation Model"
    ],
    "c_abstract":[
      "This paper proposes novel methods to enhance the performance of monocular 3D\nobject detection models by leveraging the generalized feature extraction\ncapabilities of a vision foundation model. Unlike traditional CNN-based\napproaches, which often suffer from inaccurate depth estimation and rely on\nmulti-stage object detection pipelines, this study employs a Vision Transformer\n(ViT)-based foundation model as the backbone, which excels at capturing global\nfeatures for depth estimation. It integrates a detection transformer (DETR)\narchitecture to improve both depth estimation and object detection performance\nin a one-stage manner. Specifically, a hierarchical feature fusion block is\nintroduced to extract richer visual features from the foundation model, further\nenhancing feature extraction capabilities. Depth estimation accuracy is further\nimproved by incorporating a relative depth estimation model trained on\nlarge-scale data and fine-tuning it through transfer learning. Additionally,\nthe use of queries in the transformer's decoder, which consider reference\npoints and the dimensions of 2D bounding boxes, enhances recognition\nperformance. The proposed model outperforms recent state-of-the-art methods, as\ndemonstrated through quantitative and qualitative evaluations on the KITTI 3D\nbenchmark and a custom dataset collected from high-elevation racing\nenvironments. Code is available at https:\/\/github.com\/JihyeokKim\/MonoDINO-DETR."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-447",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09124",
    "b_title":[
      "Two-level control over quantum state creation via entangled\n  equal-probability state"
    ],
    "b_abstract":[
      "We propose the scheme realizing the two-level control over the unitary\noperators $U_k$ creating the required quantum state of the system $S$. These\noperators are controlled by the superposition state of the auxiliary subsystem\n$R$ which is governed by two control centers. The\n  first-level control center (main control) creates the equal-probability pure\nstate of $R$ with certain distribution of phase factors that, in turn, govern\nthe power of the second-level control center $C$ that applies the special\n$V$-operators to the same subsystem $R$ changing its state and thus controlling\nthe applicability of $U_k$. In addition, the above phases are responsible for\nthe entanglement in the subsystem $R$. We find the direct relation between this\nentanglement and the number of operators $U_k$ that can be controlled by $C$.\nThe simple example of a two-level control system governing the creation of\nentangled state of the two-qubit system $S$ is presented."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.13225",
    "c_title":[
      "Optimizing the frequency positioning of tunable couplers in a circuit\n  QED processor to mitigate spectator effects on quantum operations"
    ],
    "c_abstract":[
      "We experimentally optimize the frequency of flux-tunable couplers in a\nsuperconducting quantum processor to minimize the impact of spectator transmons\nduring quantum operations (single-qubit gates, two-qubit gates and readout) on\nother transmons. We adapt a popular transmon-like tunable-coupling element,\nachieving high-fidelity, low-leakage controlled-$Z$ gates with unipolar,\nfast-adiabatic pulsing only on the coupler. We demonstrate the ability of the\ntunable coupler to null residual $ZZ$ coupling as well as exchange couplings in\nthe one- and two-excitation manifolds. However, the nulling of these coherent\ninteractions is not simultaneous, prompting the exploration of tradeoffs. We\npresent experiments pinpointing spectator effects on specific quantum\noperations. We also study the combined effect on the three types of operations\nusing repeated quantum parity measurements."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-448",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14626",
    "b_title":[
      "An Explainable Framework for Misinformation Identification via Critical\n  Question Answering"
    ],
    "b_abstract":[
      "Natural language misinformation detection approaches have been, to date,\nlargely dependent on sequence classification methods, producing opaque systems\nin which the reasons behind classification as misinformation are unclear. While\nan effort has been made in the area of automated fact-checking to propose\nexplainable approaches to the problem, this is not the case for automated\nreason-checking systems. In this paper, we propose a new explainable framework\nfor both factual and rational misinformation detection based on the theory of\nArgumentation Schemes and Critical Questions. For that purpose, we create and\nrelease NLAS-CQ, the first corpus combining 3,566 textbook-like natural\nlanguage argumentation scheme instances and 4,687 corresponding answers to\ncritical questions related to these arguments. On the basis of this corpus, we\nimplement and validate our new framework which combines classification with\nquestion answering to analyse arguments in search of misinformation, and\nprovides the explanations in form of critical questions to the human user."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.03702",
    "c_title":[
      "Developing and Utilizing a Large-Scale Cantonese Dataset for\n  Multi-Tasking in Large Language Models"
    ],
    "c_abstract":[
      "High-quality data resources play a crucial role in learning large language\nmodels (LLMs), particularly for low-resource languages like Cantonese. Despite\nhaving more than 85 million native speakers, Cantonese is still considered a\nlow-resource language in the field of natural language processing (NLP) due to\nfactors such as the dominance of Mandarin, lack of cohesion within the\nCantonese-speaking community, diversity in character encoding and input\nmethods, and the tendency of overseas Cantonese speakers to prefer using\nEnglish. In addition, rich colloquial vocabulary of Cantonese, English\nloanwords, and code-switching characteristics add to the complexity of corpus\ncollection and processing. To address these challenges, we collect Cantonese\ntexts from a variety of sources, including open source corpora, Hong\nKong-specific forums, Wikipedia, and Common Crawl data. We conduct rigorous\ndata processing through language filtering, quality filtering, content\nfiltering, and de-duplication steps, successfully constructing a high-quality\nCantonese corpus of over 2 billion tokens for training large language models.\nWe further refined the model through supervised fine-tuning (SFT) on curated\nCantonese tasks, enhancing its ability to handle specific applications. Upon\ncompletion of the training, the model achieves state-of-the-art (SOTA)\nperformance on four Cantonese benchmarks. After training on our dataset, the\nmodel also exhibits improved performance on other mainstream language tasks."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-449",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16656",
    "b_title":[
      "Data Mining in Transportation Networks with Graph Neural Networks: A\n  Review and Outlook"
    ],
    "b_abstract":[
      "Data mining in transportation networks (DMTNs) refers to using diverse types\nof spatio-temporal data for various transportation tasks, including pattern\nanalysis, traffic prediction, and traffic controls. Graph neural networks\n(GNNs) are essential in many DMTN problems due to their capability to represent\nspatial correlations between entities. Between 2016 and 2024, the notable\napplications of GNNs in DMTNs have extended to multiple fields such as traffic\nprediction and operation. However, existing reviews have primarily focused on\ntraffic prediction tasks. To fill this gap, this study provides a timely and\ninsightful summary of GNNs in DMTNs, highlighting new progress in prediction\nand operation from academic and industry perspectives since 2023. First, we\npresent and analyze various DMTN problems, followed by classical and recent GNN\nmodels. Second, we delve into key works in three areas: (1) traffic prediction,\n(2) traffic operation, and (3) industry involvement, such as Google Maps, Amap,\nand Baidu Maps. Along these directions, we discuss new research opportunities\nbased on the significance of transportation problems and data availability.\nFinally, we compile resources such as data, code, and other learning materials\nto foster interdisciplinary communication. This review, driven by recent trends\nin GNNs in DMTN studies since 2023, could democratize abundant datasets and\nefficient GNN methods for various transportation problems including prediction\nand operation."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10234",
    "c_title":[
      "Counterfactual Explanations for k-means and Gaussian Clustering"
    ],
    "c_abstract":[
      "Counterfactuals have been recognized as an effective approach to explain\nclassifier decisions. Nevertheless, they have not yet been considered in the\ncontext of clustering. In this work, we propose the use of counterfactuals to\nexplain clustering solutions. First, we present a general definition for\ncounterfactuals for model-based clustering that includes plausibility and\nfeasibility constraints. Then we consider the counterfactual generation problem\nfor k-means and Gaussian clustering assuming Euclidean distance. Our approach\ntakes as input the factual, the target cluster, a binary mask indicating\nactionable or immutable features and a plausibility factor specifying how far\nfrom the cluster boundary the counterfactual should be placed. In the k-means\nclustering case, analytical mathematical formulas are presented for computing\nthe optimal solution, while in the Gaussian clustering case (assuming full,\ndiagonal, or spherical covariances) our method requires the numerical solution\nof a nonlinear equation with a single parameter only. We demonstrate the\nadvantages of our approach through illustrative examples and quantitative\nexperimental comparisons."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-450",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12909",
    "b_title":[
      "Topological Indices With Degree Sequence $\\mathscr{D}$ of Tree"
    ],
    "b_abstract":[
      "In this paper, we refer to a asymptotic degree sequence as\n$\\mathscr{D}=(d_1,d_2,\\dots,d_n)$. The examination of topological indices on\ntrees gives us a general overview through bounds to find the maximum and\nminimum bounds which reflect the maximum and minimum number of edges incident\nto every vertex in the graph, Albertson index known as $\\sum_{uv\\in E(G)}\\lvert\nd_u(G)-d_v(G) \\rvert$, Sigma index $\\sigma(G)$ among $\\mathscr{D}$ of tree $T$\nwhen $d_n\\geqslant \\dots \\geqslant d_1$. According to the first zegrb we show\nfor a degree sequence of order $n=4$,\n$\\operatorname{irr}(T)=M_1(T)^2-2\\sqrt{M_1(T)}+\\sum_{i=1}^4\\left|x_i-x_{i+1}\\right|-(b+c)-1$."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.05939",
    "c_title":[
      "Real-rootedness of rook-Eulerian polynomials"
    ],
    "c_abstract":[
      "We introduce rook-Eulerian polynomials, a generalization of the classical\nEulerian polynomials arising from complete rook placements on Ferrers boards,\nand prove that they are real-rooted. We show that a natural context in which to\ninterpret these rook placements is as lower intervals of $312$-avoiding\npermutations in the Bruhat order. We end with some variations and\ngeneralizations along this theme."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-451",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17821",
    "b_title":[
      "SSF: Sparse Long-Range Scene Flow for Autonomous Driving"
    ],
    "b_abstract":[
      "Scene flow enables an understanding of the motion characteristics of the\nenvironment in the 3D world. It gains particular significance in the\nlong-range, where object-based perception methods might fail due to sparse\nobservations far away. Although significant advancements have been made in\nscene flow pipelines to handle large-scale point clouds, a gap remains in\nscalability with respect to long-range. We attribute this limitation to the\ncommon design choice of using dense feature grids, which scale quadratically\nwith range. In this paper, we propose Sparse Scene Flow (SSF), a general\npipeline for long-range scene flow, adopting a sparse convolution based\nbackbone for feature extraction. This approach introduces a new challenge: a\nmismatch in size and ordering of sparse feature maps between time-sequential\npoint scans. To address this, we propose a sparse feature fusion scheme, that\naugments the feature maps with virtual voxels at missing locations.\nAdditionally, we propose a range-wise metric that implicitly gives greater\nimportance to faraway points. Our method, SSF, achieves state-of-the-art\nresults on the Argoverse2 dataset, demonstrating strong performance in\nlong-range scene flow estimation. Our code will be released at\nhttps:\/\/github.com\/KTH-RPL\/SSF.git."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03835",
    "c_title":[
      "Single-Domain Generalized Object Detection by Balancing Domain Diversity\n  and Invariance"
    ],
    "c_abstract":[
      "Single-domain generalization for object detection (S-DGOD) aims to transfer\nknowledge from a single source domain to unseen target domains. In recent\nyears, many models have focused primarily on achieving feature invariance to\nenhance robustness. However, due to the inherent diversity across domains, an\nexcessive emphasis on invariance can cause the model to overlook the actual\ndifferences between images. This overemphasis may complicate the training\nprocess and lead to a loss of valuable information. To address this issue, we\npropose the Diversity Invariance Detection Model (DIDM), which focuses on the\nbalance between the diversity of domain-specific and invariance cross domains.\nRecognizing that domain diversity introduces variations in domain-specific\nfeatures, we introduce a Diversity Learning Module (DLM). The DLM is designed\nto preserve the diversity of domain-specific information with proposed feature\ndiversity loss while limiting the category semantics in the features. In\naddition, to maintain domain invariance, we incorporate a Weighted Aligning\nModule (WAM), which aligns features without compromising feature diversity. We\nconducted our model on five distinct datasets, which have illustrated the\nsuperior performance and effectiveness of the proposed model."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-452",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14617",
    "b_title":[
      "Serving Models, Fast and Slow:Optimizing Heterogeneous LLM Inferencing\n  Workloads at Scale"
    ],
    "b_abstract":[
      "Large Language Model (LLM) inference workloads handled by global cloud\nproviders can include both latency-sensitive and insensitive tasks, creating a\ndiverse range of Service Level Agreement (SLA) requirements. Managing these\nmixed workloads is challenging due to the complexity of the inference stack,\nwhich includes multiple LLMs, hardware configurations, and geographic\ndistributions. Current optimization strategies often silo these tasks to ensure\nthat SLAs are met for latency-sensitive tasks, but this leads to significant\nunder-utilization of expensive GPU resources despite the availability of spot\nand on-demand Virtual Machine (VM) provisioning. We propose SAGESERVE, a\ncomprehensive LLM serving framework that employs adaptive control knobs at\nvarying time scales, ensuring SLA compliance while maximizing the utilization\nof valuable GPU resources. Short-term optimizations include efficient request\nrouting to data center regions, while long-term strategies involve scaling GPU\nVMs out\/in and redeploying models to existing VMs to align with traffic\npatterns. These strategies are formulated as an optimization problem for\nresource allocation and solved using Integer Linear Programming (ILP). We\nperform empirical and simulation studies based on production workload traces\nwith over 8M requests using four open-source models deployed across three\nregions. SAGESERVE achieves up to 25% savings in GPU-hours while maintaining\ntail latency and satisfying all SLOs, and it reduces the scaling overhead\ncompared to baselines by up to 80%, confirming the effectiveness of our\nproposal. In terms of dollar cost, this can save cloud providers up to $2M over\nthe course of a month."
    ],
    "b_categories":[
      [
        "cs.DC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06532",
    "c_title":[
      "FaaSMT: Lightweight Serverless Framework for Intrusion Detection Using\n  Merkle Tree and Task Inlining"
    ],
    "c_abstract":[
      "The serverless platform aims to facilitate cloud applications'\nstraightforward deployment, scaling, and management. Unfortunately, the\ndistributed nature of serverless computing makes it difficult to port\ntraditional security tools directly. The existing serverless solutions\nprimarily identify potential threats or performance bottlenecks through\npost-analysis of modified operating system audit logs, detection of encrypted\ntraffic offloading, or the collection of runtime metrics. However, these\nmethods often prove inadequate for comprehensively detecting communication\nviolations across functions. This limitation restricts the real-time log\nmonitoring and validation capabilities in distributed environments while\nimpeding the maintenance of minimal communication overhead. Therefore, this\npaper presents FaaSMT, which aims to fill this gap by addressing research\nquestions related to security checks and the optimization of performance and\ncosts in serverless applications. This framework employs parallel processing\nfor the collection of distributed data logs, incorporating Merkle Tree\nalgorithms and heuristic optimisation methods to achieve adaptive inline\nsecurity task execution. The results of experimental trials demonstrate that\nFaaSMT is capable of effectively identifying major attack types (e.g., Denial\nof Wallet (DoW) and Business Logic attacks), thereby providing comprehensive\nmonitoring and validation of function executions while significantly reducing\nperformance overhead."
    ],
    "c_categories":[
      [
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-453",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10833",
    "b_title":[
      "Multipath Component Power Delay Profile Based Joint Range and Doppler\n  Estimation for AFDM-ISAC Systems"
    ],
    "b_abstract":[
      "Integrated Sensing and Communication (ISAC) systems combine sensing and\ncommunication functionalities within a unified framework, enhancing spectral\nefficiency and reducing costs by utilizing shared hardware components. This\npaper investigates multipath component power delay profile (MPCPDP)-based joint\nrange and Doppler estimation for Affine Frequency Division Multiplexing\n(AFDM)-ISAC systems. The path resolvability of the equivalent channel in the\nAFDM system allows the recognition of Line-of-Sight (LoS) and Non-Line-of-Sight\n(NLoS) paths within a single pilot symbol in fast time-varying channels. We\ndevelop a joint estimation model that leverages multipath Doppler shifts and\ndelays information under the AFDM waveform. Utilizing the MPCPDP, we propose a\nnovel ranging method that exploits the range-dependent magnitude of the MPCPDP\nacross its delay spread by constructing a Nakagami-m statistical fading model\nfor MPC channel fading and correlating the distribution parameters with\npropagation distance in AFDM systems. This method eliminates the need for\nadditional time synchronization or extra hardware. We also transform the\nnonlinear Doppler estimation problem into a bilinear estimation problem using a\nFirst-order Taylor expansion. Moreover, we introduce the Expectation\nMaximization algorithm to estimate the hyperparameters and leverage the\nExpectation Consistent algorithm to cope with high-dimensional integration\nchallenges. Extensive numerical simulations demonstrate the effectiveness of\nour MPCPDP-based joint range and Doppler estimation in ISAC systems."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09167",
    "c_title":[
      "Kise-Manitow's Hand in Space: Securing Communication and Connections in\n  Space"
    ],
    "c_abstract":[
      "The increasing complexity of space systems, coupled with their critical\noperational roles, demands a robust, scalable, and sustainable security\nframework. This paper presents a novel system-of-systems approach for the\nupcoming Lunar Gateway. We demonstrate the application of the\nsecure-by-component approach to the two earliest deployed systems in the\nGateway, emphasizing critical security controls both internally and for\nexternal communication and connections. Additionally, we present a phased\napproach for the integration of Canadarm3, addressing the unique security\nchallenges that arise from both inter-system interactions and the arm's\nautonomous capabilities."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-454",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08174",
    "b_title":[
      "Object-Centric 2D Gaussian Splatting: Background Removal and\n  Occlusion-Aware Pruning for Compact Object Models"
    ],
    "b_abstract":[
      "Current Gaussian Splatting approaches are effective for reconstructing entire\nscenes but lack the option to target specific objects, making them\ncomputationally expensive and unsuitable for object-specific applications. We\npropose a novel approach that leverages object masks to enable targeted\nreconstruction, resulting in object-centric models. Additionally, we introduce\nan occlusion-aware pruning strategy to minimize the number of Gaussians without\ncompromising quality. Our method reconstructs compact object models, yielding\nobject-centric Gaussian and mesh representations that are up to 96\\% smaller\nand up to 71\\% faster to train compared to the baseline while retaining\ncompetitive quality. These representations are immediately usable for\ndownstream applications such as appearance editing and physics simulation\nwithout additional processing."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19128",
    "c_title":[
      "SCA3D: Enhancing Cross-modal 3D Retrieval via 3D Shape and Caption\n  Paired Data Augmentation"
    ],
    "c_abstract":[
      "The cross-modal 3D retrieval task aims to achieve mutual matching between\ntext descriptions and 3D shapes. This has the potential to enhance the\ninteraction between natural language and the 3D environment, especially within\nthe realms of robotics and embodied artificial intelligence (AI) applications.\nHowever, the scarcity and expensiveness of 3D data constrain the performance of\nexisting cross-modal 3D retrieval methods. These methods heavily rely on\nfeatures derived from the limited number of 3D shapes, resulting in poor\ngeneralization ability across diverse scenarios. To address this challenge, we\nintroduce SCA3D, a novel 3D shape and caption online data augmentation method\nfor cross-modal 3D retrieval. Our approach uses the LLaVA model to create a\ncomponent library, captioning each segmented part of every 3D shape within the\ndataset. Notably, it facilitates the generation of extensive new 3D-text pairs\ncontaining new semantic features. We employ both inter and intra distances to\nalign various components into a new 3D shape, ensuring that the components do\nnot overlap and are closely fitted. Further, text templates are utilized to\nprocess the captions of each component and generate new text descriptions.\nBesides, we use unimodal encoders to extract embeddings for 3D shapes and texts\nbased on the enriched dataset. We then calculate fine-grained cross-modal\nsimilarity using Earth Mover's Distance (EMD) and enhance cross-modal matching\nwith contrastive learning, enabling bidirectional retrieval between texts and\n3D shapes. Extensive experiments show our SCA3D outperforms previous works on\nthe Text2Shape dataset, raising the Shape-to-Text RR@1 score from 20.03 to\n27.22 and the Text-to-Shape RR@1 score from 13.12 to 16.67. Codes can be found\nin https:\/\/github.com\/3DAgentWorld\/SCA3D."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-455",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01881",
    "b_title":[
      "Creation, stabilization, and study at ambient pressure of\n  pressure-induced superconductivity in Bi$_{0.5}$Sb$_{1.5}$Te$_3$"
    ],
    "b_abstract":[
      "In light of breakthroughs in superconductivity under high pressure, and\nconsidering that record critical temperatures (T$_c$s) across various systems\nhave been achieved under high pressure, the primary challenge for higher Tc\nshould no longer solely be to increase T$_c$ under extreme conditions but also\nto reduce, or ideally eliminate, the need for applied pressure in retaining\npressure-induced or -enhanced superconductivity. The topological semiconductor\nBi$_{0.5}$Sb$_{1.5}$Te$_3$ (BST) was chosen to demonstrate our approach to\naddressing this challenge and exploring its intriguing physics. Under pressures\nup to ~ 50 GPa, three superconducting phases (BST-I, -II, and -III) were\nobserved. A superconducting phase in BST-I appears at ~ 4 GPa, without a\nstructural transition, suggesting the possible topological nature of this\nphase. Using the pressure-quench protocol (PQP) recently developed by us, we\nsuccessfully retained this pressure-induced phase at ambient pressure and\nrevealed the bulk nature of the state. Significantly, this demonstrates\nrecovery of a pressure-quenched sample from a diamond anvil cell at room\ntemperature with the pressure-induced phase retained at ambient pressure. Other\nsuperconducting phases were retained in BST-II and -III at ambient pressure and\nsubjected to thermal and temporal stability testing. Superconductivity was also\nfound in BST with T$_c$ up to 10.2 K, the record for this compound series.\nWhile PQP maintains superconducting phases in BST at ambient pressure, both\ndepressurization and PQP enhance its T$_c$, possibly due to microstructures\nformed during these processes, offering an added avenue to raise T$_c$. These\nfindings are supported by our density-functional theory calculations."
    ],
    "b_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.13857",
    "c_title":[
      "Interfacial superconductivity and a Se-vacancy ordered insulating phase\n  in the FeSe\/PbOx heterostructures"
    ],
    "c_abstract":[
      "The discovery of high-temperature superconductivity in FeSe\/SrTiO3 has\nsparked significant interests in exploring new superconducting systems with\nengineered interfaces. Here, using molecular beam epitaxy growth, we\nsuccessfully fabricate FeSe\/PbOx heterostructures and discover\nsuperconductivities in three different monolayer FeSe-related interfaces. We\nobserve superconducting gaps of 13~14 meV in the monolayer FeSe films grown on\ntwo different phases of PbOx. Moreover, we discover a new insulating Fe10Se9\nphase with an ordered $\\sqrt{5}\\times\\sqrt{5}$ Se-vacancy structure. Our\nfirst-principles calculation suggests that this new insulating phase originates\nfrom electronic correlation. Intriguingly, an additional monolayer FeSe film\ngrown on the insulating Fe10Se9 also exhibits superconductivity with the gap\nsize of 5 meV. Our results suggest that the work function differences between\nthe monolayer FeSe and the substrates, which can induce band bending and charge\ntransfer, are crucial for the interfacial superconductivity."
    ],
    "c_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-456",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14607",
    "b_title":[
      "Can Large Vision Language Models Read Maps Like a Human?"
    ],
    "b_abstract":[
      "In this paper, we introduce MapBench-the first dataset specifically designed\nfor human-readable, pixel-based map-based outdoor navigation, curated from\ncomplex path finding scenarios. MapBench comprises over 1600 pixel space map\npath finding problems from 100 diverse maps. In MapBench, LVLMs generate\nlanguage-based navigation instructions given a map image and a query with\nbeginning and end landmarks. For each map, MapBench provides Map Space Scene\nGraph (MSSG) as an indexing data structure to convert between natural language\nand evaluate LVLM-generated results. We demonstrate that MapBench significantly\nchallenges state-of-the-art LVLMs both zero-shot prompting and a\nChain-of-Thought (CoT) augmented reasoning framework that decomposes map\nnavigation into sequential cognitive processes. Our evaluation of both\nopen-source and closed-source LVLMs underscores the substantial difficulty\nposed by MapBench, revealing critical limitations in their spatial reasoning\nand structured decision-making capabilities. We release all the code and\ndataset in https:\/\/github.com\/taco-group\/MapBench."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.04918",
    "c_title":[
      "Fine-Tuning Florence2 for Enhanced Object Detection in Un-constructed\n  Environments: Vision-Language Model Approach"
    ],
    "c_abstract":[
      "Artificial intelligence has progressed through the development of\nVision-Language Models (VLMs), which integrate text and visual inputs to\nachieve comprehensive understanding and interaction in various contexts.\nEnhancing the performance of these models such as the transformer based\nFlorence 2 on specialized tasks like object detection in complex and\nunstructured environments requires fine-tuning. The goal of this paper is to\nimprove the efficiency of the Florence 2 model in challenging environments by\nfinetuning it. We accomplished this by experimenting with different\nconfigurations, using various GPU types (T4, L4, A100) and optimizers such as\nAdamW and SGD. We also employed a range of learning rates and LoRA (Low Rank\nAdaptation) settings. Analyzing the performance metrics, such as Mean Average\nPrecision (mAP) scores,reveals that the finetuned Florence 2 models performed\ncomparably to YOLO models, including YOLOv8, YOLOv9, and YOLOv10. This\ndemonstrates how transformer based VLMs can be adapted for detailed object\ndetection tasks. The paper emphasizes the capability of optimized transformer\nbased VLMs to address specific challenges in object detection within\nunstructured environments, opening up promising avenues for practical\napplications in demanding and complex settings."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-457",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05623",
    "b_title":[
      "Limits of specifiability for sensor-based robotic planning tasks"
    ],
    "b_abstract":[
      "There is now a large body of techniques, many based on formal methods, for\ndescribing and realizing complex robotics tasks, including those involving a\nvariety of rich goals and time-extended behavior. This paper explores the\nlimits of what sorts of tasks are specifiable, examining how the precise\ngrounding of specifications, that is, whether the specification is given in\nterms of the robot's states, its actions and observations, its knowledge, or\nsome other information,is crucial to whether a given task can be specified.\nWhile prior work included some description of particular choices for this\ngrounding, our contribution treats this aspect as a first-class citizen: we\nintroduce notation to deal with a large class of problems, and examine how the\ngrounding affects what tasks can be posed. The results demonstrate that certain\nclasses of tasks are specifiable under different combinations of groundings."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16460",
    "c_title":[
      "On Enhancing Structural Resilience of Multirobot Coverage Control with\n  Bearing Rigidity"
    ],
    "c_abstract":[
      "The problem of multi-robot coverage control has been widely studied to\nefficiently coordinate a team of robots to cover a desired area of interest.\nHowever, this problem faces significant challenges when some robots are lost or\ndeviate from their desired formation during the mission due to faults or\ncyberattacks. Since a majority of multi-robot systems (MRSs) rely on\ncommunication and relative sensing for their efficient operation, a failure in\none robot could result in a cascade of failures in the entire system. In this\nwork, we propose a hierarchical framework for area coverage, combining\ncentralized coordination by leveraging Voronoi partitioning with decentralized\nreference tracking model predictive control (MPC) for control design. In\naddition to reference tracking, the decentralized MPC also performs bearing\nmaintenance to enforce a rigid MRS network, thereby enhancing the structural\nresilience, i.e., the ability to detect and mitigate the effects of\nlocalization errors and robot loss during the mission. Furthermore, we show\nthat the resulting control architecture guarantees the recovery of the MRS\nnetwork in the event of robot loss while maintaining a minimally rigid\nstructure. The effectiveness of the proposed algorithm is validated through\nnumerical simulations."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-458",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16017",
    "b_title":[
      "On weakly amenable groupoids"
    ],
    "b_abstract":[
      "In this work, we study groupoids and their approximation properties,\ngeneralizing both the definitions and some known results for the group case.\nMore precisely, we introduce weak amenability for groupoids using the\ndefinition of the Fourier algebra given by Renault. We prove that weakly\namenable groupoids are inner exact. We also generalize its algebraic\ncounterpart, the CBAP. To do this we introduce the notion of a quasi Cartan\npair $(B,A)$ and see that $(C_r^*(G),C_0(G^0))$ can be viewed as such. We then\ndefine what it means for a pair $(B,A)$ to have the CBAP. We introduce the\nCowling-Haagerup constants associated to these approximation properties and\nprove that $\\Lambda_{\\text{cb}}(C_r^*(G),C_0(G^0)) \\leq\n\\Lambda_{\\text{cb}}(G)$. We then study some classes of groupoids where we could\nachieve equality, that is, $\\Lambda_{\\text{cb}}(G) =\n\\Lambda_{\\text{cb}}(C_r^*(G),C_0(G^0))$. They are discrete groupoids and\ngroupoids arising from partial actions of a discrete group $\\Gamma$ on a\nlocally compact Hausdorff space $X$."
    ],
    "b_categories":[
      [
        "math.OA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.13039",
    "c_title":[
      "Relations amongst the distances between $C^{*}$-subalgebras and some\n  canonically associated operator algebras"
    ],
    "c_abstract":[
      "We prove that the Christensen distance (resp., the Kadison-Kastler distance)\nbetween two $C^*$-subalgebras $\\mathcal{A}$ and $\\mathcal{B}$ of a\n$C^*$-algebra $\\mathcal{C}$ is equal to that between their enveloping von\nNeumann algebras $\\mathcal{A}^{**}$ and $\\mathcal{B}^{**}$ (resp., the tensor\nproduct algebras $\\mathcal{A} \\otimes^{\\min} \\mathcal{D}$ and $\\mathcal{B}\n\\otimes^{\\min} \\mathcal{D}$, for any unital commutative $C^*$-algebra\n$\\mathcal{D}$)."
    ],
    "c_categories":[
      [
        "math.OA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-459",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09697",
    "b_title":[
      "Squarefree discriminants of polynomials with prime coefficients"
    ],
    "b_abstract":[
      "In this paper, we consider the family of monic polynomials with prime\ncoefficients and the family of all polynomials with prime coefficients. We\ndetermine the number of $f(x)$ in each of these families having: squarefree\ndiscriminant; $\\mathbb{Z}[x]\/(f(x))$ as the maximal order in\n$\\mathbb{Q}[x]\/(f(x))$."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.04488",
    "c_title":[
      "New bounds in R.S. Lehman's estimates for the difference $\\pi\\left(\n  x\\right) -li\\left( x\\right) $"
    ],
    "c_abstract":[
      "We denote by $\\pi\\left( x\\right) $ the usual prime counting function and let\n$li\\left( x\\right) $ the logarithmic integral of $x$. In 1966, R.S. Lehman came\nup with a new approach and an effective method for finding an upper bound where\nit is assured that a sign change occurs for $\\pi\\left( x\\right) -li\\left(\nx\\right) $ for some value $x$ not higher than this given bound. In this paper\nwe provide further improvements on the error terms including an improvement\nupon Lehman's famous error term $S_{3}$ in his original paper. We are now able\nto eliminate the lower condition for the size-length $\\eta$ completely. For\nfurther numerical computations this enables us to establish sharper results on\nthe positions for the sign changes. We illustrate with some numerical\ncomputations on the lowest known crossover regions near $10^{316}$ and we\ndiscuss numerically on potential crossover regions below this value."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-460",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16645",
    "b_title":[
      "Optical centroid orbiting metrology"
    ],
    "b_abstract":[
      "Optical interferometry has dramatically advanced the development of modern\nscience and technology. Here we introduce an interesting centroid evolution\nphenomenon of orbital angular momentum (OAM) interference fields with broken\nrotational symmetry, and establish a novel interferometric paradigm by fully\nexploiting centroid orbiting information. The centroid positions and their\ngeometric trajectories can provide more detectable information in a\ntwo-dimensional plane to sense the interferometric perturbations, compared with\nthe conventional interferometry. We first investigate centroid orbital\nevolution under the inclined angle perturbation that allows for ultra-sensitive\nangle distinguishment with arc-second resolution. We also show centroid ellipse\nevolution under spatial phase perturbation that enables geometric\ncharacterization of arbitrary OAM superpositions on modal Poincar\\'e spheres.\nFurthermore, based on the angle subdivision of centroid orbiting, we\ndemonstrate the environmentally robust nanoscale displacement measurement with\npolarization synchronous detection, and particularly the high-resolution, fast,\nand large-range linear movement monitoring using commercial four-quadrant\nphotodetectors. This novel centroid orbiting interferometry may open new\nopportunities to advance metrological technologies beyond the conventional\ninterferometers."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20358",
    "c_title":[
      "Creating multi-beam interference from two-beam interference with\n  assistant of harmonics generation"
    ],
    "c_abstract":[
      "Linear optics-based multi-beam interference (MBI), like the Fabry-Perot\ninterferometer, plays an important role in precision optical metrology\napplications such as laser stabilization in optical clocks, precision\nspectroscopy, and gravitational wave detection. Here, we propose and\nexperimentally verify a nonlinear optics-based MBI principle with the\nassistance of cascading and recycling harmonics generation of two-beam\ninterference. By cascading and recycling the harmonics processes, in combining\nwith optical power amplification (OPA) to compensate for power losses arising\nfrom limited nonlinear conversion efficiency, a total 16th harmonic is\nachieved, and the observed interference fringes gradually evolve from a\nsinusoidal curve to a Lorentz-like curve. In principle, there is no limitation\non the number of cascading and recycling nonlinear processes with the\nassistance of OPAs and sharp interference fringes, analogous to those in a\nhigh-finesse cavity, can be obtained. The nonlinear optics-based MBI mechanism\nrevealed here will find promising applications in precision optical metrology."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-461",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09816",
    "b_title":[
      "Flexible Empirical Bayesian Approaches to Pharmacovigilance for\n  Simultaneous Signal Detection and Signal Strength Estimation in Spontaneous\n  Reporting Systems Data"
    ],
    "b_abstract":[
      "Inferring adverse events (AEs) of medical products from Spontaneous Reporting\nSystems (SRS) databases is a core challenge in contemporary pharmacovigilance.\nBayesian methods for pharmacovigilance are attractive for their rigorous\nability to simultaneously detect potential AE signals and estimate their\nstrengths\/degrees of relevance. However, existing Bayesian and empirical\nBayesian methods impose restrictive parametric assumptions and\/or demand\nsubstantial computational resources, limiting their practical utility. This\npaper introduces a suite of novel, scalable empirical Bayes methods for\npharmacovigilance that utilize flexible non-parametric priors and custom,\nefficient data-driven estimation techniques to enhance signal detection and\nsignal strength estimation at a low computational cost. Our highly flexible\nmethods accommodate a broader range of data and achieve signal detection\nperformance comparable to or better than existing Bayesian and empirical\nBayesian approaches. More importantly, they provide coherent and high-fidelity\nestimation and uncertainty quantification for potential AE signal strengths,\noffering deeper insights into the comparative importance and relevance of AEs.\nExtensive simulation experiments across diverse data-generating scenarios\ndemonstrate the superiority of our methods in terms of accurate signal strength\nestimation, as measured by replication root mean squared errors. Additionally,\nour methods maintain or exceed the signal detection performance of\nstate-of-the-art techniques, as evaluated by frequentist false discovery rates\nand sensitivity metrics. Applications on FDA FAERS data for the statin group of\ndrugs reveal interesting insights through Bayesian posterior probabilities."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.16057",
    "c_title":[
      "A Standardization Procedure to Incorporate Variance Partitioning Based\n  Priors in Latent Gaussian Models"
    ],
    "c_abstract":[
      "Latent Gaussian Models (LGMs) are a subset of Bayesian Hierarchical models\nwhere Gaussian priors, conditional on variance parameters, are assigned to all\neffects in the model. LGMs are employed in many fields for their flexibility\nand computational efficiency. However, practitioners find prior elicitation on\nthe variance parameters challenging because of a lack of intuitive\ninterpretation for them. Recently, several papers have tackled this issue by\nrethinking the model in terms of variance partitioning (VP) and assigning\npriors to parameters reflecting the relative contribution of each effect to the\ntotal variance. So far, the class of priors based on VP has been mainly\ndeployed for random effects and fixed effects separately. This work presents a\nnovel standardization procedure that expands the applicability of VP priors to\na broader class of LGMs, including both fixed and random effects. We describe\nthe steps required for standardization through various examples, with a\nparticular focus on the popular class of intrinsic Gaussian Markov random\nfields (IGMRFs). The practical advantages of standardization are demonstrated\nwith simulated data and a real dataset on survival analysis."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-462",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04820",
    "b_title":[
      "A fully conservative discrete velocity Boltzmann solver with parallel\n  adaptive mesh refinement for compressible flows"
    ],
    "b_abstract":[
      "This paper presents a parallel and fully conservative adaptive mesh\nrefinement (AMR) implementation of a finite-volume-based kinetic solver for\ncompressible flows. Time-dependent H-type refinement is combined with a\ntwo-population quasi-equilibrium Bhatnagar-Gross-Krook discrete velocity\nBoltzmann model. A validation has shown that conservation laws are strictly\npreserved through the application of refluxing operations at coarse-fine\ninterfaces. Moreover, the targeted macroscopic moments of Euler and\nNavier-Stokes-Fourier level flows were accurately recovered with correct and\nGalilean invariant dispersion rates for a temperature range over three orders\nof magnitude and dissipation rates of all eigen-modes up to Mach of order 1.8.\nResults for one- and two-dimensional benchmarks up to Mach numbers of 3.2 and\ntemperature ratios of 7, such as the Sod and Lax shock tubes, the Shu-Osher and\nseveral Riemann problems, as well as viscous shock-vortex interactions, have\ndemonstrated that the solver precisely captures reference solutions. Excellent\nperformance in obtaining sensitive quantities was proven, for example in the\ntest case involving nonlinear acoustics, whilst, for the same accuracy and\nfidelity of the solution, the AMR methodology significantly reduced\ncomputational cost and memory footprints. Over all demonstrated two-dimensional\nproblems, up to a 4- to 9-fold reduction was achieved and an upper limit of the\nAMR overhead of 30% was found in a case with very cost-intensive parameter\nchoice. The proposed solver marks an accurate, efficient and scalable framework\nfor kinetic simulations of compressible flows with moderate supersonic speeds\nand discontinuities, offering a valuable tool for studying complex problems in\nfluid dynamics."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.16951",
    "c_title":[
      "High-order mesh-free direct numerical simulation of lean hydrogen flames\n  in confined geometries"
    ],
    "c_abstract":[
      "Here we perform the first analysis of high-fidelity simulations of the\npropagation of lean hydrogen flames through porous media, taking cylindrical\narrays a representative example geometry. In this fundamental study we discuss\nthe impact of confinement on both thermodiffusive and thermoacoustic\ninstabilities. Flame propagation in these complex geometries is cannot be\nperformed by leading mesh-based codes, and is instead simulated using a\nhigh-order meshfree method, LABFM. Pore scale propagation is shown to be\ndependent on throat width between cylinders, and this is then related to\nlarge-scale flame dynamics, allowing us to give a heuristic explanation for the\nincreased growth rate of the thermodiffusive instability in more confined\ngeometries. Thermoacoustic instabilities are also observed for sufficiently\nconfined geometries. Understanding these instability mechanisms is crucial for\nimproving the design of future combustors, both in terms of controlling flame\ndynamics and increasing the durability of combustors."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-463",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08257",
    "b_title":[
      "Fluctuating Ensemble Averages and the BTZ Threshold"
    ],
    "b_abstract":[
      "Recent work shows fascinating links between ensemble averaging and the\nSwampland program. In order to break the emerging global symmetries of the\nensemble averaging as dictated by the no global symmetries conjecture, one may\nconsider fluctuations away from the average given by deviations in the\nSiegel-Weil formula. In this work, we investigate the physical interpretation\nof these fluctuations in the bulk physics and pinpoint the states giving rise\nto them. For this purpose, we explore an ensemble of generalised Narain CFTs\nand build the AdS$_{3}$ gravitational dual in the Chern-Simons (CS) framework.\nWe study the associated charged BTZ black hole solution and assess its\nstability. Using the Swampland weak gravity conjecture, we show that the\nfluctuations of the ensemble average are below the BTZ threshold and correspond\nto a sublattice of superextremal states emitted by the black hole. We exploit\nthe logarithmic density of states to derive bounds on the charged vectors of\nthe abelian CS symmetry and introduce a novel formulation of the density\nfunction to ensure consistency with the sublattice WGC. We establish bounds\nthat allows to distinguish heavy states contributing to the average from light\nstates generating fluctuations around it."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.14523",
    "c_title":[
      "HEFT Numerators from Kinematic Algebra"
    ],
    "c_abstract":[
      "The kinematic numerator factors for heavy-mass effective field theory are\nderived from a field theory limit of the string theory vertex operator\nkinematic algebra introduced in arXiv:1806.09584. The kinematic numerators are\ncorrelators of nested commutators of gluon vertex operators evaluated between\nmassive tachyonic vertex operators. The resulting numerators are given by\nproducts of structure constants of the vertex operator algebra which are gauge\ninvariant expressions. The computation of the nested commutators leads to a\nnatural organisation in the form of rooted trees, endowed with an order that\nfacilitates the enumeration of the various contributions. This kinematic\nalgebra gives a string theory understanding of the field theory fusion rules\nfor constructing the heavy-mass effective field theory numerator of\narXiv:2104.11206 and arXiv:2111.15649."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-464",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03144",
    "b_title":[
      "Temporal Separation with Entropy Regularization for Knowledge\n  Distillation in Spiking Neural Networks"
    ],
    "b_abstract":[
      "Spiking Neural Networks (SNNs), inspired by the human brain, offer\nsignificant computational efficiency through discrete spike-based information\ntransfer. Despite their potential to reduce inference energy consumption, a\nperformance gap persists between SNNs and Artificial Neural Networks (ANNs),\nprimarily due to current training methods and inherent model limitations. While\nrecent research has aimed to enhance SNN learning by employing knowledge\ndistillation (KD) from ANN teacher networks, traditional distillation\ntechniques often overlook the distinctive spatiotemporal properties of SNNs,\nthus failing to fully leverage their advantages. To overcome these challenge,\nwe propose a novel logit distillation method characterized by temporal\nseparation and entropy regularization. This approach improves existing SNN\ndistillation techniques by performing distillation learning on logits across\ndifferent time steps, rather than merely on aggregated output features.\nFurthermore, the integration of entropy regularization stabilizes model\noptimization and further boosts the performance. Extensive experimental results\nindicate that our method surpasses prior SNN distillation strategies, whether\nbased on logit distillation, feature distillation, or a combination of both.\nThe code will be available on GitHub."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19038",
    "c_title":[
      "FungalZSL: Zero-Shot Fungal Classification with Image Captioning Using a\n  Synthetic Data Approach"
    ],
    "c_abstract":[
      "The effectiveness of zero-shot classification in large vision-language models\n(VLMs), such as Contrastive Language-Image Pre-training (CLIP), depends on\naccess to extensive, well-aligned text-image datasets. In this work, we\nintroduce two complementary data sources, one generated by large language\nmodels (LLMs) to describe the stages of fungal growth and another comprising a\ndiverse set of synthetic fungi images. These datasets are designed to enhance\nCLIPs zero-shot classification capabilities for fungi-related tasks. To ensure\neffective alignment between text and image data, we project them into CLIPs\nshared representation space, focusing on different fungal growth stages. We\ngenerate text using LLaMA3.2 to bridge modality gaps and synthetically create\nfungi images. Furthermore, we investigate knowledge transfer by comparing text\noutputs from different LLM techniques to refine classification across growth\nstages."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-465",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04104",
    "b_title":[
      "LLMs Can Generate a Better Answer by Aggregating Their Own Responses"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) have shown remarkable capabilities across tasks,\nyet they often require additional prompting techniques when facing complex\nproblems. While approaches like self-correction and response selection have\nemerged as popular solutions, recent studies have shown these methods perform\npoorly when relying on the LLM itself to provide feedback or selection\ncriteria. We argue this limitation stems from the fact that common LLM\npost-training procedures lack explicit supervision for discriminative judgment\ntasks. In this paper, we propose Generative Self-Aggregation (GSA), a novel\nprompting method that improves answer quality without requiring the model's\ndiscriminative capabilities. GSA first samples multiple diverse responses from\nthe LLM, then aggregates them to obtain an improved solution. Unlike previous\napproaches, our method does not require the LLM to correct errors or compare\nresponse quality; instead, it leverages the model's generative abilities to\nsynthesize a new response based on the context of multiple samples. While GSA\nshares similarities with the self-consistency (SC) approach for response\naggregation, SC requires specific verifiable tokens to enable majority voting.\nIn contrast, our approach is more general and can be applied to open-ended\ntasks. Empirical evaluation demonstrates that GSA effectively improves response\nquality across various tasks, including mathematical reasoning, knowledge-based\nproblems, and open-ended generation tasks such as code synthesis and\nconversational responses."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16135",
    "c_title":[
      "Evaluation of NMT-Assisted Grammar Transfer for a Multi-Language\n  Configurable Data-to-Text System"
    ],
    "c_abstract":[
      "One approach for multilingual data-to-text generation is to translate\ngrammatical configurations upfront from the source language into each target\nlanguage. These configurations are then used by a surface realizer and in\ndocument planning stages to generate output. In this paper, we describe a\nrule-based NLG implementation of this approach where the configuration is\ntranslated by Neural Machine Translation (NMT) combined with a one-time human\nreview, and introduce a cross-language grammar dependency model to create a\nmultilingual NLG system that generates text from the source data, scaling the\ngeneration phase without a human in the loop. Additionally, we introduce a\nmethod for human post-editing evaluation on the automatically translated text.\nOur evaluation on the SportSett:Basketball dataset shows that our NLG system\nperforms well, underlining its grammatical correctness in translation tasks."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-466",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16748",
    "b_title":[
      "Through the Prism of Culture: Evaluating LLMs' Understanding of Indian\n  Subcultures and Traditions"
    ],
    "b_abstract":[
      "Large Language Models (LLMs) have shown remarkable advancements but also\nraise concerns about cultural bias, often reflecting dominant narratives at the\nexpense of under-represented subcultures. In this study, we evaluate the\ncapacity of LLMs to recognize and accurately respond to the Little Traditions\nwithin Indian society, encompassing localized cultural practices and\nsubcultures such as caste, kinship, marriage, and religion. Through a series of\ncase studies, we assess whether LLMs can balance the interplay between dominant\nGreat Traditions and localized Little Traditions. We explore various prompting\nstrategies and further investigate whether using prompts in regional languages\nenhances the models cultural sensitivity and response quality. Our findings\nreveal that while LLMs demonstrate an ability to articulate cultural nuances,\nthey often struggle to apply this understanding in practical, context-specific\nscenarios. To the best of our knowledge, this is the first study to analyze\nLLMs engagement with Indian subcultures, offering critical insights into the\nchallenges of embedding cultural diversity in AI systems."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.11881",
    "c_title":[
      "GPT's Devastated and LLaMA's Content: Emotion Representation Alignment\n  in LLMs for Keyword-based Generation"
    ],
    "c_abstract":[
      "In controlled text generation using large language models (LLMs), gaps arise\nbetween the language model's interpretation and human expectations. We look at\nthe problem of controlling emotions in keyword-based sentence generation for\nboth GPT-4 and LLaMA-3. We selected four emotion representations: Words,\nValence-Arousal-Dominance (VAD) dimensions expressed in both Lexical and\nNumeric forms, and Emojis. Our human evaluation looked at the Human-LLM\nalignment for each representation, as well as the accuracy and realism of the\ngenerated sentences. While representations like VAD break emotions into\neasy-to-compute components, our findings show that people agree more with how\nLLMs generate when conditioned on English words (e.g., \"angry\") rather than VAD\nscales. This difference is especially visible when comparing Numeric VAD to\nwords. However, we found that converting the originally-numeric VAD scales to\nLexical scales (e.g., +4.0 becomes \"High\") dramatically improved agreement.\nFurthermore, the perception of how much a generated sentence conveys an emotion\nis highly dependent on the LLM, representation type, and which emotion it is."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-467",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06930",
    "b_title":[
      "Tightness criteria for random compact sets of cadlag paths"
    ],
    "b_abstract":[
      "We give tightness criteria for random variables taking values in the space of\nall compact sets of cadlag real-valued paths, in terms of both the Skorohod J1\nand M1 topologies. This extends earlier work motivated by the study of the\nBrownian web that was concerned only with continuous paths. In the M1 case, we\ngive a natural extension of our tightness criteria which ensures that\nnon-crossing systems of paths have weak limit points that are also\nnon-crossing. This last result is exemplified through a rescaling of heavy\ntailed Poisson trees and a more general application to weaves."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.04210",
    "c_title":[
      "Generalized Kac's moment formula for positive continuous additive\n  functionals of symmetric Markov processes"
    ],
    "c_abstract":[
      "We establish a formula for moments of certain random variables involving\npositive continuous additive functionals of symmetric Hunt processes whose\nDirichlet forms are regular, generalizing the classical Kac's moment formula."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-468",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06966",
    "b_title":[
      "Turing-Completeness and Undecidability in Coupled Nonlinear Optical\n  Resonators"
    ],
    "b_abstract":[
      "Networks of coupled nonlinear optical resonators have emerged as an important\nclass of systems in ultrafast optical science, enabling richer and more complex\nnonlinear dynamics compared to their single-resonator or travelling-wave\ncounterparts. In recent years, these coupled nonlinear optical resonators have\nbeen applied as application-specific hardware accelerators for computing\napplications including combinatorial optimization and artificial intelligence.\nIn this work, we rigorously prove a fundamental result showing that coupled\nnonlinear optical resonators are Turing-complete computers, which endows them\nwith much greater computational power than previously thought. Furthermore, we\nshow that the minimum threshold of hardware complexity needed for\nTuring-completeness is surprisingly low, which has profound physical\nconsequences. In particular, we show that several problems of interest in the\nstudy of coupled nonlinear optical resonators are formally undecidable. These\ntheoretical findings can serve as the foundation for better understanding the\npromise of next-generation, ultrafast all-optical computers."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03514",
    "c_title":[
      "Hosting Second Order Exceptional Point in an All-lossy Dual-Core\n  Photonic Crystal Fiber"
    ],
    "c_abstract":[
      "We report an all-lossy index-guided dual-core photonic crystal fiber (PCF)\nthat hosts a second-order exceptional point (EP) in the systems parameter\nspace. By appropriately selecting a parametric encirclement scheme around the\nEP, the interaction between the coupled modes has been studied, and the mode\nconversion is subsequently observed."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-469",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08984",
    "b_title":[
      "The [NII] 205 $\\mu$m line emission from high-z SMGs and QSOs"
    ],
    "b_abstract":[
      "We present [NII] 205 $\\mu$m fine structure line observations of three\nsubmillimeter galaxies (SMGs) and three quasar host galaxies at\n4$\\lesssim$z$\\lesssim$6 using the Institut de radioastronomie millim\\'etrique\n(IRAM) interferometer. The [NII] emission is detected in three sources, and we\nreport detections of the underlying dust continuum emission in all sources. The\nobserved [NII]-to-infrared luminosity ratio spans at least 0.5 dex for our\nsources. Comparing our estimates with sources detected in the [NII] 205 $\\mu$m\nat similar redshifts shows that the overall [NII]-to-IR luminosity ratio spans\nover a dex in magnitude from L$_{[NII]}$\/L$_{IR}$ ~ 10$^{-4}$ - 10$^{-5}$ and\nfollows the trend of the so-called [NII] fine structure line deficit observed\nin (ultra)-luminous infrared galaxies in the local Universe. The [CII]-to-[NII]\nluminosity ratio is >10 for most of our sources, indicating that the bulk of\nthe [CII] 158 $\\mu$m line emission (f([CII]$^{PDR}$)>75%) arises from the\nneutral medium. From our analysis, we do not find significant differences in\nthe [NII] 205 $\\mu$m emission and the respective ratios between SMGs and QSOs,\nsuggesting a negligible contribution to the boosting of [NII] 205 $\\mu$m\nemission due to the active galactic nucleus (AGN) photoionization. Future\ninvestigations involving other fine structure lines and optical diagnostics\nwill provide further insight into a suite of ionized medium properties and\nreveal the diversity between AGN and non-AGN environments."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.10870",
    "c_title":[
      "Thermodynamics of self-gravitating fermions as a robust theory for dark\n  matter halos: Stability analysis applied to the Milky Way"
    ],
    "c_abstract":[
      "We present a framework for dark matter (DM) halo formation based on a kinetic\ntheory of self-gravitating fermions together with a solid connection to\nthermodynamics. Based on maximum entropy arguments, this approach predicts a\nmost likely phase-space distribution which takes into account the Pauli\nexclusion principle, relativistic effects, and particle evaporation. The most\ngeneral equilibrium configurations depend on the particle mass and develop a\ndegenerate compact core embedded in a diluted halo, both linked by their\nfermionic nature. By applying such a theory to the Milky Way we analyze the\nstability of different families of equilibrium solutions with implications on\nthe DM distribution and the mass of the DM candidate. We find that stable\ncore-halo profiles, which explain the DM distribution in the Galaxy, exist only\nin the range $mc^2 \\approx 194 - 387\\,\\rm{keV}$. The lower bound is a\nconsequence of imposing thermodynamical stability on the core-halo solutions\nhaving a $4.2\\times 10^6 M_\\odot$ quantum core mass alternative to the black\nhole hypothesis at the Galaxy center. The upper bound is solely an outcome of\ngeneral relativity when the quantum core reaches the Oppenheimer-Volkoff limit\nand undergoes gravitational collapse towards a black hole. We demonstrate that\nthere exists a set of stable core-halo profiles which are astrophysically\nrelevant in the sense that their total mass is finite, do not suffer from the\ngravothermal catastrophe, and agree with observations. The morphology of the\nouter halo tail is described by a polytrope of index $5\/2$, developing a sharp\ndecline of the density beyond $25\\,\\rm{kpc}$ in excellent agreement with the\nlatest Gaia DR3 rotation curve data. Moreover, we obtain a total mass of about\n$2\\times 10^{11} M_\\odot$ including baryons and a local DM density of about\n$0.4\\,\\rm{GeV}\\,c^{-2}\\,\\rm{cm}^{-3}$ in line with recent independent\nestimates."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-470",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06427",
    "b_title":[
      "Hybrid State-Space and GRU-based Graph Tokenization Mamba for\n  Hyperspectral Image Classification"
    ],
    "b_abstract":[
      "Hyperspectral image (HSI) classification plays a pivotal role in domains such\nas environmental monitoring, agriculture, and urban planning. However, it faces\nsignificant challenges due to the high-dimensional nature of the data and the\ncomplex spectral-spatial relationships inherent in HSI. Traditional methods,\nincluding conventional machine learning and convolutional neural networks\n(CNNs), often struggle to effectively capture these intricate spectral-spatial\nfeatures and global contextual information. Transformer-based models, while\npowerful in capturing long-range dependencies, often demand substantial\ncomputational resources, posing challenges in scenarios where labeled datasets\nare limited, as is commonly seen in HSI applications. To overcome these\nchallenges, this work proposes GraphMamba, a hybrid model that combines\nspectral-spatial token generation, graph-based token prioritization, and\ncross-attention mechanisms. The model introduces a novel hybridization of\nstate-space modeling and Gated Recurrent Units (GRU), capturing both linear and\nnonlinear spatial-spectral dynamics. GraphMamba enhances the ability to model\ncomplex spatial-spectral relationships while maintaining scalability and\ncomputational efficiency across diverse HSI datasets. Through comprehensive\nexperiments, we demonstrate that GraphMamba outperforms existing\nstate-of-the-art models, offering a scalable and robust solution for complex\nHSI classification tasks."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06361",
    "c_title":[
      "Adversarial Robustness of Discriminative Self-Supervised Learning in\n  Vision"
    ],
    "c_abstract":[
      "Self-supervised learning (SSL) has advanced significantly in visual\nrepresentation learning, yet comprehensive evaluations of its adversarial\nrobustness remain limited. In this study, we evaluate the adversarial\nrobustness of seven discriminative self-supervised models and one supervised\nmodel across diverse tasks, including ImageNet classification, transfer\nlearning, segmentation, and detection. Our findings suggest that discriminative\nSSL models generally exhibit better robustness to adversarial attacks compared\nto their supervised counterpart on ImageNet, with this advantage extending to\ntransfer learning when using linear evaluation. However, when fine-tuning is\napplied, the robustness gap between SSL and supervised models narrows\nconsiderably. Similarly, this robustness advantage diminishes in segmentation\nand detection tasks. We also investigate how various factors might influence\nadversarial robustness, including architectural choices, training duration,\ndata augmentations, and batch sizes. Our analysis contributes to the ongoing\nexploration of adversarial robustness in visual self-supervised representation\nsystems."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-471",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18893",
    "b_title":[
      "Distributed Online Task Assignment via Inexact ADMM for unplanned online\n  tasks and its Applications to Security"
    ],
    "b_abstract":[
      "In multi-robot system (MRS) applications, efficient task assignment is\nessential not only for coordinating agents and ensuring mission success but\nalso for maintaining overall system security. In this work, we first propose an\noptimization-based distributed task assignment algorithm that dynamically\nassigns mandatory security-critical tasks and optional tasks among teams.\nLeveraging an inexact Alternating Direction Method of Multipliers (ADMM)-based\napproach, we decompose the task assignment problem into separable and\nnon-separable subproblems. The non-separable subproblems are transformed into\nan inexact ADMM update by projected gradient descent, which can be performed\nthrough several communication steps within the team.\n  In the second part of this paper, we formulate a comprehensive framework that\nenables MRS under plan-deviation attacks to handle online tasks without\ncompromising security. The process begins with a security analysis that\ndetermines whether an online task can be executed securely by a robot and, if\nso, the required time and location for the robot to rejoin the team. Next, the\nproposed task assignment algorithm is used to allocate security-related tasks\nand verified online tasks. Finally, task fulfillment is managed using a Control\nLyapunov Function (CLF)-based controller, while security enforcement is ensured\nthrough a Control Barrier Function (CBF)-based security filter. Through\nsimulations, we demonstrate that the proposed framework allows MRS to\neffectively respond to unplanned online tasks while maintaining security\nguarantees."
    ],
    "b_categories":[
      [
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07702",
    "c_title":[
      "A Reliable Self-Organized Distributed Complex Network for Communication\n  of Smart Agents"
    ],
    "c_abstract":[
      "Collaboration is a fundamental and essential characteristic of many complex\nsystems, ranging from ant colonies to human societies. Each component within a\ncomplex system interacts with others, even at a distance, to accomplish a given\ntask. A network of collaboration can be defined to study the collective\nbehavior of such systems within the framework of complex networks. The nodes in\nthese networks may represent simple organisms or more sophisticated intelligent\nagents, such as humans. In this study, we utilize intelligent agents (nodes)\ntrained through reinforcement learning techniques to establish connections with\ntheir neighbors, ultimately leading to the emergence of a large-scale\ncommunication cluster. Notably, there is no centralized administrator; instead,\nagents must adjust their connections based on information obtained from local\nobservations. The connection strategy is formulated using a physical\nHamiltonian, thereby categorizing this intelligent system under the paradigm of\n\"Physics-Guided Machine Learning\"."
    ],
    "c_categories":[
      [
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-472",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18763",
    "b_title":[
      "Carbon Stars From Gaia DR3 and the Space Density of Dwarf Carbon Stars"
    ],
    "b_abstract":[
      "Carbon stars (with atmospheric C\/O$>1$) range widely in temperature and\nluminosity, from low mass dwarfs to asymptotic giant branch stars (AGB). The\nmain sequence dwarf carbon (dC) stars have inherited carbon-rich material from\nan AGB companion, which has since transitioned to a white dwarf. The dC stars\nare far more common than C giants, but no reliable estimates of dC space\ndensity have been published to date. We present results from an all-sky survey\nfor carbon stars using the low-resolution XP spectra from Gaia DR3. We\ndeveloped and measured a set of spectral indices contrasting C$_{\\rm 2}$ and CN\nmolecular band strengths in carbon stars against common absorption features\nfound in normal (C\/O$<1$) stars such as CaI, TiO and Balmer lines. We combined\nthese indices with the XP spectral coefficients as input to supervised\nmachine-learning algorithms trained on a vetted sample of known C stars from\nLAMOST. We describe the selection of the carbon candidate sample, and provide a\ncatalog of 43,574 candidates dominated by cool C giants in the Magellanic\nClouds and at low galactic latitude in the Milky Way. We report the\nconfirmation of candidate C stars using intermediate ($R\\sim 1800$) resolution\noptical spectroscopy from the Fred Lawrence Whipple Observatory, and provide\nestimates of sample purity and completeness. From a carefully-vetted sample of\nover 600 dCs, we measure their local space density to be\n$\\rho_0\\,=\\,1.96^{+0.14}_{-0.12}\\times10^{-6}\\,\\text{pc}^{-3}$ (about one dC in\nevery local disk volume of radius 50\\,pc), with a relatively large disk scale\nheight of $H_z\\,=\\,856^{+49}_{-43}\\,$pc."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12501",
    "c_title":[
      "Diagnosing the solar atmosphere through the Mg I b$_2$ 5173 \\AA\\ line.\n  II. Morphological classification of the intensity and circular polarization\n  profiles"
    ],
    "c_abstract":[
      "The Mg I b$_2$ line at 5173 \\r{A} is primarily magnetically sensitive to\nheights between the mid photosphere and the low chromosphere, a region that has\nnot been sufficiently explored in the solar atmosphere but is crucial for\nunderstanding the magnetic coupling between the two layers. New generation\nsolar observatories are now performing polarimetric observations of this\nspectral line, enabling simultaneous measurements with multiple spectral lines.\nThis allows for detailed studies of the magnetism around the temperature\nminimum region at high spatial, temporal, and spectral resolutions. We present\na morphological classification of the Stokes $I$ and $V$ profiles of the Mg I\nb$_2$ line using the Euclidean distance method on high spatial resolution\nobservations from the Swedish 1-m Solar Telescope. The physical properties of\nthe resulting classes were analyzed using classical inference methods.\nAdditionally, we present a two-line full-Stokes inversion of the representative\nprofiles in which the Mg I b$_2$ line is treated fully under non-local\nthermodynamic equilibrium (NLTE) conditions, while the Fe I 6173 \\r{A} line is\nsimultaneously inverted under LTE assumptions to provide photospheric\nconstraints. This approach offers insights into the temperature stratification\nand other physical gradients involved in the formation of the different profile\nmorphologies. We found nine classes of Stokes $V$ profiles and 16 classes of\nStokes $I$ profiles in our Mg I b$_2$ dataset. These classes can be further\ngrouped into families based on shared characteristics, physical properties, and\nlocation. Our classification provides important information on the different\nenvironments and processes occurring in the solar atmosphere around the\ntemperature minimum region. It is also relevant for improving the performance\nof NLTE inversions."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-473",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13889",
    "b_title":[
      "Generating Realistic Forehead-Creases for User Verification via\n  Conditioned Piecewise Polynomial Curves"
    ],
    "b_abstract":[
      "We propose a trait-specific image generation method that models forehead\ncreases geometrically using B-spline and B\\'ezier curves. This approach ensures\nthe realistic generation of both principal creases and non-prominent crease\npatterns, effectively constructing detailed and authentic forehead-crease\nimages. These geometrically rendered images serve as visual prompts for a\ndiffusion-based Edge-to-Image translation model, which generates corresponding\nmated samples. The resulting novel synthetic identities are then used to train\na forehead-crease verification network. To enhance intra-subject diversity in\nthe generated samples, we employ two strategies: (a) perturbing the control\npoints of B-splines under defined constraints to maintain label consistency,\nand (b) applying image-level augmentations to the geometric visual prompts,\nsuch as dropout and elastic transformations, specifically tailored to crease\npatterns. By integrating the proposed synthetic dataset with real-world data,\nour method significantly improves the performance of forehead-crease\nverification systems under a cross-database verification protocol."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.12531",
    "c_title":[
      "Towards Suturing World Models: Learning Predictive Models for Robotic\n  Surgical Tasks"
    ],
    "c_abstract":[
      "We introduce specialized diffusion-based generative models that capture the\nspatiotemporal dynamics of fine-grained robotic surgical sub-stitch actions\nthrough supervised learning on annotated laparoscopic surgery footage. The\nproposed models form a foundation for data-driven world models capable of\nsimulating the biomechanical interactions and procedural dynamics of surgical\nsuturing with high temporal fidelity. Annotating a dataset of $\\sim2K$ clips\nextracted from simulation videos, we categorize surgical actions into\nfine-grained sub-stitch classes including ideal and non-ideal executions of\nneedle positioning, targeting, driving, and withdrawal. We fine-tune two\nstate-of-the-art video diffusion models, LTX-Video and HunyuanVideo, to\ngenerate high-fidelity surgical action sequences at $\\ge$768x512 resolution and\n$\\ge$49 frames. For training our models, we explore both Low-Rank Adaptation\n(LoRA) and full-model fine-tuning approaches. Our experimental results\ndemonstrate that these world models can effectively capture the dynamics of\nsuturing, potentially enabling improved training simulators, surgical skill\nassessment tools, and autonomous surgical systems. The models also display the\ncapability to differentiate between ideal and non-ideal technique execution,\nproviding a foundation for building surgical training and evaluation systems.\nWe release our models for testing and as a foundation for future research.\nProject Page: https:\/\/mkturkcan.github.io\/suturingmodels\/"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-474",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13187",
    "b_title":[
      "Current Advances in Magnetoelectric Composites with Various Interphase\n  Connectivity Types"
    ],
    "b_abstract":[
      "Magnetoelectric composites integrate the coupling between magnetic and\npiezoelectric materials to create new functionalities for potential\ntechnological applications. This coupling is typically achieved through the\nexchange of magnetic, electric, or elastic energy across the interfaces between\nthe different constituent materials. Tailoring the strength of the\nmagnetoelectric effect is primarily accomplished by selecting suitable\nmaterials for each constituent and by optimizing geometrical and\nmicrostructural designs. Various composite architectures, such as (0-3), (2-2),\n(1-3) and core-shell connectivities, have been studied to enhance\nmagnetoelectric coupling and other required physical properties in composites.\nThis review examines the latest advancements in magnetoelectric materials,\nfocusing on the impact of different interphase connectivity types on their\nproperties and performance. Before exploring magnetic-electric coupling, a\nbrief overview of the historical background of multiferroic magnetoelectric\ncomposites is provided. Fundamental concepts underlying the magnetoelectric\neffect, piezoelectricity, and the magnetostrictive effect are explained,\nincluding their origins and examples of these materials' properties. So far,\nthree types of magnetoelectric composite connectivities have been investigated\nexperimentally: particulate composites (0-3), laminated and thin films (2-2),\nsticks embedded in matrix, core-shell particles, and coaxial fibers. An outlook\non the prospects and scientific challenges in the field of multiferroic\nmagnetoelectric composites is given at the end of this review."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.12311",
    "c_title":[
      "Implicit Geometric Descriptor-Enabled ANN Framework for a Unified\n  Structure-Property Relationship in Architected Nanofibrous Materials"
    ],
    "c_abstract":[
      "Hierarchically architected nanofibrous materials, such as the vertically\naligned carbon nanotube (VACNT) foams, draw their exceptional mechanical\nproperties from the interplay of nanoscale size effects and inter-nanotube\ninteractions within and across architectures. However, the distinct effects of\nthese mechanisms, amplified by the architecture, on different mechanical\nproperties remain elusive, limiting their independent tunability for targeted\nproperty combinations. Reliance on architecture-specific explicit design\nparameters further inhibits the development of a unified structure-property\nrelationship rooted in those nanoscale mechanisms. Here, we introduce two\nimplicit geometric descriptors -- multi-component shape invariants (MCSI) -- in\nan artificial neural network (ANN) framework to establish a unified\nstructure-property relationship that governs diverse architectures. The MCSIs\neffectively capture the key nanoscale mechanisms that give rise to the bulk\nmechanical properties such as specific-energy absorption, peak stress, and\naverage modulus. Exploiting their ability to predict mechanical properties for\ndesigns that are even outside of the training data, we propose generalized\ndesign strategies to achieve desired mechanical property combinations in\narchitected VACNT foams. Such implicit descriptor-enabled ANN frameworks can\nguide the accelerated and tractable design of complex hierarchical materials\nfor applications ranging from shock-absorbing layers in extreme environments to\nfunctional components in soft robotics."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-475",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14646",
    "b_title":[
      "SyncAnimation: A Real-Time End-to-End Framework for Audio-Driven Human\n  Pose and Talking Head Animation"
    ],
    "b_abstract":[
      "Generating talking avatar driven by audio remains a significant challenge.\nExisting methods typically require high computational costs and often lack\nsufficient facial detail and realism, making them unsuitable for applications\nthat demand high real-time performance and visual quality. Additionally, while\nsome methods can synchronize lip movement, they still face issues with\nconsistency between facial expressions and upper body movement, particularly\nduring silent periods. In this paper, we introduce SyncAnimation, the first\nNeRF-based method that achieves audio-driven, stable, and real-time generation\nof speaking avatar by combining generalized audio-to-pose matching and\naudio-to-expression synchronization. By integrating AudioPose Syncer and\nAudioEmotion Syncer, SyncAnimation achieves high-precision poses and expression\ngeneration, progressively producing audio-synchronized upper body, head, and\nlip shapes. Furthermore, the High-Synchronization Human Renderer ensures\nseamless integration of the head and upper body, and achieves audio-sync lip.\nThe project page can be found at https:\/\/syncanimation.github.io"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03510",
    "c_title":[
      "Mapping and Localization Using LiDAR Fiducial Markers"
    ],
    "c_abstract":[
      "LiDAR sensors are essential for autonomous systems, yet LiDAR fiducial\nmarkers (LFMs) lag behind visual fiducial markers (VFMs) in adoption and\nutility. Bridging this gap is vital for robotics and computer vision but\nchallenging due to the sparse, unstructured nature of 3D LiDAR data and\n2D-focused fiducial marker designs. This dissertation proposes a novel\nframework for mapping and localization using LFMs is proposed to benefit a\nvariety of real-world applications, including the collection of 3D assets and\ntraining data for point cloud registration, 3D map merging, Augmented Reality\n(AR), and many more.\n  First, an Intensity Image-based LiDAR Fiducial Marker (IFM) system is\nintroduced, using thin, letter-sized markers compatible with VFMs. A detection\nmethod locates 3D fiducials from intensity images, enabling LiDAR pose\nestimation. Second, an enhanced algorithm extends detection to 3D maps,\nincreasing marker range and facilitating tasks like 3D map merging. This method\nleverages both intensity and geometry, overcoming limitations of geometry-only\ndetection approaches. Third, a new LFM-based mapping and localization method\nregisters unordered, low-overlap point clouds. It employs adaptive threshold\ndetection and a two-level graph framework to solve a maximum a-posteriori (MAP)\nproblem, optimizing point cloud and marker poses. Additionally, the\nLivox-3DMatch dataset is introduced, improving learning-based multiview point\ncloud registration methods.\n  Extensive experiments with various LiDAR models in diverse indoor and outdoor\nscenes demonstrate the effectiveness and superiority of the proposed framework."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-476",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07138",
    "b_title":[
      "Strat{\\'e}gies de contr{\\^o}le pour les {\\'e}oliennes flottantes :\n  {\\'e}tat de l'art et perspectives"
    ],
    "b_abstract":[
      "The floating wind turbines sector has great energy potential. However,\nminimizing the movement of the structure under the combined effect of wind and\nwaves while ensuring maximum power extraction over a wide operating range is\none of the main challenges for the control of these turbines. This paper\npresents a review of control methods for floating wind turbines from the recent\nliterature. The limitations of these controllers are discussed, before\nintroducing a presentation of several promising data-based methods. In\nparticular, this paper focuses on artificial intelligence techniques associated\nwith data-based control methods. Finally, the CREATIF project dealing with\nreal-time simulation of floating wind turbines and their intelligent controls\nis presented."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.04536",
    "c_title":[
      "Scalable Derivative-Free Optimization Algorithms with Low-Dimensional\n  Subspace Techniques"
    ],
    "c_abstract":[
      "We re-introduce a derivative-free subspace optimization framework originating\nfrom Chapter 5 of the Ph.D. thesis [Z. Zhang, On Derivative-Free Optimization\nMethods, Ph.D. thesis, Chinese Academy of Sciences, Beijing, 2012] of the\nauthor under the supervision of Ya-xiang Yuan. At each iteration, the framework\ndefines a (low-dimensional) subspace based on an approximate gradient, and then\nsolves a subproblem in this subspace to generate a new iterate. We sketch the\nglobal convergence and worst-case complexity analysis of the framework,\nelaborate on its implementation, and present some numerical results on solving\nproblems with dimensions as high as 10^4 using only inaccurate function values."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-477",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06438",
    "b_title":[
      "Qffusion: Controllable Portrait Video Editing via Quadrant-Grid\n  Attention Learning"
    ],
    "b_abstract":[
      "This paper presents Qffusion, a dual-frame-guided framework for portrait\nvideo editing. Specifically, we consider a design principle of ``animation for\nediting'', and train Qffusion as a general animation framework from two still\nreference images while we can use it for portrait video editing easily by\napplying modified start and end frames as references during inference.\nLeveraging the powerful generative power of Stable Diffusion, we propose a\nQuadrant-grid Arrangement (QGA) scheme for latent re-arrangement, which\narranges the latent codes of two reference images and that of four facial\nconditions into a four-grid fashion, separately. Then, we fuse features of\nthese two modalities and use self-attention for both appearance and temporal\nlearning, where representations at different times are jointly modeled under\nQGA. Our Qffusion can achieve stable video editing without additional networks\nor complex training stages, where only the input format of Stable Diffusion is\nmodified. Further, we propose a Quadrant-grid Propagation (QGP) inference\nstrategy, which enjoys a unique advantage on stable arbitrary-length video\ngeneration by processing reference and condition frames recursively. Through\nextensive experiments, Qffusion consistently outperforms state-of-the-art\ntechniques on portrait video editing."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05673",
    "c_title":[
      "The Evolution of Dataset Distillation: Toward Scalable and Generalizable\n  Solutions"
    ],
    "c_abstract":[
      "Dataset distillation, which condenses large-scale datasets into compact\nsynthetic representations, has emerged as a critical solution for training\nmodern deep learning models efficiently. While prior surveys focus on\ndevelopments before 2023, this work comprehensively reviews recent advances,\nemphasizing scalability to large-scale datasets such as ImageNet-1K and\nImageNet-21K. We categorize progress into a few key methodologies: trajectory\nmatching, gradient matching, distribution matching, scalable generative\napproaches, and decoupling optimization mechanisms. As a comprehensive\nexamination of recent dataset distillation advances, this survey highlights\nbreakthrough innovations: the SRe2L framework for efficient and effective\ncondensation, soft label strategies that significantly enhance model accuracy,\nand lossless distillation techniques that maximize compression while\nmaintaining performance. Beyond these methodological advancements, we address\ncritical challenges, including robustness against adversarial and backdoor\nattacks, effective handling of non-IID data distributions. Additionally, we\nexplore emerging applications in video and audio processing, multi-modal\nlearning, medical imaging, and scientific computing, highlighting its domain\nversatility. By offering extensive performance comparisons and actionable\nresearch directions, this survey equips researchers and practitioners with\npractical insights to advance efficient and generalizable dataset distillation,\npaving the way for future innovations."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-478",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20710",
    "b_title":[
      "Balancing Thermal Relaxation Deviations of Near-Future Quantum Computing\n  Results via Bit-Inverted Programs"
    ],
    "b_abstract":[
      "One of the predominant causes of program distortion in the real quantum\ncomputing system may be attributed to the probability deviation caused by\nthermal relaxation. We introduce Barber (Balancing reAdout Results using\nBit-invErted ciRcuits), a method designed to counteract the asymmetric thermal\nrelaxation deviation and improve the reliability of near-term quantum programs.\nBarber collaborates with a bit-inverted quantum circuit, where the excited\nquantum state of qubits is assigned to the $\\lvert 0 \\rangle$ and the unexcited\nstate to the $\\lvert 1 \\rangle$. In doing so, bit-inverted quantum circuits can\nexperience thermal relaxation in the opposite direction compared to standard\nquantum circuits. Barber can effectively suppress the thermal relaxation\ndeviation in program's readout results by selectively merging distributions\nfrom the standard and bit-inverted circuits."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.16222",
    "c_title":[
      "Ultralong-lived Coherent States in Eu$^{3+}$:Y$_2$O$_3$ Optical Ceramics\n  for Quantum Memories"
    ],
    "c_abstract":[
      "Rare earth ions (REI) in solid materials are among the leading systems for\nquantum technology applications. However, developing practical REI quantum\ndevices with long-lived coherent states remains challenging due to great growth\ndifficulties of high-quality REI materials and a lack of comprehensive\nunderstanding of REI's decoherence mechanisms. Here we realize a record optical\ncoherence time of 421.5 $\\pm$ 10.5 $\\mu$s for the $^7$F$_0\\rightarrow^5$D$_0$\ntransition and more than 30 hours lifetime for the $^7$F$_0$ hyperfine spin\nstates in Eu$^{3+}$:Y$_2$O$_3$ optical ceramics. We report the elimination of\ntwo-level-system induced optical decoherence in short-range ordered crystals.\nMeanwhile, a new decoherence mechanism caused by new kinds of perturbing\nmagnetic centers is identified below 1.5 K. We further demonstrate the coherent\nlight storage over 5 $\\mu$s by using the atomic frequency comb protocol. These\nresults open up prospects for the realization of practical quantum memories and\nlarge scale quantum communications with REI optical ceramics."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-479",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16591",
    "b_title":[
      "UniK3D: Universal Camera Monocular 3D Estimation"
    ],
    "b_abstract":[
      "Monocular 3D estimation is crucial for visual perception. However, current\nmethods fall short by relying on oversimplified assumptions, such as pinhole\ncamera models or rectified images. These limitations severely restrict their\ngeneral applicability, causing poor performance in real-world scenarios with\nfisheye or panoramic images and resulting in substantial context loss. To\naddress this, we present UniK3D, the first generalizable method for monocular\n3D estimation able to model any camera. Our method introduces a spherical 3D\nrepresentation which allows for better disentanglement of camera and scene\ngeometry and enables accurate metric 3D reconstruction for unconstrained camera\nmodels. Our camera component features a novel, model-independent representation\nof the pencil of rays, achieved through a learned superposition of spherical\nharmonics. We also introduce an angular loss, which, together with the camera\nmodule design, prevents the contraction of the 3D outputs for wide-view\ncameras. A comprehensive zero-shot evaluation on 13 diverse datasets\ndemonstrates the state-of-the-art performance of UniK3D across 3D, depth, and\ncamera metrics, with substantial gains in challenging large-field-of-view and\npanoramic settings, while maintaining top accuracy in conventional pinhole\nsmall-field-of-view domains. Code and models are available at\ngithub.com\/lpiccinelli-eth\/unik3d ."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17843",
    "c_title":[
      "Automatic Vehicle Detection using DETR: A Transformer-Based Approach for\n  Navigating Treacherous Roads"
    ],
    "c_abstract":[
      "Automatic Vehicle Detection (AVD) in diverse driving environments presents\nunique challenges due to varying lighting conditions, road types, and vehicle\ntypes. Traditional methods, such as YOLO and Faster R-CNN, often struggle to\ncope with these complexities. As computer vision evolves, combining\nConvolutional Neural Networks (CNNs) with Transformer-based approaches offers\npromising opportunities for improving detection accuracy and efficiency. This\nstudy is the first to experiment with Detection Transformer (DETR) for\nautomatic vehicle detection in complex and varied settings. We employ a\nCollaborative Hybrid Assignments Training scheme, Co-DETR, to enhance feature\nlearning and attention mechanisms in DETR. By leveraging versatile label\nassignment strategies and introducing multiple parallel auxiliary heads, we\nprovide more effective supervision during training and extract positive\ncoordinates to boost training efficiency. Through extensive experiments on DETR\nvariants and YOLO models, conducted using the BadODD dataset, we demonstrate\nthe advantages of our approach. Our method achieves superior results, and\nimproved accuracy in diverse conditions, making it practical for real-world\ndeployment. This work significantly advances autonomous navigation technology\nand opens new research avenues in object detection for autonomous vehicles. By\nintegrating the strengths of CNNs and Transformers, we highlight the potential\nof DETR for robust and efficient vehicle detection in challenging driving\nenvironments."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-480",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20202",
    "b_title":[
      "Electromagnetic form factors of ${}^6$Li, ${}^7$Li, and ${}^7$Be in\n  cluster effective field theory"
    ],
    "b_abstract":[
      "Effective field theory (EFT) provides a powerful model-independent\ntheoretical framework for illuminating complicated interactions across a wide\nrange of physics areas and subfields. In this work, we consider the low-energy\ndeuteron-Helium-4, triton-Helium-4, and helion-Helium-4 systems at low energies\nin cluster EFT. In particular, we focus on the deuteron + Helium-4 cluster\nconfiguration of the Lithium-6 nucleus, the triton + Helium-4 cluster\nconfiguration of the Lithium-7 nucleus, and the Helium-3-Helium-4 configuration\nof the Beryllium-7 nucleus, respectively. We illustrate how to directly extract\nthe asymptotic normalization coefficient and several observables using\nexperimental measurement of the electromagnetic form factors of these nuclei."
    ],
    "b_categories":[
      [
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.17266",
    "c_title":[
      "Effect of nuclear deformation on Gamow-Teller strength distributions of\n  Hg isotopes"
    ],
    "c_abstract":[
      "Recent studies \\cite{1,2} predicted the sensitivity of the Gamow-Teller (GT)\nstrength distributions to nuclear deformation in neutron-deficient Hg isotopes.\nMotivated by this work, we investigate nuclear ground-state properties and GT\nstrength distributions for neutron-deficient Hg isotopes\n($^{177\\hbox{-}193}$Hg).\n  The nuclear deformation ($\\beta(E2)$) values were calculated using the\n**Relativistic Mean Field (RMF)** model. The RMF approach, with different\ndensity-dependent interactions (**DD-ME2** and **DD-PC1**), was employed to\ncompute nuclear shape parameters. These computed deformation values were then\nused within the framework of the **deformed proton-neutron quasi-particle\nrandom phase approximation (pn-QRPA)** model, with a separable interaction, to\ncalculate the allowed GT strength distributions for these Hg isotopes.\n  Our calculations validate the findings of \\cite{1} and confirm the effect of\ndeformation on GT strength distributions. This study may further provide a\ncomplementary signature for nuclear shape isomers. Noticeable differences are\nhighlighted between our results and previous calculations. The study of\n\\cite{1} suggests that $^{177\\hbox{-}182}$Hg possess prolate shapes, while\n$^{184\\hbox{-}196}$Hg exhibit oblate shapes. In contrast, our calculations\npredict **prolate** shapes for $^{177\\hbox{-}188}$Hg and **oblate** shapes for\n$^{189\\hbox{-}193}$Hg isotopes."
    ],
    "c_categories":[
      [
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-481",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05532",
    "b_title":[
      "Nonlocal Micromagnetics: Compactness Criteria, Existence of Minimizers,\n  and Brown's Fundamental Theorem"
    ],
    "b_abstract":[
      "This paper investigates the existence and qualitative properties of\nminimizers for a class of nonlocal micromagnetic energy functionals defined on\nbounded domains. The considered energy functional consists of a symmetric\nexchange interaction, which penalizes spatial variations in magnetization, and\na magnetostatic self-energy term that accounts for long-range dipolar\ninteractions. Motivated by the extension of Brown's fundamental theorem on fine\nferromagnetic particles to nonlocal settings, we develop a rigorous variational\nframework in $L^2(\\Omega;\\mathbb{S}^2)$ under mild assumptions on the\ninteraction kernel \\( j \\), including symmetry, L\\'evy-type integrability, and\nprescribed singular behavior. For spherical domains, we generalize Browns\nfundamental results by identifying critical radii $R^*$ and $R^{**}$ that\ndelineate distinct energetic regimes: for \\( R \\leq R^* \\), the uniform\nmagnetization state is energetically preferable (\\emph{small-body regime}),\nwhereas for $R \\geq R^{**}$, non-uniform magnetization configurations become\ndominant (\\emph{large-body regime}). These transitions are analyzed through\nPoincar\\'e-type inequalities and explicit energy comparisons between uniform\nand vortex-like magnetization states.\n  Our results directly connect classical micromagnetic theory and contemporary\nnonlocal models, providing new insights into domain structure formation in\nnanoscale magnetism. Furthermore, the mathematical framework developed in this\nwork contributes to advancing theoretical foundations for applications in\nspintronics and data storage technologies."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.01527",
    "c_title":[
      "$L^p-L^q$ estimates for the dissipative and conservative\n  Moore-Gibson-Thompson equations"
    ],
    "c_abstract":[
      "This paper studies some $L^p-L^q$ estimates for the dissipative or\nconservative Moore-Gibson-Thompson (MGT) equations in the whole space\n$\\mathbb{R}^n$. Our contributions are twofold. By applying the Fourier analysis\nassociated with the modified Bessel function in the dissipative case, we derive\nsome $L^p-L^q$ estimates of solutions. Then, introducing a good unknown related\nto the free wave equation in the conservative case, some $L^p-L^q$ estimates of\nsolutions with the admissible closed triangle range of exponents are deduced.\nThese results show some essential influences of dissipation from the MGT\nequations in the $L^q$ framework."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-482",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01613",
    "b_title":[
      "Fire and Ice in the Whirlpool: Spatially Resolved Scaling Relations\n  between X-ray Emitting Hot Gas and Cold Molecular Gas in M51"
    ],
    "b_abstract":[
      "The cold and hot interstellar medium (ISM) in star forming galaxies resembles\nthe reservoir for star formation and associated heating by stellar winds and\nexplosions during stellar evolution, respectively. We utilize data from deep\n$Chandra$ observations and archival millimeter surveys to study the\ninterconnection between these two phases and the relation to star formation\nactivities in M51 on kiloparsec scales. A sharp radial decrease is present in\nthe hot gas surface brightness profile within the inner 2 kpc of M51. The ratio\nbetween the total infrared luminosity ($L_{\\rm IR}$) and the hot gas luminosity\n($L_{\\rm 0.5 - 2\\,keV}^{\\rm gas}$) shows a positive correlation with the\ngalactic radius in the central region. For the entire galaxy, a twofold\ncorrelation is revealed in the $L_{\\rm 0.5 - 2\\,keV}^{\\rm gas}$${-}$$L_{\\rm\nIR}$ diagram, where $L_{\\rm 0.5 - 2\\,keV}^{\\rm gas}$ sharply increases with\n$L_{\\rm IR}$ in the center but varies more slowly in the disk. The best fit\ngives a steep relation of ${\\rm log}(L_{\\rm 0.5-2\\,keV}^{\\rm gas} \/{\\rm\nerg\\,s^{-1}})=1.82\\,{\\rm log}(L_{\\rm IR} \/{L_{\\rm \\odot}})+22.26$ for the\ncenter of M51. The similar twofold correlations are also found in the $L_{\\rm\n0.5 - 2\\,keV}^{\\rm gas}$${-}$molecular line luminosity ($L^\\prime_{\\rm gas}$)\nrelations for the four molecular emission lines CO(1-0), CO(2-1), HCN(1-0), and\nHCO$^+$(1-0). We demonstrate that the core-collapse supernovae (SNe) are the\nprimary source of energy for heating gas in the galactic center of M51, leading\nto the observed steep $L_{\\rm 0.5 - 2\\,keV}^{\\rm gas}$${-}$$L_{\\rm IR}$ and\n$L_{\\rm 0.5 - 2\\,keV}^{\\rm gas}$${-}$$L^\\prime_{\\rm gas}$ relations, as their\nX-ray radiation efficiencies ($\\eta$ $\\equiv$ $L_{\\rm 0.5 - 2\\,keV}^{\\rm\ngas}$\/$\\dot{E}_\\mathrm{SN}$) increase with the star formation rate surface\ndensities, where $\\dot{E}_\\mathrm{SN}$ is the SN mechanical energy input rate."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04089",
    "c_title":[
      "Streams, Shells, and Substructures in the Accretion-Built Stellar Halo\n  of NGC 300"
    ],
    "c_abstract":[
      "We present deep optical observations of the stellar halo of NGC 300, an\nLMC-mass galaxy, acquired with the DEEP sub-component of the DECam Local Volume\nExploration survey (DELVE) using the 4 m Blanco Telescope. Our resolved star\nanalysis reveals a large, low surface brightness stellar stream\n($M_{V}\\sim-8.5$; [Fe\/H] $= -1.4\\pm0.15$) extending more than 40 kpc north from\nthe galaxy's center. We also find other halo structures, including potentially\nan additional stream wrap to the south, which may be associated with the main\nstream. The morphology and derived low metallicities of the streams and shells\ndiscovered surrounding NGC 300 are highly suggestive of a past accretion event.\nAssuming a single progenitor, the accreted system is approximately Fornax-like\nin luminosity, with an inferred mass ratio to NGC 300 of approximately $1:15$.\nWe also present the discovery of a metal-poor globular cluster\n($R_{\\rm{proj}}=23.3$~kpc; $M_{V}=-8.99\\pm0.16$; [Fe\/H] $\\approx-1.6\\pm0.6$) in\nthe halo of NGC 300, the furthest identified globular cluster associated with\nNGC 300. The stellar structures around NGC 300 represent the richest features\nobserved in a Magellanic Cloud analog to date, strongly supporting the idea\nthat accretion and subsequent disruption is an important mechanism in the\nassembly of dwarf galaxy stellar halos."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-483",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04478",
    "b_title":[
      "Semantic Alignment of Unimodal Medical Text and Vision Representations"
    ],
    "b_abstract":[
      "General-purpose AI models, particularly those designed for text and vision,\ndemonstrate impressive versatility across a wide range of deep-learning tasks.\nHowever, they often underperform in specialised domains like medical imaging,\nwhere domain-specific solutions or alternative knowledge transfer approaches\nare typically required. Recent studies have noted that general-purpose models\ncan exhibit similar latent spaces when processing semantically related data,\nalthough this alignment does not occur naturally. Building on this insight, it\nhas been shown that applying a simple transformation - at most affine -\nestimated from a subset of semantically corresponding samples, known as\nanchors, enables model stitching across diverse training paradigms,\narchitectures, and modalities. In this paper, we explore how semantic alignment\n- estimating transformations between anchors - can bridge general-purpose AI\nwith specialised medical knowledge. Using multiple public chest X-ray datasets,\nwe demonstrate that model stitching across model architectures allows general\nmodels to integrate domain-specific knowledge without additional training,\nleading to improved performance on medical tasks. Furthermore, we introduce a\nnovel zero-shot classification approach for unimodal vision encoders that\nleverages semantic alignment across modalities. Our results show that our\nmethod not only outperforms general multimodal models but also approaches the\nperformance levels of fully trained, medical-specific multimodal solutions"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16535",
    "c_title":[
      "Vision-Language Embodiment for Monocular Depth Estimation"
    ],
    "c_abstract":[
      "Depth estimation is a core problem in robotic perception and vision tasks,\nbut 3D reconstruction from a single image presents inherent uncertainties.\nCurrent depth estimation models primarily rely on inter-image relationships for\nsupervised training, often overlooking the intrinsic information provided by\nthe camera itself. We propose a method that embodies the camera model and its\nphysical characteristics into a deep learning model, computing embodied scene\ndepth through real-time interactions with road environments. The model can\ncalculate embodied scene depth in real-time based on immediate environmental\nchanges using only the intrinsic properties of the camera, without any\nadditional equipment. By combining embodied scene depth with RGB image\nfeatures, the model gains a comprehensive perspective on both geometric and\nvisual details. Additionally, we incorporate text descriptions containing\nenvironmental content and depth information as priors for scene understanding,\nenriching the model's perception of objects. This integration of image and\nlanguage - two inherently ambiguous modalities - leverages their complementary\nstrengths for monocular depth estimation. The real-time nature of the embodied\nlanguage and depth prior model ensures that the model can continuously adjust\nits perception and behavior in dynamic environments. Experimental results show\nthat the embodied depth estimation method enhances model performance across\ndifferent scenes."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-484",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12228",
    "b_title":[
      "On the nonexistence of a Green functor with values MSpin${}^c$ and MSpin"
    ],
    "b_abstract":[
      "In this note, we show that there does not exist a $C_2$-ring spectrum whose\nunderlying ring spectrum is $\\mathrm{MSpin}^c$ and whose $C_2$-fixed point\nspectrum is $\\mathrm{MSpin}$."
    ],
    "b_categories":[
      [
        "math.AT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.05276",
    "c_title":[
      "Homotopy Types of Small Semigroups"
    ],
    "c_abstract":[
      "We algorithmically compute integral Eilenberg-MacLane homology of all\nsemigroups of order at most $8$ and present some particular semigroups with\nnotable classifying spaces, refuting conjectures of Nico. Along the way, we\ngive an alternative topological proof of the fact that if a finite semigroup\n$S$ has a left-simple or right-simple minimal ideal $K(S)$, then the\nclassifying space $BS$ is homotopy equivalent to the classifying space $B(GS)$\nof the group completion. We also describe an algorithm for computing the group\ncompletion $GS$ of a finite semigroup $S$ using asymptotically fewer than\n$|S|^2$ semigroup operations. Finally, we show that the set of homotopy types\nof classifying spaces of finite monoids is closed under suspension."
    ],
    "c_categories":[
      [
        "math.AT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-485",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03693",
    "b_title":[
      "Continuation of an Optical Spectroscopic Campaign of Fermi Blazar\n  Candidates with TNG: Discovery of a New Changing-Look Blazar"
    ],
    "b_abstract":[
      "Context. Blazars are a distinct subclass of active galactic nuclei (AGN),\nknown for their fast variability, high polarization, and intense emission\nacross the electromagnetic spectrum, from radio waves to gamma rays. Gamma-ray\nblazar candidates of uncertain type (BCU) are an ongoing challenge in gamma-ray\nastronomy due to difficulties in classification and redshift determination.\nAims. This study continues an optical spectroscopic campaign aimed at\nidentifying the characteristics of BCUs to improve classification and redshift\nestimates, particularly focusing on low-synchrotron-peak sources. Methods. We\nconducted a detailed analysis of optical spectroscopic data for a sample of 21\nlow-synchrotron-peak BCUs plus one bl lac with contradictory results in the\nliterature, using the 3.58-m Telescopio Nazionale Galileo (TNG, La Palma,\nSpain). Results. Our analysis identifies 14 out of the 21 BCUs as flat-spectrum\nradio quasars (FSRQs), demonstrating the effectiveness of our selection\ncriteria. Notably, four FSRQs have redshifts exceeding 1, including 4FGL\nJ2000.0+4214 at z = 2.04. Six sources are classified as bl lacs, with one of\nthem, 4FGL J0746.5-0719, showing a featureless spectrum in this work despite\npreviously exhibiting strong lines, suggesting it may be a changing-look\nblazar. One source remains classified as a BCU due to a noisy spectrum.\nAdditionally, we observed a bl lac object, 4FGL J1054.5+2211, due to\ninconsistent redshift estimates in the literature, but we could not confirm any\nredshift due to its featureless spectrum. Our findings provide insights into\nthe classification and redshift estimation of blazar candidates, emphasizing\nthe need for continued spectroscopic monitoring."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.12463",
    "c_title":[
      "Revisiting the fundamental parameters for the black hole X-ray transient\n  Swift J1753.5-0127"
    ],
    "c_abstract":[
      "We present time-resolved Gran Telescopio Canarias optical spectroscopy and\nWilliam Herschel Telescope $i$-band photometry of the X-ray transient SWIFT\nJ1753.5-0127 in quiescence. The $i$-band light curve is dominated by flickering\nwith an amplitude of $\\sim 0.5$ mag and shows no evidence of the ellipsoidal\nmodulation of the companion star. The telluric-corrected average spectrum, on\nthe other hand, reveals the presence of weak (strongly veiled) TiO bands at\n$7055$ \\.A and $7589$ \\.A. We used them for a spectral classification, finding\nan M4-5 V companion star. However, as velocity shifts are not clearly detected\nin the individual spectra, we turned the analysis to the double-peaked\nH$\\alpha$ emission line from the accretion disc. By exploiting the empirical\ncorrelations established for quiescent X-ray transients between the line\nmorphology and fundamental binary parameters, we estimated the radial velocity\nsemi-amplitude of the companion $K_2 = 820 \\pm 36$ km s$^{-1}$, a mass ratio $q\n= 0.023 \\pm 0.006$ and an inclination $i = 79 \\pm 5$ deg. Moreover, an orbital\nperiod of $3.26 \\pm 0.02$ h was measured from the modulation of the centroid\nvelocities and the double-peak trough depth of the H$\\alpha$ profile. These\nquantities yielded a mass function $f(M_1) = 7.8 \\pm 1.0$ M$_\\odot$ and black\nhole and companion star masses of $M_1 = 8.8 \\pm 1.3$ M$_\\odot$ and $M_2 = 0.20\n\\pm 0.06$ M$_\\odot$, respectively. The companion star mass is in line with the\nspectral classification obtained from the relative depth of the TiO bands.\nBased on the mean quiescent magnitude ($i = 21.4 \\pm 0.1$), orbital period, and\ninterstellar extinction, we estimate the distance to the source to be $3.9 \\pm\n0.7$ kpc and a Galactic plane elevation of $0.8 \\pm 0.2$ kpc, supporting the\ncase for a large natal kick."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-486",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09791",
    "b_title":[
      "Star-Forming Nuclear Clusters in Dwarf Galaxies Mimicking AGN Signatures\n  in the Mid-Infrared"
    ],
    "b_abstract":[
      "Effectively finding and identifying active galactic nuclei (AGNs) in dwarf\ngalaxies is an important step in studying black hole formation and evolution.\nIn this work, we examine four mid-IR-selected AGN candidates in dwarf galaxies\nwith stellar masses between $M_\\star \\sim 10^8 - 10^9 M_\\odot$ , and find that\nthe galaxies are host to nuclear star clusters (NSCs) that are notably rare in\nhow young and massive they are. We perform photometric measurements on the\ncentral star clusters in our target galaxies galaxies using Hubble Space\nTelescope optical and near-IR imaging and compare their observed properties to\nmodels of stellar population evolution. We find that these galaxies are host to\nvery massive ($\\sim10^7 M_\\odot$), extremely young ($\\lesssim 8$ Myr), dusty\n($0.6 \\lesssim \\mathrm{A_v} \\lesssim 1.8$) nuclear star clusters. Our results\nindicate that these galactic nuclei have ongoing star-formation, are still at\nleast partially obscured by clouds of gas and dust, and are most likely\nproducing the extremely red AGN-like mid-IR colors. Moreover, prior work has\nshown that these galaxies do not exhibit X-ray or optical AGN signatures.\nTherefore, we recommend caution when using mid-IR color-color diagnostics for\nAGN selection in dwarf galaxies, since, as directly exemplified in this sample,\nthey can be contaminated by massive star clusters with ongoing star formation."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.08212",
    "c_title":[
      "Cloud populations versus galactic environment in NGC4689, NGC628,\n  NGC1566, and NGC4321"
    ],
    "c_abstract":[
      "The study of molecular clouds in galaxies beyond the Local Group is limited\nby the need to efficiently sample diverse galactic environments across galactic\ndiscs, typically resulting in a loss of resolution. Using a high-resolution\ndust extinction technique, we image the dust (and gas) of 4 nearby galaxies\n(<18 Mpc; NGC 4689, NGC 628, NGC 1566, and NGC 4321) with resolutions between\n5-9 pc. We present catalogues of spatially-resolved clouds for these galaxies,\nwith which we investigate whether different galactic environments and\nmorphologies have a significant impact on observed cloud properties. We find no\nsystematic differences in cloud size, aspect ratio, or morphology with galactic\nenvironment or radius. We do find changes in cloud masses\/surface densities\nbetween the centres and discs of galaxies, with clouds in centres typically\ndisplaying higher values of mass\/surface density. Furthermore, we find distinct\ndistributions of cloud surface densities across the bars of NGC 1566 and NGC\n4321. Differences between the arm and inter-arm populations are more subtle,\nwith some galaxies in the sample having much higher cloud masses\/surface\ndensities in their spiral arms, and other galaxies showing fairly similar\narm\/inter-arm distributions. These results suggest that, even within this small\nsample of galaxies, not all spiral arms and bars seem to behave and affect the\ninterstellar medium equally. Therefore, performing a qualitative environment\nanalysis, where clouds of different galaxies are all binned together under the\nsame visual environmental classification, leads to the loss of information on\ninteresting property variations which in turn demonstrate the impact of the\nunderlying dynamics."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-487",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09553",
    "b_title":[
      "Plasmon-sound hybridization in ionic crystals"
    ],
    "b_abstract":[
      "We study the hybridization between plasmons, phonons, and electronic sound in\nionic crystals using the Debye model, where the ionic background is modeled as\na homogeneous, isotropic, elastic medium. We explicitly obtain the energies and\nthe damping of the hybrid plasmon-sound modes in the hydrodynamic regime and\ncalculate the corresponding dynamic structure factor. We show that the direct\nCoulomb interaction between the ions is essential to obtain a collective sound\nmode with linear dispersion."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11063",
    "c_title":[
      "Magnetoconductivity due to electron-electron interaction in a\n  non-Galilean--invariant Fermi liquid"
    ],
    "c_abstract":[
      "The $T^2$-scaling of resistivity with temperature is often viewed as a\nclassic hallmark of a Fermi-liquid (FL) behavior in metals. However, if umklapp\nscattering is suppressed, this scaling is not universally guaranteed to occur.\nIn this case, the resistivity behavior is influenced by several factors, such\nas dimensionality (two vs. three), topology (simply- vs. multiply-connected\nFermi surfaces), and (in two dimensions) the shape (convex vs. concave) of the\nFermi surface (FS). Specifically for an isotropic spectrum, as well as for a\ntwo-dimensional (2D) convex FS, the $T^2$ term is absent, and the first\nnon-zero contribution scales as $T^4\\ln T$ in 2D and as $T^4$ in 3D. In this\npaper, we study the $T$-dependence of the resistivity, arising from\nelectron-electron interactions, in the presence of a weak magnetic field. We\nshow that, for an isotropic FS in any dimensions and for a convex 2D FS, the\n$T^2$ term is also absent in both Hall and diagonal magnetoconductivity, which\ninstead scale as $BT^4\\ln T$ and $B^2T^4\\ln T$, respectively, in 2D and as\n$BT^4$ and $B^2T^4$ in 3D. The FL-like scaling, i.e., $BT^2$ and $B^2T^2$ of\nthe Hall and diagonal conductivities is recovered for a concave FS in 2D.\nFurthermore, we show that, for an isotropic spectrum, magnetoresistance is\nabsent even in the presence of electron-electron interactions. Additionally, we\nexamine the high-temperature limit, when electron-electron scattering prevails\nover electron-impurity one, and show that all components of the conductivity\ntensor saturate in this limit at values that are determined by impurity\nscattering but, in general, differ from the corresponding values at $T=0$."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-488",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19917",
    "b_title":[
      "Picking the Cream of the Crop: Visual-Centric Data Selection with\n  Collaborative Agents"
    ],
    "b_abstract":[
      "To improve Multimodal Large Language Models' (MLLMs) ability to process\nimages and complex instructions, researchers predominantly curate large-scale\nvisual instruction tuning datasets, which are either sourced from existing\nvision tasks or synthetically generated using LLMs and image descriptions.\nHowever, they often suffer from critical flaws, including misaligned\ninstruction-image pairs and low-quality images. Such issues hinder training\nefficiency and limit performance improvements, as models waste resources on\nnoisy or irrelevant data with minimal benefit to overall capability. To address\nthis issue, we propose a \\textbf{Vi}sual-Centric \\textbf{S}election approach\nvia \\textbf{A}gents Collaboration (ViSA), which centers on image quality\nassessment and image-instruction relevance evaluation. Specifically, our\napproach consists of 1) an image information quantification method via visual\nagents collaboration to select images with rich visual information, and 2) a\nvisual-centric instruction quality assessment method to select high-quality\ninstruction data related to high-quality images. Finally, we reorganize 80K\ninstruction data from large open-source datasets. Extensive experiments\ndemonstrate that ViSA outperforms or is comparable to current state-of-the-art\nmodels on seven benchmarks, using only 2.5\\% of the original data, highlighting\nthe efficiency of our data selection approach. Moreover, we conduct ablation\nstudies to validate the effectiveness of each component of our method. The code\nis available at https:\/\/github.com\/HITsz-TMG\/ViSA."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15108",
    "c_title":[
      "Knowledge Hierarchy Guided Biological-Medical Dataset Distillation for\n  Domain LLM Training"
    ],
    "c_abstract":[
      "The rapid advancement of large language models (LLMs) in biological-medical\napplications has highlighted a gap between their potential and the limited\nscale and often low quality of available open-source annotated textual\ndatasets. In addition, the inherent complexity of the biomedical knowledge\nhierarchy significantly hampers efforts to bridge this gap.Can LLMs themselves\nplay a pivotal role in overcoming this limitation? Motivated by this question,\nwe investigate this challenge in the present study.We propose a framework that\nautomates the distillation of high-quality textual training data from the\nextensive scientific literature. Our approach self-evaluates and generates\nquestions that are more closely aligned with the biomedical domain, guided by\nthe biomedical knowledge hierarchy through medical subject headings (MeSH).\nThis comprehensive framework establishes an automated workflow, thereby\neliminating the need for manual intervention. Furthermore, we conducted\ncomprehensive experiments to evaluate the impact of our framework-generated\ndata on downstream language models of varying sizes. Our approach substantially\nimproves question-answering tasks compared to pre-trained models from the life\nsciences domain and powerful close-source models represented by GPT-4. Notably,\nthe generated AI-Ready dataset enabled the Llama3-70B base model to outperform\nGPT-4 using MedPrompt with multiple times the number of parameters. Detailed\ncase studies and ablation experiments underscore the significance of each\ncomponent within our framework"
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-489",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08000",
    "b_title":[
      "Bloch oscillations in interacting systems driven by a time-dependent\n  magnetic field"
    ],
    "b_abstract":[
      "According to Faraday's law in classical physics, a varying magnetic field\nstimulates an electric eddy field. Intuitively, when a classical field is\nconstant and imposed on a lattice, the Wannier-Stark ladders (WSL) can be\nestablished, resulting in Bloch oscillations. In this work, we investigate the\ndynamics of an interacting system on a (generalized) ring lattice threaded by a\nvarying magnetic flux. Based on the rigorious results, we demonstrate that\nthere exist many invariant subspaces in which the dynamics is periodic when the\nflux varies linearly over time. Nevertheless, for a given initial state, the\nevolved state differs from that driven by a linear field. However, the\nprobability distributions of the two states are identical, referred to as the\nquantum analogue of Faraday's law. Our results are ubiquitous for a wide\nvariety of interacting systems. We demonstrate these results through numerical\nsimulations in an extended fermi-Hubbard model."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.07471",
    "c_title":[
      "Quantum oscillations in the heat capacity of Kondo insulator YbB12"
    ],
    "c_abstract":[
      "We observe the magnetic quantum oscillation in the heat capacity of the Kondo\ninsulator YbB$_{12}$. The frequency of these oscillations $F = 670$ T, aligns\nwith findings from magnetoresistance and torque magnetometry experiments for\n$\\mu_0 H > 35$ T in the Kondo insulating phase. Remarkably, the quantum\noscillation amplitudes in the heat capacity are substantial, with $\\Delta\n\\tilde{C}\/T \\approx$ 0.5 $\\rm{mJ}$ $\\rm{mol^{-1}K^{-2}}$ at 0.8 K, accounting\nfor 13$\\%$ of the known linear heat capacity coefficient $\\gamma$. Double-peak\nstructures of quantum-oscillation amplitudes due to the distribution function\nof fermions were identified and used to determine the value of the effective\nmass from the heat capacity, which agrees well with that from torque\nmagnetometry. These observations support charge-neutral fermions contributing\nto the quantum oscillations in YbB$_{12}$."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-490",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08659",
    "b_title":[
      "BRIGHT-VO: Brightness-Guided Hybrid Transformer for Visual Odometry with\n  Multi-modality Refinement Module"
    ],
    "b_abstract":[
      "Visual odometry (VO) plays a crucial role in autonomous driving, robotic\nnavigation, and other related tasks by estimating the position and orientation\nof a camera based on visual input. Significant progress has been made in\ndata-driven VO methods, particularly those leveraging deep learning techniques\nto extract image features and estimate camera poses. However, these methods\noften struggle in low-light conditions because of the reduced visibility of\nfeatures and the increased difficulty of matching keypoints. To address this\nlimitation, we introduce BrightVO, a novel VO model based on Transformer\narchitecture, which not only performs front-end visual feature extraction, but\nalso incorporates a multi-modality refinement module in the back-end that\nintegrates Inertial Measurement Unit (IMU) data. Using pose graph optimization,\nthis module iteratively refines pose estimates to reduce errors and improve\nboth accuracy and robustness. Furthermore, we create a synthetic low-light\ndataset, KiC4R, which includes a variety of lighting conditions to facilitate\nthe training and evaluation of VO frameworks in challenging environments.\nExperimental results demonstrate that BrightVO achieves state-of-the-art\nperformance on both the KiC4R dataset and the KITTI benchmarks. Specifically,\nit provides an average improvement of 20% in pose estimation accuracy in normal\noutdoor environments and 259% in low-light conditions, outperforming existing\nmethods. For widespread use and further development, the research work is fully\nopen-source at https:\/\/github.com\/Anastasiawd\/BrightVO."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17131",
    "c_title":[
      "Scenario Understanding of Traffic Scenes Through Large Visual Language\n  Models"
    ],
    "c_abstract":[
      "Deep learning models for autonomous driving, encompassing perception,\nplanning, and control, depend on vast datasets to achieve their high\nperformance. However, their generalization often suffers due to domain-specific\ndata distributions, making an effective scene-based categorization of samples\nnecessary to improve their reliability across diverse domains. Manual\ncaptioning, though valuable, is both labor-intensive and time-consuming,\ncreating a bottleneck in the data annotation process. Large Visual Language\nModels (LVLMs) present a compelling solution by automating image analysis and\ncategorization through contextual queries, often without requiring retraining\nfor new categories. In this study, we evaluate the capabilities of LVLMs,\nincluding GPT-4 and LLaVA, to understand and classify urban traffic scenes on\nboth an in-house dataset and the BDD100K. We propose a scalable captioning\npipeline that integrates state-of-the-art models, enabling a flexible\ndeployment on new datasets. Our analysis, combining quantitative metrics with\nqualitative insights, demonstrates the effectiveness of LVLMs to understand\nurban traffic scenarios and highlights their potential as an efficient tool for\ndata-driven advancements in autonomous driving."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-491",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05353",
    "b_title":[
      "Point-Identifying Semiparametric Sample Selection Models with No\n  Excluded Variable"
    ],
    "b_abstract":[
      "Sample selection is pervasive in applied economic studies. This paper\ndevelops semiparametric selection models that achieve point identification\nwithout relying on exclusion restrictions, an assumption long believed\nnecessary for identification in semiparametric selection models. Our\nidentification conditions require at least one continuously distributed\ncovariate and certain nonlinearity in the selection process. We propose a\ntwo-step plug-in estimator that is root-n-consistent, asymptotically normal,\nand computationally straightforward (readily available in statistical\nsoftware), allowing for heteroskedasticity. Our approach provides a middle\nground between Lee (2009)'s nonparametric bounds and Honor\\'e and Hu (2020)'s\nlinear selection bounds, while ensuring point identification. Simulation\nevidence confirms its excellent finite-sample performance. We apply our method\nto estimate the racial and gender wage disparity using data from the US Current\nPopulation Survey. Our estimates tend to lie outside the Honor\\'e and Hu\nbounds."
    ],
    "b_categories":[
      [
        "econ.EM"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2502.12867",
    "c_title":[
      "Assortative Marriage and Geographic Sorting"
    ],
    "c_abstract":[
      "Between 1980 and 2000, the U.S. experienced a significant rise in geographic\nsorting and educational homogamy, with college graduates increasingly\nconcentrating in high-skill cities and marrying similarly educated spouses. We\ndevelop and estimate a spatial equilibrium model with local labor, housing, and\nmarriage markets, incorporating a marriage matching framework with transferable\nutility. Using the model, we estimate trends in assortative preferences,\nquantify the interplay between marital and geographic sorting, and assess their\ncombined impact on household inequality. Welfare analyses show that after\naccounting for marriage, the college well-being gap grew substantially more\nthan the college wage gap."
    ],
    "c_categories":[
      [
        "econ.EM"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-492",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00515",
    "b_title":[
      "Curvature and conformal curvature dynamics formalisms and their\n  applications in linearized gravity"
    ],
    "b_abstract":[
      "Tensorial, spinorial and helicity formalisms of the curvature and conformal\ncurvature dynamics are developed. Equations of linearized gravity within that\nformalisms are given. Gravitational radiation in linearized gravity in terms of\ncurvature dynamics is investigated. Equivalence of the Bia\\l{}ynicki-Birula\nformula for the gravitational energy in linearized gravity and the\nLandau-Lifschitz formula is proved. Analogous result is found for the momentum\nin linearized gravity."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.08362",
    "c_title":[
      "Dark Energy and Cosmic Evolution: A Study in f (R, T) Gravity"
    ],
    "c_abstract":[
      "In the context of f(R, T) gravity theory for the flat Friedmann Lemaitre\nRobertson Walker (FLRW) model, the accelerating expansion of the universe is\ninvestigated using a specific form of the emergent Hubble parameter. Datasets\nfrom H(z), Type Ia supernovae (SNIa), and Baryon Acoustic Oscillations (BAO)\nare used to constrain the model and identify the ideal parameter values in\norder to evaluate the statistical significance of f(R, T) gravity. The best-fit\nparameters are derived by solving the modified Friedmann equations through a\nMCMC analysis. These parameters are used to compute the equation of state,\nstatefinders, energy conditions, and the (w-w) plane. Furthermore, the\nevolution of kinematic cosmographic parameters is examined. The findings\nprovide significant behavior and features of dark energy models. Our\ncomprehension of the dynamics and evolution of the universe is improved by this\nstudy, which also advances our understanding of dark energy and how it shapes\nthe universe."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-493",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04112",
    "b_title":[
      "A Class of Non-Contracting Branch Groups with Non-Torsion Rigid Kernels"
    ],
    "b_abstract":[
      "In this work, we provide the first example of an infinite family of branch\ngroups in the class of non-contracting self-similar groups. We show that these\ngroups are very strongly fractal, not regular branch, and of exponential\ngrowth. Further, we prove that these groups do not have the congruence subgroup\nproperty by explicitly calculating the structure of their rigid kernels. This\nclass of groups is also the first example of branch groups with non-torsion\nrigid kernels. As a consequence of these results, we also determine the\nHausdorff dimension of these groups."
    ],
    "b_categories":[
      [
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03737",
    "c_title":[
      "On a character correspondence associated to $\\mathfrak{F}$-projectors"
    ],
    "c_abstract":[
      "We study the conditions under which the head characters of a solvable group,\nas defined by I. M. Isaacs, behave well with respect to restriction. We also\ndetermine the intersection of the kernels of all head characters of the group.\nUsing G. Navarro's definition of $\\mathfrak{F}'$-characters, we generalize\nthese results for any saturated formation $\\mathfrak{F}$ containing the\nnilpotent groups."
    ],
    "c_categories":[
      [
        "math.GR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-494",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12950",
    "b_title":[
      "Towards Hybrid Traffic Laws for Mixed Flow of Human-Driven Vehicles and\n  Connected Autonomous Vehicles"
    ],
    "b_abstract":[
      "Hybrid traffic laws represent an innovative approach to managing mixed\nenvironments of connected autonomous vehicles (CAVs) and human-driven vehicles\n(HDVs) by introducing separate sets of regulations for each vehicle type. These\nlaws are designed to leverage the unique capabilities of CAVs while ensuring\nboth types of cars coexist effectively, ultimately aiming to enhance overall\nsocial welfare. This study uses the SUMO simulation platform to explore hybrid\ntraffic laws in a restricted lane scenario. It evaluates static and dynamic\nlane access policies under varying traffic demands and CAV proportions. The\npolicies aim to minimize average passenger delay and encourage the\nincorporation of autonomous vehicles with higher occupancy rates. Results\ndemonstrate that dynamic policies significantly improve traffic flow,\nespecially at low CAV proportions, compared to traditional dedicated bus lane\nstrategies. These findings highlight the potential of hybrid traffic laws to\nenhance traffic efficiency and accelerate the transition to autonomous\ntechnology."
    ],
    "b_categories":[
      [
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16098",
    "c_title":[
      "Multi-Agent Meta-Offline Reinforcement Learning for Timely UAV Path\n  Planning and Data Collection"
    ],
    "c_abstract":[
      "Multi-agent reinforcement learning (MARL) has been widely adopted in\nhigh-performance computing and complex data-driven decision-making in the\nwireless domain. However, conventional MARL schemes face many obstacles in\nreal-world scenarios. First, most MARL algorithms are online, which might be\nunsafe and impractical. Second, MARL algorithms are environment-specific,\nmeaning network configuration changes require model retraining. This letter\nproposes a novel meta-offline MARL algorithm that combines conservative\nQ-learning (CQL) and model agnostic meta-learning (MAML). CQL enables offline\ntraining by leveraging pre-collected datasets, while MAML ensures scalability\nand adaptability to dynamic network configurations and objectives. We propose\ntwo algorithm variants: independent training (M-I-MARL) and centralized\ntraining decentralized execution (M-CTDE-MARL). Simulation results show that\nthe proposed algorithm outperforms conventional schemes, especially the CTDE\napproach that achieves 50 % faster convergence in dynamic scenarios than the\nbenchmarks. The proposed framework enhances scalability, robustness, and\nadaptability in wireless communication systems by optimizing UAV trajectories\nand scheduling policies."
    ],
    "c_categories":[
      [
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-495",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00087",
    "b_title":[
      "Doppler, gravitational and cosmological redshifts"
    ],
    "b_abstract":[
      "Ortiz and Ibarra-Castor (2024) have presented a \"Generalized redshift\nformula\" taking account of only energy conservation considerations. Contrary to\ntheir claim, we emphasize to invoke both energy and momentum considerations in\norder to deduce all three types of redshift (Doppler, gravitational and\ncosmological). We formulate our views on the three physical effects in a\nconsistent manner in addition to addressing the lack of relevant references in\nRef.(Ortizand Ibarra-Castor, 2024)."
    ],
    "b_categories":[
      [
        "physics.gen-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.10445",
    "c_title":[
      "Electromagnetism from relativistic fluid dynamics"
    ],
    "c_abstract":[
      "We present a matter-space framework characterizing particles and establish\nits compatibility with electromagnetism. In this approach, matter, such as\nphotons, is considered to reside in a three-dimensional matter space, with the\nelectromagnetic fields observed in four-dimensional spacetime interpreted as\nprojections from this space. By imposing gauge symmetry through constraint\nequations, we derive the relationship between the vector field $A_a$ and the\nantisymmetric tensor $F_{ab}$, forming part of Maxwell's equations. The\nremaining Maxwell equation is obtained through the action principle in\nrelativistic fluid dynamics. Notably, we demonstrate that this imposition of\nthe gauge symmetry and constraints develop the dynamics. This framework offers\na fresh perspective on particle-field interactions and deepens the theoretical\nfoundation of relativistic fluid dynamics."
    ],
    "c_categories":[
      [
        "physics.gen-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-496",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20831",
    "b_title":[
      "A Dynamic Bus Lane Strategy for Integrated Management of Human-Driven\n  and Autonomous Vehicles"
    ],
    "b_abstract":[
      "This study introduces a dynamic bus lane (DBL) strategy, referred to as the\ndynamic bus priority lane (DBPL) strategy, designed for mixed traffic\nenvironments featuring both manual and automated vehicles. Unlike previous DBL\nstrategies, this approach accounts for partially connected and autonomous\nvehicles (CAVs) capable of autonomous trajectory planning. By leveraging this\ncapability, the strategy grants certain CAVs Right of Way (ROW) in bus lanes\nwhile utilizing their leading effects in general lanes to guide vehicle\nplatoons through intersections, thereby indirectly influencing the trajectories\nof other vehicles. The ROW allocation is optimized using a mixed-integer linear\nprogramming (MILP) model, aimed at minimizing total vehicle travel time. Since\ndifferent CAVs entering the bus lane affect other vehicles travel times, the\nmodel incorporates lane change effects when estimating the states of CAVs,\nhuman-driven vehicles (HDVs), and connected autonomous buses (CABs) as they\napproach the stop bar. A dynamic control framework with a rolling horizon\nprocedure is established to ensure precise execution of the ROW optimization\nunder varying traffic conditions. Simulation experiments across two scenarios\nassess the performance of the proposed DBPL strategy at different CAV market\npenetration rates (MPRs)."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.01583",
    "c_title":[
      "Classification and Feasibility Assessment of Infinitely Many Iso-Impulse\n  Three-Dimensional Trajectories"
    ],
    "c_abstract":[
      "In two-body dynamics, it is proven that for a sufficiently long flight time,\ngenerating infinitely many iso-impulse solutions is possible by solving a\nnumber of $\\Delta v$-allocation problems analytically. A distinct feature of\nthese solutions is the existence of two impulse anchor positions (APs) that\ncorrespond to the locations of the impulses on time-free, phase-free, base\nsolutions. In this paper, the existence and utility of three-impulse base\nsolutions are investigated and their complete solution spaces are characterized\nand analyzed. Since two- and three-impulse base solutions exist, a question\narises: How many APs should base solutions have? A strategy is developed for\nchoosing base solutions, which offers a certificate for $\\Delta v$ optimality\nof general three-dimensional time-fixed rendezvous solutions. Simultaneous\nallocation of $\\Delta v$ at two and three APs is formulated, which allows for\ngenerating $\\Delta v$-optimal solutions while satisfying a constraint on\nindividual impulses such that $\\Delta v \\leq \\Delta v_\\text{max}$. All\niso-impulse solutions are classified in four layers: 1) base solutions, 2)\nfeasible solution spaces, 3) solution families, and 4) solution envelopes. The\nmethod enables us to characterize the complete solution space of\nminimum-$\\Delta v$, iso-impulse, three-dimensional trajectories under the\nnonlinear two-body dynamics. To illustrate the utility of the method,\ninterplanetary and geocentric problems are considered."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-497",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18008",
    "b_title":[
      "Batalin-Vilkovisky formulation of the $\\mathcal N=1$ supergravity in ten\n  dimensions"
    ],
    "b_abstract":[
      "We present a full Batalin-Vilkovisky action in the component field formalism\nfor $\\mathcal N=1$ supergravity in ten dimensions coupled to Yang-Mills\nmultiplets."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04791",
    "c_title":[
      "Supersymmetric scale-separated AdS$_3$ vacua of type IIB"
    ],
    "c_abstract":[
      "I construct supersymmetric, parametrically scale-separated AdS$_3$ vacua of\ntype IIB string theory. These arise as compactifications with orientifold\nplanes on specific seven-dimensional solvmanifolds admitting co-closed\n$G_2$-structures, preserving minimal supersymmetry. There are solutions that\ninclude either one set or four sets of intersecting O5-planes in the smeared\napproximation, and parametric scale separation can be achieved by tuning\nunbounded fluxes to infinity. Additionally, the putative holographic field\ntheory operators that are dual to the lightest scalars in the gravitational\ntheory have integer conformal dimensions at tree level, aligning with other\nscale-separated models of type II string theory."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-498",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01668",
    "b_title":[
      "Light quark contributions to Higgs decays"
    ],
    "b_abstract":[
      "The literature establishes that the light fermions contributions to the\ndecays $H\\to Z\\gamma$ and $H\\to\\gamma\\gamma$ are negligible since their\ncoupling with the Higgs is proportional to $m_f$. In the present letter, we\nshow that although such a conclusion is true for leptons, the light quark\ncontributions are zero when we consider their non-perturbative effects."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.19488",
    "c_title":[
      "Extended IDM theory with low scale seesaw mechanisms"
    ],
    "c_abstract":[
      "We have developed an extension of the inert doublet model in which the\nCP-phases in the weak sector are generated from one-loop level corrections\nmediated by dark fields, while the strong-CP phase arises at three-loop. In\nthis framework, the tiny masses of the active neutrinos are produced through a\nradiative inverse seesaw mechanism at a two-loop level, the masses of the first\nand second families of SM-charged fermions arise from a one-loop level\nradiative seesaw mechanism, and the third generation of SM charged fermion\nmasses are generated at tree level. We have demonstrated that the proposed\nmodel successfully accounts for SM fermion masses and mixings. The radiative\nnature of the seesaw mechanisms is attributed to preserved discrete symmetries,\nwhich are required for ensuring the stability of fermionic and scalar dark\nmatter candidates. The preserved discrete symmetries also allow for\nmulti-component dark matter, whose annihilation processes permits to\nsuccessfully reproduce the measured amount of dark matter relic abundance for\nan appropriate region of parameter space, which has shown to be compatible with\ncurrent dark matter direct detection limits. Besides that, we explore the\nmodel's ability to explain the $95$ GeV diphoton excess observed by the CMS\ncollaboration, showing that it readily accommodates this anomaly. We have shown\nthat charged lepton flavor violating decays acquire rates within the current\nexperimental sensitivity."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-499",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16842",
    "b_title":[
      "Exploring Causes and Mitigation of Hallucinations in Large Vision\n  Language Models"
    ],
    "b_abstract":[
      "Large Vision-Language Models (LVLMs) integrate image encoders with Large\nLanguage Models (LLMs) to process multi-modal inputs and perform complex visual\ntasks. However, they often generate hallucinations by describing non-existent\nobjects or attributes, compromising their reliability. This study analyzes\nhallucination patterns in image captioning, showing that not all tokens in the\ngeneration process are influenced by image input and that image dependency can\nserve as a useful signal for hallucination detection. To address this, we\ndevelop an automated pipeline to identify hallucinated objects and train a\ntoken-level classifier using hidden representations from parallel inference\npasses-with and without image input. Leveraging this classifier, we introduce a\ndecoding strategy that effectively controls hallucination rates in image\ncaptioning at inference time."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11287",
    "c_title":[
      "MC-BEVRO: Multi-Camera Bird Eye View Road Occupancy Detection for\n  Traffic Monitoring"
    ],
    "c_abstract":[
      "Single camera 3D perception for traffic monitoring faces significant\nchallenges due to occlusion and limited field of view. Moreover, fusing\ninformation from multiple cameras at the image feature level is difficult\nbecause of different view angles. Further, the necessity for practical\nimplementation and compatibility with existing traffic infrastructure compounds\nthese challenges. To address these issues, this paper introduces a novel\nBird's-Eye-View road occupancy detection framework that leverages multiple\nroadside cameras to overcome the aforementioned limitations. To facilitate the\nframework's development and evaluation, a synthetic dataset featuring diverse\nscenes and varying camera configurations is generated using the CARLA\nsimulator. A late fusion and three early fusion methods were implemented within\nthe proposed framework, with performance further enhanced by integrating\nbackgrounds. Extensive evaluations were conducted to analyze the impact of\nmulti-camera inputs and varying BEV occupancy map sizes on model performance.\nAdditionally, a real-world data collection pipeline was developed to assess the\nmodel's ability to generalize to real-world environments. The sim-to-real\ncapabilities of the model were evaluated using zero-shot and few-shot\nfine-tuning, demonstrating its potential for practical application. This\nresearch aims to advance perception systems in traffic monitoring, contributing\nto improved traffic management, operational efficiency, and road safety."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-500",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16186",
    "b_title":[
      "Learn to Optimize Resource Allocation under QoS Constraint of AR"
    ],
    "b_abstract":[
      "This paper studies the uplink and downlink power allocation for interactive\naugmented reality (AR) services, where live video captured by an AR device is\nuploaded to the network edge and then the augmented video is subsequently\ndownloaded. By modeling the AR transmission process as a tandem queuing system,\nwe derive an upper bound for the probabilistic quality of service (QoS)\nrequirement concerning end-to-end latency and reliability. The resource\nallocation with the QoS constraints results in a functional optimization\nproblem. To address it, we design a deep neural network to learn the power\nallocation policy, leveraging the structure of optimal power allocation to\nenhance learning performance. Simulation results demonstrate that the proposed\nmethod effectively reduces transmit powers while meeting the QoS requirement."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03132",
    "c_title":[
      "Communication Bounds for the Distributed Experts Problem"
    ],
    "c_abstract":[
      "In this work, we study the experts problem in the distributed setting where\nan expert's cost needs to be aggregated across multiple servers. Our study\nconsiders various communication models such as the message-passing model and\nthe broadcast model, along with multiple aggregation functions, such as summing\nand taking the $\\ell_p$ norm of an expert's cost across servers. We propose the\nfirst communication-efficient protocols that achieve near-optimal regret in\nthese settings, even against a strong adversary who can choose the inputs\nadaptively. Additionally, we give a conditional lower bound showing that the\ncommunication of our protocols is nearly optimal. Finally, we implement our\nprotocols and demonstrate empirical savings on the HPO-B benchmarks."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-501",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16622",
    "b_title":[
      "Leveraging Large Language Models for Explainable Activity Recognition in\n  Smart Homes: A Critical Evaluation"
    ],
    "b_abstract":[
      "Explainable Artificial Intelligence (XAI) aims to uncover the inner reasoning\nof machine learning models. In IoT systems, XAI improves the transparency of\nmodels processing sensor data from multiple heterogeneous devices, ensuring\nend-users understand and trust their outputs. Among the many applications, XAI\nhas also been applied to sensor-based Activities of Daily Living (ADLs)\nrecognition in smart homes. Existing approaches highlight which sensor events\nare most important for each predicted activity, using simple rules to convert\nthese events into natural language explanations for non-expert users. However,\nthese methods produce rigid explanations lacking natural language flexibility\nand are not scalable. With the recent rise of Large Language Models (LLMs), it\nis worth exploring whether they can enhance explanation generation, considering\ntheir proven knowledge of human activities. This paper investigates potential\napproaches to combine XAI and LLMs for sensor-based ADL recognition. We\nevaluate if LLMs can be used: a) as explainable zero-shot ADL recognition\nmodels, avoiding costly labeled data collection, and b) to automate the\ngeneration of explanations for existing data-driven XAI approaches when\ntraining data is available and the goal is higher recognition rates. Our\ncritical evaluation provides insights into the benefits and challenges of using\nLLMs for explainable ADL recognition."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09572",
    "c_title":[
      "Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks"
    ],
    "c_abstract":[
      "Large language models (LLMs) have shown remarkable advancements in enabling\nlanguage agents to tackle simple tasks. However, applying them for complex,\nmulti-step, long-horizon tasks remains a challenge. Recent work have found\nsuccess by separating high-level planning from low-level execution, which\nenables the model to effectively balance high-level planning objectives and\nlow-level execution details. However, generating accurate plans remains\ndifficult since LLMs are not inherently trained for this task. To address this,\nwe propose Plan-and-Act, a novel framework that incorporates explicit planning\ninto LLM-based agents and introduces a scalable method to enhance plan\ngeneration through a novel synthetic data generation method. Plan-and-Act\nconsists of a Planner model which generates structured, high-level plans to\nachieve user goals, and an Executor model that translates these plans into\nenvironment-specific actions. To train the Planner effectively, we introduce a\nsynthetic data generation method that annotates ground-truth trajectories with\nfeasible plans, augmented with diverse and extensive examples to enhance\ngeneralization. We evaluate Plan-and-Act using web navigation as a\nrepresentative long-horizon planning environment, demonstrating a state-of\nthe-art 54% success rate on the WebArena-Lite benchmark."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-502",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11965",
    "b_title":[
      "Revisiting Gradient Descent: A Dual-Weight Method for Improved Learning"
    ],
    "b_abstract":[
      "We introduce a novel framework for learning in neural networks by decomposing\neach neuron's weight vector into two distinct parts, $W_1$ and $W_2$, thereby\nmodeling contrastive information directly at the neuron level. Traditional\ngradient descent stores both positive (target) and negative (non-target)\nfeature information in a single weight vector, often obscuring fine-grained\ndistinctions. Our approach, by contrast, maintains separate updates for target\nand non-target features, ultimately forming a single effective weight $W = W_1\n- W_2$ that is more robust to noise and class imbalance. Experimental results\non both regression (California Housing, Wine Quality) and classification\n(MNIST, Fashion-MNIST, CIFAR-10) tasks suggest that this decomposition enhances\ngeneralization and resists overfitting, especially when training data are\nsparse or noisy. Crucially, the inference complexity remains the same as in the\nstandard $WX + \\text{bias}$ setup, offering a practical solution for improved\nlearning without additional inference-time overhead."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.13790",
    "c_title":[
      "Local Steps Speed Up Local GD for Heterogeneous Distributed Logistic\n  Regression"
    ],
    "c_abstract":[
      "We analyze two variants of Local Gradient Descent applied to distributed\nlogistic regression with heterogeneous, separable data and show convergence at\nthe rate $O(1\/KR)$ for $K$ local steps and sufficiently large $R$ communication\nrounds. In contrast, all existing convergence guarantees for Local GD applied\nto any problem are at least $\\Omega(1\/R)$, meaning they fail to show the\nbenefit of local updates. The key to our improved guarantee is showing progress\non the logistic regression objective when using a large stepsize $\\eta \\gg\n1\/K$, whereas prior analysis depends on $\\eta \\leq 1\/K$."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-503",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13763",
    "b_title":[
      "Unsupervised Graph Embeddings for Session-based Recommendation with Item\n  Features"
    ],
    "b_abstract":[
      "In session-based recommender systems, predictions are based on the user's\npreceding behavior in the session. State-of-the-art sequential recommendation\nalgorithms either use graph neural networks to model sessions in a graph or\nleverage the similarity of sessions by exploiting item features. In this paper,\nwe combine these two approaches and propose a novel method, Graph Convolutional\nNetwork Extension (GCNext), which incorporates item features directly into the\ngraph representation via graph convolutional networks. GCNext creates a\nfeature-rich item co-occurrence graph and learns the corresponding item\nembeddings in an unsupervised manner. We show on three datasets that\nintegrating GCNext into sequential recommendation algorithms significantly\nboosts the performance of nearest-neighbor methods as well as neural network\nmodels. Our flexible extension is easy to incorporate in state-of-the-art\nmethods and increases the MRR@20 by up to 12.79%."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00131",
    "c_title":[
      "Middleman Bias in Advertising: Aligning Relevance of Keyphrase\n  Recommendations with Search"
    ],
    "c_abstract":[
      "E-commerce sellers are recommended keyphrases based on their inventory on\nwhich they advertise to increase buyer engagement (clicks\/sales). Keyphrases\nmust be pertinent to items; otherwise, it can result in seller dissatisfaction\nand poor targeting -- towards that end relevance filters are employed. In this\nwork, we describe the shortcomings of training relevance filter models on\nbiased click\/sales signals. We re-conceptualize advertiser keyphrase relevance\nas interaction between two dynamical systems -- Advertising which produces the\nkeyphrases and Search which acts as a middleman to reach buyers. We discuss the\nbias of search relevance systems (middleman bias) and the need to align\nadvertiser keyphrases with search relevance signals. We also compare the\nperformance of cross encoders and bi-encoders in modeling this alignment and\nthe scalability of such a solution for sellers at eBay."
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-504",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03462",
    "b_title":[
      "Efficient Lindblad synthesis for noise model construction"
    ],
    "b_abstract":[
      "Effective noise models are essential for analyzing and understanding the\ndynamics of quantum systems, particularly in applications like quantum error\nmitigation and correction. However, even when noise processes are\nwell-characterized in isolation, the effective noise channels impacting target\nquantum operations can differ significantly, as different gates experience\nnoise in distinct ways. Here, we present a noise model construction method that\nbuilds an effective model from a Lindbladian description of the physical noise\nprocesses acting simultaneously to the desired gate operation. It employs the\nMagnus expansion and Dyson series, and can be utilized for both low-order\nsymbolic and high-order numerical approximations of the noise channel of a\nmulti-qubit quantum gate. We envision multiple use cases of our noise\nconstruction method such as (i) computing the corresponding noise channel from\na learned Lindbladian, and (ii) generating the noise channel starting with\nphysically motivated Lindbladians for a given hardware architecture. In doing\nso, we close the gap between physical Lindbladians and operational level noise\nmodel parameters. We demonstrate a strong agreement between our symbolic noise\nconstruction and full numerical Lindblad simulations for various two-qubit\ngates, in isolation and in three- and four-qubit scenarios, for a variety of\nphysically motivated noise sources. Our symbolic construction provides a useful\nbreakdown of how noise model parameters depend on the underlying physical noise\nparameters, which gives qualitative insight into the structure of errors. For\ninstance, our theory provides insight into the interplay of Lindblad noise with\nthe intended gate operations, and can predict how local Lindblad noise can\neffectively spread into multi-qubit error."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.05475",
    "c_title":[
      "Desorption-induced decoherence of nanoparticle motion"
    ],
    "c_abstract":[
      "We derive the quantum master equation predicting how the translational and\nrotational dynamics of a nanoparticle is affected by the emission of surface\nadsorbates. This is motivated by recent experiments which prepared the motion\nof internally hot silica particles in the deep quantum regime. In the limit of\na well localized nanoparticle the ro-translational dynamics can be\ncharacterized by diffusion rates in quantitative agreement with classical\nexpectations. The theory is also suited to describe the decoherence effect of\noutgassing and sublimation."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-505",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07748",
    "b_title":[
      "Reliable Vertical Ground Reaction Force Estimation with Smart Insole\n  During Walking"
    ],
    "b_abstract":[
      "The vertical ground reaction force (vGRF) and its characteristic weight\nacceptance and push-off peaks measured during walking are important for gait\nand biomechanical analysis. Current wearable vGRF estimation methods suffer\nfrom drifting errors or low generalization performances, limiting their\npractical application. This paper proposes a novel method for reliably\nestimating vGRF and its characteristic peaks using data collected from the\nsmart insole, including inertial measurement unit data and the newly introduced\ncenter of the pressed sensor data. These data were fused with machine learning\nalgorithms including artificial neural networks, random forest regression, and\nbi-directional long-short-term memory. The proposed method outperformed the\nstate-of-the-art methods with the root mean squared error, normalized root mean\nsquared error, and correlation coefficient of 0.024 body weight (BW), 1.79% BW,\nand 0.997 in intra-participant testing, and 0.044 BW, 3.22% BW, and 0.991 in\ninter-participant testing, respectively. The difference between the reference\nand estimated weight acceptance and push-off peak values are 0.022 BW and 0.017\nBW with a delay of 1.4% and 1.8% of the gait cycle for the intra-participant\ntesting and 0.044 BW and 0.025 BW with a delay of 1.5% and 2.3% of the gait\ncycle for the inter-participant testing. The results indicate that the proposed\nvGRF estimation method has the potential to achieve accurate vGRF measurement\nduring walking in free living environments."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03732",
    "c_title":[
      "More Modality, More AI: Exploring Design Opportunities of AI-Based\n  Multi-modal Remote Monitoring Technologies for Early Detection of Mental\n  Health Sequelae in Youth Concussion Patients"
    ],
    "c_abstract":[
      "Anxiety, depression, and suicidality are common mental health sequelae\nfollowing concussion in youth patients, often exacerbating concussion symptoms\nand prolonging recovery. Despite the critical need for early detection of these\nmental health symptoms, clinicians often face challenges in accurately\ncollecting patients' mental health data and making clinical decision-making in\na timely manner. Today's remote patient monitoring (RPM) technologies offer\nopportunities to objectively monitor patients' activities, but they were not\nspecifically designed for youth concussion patients; moreover, the large amount\nof data collected by RPM technologies may also impose significant workloads on\nclinicians to keep up with and use the data. To address these gaps, we employed\na three-stage study consisting of a formative study, interface design, and\ndesign evaluation. We first conducted a formative study through semi-structured\ninterviews with six highly professional concussion clinicians and identified\nclinicians' key challenges in remotely collecting patient information and\naccessing patient treatment compliance. Subsequently, we proposed preliminary\nclinician-facing interface designs with the integration of AI-based RPM\ntechnologies (AI-RPM), followed by design evaluation sessions with highly\nprofessional concussion clinicians. Clinicians underscored the value of\nintegrating multi-modal AI-RPM technologies to support clinicians'\ndecision-making while emphasizing the importance of customizable interfaces\nwith explainability and multiple responsible design considerations."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-506",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13591",
    "b_title":[
      "A Rotational Disruption Crisis for Zodiacal Dust"
    ],
    "b_abstract":[
      "A systematic torque from anisotropic radiation can rapidly spin up irregular\ngrains to the point of breakup. We apply the standard theory of rotational\ndisruption from radiative torques to solar system grains, finding that grains\nwith radii $\\sim$0.03 --3 $\\mu$m at 1 a.u. from the Sun are spun to the point\nof breakup on timescales $\\lesssim1$ yr even when assuming them to have an\nunrealistically high tensile strength of pure meteoritic iron. Such a rapid\ndisruption timescale is incompatible with both the abundance of micron-sized\ngrains detected in the inner solar system and with the low production rate of\n$\\beta$ meteoroids. We suggest the possibility that zodiacal grains have a\nstrong propensity to attain rotational equilibrium at low angular velocity (a\nso-called low-$J$ attractor) and that the efficacy of rotational disruption in\nthe Solar System -- and likely elsewhere -- has been greatly overestimated."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.02084",
    "c_title":[
      "Convective Overstability in Radially Global Protoplanetary Disks. II.\n  Impact on planetesimal formation"
    ],
    "c_abstract":[
      "The Convective Overstability (COS) is a hydrodynamic instability occurring in\nprotoplanetary disk (PPD) regions with an adverse radial entropy gradient. It\nis a potential driver of turbulence and may influence planetesimal formation.\nIn this second paper of our series, we study the effects of the COS on dust\ndynamics in radially global PPD simulations, focusing on the mid-plane region,\nwhere vertical gravity on the dust is included.\n  Axisymmetric 2D simulations show susceptibility to both the COS and the\nVertically Shearing Streaming Instability. For a Stokes number tau = 0.1,\nstrong dust clumping occurs only for highly super-solar initial metallicities Z\ngreater than 0.05.\n  In 3D non-axisymmetric simulations, the COS generates large-scale, long-lived\nvortices that have the potential to efficiently concentrate dust, with dust\naccumulation strengthening as tau increases. For tau = 0.01, no strong clumping\noccurs even at metallicities as high as Z = 0.1, and vortices remain robust and\nlong-lived. At tau = 0.04, strong dust clumping is observed for solar\nmetallicity (Z = 0.01) and higher. For tau = 0.1, clumping occurs even at\nstrongly sub-solar metallicities (Z greater or equal to 0.004), peaking at Z\napproximately 0.01 to 0.03, including solar values. Under these conditions,\nvortices weaken significantly and become more spatially extended. At higher\nmetallicities (Z greater or equal to 0.04) with tau = 0.1, large-scale vortex\nformation is suppressed, leading to nearly axisymmetric dust rings, which can\nstill undergo clumping via the classical Streaming Instability."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-507",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12895",
    "b_title":[
      "Multilingual European Language Models: Benchmarking Approaches and\n  Challenges"
    ],
    "b_abstract":[
      "The breakthrough of generative large language models (LLMs) that can solve\ndifferent tasks through chat interaction has led to a significant increase in\nthe use of general benchmarks to assess the quality or performance of these\nmodels beyond individual applications. There is also a need for better methods\nto evaluate and also to compare models due to the ever increasing number of new\nmodels published. However, most of the established benchmarks revolve around\nthe English language. This paper analyses the benefits and limitations of\ncurrent evaluation datasets, focusing on multilingual European benchmarks. We\nanalyse seven multilingual benchmarks and identify four major challenges.\nFurthermore, we discuss potential solutions to enhance translation quality and\nmitigate cultural biases, including human-in-the-loop verification and\niterative translation ranking. Our analysis highlights the need for culturally\naware and rigorously validated benchmarks to assess the reasoning and\nquestion-answering capabilities of multilingual LLMs accurately."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05816",
    "c_title":[
      "IndoNLP 2025: Shared Task on Real-Time Reverse Transliteration for\n  Romanized Indo-Aryan languages"
    ],
    "c_abstract":[
      "The paper overviews the shared task on Real-Time Reverse Transliteration for\nRomanized Indo-Aryan languages. It focuses on the reverse transliteration of\nlow-resourced languages in the Indo-Aryan family to their native scripts.\nTyping Romanized Indo-Aryan languages using ad-hoc transliterals and achieving\naccurate native scripts are complex and often inaccurate processes with the\ncurrent keyboard systems. This task aims to introduce and evaluate a real-time\nreverse transliterator that converts Romanized Indo-Aryan languages to their\nnative scripts, improving the typing experience for users. Out of 11 registered\nteams, four teams participated in the final evaluation phase with\ntransliteration models for Sinhala, Hindi and Malayalam. These proposed\nsolutions not only solve the issue of ad-hoc transliteration but also empower\nlow-resource language usability in the digital arena."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-508",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04212",
    "b_title":[
      "Analysis of a nonlinear free boundary problem modeling the radial growth\n  of two-layer tumors"
    ],
    "b_abstract":[
      "In this paper we study a nonlinear free boundary problem on the radial growth\nof a two-layer solid tumor with a quiescent core. The tumor surface and its\ninner interface separating the proliferating cells and the quiescent cells are\nboth free boundaries. By deeply analyzing their relationship and employing the\nmaximum principle, we show this problem is globally well-posed and prove the\nexistence of a unique positive threshold $\\sigma^*$ such that the problem\nadmits a unique stationary solution with a quiescent core if and only if the\nexternally supplied nutrient $\\bar\\sigma> \\sigma^*$. The stationary solution is\nglobally asymptotically stable. The formation of the quiescent core and its\ninteresting connection with the necrotic core are also given."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.00571",
    "c_title":[
      "The transition problem between time-independent motions of a body in a\n  viscous liquid"
    ],
    "c_abstract":[
      "A body $\\mathscr B$ moves in an unbounded Navier-Stokes liquid by\ntime-independent translatory motion. Suppose that at time $t=0$, $\\mathscr B$\nsmoothly changes its motion to an arbitrary rigid motion, reached at time\n$t=1$. We then show that the associated Navier-Stokes problem has a unique\nsolution connecting the two steady-states generated by the motion of $\\mathscr\nB$, provided all the involved velocities of $\\mathscr B$ are sufficiently\nsmall."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-509",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02968",
    "b_title":[
      "The Labeled Coupon Collector Problem with Random Sample Sizes and\n  Partial Recovery"
    ],
    "b_abstract":[
      "We extend the Coupon Collector's Problem (CCP) and present a novel\ngeneralized model, referred as the k-LCCP problem, where one is interested in\nrecovering a bipartite graph with a perfect matching, which represents the\ncoupons and their matching labels. We show two extra-extensions to this\nvariation: the heterogeneous sample size case (K-LCCP) and the partly\nrecovering case."
    ],
    "b_categories":[
      [
        "cs.DM"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15675",
    "c_title":[
      "Exploring subgraph complementation to bounded degree graphs"
    ],
    "c_abstract":[
      "Graph modification problems are computational tasks where the goal is to\nchange an input graph $G$ using operations from a fixed set, in order to make\nthe resulting graph satisfy a target property, which usually entails membership\nto a desired graph class $\\mathcal{C}$. Some well-known examples of operations\ninclude vertex-deletion, edge-deletion, edge-addition and edge-contraction. In\nthis paper we address an operation known as subgraph complement. Given a graph\n$G$ and a subset $S$ of its vertices, the subgraph complement $G \\oplus S$ is\nthe graph resulting of complementing the edge set of the subgraph induced by\n$S$ in $G$. We say that a graph $H$ is a subgraph complement of $G$ if there is\nan $S$ such that $H$ is isomorphic to $G \\oplus S$. For a graph class\n$\\mathcal{C}$, subgraph complementation to $\\mathcal{C}$ is the problem of\ndeciding, for a given graph $G$, whether $G$ has a subgraph complement in\n$\\mathcal{C}$. This problem has been studied and its complexity has been\nsettled for many classes $\\mathcal{C}$ such as $\\mathcal{H}$-free graphs, for\nvarious families $\\mathcal{H}$, and for classes of bounded degeneracy. In this\nwork, we focus on classes graphs of minimum\/maximum degree upper\/lower bounded\nby some value $k$. In particular, we answer an open question of Antony et al.\n[Information Processing Letters 188, 106530 (2025)], by showing that subgraph\ncomplementation to $\\mathcal{C}$ is NP-complete when $\\mathcal{C}$ is the class\nof graphs of minimum degree at least $k$, if $k$ is part of the input. We also\nshow that subgraph complementation to $k$-regular parameterized by $k$ is\nfixed-parameter tractable."
    ],
    "c_categories":[
      [
        "cs.DM"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-510",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04014",
    "b_title":[
      "Dexterous Hand Manipulation via Efficient Imitation-Bootstrapped Online\n  Reinforcement Learning"
    ],
    "b_abstract":[
      "Dexterous hand manipulation in real-world scenarios presents considerable\nchallenges due to its demands for both dexterity and precision. While imitation\nlearning approaches have thoroughly examined these challenges, they still\nrequire a significant number of expert demonstrations and are limited by a\nconstrained performance upper bound. In this paper, we propose a novel and\nefficient Imitation-Bootstrapped Online Reinforcement Learning (IBORL) method\ntailored for robotic dexterous hand manipulation in real-world environments.\nSpecifically, we pretrain the policy using a limited set of expert\ndemonstrations and subsequently finetune this policy through direct\nreinforcement learning in the real world. To address the catastrophic\nforgetting issues that arise from the distribution shift between expert\ndemonstrations and real-world environments, we design a regularization term\nthat balances the exploration of novel behaviors with the preservation of the\npretrained policy. Our experiments with real-world tasks demonstrate that our\nmethod significantly outperforms existing approaches, achieving an almost 100%\nsuccess rate and a 23% improvement in cycle time. Furthermore, by finetuning\nwith online reinforcement learning, our method surpasses expert demonstrations\nand uncovers superior policies. Our code and empirical results are available in\nhttps:\/\/hggforget.github.io\/iborl.github.io\/."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02700",
    "c_title":[
      "Multi-Strategy Enhanced COA for Path Planning in Autonomous Navigation"
    ],
    "c_abstract":[
      "Autonomous navigation is reshaping various domains in people's life by\nenabling efficient and safe movement in complex environments. Reliable\nnavigation requires algorithmic approaches that compute optimal or near-optimal\ntrajectories while satisfying task-specific constraints and ensuring obstacle\navoidance. However, existing methods struggle with slow convergence and\nsuboptimal solutions, particularly in complex environments, limiting their\nreal-world applicability. To address these limitations, this paper presents the\nMulti-Strategy Enhanced Crayfish Optimization Algorithm (MCOA), a novel\napproach integrating three key strategies: 1) Refractive Opposition Learning,\nenhancing population diversity and global exploration, 2) Stochastic\nCentroid-Guided Exploration, balancing global and local search to prevent\npremature convergence, and 3) Adaptive Competition-Based Selection, dynamically\nadjusting selection pressure for faster convergence and improved solution\nquality. Empirical evaluations underscore the remarkable planning speed and the\namazing solution quality of MCOA in both 3D Unmanned Aerial Vehicle (UAV) and\n2D mobile robot path planning. Against 11 baseline algorithms, MCOA achieved a\n69.2% reduction in computational time and a 16.7% improvement in minimizing\noverall path cost in 3D UAV scenarios. Furthermore, in 2D path planning, MCOA\noutperformed baseline approaches by 44% on average, with an impressive 75.6%\nadvantage in the largest 60*60 grid setting. These findings validate MCOA as a\npowerful tool for optimizing autonomous navigation in complex environments. The\nsource code is available at: https:\/\/github.com\/coedv-hub\/MCOA."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-511",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00986",
    "b_title":[
      "Background-field method and QCD factorization"
    ],
    "b_abstract":[
      "One method for deriving a factorization for QCD processes is to use\nsuccessive integration over fields in the functional integral. In this\napproach, we separate the fields into two categories: dynamical fields with\nmomenta above a relevant cutoff, and background fields with momenta below the\ncutoff. The dynamical fields are then integrated out in the background of the\nlow-momentum background fields. This strategy works well at tree level,\nallowing us to quickly derive QCD factorization formulas at leading order.\nHowever, to extend the approach to higher loops, it is necessary to rigorously\ndefine the functional integral over dynamical fields in an arbitrary background\nfield. This framework was carefully developed for the calculation of the\neffective action in a background field at the two-loop level in the classic\npaper by Abbott [1]. Building on this work, I specify the renormalized\nbackground-field Lagrangian and define the notion of the quantum average of an\noperator in a background field, consistent with the ``separation of scales''\nscheme mentioned earlier. As examples, I discuss the evolution of the twist-2\ngluon light-ray operator and the one-loop gluon propagator in a background\nfield near the light cone."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.11958",
    "c_title":[
      "Probing late-time annihilations of oscillating asymmetric dark matter\n  via rotation curves of galaxies"
    ],
    "c_abstract":[
      "In this paper, we explore the Oscillating Asymmetric Dark Matter (OADM) model\nto address the core-cusp problem, aiming to resolve the discrepancy between the\npredictions of the $\\Lambda\\rm{CDM}$ cosmological model and the observed dark\nmatter profiles in dwarf spheroidal galaxies. The reactivation of dark matter\nannihilation during the structure formation epoch is possible if there is a\nsmall Majorana mass term that breaks the conservation of dark matter particle\nnumber, leading to oscillations between dark matter and its antiparticle. We\nanalyzed the effects of the annihilation mechanism in the galaxy rotation\ncurves of the SPARC and LITTLE THINGS catalogs. We searched for the\ncharacteristics of the OADM model which best describes the data. Our results\nshow that the OADM model can successfully turn originally cusp-type halos into\ncore-type ones according to our data sample."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-512",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06656",
    "b_title":[
      "A Frontier AI Risk Management Framework: Bridging the Gap Between\n  Current AI Practices and Established Risk Management"
    ],
    "b_abstract":[
      "The recent development of powerful AI systems has highlighted the need for\nrobust risk management frameworks in the AI industry. Although companies have\nbegun to implement safety frameworks, current approaches often lack the\nsystematic rigor found in other high-risk industries. This paper presents a\ncomprehensive risk management framework for the development of frontier AI that\nbridges this gap by integrating established risk management principles with\nemerging AI-specific practices. The framework consists of four key components:\n(1) risk identification (through literature review, open-ended red-teaming, and\nrisk modeling), (2) risk analysis and evaluation using quantitative metrics and\nclearly defined thresholds, (3) risk treatment through mitigation measures such\nas containment, deployment controls, and assurance processes, and (4) risk\ngovernance establishing clear organizational structures and accountability.\nDrawing from best practices in mature industries such as aviation or nuclear\npower, while accounting for AI's unique challenges, this framework provides AI\ndevelopers with actionable guidelines for implementing robust risk management.\nThe paper details how each component should be implemented throughout the\nlife-cycle of the AI system - from planning through deployment - and emphasizes\nthe importance and feasibility of conducting risk management work prior to the\nfinal training run to minimize the burden associated with it."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.08759",
    "c_title":[
      "Contextual bandits with entropy-based human feedback"
    ],
    "c_abstract":[
      "In recent years, preference-based human feedback mechanisms have become\nessential for enhancing model performance across diverse applications,\nincluding conversational AI systems such as ChatGPT. However, existing\napproaches often neglect critical aspects, such as model uncertainty and the\nvariability in feedback quality. To address these challenges, we introduce an\nentropy-based human feedback framework for contextual bandits, which\ndynamically balances exploration and exploitation by soliciting expert feedback\nonly when model entropy exceeds a predefined threshold. Our method is\nmodel-agnostic and can be seamlessly integrated with any contextual bandit\nagent employing stochastic policies. Through comprehensive experiments, we show\nthat our approach achieves significant performance improvements while requiring\nminimal human feedback, even under conditions of suboptimal feedback quality.\nThis work not only presents a novel strategy for feedback solicitation but also\nhighlights the robustness and efficacy of incorporating human guidance into\nmachine learning systems. Our code is publicly available:\nhttps:\/\/github.com\/BorealisAI\/CBHF"
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-513",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04294",
    "b_title":[
      "A shadowable chain recurrent set with an attached hyperbolic singularity"
    ],
    "b_abstract":[
      "We construct a $C^\\infty$-flow on the four-dimensional sphere whose\nnonwandering set contains an attached hyperbolic singularity yet possesses the\nstandard shadowing property. This gives a counterexample to a conjecture given\nby Arbieto, L\\'{o}pez, Rego and S\\'{a}nchez (Math. Annalen 390:417-437)."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.04612",
    "c_title":[
      "On the distribution of the angle between Oseledets spaces"
    ],
    "c_abstract":[
      "This note is concerned with the distribution of the angles between Oseledets\nsubspaces for linear cocycles driven by an ergodic transformation. We restrict\nourselves to dimension $2$, and give particular attention to the question of\nlog-integrability of those angles. In the setting of random i.i.d.\\ products of\nmatrices, we construct examples of probability measures on \\(\\GL_2(\\R)\\) with\nfinite first moment, for which the angle between Oseledets directions of the\nassociated cocycle is not log-integrable. Building on work for the totally\nirreducible case by Benoist and Quint, we show that for probability measures\nwith finite second moment the angle between Oseledets subspaces is always\nlog-integrable. Then we pivot to general measurable \\(\\GL_2(\\R)\\)-cocycles over\nan arbitrary ergodic automorphism of a non-atomic Lebesgue space. We show that\nno integrability condition on the distribution of the matrices is sufficient to\nguarantee log-integrability of the angle between Oseledets spaces. In fact, in\nthis context we show that the joint distribution of the Oseledets spaces may be\nchosen arbitrarily. We also obtain a similar flexibility result for bounded\ncocycles under the proper condition on the distribution of angles."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-514",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05162",
    "b_title":[
      "A Key Conditional Quotient Filter for Nonlinear, non-Gaussian and\n  non-Markovian System"
    ],
    "b_abstract":[
      "This paper proposes a novel and efficient key conditional quotient filter\n(KCQF) for the estimation of state in the nonlinear system which can be either\nGaussian or non-Gaussian, and either Markovian or non-Markovian. The core idea\nof the proposed KCQF is that only the key measurement conditions, rather than\nall measurement conditions, should be used to estimate the state. Based on key\nmeasurement conditions, the quotient-form analytical integral expressions for\nthe conditional probability density function, mean, and variance of state are\nderived by using the principle of probability conservation, and are calculated\nby using the Monte Carlo method, which thereby constructs the KCQF. Two\nnonlinear numerical examples were given to demonstrate the superior estimation\naccuracy of KCQF, compared to seven existing filters."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.17616",
    "c_title":[
      "Generalized Scattering Matrix Synthesis for Hybrid Systems with Multiple\n  Scatterers and Antennas Using Independent Structure Simulations"
    ],
    "c_abstract":[
      "This paper presents a unified formulation for calculating the generalized\nscattering matrix (GS-matrix) of hybrid systems involving multiple scatterers\nand antennas. The GS-matrix of the entire system is synthesized through the\nscattering matrices and GS-matrices of each independent component, using the\naddition theorem of vector spherical wavefunctions and fully matrix-based\noperations. Since our formulation is applicable to general antenna-scatterer\nhybrid systems, previous formulas for multiple scattering and antenna arrays\nbecome special cases of our approach. This also establishes our formulation as\na universal domain decomposition method for analyzing the electromagnetic\nperformance of hybrid systems. We provide numerous numerical examples to\ncomprehensively demonstrate the capabilities and compatibility of the proposed\nformulation, including its potential application in studying the effects of\nstructural rotation."
    ],
    "c_categories":[
      [
        "cs.CE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-515",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08063",
    "b_title":[
      "Logics and Algorithms for Hyperproperties"
    ],
    "b_abstract":[
      "System requirements related to concepts like information flow, knowledge, and\nrobustness cannot be judged in terms of individual system executions, but\nrather require an analysis of the relationship between multiple executions.\nSuch requirements belong to the class of hyperproperties, which generalize\nclassic trace properties to properties of sets of traces. During the past\ndecade, a range of new specification logics has been introduced with the goal\nof providing a unified theory for reasoning about hyperproperties. This paper\ngives an overview on the current landscape of logics for the specification of\nhyperproperties and on algorithms for satisfiability checking, model checking,\nmonitoring, and synthesis."
    ],
    "b_categories":[
      [
        "cs.LO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05826",
    "c_title":[
      "The Fertile Steppe: Computability Logic and the decidability of one of\n  its fragments"
    ],
    "c_abstract":[
      "The present work is devoted to Computability Logic (CoL), the young and\nvolcanic research-project developed by Giorgi Japaridze. Our main goal is to\nprovide the reader with a clear panoramic view of this vast new land, starting\nfrom its core knots and making our way towards the outer threads, in a somewhat\nthree-dimensional, spacial gait. Furthermore, through the present work, we\nprovide a tentative proof for the decidability of one of CoL's numerous\naxiomatisations, namely CL15. Thus, our expedition initially takes off for an\naerial, perusal overview of this fertile steppe. The first chapter introduces\nCoL in a philosophical fashion, exposing and arguing its main key points. We\nthen move over to unfold its semantics and syntax profiles, allowing the reader\nto become increasingly more familiar with this new environment. Landing on to\nthe second chapter, we thoroughly introduce Cirquent Calculus, the new\ndeductive system Japaridze has developed in order to axiomatise Computability\nLogic. Indeed, this new proof-system can also be a useful tool for many other\nlogics. We then review each of the 17 axiomatisations found so far. The third\nchapter zooms-in on CL15, in order to come up with a possible solution to its\nopen problem. We outline its soundness and completeness proofs; then provide\nsome few deductive examples; and, finally, build a tentative proof of its\ndecidability. Lastly, the fourth chapter focuses on the potential and actual\napplications of Computability Logic, both in arithmetic (clarithmetic) and in\nArtificial Intelligence systems (meaning knowledgebase and planning-and-action\nones). We close our journey with some final remarks on the richness of this\nframework and, hence, the research-worthiness it entails."
    ],
    "c_categories":[
      [
        "cs.LO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-516",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03345",
    "b_title":[
      "Formation of super-Earths and mini-Neptunes from rings of planetesimals"
    ],
    "b_abstract":[
      "The solar system planetary architecture has been proposed to be consistent\nwith the terrestrial and giant planets forming from material rings at ~1 au and\n~5 au, respectively. Here, we show that super-Earths and mini-Neptunes may\nshare a similar formation pathway. In our simulations conducted with a disk\nalpha-viscosity of 4e-3, super-Earths accrete from rings of rocky material in\nthe inner disk, growing predominantly via planetesimal accretion. Mini-Neptunes\nprimarily originate from rings located beyond the water snowline, forming via\npebble accretion. Our simulations broadly match the period-ratio distribution,\nthe intra-system size uniformity, and the planet multiplicity distribution of\nexoplanets. The radius valley constrains the typical total mass available for\nrocky planet formation to be less than 3-6 Earth masses. Our results predict\nthat planets at ~1 au in systems with close-in super-Earths and mini-Neptunes\nare predominantly water-rich. Though relatively uncommon, at ~1% level, such\nsystems might also host rocky Earth-sized planets in the habitable zone that\nunderwent late giant impacts, akin to the Moon-forming event."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05337",
    "c_title":[
      "Martian atmospheric disturbances from orbital images and surface\n  pressure at Jezero Crater, Mars, during Martian Year 36"
    ],
    "c_abstract":[
      "We present a study of atmospheric disturbances at Jezero Crater, Mars, using\nground-based measurements of surface pressure by the Perseverance rover in\ncombination with orbital images from the Mars Express and Mars Reconnaissance\nOrbiter missions. The study starts at Ls $\\sim$ 13.3{\\deg} in MY36 (March 6th,\n2021) and extends up to Ls $\\sim$ 30.3{\\deg} in MY37 (February 28th, 2023). We\nfocus on the characterization of the major atmospheric phenomena at synoptic\nand planetary-scales. These are the thermal tides (measured up to the sixth\ncomponent), long-period pressure oscillations (periods > 1 sol), the Aphelion\nCloud Belt, and the occasional development of regional dust storms over Jezero.\nWe present the seasonal evolution of the amplitudes and phases of the thermal\ntides and their relation with the atmospheric dust content (optical depth).\nThree regional dust storms and one polar storm extending over Jezero produced\nan increase in the diurnal and semidiurnal amplitudes but resulted in inverse\nresponses in their phases. We show that the primary regular wave activity is\ndue to baroclinic disturbances with periods of 2-4 sols and amplitudes $\\sim$\n1-15 Pa increasing with dust content, in good agreement with theoretical\npredictions by model calculations. The spacecraft images show a number of\narc-shaped, spiral and irregular cyclonic vortices, traced by dust and clouds\nat the edge of the North Polar Cap, that could be behind some of the pressure\noscillations measured at Jezero."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-517",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10774",
    "b_title":[
      "Model Monitoring in the Absence of Labeled Data via Feature Attributions\n  Distributions"
    ],
    "b_abstract":[
      "Model monitoring involves analyzing AI algorithms once they have been\ndeployed and detecting changes in their behaviour. This thesis explores machine\nlearning model monitoring ML before the predictions impact real-world decisions\nor users. This step is characterized by one particular condition: the absence\nof labelled data at test time, which makes it challenging, even often\nimpossible, to calculate performance metrics.\n  The thesis is structured around two main themes: (i) AI alignment, measuring\nif AI models behave in a manner consistent with human values and (ii)\nperformance monitoring, measuring if the models achieve specific accuracy goals\nor desires.\n  The thesis uses a common methodology that unifies all its sections. It\nexplores feature attribution distributions for both monitoring dimensions.\nUsing these feature attribution explanations, we can exploit their theoretical\nproperties to derive and establish certain guarantees and insights into model\nmonitoring."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16772",
    "c_title":[
      "Model-Based Exploration in Monitored Markov Decision Processes"
    ],
    "c_abstract":[
      "A tenet of reinforcement learning is that rewards are always observed by the\nagent. However, this is not true in many realistic settings, e.g., a human\nobserver may not always be able to provide rewards, a sensor to observe rewards\nmay be limited or broken, or rewards may be unavailable during deployment.\nMonitored Markov decision processes (Mon-MDPs) have recently been proposed as a\nmodel of such settings. Yet, Mon-MDP algorithms developed thus far do not fully\nexploit the problem structure, cannot take advantage of a known monitor, have\nno worst-case guarantees for ``unsolvable'' Mon-MDPs without specific\ninitialization, and only have asymptotic proofs of convergence. This paper\nmakes three contributions. First, we introduce a model-based algorithm for\nMon-MDPs that addresses all of these shortcomings. The algorithm uses two\ninstances of model-based interval estimation, one to guarantee that observable\nrewards are indeed observed, and another to learn the optimal policy. Second,\nempirical results demonstrate these advantages, showing faster convergence than\nprior algorithms in over two dozen benchmark settings, and even more dramatic\nimprovements when the monitor process is known. Third, we present the first\nfinite-sample bound on performance and show convergence to an optimal\nworst-case policy when some rewards are never observable."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-518",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12915",
    "b_title":[
      "Smoothing Accelerated Proximal Gradient Method with Backtracking for\n  Nonsmooth Multiobjective Optimization"
    ],
    "b_abstract":[
      "For the composite multi-objective optimization problem composed of two\nnonsmooth terms, a smoothing method is used to overcome the nonsmoothness of\nthe objective function, making the objective function contain at most one\nnonsmooth term. Then, inspired by the design idea of the aforementioned\nbacktracking strategy, an update rule is proposed by constructing a\nrelationship between an estimation sequence of the Lipschitz constant and a\nsmoothing factor, which results in a backtracking strategy suitable for this\nproblem, allowing the estimation sequence to be updated in a non-increasing\nmanner. On this basis, a smoothing accelerated proximal gradient algorithm\nbased on the backtracking strategy is further proposed. Under appropriate\nconditions, it is proven that all accumulation points of the sequence generated\nby this algorithm are weak Pareto optimal solutions. Additionally, the\nconvergence rate of the algorithm under different parameters is established\nusing a utility function. Numerical experiments show that, compared with the\nsubgradient algorithm, the proposed algorithm demonstrates significant\nadvantages in terms of runtime, iteration count, and function evaluations."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.08011",
    "c_title":[
      "Extension of Controllability Score to Infinite-Dimensional Systems"
    ],
    "c_abstract":[
      "Centrality analysis in dynamical network systems is essential for\nunderstanding system behavior. In finite-dimensional settings, controllability\nscores -- namely, the Volumetric Controllability Score (VCS) and the Average\nEnergy Controllability Score (AECS) -- are defined as the unique solutions of\nspecific optimization problems. In this work, we extend these concepts to\ninfinite-dimensional systems by formulating analogous optimization problems.\nMoreover, we prove that these optimization problems have optimal solutions\nunder weak assumptions, and that both VCS and AECS remain unique in the\ninfinite-dimensional context under appropriate assumptions. The uniqueness of\nthe controllability scores is essential to use them as a centrality measure,\nsince it not only reflects the importance of each state in the dynamical\nnetwork but also provides a consistent basis for interpretation and comparison\nacross different researchers. Finally, we illustrate the behavior of VCS and\nAECS with a numerical experiment based on the heat equation."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-519",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12539",
    "b_title":[
      "BFANet: Revisiting 3D Semantic Segmentation with Boundary Feature\n  Analysis"
    ],
    "b_abstract":[
      "3D semantic segmentation plays a fundamental and crucial role to understand\n3D scenes. While contemporary state-of-the-art techniques predominantly\nconcentrate on elevating the overall performance of 3D semantic segmentation\nbased on general metrics (e.g. mIoU, mAcc, and oAcc), they unfortunately leave\nthe exploration of challenging regions for segmentation mostly neglected. In\nthis paper, we revisit 3D semantic segmentation through a more granular lens,\nshedding light on subtle complexities that are typically overshadowed by\nbroader performance metrics. Concretely, we have delineated 3D semantic\nsegmentation errors into four comprehensive categories as well as corresponding\nevaluation metrics tailored to each. Building upon this categorical framework,\nwe introduce an innovative 3D semantic segmentation network called BFANet that\nincorporates detailed analysis of semantic boundary features. First, we design\nthe boundary-semantic module to decouple point cloud features into semantic and\nboundary features, and fuse their query queue to enhance semantic features with\nattention. Second, we introduce a more concise and accelerated boundary\npseudo-label calculation algorithm, which is 3.9 times faster than the\nstate-of-the-art, offering compatibility with data augmentation and enabling\nefficient computation in training. Extensive experiments on benchmark data\nindicate the superiority of our BFANet model, confirming the significance of\nemphasizing the four uniquely designed metrics. Code is available at\nhttps:\/\/github.com\/weiguangzhao\/BFANet."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.11481",
    "c_title":[
      "T2I-FineEval: Fine-Grained Compositional Metric for Text-to-Image\n  Evaluation"
    ],
    "c_abstract":[
      "Although recent text-to-image generative models have achieved impressive\nperformance, they still often struggle with capturing the compositional\ncomplexities of prompts including attribute binding, and spatial relationships\nbetween different entities. This misalignment is not revealed by common\nevaluation metrics such as CLIPScore. Recent works have proposed evaluation\nmetrics that utilize Visual Question Answering (VQA) by decomposing prompts\ninto questions about the generated image for more robust compositional\nevaluation. Although these methods align better with human evaluations, they\nstill fail to fully cover the compositionality within the image. To address\nthis, we propose a novel metric that breaks down images into components, and\ntexts into fine-grained questions about the generated image for evaluation. Our\nmethod outperforms previous state-of-the-art metrics, demonstrating its\neffectiveness in evaluating text-to-image generative models. Code is available\nat https:\/\/github.com\/hadi-hosseini\/ T2I-FineEval."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-520",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03489",
    "b_title":[
      "Probing the nonclassical dynamics of a quantum particle in a\n  gravitational field"
    ],
    "b_abstract":[
      "In quantum mechanics, the time evolution of particles is given by the\nSchr\\\"odinger equation. It is valid in a nonrelativistic regime where the\ninteractions with the particle can be modelled by a potential and quantised\nfields are not required. This has been verified in countless experiments when\nthe interaction is of electromagnetic origin, but also corrections due to the\nquantised field are readily observed. When the interaction is due to gravity,\nthen one cannot expect to see effects of the quantised field in\ncurrent-technology Earth-bound experiments. However, this does not yet\nguarantee that in the accessible regime, the time evolution is accurately given\nby the Schr\\\"odinger equation. Here we propose to measure the effects of an\nasymmetric mass configuration on a quantum particle in an interferometer. For\nthis setup we show that with parameters within experimental reach, one can be\nsensitive to possible deviations from the Schr\\\"odinger equation, beyond the\nalready verified lowest-order regime. Performing this experiment will hence\ndirectly test the nonclassical behaviour of a quantum particle in the\ngravitational field."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.19179",
    "c_title":[
      "Higher order coherence as witness of exceptional point in Hermitian\n  bosonic Kitaev dimer"
    ],
    "c_abstract":[
      "The non-analyticity induced by exceptional points (EPs) has manifestations\nnot only in non-Hermitian but also in Hermitian systems. In this work, we focus\non a minimal Hermitian bosonic Kitaev model to reveal the dynamical\ndemonstration of EPs in a Hermitian system. It is shown that the EPs separate\nthe parameter space into four regions, in which the systems are characterized\nby different equivalent Hamiltonians, including the harmonic oscillator, the\ninverted harmonic oscillator, and their respective counterparts. We employ the\nsecond-order intensity correlation to characterize a nonequilibrium quantum\nphase transition by calculating the time evolution of a trivial initial state.\nThe results indicate that the concept of the EP can be detected in a small\nHermitian bosonic system."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-521",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11995",
    "b_title":[
      "Fabrication of Poly ({\\epsilon}-Caprolactone) 3D scaffolds with\n  controllable porosity using ultrasound"
    ],
    "b_abstract":[
      "3D printing has progressed significantly, allowing objects to be produced\nusing a wide variety of materials. Recent advances have employed focused\nultrasound in 3D printing, to allow printing inside acoustically transparent\nmaterials. Here we introduce a Selective Ultrasonic Melting (SUM) method for 3D\nprinting of poly ({\\epsilon}-caprolactone) (PCL) powder mixed with water. The\nprinting was done by mechanically moving a focused ultrasound transducer. The\nmicrostructure and porosity of the prints were analyzed with micro-computed\ntomography ({\\mu}CT). The open porosity of the printed samples was determined\nusing the water intrusion method and by passing fluorescent microspheres\nthrough the structure. The cytocompatibility of the printed structures was\nconfirmed by seeding NIH-3T3 fibroblast cells on the scaffolds, followed by\nanalysis using live\/dead fluorescent assay. and visualization using scanning\nelectron microscopy (SEM). We demonstrated that SUM is a viable technique to\nprint structures with active control of their porosity This method provides an\nalternative to methods such as fused deposition modelling (FDM) and material\njetting."
    ],
    "b_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.16394",
    "c_title":[
      "Propagation Performance of Terahertz Channels in Lunar Dust"
    ],
    "c_abstract":[
      "The growing momentum in lunar exploration programs and urgent need for robust\ncommunication systems capable of operating in dust-laden lunar environments\nnecessitate comprehensive understanding of channel propagation characteristics\nin lunar conditions. In this article, we present a comprehensive analysis of\nterahertz (THz) channel propagation characteristics through lunar dust\nenvironments, critical for establishing reliable communication and sensing\ninfrastructure on the Moon. We develop an extended Mie scattering model\nincorporating the unique properties of lunar dust particles (Apollo 11 sample\n10084, Apollo 14 sample 14003, and Apollo 17 sample 70051), including their\nirregular morphology, dielectric characteristics, and charge-dependent\nbehavior. Through theoretical analysis and experimental verification, we\nexamine both power and bit error rate (BER) performance across varying dust\nconditions. Our results reveal distinct relationships between particle charge\nlevels, morphological characteristics, and channel performance with power loss\npatterns and BER evolution. Our findings provide essential guidelines for\ndeveloping robust lunar communication systems that integrate sensing\ncapabilities, contributing to the establishment of sustainable lunar\ninfrastructure."
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-522",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04585",
    "b_title":[
      "Advancing Solutions for the Three-Body Problem Through Physics-Informed\n  Neural Networks"
    ],
    "b_abstract":[
      "First formulated by Sir Isaac Newton in his work \"Philosophiae Naturalis\nPrincipia Mathematica\", the concept of the Three-Body Problem was put forth as\na study of the motion of the three celestial bodies within the Earth-Sun-Moon\nsystem. In a generalized definition, it seeks to predict the motion for an\nisolated system composed of three point masses freely interacting under\nNewton's law of universal attraction. This proves to be analogous to a\nmultitude of interactions between celestial bodies, and thus, the problem finds\napplicability within the studies of celestial mechanics. Despite numerous\nattempts by renowned physicists to solve it throughout the last three\ncenturies, no general closed-form solutions have been reached due to its\ninherently chaotic nature for most initial conditions. Current state-of-the-art\nsolutions are based on two approaches, either numerical high-precision\nintegration or machine learning-based. Notwithstanding the breakthroughs of\nneural networks, these present a significant limitation, which is their\nignorance of any prior knowledge of the chaotic systems presented. Thus, in\nthis work, we propose a novel method that utilizes Physics-Informed Neural\nNetworks (PINNs). These deep neural networks are able to incorporate any prior\nsystem knowledge expressible as an Ordinary Differential Equation (ODE) into\ntheir learning processes as a regularizing agent. Our findings showcase that\nPINNs surpass current state-of-the-art machine learning methods with comparable\nprediction quality. Despite a better prediction quality, the usability of\nnumerical integrators suffers due to their prohibitively high computational\ncost. These findings confirm that PINNs are both effective and time-efficient\nopen-form solvers of the Three-Body Problem that capitalize on the extensive\nknowledge we hold of classical mechanics."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07783",
    "c_title":[
      "Curvature Tuning: Provable Training-free Model Steering From a Single\n  Parameter"
    ],
    "c_abstract":[
      "The scaling of model size and data size has reshaped the paradigm of AI. As a\nresult, the common protocol to leverage the latest models is to steer them\ntowards a specific downstream task of interest through {\\em fine-tuning}.\nDespite its importance, the main methods for fine-tuning remain limited to full\nor low-rank adapters--containing countless hyper-parameters and lacking\ninterpretability. In this paper, we take a step back and demonstrate how novel\nand explainable post-training steering solutions can be derived theoretically\nfrom {\\em spline operators}, a rich mathematical framing of Deep Networks that\nwas recently developed. Our method--coined \\textbf{Curvature Tuning (CT)}--has\na single parameter that provably modulates the curvature of the model's\ndecision boundary henceforth allowing training-free steering. This makes CT\nboth more efficient and interpretable than conventional fine-tuning methods. We\nempirically validate its effectiveness in improving generalization and\nrobustness of pretrained models. For example, CT improves out-of-distribution\ntransfer performances of ResNet-18\/50 by 2.57\\%\/1.74\\% across seventeen\ndownstream datasets, and improves RobustBench robust accuracy by\n11.76\\%\/348.44\\%. Additionally, we apply CT to ReLU-based Swin-T\/S, improving\ntheir generalization on nine downstream datasets by 2.43\\%\/3.33\\%. Our code is\navailable at\n\\href{https:\/\/github.com\/Leon-Leyang\/curvature-tuning}{https:\/\/github.com\/Leon-Leyang\/curvature-tuning}."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-523",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19639",
    "b_title":[
      "Elemental Abundances at Coronal Hole Boundaries as a Means to\n  Investigate Interchange Reconnection and the Solar Wind"
    ],
    "b_abstract":[
      "The origin of the slow solar wind is not well understood, unlike the fast\nsolar wind which originates from coronal holes. In-situ elemental abundances of\nthe slow solar wind suggest that it originates from initially closed field\nlines that become open. Coronal hole boundary regions are a potential source of\nslow solar wind as there open field lines interact with the closed loops\nthrough interchange reconnection. Our primary aim is to quantify the role of\ninterchange reconnection at the boundaries of coronal holes. To this end, we\nhave measured the relative abundances of different elements at these\nboundaries. Reconnection is expected to modulate the relative abundances\nthrough the first ionization potential (FIP) effect. For our analysis we used\nspectroscopic data from the extreme ultraviolet imaging spectrometer (EIS) on\nboard Hinode. To account for the temperature structure of the observed region\nwe computed the differential emission measure (DEM). Using the DEM we were able\nto infer the ratio between coronal and photospheric abundances, known as the\nFIP bias. By examining the variation of the FIP bias moving from the coronal\nhole to the quiet Sun, we have been able to constrain models of interchange\nreconnection. The FIP bias variation in the boundary region around the coronal\nhole has an approximate width of 30-50 Mm, comparable to the size of\nsupergranules. This boundary region is also a source of open flux into\ninterplanetary space. We find that there is an additional ~30% open flux that\noriginates from this boundary region."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11878",
    "c_title":[
      "Investigating the Temperature Sensitivity of UV Line Ratios in the 280\n  nm Region of Solar-like Stars"
    ],
    "c_abstract":[
      "Stellar UV spectra are fundamental diagnostics of physical and magnetic\nproperties of stars. For instance, lines like Mg II at 280 nm serve as valuable\nindicators of stellar activity, providing insights into the activity levels of\nSun-like stars and their potential influence on the atmospheres of orbiting\nplanets. On the other hand, the effective temperature (Teff) is a fundamental\nstellar parameter, critical for determining stellar properties such as mass,\nage, composition and evolutionary status. In this study, we investigate the\ntemperature sensitivity of three lines in the mid-ultraviolet range (i.e., Mg\nII 280.00 nm, Mg I 285.20 nm, and Si I 286.15 nm). Using spectra from the\nInternational Ultraviolet Explorer (IUE), we analyze the behavior of the ratios\nof their corresponding indices (core\/continuum) for a sample of calibrating\nsolar-like stars, and find that the ration R = Mg II\/Mg I best traces Teff\nthrough a log-log relation. The Teff estimated using this relation on a\ntest-sample of solar-like stars agree with the Teff from the literature at the\n95% confidence level. The observed results are interpreted making use of\nResponse Functions as diagnostics. This study extends the well-established use\nof line depth ratio-temperature relationships, traditionally applied in the\nvisible and near-infrared ranges, to the mid-UV spectrum. With the growing\ninterest in stellar UV spectroscopy, results presented in this paper are\npotentially relevant for future missions as HWO, MANTIS and UVEX."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-524",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08164",
    "b_title":[
      "Dynamical Models of the Milky Way in Action Space with LAMOST DR8 and\n  GAIA EDR3"
    ],
    "b_abstract":[
      "This work explores dynamical models of the Milky Way (MW) by analyzing a\nsample of 86,109 K giant stars selected through cross-matching the LAMOST DR8\nand Gaia EDR3 surveys. Our earlier torus models in Wang et al. (2017) did not\ninclude Gaia data, making them incompatible with the new proper motion\ndistributions of samples. Here, we refine the construction of action-based,\nself-consistent models to constrain the three-dimensional velocity distribution\nof K giants over a larger parameter space, drawing on a series of existing MW\nmodels. This approach produces several new MW models. Our best-fit model for\nthe local kinematics near the Sun indicates a MW virial mass of 1.35 $\\times\n10^{12} M_\\odot$, a local stellar density of 0.0696 $\\rm M_\\odot pc^{-3}$, and\na local dark matter density of 0.0115 $\\rm M_\\odot pc^{-3}$. Our main\nconclusion supports a thicker and more extended thick disk, alongside a cooler\nthin disk, compared to the best-fitting model in Wang et al. (2017). Near the\nSun, our model aligns well with observations, but is less satisfactory at\ndistances far from the Galactic center, perhaps implying unidentified\nstructures. Further high-precision observations will be critical for\nunderstanding the dynamics in these outer Galactic regions, and will require a\nmore realistic model."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.10870",
    "c_title":[
      "Thermodynamics of self-gravitating fermions as a robust theory for dark\n  matter halos: Stability analysis applied to the Milky Way"
    ],
    "c_abstract":[
      "We present a framework for dark matter (DM) halo formation based on a kinetic\ntheory of self-gravitating fermions together with a solid connection to\nthermodynamics. Based on maximum entropy arguments, this approach predicts a\nmost likely phase-space distribution which takes into account the Pauli\nexclusion principle, relativistic effects, and particle evaporation. The most\ngeneral equilibrium configurations depend on the particle mass and develop a\ndegenerate compact core embedded in a diluted halo, both linked by their\nfermionic nature. By applying such a theory to the Milky Way we analyze the\nstability of different families of equilibrium solutions with implications on\nthe DM distribution and the mass of the DM candidate. We find that stable\ncore-halo profiles, which explain the DM distribution in the Galaxy, exist only\nin the range $mc^2 \\approx 194 - 387\\,\\rm{keV}$. The lower bound is a\nconsequence of imposing thermodynamical stability on the core-halo solutions\nhaving a $4.2\\times 10^6 M_\\odot$ quantum core mass alternative to the black\nhole hypothesis at the Galaxy center. The upper bound is solely an outcome of\ngeneral relativity when the quantum core reaches the Oppenheimer-Volkoff limit\nand undergoes gravitational collapse towards a black hole. We demonstrate that\nthere exists a set of stable core-halo profiles which are astrophysically\nrelevant in the sense that their total mass is finite, do not suffer from the\ngravothermal catastrophe, and agree with observations. The morphology of the\nouter halo tail is described by a polytrope of index $5\/2$, developing a sharp\ndecline of the density beyond $25\\,\\rm{kpc}$ in excellent agreement with the\nlatest Gaia DR3 rotation curve data. Moreover, we obtain a total mass of about\n$2\\times 10^{11} M_\\odot$ including baryons and a local DM density of about\n$0.4\\,\\rm{GeV}\\,c^{-2}\\,\\rm{cm}^{-3}$ in line with recent independent\nestimates."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-525",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12935",
    "b_title":[
      "Neuro-oscillatory models of cortical speech processing"
    ],
    "b_abstract":[
      "In this review, we examine computational models that explore the role of\nneural oscillations in speech perception, spanning from early auditory\nprocessing to higher cognitive stages. We focus on models that use rhythmic\nbrain activities, such as gamma, theta, and delta oscillations, to encode\nphonemes, segment speech into syllables and words, and integrate linguistic\nelements to infer meaning. We analyze the mechanisms underlying these models,\ntheir biological plausibility, and their potential applications in processing\nand understanding speech in real time, a computational feature that is achieved\nby the human brain but not yet implemented in speech recognition models.\nReal-time processing enables dynamic adaptation to incoming speech, allowing\nsystems to handle the rapid and continuous flow of auditory information\nrequired for effective communication, interactive applications, and accurate\nspeech recognition in a variety of real-world settings. While significant\nprogress has been made in modeling the neural basis of speech perception,\nchallenges remain, particularly in accounting for the complexity of semantic\nprocessing and the integration of contextual influences. Moreover, the high\ncomputational demands of biologically realistic models pose practical\ndifficulties for their implementation and analysis. Despite these limitations,\nthese models provide valuable insights into the neural mechanisms of speech\nperception. We conclude by identifying current limitations, proposing future\nresearch directions, and suggesting how these models can be further developed\nto achieve a more comprehensive understanding of speech processing in the human\nbrain."
    ],
    "b_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2502.16088",
    "c_title":[
      "Electrophysiological Investigation of Insect Pain Threshold"
    ],
    "c_abstract":[
      "The question of whether insects experience pain has long been debated in\nneuroscience and animal behavior research. Increasing evidence suggests that\ninsects possess the ability to detect and respond to noxious stimuli,\nexhibiting behaviors indicative of pain perception. This study investigates the\nrelationship between pain stimuli and physiological responses in crickets\n(Gryllidae), focusing on heart rate (ECG) and brain wave (EEG) patterns. We\napplied a range of mechanical, chemical, thermal, and electrical stimuli to\ncrickets, recording ECG and EEG data while employing a deep learning-based\nmodel to classify pain levels. Our findings revealed significant heart rate\nchanges and EEG fluctuations in response to various stimuli, with the highest\nintensity stimuli inducing marked physiological stress. The AI-based analysis,\nutilizing AlexNet for EEG signal classification, achieved 90% accuracy in\ndistinguishing between resting, low-pain, and high-pain states. While no social\nsharing of pain was observed through ECG measurements, these results contribute\nto the growing body of evidence supporting insect nociception and offer new\ninsights into their physiological responses to external stressors. This\nresearch advances the understanding of insect pain mechanisms and demonstrates\nthe potential for AI-driven analysis in entomological studies."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-526",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07880",
    "b_title":[
      "Structure and Dynamics of the Sun's Interior Revealed by Helioseismic\n  and Magnetic Imager"
    ],
    "b_abstract":[
      "High-resolution helioseismology observations with the Helioseismic and\nMagnetic Imager (HMI) onboard Solar Dynamics Observatory (SDO) provide a unique\nthree-dimensional view of the solar interior structure and dynamics, revealing\na tremendous complexity of the physical processes inside the Sun. We present an\noverview of the results of the HMI helioseismology program and discuss their\nimplications for modern theoretical models and simulations of the solar\ninterior."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.05663",
    "c_title":[
      "Small-scale variability in the spectrum of Vega"
    ],
    "c_abstract":[
      "We reported the results of observations of small-scale variability in the\nhydrogen Balmer lines in Vega. Spectral observations were carried out with\nlow-resolution spectrograph (R $\\simeq$ 600) installed in the Main Astronomical\nObservatory, Ukraine. Spectra were obtained with a time resolution in the\nsecond range. It has been found that Vega shows variations in the hydrogen\nlines $H_{\\beta} $, $H_{\\gamma} $, $H_{ \\delta} $. This can be interpreted that\ntheir variations are non-radial pulsations. The characteristic time of the\nobserved variations ranges from 300 to 1200 sec. The horizontal scale for\noscillating elements is about 800 Mm, which is comparable to the solar radius.\nThe radial velocity of the variations is about 36 km\/s."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-527",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07216",
    "b_title":[
      "Temperature Driven Multi-modal\/Single-actuated Soft Finger"
    ],
    "b_abstract":[
      "Soft pneumatic fingers are of great research interest. However, their\nsignificant potential is limited as most of them can generate only one motion,\nmostly bending. The conventional design of soft fingers does not allow them to\nswitch to another motion mode. In this paper, we developed a novel multi-modal\nand single-actuated soft finger where its motion mode is switched by changing\nthe finger's temperature. Our soft finger is capable of switching between three\ndistinctive motion modes: bending, twisting, and extension-in approximately\nfive seconds. We carried out a detailed experimental study of the soft finger\nand evaluated its repeatability and range of motion. It exhibited repeatability\nof around one millimeter and a fifty percent larger range of motion than a\nstandard bending actuator. We developed an analytical model for a\nfiber-reinforced soft actuator for twisting motion. This helped us relate the\ninput pressure to the output twist radius of the twisting motion. This model\nwas validated by experimental verification. Further, a soft robotic gripper\nwith multiple grasp modes was developed using three actuators. This gripper can\nadapt to and grasp objects of a large range of size, shape, and stiffness. We\nshowcased its grasping capabilities by successfully grasping a small berry, a\nlarge roll, and a delicate tofu cube."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15078",
    "c_title":[
      "Impact-resistant, autonomous robots inspired by tensegrity architecture"
    ],
    "c_abstract":[
      "Future robots will navigate perilous, remote environments with resilience and\nautonomy. Researchers have proposed building robots with compliant bodies to\nenhance robustness, but this approach often sacrifices the autonomous\ncapabilities expected of rigid robots. Inspired by tensegrity architecture, we\nintroduce a tensegrity robot -- a hybrid robot made from rigid struts and\nelastic tendons -- that demonstrates the advantages of compliance and the\nautonomy necessary for task performance. This robot boasts impact resistance\nand autonomy in a field environment and additional advances in the state of the\nart, including surviving harsh impacts from drops (at least 5.7 m), accurately\nreconstructing its shape and orientation using on-board sensors, achieving high\nlocomotion speeds (18 bar lengths per minute), and climbing the steepest\nincline of any tensegrity robot (28 degrees). We characterize the robot's\nlocomotion on unstructured terrain, showcase its autonomous capabilities in\nnavigation tasks, and demonstrate its robustness by rolling it off a cliff."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-528",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05108",
    "b_title":[
      "Towards Emotionally Intelligent Software Engineers: Understanding\n  Students' Self-Perceptions After a Cooperative Learning Experience"
    ],
    "b_abstract":[
      "[Background] Emotional Intelligence (EI) can impact Software Engineering (SE)\noutcomes through improved team communication, conflict resolution, and stress\nmanagement. SE workers face increasing pressure to develop both technical and\ninterpersonal skills, as modern software development emphasizes collaborative\nwork and complex team interactions. Despite EI's documented importance in\nprofessional practice, SE education continues to prioritize technical knowledge\nover emotional and social competencies. [Objective] This paper analyzes SE\nstudents' self-perceptions of their EI after a two-month cooperative learning\nproject, using Mayer and Salovey's four-ability model to examine how students\nhandle emotions in collaborative development. [Method] We conducted a case\nstudy with 29 SE students organized into four squads within a project-based\nlearning course, collecting data through questionnaires and focus groups that\nincluded brainwriting and sharing circles, then analyzing the data using\ndescriptive statistics and open coding. [Results] Students demonstrated\nstronger abilities in managing their own emotions compared to interpreting\nothers' emotional states. Despite limited formal EI training, they developed\ninformal strategies for emotional management, including structured planning and\npeer support networks, which they connected to improved productivity and\nconflict resolution. [Conclusion] This study shows how SE students perceive EI\nin a collaborative learning context and provides evidence-based insights into\nthe important role of emotional competencies in SE education."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02875",
    "c_title":[
      "METFORD -- Mutation tEsTing Framework fOR anDroid"
    ],
    "c_abstract":[
      "Mutation testing may be used to guide test case generation and as a technique\nto assess the quality of test suites. Despite being used frequently, mutation\ntesting is not so commonly applied in the mobile world. One critical challenge\nin mutation testing is dealing with its computational cost. Generating mutants,\nrunning test cases over each mutant, and analyzing the results may require\nsignificant time and resources. This research aims to contribute to reducing\nAndroid mutation testing costs. It implements mutation testing operators\n(traditional and Android-specific) according to mutant schemata (implementing\nmultiple mutants into a single code file). It also describes an Android\nmutation testing framework developed to execute test cases and determine\nmutation scores. Additional mutation operators can be implemented in JavaScript\nand easily integrated into the framework. The overall approach is validated\nthrough case studies showing that mutant schemata have advantages over the\ntraditional mutation strategy (one file per mutant). The results show mutant\nschemata overcome traditional mutation in all evaluated aspects with no\nadditional cost: it takes 8.50% less time for mutant generation, requires\n99.78% less disk space, and runs, on average, 6.45% faster than traditional\nmutation. Moreover, considering sustainability metrics, mutant schemata have\n8,18% less carbon footprint than traditional strategy."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-529",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15112",
    "b_title":[
      "Bayesian Unit-level Modeling of Categorical Survey Data with a\n  Longitudinal Design"
    ],
    "b_abstract":[
      "Categorical response data are ubiquitous in complex survey applications, yet\nfew methods model the dependence across different outcome categories when the\nresponse is ordinal. Likewise, few methods exist for the common combination of\na longitudinal design and categorical data. By modeling individual survey\nresponses at the unit-level, it is possible to capture both ordering\ninformation in ordinal responses and any longitudinal correlation. However,\naccounting for a complex survey design becomes more challenging in the\nunit-level setting. We propose a Bayesian hierarchical, unit-level, model-based\napproach for categorical data that is able to capture ordering among response\ncategories, can incorporate longitudinal dependence, and accounts for the\nsurvey design. To handle computational scalability, we develop efficient Gibbs\nsamplers with appropriate data augmentation as well as variational Bayes\nalgorithms. Using public-use microdata from the Household Pulse Survey, we\nprovide an analysis of an ordinal response that asks about the frequency of\nanxiety symptoms at the beginning of the COVID-19 pandemic. We compare both\ndesign-based and model-based estimators and demonstrate superior performance\nfor the proposed approaches."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.09812",
    "c_title":[
      "Methods of Selective Inference for Linear Mixed Models: a Review and\n  Empirical Comparison"
    ],
    "c_abstract":[
      "Selective inference aims at providing valid inference after a data-driven\nselection of models or hypotheses. It is essential to avoid overconfident\nresults and replicability issues. While significant advances have been made in\nthis area for standard regression models, relatively little attention has been\ngiven to linear mixed models (LMMs), which are widely used for analyzing\nclustered or longitudinal data. This paper reviews the existing selective\ninference approaches developed for LMMs, focusing on selection of fixed\neffects, where the random effects structure is given. We present these methods\nin detail and, through comparative simulations, assess their practical\nperformance and computational feasibility under varying data structures. In\naddition, we apply them to a real-world biological dataset to examine how\nmethod choice can impact inference in practice. Our findings highlight an\nexisting trade-off between computational complexity and statistical power and\nemphasize the scarcity of methods that perform well as the number of variables\nincreases. In such scenarios, basic sample splitting emerges as the most\nreliable approach."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-530",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09020",
    "b_title":[
      "Octopus: Scalable Low-Cost CXL Memory Pooling"
    ],
    "b_abstract":[
      "Compute Express Link (CXL) is widely-supported interconnect standard that\npromises to enable memory disaggregation in data centers. CXL allows for memory\npooling, which can be used to create a shared memory space across multiple\nservers. However, CXL does not specify how to actually build a memory pool.\nExisting proposals for CXL memory pools are expensive, as they require CXL\nswitches or large multi-headed devices. In this paper, we propose a new design\nfor CXL memory pools that is cost-effective. We call these designs Octopus\ntopologies. Our design uses small CXL devices that can be made cheaply and\noffer fast access latencies. Specifically, we propose asymmetric CXL topologies\nwhere hosts connect to different sets of CXL devices. This enables pooling and\nsharing memory across multiple hosts even as each individual CXL device is only\nconnected to a small number of hosts. Importantly, this uses hardware that is\nreadily available today. We also show the trade-off in terms of CXL pod size\nand cost overhead per host. Octopus improves the Pareto frontier defined by\nprior policies, e.g., offering to connect 3x as many hosts at 17% lower cost\nper host."
    ],
    "b_categories":[
      [
        "cs.AR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17434",
    "c_title":[
      "Realizing Hardware-Optimized General Tree-Based Data Structures for\n  Heterogeneous System Classes"
    ],
    "c_abstract":[
      "Tree-based data structures are ubiquitous across applications. Therefore, a\nmultitude of different tree implementations exist. However, while these\nimplementations are diverse, they share a tree structure as the underlying data\nstructure. As such, the access patterns inside these trees are very similar,\nfollowing a path from the root of the tree towards a leaf node. Similarly, many\ndistinct types of memory exist. These types of memory all have different\ncharacteristics. Some of these have an impact on the overall system\nperformance. While the concrete types of memory are varied, their\ncharacteristics can often be abstracted to have a similar effect on the\nperformance. We show how the characteristics of different types of memories can\nbe used to improve the performance of tree-based data structures. By reordering\nthe nodes of a tree inside memory, the characteristics of memory can be\nexploited to optimize the performance. To this end, this paper presents\ndifferent strategies for reordering nodes inside memory as well as efficient\nalgorithms for realizing these strategies. It additionally provides strategies\nto decide when such a reordering operation should be triggered during\noperation. Further, this paper conducts experiments showing the performance\nimpact of the proposed strategies. The experiments show that the strategies can\nimprove the performance of trees by up to 95\\% as offline optimization and 75\\%\nas online optimization."
    ],
    "c_categories":[
      [
        "cs.AR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-531",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12268",
    "b_title":[
      "Affineness on Noetherian graded rings, algebras and Hopf algebras"
    ],
    "b_abstract":[
      "In this note, we show that every Noetherian graded ring with an affine degree\nzero part is affine. As a result, a Noetherian graded Hopf algebra whose degree\nzero component is a commutative or a cocommutative Hopf subalgebra is affine.\nMoreover, we show that the braided Hopf algebra of a Noetherian graded Hopf\nalgebra is affine."
    ],
    "b_categories":[
      [
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02897",
    "c_title":[
      "Existence of polynomials with given roots over non-commutative rings"
    ],
    "c_abstract":[
      "The paper studies the question of existence of polynomials with given roots\nover associative non-commutative rings with identity. It is shown that in the\ncase of an associative division ring for arbitrary n elements of this ring\nthere exists a polynomial of degree n whose roots are these elements.\nSufficient conditions for the existence of such a polynomial are also obtained\nin the case of an arbitrary (not necessarily division) associative ring with\nidentity. The case of polynomials defined over a matrix ring over a field is\nconsidered separately; for such polynomials a criterion for the existence of a\nsecond-degree polynomial with given roots is obtained; examples of constructing\npolynomials with given roots are also given."
    ],
    "c_categories":[
      [
        "math.RA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-532",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05550",
    "b_title":[
      "Elsevier's Pre-proof Policy Blocks Google Scholar Indexing"
    ],
    "b_abstract":[
      "Google Scholar is a vital tool for engineering scholars, enabling efficient\nliterature searches and facilitating academic dissemination. Elsevier, as one\nof the largest publishers of engineering journals, produces essential research\nthat scholars rely on. The pre-proof policy, adopted by Elsevier for certain\njournals, allows articles to be published online in their accepted draft form\nbefore final proofreading and formatting. However, this study empirically\ndemonstrates that the pre-proof publication policy hinders comprehensive\nindexing by Google Scholar. Articles published under this policy are only\npartially indexed, often limited to titles and abstracts, while crucial\nsections such as introductions, methods, results, discussions, conclusions,\nappendices, and data availability statements remain unsearchable. This problem\nhas persisted for years, resulting in reduced visibility and accessibility of\ncertain Elsevier articles. To improve academic dissemination, both Elsevier and\nGoogle Scholar must address this problem by modifying publishing policies or\nenhancing indexing practices. Additionally, this paper explores strategies that\nauthors can use to mitigate the issue and ensure broader discoverability of\ntheir research."
    ],
    "b_categories":[
      [
        "cs.DL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.13567",
    "c_title":[
      "Science mapping of the Revista General de Informacion y Documentacion\n  (2005-2022)"
    ],
    "c_abstract":[
      "A study of the Revista General de Informacion y Documentacion, from 2005 to\n2022. The objective is aimed at qualifying the structure of the research field\nand assessing the trajectory of the thematic areas covered. Applying as\nmethodology the analysis of co-words, the construction of bibliometric networks\nand the creation of scientific maps. 514 documents are extracted from the Web\nof Science (WoS) database. The keywords assigned by the authors of the\ndocuments are selected and divided into three subperiods: 2005-2010, 2011-2016\nand 2017-2022. In the results, 1701 author keywords and 37 bibliometric\nnetworks are obtained. In the period 2005-2010, the structure of the research\nfield is represented on the scientific map with very few central and\nspecialized topics, considering an initial and underdeveloped organization. In\nthe period 2011-2016, the structure of the research field is distributed on the\nscientific map with a more varied number of central and specialized topics, but\nstill insufficient, considering an organization in the process of development.\nIn the period 2017-2022, the structure of the research field is shown on the\nmap with all kinds of family of topics (central, specialized, transversal,\nemerging or disappearing), being valued as a dynamic, complex and heterogeneous\norganization. Regarding the evolution of the thematic areas, the map shows\nsolid progress between the last two periods. The morphology of the thematic\nfield treated in RGID is outlined in three phases: foundation, process of\ndevelopment and consolidation."
    ],
    "c_categories":[
      [
        "cs.DL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-533",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01150",
    "b_title":[
      "Deciphering the Multi-Wavelength Flares of the Most Distant Very\n  High-Energy (>100 GeV) Gamma-ray Emitting Blazar"
    ],
    "b_abstract":[
      "This study analyzes the multi-wavelength flaring activity of the distant flat\nspectrum radio quasar (FSRQ) OP 313 (z=0.997) during November 2023 to March\n2024, using data from Fermi-Large Area Telescope, Swift X-ray Telescope, and\nUltraviolet and Optical Telescope. The analysis highlights two significant very\nhigh energy(VHE) detection epochs and GeV gamma-ray flaring episodes, providing\ninsight into jet emission processes and radiative mechanisms. Key findings\ninclude broadband spectral energy distribution (SED) evolution, including\nenigmatic X-ray spectral changes. Modeling of the multi-wavelength SED with a\none-zone leptonic radiative processes attributes the emissions to synchrotron\nradiation, Synchrotron Self-Compton (SSC), and External Compton (EC)\nmechanisms, with torus photons as the primary source for EC processes. The\nresults suggest that the gamma-ray emitting region lies outside the broad-line\nregion but within the dusty torus. Furthermore, we find that the radiated power\nis significantly smaller than the total jet power, suggesting that most of the\nbulk energy remains within the jet even after passing through the blazar\nemission zone. These findings advance our understanding of particle\nacceleration, jet dynamics, and photon field interactions in FSRQs."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09300",
    "c_title":[
      "A long-term study of Mrk 50 : Appearance and disappearance of soft\n  excess"
    ],
    "c_abstract":[
      "We present an extensive temporal and spectral study of the Seyfert 1 AGN Mrk\n50 using 15 years (2007-2022) of multiwavelength observations from XMM-Newton,\nSwift, and NuSTAR for the first time. From the timing analysis, we found that\nthe source exhibited variability of $\\sim$20 % during the 2007 observation,\nwhich reduced to below 10 % in the subsequent observations and became\nnon-variable in the observations from 2010 onward. From the spectral study, we\nfound that the spectra are nearly featureless. Non-detection of absorption in\nthe low-energy domain during the 15 years of observation infers the absence of\nobscuration around the central engine, rendering the nucleus a `bare' type. A\nprominent soft X-ray excess below 2 keV was detected in the source spectrum\nduring the observations between 2007 and 2010, which vanished during the later\nobservations. To describe the nature of the soft excess, we use two physical\nmodels, such as warm Comptonization and blurred reflection from the ionized\naccretion disk. Both the physical models explain the nature and origin of the\nsoft excess in this source. Our analysis found that Mrk~50 accretes at\nsub-Eddington accretion rate ($\\lambda_{Edd}=0.13-0.02$) during all the\nobservations used in this work."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-534",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06715",
    "b_title":[
      "Morita Equivalence of Subrings with Applications to Inverse Semigroup\n  Algebras"
    ],
    "b_abstract":[
      "We develop a technique to show the Morita equivalence of certain subrings of\na ring with local units. We then apply this technique to develop conditions\nthat are sufficient to show the Morita equivalence of subalgebras induced by\npartial subactions on generalized Boolean algebras and, subsequently, strongly\n$E^{\\ast}$-unitary inverse subsemigroups. As an application, we prove that the\nLeavitt path algebra of a graph is Morita equivalent to the Leavitt path\nalgebra of certain subgraphs and use this to calculate the Morita equivalence\nclass of some Leavitt path algebras. Finally, as the main application, we prove\na desingularization result for labelled Leavitt path algebras."
    ],
    "b_categories":[
      [
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.19078",
    "c_title":[
      "Generalized Jordan derivations of unital algebras"
    ],
    "c_abstract":[
      "Let $A$ be a unital algebra over a field $F$ with $\\operatorname*{char}\n(F)\\neq2$. In this paper we introduce a new concept of a generalized Jordan\nderivation, covering Jordan centralizers and Jordan derivations, as follows: a\nlinear map $f:A\\rightarrow A$ is a generalized Jordan derivation if there exist\nlinear maps $g;h:A\\rightarrow A$ such that $f\\left( x\\right) \\circ y+x\\circ\ng\\left( y\\right) =h\\left( x\\circ y\\right) $ for all $x,y\\in A$ (here $x\\circ\ny=xy+yx$). Our aim is to give the form of map $f$ in terms of the so called\nquasi Jordan centralizers and quasi Jordan derivations. In addition, a\ncharacterization of such maps is presented."
    ],
    "c_categories":[
      [
        "math.RA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-535",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13483",
    "b_title":[
      "PyJobShop: Solving scheduling problems with constraint programming in\n  Python"
    ],
    "b_abstract":[
      "This paper presents PyJobShop, an open-source Python library for solving\nscheduling problems with constraint programming. PyJobShop provides an\neasy-to-use modeling interface that supports a wide variety of scheduling\nproblems, including well-known variants such as the flexible job shop problem\nand the resource-constrained project scheduling problem. PyJobShop integrates\ntwo state-of-the-art constraint programming solvers: Google's OR-Tools CP-SAT\nand IBM ILOG's CP Optimizer. We leverage PyJobShop to conduct large-scale\nnumerical experiments on more than 9,000 benchmark instances from the machine\nscheduling and project scheduling literature, comparing the performance of\nOR-Tools and CP Optimizer. While CP Optimizer performs better on permutation\nscheduling and large-scale problems, OR-Tools is highly competitive on job shop\nscheduling and project scheduling problems--while also being fully open-source.\nBy providing an accessible and tested implementation of constraint programming\nfor scheduling, we hope that PyJobShop will enable researchers and\npractitioners to use constraint programming for real-world scheduling problems."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02098",
    "c_title":[
      "Graph-Based Modeling and Decomposition of Hierarchical Optimization\n  Problems"
    ],
    "c_abstract":[
      "We present a graph-theoretic modeling approach for hierarchical optimization\nthat leverages the OptiGraph abstraction implemented in the Julia package\nPlasmo$.$jl. We show that the abstraction is flexible and can effectively\ncapture complex hierarchical connectivity that arises from decision-making over\nmultiple spatial and temporal scales (e.g., integration of planning,\nscheduling, and operations in manufacturing and infrastructures). We also show\nthat the graph abstraction facilitates the conceptualization and implementation\nof decomposition and approximation schemes. Specifically, we propose a\ngraph-based Benders decomposition (gBD) framework that enables the exploitation\nof hierarchical (nested) structures and that uses graph\naggregation\/partitioning procedures to discover such structures. In addition,\nwe provide a Julia implementation of gBD, which we call PlasmoBenders$.$jl. We\nillustrate the capabilities using examples arising in the context of energy and\npower systems."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-536",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12847",
    "b_title":[
      "Single spin asymmetry in forward $pA$ collisions from Pomeron-Odderon\n  interference"
    ],
    "b_abstract":[
      "Working in the hybrid framework of the high energy $pA$ collisions we\nidentify a new contribution to transverse single spin asymmetry (SSA). The\nphase necessary for the SSA is provided by the Pomeron-Odderon interference in\nthe dense nuclear target. The complete formula for the $pA \\to h X$ polarized\ncross section also contains the transversity distribution for the polarized\nprojectile as well as the real part of the twist-3 fragmentation function. We\nnumerically estimate the asymmetry $A_N$ and its nuclear dependence. Based on a\nmodel computation we find that $A_N$ can be a percent level in the forward and\nlow-$P_{h\\perp}$ region. For large nuclei we find significant suppression, with\n$A_N \\propto A^{-7\/6}$ parametrically. As a notable feature we find a node of\n$A_N$ as a function of the $P_{h\\perp}$ around the values of the initial\nsaturation scale that could be used to test this mechanism experimentally."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07576",
    "c_title":[
      "One-loop matching for leading-twist generalised\n  transverse-momentum-dependent distributions"
    ],
    "c_abstract":[
      "We present the one-loop matching coefficients necessary to match all of the\nleading-twist generalised transverse-momentum-dependent distributions (GTMDs)\nonto generalised parton distributions (GPDs). Matching functions are extracted\nby computing the first radiative corrections to partonic bilocal correlators\nwith staple-like Wilson lines, as appropriate for high-energy collisions. These\ncorrelators are characterised by a transverse displacement and skewed\nkinematics of external states. Using the proton helicity basis, they are\nparametrised in terms of GTMDs, which are subsequently related to leading-twist\nGPDs. Our results provide new insights into the complex dynamics of GTMDs\ngenerated by radiative corrections. In particular, we show that time-reversal\neven and odd contributions to GTMDs in the so-called ERBL region mix both under\nmatching and evolution. Finally, we present a selection of numerical results\nand comment on the quantitative behaviour of GTMDs."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-537",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01063",
    "b_title":[
      "AI-Invented Tonal Languages: Preventing a Machine Lingua Franca Beyond\n  Human Understanding"
    ],
    "b_abstract":[
      "This paper investigates the potential for large language models (LLMs) to\ndevelop private tonal languages for machine-to-machine (M2M) communication.\nInspired by cryptophasia in human twins (affecting up to 50% of twin births)\nand natural tonal languages like Mandarin and Vietnamese, we implement a\nprecise character-to-frequency mapping system that encodes the full ASCII\ncharacter set (32-126) using musical semitones. Each character is assigned a\nunique frequency, creating a logarithmic progression beginning with space (220\nHz) and ending with tilde (50,175.42 Hz). This spans approximately 7.9 octaves,\nwith higher characters deliberately mapped to ultrasonic frequencies beyond\nhuman perception (>20 kHz). Our implemented software prototype demonstrates\nthis encoding through visualization, auditory playback, and ABC musical\nnotation, allowing for analysis of information density and transmission speed.\nTesting reveals that tonal encoding can achieve information rates exceeding\nhuman speech while operating partially outside human perceptual boundaries.\nThis work responds directly to concerns about AI systems catastrophically\ndeveloping private languages within the next five years, providing a concrete\nprototype software example of how such communication might function and the\ntechnical foundation required for its emergence, detection, and governance."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03080",
    "c_title":[
      "IAO Prompting: Making Knowledge Flow Explicit in LLMs through Structured\n  Reasoning Templates"
    ],
    "c_abstract":[
      "While Large Language Models (LLMs) demonstrate impressive reasoning\ncapabilities, understanding and validating their knowledge utilization remains\nchallenging. Chain-of-thought (CoT) prompting partially addresses this by\nrevealing intermediate reasoning steps, but the knowledge flow and application\nremain implicit. We introduce IAO (Input-Action-Output) prompting, a structured\ntemplate-based method that explicitly models how LLMs access and apply their\nknowledge during complex reasoning tasks. IAO decomposes problems into\nsequential steps, each clearly identifying the input knowledge being used, the\naction being performed, and the resulting output. This structured decomposition\nenables us to trace knowledge flow, verify factual consistency, and identify\npotential knowledge gaps or misapplications. Through experiments across diverse\nreasoning tasks, we demonstrate that IAO not only improves zero-shot\nperformance but also provides transparency in how LLMs leverage their stored\nknowledge. Human evaluation confirms that this structured approach enhances our\nability to verify knowledge utilization and detect potential hallucinations or\nreasoning errors. Our findings provide insights into both knowledge\nrepresentation within LLMs and methods for more reliable knowledge application."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-538",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05273",
    "b_title":[
      "Luminosity measurement with the LHCb RICH detectors in Run 3"
    ],
    "b_abstract":[
      "The LHCb Ring-Imaging Cherenkov detectors are built to provide charged hadron\nidentification over a large range of momentum. The upgraded detectors are also\ncapable of providing an independent measurement of the luminosity for the LHCb\nexperiment during LHC Run 3. The modelling of the opto-electronics chain, the\napplication of the powering strategy during operations, the calibration\nprocedures and the proof of principle of a novel technique for luminosity\ndetermination are presented. In addition, the preliminary precision achieved\nduring the 2023 data-taking year for real-time and offline luminosity\nmeasurements is reported."
    ],
    "b_categories":[
      [
        "hep-ex"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.08235",
    "c_title":[
      "Scripting data acquisition operations and choice of data format for the\n  data files of the DUCK ultra-high energy cosmic rays detector"
    ],
    "c_abstract":[
      "This document outlines the control software considerations for the D.U.C.K\n(Detection of Unusual Cosmic casKades). The primary goal of this software is to\nprovide users with the ability to control Flash Analog to Digital Converter\nfunctions and conduct DAQ (Data Acquisition) operations as well as set the file\nformat for saving the data. The ROOT software framework was found to be\nparticularly useful for DAQ and serves as the primary tool for storing and\nanalyzing our data. Limitations of the software are being considered, and\nfurther development is being conducted."
    ],
    "c_categories":[
      [
        "hep-ex"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-539",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06901",
    "b_title":[
      "Games! What are they good for? The Struggle of Serious Game Adoption for\n  Rehabilitation"
    ],
    "b_abstract":[
      "The field of serious games for health has grown significantly, demonstrating\neffectiveness in various clinical contexts such as stroke, spinal cord injury,\nand degenerative neurological diseases. Despite their potential benefits,\ntherapists face barriers to adopting serious games in rehabilitation, including\nlimited training and game literacy, concerns about cost and equipment\navailability, and a lack of evidence-based research on game effectiveness.\nSerious games for rehabilitation often involve repetitive exercises, which can\nbe tedious and reduce motivation for continued rehabilitation, treating clients\nas passive recipients of clinical outcomes rather than players. This study\nidentifies gaps and provides essential insights for advancing serious games in\nrehabilitation, aiming to enhance their engagement for clients and\neffectiveness as a therapeutic tool. Addressing these challenges requires a\nparadigm shift towards developing and co-creating serious games for\nrehabilitation with therapists, researchers, and stakeholders. Furthermore,\nfuture research is crucial to advance the development of serious games,\nensuring they adhere to evidence-based principles and engage both clients and\ntherapists. This endeavor will identify gaps in the field, inspire new\ndirections, and support the creation of practical guidelines for serious games\nresearch."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04163",
    "c_title":[
      "HistoryPalette: Supporting Exploration and Reuse of Past Alternatives in\n  Image Generation and Editing"
    ],
    "c_abstract":[
      "All creative tasks require creators to iteratively produce, select, and\ndiscard potentially useful ideas. Now, creativity tools include generative AI\nfeatures (e.g., Photoshop Generative Fill) that increase the number of\nalternatives creators consider due to rapid experiments with text prompts and\nrandom generations. Creators use tedious manual systems for organizing their\nprior ideas by saving file versions or hiding layers, but they lack the support\nthey want for reusing prior alternatives in personal work or in communication\nwith others. We present HistoryPalette, a system that supports exploration and\nreuse of prior designs in generative image creation and editing. Using\nHistoryPalette, creators and their collaborators explore a \"palette\" of prior\ndesign alternatives organized by spatial position, topic category, and creation\ntime. HistoryPalette enables creators to quickly preview and reuse their prior\nwork. In creative professional and client collaborator user studies,\nparticipants generated and edited images by exploring and reusing past design\nalternatives with HistoryPalette."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-540",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16106",
    "b_title":[
      "Towards Explainable Multimodal Depression Recognition for Clinical\n  Interviews"
    ],
    "b_abstract":[
      "Recently, multimodal depression recognition for clinical interviews (MDRC)\nhas recently attracted considerable attention. Existing MDRC studies mainly\nfocus on improving task performance and have achieved significant development.\nHowever, for clinical applications, model transparency is critical, and\nprevious works ignore the interpretability of decision-making processes. To\naddress this issue, we propose an Explainable Multimodal Depression Recognition\nfor Clinical Interviews (EMDRC) task, which aims to provide evidence for\ndepression recognition by summarizing symptoms and uncovering underlying\ncauses. Given an interviewer-participant interaction scenario, the goal of\nEMDRC is to structured summarize participant's symptoms based on the eight-item\nPatient Health Questionnaire depression scale (PHQ-8), and predict their\ndepression severity. To tackle the EMDRC task, we construct a new dataset based\non an existing MDRC dataset. Moreover, we utilize the PHQ-8 and propose a\nPHQ-aware multimodal multi-task learning framework, which captures the\nutterance-level symptom-related semantic information to help generate\ndialogue-level summary. Experiment results on our annotated dataset demonstrate\nthe superiority of our proposed methods over baseline systems on the EMDRC\ntask."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.15499",
    "c_title":[
      "Scale-Distribution Decoupling: Enabling Stable and Effective Training of\n  Large Language Models"
    ],
    "c_abstract":[
      "Training stability is a persistent challenge in the pre-training of large\nlanguage models (LLMs), particularly for architectures such as Post-Norm\nTransformers, which are prone to gradient explosion and dissipation. In this\npaper, we propose Scale-Distribution Decoupling (SDD), a novel approach that\nstabilizes training by explicitly decoupling the scale and distribution of the\nweight matrix in fully-connected layers. SDD applies a normalization mechanism\nto regulate activations and a learnable scaling vector to maintain\nwell-conditioned gradients, effectively preventing $\\textbf{gradient explosion\nand dissipation}$. This separation improves optimization efficiency,\nparticularly in deep networks, by ensuring stable gradient propagation.\nExperimental results demonstrate that our method stabilizes training across\nvarious LLM architectures and outperforms existing techniques in different\nnormalization configurations. Furthermore, the proposed method is lightweight\nand compatible with existing frameworks, making it a practical solution for\nstabilizing LLM training. Code is available at https:\/\/github.com\/kaihemo\/SDD."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-541",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11523",
    "b_title":[
      "AI-Assisted Thin Section Image Processing for Pore-Throat\n  Characterization in Tight Clastic Rocks"
    ],
    "b_abstract":[
      "The characterization of pore-throat structures in tight sandstones is crucial\nfor understanding fluid flow in hydrocarbon reservoirs and groundwater systems.\nBoth thin-section and Mercury Intrusion Capillary Pressure (MICP) offer\ninsights rock petrophysical parameters. However, thin-section analysis is\nlimited by its 2D nature and subjective interpretation, while MICP provides 3D\npore-throat distributions, it lacks direct visualization of pore morphology.\nThis study evaluates AI-assisted thin-section image analysis for pore-throat\ncharacterization by comparing its results to MICP-derived measurements. A\nmachine learning-based workflow was developed using color thresholding, K-Means\nclustering, and medial axis transformation to segment pore structures in\nthin-section images. Throat width, porosity, and permeability were\nquantitatively assessed against MICP to determine the accuracy and reliability\nof the technique. The analysis of 26 sandstone samples outlined differences\nbetween the two methods. Thin-section analysis showed porosity values from\n1.37% to 53.37%, with average pore-throat sizes between 5.63 micron and 30.09\nmicron, while permeability estimates ranged from 0.01 mD to 344.35 mD.\nCorrelation analysis showed moderate agreement for throat size (r=0.62) and\npermeability (r=0.61), but weaker for porosity (r=0.32), highlighting the\ndifferences in how each method captures pore connectivity. Results demonstrate\nthat the AI-assisted segmentation provides a scalable and reproducible approach\nbut is constrained by thin-section imaging resolution. While MICP remains\nreliable for permeability evaluation, its comparison with AI-driven image\nanalysis helps assess the reliability of the method. Future research should\nrefine segmentation algorithms, incorporate pretrained data to validate\nAI-derived pore-throat attributes for improved reservoir quality assessment and\npredictive modeling."
    ],
    "b_categories":[
      [
        "physics.geo-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.02023",
    "c_title":[
      "Reducing Frequency Bias of Fourier Neural Operators in 3D Seismic\n  Wavefield Simulations Through Multi-Stage Training"
    ],
    "c_abstract":[
      "The recent development of Neural Operator (NeurOp) learning for solutions to\nthe elastic wave equation shows promising results and provides the basis for\nfast large-scale simulations for different seismological applications. In this\npaper, we use the Fourier Neural Operator (FNO) model to directly solve the 3D\nHelmholtz wave equation for fast seismic ground motion simulations on different\nfrequencies, and show the frequency bias of the FNO model, i.e. it learns the\nlower frequencies better comparing to the higher frequencies. To reduce the\nfrequency bias, we adopt the multi-stage FNO training, i.e., after training a\n1st stage FNO model for estimating the ground motion, we use a second FNO model\nas the 2nd stage to learn from the residual, which greatly reduced the errors\non the higher frequencies. By adopting this multi-stage training, the FNO\nmodels show reduced biases on higher frequencies, which enhanced the overall\nresults of the ground motion simulations. Thus the multi-stage training FNO\nimproves the accuracy and realism of the ground motion simulations."
    ],
    "c_categories":[
      [
        "physics.geo-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-542",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03521",
    "b_title":[
      "Inductive Construction of Variational Quantum Circuit for Constrained\n  Combinatorial Optimization"
    ],
    "b_abstract":[
      "In this study, we propose a new method for constrained combinatorial\noptimization using variational quantum circuits. Quantum computers are\nconsidered to have the potential to solve large combinatorial optimization\nproblems faster than classical computers. Variational quantum algorithms, such\nas Variational Quantum Eigensolver (VQE), have been studied extensively because\nthey are expected to work on noisy intermediate scale devices. Unfortunately,\nmany optimization problems have constraints, which induces infeasible solutions\nduring VQE process. Recently, several methods for efficiently solving\nconstrained combinatorial optimization problems have been proposed by designing\na quantum circuit so as to output only the states that satisfy the constraints.\nHowever, the types of available constraints are still limited. Therefore, we\nhave started to develop variational quantum circuits that can handle a wider\nrange of constraints. The proposed method utilizes a forwarding operation that\nmaps from feasible states for subproblems to those for larger subproblems. As\nlong as appropriate forwarding operations can be defined, iteration of this\nprocess can inductively construct variational circuits outputting feasible\nstates even in the case of multiple and complex constraints. In this paper, the\nproposed method was applied to facility location problem and was found to\nincrease the probability for measuring feasible solutions or optimal solutions.\nIn addition, the cost of the obtained circuit was comparable to that of\nconventional variational circuits."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09438",
    "c_title":[
      "Testing Born's rule via photoionization of helium"
    ],
    "c_abstract":[
      "It is shown how state-of-the-art attosecond photoionization experiments can\ntest Born's rule -- a postulate of quantum mechanics -- via the so-called\nSorkin test. A simulation of the Sorkin test under consideration of typical\nexperimental noise and data acquisition efficiencies infers an achievable\nmeasurement precision in the range of the best Sorkin tests to date. The\nimplementation of further fundamental tests of quantum mechanics is discussed."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-543",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05670",
    "b_title":[
      "Leveraging Epsilon Near Zero phenomena for on-chip photonic modulation"
    ],
    "b_abstract":[
      "Epsilon-near-zero (ENZ) systems exhibit unconventional electromagnetic\nresponse close to their zero permittivity regime. Here, we explore the ability\nof ultrathin ENZ films to modulate the transmission of radiation from an\nunderlying quantum emitter through active control of the carrier density of the\nENZ film. The achievable on\/off switching ratio is shown to be constrained by\nthe material's loss parameter, particularly in the ENZ regime, where\ntransmissivity increases with higher material loss. The finite loss in real\nmaterials limit the more extraordinary potential of ideal near-zero-index\nsystems. Along with an in-depth discussion on the material parameters vis-a-vis\nthe underlying physics, this work provides avenues to overcome the shortcomings\nof finite loss in real materials. These findings are intended to guide material\ndevelopment and offer valuable insights for designing on-chip optical\nmodulators and beam steering devices operating in the near-infrared regime."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20610",
    "c_title":[
      "A systolic update scheme to overcome memory bandwidth limitations in\n  GPU-accelerated FDTD simulations"
    ],
    "c_abstract":[
      "The exponential growth of artificial intelligence has fueled the development\nof high-bandwidth photonic interconnect fabrics as a critical component of\nmodern AI supercomputers. As the demand for ever-increasing AI compute and\nconnectivity continues to grow, the need for high-throughput photonic\nsimulation engines to accelerate and even revolutionize photonic design and\nverification workflows will become an increasingly indispensable capability for\nthe integrated photonics industry. Unfortunately, the mainstay and workhorse of\nphotonic simulation algorithms, the finite-difference time-domain (FDTD)\nmethod, because it is a memory-intensive but computationally-lightweight\nalgorithm, is fundamentally misaligned with modern computational platforms\nwhich are equipped to deal with compute intensive workloads instead. This paper\nintroduces a systolic update scheme for the FDTD method, which circumvents this\nmismatch by reducing the need for global synchronization while also relegating\nthe need to access global memory to the case of boundary values between\nneighboring subdomains only. We demonstrate a practical implementation of our\nscheme as applied to the full three-dimensional FDTD algorithm that achieves a\nperformance of roughly 0.15 trillion cell updates per second (TCUPS) on a\nsingle Nvidia H100 GPU. Our work paves the way for the increasingly efficient,\ncost-effective, and high-throughput photonic simulation engines needed to\ncontinue powering the AI era."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-544",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03545",
    "b_title":[
      "Revisiting the Role of Relearning in Semantic Dementia"
    ],
    "b_abstract":[
      "Patients with semantic dementia (SD) present with remarkably consistent\natrophy of neurons in the anterior temporal lobe and behavioural impairments,\nsuch as graded loss of category knowledge. While relearning of lost knowledge\nhas been shown in acute brain injuries such as stroke, it has not been widely\nsupported in chronic cognitive diseases such as SD. Previous research has shown\nthat deep linear artificial neural networks exhibit stages of semantic learning\nakin to humans. Here, we use a deep linear network to test the hypothesis that\nrelearning during disease progression rather than particular atrophy cause the\nspecific behavioural patterns associated with SD. After training the network to\ngenerate the common semantic features of various hierarchically organised\nobjects, neurons are successively deleted to mimic atrophy while retraining the\nmodel. The model with relearning and deleted neurons reproduced errors specific\nto SD, including prototyping errors and cross-category confusions. This\nsuggests that relearning is necessary for artificial neural networks to\nreproduce the behavioural patterns associated with SD in the absence of\n\\textit{output} non-linearities. Our results support a theory of SD progression\nthat results from continuous relearning of lost information. Future research\nshould revisit the role of relearning as a contributing factor to cognitive\ndiseases."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18655",
    "c_title":[
      "Provably Efficient RL for Linear MDPs under Instantaneous Safety\n  Constraints in Non-Convex Feature Spaces"
    ],
    "c_abstract":[
      "In Reinforcement Learning (RL), tasks with instantaneous hard constraints\npresent significant challenges, particularly when the decision space is\nnon-convex or non-star-convex. This issue is especially relevant in domains\nlike autonomous vehicles and robotics, where constraints such as collision\navoidance often take a non-convex form. In this paper, we establish a regret\nbound of $\\tilde{\\mathcal{O}}\\bigl(\\bigl(1 + \\tfrac{1}{\\tau}\\bigr)\n\\sqrt{\\log(\\tfrac{1}{\\tau}) d^3 H^4 K} \\bigr)$, applicable to both star-convex\nand non-star-convex cases, where $d$ is the feature dimension, $H$ the episode\nlength, $K$ the number of episodes, and $\\tau$ the safety threshold. Moreover,\nthe violation of safety constraints is zero with high probability throughout\nthe learning process. A key technical challenge in these settings is bounding\nthe covering number of the value-function class, which is essential for\nachieving value-aware uniform concentration in model-free function\napproximation. For the star-convex setting, we develop a novel technique called\nObjective Constraint-Decomposition (OCD) to properly bound the covering number.\nThis result also resolves an error in a previous work on constrained RL. In\nnon-star-convex scenarios, where the covering number can become infinitely\nlarge, we propose a two-phase algorithm, Non-Convex Safe Least Squares Value\nIteration (NCS-LSVI), which first reduces uncertainty about the safe set by\nplaying a known safe policy. After that, it carefully balances exploration and\nexploitation to achieve the regret bound. Finally, numerical simulations on an\nautonomous driving scenario demonstrate the effectiveness of NCS-LSVI."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-545",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18328",
    "b_title":[
      "TensoFlow: Tensorial Flow-based Sampler for Inverse Rendering"
    ],
    "b_abstract":[
      "Inverse rendering aims to recover scene geometry, material properties, and\nlighting from multi-view images. Given the complexity of light-surface\ninteractions, importance sampling is essential for the evaluation of the\nrendering equation, as it reduces variance and enhances the efficiency of Monte\nCarlo sampling. Existing inverse rendering methods typically use pre-defined\nnon-learnable importance samplers in prior manually, struggling to effectively\nmatch the spatially and directionally varied integrand and resulting in high\nvariance and suboptimal performance. To address this limitation, we propose the\nconcept of learning a spatially and directionally aware importance sampler for\nthe rendering equation to accurately and flexibly capture the unconstrained\ncomplexity of a typical scene. We further formulate TensoFlow, a generic\napproach for sampler learning in inverse rendering, enabling to closely match\nthe integrand of the rendering equation spatially and directionally.\nConcretely, our sampler is parameterized by normalizing flows, allowing both\ndirectional sampling of incident light and probability density function (PDF)\ninference. To capture the characteristics of the sampler spatially, we learn a\ntensorial representation of the scene space, which imposes spatial conditions,\ntogether with reflected direction, leading to spatially and directionally aware\nsampling distributions. Our model can be optimized by minimizing the difference\nbetween the integrand and our normalizing flow. Extensive experiments validate\nthe superiority of TensoFlow over prior alternatives on both synthetic and\nreal-world benchmarks."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05335",
    "c_title":[
      "New multimodal similarity measure for image registration via modeling\n  local functional dependence with linear combination of learned basis\n  functions"
    ],
    "c_abstract":[
      "The deformable registration of images of different modalities, essential in\nmany medical imaging applications, remains challenging. The main challenge is\ndeveloping a robust measure for image overlap despite the compared images\ncapturing different aspects of the underlying tissue. Here, we explore\nsimilarity metrics based on functional dependence between intensity values of\nregistered images. Although functional dependence is too restrictive on the\nglobal scale, earlier work has shown competitive performance in deformable\nregistration when such measures are applied over small enough contexts. We\nconfirm this finding and further develop the idea by modeling local functional\ndependence via the linear basis function model with the basis functions learned\njointly with the deformation. The measure can be implemented via convolutions,\nmaking it efficient to compute on GPUs. We release the method as an easy-to-use\ntool and show good performance on three datasets compared to well-established\nbaseline and earlier functional dependence-based methods."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-546",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05376",
    "b_title":[
      "BCQ: Block Clustered Quantization for 4-bit (W4A4) LLM Inference"
    ],
    "b_abstract":[
      "Post-training quantization (PTQ) is a promising approach to reducing the\nstorage and computational requirements of large language models (LLMs) without\nadditional training cost. Recent PTQ studies have primarily focused on\nquantizing only weights to sub-8-bits while maintaining activations at 8-bits\nor higher. Accurate sub-8-bit quantization for both weights and activations\nwithout relying on quantization-aware training remains a significant challenge.\nWe propose a novel quantization method called block clustered quantization\n(BCQ) wherein each operand tensor is decomposed into blocks (a block is a group\nof contiguous scalars), blocks are clustered based on their statistics, and a\ndedicated optimal quantization codebook is designed for each cluster. As a\nspecific embodiment of this approach, we propose a PTQ algorithm called\nLocally-Optimal BCQ (LO-BCQ) that iterates between the steps of block\nclustering and codebook design to greedily minimize the quantization mean\nsquared error. When weight and activation scalars are encoded to W4A4 format\n(with 0.5-bits of overhead for storing scaling factors and codebook selectors),\nwe advance the current state-of-the-art by demonstrating <1% loss in inference\naccuracy across several LLMs and downstream tasks."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05541",
    "c_title":[
      "Customizable LLM-Powered Chatbot for Behavioral Science Research"
    ],
    "c_abstract":[
      "The rapid advancement of Artificial Intelligence has resulted in the advent\nof Large Language Models (LLMs) with the capacity to produce text that closely\nresembles human communication. These models have been seamlessly integrated\ninto diverse applications, enabling interactive and responsive communication\nacross multiple platforms. The potential utility of chatbots transcends these\ntraditional applications, particularly in research contexts, wherein they can\noffer valuable insights and facilitate the design of innovative experiments. In\nthis study, we present a Customizable LLM-Powered Chatbot (CLPC), a web-based\nchatbot system designed to assist in behavioral science research. The system is\nmeticulously designed to function as an experimental instrument rather than a\nconventional chatbot, necessitating users to input a username and experiment\ncode upon access. This setup facilitates precise data cross-referencing,\nthereby augmenting the integrity and applicability of the data collected for\nresearch purposes. It can be easily expanded to accommodate new basic events as\nneeded; and it allows researchers to integrate their own logging events without\nthe necessity of implementing a separate logging mechanism. It is worth noting\nthat our system was built to assist primarily behavioral science research but\nis not limited to it, it can easily be adapted to assist information retrieval\nresearch or interacting with chat bot agents in general."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-547",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06084",
    "b_title":[
      "Verifying the Fisher-Yates Shuffle Algorithm in Dafny"
    ],
    "b_abstract":[
      "The Fisher-Yates shuffle is a well-known algorithm for shuffling a finite\nsequence, such that every permutation is equally likely. Despite its\nsimplicity, it is prone to implementation errors that can introduce bias into\nthe generated permutations. We verify its correctness in Dafny as follows.\nFirst, we define a functional model that operates on sequences and streams of\nrandom bits. Second, we establish that the functional model has the desired\ndistribution. Third, we define an executable imperative implementation that\noperates on arrays and prove it equivalent to the functional model. The\napproach may serve as a blueprint for the verification of more complex\nalgorithms."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10448",
    "c_title":[
      "Supply Chain Network Security Investment Strategies Based on Nonlinear\n  Budget Constraints: The Moderating Roles of Market Share and Attack Risk"
    ],
    "c_abstract":[
      "In the context of the rapid development of digital supply chain networks,\ndealing with the increasing cybersecurity threats and formulating effective\nsecurity investment strategies to defend against cyberattack risks are the core\nissues in supply chain management. Cybersecurity investment decision-making is\na key strategic task in enterprise supply chain manage-ment. Traditional game\ntheory models and linear programming methods make it challenging to deal with\ncomplex problems such as multi-party par-ticipation in the supply chain,\nresource constraints, and risk uncertainty, re-sulting in enterprises facing\nhigh risks and uncertainties in the field of cy-bersecurity. To effectively\nmeet this challenge, this study proposes a nonlin-ear budget-constrained\ncybersecurity investment optimization model based on variational inequality and\nprojection shrinkage algorithm. This method simulates the impact of market\ncompetition on security investment by intro-ducing market share variables,\ncombining variational inequality and projec-tion shrinkage algorithm to solve\nthe model, and analyzing the effect of dif-ferent variables such as budget\nconstraints, cyberattack losses, and market share on supply chain network\nsecurity. In numerical analysis, the model achieved high cybersecurity levels\nof 0.96 and 0.95 in the experimental sce-narios of two retailers and two demand\nmarkets, respectively, and the budget constraint analysis revealed the profound\nimpact of budget constraints on cybersecurity investment. Through numerical\nexperiments and comparative analysis, the effectiveness and operability of this\nmethod in improving sup-ply chain network security are verified."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-548",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11933",
    "b_title":[
      "Clifford circuit based heuristic optimization of fermion-to-qubit\n  mappings"
    ],
    "b_abstract":[
      "Simulation of interacting fermionic Hamiltonians is one of the most promising\napplications of quantum computers. However, the feasibility of analysing\nfermionic systems with a quantum computer hinges on the efficiency of\nfermion-to-qubit mappings that encode non-local fermionic degrees of freedom in\nlocal qubit degrees of freedom. While recent works have highlighted the\nimportance of designing fermion-to-qubit mappings that are tailored to specific\nproblem Hamiltonians, the methods proposed so far are either restricted to a\nnarrow class of mappings or they use computationally expensive and unscalable\nbrute-force search algorithms. Here, we address this challenge by designing a\n$\\mathrm{\\textbf{heuristic}}$ numerical optimization framework for\nfermion-to-qubit mappings. To this end, we first translate the fermion-to-qubit\nmapping problem to a Clifford circuit optimization problem, and then use\nsimulated annealing to optimize the average Pauli weight of the problem\nHamiltonian. For all fermionic Hamiltonians we have considered, the numerically\noptimized mappings outperform their conventional counterparts, including\nternary-tree-based mappings that are known to be optimal for single creation\nand annihilation operators. We find that our optimized mappings yield between\n$15\\%$ to $40\\%$ improvements on the average Pauli weight when the simulation\nHamiltonian has an intermediate level of complexity. Most remarkably, the\noptimized mappings improve the average Pauli weight for $6 \\times 6$\nnearest-neighbor hopping and Hubbard models by more than $40\\%$ and $20\\%$,\nrespectively. Surprisingly, we also find specific interaction Hamiltonians for\nwhich the optimized mapping outperform $\\mathrm{\\textbf{any}}$\nternary-tree-based mapping. Our results establish heuristic numerical\noptimization as an effective method for obtaining mappings tailored for\nspecific fermionic Hamiltonian."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02094",
    "c_title":[
      "Potential of photon-subtracted CV states towards gain sensitivity of the\n  Mach-Zehnder interferometer"
    ],
    "c_abstract":[
      "Quantum Cramer-Rao (QCR) bound is attached to a particular nonclassical\nstate, therefore appropriate choice of the probe state is of the key importance\nto enhance sensitivity beyond classical one. Since the work of C.M. Caves\n(Phys. Rev. D 23 1693 (1981)) Mach-Zehnder (MZ) interferometry operates with\nsingle-mode squeezed vacuum (SMSV) light coupled with a coherent state. We\nreport the gain sensitivity of the phase-dependent MZ interferometer by more\nthan 10 dB compared to the original result (Phys. Rev. Lett. 100, 073601\n(2008)) by using SMSV state with squeezing <10 dB from which a certain number\nof photons was initially subtracted. The gain sensitivity is also observed when\nmeasuring the difference of output intensities of the SMSV state with squeezing\n<3 dB from which 2,4,6 photons are subtracted and large coherent state.\nOverall, subtracting photons from the initially weakly squeezed light can prove\nto be a more efficient strategy in the quantum MZ interferometry compared to\nhighly squeezed SMSV state generation."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-549",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07982",
    "b_title":[
      "DiffEGG: Diffusion-Driven Edge Generation as a Pixel-Annotation-Free\n  Alternative for Instance Annotation"
    ],
    "b_abstract":[
      "Achieving precise panoptic segmentation relies on pixel-wise instance\nannotations, but obtaining such datasets is costly. Unsupervised instance\nsegmentation (UIS) eliminates annotation requirements but struggles with\nadjacent instance merging and single-instance fragmentation, largely due to the\nlimitations of DINO-based backbones which lack strong instance separation cues.\nWeakly-supervised panoptic segmentation (WPS) reduces annotation costs using\nsparse labels (e.g., points, boxes), yet these annotations remain expensive and\nintroduce human bias and boundary errors. To address these challenges, we\npropose DiffEGG (Diffusion-Driven EdGe Generation), a fully annotation-free\nmethod that extracts instance-aware features from pretrained diffusion models\nto generate precise instance edge maps. Unlike DINO-based UIS methods,\ndiffusion models inherently capture fine-grained, instance-aware features,\nenabling more precise boundary delineation. For WPS, DiffEGG eliminates\nannotation costs and human bias by operating without any form of manual\nsupervision, addressing the key limitations of prior best methods.\nAdditionally, we introduce RIP, a post-processing technique that fuses\nDiffEGG's edge maps with segmentation masks in a task-agnostic manner. RIP\nallows DiffEGG to be seamlessly integrated into various segmentation\nframeworks. When applied to UIS, DiffEGG and RIP achieve an average $+4.4\\text{\nAP}$ improvement over prior best UIS methods. When combined with\nweakly-supervised semantic segmentation (WSS), DiffEGG enables WPS without\ninstance annotations, outperforming prior best point-supervised WPS methods by\n$+1.7\\text{ PQ}$. These results demonstrate that DiffEGG's edge maps serve as a\ncost-effective, annotation-free alternative to instance annotations,\nsignificantly improving segmentation without human intervention. Code is\navailable at https:\/\/github.com\/shjo-april\/DiffEGG."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05936",
    "c_title":[
      "CASP: Compression of Large Multimodal Models Based on Attention Sparsity"
    ],
    "c_abstract":[
      "In this work, we propose an extreme compression technique for Large\nMultimodal Models (LMMs). While previous studies have explored quantization as\nan efficient post-training compression method for Large Language Models (LLMs),\nlow-bit compression for multimodal models remains under-explored. The redundant\nnature of inputs in multimodal models results in a highly sparse attention\nmatrix. We theoretically and experimentally demonstrate that the attention\nmatrix's sparsity bounds the compression error of the Query and Key weight\nmatrices. Based on this, we introduce CASP, a model compression technique for\nLMMs. Our approach performs a data-aware low-rank decomposition on the Query\nand Key weight matrix, followed by quantization across all layers based on an\noptimal bit allocation process. CASP is compatible with any quantization\ntechnique and enhances state-of-the-art 2-bit quantization methods (AQLM and\nQuIP#) by an average of 21% on image- and video-language benchmarks."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-550",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00958",
    "b_title":[
      "Inertial Updating with General Information"
    ],
    "b_abstract":[
      "We study belief revision when information is represented by a set of\nprobability distributions, or general information. General information extends\nthe standard event notion while including qualitative information (A is more\nlikely than B), interval information (A has a ten-to-twenty percent chance),\nand more. We behaviorally characterize Inertial Updating: the decision maker's\nposterior is of minimal subjective distance from her prior, given the\ninformation constraint. Further, we introduce and characterize a notion of\nBayesian updating for general information and show that Bayesian agents may\ndisagree. We also behaviorally characterize f-divergences, the class of\ndistances consistent with Bayesian updating."
    ],
    "b_categories":[
      [
        "econ.TH"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2503.10132",
    "c_title":[
      "Shinohara Rock-Paper-Scissors"
    ],
    "c_abstract":[
      "This paper analyzes Shinohara Rock-Paper-Scissors (RPS), a variant of the\nclassic RPS game introduced by board game designer Yoshiteru Shinohara. Players\ncompete against a host who always plays rock, so players choose either rock or\npaper. The twist is that if two or more players choose paper, they are\neliminated, and the last remaining player is the winner, creating strategic\ntension among the players. There exists a unique symmetric subgame perfect\nequilibrium, in which the probability of choosing paper satisfies the equation\n$(1-p)^{n-1} + p^{n-1}\/n = 1\/n$, where $n$ is the number of remaining players.\nThe game also admits a continuum of asymmetric equilibria."
    ],
    "c_categories":[
      [
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-551",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07657",
    "b_title":[
      "Heterogeneous-free narrow linewidth semiconductor laser with optical\n  injection locking"
    ],
    "b_abstract":[
      "Narrow linewidth lasers are indispensable for coherent optical systems,\nincluding communications, metrology, and sensing. Although compact\nsemiconductor lasers with narrow linewidths and low noise have been\ndemonstrated, their spectral purity typically relies on hybrid or heterogeneous\nexternal cavity feedback. Here, we present a theoretical and experimental\ndemonstration of a heterogeneous free optical injection locking (HF OIL)\nsemiconductor laser. By integrating a topological interface state extended\n(TISE) laser with a micro ring resonator (MRR) on an AlGaInAs multiple quantum\nwell platform,we achieve monolithic photon injection and phase locking, thereby\nreducing the optical linewidth. We fabricated and characterized a 1550 nm\nsidewall HF OIL laser, achieving stable single mode operation over a broad\ncurrent range (65 to 300 mA) and a side mode suppression ratio (SMSR) over 50\ndB. Under injection locking, the devices Voigt fitted linewidth narrowed from\nover 1.7 MHz (free running) to 4.2 kHz, representing a three order of magnitude\nimprovement over conventional distributed feedback lasers. The intrinsic\nlinewidth of 1.4 kHz is measured by correlated delayed self-heterodyne\nfrequency noise power spectrum density (FN PSD) method. Moreover, the HF OIL\nlaser demonstrated high phase stability and the ability to transition from a\nrandom phased to a phase locked state. These results underscore the potential\nof HF-OIL lasers in advancing coherent optical communications and phase\nencoders in quantum key distribution (QKD) systems."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10345",
    "c_title":[
      "Fundamental mode power estimation through a $M^2$-measurement"
    ],
    "c_abstract":[
      "Beam quality is a crucial metric for evaluating light source performance,\nwith the $M^2$ beam quality parameter serving as the standard since the 1990s.\nApplications typically demand a mode profile resembling a fundamental Gaussian\nmode, characterized by an $M^2$ value near 1. However, direct quantification of\nthe fundamental mode's contribution has remained challenging. We establish a\nrelation between $M^2$ measurements and the fundamental mode power, in its most\ngeneral form: $P_{00}\\geq 2 - M_x^2\/2 - M_y^2\/2$. This enables more accurate\nbeam quality assessments, critical for a majority of light source applications."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-552",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00184",
    "b_title":[
      "Geometric properties of solutions to elliptic PDE's in Gauss space and\n  related Brunn-Minkowski type inequalities"
    ],
    "b_abstract":[
      "We prove a Brunn-Minkowski type inequality for the first (nontrivial)\nDirichlet eigenvalue of the weighted $p$-operator \\[\n-\\Delta_{p,\\gamma}u=-\\text{div}(|\\nabla u|^{p-2} \\nabla u)+(x,\\nabla u)|\\nabla\nu|^{p-2}, \\] where $p>1$, in the class of bounded Lipschitz domains in\n$\\mathbb{R}^n$. We also prove that any corresponding positive eigenfunction is\nlog-concave if the domain is convex."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.17765",
    "c_title":[
      "Entire solutions to a quasilinear purely critical competitive system"
    ],
    "c_abstract":[
      "We establish the existence of a fully nontrivial solution with nonnegative\ncomponents for a weakly coupled competitive system for the $p$-Laplacian in\n$\\mathbb{R}^N$ whose nonlinear terms are purely critical.\n  We also show that the purely critical equation for the $p$-Laplacian in\n$\\mathbb{R}^N$ has infinitely many nodal solutions."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-553",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14131",
    "b_title":[
      "Spinor ice correlation in flat-band electronic states on kagome and\n  pyrochlore lattices with spin-orbit coupling"
    ],
    "b_abstract":[
      "We investigate the emergence and transformation of pinch-point singularities\nin the excitation spectrum of electronic flat band systems on kagome and\npyrochlore lattices with spin-orbit coupling (SOC) and Coulomb interactions.\nWhile pinch points are widely recognized as signatures of classical spin\nliquids, they also appear in electronic flat-band systems when there exists a\nsingular band-touching point to dispersive bands. We explore how SOC modifies\nthe pinch-point structure in the chiral spin flat-band metallic state, which we\nterm spinor-ice. The pinch point profile can rotate or redistribute its\nspectral weight, governed by a prefactor in the spectral function that\nprimarily depends on the direction of the ground-state spin polarization, where\nwe show that SOC flat bands could be experimentally probed by rotating the spin\npolarization of the injected electron to infer internal magnetic structures.\nThese observations are discussed in conjunction with the angle-resolved\nphotoemission spectroscopy (ARPES) and the application to the potential SOC\nflat-band material $\\rm CsW_2O_6$. We also demonstrate the persistent residual\npinch-point features under Coulomb interactions and deviations from the ideal\nflat-band limit."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.03980",
    "c_title":[
      "Classical signatures of quenched and thermal disorder in the dynamics of\n  correlated spin systems"
    ],
    "c_abstract":[
      "Neutron scattering is frequently used to look for evidence of features\nindicative of quantum-entangled phases of matter such as continua from\nfractionalisation or quantised excitations. However, the non-specificity of\nthese features and difficulty of both fully quantum treatments and\nsemiclassical models of disorder, make the diagnosis of such states\nproblematic. Here, we demonstrate the feasibility of semiclassical treatments\nof disordered systems for supercells of $\\sim 10,000$ spins. By examining a\nnumber of classically disordered models we show the presence of quantised\nexcitations, broad continua and anomalous damping originating from quenched\ndisorder or large classical degeneracies."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-554",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19370",
    "b_title":[
      "Greedy Stein Variational Gradient Descent: An algorithmic approach for\n  wave prospection problems"
    ],
    "b_abstract":[
      "In this project, we propose a Variational Inference algorithm to approximate\nposterior distributions. Building on prior methods, we develop the\nGradient-Steered Stein Variational Gradient Descent (G-SVGD) approach. This\nmethod introduces a novel loss function that combines a weighted gradient and\nthe Evidence Lower Bound (ELBO) to enhance convergence speed and accuracy. The\nlearning rate is determined through a suboptimal minimization of this loss\nfunction within a gradient descent framework.\n  The G-SVGD method is compared against the standard Stein Variational Gradient\nDescent (SVGD) approach, employing the ADAM optimizer for learning rate\nadaptation, as well as the Markov Chain Monte Carlo (MCMC) method. We assess\nperformance in two wave prospection models representing low-contrast and\nhigh-contrast subsurface scenarios. To achieve robust numerical approximations\nin the forward model solver, a five-point operator is employed, while the\nadjoint method improves accuracy in computing gradients of the log posterior.\n  Our findings demonstrate that G-SVGD accelerates convergence and offers\nimproved performance in scenarios where gradient evaluation is computationally\nexpensive. The abstract highlights the algorithm's applicability to wave\nprospection models and its potential for broader applications in Bayesian\ninference. Finally, we discuss the benefits and limitations of G-SVGD,\nemphasizing its contribution to advancing computational efficiency in\nuncertainty quantification."
    ],
    "b_categories":[
      [
        "stat.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.05908",
    "c_title":[
      "MCMC for multi-modal distributions"
    ],
    "c_abstract":[
      "We explain the fundamental challenges of sampling from multimodal\ndistributions, particularly for high-dimensional problems. We present the major\ntypes of MCMC algorithms that are designed for this purpose, including parallel\ntempering, mode jumping and Wang-Landau, as well as several state-of-the-art\napproaches that have recently been proposed. We demonstrate these methods using\nboth synthetic and real-world examples of multimodal distributions with\ndiscrete or continuous state spaces."
    ],
    "c_categories":[
      [
        "stat.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-555",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10259",
    "b_title":[
      "MITO: A Millimeter-Wave Dataset and Simulator for Non-Line-of-Sight\n  Perception"
    ],
    "b_abstract":[
      "The ability to observe the world is fundamental to reasoning and making\ninformed decisions on how to interact with the environment. However, optical\nperception can often be disrupted due to common occurrences, such as\nocclusions, which can pose challenges to existing vision systems. We present\nMITO, the first millimeter-wave (mmWave) dataset of diverse, everyday objects,\ncollected using a UR5 robotic arm with two mmWave radars operating at different\nfrequencies and an RGB-D camera. Unlike visible light, mmWave signals can\npenetrate common occlusions (e.g., cardboard boxes, fabric, plastic) but each\nmmWave frame has much lower resolution than typical cameras. To capture\nhigher-resolution mmWave images, we leverage the robot's mobility and fuse\nframes over the synthesized aperture. MITO captures over 24 million mmWave\nframes and uses them to generate 550 high-resolution mmWave (synthetic\naperture) images in line-of-sight and non-light-of-sight (NLOS), as well as\nRGB-D images, segmentation masks, and raw mmWave signals, taken from 76\ndifferent objects. We develop an open-source simulation tool that can be used\nto generate synthetic mmWave images for any 3D triangle mesh. Finally, we\ndemonstrate the utility of our dataset and simulator for enabling broader NLOS\nperception by developing benchmarks for NLOS segmentation and classification."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.06818",
    "c_title":[
      "UR2P-Dehaze: Learning a Simple Image Dehaze Enhancer via Unpaired Rich\n  Physical Prior"
    ],
    "c_abstract":[
      "Image dehazing techniques aim to enhance contrast and restore details, which\nare essential for preserving visual information and improving image processing\naccuracy. Existing methods rely on a single manual prior, which cannot\neffectively reveal image details. To overcome this limitation, we propose an\nunpaired image dehazing network, called the Simple Image Dehaze Enhancer via\nUnpaired Rich Physical Prior (UR2P-Dehaze). First, to accurately estimate the\nillumination, reflectance, and color information of the hazy image, we design a\nshared prior estimator (SPE) that is iteratively trained to ensure the\nconsistency of illumination and reflectance, generating clear, high-quality\nimages. Additionally, a self-monitoring mechanism is introduced to eliminate\nundesirable features, providing reliable priors for image reconstruction. Next,\nwe propose Dynamic Wavelet Separable Convolution (DWSC), which effectively\nintegrates key features across both low and high frequencies, significantly\nenhancing the preservation of image details and ensuring global consistency.\nFinally, to effectively restore the color information of the image, we propose\nan Adaptive Color Corrector that addresses the problem of unclear colors. The\nPSNR, SSIM, LPIPS, FID and CIEDE2000 metrics on the benchmark dataset show that\nour method achieves state-of-the-art performance. It also contributes to the\nperformance improvement of downstream tasks. The project code will be available\nat https:\/\/github.com\/Fan-pixel\/UR2P-Dehaze. \\end{abstract}"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-556",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14564",
    "b_title":[
      "Affine diffractive beam dividers"
    ],
    "b_abstract":[
      "Diffractive optical elements that divide an input beam into a set of replicas\nare used in many optical applications ranging from image processing to\ncommunications. Their design requires time-consuming optimization processes,\nwhich, for a given number of generated beams, are to be separately treated for\none-dimensional and two-dimensional cases because the corresponding optimal\nefficiencies may be different. After generalizing their Fourier treatment, we\nprove that, once a particular divider has been designed, its transmission\nfunction can be used to generate numberless other dividers through affine\ntransforms that preserve the efficiency of the original element without\nrequiring any further optimization."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.03077",
    "c_title":[
      "Nonlocal Generation of Fano Resonance with No Symmetry Breaking in THz\n  Hybrid Metasurfaces"
    ],
    "c_abstract":[
      "Fano resonance, arising from the interference between a discrete resonance\nand a continuum of states, results in sharp and asymmetric line shapes and has\nsignificant applications in advanced photonic devices, particularly in sensing,\nfiltering, and nonlinear optics. Nowadays, metasurfaces comprised of\nengineering microstructures play a crucial role in generation and manipulation\nof Fano resonance in photonics. However, current metasurfaces dominantly rely\non local symmetry breaking of the microstructures to induce Fano resonances,\nwhich significant limits their tunability and scalable fabrication for\npractical applications. To address the challenge, a metal-dielectric hybrid\nmetasurface is demonstrated to achieve nonlocal generation of Fano resonance\nwith no symmetry breaking in the terahertz (THz) band. The Fano resonance,\nincluding its existence and peak frequency, is sensitively controlled by the\nthickness and dielectric constant of the dielectric layer, which is\nexperimentally observed. Our analysis elucidates that the metallic layer with a\npair of dumbbell holes leads to the band folding and coupling of guided modes\nwithin the dielectric layer. When the thickness or dielectric constant\nsurpasses a critical value, the guided mode resonance falls below the\ndiffraction limit, resulting in a unique nonlocal Fano resonance due to the\ninteraction between the resonance and background transmission facilitated by\ndumbbell holes. Furthermore, the Fano transmission peak corresponds to an\nanapole excitation, revealed by multipole calculations. Benefiting from the\nability to control the Fano resonance with no symmetry breaking, the proposed\nhybrid THz metasurface will advance broad applications in the fields of\nsensors, optical switches, and tunable filters."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-557",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18619",
    "b_title":[
      "The Offended Voter Model"
    ],
    "b_abstract":[
      "We study a variant of the voter model on a coevolving network in which\ninteractions of two individuals with differing opinions only lead to an\nagreement on one of these opinions with a fixed probability $q$. Otherwise,\nwith probability $1-q$, both individuals become offended in the sense that they\nnever interact again, i.e.\\ the corresponding edge is removed from the\nunderlying network. Eventually, these dynamics reach an absorbing state at\nwhich there is only one opinion present in each connected component of the\nnetwork. If globally both opinions are present at absorption we speak of\n``segregation'', otherwise of ``consensus''. We rigorously show that\nsegregation and a weaker form of consensus both occur with positive probability\nfor every $q \\in (0,1)$ and that the segregation probability tends to $1$ as $q\n\\to 0$. Furthermore, we establish that, if $q \\to 1$ fast enough, with high\nprobability the population reaches consensus while the underlying network is\nstill densely connected. We provide results from simulations to assess the\nobtained bounds and to discuss further properties of the limiting state."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.04210",
    "c_title":[
      "Generalized Kac's moment formula for positive continuous additive\n  functionals of symmetric Markov processes"
    ],
    "c_abstract":[
      "We establish a formula for moments of certain random variables involving\npositive continuous additive functionals of symmetric Hunt processes whose\nDirichlet forms are regular, generalizing the classical Kac's moment formula."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-558",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12931",
    "b_title":[
      "Delta-function-potential junctions with quasiparticles occupying tilted\n  bands with quadratic-in-momentum dispersion"
    ],
    "b_abstract":[
      "We continue our explorations of the transport characteristics in\njunction-configurations comprising semimetals with quadratic band-crossings,\nobserved in the bandstructures of both two- and three-dimensional materials.\nHere, we consider short potential barriers\/wells modelled by delta-function\npotentials. We also generalize our analysis by incorporating tilts in the\ndispersion. Due to the parabolic nature of the spectra, caused by\nquadratic-in-momentum dependence, there exist evanescent waves, which decay\nexponentially as we move away from the junction represented by the location of\nthe delta-function potential. Investigating the possibility of the appearance\nof bound states, we find that their energies appear as pairs of $\\pm |E_b |$,\nreflecting the presence of the imaginary-valued wavevectors at both positive\nand negative values of energies of the propagating quasiparticles."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.18255",
    "c_title":[
      "Large frequency nonreciprocity of azimuthal spin wave modes in submicron\n  vortex state disks"
    ],
    "c_abstract":[
      "Vortex states in thin film disks host spin wave modes that are geometrically\nquantized according to their radial and azimuthal indices. Previous studies\nhave shown that hybridization between these modes and the vortex core results\nin a sizeable frequency nonreciprocity between low-order clockwise and\ncounterclockwise propagating azimuthal modes. Here, we present a computational\nstudy of these spin wave modes in submicron disks in which the spatial\nextension of the vortex core becomes comparable to the wavelength of certain\nmodes. In such cases, we find that the frequency nonreciprocity can be large\neven for higher order radial and azimuthal indices, reaching several GHz and\ncomparable to the mode frequencies themselves."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-559",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10441",
    "b_title":[
      "Transit Timing Variations of the Sub-Saturn Exoplanet HAT-P-12b"
    ],
    "b_abstract":[
      "We present Transit Timing Variations (TTVs) of HAT-P-12b, a low-density\nsub-Saturn mass planet orbiting a metal-poor K4 dwarf star. Using 14 years of\nobservational data (2009-2022), our study incorporates 7 new ground-based\nphotometric transit observations, three sectors of Transiting Exoplanet Survey\nSatellite (TESS) data, and 23 previously published light curves. A total of 46\nlight curves were analyzed using various analytical models, such as linear,\norbital decay, apsidal precession, and sinusoidal models to investigate the\npresence of additional planets. The stellar tidal quality factor ($Q_\\star'\n\\sim$ 28.4) is lower than the theoretical predictions, making the orbital decay\nmodel an unlikely explanation. The apsidal precession model with a $\\chi_r^2$\nof 4.2 revealed a slight orbital eccentricity (e = 0.0013) and a precession\nrate of 0.0045 rad\/epoch. Frequency analysis using the Generalized Lomb-Scargle\n(GLS) periodogram identified a significant periodic signal at 0.00415\ncycles\/day (FAP = 5.1$\\times$10$^{-6}$ %), suggesting the influence of an\nadditional planetary companion. The sinusoidal model provides the lowest\nreduced chi-squared value ($\\chi_r^2$) of 3.2. Sinusoidal fitting of the timing\nresiduals estimated this companion to have a mass of approximately 0.02 $M_J$ ,\nassuming it is in a 2:1 Mean-Motion Resonance (MMR) with HAT-P-12b.\nAdditionally, the Applegate mechanism, with an amplitude much smaller than the\nobserved TTV amplitude of 156 s, confirms that stellar activity is not\nresponsible for the observed variations."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04524",
    "c_title":[
      "Near-infrared spectroscopic characterization of the Pallas family"
    ],
    "c_abstract":[
      "The Pallas collisional family of asteroids, named after (2) Pallas, is\nnotable for its high orbital inclination and the distinct blue color of Pallas\nand a few larger B-type family members. While Pallas itself, as one of the\nlargest asteroids, has been studied in detail, most of its smaller family\nmembers still remain unexplored. This study aims to characterize the physical\nproperties of medium- to small-sized Pallas family asteroids to investigate the\norigin of their unusual blueness. Additionally, we explore the relationship\nbetween the Pallas family and the near-Earth object (NEO) (3200) Phaethon. We\nconducted near-infrared (NIR) spectroscopy with the NASA Infrared Telescope\nFacility (IRTF) to collect reflectance spectra for 22 asteroids, including one\nfrom the IRTF Legacy Archive. Spectroscopic and dynamical analyses were carried\nout to identify outliers, while additional data from NEOWISE and Gaia were\nincorporated to examine potential correlations among their physical properties.\nMeteorite analogs were identified through chi-square matching using samples\nfrom the RELAB database. The observed Pallas family asteroids exhibit nearly\nidentical spectral profiles, suggesting a homogeneous composition of ejected\nmaterial. Small variations in spectral slopes are observed, which may result\nfrom different levels of alteration experienced by individual asteroids, with\nsome influence from variations in grain size. Most of the observed spectra of\nthe Pallas asteroids, from 0.8 to 2.2 micron, closely resemble those of the CY\nand CI meteorites. The blueness of asteroid surfaces is likely due to the\npresence of magnetite, troilite, or phyllosilicates, which are products of\naqueous alteration. The striking spectral similarity between (3200) Phaethon\nand Pallas family members of comparable sizes suggests a potential common\norigin."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-560",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03661",
    "b_title":[
      "Bridging high resolution sub-cellular imaging with physiologically\n  relevant engineered tissues"
    ],
    "b_abstract":[
      "While high-resolution microscopic techniques are crucial for studying\ncellular structures in cell biology, obtaining such images from thick 3D\nengineered tissues remains challenging. In this review, we explore advancements\nin fluorescence microscopy, alongside the use of various fluorescent probes and\nmaterial processing techniques to address these challenges. We navigate through\nthe diverse array of imaging options available in tissue engineering field,\nfrom wide field to super-resolution microscopy, so researchers can make more\ninformed decisions based on the specific tissue and cellular structures of\ninterest. Finally, we provide some recent examples of how traditional\nlimitations on obtaining high-resolution images on sub-cellular architecture\nwithin 3D tissues have been overcome by combining imaging advancements with\ninnovative tissue engineering approaches."
    ],
    "b_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2502.11130",
    "c_title":[
      "Advanced 3D-Printed Multiphasic Scaffold with Optimal PRP Dosage for\n  Chondrogenesis of BM-MSCs in Osteochondral Tissue Engineering"
    ],
    "c_abstract":[
      "In osteochondral tissue engineering (OCTE), simultaneously regenerating\nsubchondral bone and cartilage tissue presents a significant challenge.\nMultiphasic scaffolds were created and manufactured using 3D printing to\naddress this issue. Excellent interfacial mechanical properties and\nbiocompatibility enhance the growth and chondrogenic differentiation of bone\nmarrow mesenchymal stem cells (BM-MSCs). The subchondral bone bottom layer is\nmimicked by incorporating varying concentrations of graphene oxide (GO) (0%,\n1%, and 2% w\/v) into a bioink composed of alginate (Alg) and gelatin (Gel).\nBased on evaluations of mechanical and biocompatibility properties, 1% GO is\nselected for further studies. Subsequently, the GO concentration is kept\nconstant while varying the platelet-rich plasma (PRP) dosage in the multiphasic\nscaffolds. Different PRP dosages (0%, 1%, 2%, and 3% w\/v) are integrated into\nthe Alg-Gel bioink to simulate cartilage tissues. Results indicate that\n3D-printed scaffolds containing 1% or 2% PRP exhibit favorable biomechanical\nproperties, with no significant differences observed. However, BM-MSCs exposed\nto 2% PRP demonstrate enhanced adhesion, growth, and viability. Additionally,\nreal-time PCR and Alcian blue staining confirm increased chondrogenic\nexpression and glycosaminoglycans (GAGs) synthesis. This work highlights the\npromising potential of 3D-printed multiphasic frameworks in the development of\nOCTE."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-561",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00337",
    "b_title":[
      "Efficient calculation of phonon dynamics through a low-rank solution of\n  the Boltzmann equation"
    ],
    "b_abstract":[
      "Exotic nondiffusive heat transfer regimes such as the second sound, where\nheat propagates as a damped wave at speeds comparable to those of mechanical\ndisturbances, often occur at cryogenic temperatures (T) and nanosecond\ntimescales in semiconductors. First-principles prediction of such rapid, low-T\nphonon dynamics requires finely-resolved temporal tracking of large, dense, and\ncoupled linear phonon dynamical systems arising from the governing linearized\nPeierls-Boltzmann equation (LPBE). Here, we uncover a rigorous low-rank\nrepresentation of these linear dynamical systems, derived from the spectral\nproperties of the phonon collision matrix, that accelerates the\nfirst-principles prediction of phonon dynamics by a factor of over a million\nwithout compromising on the computational accuracy. By employing this low-rank\nrepresentation of the LPBE, we predict strong amplification of the wave-like\nsecond sound regime upon isotopic enrichment in diamond - a finding that would\nhave otherwise been computationally intractable using the conventional\nbrute-force approaches. Our framework enables a rapid and accurate discovery of\nthe conditions under which wave-like heat flow can be realized in common\nsemiconductors."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.07951",
    "c_title":[
      "Symmetry and Minimal Hamiltonian of Nonsymmorphic Collinear\n  Antiferromagnet MnTe"
    ],
    "c_abstract":[
      "$\\alpha$-MnTe, an $A$-type collinear antiferromagnet, has recently attracted\nsignificant attention due to its pronounced spin splitting despite having net\nzero magnetization, a phenomenon unique for a new class of magnetism dubbed\naltermagnetism. In this work, we develop a minimal effective Hamiltonian for\n$\\alpha$-MnTe based on realistic orbitals near the Fermi level at both the\n$\\Gamma$ and $A$ points. Our model is derived using group representation\ntheory, first-principles calculations, and tight-binding modeling. The\nresulting effective Hamiltonian exhibits qualitatively distinct electron\ntransport characteristics between these high-symmetry points and for different\nin-plane N\\'{e}el vector orientations along the $[11\\bar{2}0]$ and\n$[1\\bar{1}00]$ directions. Although relativistic correction of the spin-orbit\ncoupling (SOC) is believed to be not important in altermagnets, we show the\ndominant role of SOC in the spin splitting and valence electrons of MnTe. These\nfindings provide critical insights into altermagnetic electron transport in\nMnTe and establish a model playground for future theoretical and experimental\nstudies."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-562",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15687",
    "b_title":[
      "On conservative algebras of 2-dimensional Algebras"
    ],
    "b_abstract":[
      "In 1990 Kantor introduced the conservative algebra $\\mathcal{W}(n)$ of all\nalgebras (i.e. bilinear maps) on the $n$-dimensional vector space. In case $n\n>1$ the algebra $\\mathcal{W}(n)$ does not belong to well known classes of\nalgebras (such as associative, Lie, Jordan, Leibniz algebras). We describe\n$\\frac{1}{2}$derivations, local (resp. $2$-local) $\\frac{1}{2}$-derivations and\nbiderivations of $\\mathcal{W}(2)$. We also study similar problems for the\nalgebra $\\mathcal{W}_2$ of all commutative algebras on the two-dimensional\nvector space and the algebra $\\mathcal{S}_2$ of all commutative algebras with\ntrace zero multiplication on the two-dimensional space."
    ],
    "b_categories":[
      [
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.10495",
    "c_title":[
      "Cohomology and deformations of nonabelian embedding tensors between Lie\n  triple systems"
    ],
    "c_abstract":[
      "In this paper, first we introduce the notion of nonabelian embedding tensors\nbetween Lie triple systems and show that nonabelian embedding tensors induce\nnaturally 3-Leibniz algebras. Next, we construct an $L_{\\infty}$-algebra whose\nMaurer-Cartan elements are nonabelian embedding tensors. Then, we have the\ntwisted $L_{\\infty}$-algebra that governs deformations of nonabelian embedding\ntensors. Following this, we establish the cohomology of a nonabelian embedding\ntensor between Lie triple systems and realize it as the cohomology of the\ndescendent 3-Leibniz algebra with coefficients in a suitable representation. As\napplications, we consider infinitesimal deformations of a nonabelian embedding\ntensor between Lie triple systems and demonstrate that they are governed by the\nabove-established cohomology. Furthermore, the notion of Nijenhuis elements\nassociated with a nonabelian embedding tensor is introduced to characterize\ntrivial infinitesimal deformations. Finally, we provide relationships between\nnonabelian embedding tensors on Lie algebras and associated Lie triple systems."
    ],
    "c_categories":[
      [
        "math.RA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-563",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16924",
    "b_title":[
      "FilterLLM: Text-To-Distribution LLM for Billion-Scale Cold-Start\n  Recommendation"
    ],
    "b_abstract":[
      "Large Language Model (LLM)-based cold-start recommendation systems continue\nto face significant computational challenges in billion-scale scenarios, as\nthey follow a \"Text-to-Judgment\" paradigm. This approach processes user-item\ncontent pairs as input and evaluates each pair iteratively. To maintain\nefficiency, existing methods rely on pre-filtering a small candidate pool of\nuser-item pairs. However, this severely limits the inferential capabilities of\nLLMs by reducing their scope to only a few hundred pre-filtered candidates. To\novercome this limitation, we propose a novel \"Text-to-Distribution\" paradigm,\nwhich predicts an item's interaction probability distribution for the entire\nuser set in a single inference. Specifically, we present FilterLLM, a framework\nthat extends the next-word prediction capabilities of LLMs to billion-scale\nfiltering tasks. FilterLLM first introduces a tailored distribution prediction\nand cold-start framework. Next, FilterLLM incorporates an efficient\nuser-vocabulary structure to train and store the embeddings of billion-scale\nusers. Finally, we detail the training objectives for both distribution\nprediction and user-vocabulary construction. The proposed framework has been\ndeployed on the Alibaba platform, where it has been serving cold-start\nrecommendations for two months, processing over one billion cold items.\nExtensive experiments demonstrate that FilterLLM significantly outperforms\nstate-of-the-art methods in cold-start recommendation tasks, achieving over 30\ntimes higher efficiency. Furthermore, an online A\/B test validates its\neffectiveness in billion-scale recommendation systems."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11374",
    "c_title":[
      "Leave No One Behind: Enhancing Diversity While Maintaining Accuracy in\n  Social Recommendation"
    ],
    "c_abstract":[
      "Social recommendation, which incorporates social connections into recommender\nsystems, has proven effective in improving recommendation accuracy. However,\nbeyond accuracy, diversity is also crucial for enhancing user engagement.\nDespite its importance, the impact of social recommendation models on diversity\nremains largely unexplored. In this study, we systematically examine the dual\nperformance of existing social recommendation algorithms in terms of both\naccuracy and diversity. Our empirical analysis reveals a concerning trend:\nwhile social recommendation models enhance accuracy, they often reduce\ndiversity. To address this issue, we propose Diversified Social Recommendation\n(DivSR), a novel approach that employs relational knowledge distillation to\ntransfer high-diversity structured knowledge from non-social recommendation\nmodels to social recommendation models. DivSR is a lightweight, model-agnostic\nframework that seamlessly integrates with existing social recommendation\narchitectures. Experiments on three benchmark datasets demonstrate that DivSR\nsignificantly enhances diversity while maintaining competitive accuracy,\nachieving a superior accuracy-diversity trade-off. Our code and data are\npublicly available at: https:\/\/github.com\/ll0ruc\/DivSR."
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-564",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09103",
    "b_title":[
      "VaxGuard: A Multi-Generator, Multi-Type, and Multi-Role Dataset for\n  Detecting LLM-Generated Vaccine Misinformation"
    ],
    "b_abstract":[
      "Recent advancements in Large Language Models (LLMs) have significantly\nimproved text generation capabilities. However, they also present challenges,\nparticularly in generating vaccine-related misinformation, which poses risks to\npublic health. Despite research on human-authored misinformation, a notable gap\nremains in understanding how LLMs contribute to vaccine misinformation and how\nbest to detect it. Existing benchmarks often overlook vaccine-specific\nmisinformation and the diverse roles of misinformation spreaders. This paper\nintroduces VaxGuard, a novel dataset designed to address these challenges.\nVaxGuard includes vaccine-related misinformation generated by multiple LLMs and\nprovides a comprehensive framework for detecting misinformation across various\nroles. Our findings show that GPT-3.5 and GPT-4o consistently outperform other\nLLMs in detecting misinformation, especially when dealing with subtle or\nemotionally charged narratives. On the other hand, PHI3 and Mistral show lower\nperformance, struggling with precision and recall in fear-driven contexts.\nAdditionally, detection performance tends to decline as input text length\nincreases, indicating the need for improved methods to handle larger content.\nThese results highlight the importance of role-specific detection strategies\nand suggest that VaxGuard can serve as a key resource for improving the\ndetection of LLM-generated vaccine misinformation."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06040",
    "c_title":[
      "Mitigating Memorization in LLMs using Activation Steering"
    ],
    "c_abstract":[
      "The memorization of training data by Large Language Models (LLMs) poses\nsignificant risks, including privacy leaks and the regurgitation of copyrighted\ncontent. Activation steering, a technique that directly intervenes in model\nactivations, has emerged as a promising approach for manipulating LLMs. In this\nwork, we explore the effectiveness of activation steering in reducing\nmemorization while preserving generalization capabilities. We conduct empirical\nevaluations using a controlled memorization benchmark of literary material and\ndemonstrate that our method successfully suppresses memorized content with\nminimal degradation in model performance in Gemma. Additionally, we analyze the\ntrade-offs between suppression effectiveness and linguistic fluency,\nhighlighting the advantages and limitations of activation-based interventions.\nOur findings contribute to ongoing efforts in developing safer and more\nprivacy-preserving LLMs by providing a practical and efficient mechanism to\nmitigate unintended memorization."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-565",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15145",
    "b_title":[
      "PromptShield: Deployable Detection for Prompt Injection Attacks"
    ],
    "b_abstract":[
      "Current application designers have moved to integrate large language models\n(LLMs) into their products. These LLM-integrated applications are vulnerable to\nprompt injection vulnerabilities. While attempts have been made to address this\nproblem by building a detector that can monitor inputs to the LLM and detect\nattacks, we find that many detectors are not yet suitable for practical\ndeployment. To support research in this area, we design the PromptShield\nbenchmark for evaluating practical prompt injection detectors. We also\nconstruct a new detector, the PromptShield detector, which achieves\nsignificantly better performance at detecting prompt injection attacks than any\nprior scheme. Our work suggests that larger models, more training data,\nappropriate metrics, and careful curation of training data can contribute to\nstrong detector performance."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.16177",
    "c_title":[
      "A Review of Several Keystroke Dynamics Methods"
    ],
    "c_abstract":[
      "Keystroke dynamics is a behavioral biometric that captures an individual's\ntyping patterns for authentication and security applications. This paper\npresents a comparative analysis of keystroke authentication models using\nGaussian Mixture Models (GMM), Mahalanobis Distance-based Classification, and\nGunetti Picardi's Distance Metrics. These models leverage keystroke timing\nfeatures such as hold time (H), up-down time (UD), and down-down time (DD)\nextracted from datasets including Aalto, Buffalo and Nanglae-Bhattarakosol.\nEach model is trained and validated using structured methodologies, with\nperformance evaluated through False Acceptance Rate (FAR), False Rejection Rate\n(FRR), and Equal Error Rate (EER). The results, visualized through Receiver\nOperating Characteristic (ROC) curves, highlight the relative strengths and\nweaknesses of each approach in distinguishing genuine users from impostors."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-566",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11333",
    "b_title":[
      "Manipulation of Majorana wave packets at surfaces of nodal\n  noncentrosymmetric superconductors"
    ],
    "b_abstract":[
      "Nodal noncentrosymmetric superconductors can host zero-energy flat bands of\nMajorana surface states within the projection of the nodal lines onto the\nsurface Brillouin zone. Thus, these systems can have stationary, localized\nMajorana wave packets on certain surfaces, which may be a promising platform\nfor quantum computation. Such applications require protocols to manipulate the\nwave packets in order to move them without destroying their localization or\ncoherence. As a step in this direction, we explore the idea that the surface\nstates have a nontrivial spin polarization, which can couple for example to the\nmagnetization of a ferromagnetic insulator in contact to the surface, via an\nexchange term in the Hamiltonian. Such a coupling can make the previously flat\nbands weakly dispersive. We aim to model the motion of spatially localized wave\npackets under the influence of an exchange field which is changed\nadiabatically. We calculate the time-evolved wave packet for a model system and\ndiscuss which factors influence the direction of motion and the broadening of\nthe wave packet."
    ],
    "b_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.02779",
    "c_title":[
      "Selective electron-phonon coupling strength from nonequilibrium optical\n  spectroscopy: The case of MgB$_2$"
    ],
    "c_abstract":[
      "The coupling between quasiparticles and bosonic excitations rules the energy\ntransfer pathways in condensed matter systems. The possibility of inferring the\nstrength of specific coupling channels from their characteristic time scales\nmeasured in nonequilibrium experiments is still an open question. Here, we\ninvestigate MgB$_2$, in which conventional superconductivity at temperatures as\nhigh as 39 K is mediated by the strong coupling between the conduction\nelectrons and the E$_{2g}$ phonon mode. By means of broadband time-resolved\noptical spectroscopy, we show that this selective electron-phonon coupling\ndictates the nonequilibrium optical response of MgB$_2$ at early times (<100\nfs) after photoexcitation. Furthermore, based on an effective temperature model\nanalysis, we estimate its contribution to the total electron-boson coupling\nfunction extracted from complementary equilibrium spectroscopy approaches,\nnamely optical reflectivity and ARPES. The coupling strength with the E$_{2g}$\nphonon modes is thus estimated to be $\\lambda$ ~ 0.56, which is approximately\nhalf of the total coupling constant, in agreement with ab-initio calculations\nfrom the literature. As a benchmark, broadband time-resolved optical\nspectroscopy is performed also on the isostructural and non-superconducting\ncompound AlB$_2$, showing that the nonequilibrium optical response relaxes on a\nslower timescale due to the lack of strongly-coupled phonon modes. Our findings\ndemonstrate the possibility to resolve and quantify selective electron-phonon\ncoupling from nonequilibrium optical spectroscopy."
    ],
    "c_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-567",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08837",
    "b_title":[
      "MANTA: Diffusion Mamba for Efficient and Effective Stochastic Long-Term\n  Dense Anticipation"
    ],
    "b_abstract":[
      "Long-term dense action anticipation is very challenging since it requires\npredicting actions and their durations several minutes into the future based on\nprovided video observations. To model the uncertainty of future outcomes,\nstochastic models predict several potential future action sequences for the\nsame observation. Recent work has further proposed to incorporate uncertainty\nmodelling for observed frames by simultaneously predicting per-frame past and\nfuture actions in a unified manner. While such joint modelling of actions is\nbeneficial, it requires long-range temporal capabilities to connect events\nacross distant past and future time points. However, the previous work\nstruggles to achieve such a long-range understanding due to its limited and\/or\nsparse receptive field. To alleviate this issue, we propose a novel MANTA\n(MAmba for ANTicipation) network. Our model enables effective long-term\ntemporal modelling even for very long sequences while maintaining linear\ncomplexity in sequence length. We demonstrate that our approach achieves\nstate-of-the-art results on three datasets - Breakfast, 50Salads, and\nAssembly101 - while also significantly improving computational and memory\nefficiency. Our code is available at https:\/\/github.com\/olga-zats\/DIFF_MANTA ."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03410",
    "c_title":[
      "ScaleMAI: Accelerating the Development of Trusted Datasets and AI Models"
    ],
    "c_abstract":[
      "Building trusted datasets is critical for transparent and responsible Medical\nAI (MAI) research, but creating even small, high-quality datasets can take\nyears of effort from multidisciplinary teams. This process often delays AI\nbenefits, as human-centric data creation and AI-centric model development are\ntreated as separate, sequential steps. To overcome this, we propose ScaleMAI,\nan agent of AI-integrated data curation and annotation, allowing data quality\nand AI performance to improve in a self-reinforcing cycle and reducing\ndevelopment time from years to months. We adopt pancreatic tumor detection as\nan example. First, ScaleMAI progressively creates a dataset of 25,362 CT scans,\nincluding per-voxel annotations for benign\/malignant tumors and 24 anatomical\nstructures. Second, through progressive human-in-the-loop iterations, ScaleMAI\nprovides Flagship AI Model that can approach the proficiency of expert\nannotators (30-year experience) in detecting pancreatic tumors. Flagship Model\nsignificantly outperforms models developed from smaller, fixed-quality\ndatasets, with substantial gains in tumor detection (+14%), segmentation (+5%),\nand classification (72%) on three prestigious benchmarks. In summary, ScaleMAI\ntransforms the speed, scale, and reliability of medical dataset creation,\npaving the way for a variety of impactful, data-driven applications."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-568",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03125",
    "b_title":[
      "On the renormalization of ultraviolet divergences in the inflationary\n  angular power spectrum"
    ],
    "b_abstract":[
      "We revise the role that ultraviolet divergences of quantum fields play in\nslow-roll inflation, and discuss the renormalization of cosmological\nobservables from a space-time perspective, namely the angular power spectrum.\nWe first derive an explicit expression for the multipole coefficients\n$C_{\\ell}$ in the Sachs-Wolfe regime in terms of the two-point function of\nprimordial perturbations. We then analyze the ultraviolet behavior, and point\nout that the standard result in the literature is equivalent to a\nrenormalization of $C_{\\ell}$ at zero ``adiabatic'' order. We further argue\nthat renormalization at second ``adiabatic'' order may be more appropriate from\nthe viewpoint of standard quantum field theory. This may change significantly\nthe predictions for $C_{\\ell}$, while maintaining scale invariance."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.02350",
    "c_title":[
      "Testing the behaviour of exotic matter near wormhole throat in $f(R,T)$\n  gravity"
    ],
    "c_abstract":[
      "In this paper, I propose a static wormhole model within modified $f(R,T)$\ngravity where $f(R,T)=R+2\\lambda T$. The wormhole solutions have been evolved\nin four cases: three different shape function along with redshift\n$\\phi=\\frac{\\phi_0}{r}$ and a variable EoS parameter $\\omega(r)$ with constant\nredshift function. I also have explored the energy conditions and the behaviour\nof exotic matter within the wormhole in all scenarios. Presence of exotic\nmatter violates necessary energy conditions near wormhole throat which gives\nconstraint on modified gravity parameter $\\lambda$ in all different cases."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-569",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16832",
    "b_title":[
      "FedBM: Stealing Knowledge from Pre-trained Language Models for\n  Heterogeneous Federated Learning"
    ],
    "b_abstract":[
      "Federated learning (FL) has shown great potential in medical image computing\nsince it provides a decentralized learning paradigm that allows multiple\nclients to train a model collaboratively without privacy leakage. However,\ncurrent studies have shown that data heterogeneity incurs local learning bias\nin classifiers and feature extractors of client models during local training,\nleading to the performance degradation of a federation system. To address these\nissues, we propose a novel framework called Federated Bias eliMinating (FedBM)\nto get rid of local learning bias in heterogeneous federated learning (FL),\nwhich mainly consists of two modules, i.e., Linguistic Knowledge-based\nClassifier Construction (LKCC) and Concept-guided Global Distribution\nEstimation (CGDE). Specifically, LKCC exploits class concepts, prompts and\npre-trained language models (PLMs) to obtain concept embeddings. These\nembeddings are used to estimate the latent concept distribution of each class\nin the linguistic space. Based on the theoretical derivation, we can rely on\nthese distributions to pre-construct a high-quality classifier for clients to\nachieve classification optimization, which is frozen to avoid classifier bias\nduring local training. CGDE samples probabilistic concept embeddings from the\nlatent concept distributions to learn a conditional generator to capture the\ninput space of the global model. Three regularization terms are introduced to\nimprove the quality and utility of the generator. The generator is shared by\nall clients and produces pseudo data to calibrate updates of local feature\nextractors. Extensive comparison experiments and ablation studies on public\ndatasets demonstrate the superior performance of FedBM over state-of-the-arts\nand confirm the effectiveness of each module, respectively. The code is\navailable at https:\/\/github.com\/CUHK-AIM-Group\/FedBM."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10259",
    "c_title":[
      "MITO: A Millimeter-Wave Dataset and Simulator for Non-Line-of-Sight\n  Perception"
    ],
    "c_abstract":[
      "The ability to observe the world is fundamental to reasoning and making\ninformed decisions on how to interact with the environment. However, optical\nperception can often be disrupted due to common occurrences, such as\nocclusions, which can pose challenges to existing vision systems. We present\nMITO, the first millimeter-wave (mmWave) dataset of diverse, everyday objects,\ncollected using a UR5 robotic arm with two mmWave radars operating at different\nfrequencies and an RGB-D camera. Unlike visible light, mmWave signals can\npenetrate common occlusions (e.g., cardboard boxes, fabric, plastic) but each\nmmWave frame has much lower resolution than typical cameras. To capture\nhigher-resolution mmWave images, we leverage the robot's mobility and fuse\nframes over the synthesized aperture. MITO captures over 24 million mmWave\nframes and uses them to generate 550 high-resolution mmWave (synthetic\naperture) images in line-of-sight and non-light-of-sight (NLOS), as well as\nRGB-D images, segmentation masks, and raw mmWave signals, taken from 76\ndifferent objects. We develop an open-source simulation tool that can be used\nto generate synthetic mmWave images for any 3D triangle mesh. Finally, we\ndemonstrate the utility of our dataset and simulator for enabling broader NLOS\nperception by developing benchmarks for NLOS segmentation and classification."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-570",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13169",
    "b_title":[
      "Global Turbulent Solar Convection: a Numerical Path Investigating Key\n  Force Balances in the context of the Convective Conundrum"
    ],
    "b_abstract":[
      "Understanding solar turbulent convection and its influence on differential\nrotation has been a challenge over the past two decades. Current models often\noverestimate giant convection cells amplitude, leading to an effective Rossby\nnumber too large and a shift towards an anti-solar rotation regime. This\nConvective Conundrum, underscores the need for improved comprehension of solar\nconvective dynamics. We propose a numerical experiment in the parameter space\nthat controls $Ro$ while increasing the Reynolds number ($Re$) and maintaining\nsolar parameters. By controlling the Nusselt number ($Nu$), we limit the energy\ntransport by convection while reducing viscous dissipation. This approach\nenabled us to construct a Sun-like rotating model (SBR97n035) with strong\nturbulence ($Re \\sim 800$) that exhibits prograde equatorial rotation and\naligns with observational data from helioseismology. We compare this model with\nan anti-solar rotating counterpart, and provide an in-depth spectral analysis\nto investigate the changes in convective dynamics. We also find the appearance\nof vorticity rings near the poles, which existence on the Sun could be probed\nin the future. The Sun-like model shows reduced buoyancy over the spectrum, as\nwell as an extended quasi-geostrophic equilibrium towards smaller scales. This\npromotes a Coriolis-Inertia (CI) balance rather than a\nCoriolis-Inertia-Archimedes (CIA) balance, in order to favor the establishment\nof a prograde equator. The presence of convective columns in the bulk of the\nconvection zone, with limited surface manifestations, also hints at such\nstructures potentially occurring in the Sun."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.19011",
    "c_title":[
      "The dynamics of small-scale magnetic fields modulated by the solar cycle"
    ],
    "c_abstract":[
      "In addition to sunspots, which represent the most easily visualized\nmanifestation of solar magnetism, cutting-edge observations of the solar\natmosphere have uncovered a plethora of magnetic flux tubes, down to the\nresolving power of modern high-resolution telescopes (a few tens of km),\nrevealing how the Sun is a fully magnetized star. These magnetic elements are\nadvected and buffeted by ambient plasma flows and turbulent convection,\nresulting in perturbations of the flux tubes that make them natural conduits\nfor channeling wave energy into the upper layers of the Sun's atmosphere and\nsignificantly contributing to the acceleration of the solar wind. Today, data\nacquired by the Helioseismic and Magnetic Imager (HMI) onboard NASA's Solar\nDynamics Observatory (SDO), have made it possible to study the dynamics of\nsmall-scale magnetic fields over long timescales. Here, for the first time, we\npresent the discovery of a modulation in the dynamical behavior of small-scale\nmagnetic concentrations in the photosphere over temporal scales consistent with\nthe solar activity cycle (i.e. 11 years), which has only been made possible by\nthe long observing lifetime of the SDO\/HMI spacecraft. Furthermore, a temporal\nvarying polarization of their perturbations is also found on similar\ntimescales. This demonstrates how the small-scale dynamics of magnetic fields\nare also affected by the global dynamo. These discoveries were realized through\nautomated tracking of magnetic fields in the solar photosphere across 11\ncontinuous years, resulting in the most extended statistical analyses of its\nkind so far, with more than 31 million magnetic concentrations examined."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-571",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17407",
    "b_title":[
      "Time dispersion in bound states"
    ],
    "b_abstract":[
      "In quantum mechanics time is generally treated as a parameter rather than an\nobservable. For instance wave functions are treated as extending in space, but\nnot in time. But from relativity we expect time and space should be treated on\nthe same basis. What are the effects if time is an observable? Are these\neffects observable with current technology?\n  In earlier work we showed we should see effects in various high energy\nscattering processes. We here extend that work to include bound states. The\ncritical advantage of working with bound states is that the predictions are\nsignificantly more definite, taking the predictions from testable to\nfalsifiable.\n  We estimate the time dispersion for hydrogen as $.177$ attoseconds, possibly\nbelow the current threshold for detection. But the time dispersion should scale\nas the $3\/2$ power of the principle quantum number $n$. Rydberg atoms can have\n$n$ of order $100$, implying a boost by a factor of $1000$. This takes the the\ntime dispersion to $177$ attoseconds, well within reach of current technology.\n  There are a wide variety of experimental targets: any time-dependent\nprocesses should show effects. Falsification will be technically challenging\n(due to the short time scales) but immediate and unambiguous. Confirmation\nwould have significant implications for attosecond physics, quantum computing\nand communications, quantum gravity, and the measurement problem. And would\nsuggest practical uses in these areas as well as circuit design, high speed\nbiochemistry, cryptography, fusion research, and any area involving change at\nattosecond time scales."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02698",
    "c_title":[
      "Chaos in a Nonlinear Wavefunction Model: An Alternative to Born's\n  Probability Hypothesis"
    ],
    "c_abstract":[
      "In a prior paper, the author described an instability in a nonlinear\nwavefunction model. Proposed in connection with the Measurement Problem, the\nmodel contained an external potential creating a ``classical'' instability.\nHowever, it is interesting to ask whether such models possess an intrinsic\nrandomness -- even ``chaos\" -- independent of external potentials. In this\nwork, I investigate the criterion analytically and simulate from a small (``3\nqubit\") model, demonstrating that the Lyapunov exponent -- a standard measure\nof ``chaos\" -- is positive. I also extend the instability criterion to models\nin the continuum. These results suggest that the boundary between classical and\nwavefunction physics may also constitute the threshold of chaos, and present an\nalternative to Max Born's ad hoc probability hypothesis: random outcomes in\nexperiments result not from ``wave-particle duality\" or ``the existence of the\nquantum,\" but from sensitive dependence on initial conditions, as is common in\nthe other sciences."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-572",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12150",
    "b_title":[
      "DNRSelect: Active Best View Selection for Deferred Neural Rendering"
    ],
    "b_abstract":[
      "Deferred neural rendering (DNR) is an emerging computer graphics pipeline\ndesigned for high-fidelity rendering and robotic perception. However, DNR\nheavily relies on datasets composed of numerous ray-traced images and demands\nsubstantial computational resources. It remains under-explored how to reduce\nthe reliance on high-quality ray-traced images while maintaining the rendering\nfidelity. In this paper, we propose DNRSelect, which integrates a reinforcement\nlearning-based view selector and a 3D texture aggregator for deferred neural\nrendering. We first propose a novel view selector for deferred neural rendering\nbased on reinforcement learning, which is trained on easily obtained rasterized\nimages to identify the optimal views. By acquiring only a few ray-traced images\nfor these selected views, the selector enables DNR to achieve high-quality\nrendering. To further enhance spatial awareness and geometric consistency in\nDNR, we introduce a 3D texture aggregator that fuses pyramid features from\ndepth maps and normal maps with UV maps. Given that acquiring ray-traced images\nis more time-consuming than generating rasterized images, DNRSelect minimizes\nthe need for ray-traced data by using only a few selected views while still\nachieving high-fidelity rendering results. We conduct detailed experiments and\nablation studies on the NeRF-Synthetic dataset to demonstrate the effectiveness\nof DNRSelect. The code will be released."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16239",
    "c_title":[
      "Distilling foundation models for robust and efficient models in digital\n  pathology"
    ],
    "c_abstract":[
      "In recent years, the advent of foundation models (FM) for digital pathology\nhas relied heavily on scaling the pre-training datasets and the model size,\nyielding large and powerful models. While it resulted in improving the\nperformance on diverse downstream tasks, it also introduced increased\ncomputational cost and inference time. In this work, we explore the\ndistillation of a large foundation model into a smaller one, reducing the\nnumber of parameters by several orders of magnitude. Leveraging distillation\ntechniques, our distilled model, H0-mini, achieves nearly comparable\nperformance to large FMs at a significantly reduced inference cost. It is\nevaluated on several public benchmarks, achieving 3rd place on the HEST\nbenchmark and 5th place on the EVA benchmark. Additionally, a robustness\nanalysis conducted on the PLISM dataset demonstrates that our distilled model\nreaches excellent robustness to variations in staining and scanning conditions,\nsignificantly outperforming other state-of-the art models. This opens new\nperspectives to design lightweight and robust models for digital pathology,\nwithout compromising on performance."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-573",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17549",
    "b_title":[
      "Query-Aware Learnable Graph Pooling Tokens as Prompt for Large Language\n  Models"
    ],
    "b_abstract":[
      "Graph-structured data plays a vital role in numerous domains, such as social\nnetworks, citation networks, commonsense reasoning graphs and knowledge graphs.\nWhile graph neural networks have been employed for graph processing, recent\nadvancements have explored integrating large language models for graph-based\ntasks. In this paper, we propose a novel approach named Learnable Graph Pooling\nToken (LGPT), which addresses the limitations of the scalability issues in\nnode-level projection and information loss in graph-level projection. LGPT\nenables flexible and efficient graph representation by introducing learnable\nparameters that act as tokens in large language models, balancing fine-grained\nand global graph information. Additionally, we investigate an Early Query\nFusion technique, which fuses query context before constructing the graph\nrepresentation, leading to more effective graph embeddings. Our method achieves\na 4.13\\% performance improvement on the GraphQA benchmark without training the\nlarge language model, demonstrating significant gains in handling complex\ntextual-attributed graph data."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14996",
    "c_title":[
      "Right Answer, Wrong Score: Uncovering the Inconsistencies of LLM\n  Evaluation in Multiple-Choice Question Answering"
    ],
    "c_abstract":[
      "One of the most widely used tasks to evaluate Large Language Models (LLMs) is\nMultiple-Choice Question Answering (MCQA). While open-ended question answering\ntasks are more challenging to evaluate, MCQA tasks are, in principle, easier to\nassess, as the model's answer is thought to be simple to extract and is\ndirectly compared to a set of predefined choices. However, recent studies have\nstarted to question the reliability of MCQA evaluation, showing that multiple\nfactors can significantly impact the reported performance of LLMs, especially\nwhen the model generates free-form text before selecting one of the answer\nchoices. In this work, we shed light on the inconsistencies of MCQA evaluation\nstrategies, which can lead to inaccurate and misleading model comparisons. We\nsystematically analyze whether existing answer extraction methods are aligned\nwith human judgment, and how they are influenced by answer constraints in the\nprompt across different domains. Our experiments demonstrate that traditional\nevaluation strategies often underestimate LLM capabilities, while LLM-based\nanswer extractors are prone to systematic errors. Moreover, we reveal a\nfundamental trade-off between including format constraints in the prompt to\nsimplify answer extraction and allowing models to generate free-form text to\nimprove reasoning. Our findings call for standardized evaluation methodologies\nand highlight the need for more reliable and consistent MCQA evaluation\npractices."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-574",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06005",
    "b_title":[
      "Remarks on nonperturbative perturbations"
    ],
    "b_abstract":[
      "We consider the linearized perturbations of near-horizon extremal\nReissner-Nordstr\\\"om black holes in $d$-dimensional\nEinstein-Maxwell-Gauss-Bonnet gravity and seven-dimensional third-order\nLovelock gravity. We find the solutions for the gravitational perturbations as\na function of the higher-derivative coupling coefficients, which we treat\nnonperturbatively. Consequently, we observe a breakdown in perturbation theory\nfor large harmonics for the six-derivative corrections."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05805",
    "c_title":[
      "Conformal blocks from celestial graviton amplitudes"
    ],
    "c_abstract":[
      "Four-point gluon and graviton correlators in celestial holography are\nfamously non-analytic, having distributional support. In this work, we propose\nan alternative graviton correlator that is analytic and displays several\ndesirable properties. We compute the four-point correlator involving one\ngraviton shadow operator and three graviton primary operators from the\ncelestial four-point graviton amplitudes at tree-level. We perform the\nconformal block decomposition for the shadow correlator in the compatible\nchannel. For the case when the shadow operator is conformally soft, we compute\nthe single-valued completion of the shadow correlator and perform the conformal\nblock decomposition of the single-valued shadow correlator in all channels. We\nfind an integral representation of the single-valued shadow correlator, which\nallows us to invert the shadow transform to find the single-valued celestial\ngraviton amplitude. We study various properties of the single-valued celestial\ngraviton amplitude. Interestingly, it exhibits a double copy structure in\nrelation to its counterpart gluon amplitude."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-575",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18979",
    "b_title":[
      "A compact frozen-spin trap for the search for the electric dipole moment\n  of the muon"
    ],
    "b_abstract":[
      "The electric dipole moments~(EDM) of fundamental particles inherently violate\nparity~(P) and time-reversal~(T) symmetries. By virtue of the CPT theorem in\nquantum field theory, the latter also implies the violation of the combined\ncharge-conjugation and parity~(CP) symmetry. We aim to measure the EDM of the\nmuon using the frozen-spin technique within a compact storage trap. This method\nexploits the high effective electric field, \\$E \\approx 165\\$ MV\/m, experienced\nin the rest frame of the muon with a momentum of about 23 MeV\/c when it passes\nthrough a solenoidal magnetic field of \\$|\\vec{B}|=2.5\\$ T. In this paper, we\noutline the fundamental considerations for a muon EDM search and present a\nconceptual design for a demonstration experiment to be conducted at secondary\nmuon beamlines of the Paul Scherrer Institute in Switzerland. In Phase~I, with\nan anticipated data acquisition period of 200 days, the expected sensitivity to\na muon EDM is 4E-21 ecm. In a subsequent phase, Phase~II, we propose to improve\nthe sensitivity to 6E-23 ecm using a dedicated instrument installed on a\ndifferent beamline that produces muons of momentum 125 MeV\/c}."
    ],
    "b_categories":[
      [
        "hep-ex"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17631",
    "c_title":[
      "Graph Neural Network Flavor Tagger and measurement of\n  $\\mathrm{sin}2\\beta$ at Belle II"
    ],
    "c_abstract":[
      "We present GFlaT, a new algorithm that uses a graph-neural-network to\ndetermine the flavor of neutral B mesons produced in $\\mathrm{\\Upsilon(4S)}$\ndecays. We evaluate its performance using $B$ decays to flavor-specific\nhadronic final states reconstructed in a $362$ $\\mathrm{fb}^{-1}$ sample of\nelectron-positron collisions recorded at the $\\mathrm{\\Upsilon(4S)}$ resonance\nwith the Belle II detector at the SuperKEKB collider. We achieve an effective\ntagging efficiency of $(37.40 \\pm 0.43 \\pm 0.36) \\%$, where the first\nuncertainty is statistical and the second systematic, which is $18\\%$ better\nthan the previous Belle II algorithm. Demonstrating the algorithm, we use $B^0\n\\to J\/\\psi K_\\mathrm{S}^0$ decays to measure the direct and mixing-induced CP\nviolation parameters, $C = (-0.035 \\pm 0.026 \\pm 0.013)$ and $S = (0.724 \\pm\n0.035 \\pm 0.014)$, from which we obtain $\\beta = (23.2 \\pm 1.5 \\pm\n0.6)^{\\circ}$."
    ],
    "c_categories":[
      [
        "hep-ex"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-576",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09533",
    "b_title":[
      "Large Language Models for Multi-Facility Location Mechanism Design"
    ],
    "b_abstract":[
      "Designing strategyproof mechanisms for multi-facility location that optimize\nsocial costs based on agent preferences had been challenging due to the\nextensive domain knowledge required and poor worst-case guarantees. Recently,\ndeep learning models have been proposed as alternatives. However, these models\nrequire some domain knowledge and extensive hyperparameter tuning as well as\nlacking interpretability, which is crucial in practice when transparency of the\nlearned mechanisms is mandatory. In this paper, we introduce a novel approach,\nnamed LLMMech, that addresses these limitations by incorporating large language\nmodels (LLMs) into an evolutionary framework for generating interpretable,\nhyperparameter-free, empirically strategyproof, and nearly optimal mechanisms.\nOur experimental results, evaluated on various problem settings where the\nsocial cost is arbitrarily weighted across agents and the agent preferences may\nnot be uniformly distributed, demonstrate that the LLM-generated mechanisms\ngenerally outperform existing handcrafted baselines and deep learning models.\nFurthermore, the mechanisms exhibit impressive generalizability to\nout-of-distribution agent preferences and to larger instances with more agents."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04409",
    "c_title":[
      "Lossless Privacy-Preserving Aggregation for Decentralized Federated\n  Learning"
    ],
    "c_abstract":[
      "Privacy concerns arise as sensitive data proliferate. Despite decentralized\nfederated learning (DFL) aggregating gradients from neighbors to avoid direct\ndata transmission, it still poses indirect data leaks from the transmitted\ngradients. Existing privacy-preserving methods for DFL add noise to gradients.\nThey either diminish the model predictive accuracy or suffer from ineffective\ngradient protection. In this paper, we propose a novel lossless\nprivacy-preserving aggregation rule named LPPA to enhance gradient protection\nas much as possible but without loss of DFL model predictive accuracy. LPPA\nsubtly injects the noise difference between the sent and received noise into\ntransmitted gradients for gradient protection. The noise difference\nincorporates neighbors' randomness for each client, effectively safeguarding\nagainst data leaks. LPPA employs the noise flow conservation theory to ensure\nthat the noise impact can be globally eliminated. The global sum of all noise\ndifferences remains zero, ensuring that accurate gradient aggregation is\nunaffected and the model accuracy remains intact. We theoretically prove that\nthe privacy-preserving capacity of LPPA is \\sqrt{2} times greater than that of\nnoise addition, while maintaining comparable model accuracy to the standard DFL\naggregation without noise injection. Experimental results verify the\ntheoretical findings and show that LPPA achieves a 14% mean improvement in\naccuracy over noise addition. We also demonstrate the effectiveness of LPPA in\nprotecting raw data and guaranteeing lossless model accuracy."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-577",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10275",
    "b_title":[
      "Vector soliton molecules and their collisions"
    ],
    "b_abstract":[
      "In recent times, bound soliton states have often been referred to as soliton\nmolecules in the nonlinear optics literature. The striking analogies between\nphotonic bound states and matter molecular structures in chemistry and physics\nhave intensified studies on optical soliton molecules in both conservative and\ndissipative systems. In this paper, we demonstrate the existence of vector\nsoliton molecules and their related isomer structures in a conservative optical\nfiber system by considering the integrable Manakov equation. We show their\nexistence by applying the velocity resonance condition and appropriate choice\nof temporal separations to the degenerate $N=(\\bar{N}+\\bar{M})$-soliton\nsolution. Then, we classify the obtained molecular states as either dissociated\nor synthesized molecular states based on the temporal locations of the\nconstituent solitons. Furthermore, we analyze the collision properties of\nvector soliton molecules in the present conservative system. The collision\nscenarios reveal that the soliton molecules undergo intriguing energy-sharing\ncollisions through energy redistribution among the modes. To characterize these\ncollisions, we have carried out an appropriate asymptotic analysis and found\nthat elastic collisions arise as a special case of energy-sharing collisions\nunder specific choices of polarization constants. Finally, we numerically\nverify the robustness of vector soliton molecules. We believe that the results\npresented in this paper show potential for soliton molecule-based applications\nsuch as optical computation and multi-level encoding for communications."
    ],
    "b_categories":[
      [
        "nlin.PS"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.13741",
    "c_title":[
      "Quasi-fluxon bubble dynamics in a rapid oscillatory microwave field"
    ],
    "c_abstract":[
      "In this article, we numerically study the dynamics of a two-dimensional\nquasi-fluxon bubble in an oscillatory regime stabilized by a localized annular\nforce under a rapidly oscillating microwave field. The bubble exhibits two\ndistinctly dynamical regimes. At first, the oscillation of the bubble wall\nscales up linearly with the microwave field frequency until it reaches a\ncutoff, after which it detaches from the external field, returning to its\nnatural oscillation frequency. The amplitude of the quasi-fluxon oscillations\nis inversely proportional to the square of the microwave field frequency.\nFollowing a simplified model based on the Kapitza approach, we proved that this\ndynamical behavior is characteristic of systems with a harmonic potential\nsubjected to a rapidly oscillating field. Possible applications of microwave\ndetection are discussed."
    ],
    "c_categories":[
      [
        "nlin.PS"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-578",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04364",
    "b_title":[
      "An innovative data collection method to eliminate the preprocessing\n  phase in web usage mining"
    ],
    "b_abstract":[
      "The underlying data source for web usage mining (WUM) is commonly thought to\nbe server logs. However, access log files ensure quite limited data about the\nclients. Identifying sessions from this messy data takes a considerable effort,\nand operations performed for this purpose do not always yield excellent\nresults. Also, this data cannot be used for web analytics efficiently. This\nstudy proposes an innovative method for user tracking, session management, and\ncollecting web usage data. The method is mainly based on a new approach for\nusing collected data for web analytics extraction as the data source in web\nusage mining. An application-based API has been developed with a different\nstrategy from conventional client-side methods to obtain and process log data.\nThe log data has been successfully gathered by integrating the technique into\nan enterprise web application. The results reveal that the homogeneous\nstructured data collected and stored with this method is more convenient to\nbrowse, filter, and process than web server logs. This data stored on a\nrelational database can be used effortlessly as a reliable data source for\nhigh-performance web usage mining activity, real-time web analytics, or a\nfunctional recommendation system."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08541",
    "c_title":[
      "LongEval at CLEF 2025: Longitudinal Evaluation of IR Model Performance"
    ],
    "c_abstract":[
      "This paper presents the third edition of the LongEval Lab, part of the CLEF\n2025 conference, which continues to explore the challenges of temporal\npersistence in Information Retrieval (IR). The lab features two tasks designed\nto provide researchers with test data that reflect the evolving nature of user\nqueries and document relevance over time. By evaluating how model performance\ndegrades as test data diverge temporally from training data, LongEval seeks to\nadvance the understanding of temporal dynamics in IR systems. The 2025 edition\naims to engage the IR and NLP communities in addressing the development of\nadaptive models that can maintain retrieval quality over time in the domains of\nweb search and scientific retrieval."
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-579",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10764",
    "b_title":[
      "Energy-Threshold Bias Calculator: A Physics-Model Based Adaptive\n  Correction Scheme for Photon-Counting CT"
    ],
    "b_abstract":[
      "Photon-counting detector based computed tomography (PCCT) has greatly\nadvanced in recent years. However, the spectral inconsistency is still a\nserious challenge for PCCT that could directly introduce obvious artifacts and\nsevere inaccuracies. This work attempts to overcome the challenge by modeling\nthe spectral inconsistency in a novel, unified, and two-term factorized\nframework, with a spectral skew term independent of the energy threshold, and\nan energy-threshold bias analytical characterization term. To solve the\nspectral inconsistency, a two-step decomposition algorithm called\nenergy-threshold bias calculator (ETB-Cal) is derived here, in which the\nspectral skew term is grossly determined at a relatively low energy threshold\nand only the energy-threshold bias is needed to be calculated as the energy\nthreshold changes. After the two terms being computed out in calibration stage,\nthey will be incorporated into our spectral model to generate the spectral\ncorrection vectors as well as the material decomposition vectors if needed, for\nPCCT projection data. To validate our method, both numerical simulations\nphysics experiments were carried out on a tabletop PCCT system. Preliminary\nresults showed that the spectral inconsistency can be significantly reduced,\nfor example, with an non-uniformity quantitative indicators decreasing from\n26.27 to 5.80 HU for Gammex multi-energy phantom and from 27.88 to 3.16 HU for\nkyoto head phantom. The considerable improvements consistently demonstrate a\ngreat potential of the proposed novel physics-model based correction scheme in\npractical applications, as computationally efficient, calibration-wise\nconvenient with high degree of generality, and substantially avoiding the use\nof X-ray florescence material in the energy-threshold calibration."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.06161",
    "c_title":[
      "High-Intensity Helical Flow: A Double-Edged Sword in Coronary Artery\n  Haemodynamics"
    ],
    "c_abstract":[
      "The role of Helical Flow (HF) in human coronary arteries remains uncertain,\nyet its understanding promises unprecedented insights into atherosclerotic\nprocesses. In this study, we investigated the effects of HF and key\nhaemodynamic descriptors in 39 patient-specific left coronary artery trees from\nthe ASOCA dataset, including 20 non-stenosed and 19 stenosed cases. Absolute HF\nintensity $h_2$ correlated with higher Time-Averaged Endothelial Shear Stress\n(TAESS) in all vessel segments regardless of stenosis (p < 0.05). In stenosed\ncases, this correlation was so prominent that the vessel area exposed to\nadversely low TAESS was reduced (< 0.5 Pa, p = 0.0001), while areas of\nadversely high TAESS increased (> 4.71 Pa, p < 0.05), coinciding with high\n$h_2$ regions. This suggests that HF in coronary arteries is not always\nprotective as previously thought. It not only mitigates low TAESS, which is\nassociated with long-term plaque development and restenosis, but also\nexacerbates adversely high TAESS, which is linked to increased plaque\nvulnerability and acute events. Our findings redefine the current understanding\nof helical blood flow's role in cardiovascular atherosclerotic disease\nprocesses."
    ],
    "c_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-580",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02862",
    "b_title":[
      "Stochastic Calculus via Stopping Derivatives"
    ],
    "b_abstract":[
      "We show that a substantial portion of stochastic calculus can be developed\nalong similar lines to ordinary calculus, with derivative-based concepts\ndriving the development. We define a notion of stopping derivative, which is a\nform of right derivative with respect to stopping times. Using this, we define\nthe drift and variance rate of a process as stopping derivatives for\n(generalised) conditional expectation and conditional variance respectively.\nApplying elementary, derivative-based methods, we derive a calculus of rules\ndescribing how drift and variance rate transform under constructions on\nprocesses, culminating in a version of the multi-dimensional It\\^o formula. Our\napproach connects with the standard machinery of stochastic calculus via a\ntheorem establishing that continuous processes with zero drift coincide with\nrandom translations of continuous local martingales. This equivalence allows us\nto derive a Fundamental Theorem of Calculus for stopping derivatives, which\nrelates the quantities of drift and variance rate, defined as stopping\nderivatives, to parameters used in the description of a process as a stochastic\nintegral."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.14255",
    "c_title":[
      "Hitting probabilities, thermal capacity, and Hausdorff dimension results\n  for the Brownian sheet"
    ],
    "c_abstract":[
      "Let $W= \\{W(t): t \\in \\mathbb{R}_+^N \\}$ be an $(N, d)$-Brownian sheet and\nlet $E \\subset (0, \\infty)^N$ and $F \\subset \\mathbb{R}^d$ be compact sets. We\nprove a necessary and sufficient condition for $W(E)$ to intersect $F$ with\npositive probability and determine the essential supremum of the Hausdorff\ndimension of the intersection set $W(E)\\cap F$ in terms of the thermal capacity\nof $E \\times F$. This extends the previous results of Khoshnevisan and Xiao\n(2015) for the Brownian motion and Khoshnevisan and Shi (1999) for the Brownian\nsheet in the special case when $E \\subset (0, \\infty)^N$ is an interval."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-581",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15451",
    "b_title":[
      "MotionStreamer: Streaming Motion Generation via Diffusion-based\n  Autoregressive Model in Causal Latent Space"
    ],
    "b_abstract":[
      "This paper addresses the challenge of text-conditioned streaming motion\ngeneration, which requires us to predict the next-step human pose based on\nvariable-length historical motions and incoming texts. Existing methods\nstruggle to achieve streaming motion generation, e.g., diffusion models are\nconstrained by pre-defined motion lengths, while GPT-based methods suffer from\ndelayed response and error accumulation problem due to discretized non-causal\ntokenization. To solve these problems, we propose MotionStreamer, a novel\nframework that incorporates a continuous causal latent space into a\nprobabilistic autoregressive model. The continuous latents mitigate information\nloss caused by discretization and effectively reduce error accumulation during\nlong-term autoregressive generation. In addition, by establishing temporal\ncausal dependencies between current and historical motion latents, our model\nfully utilizes the available information to achieve accurate online motion\ndecoding. Experiments show that our method outperforms existing approaches\nwhile offering more applications, including multi-round generation, long-term\ngeneration, and dynamic motion composition. Project Page:\nhttps:\/\/zju3dv.github.io\/MotionStreamer\/"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.17359",
    "c_title":[
      "Position: Interactive Generative Video as Next-Generation Game Engine"
    ],
    "c_abstract":[
      "Modern game development faces significant challenges in creativity and cost\ndue to predetermined content in traditional game engines. Recent breakthroughs\nin video generation models, capable of synthesizing realistic and interactive\nvirtual environments, present an opportunity to revolutionize game creation. In\nthis position paper, we propose Interactive Generative Video (IGV) as the\nfoundation for Generative Game Engines (GGE), enabling unlimited novel content\ngeneration in next-generation gaming. GGE leverages IGV's unique strengths in\nunlimited high-quality content synthesis, physics-aware world modeling,\nuser-controlled interactivity, long-term memory capabilities, and causal\nreasoning. We present a comprehensive framework detailing GGE's core modules\nand a hierarchical maturity roadmap (L0-L4) to guide its evolution. Our work\ncharts a new course for game development in the AI era, envisioning a future\nwhere AI-powered generative systems fundamentally reshape how games are created\nand experienced."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-582",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13515",
    "b_title":[
      "Mixed Fe-Mo carbide prepared by a sonochemical synthesis as highly\n  efficient nitrate reduction electrocatalyst"
    ],
    "b_abstract":[
      "Ammonia, a versatile compound that can be used as a fertilizer, chemical or\nfuel, has since long been produced through the energy-intensive Haber-Bosch\nprocess. Recently, the electrochemical nitrate reduction reaction (NO3RR) using\nelectricity generated from renewable sources has attracted widespread\nattention. However, the complex reaction pathway of NO3RR leads to the\nformation of many undesirable by-products. Herein we successfully prepared a\nmixed (FeMo)2C catalyst with good electrocatalytic NO3RR, having a NH3 yield of\n14.66 mg h-1 cm-2 and an FE of 94.35 % at low potential -0.3 V vs RHE. DFT\ncalculations show that the presence of Fe in Mo2C lattice changes the reaction\nmechanism, decreasing the potential barrier to be overcome from 1.36 to 0.89\neV. In addition, mixed Fe-Mo carbide facilitates the adsorption of\nintermediates and promotes NH3 desorption, facilitating NO3- reduction to NH3.\nIn addition, (FeMo)2C was used as cathode for Zn-NO3 battery to generate\nelectricity, producing ammonia at the same time, with a power density of 3.8\nmWcm-2 and an NH3 FE of 88 %. This work describes a new synthesis method for\nmixed metal carbides and provides a promising strategy for NH3 production."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.02000",
    "c_title":[
      "At extreme strain rates, pure metals thermally harden while alloys\n  thermally soften"
    ],
    "c_abstract":[
      "When materials are deformed at extreme strain rates, greater than $10^6\n\\text{ s}^{-1}$, a counterintuitive mechanical response is seen where the\nstrength and hardness of pure metals increases with increasing temperature. The\nanti-thermal hardening is due to defects in the material becoming pinned by\nphonons in the crystal lattice. However, here, using optically driven\nmicroballistic impact testing to measure the dynamic strength and hardness, we\nshow that when the composition is systematically varied away from high purity,\nthe mechanical response of metals transitions from ballistic transport of\ndislocations back to thermally activated pinning of dislocations, even at the\nhighest strain rates. This boundary from \"hotter-is-stronger\" to\n\"hotter-is-softer\" is observed and mapped for nickel, titanium, and gold. The\nability to tune between deformation mechanisms with very different temperature\ndependencies speaks to new directions for alloy design in extreme conditions."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-583",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15548",
    "b_title":[
      "Rationalizability and Monotonocity in Games with Incomplete Information"
    ],
    "b_abstract":[
      "This paper examines games with strategic complements or substitutes and\nincomplete information, where players are uncertain about the opponents'\nparameters. We assume that the players' beliefs about the opponent's parameters\nare selected from some given set of beliefs. One extreme is the case where\nthese sets only contain a single belief, representing a scenario where the\nplayers' actual beliefs about the parameters are commonly known among the\nplayers. Another extreme is the situation where these sets contain all possible\nbeliefs, representing a scenario where the players have no information about\nthe opponents' beliefs about parameters. But we also allow for intermediate\ncases, where these sets contain some, but not all, possible beliefs about the\nparameters. We introduce an assumption of weakly increasing differences that\ntakes both the choice belief and parameter belief of a player into account.\nUnder this assumption, we demonstrate that greater choice-parameter beliefs\nleads to greater optimal choices. Moreover, we show that the greatest and least\npoint rationalizable choice of a player is increasing in their parameter, and\nthese can be determined through an iterative procedure. In each round of the\niterative procedure, the lowest surviving choice is optimal for the lowest\nchoice-parameter belief, while the greatest surviving choice is optimal for the\nhighest choice-parameter belief."
    ],
    "b_categories":[
      [
        "econ.TH"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2503.18144",
    "c_title":[
      "Shapley-Scarf Markets with Objective Indifferences"
    ],
    "c_abstract":[
      "In many object allocation problems, some of the objects may effectively be\nindistinguishable from each other, such as with dorm rooms or school seats. In\nsuch cases, it is reasonable to assume that agents are indifferent between\nidentical copies of the same object. We call this setting ``objective\nindifferences.'' Top trading cycles (TTC) with fixed tie-breaking has been\nsuggested and used in practice to deal with indifferences in object allocation\nproblems. Under general indifferences, TTC with fixed tie-breaking is not\nPareto efficient nor group strategy-proof. Furthermore, it may not select the\ncore, even when it exists. Under objective indifferences, agents are always and\nonly indifferent between copies of the same object. In this setting, TTC with\nfixed tie-breaking maintains Pareto efficiency, group strategy-proofness, and\ncore selection. In fact, we present domain characterization results which\ntogether show that objective indifferences is the most general setting where\nTTC with fixed tie-breaking maintains these important properties."
    ],
    "c_categories":[
      [
        "econ.TH"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-584",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03356",
    "b_title":[
      "Complex Riemannian spacetime and singularity-free black holes and\n  cosmology"
    ],
    "b_abstract":[
      "An approach is presented to address singularities in general relativity using\na complex Riemannian spacetime extension. We demonstrate how this method can be\napplied to both black hole and cosmological singularities, specifically\nfocusing on the Schwarzschild and Kerr black holes and the\nFriedmann-Lema\\^itre-Robertson-Walker (FLRW) Big Bang cosmology. By extending\nthe relevant coordinates into the complex plane and carefully choosing\nintegration contours, we show that it is possible to regularize these\nsingularities, resulting in physically meaningful, singularity-free solutions\nwhen projected back onto real spacetime. The removal of the singularity at the\nBig Bang allows for a bounce cosmology. This approach offers a potential bridge\nbetween classical general relativity and quantum gravity effects, suggesting a\nway to resolve longstanding issues in gravitational physics without requiring a\nfull theory of quantum gravity."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.05829",
    "c_title":[
      "Stochastic Clocks in ADM-Based Canonical Gravity"
    ],
    "c_abstract":[
      "The problem of time in canonical quantum gravity remains one of the most\nsignificant challenges, primarily due to the ``frozen'' formalism emerging from\nthe Wheeler--DeWitt equation. Within the ADM formalism, we introduce a novel\napproach in which a scalar field is treated as a stochastic clock. By imposing\na divergence-free condition on the scalar momentum, we integrate out quantum\ngravitational fluctuations and derive an effective noise term via the\nHubbard--Stratonovich transformation. This noise drives dynamic adjustments in\nspacetime foliations, enabling a Schr\\\"{o}dinger-like evolution that preserves\ndiffeomorphism invariance and, upon noise averaging, maintains unitary\nevolution. Interestingly, by introducing stochastic variations in the\nfoliations, the quantum indeterminacy of the clock recasts time as a diffusive\nprocess emerging from quantum fluctuations -- where correlations between matter\nand geometry replace an absolute time parameter. This is considerably a\npotential pathway for understanding quantum time evolution while maintaining\nbackground independence in canonical quantum gravity."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-585",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15388",
    "b_title":[
      "Simulation of current-driven magnetisation switching in nanopillars with\n  Perpendicular Shape Anisotropy"
    ],
    "b_abstract":[
      "The Perpendicular Shape Anisotropy Spin Transfer Torque Magnetic Random\nAccess Memory (PSA-STT-MRAM) is a recent concept proposed to maintain the\nthermal stability of standard MRAM at small diameters, considering thick\nvertical pillars as the free layer. In order to explore the specific physics of\nPSA-STT-MRAMs expected in relation with their three-dimensional nature, we have\nperformed simulations combining a micromagnetic model coupled self-consistently\nwith spin-dependent transport equations. The 3D shape induces flower states at\nthe upper and lower surfaces. Besides, the field-like component of STT is found\nto be larger than in standard MRAMs, suggesting that it needs to be considered.\nThe combination of both effects leads to the excitation of high-order 3D\nferromagnetic resonance modes, playing a key role in magnetisation reversal.\nThese results highlight features of 3D nanomagnetic systems, largely\ndisregarded so far, which need to be considered to optimise PSA-STT-MRAM to be\na competitive solution for technological implementation."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.16033",
    "c_title":[
      "Dynamic Carrier Modulation via Nonlinear Acoustoelectric Transport in\n  van der Waals Heterostructures"
    ],
    "c_abstract":[
      "Dynamically manipulating carriers in van der Waals heterostructures could\nenable solid-state quantum simulators with tunable lattice parameters. A key\nrequirement is forming deep potential wells to reliably trap excitations. Here,\nwe report the observation of nonlinear acoustoelectric transport and dynamic\ncarrier modulation in boron nitride-encapsulated graphene devices coupled to\nintense surface acoustic waves (SAWs) on LiNbO3 substrates. SAWs generate\nstrong acoustoelectric current densities (JAE), transitioning from linear to\nnonlinear regimes with increasing SAW intensity. In the nonlinear regime,\nperiodic carrier (electrons, holes, or their mixtures) stripes emerge. Using\ncounter-propagating SAWs, we create standing SAWs (SSAWs) to dynamically\nmanipulate charge distributions without static gates. The saturation of JAE,\nattenuation transitions, and tunable resistance peaks confirm strong carrier\nlocalization. These results establish SAWs as a powerful tool for controlling\ncarrier dynamics in two-dimensional (2D) materials, paving the way for the\ndevelopment of time-dependent quantum systems and acoustic lattices for quantum\nsimulation."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-586",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01597",
    "b_title":[
      "Simulation studies of a high-repetition-rate electron-driven surface\n  muon beamline at SHINE"
    ],
    "b_abstract":[
      "A high-repetition-rate pulsed muon source operating at approximately 50\\,kHz\nholds the potential to improve the sensitivity of various particle physics and\nmaterial science experiments involving muons. In this article, we propose\nutilizing the high-repetition-rate pulsed electron beam at the SHINE facility\nto generate a surface muon beam. Our simulation studies indicate that an\n8\\,GeV, 100\\,pC charge pulsed electron beam impinging on a copper target can\nproduce up to $2 \\times 10^{3}$ muons per pulse. Beamline optimization results\ndemonstrate that approximately 60 surface muons per electron bunch can be\nefficiently transported to the end of the beamline. This translates to a\nsurface muon rate of $3 \\times 10^{6}\\,\\mu^{+}$\/s when the pulsed electron beam\nis operated at 50\\,kHz, which is comparable to existing muon facilities. This\nhigh-repetition-rate pulsed muon beam, with its ideal time structure,\nrepresents a unique and pioneering effort once constructed. It serves as a\nmodel for building cost-effective muon sources at existing electron machines\nwith GeV electron energies. The main challenge of positron removal is also\ndiscussed."
    ],
    "b_categories":[
      [
        "physics.acc-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10550",
    "c_title":[
      "Measurement of the mean excitation energy of liquid argon"
    ],
    "c_abstract":[
      "The mean excitation energy (I-value) of liquid argon is a critical input for\nenergy estimation in neutrino oscillation experiments. It is measured to be\n$(205\\pm4)$\\,eV using the range of 402.2\\,MeV protons from the Fermilab Linac.\nThis compares to the author's recent evaluation of $(197\\pm 7)$\\,eV based on a\ncombination of an oscillator strength distribution analysis, gaseous argon\nrange measurements, sparse stopping power data on solid argon, and an\nextrapolation of data on the effect of phase from other substances. Using all\nsources of information, we recommend a value of $(203.0\\pm3.2)$\\,eV for liquid\nargon, which is significantly higher than 188\\,eV, from ICRU-37's gaseous argon\nevaluation, commonly used in Monte Carlo codes such as \\textsc{Geant4}."
    ],
    "c_categories":[
      [
        "physics.acc-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-587",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12976",
    "b_title":[
      "LiT: Delving into a Simplified Linear Diffusion Transformer for Image\n  Generation"
    ],
    "b_abstract":[
      "In commonly used sub-quadratic complexity modules, linear attention benefits\nfrom simplicity and high parallelism, making it promising for image synthesis\ntasks. However, the architectural design and learning strategy for linear\nattention remain underexplored in this field. In this paper, we offer a suite\nof ready-to-use solutions for efficient linear diffusion Transformers. Our core\ncontributions include: (1) Simplified Linear Attention using few heads,\nobserving the free-lunch effect of performance without latency increase. (2)\nWeight inheritance from a fully pre-trained diffusion Transformer: initializing\nlinear Transformer using pre-trained diffusion Transformer and loading all\nparameters except for those related to linear attention. (3) Hybrid knowledge\ndistillation objective: using a pre-trained diffusion Transformer to help the\ntraining of the student linear Transformer, supervising not only the predicted\nnoise but also the variance of the reverse diffusion process. These guidelines\nlead to our proposed Linear Diffusion Transformer (LiT), an efficient\ntext-to-image Transformer that can be deployed offline on a laptop. Experiments\nshow that in class-conditional 256*256 and 512*512 ImageNet benchmark LiT\nachieves highly competitive FID while reducing training steps by 80% and 77%\ncompared to DiT. LiT also rivals methods based on Mamba or Gated Linear\nAttention. Besides, for text-to-image generation, LiT allows for the rapid\nsynthesis of up to 1K resolution photorealistic images. Project page:\nhttps:\/\/techmonsterwang.github.io\/LiT\/."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.20387",
    "c_title":[
      "InsTaG: Learning Personalized 3D Talking Head from Few-Second Video"
    ],
    "c_abstract":[
      "Despite exhibiting impressive performance in synthesizing lifelike\npersonalized 3D talking heads, prevailing methods based on radiance fields\nsuffer from high demands for training data and time for each new identity. This\npaper introduces InsTaG, a 3D talking head synthesis framework that allows a\nfast learning of realistic personalized 3D talking head from few training data.\nBuilt upon a lightweight 3DGS person-specific synthesizer with universal motion\npriors, InsTaG achieves high-quality and fast adaptation while preserving\nhigh-level personalization and efficiency. As preparation, we first propose an\nIdentity-Free Pre-training strategy that enables the pre-training of the\nperson-specific model and encourages the collection of universal motion priors\nfrom long-video data corpus. To fully exploit the universal motion priors to\nlearn an unseen new identity, we then present a Motion-Aligned Adaptation\nstrategy to adaptively align the target head to the pre-trained field, and\nconstrain a robust dynamic head structure under few training data. Experiments\ndemonstrate our outstanding performance and efficiency under various data\nscenarios to render high-quality personalized talking heads."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-588",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04584",
    "b_title":[
      "A Direct-adjoint Approach for Material Point Model Calibration with\n  Application to Plasticity"
    ],
    "b_abstract":[
      "This paper proposes a new approach for the calibration of material parameters\nin elastoplastic constitutive models. The calibration is posed as a constrained\noptimization problem, where the constitutive evolution equations serve as\nconstraints. The objective function quantifies the mismatch between the stress\npredicted by the model and corresponding experimental measurements. To improve\ncalibration efficiency, a novel direct-adjoint approach is presented to compute\nthe Hessian of the objective function, which enables the use of second-order\noptimization algorithms. Automatic differentiation (AD) is used for gradient\nand Hessian computations. Two numerical examples are employed to validate the\nHessian matrices and to demonstrate that the Newton-Raphson algorithm\nconsistently outperforms gradient-based algorithms such as L-BFGS-B."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.20343",
    "c_title":[
      "Topology Optimization for Multi-Axis Additive Manufacturing Considering\n  Overhang and Anisotropy"
    ],
    "c_abstract":[
      "Topology optimization produces designs with intricate geometries and complex\ntopologies that require advanced manufacturing techniques such as additive\nmanufacturing (AM). However, insufficient consideration of manufacturability\nduring the optimization process often results in design modifications that\ncompromise the optimality of the design. While multi-axis AM enhances\nmanufacturability by enabling flexible material deposition in multiple\norientations, challenges remain in addressing overhang structures, potential\ncollisions, and material anisotropy caused by varying build orientations. To\novercome these limitations, this study proposes a novel space-time topology\noptimization framework for multi-axis AM. The framework employs a pseudo-time\nfield as a design variable to represent the fabrication sequence,\nsimultaneously optimizing the density distribution and build orientations. This\napproach ensures that the overhang angles remain within manufacturable limits\nwhile also mitigating collisions. Moreover, by incorporating material\nanisotropy induced by diverse build orientations into the design process, the\nframework can take the scan path-dependent structural behaviors into account\nduring the design optimization. Numerical examples demonstrate that the\nproposed framework effectively derives feasible and optimal designs that\naccount for the manufacturing characteristics of multi-axis AM."
    ],
    "c_categories":[
      [
        "cs.CE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-589",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13929",
    "b_title":[
      "Formal verification in Solidity and Move: insights from a comparative\n  analysis"
    ],
    "b_abstract":[
      "Formal verification plays a crucial role in making smart contracts safer,\nbeing able to find bugs or to guarantee their absence, as well as checking\nwhether the business logic is correctly implemented. For Solidity, even though\nthere already exist several mature verification tools, the semantical quirks of\nthe language can make verification quite hard in practice. Move, on the other\nhand, has been designed with security and verification in mind, and it has been\naccompanied since its early stages by a formal verification tool, the Move\nProver. In this paper, we investigate through a comparative analysis: 1) how\nthe different designs of the two contract languages impact verification, and 2)\nwhat is the state-of-the-art of verification tools for the two languages, and\nhow do they compare on three paradigmatic use cases. Our investigation is\nsupported by an open dataset of verification tasks performed in Certora and in\nthe Aptos Move Prover."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02520",
    "c_title":[
      "Predicting IoT Device Vulnerability Fix Times with Survival and Failure\n  Time Models"
    ],
    "c_abstract":[
      "The rapid integration of Internet of Things (IoT) devices into enterprise\nenvironments presents significant security challenges. Many IoT devices are\nreleased to the market with minimal security measures, often harbouring an\naverage of 25 vulnerabilities per device. To enhance cybersecurity measures and\naid system administrators in managing IoT patches more effectively, we propose\nan innovative framework that predicts the time it will take for a vulnerable\nIoT device to receive a fix or patch. We developed a survival analysis model\nbased on the Accelerated Failure Time (AFT) approach, implemented using the\nXGBoost ensemble regression model, to predict when vulnerable IoT devices will\nreceive fixes or patches. By constructing a comprehensive IoT vulnerabilities\ndatabase that combines public and private sources, we provide insights into\naffected devices, vulnerability detection dates, published CVEs, patch release\ndates, and associated Twitter activity trends. We conducted thorough\nexperiments evaluating different combinations of features, including\nfundamental device and vulnerability data, National Vulnerability Database\n(NVD) information such as CVE, CWE, and CVSS scores, transformed textual\ndescriptions into sentence vectors, and the frequency of Twitter trends related\nto CVEs. Our experiments demonstrate that the proposed model accurately\npredicts the time to fix for IoT vulnerabilities, with data from VulDB and NVD\nproving particularly effective. Incorporating Twitter trend data offered\nminimal additional benefit. This framework provides a practical tool for\norganisations to anticipate vulnerability resolutions, improve IoT patch\nmanagement, and strengthen their cybersecurity posture against potential\nthreats."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-590",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10042",
    "b_title":[
      "A theoretical model for linear and nonlinear spectroscopy of plexcitons"
    ],
    "b_abstract":[
      "We present a theoretical model to investigate the dynamics and spectroscopic\nproperties of a plexciton system consisting of a molecular exciton coupled to a\nsingle short-lived plasmonic mode. The exciton is described as a two-level\nsystem (TLS), while the plasmonic mode is treated as a dissipative harmonic\noscillator. The hierarchical equations of motion method is employed to simulate\nenergy transfer dynamics, absorption spectra, and two-dimensional electronic\nspectra (2DES) of the system across a range of coupling strengths. It is shown\nthat increasing the exciton-plasmon coupling strength drives a transition in\nthe absorption spectra from an asymmetric Fano line shape to a Rabi splitting\npattern, while coupling the TLS to intramolecular vibrational modes reduces the\ncentral dip of the absorption spectra and makes the line shape more symmetric.\nThe simulated 2DES exhibit distinct features compared to those of a coupled\nmolecular dimer, highlighting the unique nonlinear response of plexciton\nsystems. In addition, a \"breathing mod\" pattern observed in the strong coupling\nregime can serve as a direct evidence of Rabi oscillation."
    ],
    "b_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.11932",
    "c_title":[
      "Computational Study of Li+ Solvation Structures in Fluorinated Ether,\n  Non-Fluorinated Ether, and Organic Carbonate-Based Electrolytes at Low and\n  High Salt Concentrations"
    ],
    "c_abstract":[
      "Understanding the solvation structure of electrolytes is crucial for\noptimizing the performance and stability of lithium-ion batteries. Novel\nsolvents are essential for enhancing electrolyte structure and ensuring better\nintegration with modern electrode systems. However, there are limited studies\nfocused on fluorinated solvent-based electrolytes. Herein, we report a new\nweakly solvated ether electrolyte (WSEE) composed of a pure fluorinated ether\nsolvent, which results in an anion-rich solvation structure even at a low salt\nconcentration of 1M. To explore this, we selected the advanced fluorinated\nsolvent 2,2-Difluoroethyl Methyl Ether (FEME) and compared it with Dipropyl\nEther (DPE), Ethylene Carbonate (EC), and Diethyl Carbonate (DEC). The prepared\nelectrolyte systems include DPE with 1M, 1.8M, and 4M LiFSI, FEME with 1M,\n1.8M, and 4M LiFSI, and a 1:1 vol% EC\/DEC mixture containing 1M LiPF6. In this\nwork, we comprehensively investigate the Li+ solvation structures in these\nelectrolytes using Molecular Dynamics (MD) simulations and Density Functional\nTheory (DFT) calculations. Our computational findings indicate the presence of\nlarge ion aggregates (AGGs) in each DPE- and FEME-based electrolyte, while\nSSIPs (68%) are the dominant species in the mixed EC\/DEC electrolyte. Notably,\nthe formation of large ion aggregates is more pronounced in FEME-based\nelectrolytes. We find that, similar to DPE, FEME solvent also exhibits weak\nsolvating power across all examined salt concentrations. Furthermore, the\nquantum mechanical features of the Li+ solvation structures in DPE+1.8M LiFSI,\nFEME+1.8M LiFSI, and EC\/DEC+1M LiPF6 electrolytes have been analyzed in detail\nusing DFT calculations. We anticipate that this study will provide valuable\ninsights into the Li+ solvation structures in DPE, FEME, and EC\/DEC\nelectrolytes, where the ether-based electrolytes exhibit closely similar\nproperties."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-591",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12480",
    "b_title":[
      "Stable gigahertz- and mmWave-repetition-rate soliton microcombs on X-cut\n  lithium niobate"
    ],
    "b_abstract":[
      "Soliton microcombs are a cornerstone of integrated frequency comb\ntechnologies, with applications spanning photonic computing, ranging, microwave\nsynthesis, optical communications, and quantum light generation. In nearly all\nsuch applications, electro-optic (EO) components play a critical role in\ngenerating, monitoring, stabilizing, and modulating the solitons. Towards\nbuilding photonic integrated circuits for next-generation applications, that\nwill simultaneously maximize system performance and minimize size, weight, and\npower consumption metrics, achieving soliton microcombs and efficient EO\nmodulation on a chip is essential. X-cut thin-film lithium niobate (TFLN) has\nemerged as a leading photonic platform for the realization of high-performance\nintegrated EO devices and systems. However, despite extensive research, soliton\nmicrocombs have remained elusive to X-cut TFLN due to its multiple strong\nRaman-active modes, in-plane refractive index anisotropy, and photorefractive\neffects. Here, we address this long-standing challenge and demonstrate\nversatile soliton microcombs on X-cut TFLN, with repetition-rates spanning from\nthe gigahertz (~26 GHz) up to the millimeter-wave (~0.156 THz) regime. The\ncombs feature exceptional long-term stability, maintaining a direct\ninjection-locked state for over 90 minutes (manually terminated), with\nrepetition-rate phase noise closely tracking that of a high-quality electronic\nmicrowave synthesizer. Our finding broadly advances both the fundamental\nscience and practical applications of integrated comb sources by enabling\nefficient EO modulation and broadband coherent solitons to be monolithically\ncombined on the same chip."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.12669",
    "c_title":[
      "Ultrawide dynamic bandwidth modulation of an antiresonant nanoweb\n  hollow-core fiber"
    ],
    "c_abstract":[
      "We experimentally demonstrate an acoustically modulated antiresonant nanoweb\nhollow-core fiber (N-HCF) for the first time. The N-HCF contains two off-center\nair cores with a diameter difference of 5 microns, separated by a nanoweb of\nsilica. We analytically simulate the influence of the N-HCF core diameter,\ncladding wall, and nanoweb thicknesses on the confinement losses, effective\nindices, and beatlengths of the guided fundamental (HE11) and higher-order\nmodes (TE01, TM01), from 750 to 1200 nm. The phase-matching of the acoustic\nwaves and modal beatlengths is also estimated and discussed. The fabricated 3.6\ncm long acousto-optic device modulates record-wide bandwidths (up to 450 nm)\nwhile providing high modulation depths (up to 8 dB) at low drive voltages (10\nV). Simulated and measured results provide useful insights for designing,\nmodeling, and characterizing the N-HCF transmission spectrum and modulation\nperformance. These achievements lead to highly efficient, compact, and fast\nall-fiber sensors and modulators promising for application in pulsed fiber\nlasers."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-592",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01765",
    "b_title":[
      "SaLoRA: Safety-Alignment Preserved Low-Rank Adaptation"
    ],
    "b_abstract":[
      "As advancements in large language models (LLMs) continue and the demand for\npersonalized models increases, parameter-efficient fine-tuning (PEFT) methods\n(e.g., LoRA) will become essential due to their efficiency in reducing\ncomputation costs. However, recent studies have raised alarming concerns that\nLoRA fine-tuning could potentially compromise the safety alignment in LLMs,\nposing significant risks for the model owner. In this paper, we first\ninvestigate the underlying mechanism by analyzing the changes in safety\nalignment related features before and after fine-tuning. Then, we propose a\nfixed safety module calculated by safety data and a task-specific\ninitialization for trainable parameters in low-rank adaptations, termed\nSafety-alignment preserved Low-Rank Adaptation (SaLoRA). Unlike previous LoRA\nmethods and their variants, SaLoRA enables targeted modifications to LLMs\nwithout disrupting their original alignments. Our experiments show that SaLoRA\noutperforms various adapters-based approaches across various evaluation metrics\nin different fine-tuning tasks."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.11452",
    "c_title":[
      "Deep Learning Agents Trained For Avoidance Behave Like Hawks And Doves"
    ],
    "c_abstract":[
      "We present heuristically optimal strategies expressed by deep learning agents\nplaying a simple avoidance game. We analyse the learning and behaviour of two\nagents within a symmetrical grid world that must cross paths to reach a target\ndestination without crashing into each other or straying off of the grid world\nin the wrong direction. The agent policy is determined by one neural network\nthat is employed in both agents. Our findings indicate that the fully trained\nnetwork exhibits behaviour similar to that of the game Hawks and Doves, in that\none agent employs an aggressive strategy to reach the target while the other\nlearns how to avoid the aggressive agent."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-593",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07350",
    "b_title":[
      "Ultra-resolution photochemical sensing"
    ],
    "b_abstract":[
      "Photochemistry in the earth's atmosphere is driven by the sun, continuously\naltering the concentration and spatial distribution of pollutants. Precisely\nmonitoring their atmospheric abundance relies predominantly on optical sensing,\nwhich requires the knowledge of exact absorption cross sections. One key\npollutant which impacts many photochemical reaction-pathways is formaldehyde.\nAgreement on formaldehyde absolute absorption cross section remains elusive in\nthe photochemically-relevant ultraviolet spectral region, hampering sensitive\nconcentration tracking. Here, we introduce free-running ultraviolet dual comb\nspectroscopy, combining high spectral resolution (1 GHz), broad spectral\ncoverage (12 THz), and fast acquisition speed (500 ms), as a novel method for\nabsolute absorption cross section determination with unprecedented fidelity.\nWithin this bandwidth, our method uncovers almost one order of magnitude more\nrovibrational transitions than detected before which leads to refined\nrotational constants for high-level quantum simulations of molecular\neigenstates. This ultra-resolution method can be generalized to provide a\nuniversal tool for fast electronic fingerprinting of atmospherically-relevant\nspecies, both for sensing applications and to benchmark improvements of\nab-initio quantum theory."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10760",
    "c_title":[
      "Optical Quasiparticles: Skyrmions, Bimerons and Skyrmionic Hopfions in\n  Paraxial Laser Beams"
    ],
    "c_abstract":[
      "Skyrmions, merons, bimerons, and skyrmionic hopfions are quasiparticles which\nhave stable topological textures. They have been observed across multiple\nphysical domains including nucleons, water waves, magnetic materials,\nelectromagnetic fields, condensed-matter physics, liquid crystals, and\nBose-Einstein condensates. The nontrivial topological texture of these\nquasiparticles exhibited promising applications across several research fields\nincluding cosmology, particle physics, superfluids, high-energy physics,\noptics, condensed matter, early-universe cosmology, cold quantum matter, and\nliquid crystals. These quasiparticles have most recently been observed in\nparaxial vector beams. Due to the inhomogeneous polarization distribution of\nvector beams, the quasiparticle textures reside in the Stokes vector fields.\nHere, we review recent developments in paraxial quasiparticle research and\nprovide detailed information on their fundamental properties and future\nprospects. We discuss various techniques which have been used to experimentally\ngenerate these quasiparticles and we examine a number of their proposed\napplications. Notably, this review offers insight into the concepts and\ntechniques which can be applied to the generation of optical skyrmions in\nparaxial laser beams, and investigates their intriguing applications across\nboth fundamental and applied optics."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-594",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08779",
    "b_title":[
      "SB-Bench: Stereotype Bias Benchmark for Large Multimodal Models"
    ],
    "b_abstract":[
      "Stereotype biases in Large Multimodal Models (LMMs) perpetuate harmful\nsocietal prejudices, undermining the fairness and equity of AI applications. As\nLMMs grow increasingly influential, addressing and mitigating inherent biases\nrelated to stereotypes, harmful generations, and ambiguous assumptions in\nreal-world scenarios has become essential. However, existing datasets\nevaluating stereotype biases in LMMs often lack diversity and rely on synthetic\nimages, leaving a gap in bias evaluation for real-world visual contexts. To\naddress this, we introduce the Stereotype Bias Benchmark (SB-bench), the most\ncomprehensive framework to date for assessing stereotype biases across nine\ndiverse categories with non-synthetic images. SB-bench rigorously evaluates\nLMMs through carefully curated, visually grounded scenarios, challenging them\nto reason accurately about visual stereotypes. It offers a robust evaluation\nframework featuring real-world visual samples, image variations, and\nmultiple-choice question formats. By introducing visually grounded queries that\nisolate visual biases from textual ones, SB-bench enables a precise and nuanced\nassessment of a model's reasoning capabilities across varying levels of\ndifficulty. Through rigorous testing of state-of-the-art open-source and\nclosed-source LMMs, SB-bench provides a systematic approach to assessing\nstereotype biases in LMMs across key social dimensions. This benchmark\nrepresents a significant step toward fostering fairness in AI systems and\nreducing harmful biases, laying the groundwork for more equitable and socially\nresponsible LMMs. Our code and dataset are publicly available."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16822",
    "c_title":[
      "RigGS: Rigging of 3D Gaussians for Modeling Articulated Objects in\n  Videos"
    ],
    "c_abstract":[
      "This paper considers the problem of modeling articulated objects captured in\n2D videos to enable novel view synthesis, while also being easily editable,\ndrivable, and re-posable. To tackle this challenging problem, we propose RigGS,\na new paradigm that leverages 3D Gaussian representation and skeleton-based\nmotion representation to model dynamic objects without utilizing additional\ntemplate priors. Specifically, we first propose skeleton-aware node-controlled\ndeformation, which deforms a canonical 3D Gaussian representation over time to\ninitialize the modeling process, producing candidate skeleton nodes that are\nfurther simplified into a sparse 3D skeleton according to their motion and\nsemantic information. Subsequently, based on the resulting skeleton, we design\nlearnable skin deformations and pose-dependent detailed deformations, thereby\neasily deforming the 3D Gaussian representation to generate new actions and\nrender further high-quality images from novel views. Extensive experiments\ndemonstrate that our method can generate realistic new actions easily for\nobjects and achieve high-quality rendering."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-595",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17241",
    "b_title":[
      "Superconducting non-volatile memory based on charge trapping and\n  gate-controlled superconductivity"
    ],
    "b_abstract":[
      "Superconducting electronics represents a promising technology, offering not\nonly efficient integration with quantum computing systems, but also the\npotential for significant power reduction in high-performance computing.\nNonetheless, the lack of superconducting memories better than conventional\nmetal-oxide semiconductor (CMOS) memories represent a major obstacle towards\nthe development of computing systems entirely based on superconducting\nelectronics. In this work, we combine the emerging concept of gate-controlled\nsupercurrent (GCS) with the well-established mechanism of charge-trapping\nmemory to demonstrate a novel, highly scalable, voltage-controlled and\nnon-volatile superconducting memory. GCS denotes the observation that the\nsupercurrent in a superconducting constriction can be suppressed by applying a\ncertain gate voltage (VG) to it. Our findings show that charge trapping within\nthe gate dielectric, here sapphire, influences the voltage threshold needed to\nsuppress the supercurrent. We demonstrate reliable reading and reversible\nwriting of two distinct charge-trapping memory states, associated with\ndifferent supercurrent values. Based on our memory device demonstrator, we\ndiscuss its integration into a NOT AND (NAND) gate layout, outlining the\nsignificant improvements offered by this novel memory concept over other\nexisting NAND memory technologies."
    ],
    "b_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04560",
    "c_title":[
      "Nonlinear electron-phonon interactions in Migdal-Eliashberg theory"
    ],
    "c_abstract":[
      "Superconducting systems based on attractive electron-phonon interactions are\nthe ones which are best understood at a fundamental level. They are well\ndescribed using Eliashberg theory, which, unlike BCS theory, explicitly takes\ninto account phonon dynamics. It is most often assumed that only linear\nelectron-phonon interactions are relevant. However, for some superconductors\nlike MgB$_2$ or hydride based superconductors, nonlinear electron-phonon\ninteractions are known to contribute significantly, which is not taken into\naccount in conventional Eliashberg theory. We provide a modification to\nEliashberg theory by introducing nonlinear electron-phonon interactions. We\nshow that the Eliashberg equations remain unchanged apart from a nonlinear\nextension of the Eliashberg spectral function. This extended spectral function\ncan be used as a baseline for future ab initio calculations. We use it to\nconstruct an analytical toy model and show that the nonlinear electron-phonon\ncoupling affects the superconducting gap function on the imaginary and real\naxis and causes an increase in the superconducting critical temperature."
    ],
    "c_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-596",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09294",
    "b_title":[
      "Indeterminacy in Affective Computing: Considering Meaning and Context in\n  Data Collection Practices"
    ],
    "b_abstract":[
      "Automatic Affect Prediction (AAP) uses computational analysis of input data\nsuch as text, speech, images, and physiological signals to predict various\naffective phenomena (e.g., emotions or moods). These models are typically\nconstructed using supervised machine-learning algorithms, which rely heavily on\nlabeled training datasets. In this position paper, we posit that all AAP\ntraining data are derived from human Affective Interpretation Processes,\nresulting in a form of Affective Meaning. Research on human affect indicates a\nform of complexity that is fundamental to such meaning: it can possess what we\nrefer to here broadly as Qualities of Indeterminacy (QIs) - encompassing\nSubjectivity (meaning depends on who is interpreting), Uncertainty (lack of\nconfidence regarding meanings' correctness), Ambiguity (meaning contains\nmutually exclusive concepts) and Vagueness (meaning is situated at different\nlevels in a nested hierarchy). Failing to appropriately consider QIs leads to\nresults incapable of meaningful and reliable predictions. Based on this\npremise, we argue that a crucial step in adequately addressing indeterminacy in\nAAP is the development of data collection practices for modeling corpora that\ninvolve the systematic consideration of 1) a relevant set of QIs and 2) context\nfor the associated interpretation processes. To this end, we are 1) outlining a\nconceptual model of AIPs and the QIs associated with the meaning these produce\nand a conceptual structure of relevant context, supporting understanding of its\nrole. Finally, we use our framework for 2) discussing examples of\ncontext-sensitivity-related challenges for addressing QIs in data collection\nsetups. We believe our efforts can stimulate a structured discussion of both\nthe role of aspects of indeterminacy and context in research on AAP, informing\nthe development of better practices for data collection and analysis."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10041",
    "c_title":[
      "Spatiotemporal Prediction of Secondary Crashes by Rebalancing Dynamic\n  and Static Data with Generative Adversarial Networks"
    ],
    "c_abstract":[
      "Data imbalance is a common issue in analyzing and predicting sudden traffic\nevents. Secondary crashes constitute only a small proportion of all crashes.\nThese secondary crashes, triggered by primary crashes, significantly exacerbate\ntraffic congestion and increase the severity of incidents. However, the severe\nimbalance of secondary crash data poses significant challenges for prediction\nmodels, affecting their generalization ability and prediction accuracy.\nExisting methods fail to fully address the complexity of traffic crash data,\nparticularly the coexistence of dynamic and static features, and often struggle\nto effectively handle data samples of varying lengths. Furthermore, most\ncurrent studies predict the occurrence probability and spatiotemporal\ndistribution of secondary crashes separately, lacking an integrated solution.\nTo address these challenges, this study proposes a hybrid model named\nVarFusiGAN-Transformer, aimed at improving the fidelity of secondary crash data\ngeneration and jointly predicting the occurrence and spatiotemporal\ndistribution of secondary crashes. The VarFusiGAN-Transformer model employs\nLong Short-Term Memory (LSTM) networks to enhance the generation of\nmultivariate long-time series data, incorporating a static data generator and\nan auxiliary discriminator to model the joint distribution of dynamic and\nstatic features. In addition, the model's prediction module achieves\nsimultaneous prediction of both the occurrence and spatiotemporal distribution\nof secondary crashes. Compared to existing methods, the proposed model\ndemonstrates superior performance in generating high-fidelity data and\nimproving prediction accuracy."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-597",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15649",
    "b_title":[
      "Supercooled Dark Scalar Phase Transitions explanation of NANOGrav data"
    ],
    "b_abstract":[
      "The evidence of a Stochastic Gravitational Wave Background (SGWB) in the nHz\nfrequency range is posed to open a new window on the Universe. A preferred\nexplanation relies on a supercooled first order phase transition at the 100 MeV\n- GeV scale. In this article, we address the feasibility going from the\nparticle physics model to the production of the gravitational waves. We take a\nminimal approach for the dark sector model introducing the fewest ingredients\nrequired, namely a new U(1) gauge group and a dark scalar that dynamically\nbreaks the symmetry. Supercooling poses challenges in the analysis that put\nunder question the feasibility of this explanation: we address them, going\nbeyond previous studies by carefully considering the effects of a vacuum\ndomination phase and explicitly tracking the phase transition from its onset to\nits completion. We find that the proposed model can successfully give origin to\nthe observed PTA SGWB signal. The strong supercooling imposes a correlation\nbetween the new gauge coupling and the scalar quartic one, leading to a\nsignificant hierarchy between the (heavier) gauge boson and the dark scalar.\nUltimately, information on phase transitions from SGWB observations could\nprovide a direct probe of the microphysics of the Early Universe and be used to\nguide future searches of dark sector in laboratories."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.02479",
    "c_title":[
      "Searching for mirror neutrons and dark matter with cold neutron\n  interferometry"
    ],
    "c_abstract":[
      "We report a novel neutron interferometry scheme aimed at probing the\npotential existence of mirror neutrons, which have been proposed as viable dark\nmatter candidates. Our theoretical analysis demonstrates that if mirror\nneutrons exist, ordinary neutrons would acquire a measurable geometric phase as\na result of their mixing with these mirror counterparts."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-598",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06662",
    "b_title":[
      "An exponentially stable discrete-time primal-dual algorithm for\n  distributed constrained optimization"
    ],
    "b_abstract":[
      "This paper studies a distributed algorithm for constrained consensus\noptimization that is obtained by fusing the Arrow-Hurwicz-Uzawa primal-dual\ngradient method for centralized constrained optimization and the Wang-Elia\nmethod for distributed unconstrained optimization. It is shown that the optimal\nprimal-dual point is a semiglobally exponentially stable equilibrium for the\nalgorithm, which implies linear convergence. The analysis is based on the\nseparation between a slow centralized optimization dynamics describing the\nevolution of the average estimate toward the optimum, and a fast dynamics\ndescribing the evolution of the consensus error over the network. These two\ndynamics are mutually coupled, and the stability analysis builds on control\ntheoretic tools such as time-scale separation, Lyapunov theory, and the\nsmall-gain principle. Our analysis approach highlights that the consensus\ndynamics can be seen as a fast, parasite one, and that stability of the\ndistributed algorithm is obtained as a robustness consequence of the semiglobal\nexponential stability properties of the centralized method. This perspective\ncan be used to enable other significant extensions, such as time-varying\nnetworks or delayed communication, that can be seen as ``perturbations\" of the\ncentralized algorithm."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.15399",
    "c_title":[
      "A new separable property of the joint numerical range of quadratic\n  functions and its applications to the Smallest Enclosing Ball Problem"
    ],
    "c_abstract":[
      "We explore separable property of the joint numerical range $G(\\Bbb R^n)$ of a\nspecial class of quadratic functions and apply it to solving the smallest\nenclosing ball (SEB) problem which asks to find a ball $B(a,r)$ in $\\Bbb R^n$\nwith smallest radius $r$ such that $B(a,r)$ contains the intersection\n$\\cap_{i=1}^mB(a_i,r_i)$ of $m$ given balls $B(a_i,r_i).$ We show that $G(\\Bbb\nR^n)$ is convex if and only if ${\\rm rank}\\{a_1-a, a_2-a, \\ldots, a_m-a\\}\\le\nn-1.$ Otherwise, ${\\rm rank}\\{a_1-a, a_2-a, \\ldots, a_m-a\\}=n$ and $G(\\Bbb\nR^n)$ is not convex. In this case we propose a new set $G(\\Bbb R^n)^\\bullet$\nwhich allows to show that if $m=n$ then $G(\\Bbb R^n)^\\bullet$ is convex even\n$G(\\Bbb R^n)$ is not. Importantly, the separable property of $G(\\Bbb\nR^n)^\\bullet$ then implies the separable property for $G(\\Bbb R^n).$ As a\nresult, a new progress on solving the SEB problem is obtained."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-599",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10746",
    "b_title":[
      "NPA Hierarchy and Extremal Criterion in the Simplest Bell Scenario"
    ],
    "b_abstract":[
      "It is difficult to establish an analytical criterion to identify the\nboundaries of quantum correlations, even for the simplest Bell scenario. Here,\nwe briefly reviewed the plausible analytical criterion, and we found a way to\nconfirm the extremal conditions from another direction. For that purpose, we\nanalyzed the Navascu\\'es-Pironio-Ac\\'{\\i}n (NPA) hierarchy to study the\nalgebraic structure and found that the problem could not be simplified using\n$1\\!+\\!AB$ level. However, considering the plausible criterion, the $1\\!+\\!AB$\nand second levels for correlations were equal, and the extremal condition in\nthe simplest Bell scenario was replaced by that in the $1\\!+\\!AB$ level. Thus,\nthe correctness of the plausible criterion was verified, and the results\ndemonstrated that the plausible criterion held, thereby explaining its\nsimplicity. It seemed plausible, but now it becomes more certain."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09303",
    "c_title":[
      "General detectability measure"
    ],
    "c_abstract":[
      "Distinguishing resource states from resource-free states is a fundamental\ntask in quantum information. We have approached the state detection problem\nthrough a hypothesis testing framework, with the alternative hypothesis set\ncomprising resource-free states in a general context. Consequently, we derived\nthe optimal exponential decay rate of the failure probability for detecting a\ngiven $n$-tensor product state when the resource-free states are separable\nstates, positive partial transpose (PPT) states, or the convex hull of the set\nof stabilizer states. This optimal exponential decay rate is determined by the\nminimum of the reverse relative entropy, indicating that this minimum value\nserves as the general detectability measure. The key technique of this paper is\na quantum version of empirical distribution."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-600",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13722",
    "b_title":[
      "Symmetric 2-(35,17,8) designs with an automorphism of order 2"
    ],
    "b_abstract":[
      "The largest prime p that can be the order of an automorphism of a 2-(35,17,8)\ndesign is p=17, and all 2-(35,17,8) designs with an automorphism of order 17\nwere classified by Tonchev. The symmetric 2-(35,17,8) designs with\nautomorphisms of odd prime order $p<17$ were also classified. In this paper we\ngive the classification of all symmetric 2-(35,17,8) designs that admit an\nautomorphism of order $p=2$. It is shown that there are exactly $11,642,495$\nnonisomorphic such designs. Furthermore, it is shown that the number of\nnonisomorphic 3-(36,18,8) designs which have at least one derived 2-$(35,17,8)$\ndesign with an automorphism of order 2, is $1,015,225$."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.01794",
    "c_title":[
      "Studying the divisibility of power LCM matrics by power GCD matrices on\n  gcd-closed sets"
    ],
    "c_abstract":[
      "Let $S=\\{x_1,\\ldots, x_n\\}$ be a gcd-closed set (i.e. $(x_i,x_j)\\in S $ for\nall $1\\le i,j\\le n$). In 2002, Hong proposed the divisibility problem of\ncharacterizing all gcd-closed sets $S$ with $|S|\\ge 4$ such that the GCD matrix\n$(S)$ divides the LCM matrix $[S]$ in the ring $M_{n}(\\mathbb{Z})$. For $x\\in\nS,$ let $G_S(x):=\\{z\\in S: z<x, z|x \\text{ and } (z|y|x, y\\in S)\\Rightarrow\ny\\in\\{z,x\\}\\}$. In 2009, Feng, Hong and Zhao answered this problem in the\ncontext where $\\max_{x \\in S}\\{|G_S(x)|\\} \\leq 2$. In 2022, Zhao, Chen and Hong\nobtained a necessary and sufficient condition on the gcd-closed set $S$ with\n$\\max_{x \\in S}\\{|G_S(x)|\\}=3$ such that $(S)|\\left[S\\right].$ Meanwhile, they\nraised a conjecture on the necessary and sufficient condition such that\n$(S)|\\left[S\\right]$ holds for the remaining case $\\max_{x \\in\nS}\\{|G_S(x)|\\}\\ge 4$. In this papar, we confirm the Zhao-Chen-Hong conjecture\nfrom a novel perspective, consequently solve Hong's open problem completely."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-601",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06702",
    "b_title":[
      "Optimistic Noise-Aware Sequential Quadratic Programming for Equality\n  Constrained Optimization with Rank-Deficient Jacobians"
    ],
    "b_abstract":[
      "We propose and analyze a sequential quadratic programming algorithm for\nminimizing a noisy nonlinear smooth function subject to noisy nonlinear smooth\nequality constraints. The algorithm uses a step decomposition strategy and, as\na result, is robust to potential rank-deficiency in the constraints, allows for\ntwo different step size strategies, and has an early stopping mechanism. Under\nthe linear independence constraint qualification, convergence is established to\na neighborhood of a first-order stationary point, where the radius of the\nneighborhood is proportional to the noise levels in the objective function and\nconstraints. Moreover, in the rank-deficient setting, the merit parameter may\nconverge to zero, and convergence to a neighborhood of an infeasible stationary\npoint is established. Numerical experiments demonstrate the efficiency and\nrobustness of the proposed method."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.06476",
    "c_title":[
      "Global Convergence and Rate Analysis of the Steepest Descent Method for\n  Uncertain Multiobjective Optimization via a Robust Optimization Approach"
    ],
    "c_abstract":[
      "In this article, we extend our previous work (Applicable Analysis, 2024, pp.\n1-25) on the steepest descent method for uncertain multiobjective optimization\nproblems. While that study established local convergence, it did not address\nglobal convergence and the rate of convergence of the steepest descent\nalgorithm. To bridge this gap, we provide rigorous proofs for both global\nconvergence and the linear convergence rate of the steepest descent algorithm.\nGlobal convergence analysis strengthens the theoretical foundation of the\nsteepest descent method for uncertain multiobjective optimization problems,\noffering deeper insights into its efficiency and robustness across a broader\nclass of optimization problems. These findings enhance the method's practical\napplicability and contribute to the advancement of robust optimization\ntechniques."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-602",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11974",
    "b_title":[
      "Wideband Pulse Generation for Underwater Applications Using Parametric\n  Array"
    ],
    "b_abstract":[
      "We investigated wideband pulse generation for underwater acoustic\napplications using a parametric array. We fabricated a transducer consisting of\na 3 mm thick 75 mm-by-75 mm square-shaped PZT ceramic plate, which is matched\nto water media at the radiating face and terminated by a very low impedance at\nthe back. All measurements were made in a large test tank. We transmitted\nsquare-root amplitude modulated pulses centered around 855 kHz primary\nfrequency. We showed that phase-sensitive generation of in-phase and\nout-of-phase bursts suitable for coded transmission using a parametric array is\npossible. We generated very short duration bursts, as short as half-cycle, at a\n10-80 kHz difference frequency range. The definition of the bursts is\nexcellent, e.g., with a normalized cross-correlation of 0.92 with an ideal\n2-cycle square burst, for both in-phase and out-of-phase pulses."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11212",
    "c_title":[
      "Non-negative tensor factorization-based dependence map analysis for\n  local damage detection in presence of non-Gaussian noise"
    ],
    "c_abstract":[
      "The time-frequency map (TFM) is frequently used in condition monitoring,\nnecessitating further processing to select an informative frequency band (IFB)\nor directly detect damage. However, selecting an IFB is challenging due to the\ncomplexity of spectral structures, non-Gaussian disturbances, and overlapping\nfault signatures in vibration signals. Additionally, dynamic operating\nconditions and low signal-to-noise ratio further complicate the identification\nof relevant features that indicate damage. To solve this problem, the present\nwork proposes a novel method for informative band selection and local damage\ndetection in rolling element bearings, utilizing non-negative tensor\nfactorization (NTF)-based dependence map analysis. The recently introduced\nconcept of the dependence map is leveraged, with a set of these maps being\nfactorized to separate informative components from non-informative ones.\nDependence maps provide valuable information on the auto-similarity of spectral\ncontent, while NTF, a powerful tool commonly used in image processing for\nfeature extraction, enhances this process. The combination of these methods\nallows for the extraction of IFBs, forming the basis for local damage\ndetection. The effectiveness of the proposed method has been validated using\nboth synthetic and real vibration signals corrupted with non-Gaussian\ndisturbances."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-603",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03742",
    "b_title":[
      "MaNGA AGN dwarf galaxies (MAD) -- III. The role of mergers and\n  environment in AGN activity in dwarf galaxies"
    ],
    "b_abstract":[
      "Investigating whether and how galaxy mergers affect black hole growth can be\ndeterminant for black hole-galaxy evolution models and, in particular, for\nunderstanding how early Universe seed black holes grew to become supermassive.\nHowever, while mergers have been observed to enhance the active galactic\nnucleus (AGN) activity, and thus black hole growth in massive galaxies, it is\nyet not known how this relation and the role of the environment translates to\ndwarf galaxies (the most likely hosts of the early seed black holes), since\nthere are scarce and mixed results in the literature. We want to assess the\nimpact of galaxy mergers and the environment on AGN triggering in dwarf\ngalaxies. We use a sample of 3280 dwarf galaxies with integral-field\nspectroscopic data from the MaNGA survey to study the AGN fraction throughout\nthe merger process and how it is affected by the environment (characterized by\ngalaxy isolation, being in a void, and group richness). We also compare the\nfraction of interacting galaxies in AGN and non-AGN dwarf galaxies. We find\nthat dwarf galaxy mergers can ignite AGNs at separations below 20 kpc. The AGN\nfraction increases notoriously after the first pass and remains enhanced until\nthe final stage. Despite this, mergers are not the dominant AGN triggering\nmechanism. We also find that the environment has a non-negligible impact on AGN\nactivity in dwarf galaxies, as the AGN fraction increases when moving to lower\ndensity environments. These findings provide the most statistically robust\nconstraints to date on the effects of dwarf galaxy mergers and environment on\nAGN activity and black hole growth."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.15059",
    "c_title":[
      "SOFIA FIFI-LS spectroscopy of DR21 Main: energetics of the\n  spatially-resolved outflow from a high-mass protostar"
    ],
    "c_abstract":[
      "Massive star formation is associated with energetic processes that may\ninfluence the physics and chemistry of parental molecular clouds and impact\ngalaxy evolution. The high-mass protostar DR21 Main in Cygnus X possesses one\nof the largest and most luminous outflows ever detected in the Galaxy, but the\norigin of its structure and driving mechanisms is still debated. Our aim is to\nspatially resolve the far-infrared line emission from DR21 Main and to\ninvestigate the gas physical conditions, energetics, and current mass loss\nrates along its outflow. Far-infrared SOFIA FIFI-LS spectra covering selected\nhigh-J CO lines, OH, [O I], [CII] and [O III] lines are analyzed across the\nalmost full extent of the DR21 Main outflow using 2.00' x 3.75' mosaic. The\nspatial extent of far-infrared emission follows closely the well-known outflow\ndirection of DR21 Main in case of high-J CO, [O I] 63.18 um, and the OH line at\n163.13 um. On the contrary, the emission from the [C II] 157.74 um and [O I]\n145.53 um lines arises mostly from the eastern part of the outflow, and it is\nlikely linked with a photodissociation region. Comparison of non-LTE radiative\ntransfer models with the observed [O I] line ratios suggest H2 densities of\n~10^5 cm^(-3) in the western part of the outflow and ~10^4 cm^(-3) in the East.\nSuch densities are consistent with the predictions of UV-irradiated\nnon-dissociative shock models for the observed ratios of CO and [O I] along the\nDR21 Main. Main outflow. Assuming that the bulk of emission arises in shocks,\nthe outflow power of DR21 Main of 4.3-4.8x10^2 Lsol and the mass-loss rate of\n3.3-3.7x10^(-3) Msol\/yr are determined. Observations provide strong support for\nits origin in outflow shocks, and the stratification of physical conditions\nalong the outflow. The total line cooling provides additional evidence that\nDR21 Main drives one of the most energetic outflows in the Milky Way."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-604",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09237",
    "b_title":[
      "City Models: Past, Present and Future Prospects"
    ],
    "b_abstract":[
      "We attempt to take a comprehensive look at the challenges of representing the\nspatio-temporal structures and dynamic processes defining a city's overall\ncharacteristics. For the task of urban planning and urban operation, we take\nthe stance that even if the necessary representations of these structures and\nprocesses can be achieved, the most important representation of the relevant\nmindsets of the citizens are, unfortunately, mostly neglected.\n  After a review of major \"traditional\" urban models of structures behind urban\nscale, form, and dynamics, we turn to major recent modeling approaches\ntriggered by recent advances in AI that enable multi-modal generative models.\nSome of these models can create representations of geometries, networks and\nimages, and reason flexibly at a human-compatible semantic level. They provide\nhuge amounts of knowledge extracted from Terabytes of text and image documents\nand cover the required rich representation spectrum including geographic\nknowledge by different knowledge sources, degrees of granularity and scales.\n  We then discuss what these new opportunities mean for the modeling challenges\nposed by cities, in particular with regard to the role and impact of citizens\nand their interactions within the city infrastructure. We propose to integrate\nthese possibilities with existing approaches, such as agent-based models, which\nopens up new modeling spaces including rich citizen models which are able to\nalso represent social interactions.\n  Finally, we put forward some thoughts about a vision of a \"social AI in a\ncity ecosystem\" that adds relevant citizen models to state-of-the-art\nstructural and process models. This extended city representation will enable\nurban planners to establish citizen-oriented planning of city infrastructures\nfor human culture, city resilience and sustainability."
    ],
    "b_categories":[
      [
        "cs.ET"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02162",
    "c_title":[
      "Optimizing Sequence Alignment with Scored NFAs"
    ],
    "c_abstract":[
      "The rapid increase in symbolic data has underscored the significance of\npattern matching and regular expression processing. While nondeterministic\nfinite automata (NFA) are commonly used for these tasks, they are limited to\ndetecting matches without determining the optimal one. This research expands on\nthe NAPOLY pattern-matching accelerator by introducing NAPOLY+, which adds\nregisters to each processing element to store variables like scores, weights,\nor edge costs. This enhancement allows NAPOLY+ to identify the highest score\ncorresponding to the best match in sequence alignment tasks through the\nnew-added arithmetic unit in each processor element. The design was evaluated\nagainst the original NAPOLY, with results showing that NAPOLY+ offers superior\nfunctionality and improved performance in identifying the best match. The\ndesign was implemented and tested on zynq102 and zynq104 FPGA devices, with\nperformance metrics compared across array sizes from 1K to 64K processing\nelements. The results showed that memory usage increased proportionally with\narray size with Fmax decreasing as the array size grew on both platforms. The\nreported findings focus specifically on the core array, excluding the impact of\nbuffers and DRAMs."
    ],
    "c_categories":[
      [
        "cs.ET"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-605",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17538",
    "b_title":[
      "Policy Learning with a Natural Language Action Space: A Causal Approach"
    ],
    "b_abstract":[
      "This paper introduces a novel causal framework for multi-stage\ndecision-making in natural language action spaces where outcomes are only\nobserved after a sequence of actions. While recent approaches like Proximal\nPolicy Optimization (PPO) can handle such delayed-reward settings in\nhigh-dimensional action spaces, they typically require multiple models (policy,\nvalue, and reward) and substantial training data. Our approach employs\nQ-learning to estimate Dynamic Treatment Regimes (DTR) through a single model,\nenabling data-efficient policy learning via gradient ascent on language\nembeddings. A key technical contribution of our approach is a decoding strategy\nthat translates optimized embeddings back into coherent natural language. We\nevaluate our approach on mental health intervention, hate speech countering,\nand sentiment transfer tasks, demonstrating significant improvements over\ncompetitive baselines across multiple metrics. Notably, our method achieves\nsuperior transfer strength while maintaining content preservation and fluency,\nas validated through human evaluation. Our work provides a practical foundation\nfor learning optimal policies in complex language tasks where training data is\nlimited."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00134",
    "c_title":[
      "Personalized Causal Graph Reasoning for LLMs: A Case Study on Dietary\n  Recommendations"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) effectively leverage common-sense knowledge for\ngeneral reasoning, yet they struggle with personalized reasoning when tasked\nwith interpreting multifactor personal data. This limitation restricts their\napplicability in domains that require context-aware decision-making tailored to\nindividuals. This paper introduces Personalized Causal Graph Reasoning as an\nagentic framework that enhances LLM reasoning by incorporating personal causal\ngraphs derived from data of individuals. These graphs provide a foundation that\nguides the LLM's reasoning process. We evaluate it on a case study on\nnutrient-oriented dietary recommendations, which requires personal reasoning\ndue to the implicit unique dietary effects. We propose a counterfactual\nevaluation to estimate the efficiency of LLM-recommended foods for glucose\nmanagement. Results demonstrate that the proposed method efficiently provides\npersonalized dietary recommendations to reduce average glucose iAUC across\nthree time windows, which outperforms the previous approach. LLM-as-a-judge\nevaluation results indicate that our proposed method enhances personalization\nin the reasoning process."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-606",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13010",
    "b_title":[
      "Magneto-thermally Coupled Field Simulation of Homogenized Foil Winding\n  Models"
    ],
    "b_abstract":[
      "Foil windings have, due to their layered structure, different properties than\nconventional wire windings, which make them advantageous for high frequency\napplications. Both electromagnetic and thermal analyses are relevant for foil\nwindings. These two physical areas are coupled through Joule losses and\ntemperature dependent material properties. For an efficient simulation of foil\nwindings, homogenization techniques are used to avoid resolving the single\nturns. Therefore, this paper comprises a coupled magneto-thermal simulation\nthat uses a homogenization method in the electromagnetic and thermal part. A\nweak coupling with different time step sizes for both parts is presented. The\nmethod is validated on a simple geometry and showcased for a pot transformer\nthat uses a foil and a wire winding."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12053",
    "c_title":[
      "PINNsAgent: Automated PDE Surrogation with Large Language Models"
    ],
    "c_abstract":[
      "Solving partial differential equations (PDEs) using neural methods has been a\nlong-standing scientific and engineering research pursuit. Physics-Informed\nNeural Networks (PINNs) have emerged as a promising alternative to traditional\nnumerical methods for solving PDEs. However, the gap between domain-specific\nknowledge and deep learning expertise often limits the practical application of\nPINNs. Previous works typically involve manually conducting extensive PINNs\nexperiments and summarizing heuristic rules for hyperparameter tuning. In this\nwork, we introduce PINNsAgent, a novel surrogation framework that leverages\nlarge language models (LLMs) and utilizes PINNs as a foundation to bridge the\ngap between domain-specific knowledge and deep learning. Specifically,\nPINNsAgent integrates (1) Physics-Guided Knowledge Replay (PGKR), which encodes\nthe essential characteristics of PDEs and their associated best-performing\nPINNs configurations into a structured format, enabling efficient knowledge\ntransfer from solved PDEs to similar problems and (2) Memory Tree Reasoning, a\nstrategy that effectively explores the search space for optimal PINNs\narchitectures. By leveraging LLMs and exploration strategies, PINNsAgent\nenhances the automation and efficiency of PINNs-based solutions. We evaluate\nPINNsAgent on 14 benchmark PDEs, demonstrating its effectiveness in automating\nthe surrogation process and significantly improving the accuracy of PINNs-based\nsolutions."
    ],
    "c_categories":[
      [
        "cs.CE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-607",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04420",
    "b_title":[
      "A Closer Look on Gender Stereotypes in Movie Recommender Systems and\n  Their Implications with Privacy"
    ],
    "b_abstract":[
      "The movie recommender system typically leverages user feedback to provide\npersonalized recommendations that align with user preferences and increase\nbusiness revenue. This study investigates the impact of gender stereotypes on\nsuch systems through a specific attack scenario. In this scenario, an attacker\ndetermines users' gender, a private attribute, by exploiting gender stereotypes\nabout movie preferences and analyzing users' feedback data, which is either\npublicly available or observed within the system. The study consists of two\nphases. In the first phase, a user study involving 630 participants identified\ngender stereotypes associated with movie genres, which often influence viewing\nchoices. In the second phase, four inference algorithms were applied to detect\ngender stereotypes by combining the findings from the first phase with users'\nfeedback data. Results showed that these algorithms performed more effectively\nthan relying solely on feedback data for gender inference. Additionally, we\nquantified the extent of gender stereotypes to evaluate their broader impact on\ndigital computational science. The latter part of the study utilized two major\nmovie recommender datasets: MovieLens 1M and Yahoo!Movie. Detailed experimental\ninformation is available on our GitHub repository:\nhttps:\/\/github.com\/fr-iit\/GSMRS"
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.02968",
    "c_title":[
      "FlipedRAG: Black-Box Opinion Manipulation Attacks to Retrieval-Augmented\n  Generation of Large Language Models"
    ],
    "c_abstract":[
      "Retrieval-Augmented Generation (RAG) addresses hallucination and real-time\nconstraints by dynamically retrieving relevant information from a knowledge\ndatabase to supplement the LLMs' input. When presented with a query, RAG\nselects the most semantically similar texts from its knowledge bases and uses\nthem as context for the LLMs to generate more accurate responses. RAG also\ncreates a new attack surface, especially since RAG databases are frequently\nsourced from public domains. While existing studies have predominantly focused\non optimizing RAG's performance and efficiency, emerging research has begun\naddressing the security concerns associated with RAG. However, these works have\nsome limitations, typically focusing on either white-box methodologies or\nheuristic-based black-box attacks. Furthermore, prior research has mainly\ntargeted simple factoid question answering, which is neither practically\nchallenging nor resistant to correction. In this paper, we unveil a more\nrealistic and threatening scenario: opinion manipulation for controversial\ntopics against RAG. Particularly, we propose a novel RAG black-box attack\nmethod, termed FlipedRAG, which is transfer-based. By leveraging instruction\nengineering, we obtain partial retrieval model outputs from black-box RAG\nsystem, facilitating the training of surrogate models to enhance the\neffectiveness of opinion manipulation attack. Extensive experimental results\nconfirms that our approach significantly enhances the average success rate of\nopinion manipulation by 16.7%. It achieves an average of a 50% directional\nchange in the opinion polarity of RAG responses across four themes.\nAdditionally, it induces a 20% shift in user cognition. Furthermore, we discuss\nthe efficacy of potential defense mechanisms and conclude that they are\ninsufficient in mitigating this type of attack, highlighting the urgent need to\ndevelop novel defensive strategies."
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-608",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17187",
    "b_title":[
      "Hankel Determinants for Convolution of Power Series: An Extension of\n  Cigler's Results"
    ],
    "b_abstract":[
      "Cigler considered certain shifted Hankel determinants of convolution powers\nof Catalan numbers and conjectured identities for these determinants. Recently,\nFulmek gave a bijective proof of Cigler's conjecture. Cigler then provided a\ncomputational proof. We extend Cigler's determinant identities to the\nconvolution of general power series $F(x)$, where $F(x)$ satisfies a certain\ntype of quadratic equation. As an application, we present the Hankel\ndeterminant identities of convolution powers of Motzkin numbers."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.14657",
    "c_title":[
      "3D permutations and triangle solitaire"
    ],
    "c_abstract":[
      "We provide a bijection between a class of 3-dimensional pattern avoiding\npermutations and triangle bases, special sets of integer points arising from\nthe theory of tilings and TEP subshifts. This answers a conjecture of Bonichon\nand Morel."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-609",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14074",
    "b_title":[
      "An orphan flare from a plasma blob crossing the broad-line region ?"
    ],
    "b_abstract":[
      "The blazar 3C 279 is well known for its prolific emission of rapid flares. A\nparticular event occurred on 12\/20\/2013, exhibiting a large flux increase with\na doubling time scale of a few hours, a very hard gamma-ray spectrum, and a\ntime-asymmetric light curve with slow decay, but no significant variations\ndetected in the optical range. We propose a novel scenario to interpret this\nflare, based on two emission zones, a stationary blob and a moving plasma blob.\nThe stationary blob, located within the BLR, accounts for the low-state\nemission. The moving blob decouples from the stationary zone, accelerates and\ncrosses the BLR. The high-energy flare is attributed to the variable external\nCompton emission as the blob moves through the BLR, while variations in the\nsynchrotron emission are negligible. Our interpretation differs from previous\ninterpretations by attributing the flare to the bulk motion and geometry of the\nexternal photon fields, without invoking varying electron injection."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02373",
    "c_title":[
      "Consistent crust-core interpolation and its effect on non-radial neutron\n  star oscillations"
    ],
    "c_abstract":[
      "To model the structure of neutron stars (NSs) theoretically,it is common to\nconsider layers with different density regimes. Matching the equation of state\n(EoS) for the crust and core and obtaining a suitable description of these\nextreme conditions are crucial for understanding the properties of these\ncompact objects. In this work, we construct ten different NS EoSs incorporating\nthree distinct crust models, which are connected to the core using a\nthermodynamically and causally consistent formalism. For cold NSs, we propose a\nlinear relationship between pressure and energy density in a narrow region\nbetween the crust and core, effectively establishing an interpolation function\nin the pressure-baryonic chemical potential plane. We then compare this EoS\nmatching method with the classical approach, which neglects causal and\nthermodynamic consistency. We solve the Tolman-Oppenheimer-Volkoff equation to\nobtain the mass-radius relationship and compare our results with observational\nconstraints on NSs. Furthermore, we investigate the influence of the new\nmatching formalism on non-radial oscillation frequencies and damping times. Our\nfindings suggest that the method used to glue the crust and core EoS impacts NS\nobservables, such as the radius, oscillation frequencies, and damping times of\nnon-radial modes, which may be crucial for interpreting future gravitational\nwave observations from neutron star mergers or isolated pulsars. The effects\nare particularly noticeable for low-mass NSs, regardless of the specific EoS\nmodel chosen. In particular, we find that the $p_1$ oscillation mode exhibits\nsignificant differences in frequencies among alternative matching methods,\nwhereas the fundamental $f$-mode remains unaffected by changes in crust models\nor interpolation schemes."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-610",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10951",
    "b_title":[
      "Energy rates due to Fe isotopes during presupernova evolution of massive\n  stars"
    ],
    "b_abstract":[
      "This work presents the microscopic calculation of energy rates ({\\gamma} ray\nheating and (anti)neutrino cooling rates) due to weak decay of selected Fe\nisotopes. The isotopes have astrophysical significance during the presupernova\nevolution of massive stars. The energy rates are calculated using the pn QRPA\nmodel and compared with the independent particle model (IPM), large scale shell\nmodel (LSSM) and recent shell model calculation (GXPF1J). The reported\n(anti)neutrino cooling rates are smaller by up to two orders of magnitude at\nlow core temperature values than the IPM rates. The two calculations compare\nwell at T = 30 GK. The comparison of cooling rates with the LSSM is\ninteresting. The pn QRPA cooling rates due to even even Fe isotopes are smaller\n(up to 2 orders of magnitude). For the odd A isotopes, the reported rates are\nbigger up to an order of magnitude. The pn QRPA computed cooling rates are, up\nto 2 orders of magnitude, bigger when compared with the GXPF1J calculation. The\n{\\gamma} ray heating rates due to electron capture rates rise with the\ntemperature and density values of the stellar core. On the other hand, the\n{\\gamma} ray heating due to \\b{eta} decay increases with the core temperature\nvalues but decreases by orders of magnitude when the stellar core stiffens. The\npn QRPA computed {\\gamma} heating rates are bigger (up to 3 orders of\nmagnitude) at high temperatures and densities (for the case of 55 56Fe) when\ncompared with the recent shell model results. Owing to the importance of energy\nrates, this study may contribute to a realistic simulation of presupernova\nevolution of massive stars."
    ],
    "b_categories":[
      [
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.18252",
    "c_title":[
      "Benchmarking ANN extrapolations of the ground-state energies and radii\n  of Li isotopes"
    ],
    "c_abstract":[
      "We present a comparison of model-space extrapolation methods for No-Core\nShell Model calculations of ground-state energies and root-mean-square radii in\nLi isotopes. In particular, we benchmark the latest machine learning tools\nagainst widely used exponential and infrared extrapolations for energies and\ncrossing point estimates for radii. Our findings demonstrate that machine\nlearning-based approaches provide reliable predictions with robust statistical\nuncertainties for both observables even in small model spaces. These\npredictions are compatible with established exponential and IR extrapolations\nof energies and mark a notable improvement over conventional radius estimates."
    ],
    "c_categories":[
      [
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-611",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07547",
    "b_title":[
      "Bi-Directional Mental Model Reconciliation for Human-Robot Interaction\n  with Large Language Models"
    ],
    "b_abstract":[
      "In human-robot interactions, human and robot agents maintain internal mental\nmodels of their environment, their shared task, and each other. The accuracy of\nthese representations depends on each agent's ability to perform theory of\nmind, i.e. to understand the knowledge, preferences, and intentions of their\nteammate. When mental models diverge to the extent that it affects task\nexecution, reconciliation becomes necessary to prevent the degradation of\ninteraction. We propose a framework for bi-directional mental model\nreconciliation, leveraging large language models to facilitate alignment\nthrough semi-structured natural language dialogue. Our framework relaxes the\nassumption of prior model reconciliation work that either the human or robot\nagent begins with a correct model for the other agent to align to. Through our\nframework, both humans and robots are able to identify and communicate missing\ntask-relevant context during interaction, iteratively progressing toward a\nshared mental model."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05943",
    "c_title":[
      "Continual Adaptation for Autonomous Driving with the Mixture of\n  Progressive Experts Network"
    ],
    "c_abstract":[
      "Learning-based autonomous driving requires continuous integration of diverse\nknowledge in complex traffic , yet existing methods exhibit significant\nlimitations in adaptive capabilities. Addressing this gap demands autonomous\ndriving systems that enable continual adaptation through dynamic adjustments to\nevolving environmental interactions. This underscores the necessity for\nenhanced continual learning capabilities to improve system adaptability. To\naddress these challenges, the paper introduces a dynamic progressive\noptimization framework that facilitates adaptation to variations in dynamic\nenvironments, achieved by integrating reinforcement learning and supervised\nlearning for data aggregation. Building on this framework, we propose the\nMixture of Progressive Experts (MoPE) network. The proposed method selectively\nactivates multiple expert models based on the distinct characteristics of each\ntask and progressively refines the network architecture to facilitate\nadaptation to new tasks. Simulation results show that the MoPE model\noutperforms behavior cloning methods, achieving up to a 7.8% performance\nimprovement in intricate urban road environments."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-612",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18251",
    "b_title":[
      "COFO: COdeFOrces dataset for Program Classification, Recognition and\n  Tagging"
    ],
    "b_abstract":[
      "In recent years, a lot of technological advances in computer science have\naided software programmers to create innovative and real-time user-friendly\nsoftware. With the creation of the software and the urging interest of people\nto learn to write software, there is a large collection of source codes that\ncan be found on the web, also known as Big Code, which can be used as a source\nof data for driving the machine learning applications tending to solve certain\nsoftware engineering problems. In this paper, we present COFO, a dataset\nconsisting of 809 classes\/problems with a total of 369K source codes written in\nC, C++, Java, and Python programming languages, along with other metadata such\nas code tags, problem specification, and input-output specifications. COFO has\nbeen scraped from the openly available Codeforces website using a\nselenium-beautifulsoup-python based scraper. We envision that this dataset can\nbe useful for solving machine learning-based problems like program\nclassification\/recognition, tagging, predicting program properties, and code\ncomprehension."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17678",
    "c_title":[
      "Automated Repair of Cyber-Physical Systems"
    ],
    "c_abstract":[
      "Cyber-Physical Systems (CPS) integrate digital technologies with physical\nprocesses and are common in different domains and industries, such as robotic\nsystems, autonomous vehicles or satellites. Debugging and verification of CPS\nsoftware consumes much of the development budget as it is often purely manual.\nTo speed up this process, Automated Program Repair (APR) has been targeted for\na long time. Although there have been advances in software APR and CPS\nverification techniques, research specifically on APR for CPSs is limited. This\nPh.D. research project aims to develop scalable APR techniques for CPSs,\naddressing problems of fault localization, long test execution times, and\nfitness function limitations. A new method combining spectrum-based fault\nlocalization (SBFL) with patch generation and advanced artificial intelligence\ntechniques will be investigated. The approach will be validated by empirical\nstudies on open and industrial code bases of CPSs."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-613",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15807",
    "b_title":[
      "Video-VoT-R1: An efficient video inference model integrating image\n  packing and AoE architecture"
    ],
    "b_abstract":[
      "In the field of video-language pretraining, existing models face numerous\nchallenges in terms of inference efficiency and multimodal data processing.\nThis paper proposes a KunLunBaize-VoT-R1 video inference model based on a\nlong-sequence image encoder, along with its training and application methods.\nBy integrating image packing technology, the Autonomy-of-Experts (AoE)\narchitecture, and combining the video of Thought (VoT), a large language model\n(LLM) trained with large-scale reinforcement learning, and multiple training\ntechniques, the efficiency and accuracy of the model in video inference tasks\nare effectively improved. Experiments show that this model performs\noutstandingly in multiple tests, providing a new solution for video-language\nunderstanding."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10482",
    "c_title":[
      "A Self-Supervised Reinforcement Learning Approach for Fine-Tuning Large\n  Language Models Using Cross-Attention Signals"
    ],
    "c_abstract":[
      "We propose a novel reinforcement learning framework for post training large\nlanguage models that does not rely on human in the loop feedback. Instead, our\napproach uses cross attention signals within the model itself to derive a self\nsupervised reward, thereby guiding iterative fine tuning of the model policy.\nBy analyzing how the model attends to the input prompt during generation, we\nconstruct measures of prompt coverage, focus, and coherence. We then use these\nmeasures to rank or score candidate responses, providing a reward signal that\nencourages the model to produce well aligned, on topic text. In empirical\ncomparisons against standard policy gradient methods and RL fine tuning with\nsynthetic preference models, our method shows significant gains in prompt\nrelevance and consistency over a non RL baseline. While it does not yet match\nthe performance of fully human supervised RLHF systems, it highlights an\nimportant direction for scaling alignment with minimal human labeling. We\nprovide a detailed analysis, discuss potential limitations, and outline future\nwork for combining cross-attention based signals with smaller amounts of human\nfeedback."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-614",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01256",
    "b_title":[
      "Soft is Safe: Human-Robot Interaction for Soft Robots"
    ],
    "b_abstract":[
      "With the presence of robots increasing in the society, the need for\ninteracting with robots is becoming necessary. The field of Human-Robot\nInteraction (HRI) has emerged important since more repetitive and tiresome jobs\nare being done by robots. In the recent times, the field of soft robotics has\nseen a boom in the field of research and commercialization. The Industry 5.0\nfocuses on human robot collaboration which also spurs the field of soft\nrobotics. However the HRI for soft robotics is still in the nascent stage. In\nthis work we review and then discuss how HRI is done for soft robots. We first\ndiscuss the control, design, materials and manufacturing of soft robots. This\nwill provide an understanding of what is being interacted with. Then we discuss\nabout the various input and output modalities that are used in HRI. The\napplications where the HRI for soft robots are found in the literature are\ndiscussed in detail. Then the limitations of HRI for soft robots and various\nresearch opportunities that exist in this field are discussed in detail. It is\nconcluded that there is a huge scope for development for HRI for soft robots."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01127",
    "c_title":[
      "Beyond Visibility Limits: A DRL-Based Navigation Strategy for Unexpected\n  Obstacles"
    ],
    "c_abstract":[
      "Distance-based reward mechanisms in deep reinforcement learning (DRL)\nnavigation systems suffer from critical safety limitations in dynamic\nenvironments, frequently resulting in collisions when visibility is restricted.\nWe propose DRL-NSUO, a novel navigation strategy for unexpected obstacles that\nleverages the rate of change in LiDAR data as a dynamic environmental\nperception element. Our approach incorporates a composite reward function with\nenvironmental change rate constraints and dynamically adjusted weights through\ncurriculum learning, enabling robots to autonomously balance between path\nefficiency and safety maximization. We enhance sensitivity to nearby obstacles\nby implementing short-range feature preprocessing of LiDAR data. Experimental\nresults demonstrate that this method significantly improves both robot and\npedestrian safety in complex scenarios compared to traditional DRL-based\nmethods. When evaluated on the BARN navigation dataset, our method achieved\nsuperior performance with success rates of 94.0% at 0.5 m\/s and 91.0% at 1.0\nm\/s, outperforming conservative obstacle expansion strategies. These results\nvalidate DRL-NSUO's enhanced practicality and safety for human-robot\ncollaborative environments, including intelligent logistics applications."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-615",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20927",
    "b_title":[
      "Goal-Oriented Semantic Communication for Wireless Video Transmission via\n  Generative AI"
    ],
    "b_abstract":[
      "Efficient video transmission is essential for seamless communication and\ncollaboration within the visually-driven digital landscape. To achieve low\nlatency and high-quality video transmission over a bandwidth-constrained noisy\nwireless channel, we propose a stable diffusion (SD)-based goal-oriented\nsemantic communication (GSC) framework. In this framework, we first design a\nsemantic encoder that effectively identify the keyframes from video and extract\nthe relevant semantic information (SI) to reduce the transmission data size. We\nthen develop a semantic decoder to reconstruct the keyframes from the received\nSI and further generate the full video from the reconstructed keyframes using\nframe interpolation to ensure high-quality reconstruction. Recognizing the\nimpact of wireless channel noise on SI transmission, we also propose an\nSD-based denoiser for GSC (SD-GSC) condition on an instantaneous channel gain\nto remove the channel noise from the received noisy SI under a known channel.\nFor scenarios with an unknown channel, we further propose a parallel SD\ndenoiser for GSC (PSD-GSC) to jointly learn the distribution of channel gains\nand denoise the received SI. It is shown that, with the known channel, our\nproposed SD-GSC outperforms state-of-the-art ADJSCC, Latent-Diff DNSC, DeepWiVe\nand DVST, improving Peak Signal-to-Noise Ratio (PSNR) by 69%, 58%, 33% and 38%,\nreducing mean squared error (MSE) by 52%, 50%, 41% and 45%, and reducing\nFr\\'echet Video Distance (FVD) by 38%, 32%, 22% and 24%, respectively. With the\nunknown channel, our PSD-GSC achieves a 17% improvement in PSNR, a 29%\nreduction in MSE, and a 19% reduction in FVD compared to MMSE\nequalizer-enhanced SD-GSC. These significant performance improvements\ndemonstrate the robustness and superiority of our proposed methods in enhancing\nvideo transmission quality and efficiency under various channel conditions."
    ],
    "b_categories":[
      [
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.11883",
    "c_title":[
      "Gain-MLP: Improving HDR Gain Map Encoding via a Lightweight MLP"
    ],
    "c_abstract":[
      "While most images shared on the web and social media platforms are encoded in\nstandard dynamic range (SDR), many displays now can accommodate high dynamic\nrange (HDR) content. Additionally, modern cameras can capture images in an HDR\nformat but convert them to SDR to ensure maximum compatibility with existing\nworkflows and legacy displays. To support both SDR and HDR, new encoding\nformats are emerging that store additional metadata in SDR images in the form\nof a gain map. When applied to the SDR image, the gain map recovers the HDR\nversion of the image as needed. These gain maps, however, are typically\ndown-sampled and encoded using standard image compression, such as JPEG and\nHEIC, which can result in unwanted artifacts. In this paper, we propose to use\na lightweight multi-layer perceptron (MLP) network to encode the gain map. The\nMLP is optimized using the SDR image information as input and provides superior\nperformance in terms of HDR reconstruction. Moreover, the MLP-based approach\nuses a fixed memory footprint (10 KB) and requires no additional adjustments to\naccommodate different image sizes or encoding parameters. We conduct extensive\nexperiments on various MLP based HDR embedding strategies and demonstrate that\nour approach outperforms the current state-of-the-art."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-616",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10153",
    "b_title":[
      "Contemporaneous optical-radio observations of a fast radio burst in a\n  close galaxy pair"
    ],
    "b_abstract":[
      "We present the MeerKAT discovery and MeerLICHT contemporaneous optical\nobservations of the Fast Radio Burst (FRB) 20230808F, which was found to have a\ndispersion measure of $\\mathrm{DM}=653.2\\pm0.4\\mathrm{\\,pc\\,cm^{-3}}$. FRB\n20230808F has a scattering timescale $\\tau_{s}=3.1\\pm0.1\\,\\mathrm{ms}$ at\n$1563.6$ MHz, a rotation measure\n$\\mathrm{RM}=169.4\\pm0.2\\,\\mathrm{rad\\,m^{-2}}$, and a radio fluence\n$F_{\\mathrm{radio}}=1.72\\pm0.01\\,\\mathrm{Jy\\,ms}$. We find no optical\ncounterpart in the time immediately after the FRB, nor in the three months\nafter the FRB during which we continued to monitor the field of the FRB. We set\nan optical upper flux limit in MeerLICHT's $q$-band of $11.7\\,\\mathrm{\\mu Jy}$\nfor a 60 s exposure which started $\\sim3.4$ s after the burst, which\ncorresponds to an optical fluence, $F_{\\mathrm{opt}}$, of\n$0.039\\,\\mathrm{Jy\\,ms}$ on a timescale of $\\sim3.4$ s. We obtain an estimate\nfor the $q-$band luminosity limit of $vL_{v}\\sim\n1.3\\times10^{43}\\,\\mathrm{erg\\,s^{-1}}$. We localise the burst to a close\ngalaxy pair at a redshift of $z_{\\mathrm{spec}}=0.3472\\pm0.0002$. Our time\ndelay of $\\sim3.4$ s between the FRB arrival time and the start of our optical\nexposure is the shortest ever for an as yet non-repeating FRB, and hence the\nclosest to simultaneous optical follow-up that exists for such an FRB."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17360",
    "c_title":[
      "Observing Rayleigh-Taylor stable and unstable accretion through a Kalman\n  filter analysis of X-ray pulsars in the Small Magellanic Cloud"
    ],
    "c_abstract":[
      "Global, three-dimensional, magnetohydrodynamic simulations of Rayleigh-Taylor\ninstabilities at the disk-magnetosphere boundary of rotating, magnetized,\ncompact stellar objects reveal that accretion occurs in three regimes: the\nstable regime, the chaotic unstable regime, and the ordered unstable regime.\nHere we track stochastic fluctuations in the pulse period $P(t)$ and aperiodic\nX-ray luminosity $L(t)$ time series of 24 accretion-powered pulsars in the\nSmall Magellanic Cloud using an unscented Kalman filter to analyze Rossi X-ray\nTiming Explorer data. We measure time-resolved histories of the\nmagnetocentrifugal fastness parameter $\\omega(t)$ and we connect $\\omega(t)$\nwith the three Rayleigh-Taylor accretion regimes. The 24 objects separate into\ntwo distinct groups, with 10 accreting in the stable regime, and 14 accreting\nin the ordered unstable regime. None of the 24 objects except SXP 293 visit the\nchaotic unstable regime for sustained intervals, although several objects visit\nit sporadically. The Kalman filter output also reveals a positive temporal\ncross-correlation between $\\omega(t)$ and the independently measured pulse\namplitude $A(t)$, which agrees with simulation predictions regarding the\npulse-forming behavior of magnetospheric funnel flows in the three accretion\nregimes."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-617",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09023",
    "b_title":[
      "Super-resolution measurement of thermo-optic coefficient of KTP crystal\n  based on phase amplification"
    ],
    "b_abstract":[
      "Given that the phase amplification method based on harmonic generation\nexhibits significant phase super-resolution capability in interferometric\nprecision measurement, extending this technology to birefringence\ninterferometers to achieve super-resolution characterization of birefringent\ncrystal properties has important research significance and application value.\nHere, we achieve a four-fold enhancement in the measurement resolution of the\nthermo-optic coefficient of a KTiOPO4 crystal by combining a self-stabilized\nbirefringence interferometer with cascaded second harmonic generation\nprocesses. We observe the tunable interference beating phenomenon by rotating a\nbirefringent crystal versus the temperature of the crystal for the fundamental\nwave, second harmonic, and fourth harmonic. Furthermore, the fourth harmonic\ninterference fringes beat 4 times faster than the fundamental wave interference\nfringes. This beating effect is used to determine the thermo-optic coefficients\nof the two principal refractive axes with a single measurement. This work\nprovides a feasible, real-time, and robust method for super-resolution\nmeasurements based on birefringence interferometry."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05766",
    "c_title":[
      "Flexible Full-Stokes Polarization Engineering by Disorder-Scrambled\n  Metasurfaces"
    ],
    "c_abstract":[
      "Abstract: The ability to arbitrarily and flexibly control the polarization of\nlight, including both the state of polarization (SoP) and the degree of\npolarization (DoP), is highly important for quantum optics, polarization\nimaging, and coherent optical communications. Although metasurfaces have shown\npromise in polarization control, the few studies focusing on the DoP often lack\nflexibility in manipulation. Here, we propose a novel approach using a\ndisordered metasurface to flexibly convert natural light into partially\npolarized light, enabling independent and flexible control over all Stokes\nparameters. The metasurface is composed of two types of meta-atoms, uniformly\ndistributed with specific quantity ratios, decoupling the design parameters in\nthe process of polarization control, and allowing a one-to-one correspondence\nbetween metasurface and polarization spaces. The azimuthal and elevation angles\nof the SoP on the Poincar\\'e sphere are independently controlled by the\nmeta-atom rotation and size, while the DoP is governed by the quantity ratio. A\ndeveloped algorithm determines the disordered metasurface arrangement, with\ntheoretical calculations showing an average error of less than 3{\\deg} for both\nthe azimuthal and elevation angles and a control accuracy of \\pm 0.05 for the\nDoP."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-618",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14264",
    "b_title":[
      "Positivity Proofs for Linear Recurrences with Several Dominant\n  Eigenvalues"
    ],
    "b_abstract":[
      "Deciding the positivity of a sequence defined by a linear recurrence and\ninitial conditions is, in general, a hard problem. When the coefficients of the\nrecurrences are constants, decidability has only been proven up to order 5. The\ndifficulty arises when the characteristic polynomial of the recurrence has\nseveral roots of maximal modulus, called dominant roots of the recurrence. We\nstudy the positivity problem for recurrences with polynomial coefficients,\nfocusing on sequences of Poincar\\'e type, which are perturbations of\nconstant-coefficient recurrences. The dominant eigenvalues of a recurrence in\nthis class are the dominant roots of the associated constant-coefficient\nrecurrence. Previously, we have proved the decidability of positivity for\nrecurrences having a unique, simple, dominant eigenvalue, under a genericity\nassumption. The associated algorithm proves positivity by constructing a\npositive cone contracted by the recurrence operator. We extend this cone-based\napproach to a larger class of recurrences, where a contracted cone may no\nlonger exist. The main idea is to construct a sequence of cones. Each cone in\nthis sequence is mapped by the recurrence operator to the next. This\nconstruction can be applied to prove positivity by induction. For recurrences\nwith several simple dominant eigenvalues, we provide a condition that ensures\nthat these successive inclusions hold. Additionally, we demonstrate the\napplicability of our method through examples, including recurrences with a\ndouble dominant eigenvalue."
    ],
    "b_categories":[
      [
        "cs.SC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03381",
    "c_title":[
      "THOI: An efficient and accessible library for computing higher-order\n  interactions enhanced by batch-processing"
    ],
    "c_abstract":[
      "Complex systems are characterized by nonlinear dynamics, multi-level\ninteractions, and emergent collective behaviors. Traditional analyses that\nfocus solely on pairwise interactions often oversimplify these systems,\nneglecting the higher-order interactions critical for understanding their full\ncollective dynamics. Recent advances in multivariate information theory provide\na principled framework for quantifying these higher-order interactions,\ncapturing key properties such as redundancy, synergy, shared randomness, and\ncollective constraints. However, two major challenges persist: accurately\nestimating joint entropies and addressing the combinatorial explosion of\ninteracting terms. To overcome these challenges, we introduce THOI (Torch-based\nHigh-Order Interactions), a novel, accessible, and efficient Python library for\ncomputing high-order interactions in continuous-valued systems. THOI leverages\nthe well-established Gaussian copula method for joint entropy estimation,\ncombined with state-of-the-art batch and parallel processing techniques to\noptimize performance across CPU, GPU, and TPU environments. Our results\ndemonstrate that THOI significantly outperforms existing tools in terms of\nspeed and scalability. For larger systems, where exhaustive analysis is\ncomputationally impractical, THOI integrates optimization strategies that make\nhigher-order interaction analysis feasible. We validate THOI accuracy using\nsynthetic datasets with parametrically controlled interactions and further\nillustrate its utility by analyzing fMRI data from human subjects in wakeful\nresting states and under deep anesthesia. Finally, we analyzed over 900\nreal-world and synthetic datasets, establishing a comprehensive framework for\napplying higher-order interaction (HOI) analysis in complex systems."
    ],
    "c_categories":[
      [
        "cs.SC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-619",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20756",
    "b_title":[
      "A general quasilinear elliptic problem with variable exponents and\n  Neumann boundary conditions for image processing"
    ],
    "b_abstract":[
      "The aim of this paper is to state and prove existence and uniqueness results\nfor a general elliptic problem with homogeneous Neumann boundary conditions,\noften associated with image processing tasks like denoising. The novelty is\nthat we surpass the lack of coercivity of the Euler-Lagrange functional with an\ninnovative technique that has at its core the idea of showing that the minimum\nof the energy functional over a subset of the space $W^{1,p(x)}(\\Omega)$\ncoincides with the global minimum. The obtained existence result applies to\nmultiple-phase elliptic problems under remarkably weak assumptions."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.12746",
    "c_title":[
      "Transonic Shocks for 2-D Steady Euler Flows with Large Gravity in an\n  Almost Flat Nozzle for Polytropic Gases"
    ],
    "c_abstract":[
      "In this paper, we are concerned with the existence of transonic shock\nsolutions for two-dimensional (2-d) steady Euler flows of polytropic gases\nunder vertical gravity in a horizontal nozzle. The acceleration g of the\ngravity is assumed to take a generic value. And a pressure condition is imposed\nat the exit of the nozzle to determine the position of the shock front, as\nproposed by R. Courant and K.O. Friedrichs in their monograp Supersonic Flow\nand Shock Waves. It is first shown that the existence of special transonic\nshock solutions with the flow states depending only on the variable in the\ngravity direction can be established if and only if the Mach number of the\nincoming flow satisfies certain conditions. However, the shock position of the\nspecial solutions admits shifting in the nozzle. Then we show that the shock\nposition can be determined and the existence of transonic shock solution can be\nestablished as the boundary data are small perturbation of one of the special\nshock solutions and satisfy certain sufficient conditions. Mathematically, the\nperturbation problem can be formulated as a free boundary problem of a\nnonlinear mixed-type system, and the key difficulties in the analysis are\nmainly brought by the vertical gravity. Methods and techniques are developed in\nthis paper to deal with these key difficulties. It finally turns out that the\nvertical gravity plays a dominant role in the mechanism determining the\nadmissible shock position."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-620",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15612",
    "b_title":[
      "LaTIM: Measuring Latent Token-to-Token Interactions in Mamba Models"
    ],
    "b_abstract":[
      "State space models (SSMs), such as Mamba, have emerged as an efficient\nalternative to transformers for long-context sequence modeling. However,\ndespite their growing adoption, SSMs lack the interpretability tools that have\nbeen crucial for understanding and improving attention-based architectures.\nWhile recent efforts provide insights into Mamba's internal mechanisms, they do\nnot explicitly decompose token-wise contributions, leaving gaps in\nunderstanding how Mamba selectively processes sequences across layers. In this\nwork, we introduce LaTIM, a novel token-level decomposition method for both\nMamba-1 and Mamba-2 that enables fine-grained interpretability. We extensively\nevaluate our method across diverse tasks, including machine translation,\ncopying, and retrieval-based generation, demonstrating its effectiveness in\nrevealing Mamba's token-to-token interaction patterns."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01553",
    "c_title":[
      "Co-creation for Sign Language Processing and Machine Translation"
    ],
    "c_abstract":[
      "Sign language machine translation (SLMT) -- the task of automatically\ntranslating between sign and spoken languages or between sign languages -- is a\ncomplex task within the field of NLP. Its multi-modal and non-linear nature\nrequire the joint efforts of sign language (SL) linguists, technical experts\nand SL users. Effective user involvement is a challenge that can be addressed\nthrough co-creation. Co-creation has been formally defined in many fields, e.g.\nbusiness, marketing, educational and others, however in NLP and in particular\nin SLMT there is no formal, widely accepted definition. Starting from the\ninception and evolution of co-creation across various fields over time, we\ndevelop a relationship typology to address the collaboration between deaf, Hard\nof Hearing and hearing researchers and the co-creation with SL-users. We\ncompare this new typology to the guiding principles of participatory design for\nNLP. We, then, assess 110 articles from the perspective of involvement of SL\nusers and highlight the lack of involvement of the sign language community or\nusers in decision-making processes required for effective co-creation. Finally,\nwe derive formal guidelines for co-creation for SLMT which take the dynamic\nnature of co-creation throughout the life cycle of a research project into\naccount."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-621",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18282",
    "b_title":[
      "TrackID3x3: A Dataset and Algorithm for Multi-Player Tracking with\n  Identification and Pose Estimation in 3x3 Basketball Full-court Videos"
    ],
    "b_abstract":[
      "Multi-object tracking, player identification, and pose estimation are\nfundamental components of sports analytics, essential for analyzing player\nmovements, performance, and tactical strategies. However, existing datasets and\nmethodologies primarily target mainstream team sports such as soccer and\nconventional 5-on-5 basketball, often overlooking scenarios involving\nfixed-camera setups commonly used at amateur levels, less mainstream sports, or\ndatasets that explicitly incorporate pose annotations. In this paper, we\npropose the TrackID3x3 dataset, the first publicly available comprehensive\ndataset specifically designed for multi-player tracking, player identification,\nand pose estimation in 3x3 basketball scenarios. The dataset comprises three\ndistinct subsets (Indoor fixed-camera, Outdoor fixed-camera, and Drone camera\nfootage), capturing diverse full-court camera perspectives and environments. We\nalso introduce the Track-ID task, a simplified variant of the game state\nreconstruction task that excludes field detection and focuses exclusively on\nfixed-camera scenarios. To evaluate performance, we propose a baseline\nalgorithm called Track-ID algorithm, tailored to assess tracking and\nidentification quality. Furthermore, our benchmark experiments, utilizing\nrecent multi-object tracking algorithms (e.g., BoT-SORT-ReID) and top-down pose\nestimation methods (HRNet, RTMPose, and SwinPose), demonstrate robust results\nand highlight remaining challenges. Our dataset and evaluation benchmarks\nprovide a solid foundation for advancing automated analytics in 3x3 basketball.\nDataset and code will be available at\nhttps:\/\/github.com\/open-starlab\/TrackID3x3."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13947",
    "c_title":[
      "Conformal Prediction and MLLM aided Uncertainty Quantification in Scene\n  Graph Generation"
    ],
    "c_abstract":[
      "Scene Graph Generation (SGG) aims to represent visual scenes by identifying\nobjects and their pairwise relationships, providing a structured understanding\nof image content. However, inherent challenges like long-tailed class\ndistributions and prediction variability necessitate uncertainty quantification\nin SGG for its practical viability. In this paper, we introduce a novel\nConformal Prediction (CP) based framework, adaptive to any existing SGG method,\nfor quantifying their predictive uncertainty by constructing well-calibrated\nprediction sets over their generated scene graphs. These scene graph prediction\nsets are designed to achieve statistically rigorous coverage guarantees.\nAdditionally, to ensure these prediction sets contain the most practically\ninterpretable scene graphs, we design an effective MLLM-based post-processing\nstrategy for selecting the most visually and semantically plausible scene\ngraphs within these prediction sets. We show that our proposed approach can\nproduce diverse possible scene graphs from an image, assess the reliability of\nSGG methods, and improve overall SGG performance."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-622",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02254",
    "b_title":[
      "A min-max reformulation and proximal algorithms for a class of\n  structured nonsmooth fractional optimization problems"
    ],
    "b_abstract":[
      "In this paper, we consider a class of structured nonsmooth fractional\nminimization, where the first part of the objective is the ratio of a\nnonnegative nonsmooth nonconvex function to a nonnegative nonsmooth convex\nfunction, while the second part is the difference of a smooth nonconvex\nfunction and a nonsmooth convex function. This model problem has many important\napplications, for example, the scale-invariant sparse signal recovery in signal\nprocessing. However, the existing methods for fractional programs are not\nsuitable for solving this problem due to its special structure. We first\npresent a novel nonfractional min-max reformulation for the original fractional\nprogram and show the connections between their global (local) optimal solutions\nand stationary points. Based on the reformulation, we propose an alternating\nmaximization proximal descent algorithm and show its subsequential convergence\ntowards a critical point of the original fractional program under a mild\nassumption. By further assuming the Kurdyka-{\\L}ojasiewicz (KL) property of an\nauxiliary function, we also establish the convergence of the entire solution\nsequence generated by the proposed algorithm. Finally, some numerical\nexperiments on the scale-invariant sparse signal recovery are conducted to\ndemonstrate the efficiency of the proposed method."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.13849",
    "c_title":[
      "A low-rank augmented Lagrangian method for doubly nonnegative\n  relaxations of mixed-binary quadratic programs"
    ],
    "c_abstract":[
      "Doubly nonnegative (DNN) programming problems are known to be challenging to\nsolve because of their huge number of $\\Omega(n^2)$ constraints and\n$\\Omega(n^2)$ variables. In this work, we introduce RNNAL, a method for solving\nDNN relaxations of large-scale mixed-binary quadratic programs by leveraging\ntheir solutions' possible low-rank property. RNNAL is a globally convergent\nRiemannian augmented Lagrangian method (ALM) that penalizes the nonnegativity\nand complementarity constraints while preserving all other constraints as an\nalgebraic variety. After applying the low-rank decomposition to the ALM\nsubproblem, its feasible region becomes an algebraic variety with favorable\ngeometric properties. Our low-rank decomposition model is different from the\nstandard Burer-Monteiro (BM) decomposition model in that we make the key\nimprovement to equivalently reformulate most of the quadratic constraints after\nthe BM decomposition into fewer and more manageable affine constraints. This\nmodification is also important in helping us to alleviate the violation of\nSlater's condition for the primal DNN problem. Moreover, we make the crucial\nstep to show that the metric projection onto the algebraic variety, although\nnon-convex, can be transformed into a solvable convex optimization problem\nunder certain regularity conditions, which can be ensured by a\nconstraint-relaxation strategy. RNNAL is able to handle general semidefinite\nprogramming (SDP) with additional polyhedral cone constraints, thus serving as\na prototype algorithm for solving general DNN problems. Numerous numerical\nexperiments are conducted to validate the efficiency of the proposed RNNAL\nmethod."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-623",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11838",
    "b_title":[
      "Mass loss along the red giant branch of the intermediate stellar\n  populations in NGC6752 and NGC2808"
    ],
    "b_abstract":[
      "The morphology of the Horizontal Branch (HB) in Globular Clusters (GC) is\namong the early evidences that they contain multiple populations of stars.\nIndeed, the location of each star along the HB depends both on its initial\nhelium content (Y) and on the global average mass loss along the red giant\nbranch ($\\mu$). In most GCs, it is generally straightforward to analyse the\nfirst stellar population (standard Y), and the most extreme one (largest Y),\nwhile it is more tricky to look at the \"intermediate\" populations (mildly\nenhanced Y). In this work, we do this for the GCs NGC6752 and NGC2808; wherever\npossible the helium abundance for each stellar populations is constrained by\nusing independent measurements present in the literature. We compare population\nsynthesis models with photometric catalogues from the Hubble Space Telescope\nTreasury survey to derive the parameters of these HB stars. We find that the\nlocation of helium enriched stars on the HB is reproduced only by adopting a\nhigher value of $\\mu$ with respect to the first generation stars in all the\nanalysed stellar populations. We also find that $\\mu$ correlates with the\nhelium enhancement of the populations. This holds for both clusters. This\nfinding is naturally predicted by the model of ''pre-main sequence disc early\nloss'', previously suggested in the literature, and is consistent with the\nfindings of multiple-populations formation models that foresee the formation of\nsecond generation stars in a cooling flow."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.08190",
    "c_title":[
      "Farside helioseismology with Sun-as-a-star data: the solar cycle as seen\n  with 7-day-long BiSON timeseries"
    ],
    "c_abstract":[
      "We present results from fitting $p$-mode spectra derived from 7-d segments of\nSun-as-a-star helioseismic observations from the Birmingham Solar Oscillations\nNetwork covering 32 yr. The results show a clear dependence of the mode\nfrequencies on solar activity, and the frequency dependence of the sensitivity\nto activity can also be seen. Because we use data segments that cover less than\nhalf of a solar rotation, we are able to test for the effect of activity on the\nsolar far side. By fitting with a model that takes into account activity on the\nfar side of the Sun, we show that the frequency shifts are sensitive to\nactivity from the whole Sun, not just the side facing the observer. Our results\nsuggest that there is potential to investigate activity-related asteroseismic\nfrequency shifts in solar-like oscillators using short time series of\nobservations."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-624",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02991",
    "b_title":[
      "The Derrida-Retaux model on a geometric Galton-Watson tree"
    ],
    "b_abstract":[
      "We consider a generalized Derrida-Retaux model on a Galton-Watson tree with a\ngeometric offspring distribution. For a class of recursive systems, including\nthe Derrida-Retaux model with either a geometric or exponential initial\ndistribution, we characterize the critical curve using an involution-type\nequation and prove that the free energy satisfies the Derrida-Retaux\nconjecture."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.15551",
    "c_title":[
      "Reinforced Galton--Watson processes III: Empirical offspring\n  distributions"
    ],
    "c_abstract":[
      "Reinforced Galton--Watson processes describe the dynamics of a population\nwhere reproduction events are reinforced, in the sense that offspring numbers\nof forebears can be repeated randomly by descendants. More specifically, the\nevolution depends on the empirical offspring distribution of each individual\nalong its ancestral lineage. We are interested here in asymptotic properties of\nthe empirical distributions observed in the population, such as concentration,\nevanescence and persistence. For this, we incorporate tools from the theory of\nlarge deviations to our preceding analysis [arXiv:2306.02476,arXiv:2310.19030]."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-625",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03455",
    "b_title":[
      "Towards Continuous Experiment-driven MLOps"
    ],
    "b_abstract":[
      "Despite advancements in MLOps and AutoML, ML development still remains\nchallenging for data scientists. First, there is poor support for and limited\ncontrol over optimizing and evolving ML models. Second, there is lack of\nefficient mechanisms for continuous evolution of ML models which would leverage\nthe knowledge gained in previous optimizations of the same or different models.\nWe propose an experiment-driven MLOps approach which tackles these problems.\nOur approach relies on the concept of an experiment, which embodies a fully\ncontrollable optimization process. It introduces full traceability and\nrepeatability to the optimization process, allows humans to be in full control\nof it, and enables continuous improvement of the ML system. Importantly, it\nalso establishes knowledge, which is carried over and built across a series of\nexperiments and allows for improving the efficiency of experimentation over\ntime. We demonstrate our approach through its realization and application in\nthe ExtremeXP1 project (Horizon Europe)."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11792",
    "c_title":[
      "Software Process as a Service: Towards A Software Process Ecosystem"
    ],
    "c_abstract":[
      "In large-scale projects operated in regulated environments, standard\ndevelopment processes are employed to meet strict compliance demands. Since\nsuch processes are usually complex, providing process users with access to\ntheir required process, which should be tailored to a project's needs is a\nchallenging task that requires proper tool support. In this paper, we present a\nprocess ecosystem in which software processes are provided as web-based\nservices. We outline the general idea, describe the modeling approach, and we\nillustrate the concept's realization using a proof-of-concept case based on a\nlarge software process line that is mandatory to use for IT projects in the\nGerman public sector. The suitability is evaluated with three experts that\nvalued the improved accessibly and usability of the process and the end-user\nsupport tool."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-626",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15626",
    "b_title":[
      "A Scalable Game-Theoretic Approach for Selecting Security Controls from\n  Standardized Catalogues"
    ],
    "b_abstract":[
      "Selecting the combination of security controls that will most effectively\nprotect a system's assets is a difficult task. If the wrong controls are\nselected, the system may be left vulnerable to cyber-attacks that can impact\nthe confidentiality, integrity, and availability of critical data and services.\nIn practical settings, as standardized control catalogues can be quite large,\nit is not possible to select and implement every control possible. Instead,\nconsiderations, such as budget, effectiveness, and dependencies among various\ncontrols, must be considered to choose a combination of security controls that\nbest achieve a set of system security objectives. In this paper, we present a\ngame-theoretic approach for selecting effective combinations of security\ncontrols based on expected attacker profiles and a set budget. The control\nselection problem is set up as a two-person zero-sum one-shot game. Valid\ncontrol combinations for selection are generated using an algebraic formalism\nto account for dependencies among selected controls. Using a software tool, we\napply the approach on a fictional Canadian military system with Canada's\nstandardized control catalogue, ITSG-33. Through this case study, we\ndemonstrate the approach's scalability to assist in selecting an effective set\nof security controls for large systems. The results illustrate how a security\nanalyst can use the proposed approach and supporting tool to guide and support\ndecision-making in the control selection activity when developing secure\nsystems of all sizes."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02049",
    "c_title":[
      "USeR: A Web-based User Story eReviewer for Assisted Quality\n  Optimizations"
    ],
    "c_abstract":[
      "User stories are widely applied for conveying requirements within agile\nsoftware development teams. Multiple user story quality guidelines exist, but\nauthors like Product Owners in industry projects frequently fail to write\nhigh-quality user stories. This situation is exacerbated by the lack of tools\nfor assessing user story quality. In this paper, we propose User Story\neReviewer (USeR) a web-based tool that allows authors to determine and optimize\nuser story quality. For developing USeR, we collected 77 potential quality\nmetrics through literature review, practitioner sessions, and research group\nmeetings and refined these to 34 applicable metrics through expert sessions.\nFinally, we derived algorithms for eight prioritized metrics using a literature\nreview and research group meetings and implemented them with plain code and\nmachine learning techniques. USeR offers a RESTful API and user interface for\ninstant, consistent, and explainable user feedback supporting fast and easy\nquality optimizations. It has been empirically evaluated with an expert study\nusing 100 user stories and four experts from two real-world agile software\nprojects in the automotive and health sectors."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-627",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19835",
    "b_title":[
      "Disjoint $X$-paths in bidirected graphs"
    ],
    "b_abstract":[
      "Let $B$ be a bidirected multigraph with signing $\\sigma$, let $X$ be a set of\nvertices in $B$, and let $k$ be a non-negative integer. For any pair of vertex\nsets $S,T\\subset V(B)$ satisfying $X\\cap S = X\\cap T$, we denote by $B_{S,T}$\nthe multigraph with the same vertex set as $B$ and with edge set consisting of\nthose edges $e$ of $B$ each of whose endvertices $v$ satisfies $v\\notin S\\cup\nT$ or $v\\in S\\setminus T$, $\\sigma(v,e)=-$ or $v\\in T\\setminus S$,\n$\\sigma(v,e)=+$. We prove that $B$ admits a set of $k$ pairwise disjoint\n$X$-paths if and only if for any $S,T\\subseteq V(B)$ with $X\\cap S = X\\cap T$,\nthe inequality $\\left\\lvert S\\cap T \\right\\rvert +\\sum \\lfloor \\tfrac{1}{2}\n\\left\\lvert V(C)\\cap (X\\cup S\\cup T) \\right\\rvert \\rfloor \\geq k$ holds where\nthe sum is indexed by the components of $B_{S,T}$. This result is a\ngeneralization of a result of Gallai from undirected graphs to bidirected ones.\nFurthermore, we will deduce from this a kind of an Erd\\H{o}s-P\\'osa property\nfor $X$-paths in bidirected multigraphs."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.08636",
    "c_title":[
      "On Lattice Tilings of Asymmetric Limited-Magnitude Balls\n  $\\cB(n,2,m,m-1)$"
    ],
    "c_abstract":[
      "Limited-magnitude errors modify a transmitted integer vector in at most $t$\nentries, where each entry can increase by at most $\\kp$ or decrease by at most\n$\\km$. This channel model is particularly relevant to applications such as\nflash memories and DNA storage. A perfect code for this channel is equivalent\nto a tiling of $\\Z^n$ by asymmetric limited-magnitude balls $\\cB(n,t,\\kp,\\km)$.\nIn this paper, we focus on the case where $t=2$ and $\\km=\\kp-1$, and we derive\nnecessary conditions on $m$ and $n$ for the existence of a lattice tiling of\n$\\cB(n,2,m,m-1)$. Specifically, we prove that for each $m$, there are only\nfinitely many $n$ for which such a lattice tiling is possible. Moreover, for\n$m=2$, we show that no lattice tiling of $\\cB(n,2,2,1)$ exists for any $n\\geq\n3$."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-628",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01557",
    "b_title":[
      "Click-Calib: A Robust Extrinsic Calibration Method for Surround-View\n  Systems"
    ],
    "b_abstract":[
      "Surround-View System (SVS) is an essential component in Advanced Driver\nAssistance System (ADAS) and requires precise calibrations. However,\nconventional offline extrinsic calibration methods are cumbersome and\ntime-consuming as they rely heavily on physical patterns. Additionally, these\nmethods primarily focus on short-range areas surrounding the vehicle, resulting\nin lower calibration quality in more distant zones. To address these\nlimitations, we propose Click-Calib, a pattern-free approach for offline SVS\nextrinsic calibration. Without requiring any special setup, the user only needs\nto click a few keypoints on the ground in natural scenes. Unlike other offline\ncalibration approaches, Click-Calib optimizes camera poses over a wide range by\nminimizing reprojection distance errors of keypoints, thereby achieving\naccurate calibrations at both short and long distances. Furthermore,\nClick-Calib supports both single-frame and multiple-frame modes, with the\nlatter offering even better results. Evaluations on our in-house dataset and\nthe public WoodScape dataset demonstrate its superior accuracy and robustness\ncompared to baseline methods. Code is available at\nhttps:\/\/github.com\/lwangvaleo\/click_calib."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04762",
    "c_title":[
      "Autoregressive Generation of Static and Growing Trees"
    ],
    "c_abstract":[
      "We propose a transformer architecture and training strategy for tree\ngeneration. The architecture processes data at multiple resolutions and has an\nhourglass shape, with middle layers processing fewer tokens than outer layers.\nSimilar to convolutional networks, we introduce longer range skip connections\nto completent this multi-resolution approach. The key advantage of this\narchitecture is the faster processing speed and lower memory consumption. We\nare therefore able to process more complex trees than would be possible with a\nvanilla transformer architecture. Furthermore, we extend this approach to\nperform image-to-tree and point-cloud-to-tree conditional generation and to\nsimulate the tree growth processes, generating 4D trees. Empirical results\nvalidate our approach in terms of speed, memory consumption, and generation\nquality."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-629",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15220",
    "b_title":[
      "On a class of binary regression models and their robust estimation"
    ],
    "b_abstract":[
      "A robust estimation framework for binary regression models is studied, aiming\nto extend traditional approaches like logistic regression models. While\nprevious studies largely focused on logistic models, we explore a broader class\nof models defined by general link functions. We incorporate various loss\nfunctions to improve estimation under model misspecification. Our investigation\naddresses robustness against outliers and model misspecifications, leveraging\ndivergence-based techniques such as the $\\beta$-divergence and\n$\\gamma$-divergence, which generalize the maximum likelihood approach. These\ndivergences introduce loss functions that mitigate the influence of atypical\ndata points while retaining Fisher consistency. We establish a theoretical\nproperty of the estimators under both correctly specified and misspecified\nmodels, analyzing their robustness through quantifying the effect of outliers\nin linear predictor. Furthermore, we uncover novel relationships between\nexisting estimators and robust loss functions, identifying previously\nunexplored classes of robust estimators. Numerical experiments illustrate the\nefficacy of the proposed methods across various contamination scenarios,\ndemonstrating their potential to enhance reliability in binary classification\ntasks. By providing a unified framework, this study highlights the versatility\nand robustness of divergence-based methods, offering insights into their\npractical application and theoretical underpinnings."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.07275",
    "c_title":[
      "Distilling heterogeneous treatment effects: Stable subgroup estimation\n  in causal inference"
    ],
    "c_abstract":[
      "Recent methodological developments have introduced new black-box approaches\nto better estimate heterogeneous treatment effects; however, these methods fall\nshort of providing interpretable characterizations of the underlying\nindividuals who may be most at risk or benefit most from receiving the\ntreatment, thereby limiting their practical utility. In this work, we introduce\ncausal distillation trees (CDT) to estimate interpretable subgroups. CDT allows\nresearchers to fit any machine learning model to estimate the individual-level\ntreatment effect, and then leverages a simple, second-stage tree-based model to\n\"distill\" the estimated treatment effect into meaningful subgroups. As a\nresult, CDT inherits the improvements in predictive performance from black-box\nmachine learning models while preserving the interpretability of a simple\ndecision tree. We derive theoretical guarantees for the consistency of the\nestimated subgroups using CDT, and introduce stability-driven diagnostics for\nresearchers to evaluate the quality of the estimated subgroups. We illustrate\nour proposed method on a randomized controlled trial of antiretroviral\ntreatment for HIV from the AIDS Clinical Trials Group Study 175 and show that\nCDT out-performs state-of-the-art approaches in constructing stable, clinically\nrelevant subgroups."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-630",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01060",
    "b_title":[
      "$S$, $T$, $U$ Parameters in The B-LSSM"
    ],
    "b_abstract":[
      "Using the pinch technique, we compute the one-loop vertices of weak\ninteractions in the B-LSSM and incorporate their pinch contributions into the\ngauge boson self-energies. Compared to the definitions of the $S$, $T$, and $U$\nparameters in the Standard Model based on the $SU(2)_L\\otimes U(1)_Y$ group,\nthe corresponding parameters in the B-LSSM are modified. We provide these\nredefined $S$, $T$, and $U$ parameters and demonstrate the convergence of the\nresults. In the framework of the low-energy effective Lagrangian for weak\ninteractions, the $S$, $T$, and $U$ parameters can be expressed as functions of\ncertain parameters in the B-LSSM. The updated experimental and fitting results\nconstrain the parameter space of the B-LSSM strongly."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.18667",
    "c_title":[
      "Machine Learning Approaches to Top Quark Flavor-Changing Four-Fermion\n  Interactions in Trilepton Signals at the LHC"
    ],
    "c_abstract":[
      "We explore the top quark flavor-changing 4-Fermi interactions ($tuee$ and\n$tcee$) with scalar, vector, and tensor structures using machine learning\nmodels to analyze tri-lepton processes at the LHC. The study is performed using\n$t\\bar{t}$ and $tW$ processes, where a top quark decays into $u\/c+e^{+}+e^{-}$.\nThe analysis incorporates both reducible and irreducible backgrounds while\naccounting for realistic detector effects. The dominant backgrounds for these\ntrilepton signatures arise from $t\\bar{t}$ production, single top quark\nproduction in association with $V$, and $VV$ production (where $V = W, Z$).\nThese backgrounds are significantly reduced using machine learning-based\nclassification models, which optimize event selection and improve signal\nsensitivity. For an integrated luminosity of 3000 fb$^{-1}$ at the LHC, we find\nthat the expected $95\\%$ confidence level (CL) limits on the scale of 4-Fermi\nFCNC interactions reach $\\Lambda \\leq 5.5$ TeV for $tuee$ and $\\Lambda \\leq\n5.7$ TeV for $tcee$ in the $t\\bar{t}$ channel, and $\\Lambda \\leq 1.9$ TeV\n($tuee$) and $\\Lambda \\leq 2.0$ TeV ($tcee$) in the $tW$ channel. We also\nprovide an interpretation of our EFT analysis in the context of a specific $Z'$\nmodel, illustrating how the derived constraints translate into bounds on the\nparameter space of a heavy neutral gauge boson mediating flavor-changing\ninteractions."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-631",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09524",
    "b_title":[
      "H-infinity and Complex Interpolation"
    ],
    "b_abstract":[
      "This note is an (exact) copy of the report of Jaak Peetre, \"H-infinity and\nComplex Interpolation\". Published as Technical Report, Lund (1981). Some more\nrecent general references have been added, some references updated though (in\nitalics) and some misprints corrected."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.21103",
    "c_title":[
      "Arens extensions of disjointness preserving multilinear operators on\n  Riesz spaces"
    ],
    "c_abstract":[
      "Let $E_1, \\ldots, E_m$ be (non necessarily Archimedean) Riesz spaces, let $F$\nbe an Archimedean Riesz space and let $A \\colon E_1 \\times \\cdots \\times E_m\n\\to F$ be an order bounded disjointness preserving $m$-linear operator. We\nprove that all Arens extensions of $A$ are disjointness preserving if either\n$A$ has finite rank or the spaces are Banach lattices and $F^*$ has a Schauder\nbasis consisting of disjointness preserving functionals."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-632",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10542",
    "b_title":[
      "Static Algorithm, Evolving Epidemic: Understanding the Potential of\n  Human-AI Risk Assessment to Support Regional Overdose Prevention"
    ],
    "b_abstract":[
      "Drug overdose deaths, including those due to prescription opioids, represent\na critical public health issue in the United States and worldwide. Artificial\nintelligence (AI) approaches have been developed and deployed to help\nprescribers assess a patient's risk for overdose-related death, but it is\nunknown whether public health experts can leverage similar predictions to make\nlocal resource allocation decisions more effectively. In this work, we\nevaluated how AI-based overdose risk assessment could be used to inform local\npublic health decisions using a working prototype system. Experts from three\nhealth departments, of varying locations and sizes with respect to staff and\npopulation served, were receptive to the potential benefits of algorithmic risk\nprediction and of using AI-augmented visualization to connect across data\nsources. However, they also expressed concerns about whether the risk\nprediction model's formulation and underlying data would match the state of the\noverdose epidemic as it evolved in their specific locations. Our findings\nextend those of other studies on algorithmic systems in the public sector, and\nthey present opportunities for future human-AI collaborative tools to support\ndecision-making in local, time-varying contexts."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.08471",
    "c_title":[
      "Computed fingertip touch for the instrumental control of musical sound\n  with an excursion on the computed retinal afterimage"
    ],
    "c_abstract":[
      "In this thesis, we present an articulated, empirical view on what human music\nmaking is, and on how this fundamentally relates to computation. The\nexperimental evidence which we obtained seems to indicate that this view can be\nused as a tool, to systematically generate models, hypotheses and new\ntechnologies that enable an ever more complete answer to the fundamental\nquestion as to what forms of instrumental control of musical sound are possible\nto implement. This also entails the development of two novel transducer\ntechnologies for computed fingertip touch: The cyclotactor (CT) system, which\nprovides fingerpad-orthogonal force output while tracking surface-orthogonal\nfingertip movement; and the kinetic surface friction transducer (KSFT) system,\nwhich provides fingerpad-parallel force output while tracking surface-parallel\nfingertip movement.\n  In addition to the main research, the thesis also contains two research\nexcursions, which are due to the nature of the Ph.D. position. The first\nexcursion shows how repeated and varying pressing movements on the already\nheld-down key of a computer keyboard can be used both to simplify existing user\ninteractions and to implement new ones, that allow the rapid yet detailed\nnavigation of multiple possible interaction outcomes. The second excursion\nshows that automated computational techniques can display shape specifically in\nthe retinal afterimage, a well-known effect in the human visual system."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-633",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04893",
    "b_title":[
      "Normalized Solutions on large smooth domains to the Schr\\\"{o}dinger\n  equation with potential and general nonlinearity: Mass super-critical case"
    ],
    "b_abstract":[
      "In this paper, we consider the existence and multiplicity of prescribed mass\nsolutions to the following nonlinear Schr\\\"{o}dinger equation with general\nnonlinearity: Mass super-critical case: \\[\\begin{cases} -\\Delta u+V(x)u+\\lambda\nu=g(u),\\\\ \\|u\\|_2^2=\\int|u|^2\\mathrm{d}x=c, \\end{cases} \\] both on large\nbounded smooth star-shaped domain $\\Omega\\subset\\mathbb{R}^N$ and on\n$\\mathbb{R}^N$, where $V(x)$ is the potential and the nonlinearity $g(\\cdot)$\nconsidered here are very general and of mass super-critical. The standard\napproach based on the Pohozaev identity to obtain normalized solutions is\ninvalid as the presence of potential $V(x)$. In addition, our study can be\nconsidered as a complement of Bartsch-Qi-Zou (Math Ann 390, 4813--4859, 2024),\nwhich has addressed an open problem raised in Bartsch et al. (Commun Partial\nDiffer Equ 46(9):1729--1756, 2021)."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.09539",
    "c_title":[
      "Existence of weak solutions for fast diffusion equation with a\n  divergence type of drift term"
    ],
    "c_abstract":[
      "We construct non-negative weak solutions of fast diffusion equations with a\ndivergence type of drift term satisfying the $L^q$-energy inequality and speed\nestimate in Wasserstein spaces under some integrability conditions on the drift\nterm. Furthermore, in the case that the drift term has a divergence-free\nstructure, it turns out that its integrability conditions can be relaxed, which\nis also applicable to porous medium equations, thereby improving previous\nresults. As an application, the existence of weak solutions is also discussed\nfor a viscous Boussinesq system of the fast diffusion type."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-634",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16626",
    "b_title":[
      "Hyper-active repeating fast radio bursts from rotation modulated\n  starquakes on magnetars"
    ],
    "b_abstract":[
      "The non-detection of periodicity related to rotation challenges the magnetar\nmodel for fast radio bursts (FRBs). Moreover, a bimodal distribution of the\nburst waiting times is widely observed in hyper-active FRBs, a significant\ndeviation from the exponential distribution expected from stationary Poisson\nprocesses. By combining the epidemic-type aftershock sequence (ETAS) earthquake\nmodel and the rotating vector model (RVM) involving the rotation of the\nmagnetar and orientations of the spin and magnetic axes, we find that starquake\nevents modulated by the rotation of FRB-emitting magnetar can explain the\nbimodal distribution of FRB waiting times, as well as the non-detection of\nperiodicity in active repeating FRBs. We analyze data from multiple FRB\nsources, demonstrating that differences in waiting time distributions and\nobserved energies can be explained by varying parameters related to magnetar\nproperties and starquake dynamics. Our results suggest that rotation-modulated\nstarquakes on magnetars can possibly be a unified source for FRBs. Notably, we\nfind that active repeaters tend to have small magnetic inclination angles in\norder to hide their periodicity. We also show that our model can reproduce the\nwaiting time distribution of a pulsar phase of the galactic magnetar SGR\nJ1935+2154 with a larger inclination angle than the active repeaters, which\ncould explain the detection of spin period and the relatively low observed\nenergy for FRBs from the magnetar. The spin periods of active repeaters are not\nwell constrained, but most likely fall in the valley region between the two\npeaks of the waiting time distributions."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.19051",
    "c_title":[
      "Two-component jet model for the afterglow emission of GRB 201216C and\n  GRB 221009A and implications for jet structure of very-high-energy gamma-ray\n  bursts"
    ],
    "c_abstract":[
      "In recent years, afterglow emission in the very-high-energy (VHE) band above\n100 GeV have been clearly detected for at least five gamma-ray bursts (GRBs\n180720B, 190114C, 190829A, 201216C and 221009A). For some of these VHE GRBs, we\npreviously proposed a two-component jet model, consisting of two uniform jets\nwith narrow and wide opening angles to explain their multiwavelength afterglows\nincluding VHE gamma rays. In this paper, we show that the VHE emission from\nGRBs 201216C and 221009A can be also explained by our two-component jet model.\nWe find that the collimation-corrected kinetic energy of the five VHE GRBs have\ntypical values of 5\\times10^{49} erg and 5\\times10^{50} erg for the narrow and\nwide jets, respectively. We discuss the similarities and differences among the\nVHE GRBs, and the implications for the structure of their jets. In particular,\nthe narrow jet of GRB 221009A has a smaller opening angle, which can explain\nwhy its isotropic-equivalent energy is unusually large."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-635",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11077",
    "b_title":[
      "Isolated vertices in two duplication-divergence models with edge\n  deletion"
    ],
    "b_abstract":[
      "Duplication-divergence models are a popular model for the evolution of gene\nand protein interaction networks. However, existing duplication-divergence\nmodels often neglect realistic features such as loss of interactions. Thus, in\nthis paper we present two novel models that incorporate random edge deletions\ninto the duplication-divergence framework. As in protein-protein interaction\nnetworks, with proteins as vertices and interactions as edges, by design\nisolated vertices tend to be rare, our main focus is on the number of isolated\nvertices; our main result gives lower and upper bounds for the proportion of\nisolated vertices, when the network size is large. Using these bounds we\nidentify the parameter regimes for which almost all vertices are typically\nisolated; and also show that there are parameter regimes in which the\nproportion of isolated vertices can be bounded away from 0 and 1 with high\nprobability. In addition, we find regimes in which the proportion of isolated\nvertices tends to be small. The proof relies on a standard martingale argument,\nwhich in turn requires a careful analysis of the first two moments of the\nexpected degree distribution. The theoretical findings are illustrated by\nsimulations, indicating that as the network size tends to infinity, the\nproportion of isolated vertices can converge to a limit that is neither 0 or 1."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.00371",
    "c_title":[
      "$\\mathbb{L}^p$ $(p>1)$-solutions for BSDEs with jumps and stochastic\n  monotone generator"
    ],
    "c_abstract":[
      "We study multidimensional discontinuous backward stochastic differential\nequations in a filtration that supports both a Brownian motion and an\nindependent integer-valued random measure. Under suitable\n$\\mathbb{L}^p$-integrability conditions on the data, we establish the existence\nand uniqueness of $\\mathbb{L}^p$-solutions for both cases: $p \\geq 2$ and $p\n\\in (1,2)$. The generator is assumed to be stochastically monotone in the state\nvariable $y$, stochastically Lipschitz in the control variables $(z, u)$, and\nto satisfy a stochastic linear growth condition, along with an appropriate\n$\\mathbb{L}^p$-integrability requirement."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-636",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13464",
    "b_title":[
      "Mapping Research Data at the University of Bologna"
    ],
    "b_abstract":[
      "Research data management (RDM) strategies and practices play a pivotal role\nin adhering to the paradigms of reproducibility and transparency by enabling\nresearch sharing in accordance with the principles of Open Science.\nDiscipline-specificity is an essential factor when understanding RDM\ndeclinations, to tailor a comprehensive support service and to enhance\ninterdisciplinarity.\n  In this paper we present the results of a mapping carried out to gather\ninformation on research data generated and managed within the University of\nBologna (UniBO). The aim is to identify differences and commonalities between\ndisciplines and potential challenges for institutional support.\n  We analyzed the data management plans (DMPs) of European competitive projects\ndrafted by researchers affiliated with UniBO. We applied descriptive statistics\nto the collected variables to answer three main questions: How diverse is the\nrange of data managed within the University of Bologna? Which trends of\nproblems and patterns in terms of data management can influence\/improve data\nstewardship service? Is there an interdisciplinary approach to data production\nwithin the University?\n  The research work evidenced many points of contact between different\ndisciplines in terms of data produced, formats used and modest predilection for\ndata reuse. Hot topics such as data confidentiality, needed either on privacy\nor intellectual property rights (IPR) premises, and long-term preservation pose\nchallenges to all researchers.\n  These results show an increasing attention to RDM while highlighting the\nrelevance of training and support to face the relatively new challenges posed\nby this approach."
    ],
    "b_categories":[
      [
        "cs.DL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.01407",
    "c_title":[
      "Research Data in Scientific Publications: A Cross-Field Analysis"
    ],
    "c_abstract":[
      "Data sharing is fundamental to scientific progress, enhancing transparency,\nreproducibility, and innovation across disciplines. Despite its growing\nsignificance, the variability of data-sharing practices across research fields\nremains insufficiently understood, limiting the development of effective\npolicies and infrastructure. This study investigates the evolving landscape of\ndata-sharing practices, specifically focusing on the intentions behind data\nrelease, reuse, and referencing. Leveraging the PubMed open dataset, we\ndeveloped a model to identify mentions of datasets in the full-text of\npublications. Our analysis reveals that data release is the most prevalent\nsharing mode, particularly in fields such as Commerce, Management, and the\nCreative Arts. In contrast, STEM fields, especially the Biological and\nAgricultural Sciences, show significantly higher rates of data reuse. However,\nthe humanities and social sciences are slower to adopt these practices.\nNotably, dataset referencing remains low across most disciplines, suggesting\nthat datasets are not yet fully recognized as research outputs. A temporal\nanalysis highlights an acceleration in data releases after 2012, yet obstacles\nsuch as data discoverability and compatibility for reuse persist. Our findings\ncan inform institutional and policy-level efforts to improve data-sharing\npractices, enhance dataset accessibility, and promote broader adoption of open\nscience principles across research domains."
    ],
    "c_categories":[
      [
        "cs.DL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-637",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16792",
    "b_title":[
      "Anomalous Landau levels and quantum oscillation in rotation-invariant\n  insulators"
    ],
    "b_abstract":[
      "Landau levels in certain models are known to protrude into the zero-field\nenergy gap. These are known as anomalous Landau levels (ALLs). We study whether\nALLs can lead to in-gap quantum oscillation in the absence of a zero-field\nFermi surface. Focusing on two-dimensional multi-band low-energy models of\nelectrons with continuous rotation symmetry, we show that an effective-band\ndescription, akin to the semiclassical treatment of Landau level problems in\nmetals, can be used to predict the Landau level spectrum, including possible\nALLs. This description then predicts quantum oscillation for certain insulating\nmodels, which we demonstrate through numerical calculations."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04808",
    "c_title":[
      "Rotational magnetoelastic interactions in the Dzyaloshinskii-Moriya\n  magnet Ba$_2$CuGe$_2$O$_7$"
    ],
    "c_abstract":[
      "We report the magnetoelastic properties of a Ba$_2$CuGe$_2$O$_7$ single\ncrystal at low temperatures under a magnetic field applied along the\ncrystallographic [001] axis. Our results extend to low temperature the $H-T$\nphase diagram determined for this compound by neutron scattering. Furthermore,\nwe observe that specific elastic modes are better sensitive to the various\nmagnetic transitions. In particular, we observe an unusual coupling between the\nin-plane transverse acoustic mode and the cycloidal order at low field, which\nsuggests a novel spin-strain mechanism originating from Dzyaloshinskii-Moriya\ninteraction in this compound."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-638",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08535",
    "b_title":[
      "Astrophysical properties of star clusters projected toward tidally\n  perturbed SMC regions"
    ],
    "b_abstract":[
      "We report on the astrophysical properties of a sample of star clusters in the\nSmall Magellanic Cloud (SMC). They have been selected with the aim of looking\nfor the connection between their ages, heliocentric distances and metallicities\nwith the existence of tidally perturbed\/induced outermost SMC regions. We\nderived the star cluster fundamental parameters from relatively deep Survey of\nthe Magellanic Stellar History (SMASH) DR2 color magnitude diagrams, cleaned\nfrom field star contamination, and compared to thousand synthetic CMDs covering\na wide range of heliocentric distances, ages and metal content. Heliocentric\ndistances for 15 star clusters are derived for the first time, which represents\nan increase of 50 per cent of SMC clusters with estimated heliocentric\ndistances. The analysis of the age-metallicity relationships (AMRs) of cluster\nlocated in outermost regions distributed around the SMC and in the SMC Main\nBody reveals that they have followed the overall galaxy chemical enrichment\nhistory. However, since half of the studied clusters are placed in front of or\nbehind the SMC Main Body, we concluded that they formed in the SMC and have\ntraveled outward because of the tidal effects from the interaction with the\nLarge Magellanic Cloud (LMC). Furthermore, metal rich clusters formed recently\nin some of these outermost regions from gas that was also dragged by tidal\neffects from the inner SMC. This outcome leads to consider the SMC as a galaxy\nscarred by the LMC tidal interaction with distance-perturbed and newly induced\noutermost stellar substructures."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20439",
    "c_title":[
      "Chronology of our Galaxy from Gaia colour-magnitude diagram fitting\n  (ChronoGal) -- III. Age and metallicity distribution of\n  Gaia-Sausage-Enceladus stars near the Sun"
    ],
    "c_abstract":[
      "Context. Gaia-Sausage-Enceladus is considered the last major merger that\ncontributed to the formation of the Milky Way. Its remnants dominate the nearby\naccreted stellar halo of the Milky Way. Aim. We aim to characterise the star\nformation history of Gaia-Sausage-Enceladus through the age and metallicity of\nits stellar populations. Methods. From Gaia DR3 data, we dynamically define\nthree Gaia-Sausage-Enceladus samples with different criteria and possible\ndegrees of contamination from other substructures in the halo. Then, we derive\nthe stellar age and metallicity distributions using the CMDfit.Gaia package.\nResults. We identify three main populations of stars and a fourth smaller one\nfollowing an almost linear age-[M\/H] relation. The three oldest populations\ncorrespond to the bulk of the star formation that lasted for, at least,\n$\\sim$3-4 Gyr and ended about 10 Gyr ago, its metallicities ranging from $-$1.7\nto $-$0.8. We categorise these populations into two main epochs: the evolution\nof GSE in isolation and the merger event. This separation finds independent\nsupport from the age-metallicty relation of GSE globular clusters\n(Aguado-Agelet et al., subm.). The fourth population is younger and more\nmetal-rich, at $\\sim$8.5 Gyr and [M\/H]$\\sim-0.4$; its link to GSE is unclear."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-639",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03387",
    "b_title":[
      "Space Charge Doping Induced Band Modulation in Mono- and Bi-layer\n  Graphene: a nano-ARPES study"
    ],
    "b_abstract":[
      "Controlled modulation of electronic band structure in two-dimensional (2D)\nmaterials via doping is crucial for devices fabrication. For instance doped\ngraphene has been envisaged for various applications like sensors,\nsuper-capacitors, transistors, p-n junctions, photo-detectors, etc. Many\ndifferent techniques have been developed to achieve desired doping in 2D\nmaterials, like chemical doping, electrostatic doping, substrate doping, etc.\nHere, we have combined space charge doping with space and angle resolved\nphotoemission (nano-ARPES), in order to directly observe the Fermi level\nmodulation on micron-sized flakes of monolayer and bilayer graphene. The doping\nlevel can be tuned in a controlled manner, which allows us to directly observe\nthe Fermi level tuning. In our experiment we successfully doped the graphene\nwith p- and n-type carriers (holes\/electrons) which are directly observed\nthrough band shift in ARPES measurements. The observed band shift is $\\sim$250\nmeV for bilayer and $\\sim$500 meV for monolayer graphene. The results from our\nexperiment promote the space charge doping technique and nano-ARPES into other\nmaterials such as 2D semiconductors and superconductors, in order to directly\nobserve the physical phenomena such as band gap transition and phase transition\nas function of carrier doping."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.17750",
    "c_title":[
      "Ductility mechanisms in complex concentrated refractory alloys from\n  atomistic fracture simulations"
    ],
    "c_abstract":[
      "The striking variation in damage tolerance among refractory complex\nconcentrated alloys is examined through the analysis of atomistic fracture\nsimulations, contrasting behavior in elemental Nb with that in brittle NbMoTaW\nand ductile Nb45Ta25Ti15Hf15. We employ machine-learning interatomic potentials\n(MLIPs), including a new MLIP developed for NbTaTiHf, in atomistic simulations\nof crack tip extension mechanisms based on analyses of atomistic fracture\nresistance curves. While the initial behavior of sharp cracks shows good\ncorrespondence with the Rice theory, fracture resistance curves reveal marked\nchanges in fracture modes for the complex alloys as crack extension proceeds.\nIn NbMoTaW, compositional complexity appears to promote dislocation nucleation\nrelative to pure Nb, despite theoretical predictions that the alloy should be\nrelatively more brittle. In Nb45Ta25Ti15Hf15, alloying not only changes the\nfracture mode relative to elemental Nb, but promotes dislocation accumulation\nat the crack tip, leading to higher resistance to crack propagation."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-640",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15345",
    "b_title":[
      "Is the Radcliffe wave turbulent?"
    ],
    "b_abstract":[
      "We use the observed vertical velocity field, of various young tracers of the\ngas kinematics, obtained by Li and Chen (2022), Konietzka et al. (2024) and Zhu\net al. (2024), in order to test for the existence of turbulence. We do so by\ncomputing the power spectrum and the structure function of the vertical\nvelocity field. The latter suggest the existence of compressible, Burgers,\nturbulence.\n  The turbulence timescale on the largest spatial scale is about 500 Myr ,\nimplying that the turbulence has been generated 500 Myr ago. The turbulence\nregion depth in a direction perpendicular to the Radcliffe wave direction is\n  about 400 pc."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.06778",
    "c_title":[
      "ALMACAL XIII. Evolution of the CO luminosity function and the molecular\n  gas mass density out to $z$ ~ 6"
    ],
    "c_abstract":[
      "Cold molecular gas, largely traced by CO emission, is the primary fuel for\nstar formation, making it essential for understanding galaxy evolution. ALMA\nhas made significant progress in the study of the cosmic evolution of cold\nmolecular gas. Here, we exploit the ALMACAL survey to address issues relating\nto small sample sizes and cosmic variance, utilising calibration data from ALMA\nto compile a statistically significant and essentially unbiased sample of\nCO-selected galaxies. By employing a novel statistical approach to\nemission-line classification using semi-analytical models, we place strong\nconstraints on the CO luminosity function and the cosmic evolution of molecular\ngas mass density ($\\rho_{H_2}$) back to $z \\sim 6$. The cosmic molecular gas\nmass density increases with redshift, peaking around $z \\sim 1.5$, then slowly\ndeclines towards higher redshifts by $\\sim 1$ dex. Our findings confirm the key\nrole of molecular gas in fuelling star formation. The new $\\rho_{H_2}$\nestimates allow us to revisit the cosmic baryon cycle, showing that the ratio\nof molecular gas-to-stellar mass density is consistent with the so-called\n'bathtub model' of baryons, which implies a continuous replenishment of gas.\nThe cosmic gas depletion timescale, estimated on a global scale, is shown to be\nfairly constant at all redshifts. We emphasise the importance of surveys using\nmultiple small fields rather than a single contiguous area to mitigate the\neffects of cosmic variance."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-641",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03457",
    "b_title":[
      "Measure of maximal entropy for minimal Anosov actions"
    ],
    "b_abstract":[
      "For a minimal Anosov $\\mathbb R^{\\kappa}$-action on a closed manifold, we\nstudy the measure of maximal entropy constructed by Carrasco and\nRodriguez-Hertz in \\cite{CarHer} and show that it fits into the theory of\nRuelle-Taylor resonances introduced by Guedes Bonthonneau, Guillarmou, Hilgert,\nand Weich in \\cite{GBGHW}. More precisely, we show that the topological entropy\ncorresponds to the first Ruelle-Taylor resonance for the action on a certain\nbundle of forms and that the measure of maximal entropy can be retrieved as the\ndistributional product of the corresponding resonant and co-resonant states. As\na consequence, we prove a Bowen-type formula for the measure of maximal entropy\nand a counting result on the number of periodic torii."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.01589",
    "c_title":[
      "Capturing the critical coupling of large random Kuramoto networks with\n  graphons"
    ],
    "c_abstract":[
      "Collective oscillations and patterns of synchrony have long fascinated\nresearchers in the applied sciences, particularly due to their far-reaching\nimportance in chemistry, physics, and biology. The Kuramoto model has emerged\nas a prototypical mathematical equation to understand synchronization in\ncoupled oscillators, allowing one to study the effect of different frequency\ndistributions and connection networks between oscillators. In this work we\nprovide a framework for determining both the emergence and the persistence of\nsynchronous solutions to Kuramoto models on large random networks and with\nrandom frequencies. This is achieved by appealing the theory of graphons to\nanalyze a mean-field model coming in the form of an infinite oscillator limit\nwhich provides a single master equation for studying random Kuramoto models. We\nshow that bifurcations to synchrony and hyperbolic synchrony patterns in the\nmean-field model can also be found in related random Kuramoto networks for\nlarge numbers of oscillators. We further provide a detailed application of our\nresults to oscillators arranged on Erd\\H{o}s--R\\'enyi random networks, for\nwhich we further identify that not all bifurcations to synchrony emerge through\nsimple co-dimension one bifurcations."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-642",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12516",
    "b_title":[
      "Can LLMs Extract Frame-Semantic Arguments?"
    ],
    "b_abstract":[
      "Frame-semantic parsing is a critical task in natural language understanding,\nyet the ability of large language models (LLMs) to extract frame-semantic\narguments remains underexplored. This paper presents a comprehensive evaluation\nof LLMs on frame-semantic argument identification, analyzing the impact of\ninput representation formats, model architectures, and generalization to unseen\nand out-of-domain samples. Our experiments, spanning models from 0.5B to 78B\nparameters, reveal that JSON-based representations significantly enhance\nperformance, and while larger models generally perform better, smaller models\ncan achieve competitive results through fine-tuning. We also introduce a novel\napproach to frame identification leveraging predicted frame elements, achieving\nstate-of-the-art performance on ambiguous targets. Despite strong\ngeneralization capabilities, our analysis finds that LLMs still struggle with\nout-of-domain data."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10838",
    "c_title":[
      "Who Relies More on World Knowledge and Bias for Syntactic Ambiguity\n  Resolution: Humans or LLMs?"
    ],
    "c_abstract":[
      "This study explores how recent large language models (LLMs) navigate relative\nclause attachment {ambiguity} and use world knowledge biases for disambiguation\nin six typologically diverse languages: English, Chinese, Japanese, Korean,\nRussian, and Spanish. We describe the process of creating a novel dataset --\nMultiWho -- for fine-grained evaluation of relative clause attachment\npreferences in ambiguous and unambiguous contexts. Our experiments with three\nLLMs indicate that, contrary to humans, LLMs consistently exhibit a preference\nfor local attachment, displaying limited responsiveness to syntactic variations\nor language-specific attachment patterns. Although LLMs performed well in\nunambiguous cases, they rigidly prioritized world knowledge biases, lacking the\nflexibility of human language processing. These findings highlight the need for\nmore diverse, pragmatically nuanced multilingual training to improve LLMs'\nhandling of complex structures and human-like comprehension."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-643",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16904",
    "b_title":[
      "Adversarial Masked Autoencoder Purifier with Defense Transferability"
    ],
    "b_abstract":[
      "The study of adversarial defense still struggles to combat with advanced\nadversarial attacks. In contrast to most prior studies that rely on the\ndiffusion model for test-time defense to remarkably increase the inference\ntime, we propose Masked AutoEncoder Purifier (MAEP), which integrates Masked\nAutoEncoder (MAE) into an adversarial purifier framework for test-time\npurification. While MAEP achieves promising adversarial robustness, it\nparticularly features model defense transferability and attack generalization\nwithout relying on using additional data that is different from the training\ndataset. To our knowledge, MAEP is the first study of adversarial purifier\nbased on MAE. Extensive experimental results demonstrate that our method can\nnot only maintain clear accuracy with only a slight drop but also exhibit a\nclose gap between the clean and robust accuracy. Notably, MAEP trained on\nCIFAR10 achieves state-of-the-art performance even when tested directly on\nImageNet, outperforming existing diffusion-based models trained specifically on\nImageNet."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05173",
    "c_title":[
      "VideoRoPE: What Makes for Good Video Rotary Position Embedding?"
    ],
    "c_abstract":[
      "While Rotary Position Embedding (RoPE) and its variants are widely adopted\nfor their long-context capabilities, the extension of the 1D RoPE to video,\nwith its complex spatio-temporal structure, remains an open challenge. This\nwork first introduces a comprehensive analysis that identifies four key\ncharacteristics essential for the effective adaptation of RoPE to video, which\nhave not been fully considered in prior work. As part of our analysis, we\nintroduce a challenging V-NIAH-D (Visual Needle-In-A-Haystack with Distractors)\ntask, which adds periodic distractors into V-NIAH. The V-NIAH-D task\ndemonstrates that previous RoPE variants, lacking appropriate temporal\ndimension allocation, are easily misled by distractors. Based on our analysis,\nwe introduce \\textbf{VideoRoPE}, with a \\textit{3D structure} designed to\npreserve spatio-temporal relationships. VideoRoPE features\n\\textit{low-frequency temporal allocation} to mitigate periodic oscillations, a\n\\textit{diagonal layout} to maintain spatial symmetry, and \\textit{adjustable\ntemporal spacing} to decouple temporal and spatial indexing. VideoRoPE\nconsistently surpasses previous RoPE variants, across diverse downstream tasks\nsuch as long video retrieval, video understanding, and video hallucination. Our\ncode will be available at\n\\href{https:\/\/github.com\/Wiselnn570\/VideoRoPE}{https:\/\/github.com\/Wiselnn570\/VideoRoPE}."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-644",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00241",
    "b_title":[
      "Accuracy and capacity of Modern Hopfield networks with synaptic noise"
    ],
    "b_abstract":[
      "We study the retrieval accuracy and capacity of modern Hopfield networks of\nwith two-state (Ising) spins interacting via modified Hebbian $n$-spin\ninteractions. In particular, we consider systems where the interactions deviate\nfrom the Hebb rule through additive or multiplicative noise or through clipping\nor deleting interactions. We find that the capacity scales as $N^{n-1}$ with\nthe number of spins $N$ in all cases, but with a prefactor reduced compared to\nthe Hebbian case. For $n=2$ our results agree with the previously known results\nfor the conventional $n = 2$ Hopfield network."
    ],
    "b_categories":[
      [
        "cond-mat.dis-nn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04282",
    "c_title":[
      "Isolating the hard core of phaseless inference: the Phase selection\n  formulation"
    ],
    "c_abstract":[
      "Real-valued Phase retrieval is a non-convex continuous inference problem,\nwhere a high-dimensional signal is to be reconstructed from a dataset of\nsignless linear measurements. Focusing on the noiseless case, we aim to\ndisentangle the two distinct sub-tasks entailed in the Phase retrieval problem:\nthe hard combinatorial problem of retrieving the missing signs of the\nmeasurements, and the nested convex problem of regressing the input-output\nobservations to recover the hidden signal. To this end, we introduce and\nanalytically characterize a two-level formulation of the problem, called\n``Phase selection''. Within the Replica Theory framework, we perform a large\ndeviation analysis to characterize the minimum mean squared error achievable\nwith different guesses for the hidden signs. Moreover, we study the free-energy\nlandscape of the problem when both levels are optimized simultaneously, as a\nfunction of the dataset size. At low temperatures, in proximity to the\nBayes-optimal threshold -- previously derived in the context of Phase retrieval\n-- we detect the coexistence of two free-energy branches, one connected to the\nrandom initialization condition and a second to the signal. We derive the phase\ndiagram for a first-order transition after which the two branches merge.\nInterestingly, introducing an $L_2$ regularization in the regression sub-task\ncan anticipate the transition to lower dataset sizes, at the cost of a bias in\nthe signal reconstructions which can be removed by annealing the regularization\nintensity. Finally, we study the inference performance of three meta-heuristics\nin the context of Phase selection: Simulated Annealing, Approximate Message\nPassing, and Langevin Dynamics on the continuous relaxation of the sign\nvariables. With simultaneous annealing of the temperature and the $L_2$\nregularization, they are shown to approach the Bayes-optimal sample efficiency."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-645",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01685",
    "b_title":[
      "IAM: Enhancing RGB-D Instance Segmentation with New Benchmarks"
    ],
    "b_abstract":[
      "Image segmentation is a vital task for providing human assistance and\nenhancing autonomy in our daily lives. In particular, RGB-D\nsegmentation-leveraging both visual and depth cues-has attracted increasing\nattention as it promises richer scene understanding than RGB-only methods.\nHowever, most existing efforts have primarily focused on semantic segmentation\nand thus leave a critical gap. There is a relative scarcity of instance-level\nRGB-D segmentation datasets, which restricts current methods to broad category\ndistinctions rather than fully capturing the fine-grained details required for\nrecognizing individual objects. To bridge this gap, we introduce three RGB-D\ninstance segmentation benchmarks, distinguished at the instance level. These\ndatasets are versatile, supporting a wide range of applications from indoor\nnavigation to robotic manipulation. In addition, we present an extensive\nevaluation of various baseline models on these benchmarks. This comprehensive\nanalysis identifies both their strengths and shortcomings, guiding future work\ntoward more robust, generalizable solutions. Finally, we propose a simple yet\neffective method for RGB-D data integration. Extensive evaluations affirm the\neffectiveness of our approach, offering a robust framework for advancing toward\nmore nuanced scene understanding."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17131",
    "c_title":[
      "Scenario Understanding of Traffic Scenes Through Large Visual Language\n  Models"
    ],
    "c_abstract":[
      "Deep learning models for autonomous driving, encompassing perception,\nplanning, and control, depend on vast datasets to achieve their high\nperformance. However, their generalization often suffers due to domain-specific\ndata distributions, making an effective scene-based categorization of samples\nnecessary to improve their reliability across diverse domains. Manual\ncaptioning, though valuable, is both labor-intensive and time-consuming,\ncreating a bottleneck in the data annotation process. Large Visual Language\nModels (LVLMs) present a compelling solution by automating image analysis and\ncategorization through contextual queries, often without requiring retraining\nfor new categories. In this study, we evaluate the capabilities of LVLMs,\nincluding GPT-4 and LLaVA, to understand and classify urban traffic scenes on\nboth an in-house dataset and the BDD100K. We propose a scalable captioning\npipeline that integrates state-of-the-art models, enabling a flexible\ndeployment on new datasets. Our analysis, combining quantitative metrics with\nqualitative insights, demonstrates the effectiveness of LVLMs to understand\nurban traffic scenarios and highlights their potential as an efficient tool for\ndata-driven advancements in autonomous driving."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-646",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02204",
    "b_title":[
      "Deuterated Polycyclic Aromatic Hydrocarbons in the Interstellar Medium:\n  Constraints from the Orion Bar as Observed by the James Webb Space Telescope"
    ],
    "b_abstract":[
      "The gas-phase abundances of deuterium (D) in the local interstellar medium\n(ISM) exhibit considerable regional variations. Particularly, in some regions\nthe gas-phase D abundances are substantially lower than the primordial D\nabundance generated in the Big Bang, after subtracting the astration reduction\ncaused by the Galactic chemical evolution. Deuterated polycyclic aromatic\nhydrocarbon (PAH) molecules have been suggested as a potential reservoir of the\nD atoms missing from the gas-phase. Recent observations from the James Webb\nSpace Telescope's Near Infrared Spectrograph have revealed the widespread of\ndeuterated PAHs in the Orion Bar through their aliphatic C--D emission at\n4.65${\\,{\\rm \\mu m}}$ and possibly aromatic C--D emission at 4.4${\\,{\\rm \\mu\nm}}$ as well. To examine the viability of deuterated PAHs as the D reservoir,\nwe model the infrared (IR) emission spectra of small PAH molecules containing\nvarious aromatic and aliphatic D atoms in the Orion Bar. We find that small\ndeuterated PAHs exhibit a noticeable emission band at 4.4 or 4.65${\\,{\\rm \\mu\nm}}$ even if they contain only one aromatic or aliphatic D atom. We derive\n${{N_{\\rm D,ali}}}\/{N_{\\rm H}}\\approx3.4\\%$, the deuteration degree of PAHs\nmeasured as the number of aliphatic D atoms (relative to H), from the observed\nintensity ratios of the 4.65${\\,{\\rm \\mu m}}$ band to the 3.3${\\,{\\rm \\mu m}}$\naromatic C--H band. The deuteration degree for aromatically-deuterated PAHs is\nless certain as C--N stretch also contributes to the observed emission around\n4.4${\\,{\\rm \\mu m}}$. If we attribute it exclusively to aromatic C--D, we\nderive an upper limit of $\\approx14\\%$ on the deuteration degree, which is\ncapable of accounting for an appreciable fraction of the missing D budget."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.20458",
    "c_title":[
      "Turbulence in virtual: I. Thermodynamic perspective of the $\\sigma^2$-M\n  relation"
    ],
    "c_abstract":[
      "Turbulence is a mysterious phenomenon of physical systems and plays a\ncritical role in the interstellar medium (ISM). We present a thermodynamic\nperspective on turbulence, aiming to explain the origin of the variance\n(\\(\\sigma^2\\)) of the lognormal probability density function (PDF) of gas\ndensity caused by turbulence. By introducing a virtual dissipation process, in\nwhich the entropy-increasing processes of turbulent dissipation and structural\ndissipation are assumed to be coupled, we directly derive the empirical\nrelation between the variance of the (near) log-normal PDF ($\\sigma^2$) and the\nMach number ($\\mathcal{M}$): $\\sigma^2 = \\ln(1 + b^2\\mathcal{M})^2$. We also\nexplain why $b = 1$ for compressive forcing and $b = 1\/D$ for solenoidal\nforcing, where $D$ is the dimension of the system. Furthermore, by introducing\na delay parameter $q$ for the local gas temperature, we quantitatively derive\nthe deviation of $\\sigma^2$ from the empirical relation at high $\\mathcal{M}$,\nwhich is consistent with previous simulations and observations."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-647",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20080",
    "b_title":[
      "Computational Characterization of the Recently Synthesized Pristine and\n  Porous 12-Atom-Wide Armchair Graphene Nanoribbon"
    ],
    "b_abstract":[
      "Recently synthesized Porous 12-Atom-Wide Armchair Graphene Nanoribbons Nano\nLett. 2024, 24, 10718-10723 exhibit tunable properties through periodic\nporosity, enabling precise control over their electronic, optical, thermal, and\nmechanical behavior. This work presents a comprehensive theoretical\ncharacterization of pristine and porous 12-AGNRs based on density functional\ntheory (DFT) and molecular dynamics (MD) simulations. DFT calculations reveal\nsubstantial electronic modifications, including band gap widening and the\nemergence of localized states. Analyzed within the Bethe-Salpeter equation\n(BSE) framework, optical properties highlight strong excitonic effects and\nsignificant absorption shifts. Thermal transport simulations indicate a\npronounced reduction in conductivity due to enhanced phonon scattering at\nnanopores. At the same time, MD-based mechanical analysis shows decreased\nstiffness and strength while maintaining structural integrity. Despite these\nmodifications, porous 12-AGNRs remain mechanically and thermally stable. These\nfindings establish porosity engineering as a powerful strategy for tailoring\ngraphene nanoribbons' functional properties, reinforcing their potential for\nnanoelectronic, optoelectronic, and thermal management applications."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17609",
    "c_title":[
      "Effect of bismuth crystal orientations in Nernst thermomagnetic devices"
    ],
    "c_abstract":[
      "In this work we report Nernst effect measurements in single crystal bismuth\nsamples, with special emphasis on the characterization of the Nernst\ncoefficient when the magnetic field, heat current and generated voltage are\naligned along specific directions relative to the crystal axes. We found\nsignificant differences between the different orientations, reflecting the\nhighly anisotropic electronic structure of bismuth and compatible with the\nNernst characteristics obtained from polycrystalline samples. These results not\nonly complement the experimental works published in the past but also underline\nthe role of crystalline orientation in the context of transverse thermoelectric\neffects, towards an efficient design of thermomagnetic devices like the\nordinary-Nernst-effect-based energy harvesters."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-648",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18564",
    "b_title":[
      "SAM2Act: Integrating Visual Foundation Model with A Memory Architecture\n  for Robotic Manipulation"
    ],
    "b_abstract":[
      "Robotic manipulation systems operating in diverse, dynamic environments must\nexhibit three critical abilities: multitask interaction, generalization to\nunseen scenarios, and spatial memory. While significant progress has been made\nin robotic manipulation, existing approaches often fall short in generalization\nto complex environmental variations and addressing memory-dependent tasks. To\nbridge this gap, we introduce SAM2Act, a multi-view robotic transformer-based\npolicy that leverages multi-resolution upsampling with visual representations\nfrom large-scale foundation model. SAM2Act achieves a state-of-the-art average\nsuccess rate of 86.8% across 18 tasks in the RLBench benchmark, and\ndemonstrates robust generalization on The Colosseum benchmark, with only a 4.3%\nperformance gap under diverse environmental perturbations. Building on this\nfoundation, we propose SAM2Act+, a memory-based architecture inspired by SAM2,\nwhich incorporates a memory bank, an encoder, and an attention mechanism to\nenhance spatial memory. To address the need for evaluating memory-dependent\ntasks, we introduce MemoryBench, a novel benchmark designed to assess spatial\nmemory and action recall in robotic manipulation. SAM2Act+ achieves competitive\nperformance on MemoryBench, significantly outperforming existing approaches and\npushing the boundaries of memory-enabled robotic systems. Project page:\nhttps:\/\/sam2act.github.io\/"
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18901",
    "c_title":[
      "Think on your feet: Seamless Transition between Human-like Locomotion in\n  Response to Changing Commands"
    ],
    "c_abstract":[
      "While it is relatively easier to train humanoid robots to mimic specific\nlocomotion skills, it is more challenging to learn from various motions and\nadhere to continuously changing commands. These robots must accurately track\nmotion instructions, seamlessly transition between a variety of movements, and\nmaster intermediate motions not present in their reference data. In this work,\nwe propose a novel approach that integrates human-like motion transfer with\nprecise velocity tracking by a series of improvements to classical imitation\nlearning. To enhance generalization, we employ the Wasserstein divergence\ncriterion (WGAN-div). Furthermore, a Hybrid Internal Model provides structured\nestimates of hidden states and velocity to enhance mobile stability and\nenvironment adaptability, while a curiosity bonus fosters exploration. Our\ncomprehensive method promises highly human-like locomotion that adapts to\nvarying velocity requirements, direct generalization to unseen motions and\nmultitasking, as well as zero-shot transfer to the simulator and the real world\nacross different terrains. These advancements are validated through simulations\nacross various robot models and extensive real-world experiments."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-649",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16993",
    "b_title":[
      "Pareto sensitivity, most-changing sub-fronts, and knee solutions"
    ],
    "b_abstract":[
      "When dealing with a multi-objective optimization problem, obtaining a\ncomprehensive representation of the Pareto front can be computationally\nexpensive. Furthermore, identifying the most representative Pareto solutions\ncan be difficult and sometimes ambiguous. A popular selection are the so-called\nPareto knee solutions, where a small improvement in any objective leads to a\nlarge deterioration in at least one other objective. In this paper, using\nPareto sensitivity, we show how to compute Pareto knee solutions according to\ntheir verbal definition of least maximal change. We refer to the resulting\napproach as the sensitivity knee (snee) approach, and we apply it to\nunconstrained and constrained problems. Pareto sensitivity can also be used to\ncompute the most-changing Pareto sub-fronts around a Pareto solution, where the\npoints are distributed along directions of maximum change, which could be of\ninterest in a decision-making process if one is willing to explore solutions\naround a current one. Our approach is still restricted to scalarized methods,\nin particular to the weighted-sum or epsilon-constrained methods, and require\nthe computation or approximations of first- and second-order derivatives. We\ninclude numerical results from synthetic problems that illustrate the benefits\nof our approach."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.06623",
    "c_title":[
      "Deferred-Decision Trajectory Optimization"
    ],
    "c_abstract":[
      "We present DDTO--deferred-decision trajectory optimization--a framework for\ntrajectory generation with resilience to unmodeled uncertainties and\ncontingencies. The key idea is to ensure that a collection of candidate targets\nis reachable for as long as possible while satisfying constraints, which\nprovides time to quantify the uncertainties. We propose optimization-based\nconstrained reachability formulations and construct equivalent cardinality\nminimization problems, which then inform the design of computationally\ntractable and efficient solution methods that leverage state-of-the-art convex\nsolvers and sequential convex programming (SCP) algorithms. The goal of\nestablishing the equivalence between constrained reachability and cardinality\nminimization is to provide theoretically-sound underpinnings for the proposed\nsolution methods. We demonstrate the solution methods on real-world optimal\ncontrol applications encountered in quadrotor motion planning."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-650",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03382",
    "b_title":[
      "Two-point dilation-homogeneous metric spaces"
    ],
    "b_abstract":[
      "The main aim of the paper is to give a full classification (up to isometry)\nof all metric spaces X with the following two properties: X contains a compact\nset with non-empty interior; and for any three distinct points a, b and c of X\nthere exists a (bijective) dilation on X that fixes a and sends b to c. As a\nconsequence, we obtain a new characterisation of the Euclidean spaces: these\nare (up to isometry) precisely all metric spaces that have the above two\nproperties, and (in addition) contain three distinct points x, y, z that are\nmetrically collinear (that is, for which d(x,z) = d(x,y)+d(y,z))."
    ],
    "b_categories":[
      [
        "math.MG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.02613",
    "c_title":[
      "A full classification of the isometries of the class of ball-bodies"
    ],
    "c_abstract":[
      "Complementing our previous results, we give a classification of all\nisometries (not necessarily surjective) of the metric space consisting of\nball-bodies, endowed with the Hausdorff metric. \"Ball bodies\" are convex bodies\nwhich are intersections of translates of the Euclidean unit ball. We show that\nany such isometry is either a rigid motion, or a rigid motion composed with the\nc-duality mapping. In particular, any isometry on this metric space has to be\nsurjective."
    ],
    "c_categories":[
      [
        "math.MG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-651",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11797",
    "b_title":[
      "Freidlin-Wentzell type exit-time estimates for time-inhomogeneous\n  diffusions and their applications"
    ],
    "b_abstract":[
      "This paper investigates the exit-time problem for time-inhomogeneous\ndiffusion processes. The focus is on the small-noise behavior of the exit time\nfrom a bounded positively invariant domain. We demonstrate that, when the drift\nand diffusion terms are uniformly close to some time-independent functions, the\nexit time grows exponentially both in probability and in $L_1$ as a parameter\nthat controls the noise tends to zero. We also characterize the exit position\nof the time-inhomogeneous process. Additionally, we investigate the impact of\nrelaxing the uniform closeness condition on the exit-time behavior. As an\napplication, we extend these results to the McKean-Vlasov process. Our findings\nimprove upon existing results in the literature for the exit-time problem for\nthis class of processes."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.09741",
    "c_title":[
      "Asymptotic behavior of clusters in hierarchical species sampling models"
    ],
    "c_abstract":[
      "Consider a sample of size $N$ from a population governed by a hierarchical\nspecies sampling model. We study the large $N$ asymptotic behavior of the\nnumber ${\\bf K}_N$ of clusters and the number ${\\bf M}_{r,N}$ of clusters with\nfrequency $r$ in the sample. In particular, we show almost sure and $L^p$\nconvergence for ${\\bf M}_{r,N}$, obtain Gaussian fluctuation theorems for ${\\bf\nK}_N$, and establish large deviation principles for both ${\\bf K}_N$ and ${\\bf\nM}_{r,N}$. Our approach relies on a random sample size representation of the\nnumber of clusters through the corresponding non-hierarchical species sampling\nmodel."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-652",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19032",
    "b_title":[
      "WakeMint: Detecting Sleepminting Vulnerabilities in NFT Smart Contracts"
    ],
    "b_abstract":[
      "The non-fungible tokens (NFTs) market has evolved over the past decade, with\nNFTs serving as unique digital identifiers on a blockchain that certify\nownership and authenticity. However, their high value also attracts attackers\nwho exploit vulnerabilities in NFT smart contracts for illegal profits, thereby\nharming the NFT ecosystem. One notable vulnerability in NFT smart contracts is\nsleepminting, which allows attackers to illegally transfer others' tokens.\nAlthough some research has been conducted on sleepminting, these studies are\nbasically qualitative analyses or based on historical transaction data. There\nis a lack of understanding from the contract code perspective, which is crucial\nfor identifying such issues and preventing attacks before they occur. To\naddress this gap, in this paper, we categoriz four distinct types of\nsleepminting in NFT smart contracts. Each type is accompanied by a\ncomprehensive definition and illustrative code examples to provide how these\nvulnerabilities manifest within the contract code. Furthermore, to help detect\nthe defined defects before the sleepminting problem occurrence, we propose a\ntool named WakeMint, which is built on a symbolic execution framework and is\ndesigned to be compatible with both high and low versions of Solidity. The tool\nalso employs a pruning strategy to shorten the detection period. Additionally,\nWakeMint gathers some key information, such as the owner of an NFT and\nemissions of events related to the transfer of the NFT's ownership during\nsymbolic execution. Then, it analyzes the features of the transfer function\nbased on this information so that it can judge the existence of sleepminting.\nWe ran WakeMint on 11,161 real-world NFT smart contracts and evaluated the\nresults. We found 115 instances of sleepminting issues in total, and the\nprecision of our tool is 87.8%."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06549",
    "c_title":[
      "How Does Users' App Knowledge Influence the Preferred Level of Detail\n  and Format of Software Explanations?"
    ],
    "c_abstract":[
      "Context and Motivation: Due to their increasing complexity, everyday software\nsystems are becoming increasingly opaque for users. A frequently adopted method\nto address this difficulty is explainability, which aims to make systems more\nunderstandable and usable. Question\/problem: However, explanations can also\nlead to unnecessary cognitive load. Therefore, adapting explanations to the\nactual needs of a user is a frequently faced challenge. Principal\nideas\/results: This study investigates factors influencing users' preferred the\nlevel of detail and the form of an explanation (e.g., short text or video\ntutorial) in software. We conducted an online survey with 58 participants to\nexplore relationships between demographics, software usage, app-specific\nknowledge, as well as their preferred explanation form and level of detail. The\nresults indicate that users prefer moderately detailed explanations in short\ntext formats. Correlation analyses revealed no relationship between\napp-specific knowledge and the preferred level of detail of an explanation, but\nan influence of demographic aspects (like gender) on app-specific knowledge and\nits impact on application confidence were observed, pointing to a possible\nmediated relationship between knowledge and preferences for explanations.\nContribution: Our results show that explanation preferences are weakly\ninfluenced by app-specific knowledge but shaped by demographic and\npsychological factors, supporting the development of adaptive explanation\nsystems tailored to user expertise. These findings support requirements\nanalysis processes by highlighting important factors that should be considered\nin user-centered methods such as personas."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-653",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03675",
    "b_title":[
      "The $M_{*}-M_{\\rm BH}$ Relation Evolution from z $\\sim$ 6 to the Present\n  Epoch"
    ],
    "b_abstract":[
      "The ratio between the stellar mass of a galaxy, $M_{*}$, and that of its\ncentral supermassive black hole (SMBH), $M_\\bullet$, the ``Magorrian''\nrelationship, traces their coevolution. JWST observations have suggested\nsignificant evolution in $M_\\bullet\/M_{*}$ relative to local scaling\nrelationships both in low-mass galaxies and in quasars at z $\\ge$ 4. We test\nthis possibility by (1) determining the preferred $M_\\bullet\/M_{*}$ scaling\nrelation among those proposed locally; and (2) providing uniform host galaxy\nstellar mass estimates. These steps reduce the prominence of the reported\nevolution. We then apply Monte Carlo simulations to account for observational\nbiases. We still find a significant increase over the local scaling relation in\n$M_\\bullet\/M_{*}$ for z $\\ge$ 4 SMBHs in very low-mass galaxies\n($\\log(M_*\/M_{\\odot})<10$). However, similarly high values of $M_\\bullet\/M_{*}$\nare also found in low mass galaxies at $z \\sim$ 0.5 to 3 that may be common at\ncosmic noon. Nonetheless, galaxies with similar behavior are rare locally and\nnot accounted for in the local scaling relations. In contrast, z $\\sim$ 6\nquasars can have $M_\\bullet\/M_{*}$ well above the local relation value, but\nthey can be explained as extreme cases still within the scaling relation for\ntheir higher mass host galaxies. Black holes in some of them and in the\nlow-mass systems may be undergoing very high accretion episodes that result in\nhigh $M_\\bullet\/M_{*}$ but that will be followed by quiescent periods when\ngrowth of the host drives the systems toward more typical $M_\\bullet\/M_{*}$\nvalues."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.21119",
    "c_title":[
      "Detection of the 2175{\\AA} UV Bump at z>7: Evidence for Rapid Dust\n  Evolution in a Merging Reionisation-Era Galaxy"
    ],
    "c_abstract":[
      "Dust is a fundamental component of the interstellar medium (ISM) within\ngalaxies, as dust grains are highly efficient absorbers of UV and optical\nphotons. Accurately quantifying this obscuration is crucial for interpreting\ngalaxy spectral energy distributions (SEDs). The extinction curves in the Milky\nWay (MW) and Large Magellanic Cloud (LMC) exhibit a strong feature known as the\n2175A UV bump, most often attributed to small carbonaceous dust grains. This\nfeature was recently detected in faint galaxies out to z~7 suggesting rapid\nformation channels. Here we report the detection of a strong UV bump in a\nluminous Lyman-break galaxy at z = 7.11235, GNWY-7379420231, through\nobservations taken as part of the NIRSpec Wide GTO survey. We fit a dust\nattenuation curve that is consistent with the MW extinction curve within\n1{\\sigma}, in a galaxy just ~700 Myr after the Big Bang. From the integrated\nspectrum, we infer a young mass-weighted age (t* ~ 22-59 Myr) for this galaxy,\nhowever spatially resolved SED fitting unveils the presence of an older stellar\npopulation (t* ~ 252 Myr). Furthermore, morphological analysis provides\nevidence for a potential merger. The underlying older stellar population\nsuggests the merging system could be pre-enriched, with the dust illuminated by\na merger-induced starburst. Moreover, turbulence driven by stellar feedback in\nthis bursty region may be driving PAH formation through top-down shattering.\nThe presence of a UV bump in GNWY-7379420231 solidifies growing evidence for\nthe rapid evolution of dust properties within the first billion years of cosmic\ntime."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-654",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05437",
    "b_title":[
      "Sp(2)-invariant expanders and shrinkers in Laplacian flow"
    ],
    "b_abstract":[
      "We show that the complete Sp(2)-invariant expanding solitons for Bryant's\nLaplacian flow on the anti-self-dual bundle of the 4-sphere form a 1-parameter\nfamily, and that they are all asymptotically conical (AC). We determine their\nasymptotic cones, and prove that this cone determines the complete expander (up\nto scale). Neither the unique Sp(2)-invariant torsion-free G_2-cone nor the\nasymptotic cone of the explicit AC Sp(2)-invariant shrinker from\narxiv:2112.09095 occurs as the asymptotic cone of a complete AC Sp(2)-invariant\nexpander.\n  We determine all possible end behaviours of Sp(2)-invariant solitons,\nidentifying novel forward-complete end solutions for both expanders and\nshrinkers with faster-than-Euclidean volume growth. We conjecture that there\nexists a 1-parameter family of complete SU(3)-invariant expanders on the\nanti-self-dual bundle of the complex projective plane CP^2 with such asymptotic\nbehaviour.\n  We also conjecture that, in contrast to the Sp(2)-invariant case, there exist\ncomplete SU(3)-invariant AC expanders with asymptotic cone matching that of the\nexplicit AC SU(3)-invariant shrinker from arxiv:2112.09095. The latter\nconjecture suggests that Laplacian flow may naturally implement a type of\nsurgery in which a CP^2 shrinks to a conically singular point, but after which\nthe flow can be continued smoothly, expanding a topologically different CP^2\nfrom the singularity."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.15668",
    "c_title":[
      "Axially Symmetric Helfrich Spheres"
    ],
    "c_abstract":[
      "Smooth axially symmetric Helfrich topological spheres are either round or\nelse they must satisfy a second order equation known as the reduced membrane\nequation [17]. In this paper, we show that, conversely, axially symmetric\nclosed genus zero solutions of the reduced membrane equation which, in\naddition, satisfy a rescaling condition are axially symmetric Helfrich spheres.\nWe also exploit this characterization to geometrically describe these surfaces\nand present convincing evidence that they are symmetric with respect to a\nsuitable plane orthogonal to the axis of rotation and that they belong to a\nparticular infinite discrete family of surfaces."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-655",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15084",
    "b_title":[
      "A constraint on superheavy elements of the GRB-kilonova AT 2023vfi"
    ],
    "b_abstract":[
      "The discovery of the kilonova (KN) AT 2017gfo, accompanying the gravitational\nwave event GW170817, provides crucial insight into the synthesis of heavy\nelements during binary neutron star (BNS) mergers. Following this landmark\nevent, another KN was detected in association with the second-brightest\ngamma-ray burst (GRB) observed to date, GRB 230307A, and subsequently confirmed\nby observations of the James Webb Space Telescope (JWST). In this work, we\nconduct an end-to-end simulation to analyze the temporal evolution of the KN AT\n2023vfi associated with GRB 230307A, and constrain the abundances of superheavy\nelements produced. We find that the temporal evolution of AT 2023vfi is similar\nto AT 2017gfo in the first week post-burst. Additionally, the\n\\textit{r}-process nuclide abundances of lanthanide-rich ejecta, derived from\nnumerical relativity simulations of BNS mergers, can also successfully\ninterpret the temporal evolution of the KN with the lanthanide-rich ejecta mass\nof $0.02 M_\\odot$, which is consistent with the mass range of dynamical ejecta\nfrom numerical simulations in literature. Both findings strongly suggest the\nhypothesis that GRB 230307A originated from a BNS merger, similar to AT\n2017gfo. Based on the first time observation of the KN for JWST, we are able to\nconstrain the superheavy elements of another KN following AT 2017gfo. The\npre-radioactive-decay abundances of the superheavy nuclides: $^{222}$Rn,\n$^{223}$Ra, $^{224}$Ra and $^{225}$Ac, are estimated to be at least on the\norder of $1 \\times 10^{-5}$. These abundance estimates provide valuable insight\ninto the synthesis of superheavy elements in BNS mergers, contributing to our\nunderstanding of astrophysical \\textit{r}-process nucleosynthesis."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09133",
    "c_title":[
      "The emission of interpulses by a 6.45-hour period coherent radio\n  transient"
    ],
    "c_abstract":[
      "Long-period radio transients are a novel class of astronomical objects\ncharacterised by prolonged periods ranging from 18 minutes to 54 minutes. They\nexhibit highly polarised, coherent, beamed radio emission lasting only 10--100\nseconds. The intrinsic nature of these objects is subject to speculation, with\nhighly magnetised white dwarfs and neutron stars being the prevailing\ncandidates. Here we present ASKAP J183950.5-075635.0 (hereafter, ASKAP\nJ1839-0756), boasting the longest known period of this class at 6.45 hours. It\nexhibits emission characteristics of an ordered dipolar magnetic field, with\npulsar-like bright main pulses and weaker interpulses offset by about half a\nperiod are indicative of an oblique or orthogonal rotator. This phenomenon,\nobserved for the first time in a long-period radio transient, confirms that the\nradio emission originates from both magnetic poles and that the observed period\ncorresponds to the rotation period. The spectroscopic and polarimetric\nproperties of ASKAP J1839-0756 are consistent with a neutron star origin, and\nthis object is a crucial piece of evidence in our understanding of long-period\nradio sources and their links to neutron stars."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-656",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06684",
    "b_title":[
      "On the speed of coming down from infinity for (sub)critical branching\n  processes with pairwise interactions"
    ],
    "b_abstract":[
      "In this paper, we investigate the phenomenon of coming down from infinity for\n(sub)critical cooperative branching processes with pairwise interactions (BPI\nprocesses for short) under appropriate conditions. BPI processes are\ncontinuous-time Markov chains that extend pure branching dynamics by\nincorporating additional mechanisms that allow both competition and cooperation\nevents between pairs of individuals.\n  Specifically, we focus on characterising the speed at which BPI processes\nevolve when starting from a very large initial population in the subcritical\nand critical cooperative regimes. Further, in the subcritical cooperative\nregime, we analyse their second-order fluctuations."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.06502",
    "c_title":[
      "Stationary fluctuation for the occupation time of the multi-species\n  stirring process"
    ],
    "c_abstract":[
      "In this paper, we prove a fluctuation theorem for the occupation time of the\nmulti-species stirring process on a lattice starting from a stationary\ndistribution. Our result shows that the occupation times of different species\ninteract with each other at the level of equilibrium fluctuation. The proof of\nour result utilizes the resolvent strategy introduced in \\cite{Kipnis1987}. A\ncoupling relationship between the multi-species stirring process and an\nauxiliary process and a graphical representation of the auxiliary process play\nthe key roles in the proof."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-657",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03963",
    "b_title":[
      "Global well-posedness and scattering for the massive Dirac-Klein-Gordon\n  system in two dimensions"
    ],
    "b_abstract":[
      "We prove global well-posedness and scattering for the massive\nDirac-Klein-Gordon system with small and low regularity initial data in\ndimension two. To achieve this, we impose a non-resonance condition on the\nmasses."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03886",
    "c_title":[
      "Regularity estimates to quasi-linear parabolic equations in\n  non-divergence form with non-homogeneous signature"
    ],
    "c_abstract":[
      "In this manuscript, we establish the existence and sharp geometric regularity\nestimates for bounded solutions of a class of quasilinear parabolic equations\nin non-divergence form with non-homogeneous degeneracy. The model equation in\nthis class is given by \\[ \\partial_{t} u = \\left(|\\nabla u|^{\\mathfrak{p}} +\n\\mathfrak{a}(x, t)|\\nabla u|^{\\mathfrak{q}}\\right)\\Delta_{p}^{\\mathrm{N}} u +\nf(x, t) \\quad \\text{in} \\quad Q_1 = B_1 \\times (-1, 0], \\] where $p \\in (1,\n\\infty)$, $\\mathfrak{p}, \\mathfrak{q} \\in [0, \\infty)$, and $\\mathfrak{a}, f:\nQ_1 \\to \\mathbb{R}$ are suitably defined functions. Our approach is based on\ngeometric tangential methods, incorporating a refined oscillation mechanism,\ncompactness arguments, ``alternative methods,'' and scaling techniques.\nFurthermore, we derive pointwise estimates in settings exhibiting\nsingular-degenerate or doubly singular signatures. To some extent, our\nregularity estimates refine and extend previous results from \\cite{FZ23}\nthrough distinct methodological advancements. Finally, we explore connections\nbetween our findings and fundamental nonlinear models in the theory of\nquasilinear PDEs, which may be of independent interest."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-658",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07342",
    "b_title":[
      "The regular multivariate quadratic problem"
    ],
    "b_abstract":[
      "In this work, we introduce a novel variant of the multivariate quadratic\nproblem, which is at the core of one of the most promising post-quantum\nalternatives: multivariate cryptography. In this variant, the solution of a\ngiven multivariate quadratic system must also be regular, i.e. if it is split\ninto multiple blocks of consecutive entries with the same fixed length, then\neach block has only one nonzero entry. We prove the NP-completeness of this\nvariant and show similarities and differences with other computational problems\nused in cryptography. Then we analyze its hardness by reviewing the most common\nsolvers for polynomial systems over finite fields, derive asymptotic formulas\nfor the corresponding complexities and compare the different approaches."
    ],
    "b_categories":[
      [
        "cs.SC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14264",
    "c_title":[
      "Positivity Proofs for Linear Recurrences with Several Dominant\n  Eigenvalues"
    ],
    "c_abstract":[
      "Deciding the positivity of a sequence defined by a linear recurrence and\ninitial conditions is, in general, a hard problem. When the coefficients of the\nrecurrences are constants, decidability has only been proven up to order 5. The\ndifficulty arises when the characteristic polynomial of the recurrence has\nseveral roots of maximal modulus, called dominant roots of the recurrence. We\nstudy the positivity problem for recurrences with polynomial coefficients,\nfocusing on sequences of Poincar\\'e type, which are perturbations of\nconstant-coefficient recurrences. The dominant eigenvalues of a recurrence in\nthis class are the dominant roots of the associated constant-coefficient\nrecurrence. Previously, we have proved the decidability of positivity for\nrecurrences having a unique, simple, dominant eigenvalue, under a genericity\nassumption. The associated algorithm proves positivity by constructing a\npositive cone contracted by the recurrence operator. We extend this cone-based\napproach to a larger class of recurrences, where a contracted cone may no\nlonger exist. The main idea is to construct a sequence of cones. Each cone in\nthis sequence is mapped by the recurrence operator to the next. This\nconstruction can be applied to prove positivity by induction. For recurrences\nwith several simple dominant eigenvalues, we provide a condition that ensures\nthat these successive inclusions hold. Additionally, we demonstrate the\napplicability of our method through examples, including recurrences with a\ndouble dominant eigenvalue."
    ],
    "c_categories":[
      [
        "cs.SC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-659",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11485",
    "b_title":[
      "Non-uniqueness of Regular Solutions for Incompressible Static Euler\n  Equations with Given Boundary Conditions and Turbulent Global Solutions of\n  Incompressible Navier-Stokes Equations"
    ],
    "b_abstract":[
      "The incompressible Navier-Stokes equations and static Euler equations are\nconsidered. We find that there exist infinite non-trivial regular solutions of\nincompressible static Euler equations with given boundary conditions. Moreover\nthere exist random solutions of incompressible static Euler equations. Provided\nReynolds number is large enough and time variable $t$ goes to infinity, these\nrandom solutions of static Euler equations are the path limits of corresponding\nNavier-Stokes flows. But the double limits of these Navier-Stokes flows do not\nexist. These phenomena reveal randomness and turbulence of incompressible\nfluids. Therefore these solutions are called turbulent solutions. Here some\ntyping models without Prandtl layer are given."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.13360",
    "c_title":[
      "Steady Prandtl Expansion for Subsonic Flows"
    ],
    "c_abstract":[
      "Assuming construction of Prandtl and its high order corrections for\ncompressible fluids with small Mach number, we establish nonlinear remainder\nbound and justify the validity of the Prandtl layer expansion in the inviscid\nlimit for an insulated boundary. To solve the full steady compressible\nNavier-Stokes system, which consists a div-curl reduction of \\textit{the\nmomentum equations} to an elliptic system for the stream function $\\phi $ as\nwell as an transport equation for the pressure $p$. The contruction of $\\phi$\nis based on an improved Guo-Iyer's $H^{4}$ theory for incompressible flows via\ndevelopment of a $H_{00}^{1\/2}$ technique with a type \\textit{viscous-inflow}\nBC, and the pressure $p$ is solved by imposing a key additional\n\\textit{viscous-inflow} boundary condition as \\begin{equation} \\big\\{(\\mu\n+\\lambda )u_{s}\\Delta_{\\varepsilon} p + 2(\\frac{\\mu}{\\lambda}+1)p_s\n(1-\\frac{1}{2}u_s^2)p_{x}\\big\\}\\big|_{x=0}\\backsim \\text{given.} \\end{equation}\nWe reformulate the \\textit{energy equation} in terms of the \\textit{pseudo\nentropy} $S$ (not the temperature), which exhibits a crucial uniform bound for\nthe final closure."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-660",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04099",
    "b_title":[
      "Neighbor displacement-based enhanced synthetic oversampling for\n  multiclass imbalanced data"
    ],
    "b_abstract":[
      "Imbalanced multiclass datasets pose challenges for machine learning\nalgorithms. These datasets often contain minority classes that are important\nfor accurate prediction. Existing methods still suffer from sparse data and may\nnot accurately represent the original data patterns, leading to noise and poor\nmodel performance. A hybrid method called Neighbor Displacement-based Enhanced\nSynthetic Oversampling (NDESO) is proposed in this paper. This approach uses a\ndisplacement strategy for noisy data points, computing the average distance to\ntheir neighbors and moving them closer to their centroids. Random oversampling\nis then performed to achieve dataset balance. Extensive evaluations compare 14\nalternatives on nine classifiers across synthetic and 20 real-world datasets\nwith varying imbalance ratios. The results show that our method outperforms its\ncompetitors regarding average G-mean score and achieves the lowest statistical\nmean rank. This highlights its superiority and suitability for addressing data\nimbalance in practical applications."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.19090",
    "c_title":[
      "Pivoting Factorization: A Compact Meta Low-Rank Representation of\n  Sparsity for Efficient Inference in Large Language Models"
    ],
    "c_abstract":[
      "The rapid growth of Large Language Models has driven demand for effective\nmodel compression techniques to reduce memory and computation costs. Low-rank\npruning has gained attention for its tensor coherence and GPU compatibility\nacross all densities. However, low-rank pruning has struggled to match the\nperformance of semi-structured pruning, often doubling perplexity (PPL) at\nsimilar densities. In this paper, we propose Pivoting Factorization (PIFA), a\nnovel lossless meta low-rank representation that unsupervisedly learns a\ncompact form of any low-rank representation, effectively eliminating redundant\ninformation. PIFA identifies pivot rows (linearly independent rows) and\nexpresses non-pivot rows as linear combinations, achieving an additional 24.2\\%\nmemory savings and 24.6\\% faster inference over low-rank layers at r\/d = 0.5,\nthereby significantly enhancing performance at the same density. To mitigate\nthe performance degradation caused by low-rank pruning, we introduce a novel,\nretraining-free low-rank reconstruction method that minimizes error\naccumulation (M). MPIFA, combining M and PIFA into an end-to-end framework,\nsignificantly outperforms existing low-rank pruning methods and, for the first\ntime, achieves performance comparable to semi-structured pruning, while\nsurpassing it in GPU efficiency and compatibility."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-661",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09543",
    "b_title":[
      "Multiparameter Poisson Processes and Martingales"
    ],
    "b_abstract":[
      "We introduce and study a multiparameter Poisson process (MPP). In a\nparticular case, it is observed that the MPP has a unique representation. Its\nsubordination with the multivariate subordinator and inverse subordinator are\nstudied in detail. Also, we consider a multivariate multiparameter Poisson\nprocess and establish its connection with the MPP. An integral of the MPP is\ndefined, and its asymptotic distribution is obtained. Later, we study some\nproperties of the multiparameter martingales. Moreover, the multiparameter\nmartingale characterizations for the MPP and its subordinated variants are\nderived."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02571",
    "c_title":[
      "There are no geodesic hubs in the Brownian sphere"
    ],
    "c_abstract":[
      "A point of a metric space is called a $k$-hub if it is the endpoint of\nexactly $k$ disjoint geodesics, and that the concatenation of any two of these\npaths is still a geodesic. We prove that in the Brownian sphere, there is no\n$k$-hub for $k\\geq 3$."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-662",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11923",
    "b_title":[
      "Research on Research Visibility"
    ],
    "b_abstract":[
      "This editorial explores the significance of research visibility within the\nevolving landscape of academic communication, mainly focusing on the role of\nsearch engines as online meta-markets shaping the impact of research. With the\nrapid expansion of scientific output and the increasing reliance on\nalgorithm-driven platforms such as Google and Google Scholar, the online\nvisibility of scholarly work has become an essential factor in determining its\nreach and influence. The need for more rigorous research into academic search\nengine optimization (A-SEO), a field still in its infancy despite its growing\nrelevance, is also discussed, highlighting key challenges in the field,\nincluding the lack of robust research methodologies, the skepticism within the\nacademic community regarding the commercialization of science, and the need for\nstandardization in reporting and measurement techniques. This editorial thus\ninvites a multidisciplinary dialogue on the future of research visibility, with\nsignificant implications for academic publishing, science communication,\nresearch evaluation, and the global scientific ecosystem."
    ],
    "b_categories":[
      [
        "cs.DL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19360",
    "c_title":[
      "Sustaining Knowledge Infrastructures: Asking Questions and Listening for\n  Answers"
    ],
    "c_abstract":[
      "Sustaining knowledge infrastructures (KIs) remains a persistent issue that\nrequires continued engagement from diverse stakeholders. This is due to the\ncomplexity of KIs and sustainability, as well as to new questions and values\nthat are arising in relation to KI maintenance. In this commentary, we draw on\nexisting literature and our experiences at a workshop for researchers exploring\nKI evaluation to pose five directions of thinking which are especially relevant\nfor KI project managers to consider when thinking about how to make their KIs\nstand the test of time."
    ],
    "c_categories":[
      [
        "cs.DL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-663",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07659",
    "b_title":[
      "Desarrollo de competencias STEM mediante la programaci\\'on de modelos de\n  auto-organizaci\\'on"
    ],
    "b_abstract":[
      "This article presents an educational proposal based on the computational\nimplementation of a model of interaction between particles of different types,\nas a tool for the development of STEM (Science, Technology, Engineering, and\nMathematics) skills. The mathematical formulation of the model, the equations\ngoverning particle interaction, the interaction matrix that governs collective\nbehavior, and a complete pseudocode of the simulation algorithm are detailed.\nThe article discusses how this interdisciplinary project enables students to\napply and connect knowledge from physics, mathematics, programming, and systems\nthinking, fostering skills such as computational thinking, mathematical\nmodeling, and understanding of complex systems."
    ],
    "b_categories":[
      [
        "physics.ed-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.00336",
    "c_title":[
      "Astrof\\'isica Observacional e Ensino de F\\'isica Moderna: Uma Abordagem\n  Conceitual da Espectroscopia Astron\\^omica"
    ],
    "c_abstract":[
      "Continuing professional development for teachers in the physical sciences is\ncrucial to maintaining high-quality instruction, especially when addressing\nmodern physics. Nevertheless, the teaching of these topics often relies on\ntheoretical models that may seem abstract and removed from practical\napplications. In this context, research in astrophysics provides many valuable\ninsights into the nature of light and its fundamental properties, such as\ncontinuous and discrete spectra, blackbody radiation, and atomic orbitals. This\npaper, aimed at both high school and university-level physics teachers,\nexamines the peculiarities of the emission and absorption spectra of various\ntypes of astronomical objects and demonstrates how spectroscopy is applied in\nastrophysics research. From this perspective, the study conceptually\nillustrates how astrophysicists, by measuring light spectra, determine the\ncomposition, physical properties, origin, and evolution of celestial bodies\nand, by extension, of the universe as a whole. By understanding not only the\ntheory but also the direct applications of astronomical spectroscopy, teachers\nwill be better prepared to guide their students, thereby showcasing the true\nvalue of modern physics in the real world."
    ],
    "c_categories":[
      [
        "physics.ed-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-664",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05079",
    "b_title":[
      "On a Connection Between Imitation Learning and RLHF"
    ],
    "b_abstract":[
      "This work studies the alignment of large language models with preference data\nfrom an imitation learning perspective. We establish a close theoretical\nconnection between reinforcement learning from human feedback RLHF and\nimitation learning (IL), revealing that RLHF implicitly performs imitation\nlearning on the preference data distribution. Building on this connection, we\npropose DIL, a principled framework that directly optimizes the imitation\nlearning objective. DIL provides a unified imitation learning perspective on\nalignment, encompassing existing alignment algorithms as special cases while\nnaturally introducing new variants. By bridging IL and RLHF, DIL offers new\ninsights into alignment with RLHF. Extensive experiments demonstrate that DIL\noutperforms existing methods on various challenging benchmarks."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14460",
    "c_title":[
      "MLMC: Interactive multi-label multi-classifier evaluation without\n  confusion matrices"
    ],
    "c_abstract":[
      "Machine learning-based classifiers are commonly evaluated by metrics like\naccuracy, but deeper analysis is required to understand their strengths and\nweaknesses. MLMC is a visual exploration tool that tackles the challenge of\nmulti-label classifier comparison and evaluation. It offers a scalable\nalternative to confusion matrices which are commonly used for such tasks, but\ndon't scale well with a large number of classes or labels. Additionally, MLMC\nallows users to view classifier performance from an instance perspective, a\nlabel perspective, and a classifier perspective. Our user study shows that the\ntechniques implemented by MLMC allow for a powerful multi-label classifier\nevaluation while preserving user friendliness."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-665",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12739",
    "b_title":[
      "Multiscale Stochastic Gradient Descent: Efficiently Training\n  Convolutional Neural Networks"
    ],
    "b_abstract":[
      "Stochastic Gradient Descent (SGD) is the foundation of modern deep learning\noptimization but becomes increasingly inefficient when training convolutional\nneural networks (CNNs) on high-resolution data. This paper introduces\nMultiscale Stochastic Gradient Descent (Multiscale-SGD), a novel optimization\napproach that exploits coarse-to-fine training strategies to estimate the\ngradient at a fraction of the cost, improving the computational efficiency of\nSGD type methods while preserving model accuracy. We derive theoretical\ncriteria for Multiscale-SGD to be effective, and show that while standard\nconvolutions can be used, they can be suboptimal for noisy data. This leads us\nto introduce a new class of learnable, scale-independent Mesh-Free Convolutions\n(MFCs) that ensure consistent gradient behavior across resolutions, making them\nwell-suited for multiscale training. Through extensive empirical validation, we\ndemonstrate that in practice, (i) our Multiscale-SGD approach can be used to\ntrain various architectures for a variety of tasks, and (ii) when the noise is\nnot significant, standard convolutions benefit from our multiscale training\nframework. Our results establish a new paradigm for the efficient training of\ndeep networks, enabling practical scalability in high-resolution and multiscale\nlearning tasks."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04890",
    "c_title":[
      "Exploit Gradient Skewness to Circumvent Byzantine Defenses for Federated\n  Learning"
    ],
    "c_abstract":[
      "Federated Learning (FL) is notorious for its vulnerability to Byzantine\nattacks. Most current Byzantine defenses share a common inductive bias: among\nall the gradients, the densely distributed ones are more likely to be honest.\nHowever, such a bias is a poison to Byzantine robustness due to a newly\ndiscovered phenomenon in this paper - gradient skew. We discover that a group\nof densely distributed honest gradients skew away from the optimal gradient\n(the average of honest gradients) due to heterogeneous data. This gradient skew\nphenomenon allows Byzantine gradients to hide within the densely distributed\nskewed gradients. As a result, Byzantine defenses are confused into believing\nthat Byzantine gradients are honest. Motivated by this observation, we propose\na novel skew-aware attack called STRIKE: first, we search for the skewed\ngradients; then, we construct Byzantine gradients within the skewed gradients.\nExperiments on three benchmark datasets validate the effectiveness of our\nattack"
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-666",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18165",
    "b_title":[
      "SU(6) model revisited"
    ],
    "b_abstract":[
      "We discuss the vacuum structure of the SU(6) model, a chiral gauge theory,\nfrom the perspective of anomaly matching. To this end, we first identify all\npossible 't Hooft anomalies in the UV theory using the Stora-Zumino procedure.\nSubsequently, we construct an effective theory by applying the idea of the\nWess-Zumino-Witten action to derive the topological terms that encode the 't\nHooft anomalies. As a result, we demonstrate that a low-energy effective theory\nreproducing one of the anomalies, namely the mixed anomaly, is described by a\nZ3-valued scalar field. On the other hand, the effective theory that accounts\nfor the discrete chiral self-anomaly is significantly more intricate, and\nelucidating its structure remains an ongoing challenge."
    ],
    "b_categories":[
      [
        "hep-lat"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.06721",
    "c_title":[
      "High-Performance Simulations of Higher Representations of Wilson\n  Fermions"
    ],
    "c_abstract":[
      "We present HiRep v2, an open-source software suite for high-performance\nlattice field theory simulations with dynamical Wilson fermions in higher\nrepresentations of $SU(N_g)$ gauge groups. This new version fully supports GPU\nacceleration, optimizing both gauge configuration generation and measurements\nfor NVIDIA and AMD GPUs. HiRep v2 integrates improved gauge and fermionic\nlattice actions, advanced inverters, and Monte Carlo algorithms, including\n(R)HMC with Hasenbusch acceleration. It exhibits excellent scalability across\nmultiple GPUs and nodes with minimal efficiency loss, making it a robust tool\nfor large-scale simulations in physics beyond the Standard Model."
    ],
    "c_categories":[
      [
        "hep-lat"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-667",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03472",
    "b_title":[
      "Powering LLM Regulation through Data: Bridging the Gap from Compute\n  Thresholds to Customer Experiences"
    ],
    "b_abstract":[
      "The rapid advancement of Large Language Models (LLMs) has created a critical\ngap in consumer protection due to the lack of standardized certification\nprocesses for LLM-powered Artificial Intelligence (AI) systems. This paper\nargues that current regulatory approaches, which focus on compute-level\nthresholds and generalized model evaluations, are insufficient to ensure the\nsafety and effectiveness of specific LLM-based user experiences. We propose a\nshift towards a certification process centered on actual user-facing\nexperiences and the curation of high-quality datasets for evaluation. This\napproach offers several benefits: it drives consumer confidence in AI system\nperformance, enables businesses to demonstrate the credibility of their\nproducts, and allows regulators to focus on direct consumer protection. The\npaper outlines a potential certification workflow, emphasizing the importance\nof domain-specific datasets and expert evaluation. By repositioning data as the\nstrategic center of regulatory efforts, this framework aims to address the\nchallenges posed by the probabilistic nature of AI systems and the rapid pace\nof technological advancement. This shift in regulatory focus has the potential\nto foster innovation while ensuring responsible AI development, ultimately\nbenefiting consumers, businesses, and government entities alike."
    ],
    "b_categories":[
      [
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15491",
    "c_title":[
      "A Critical Field Guide for Working with Machine Learning Datasets"
    ],
    "c_abstract":[
      "Machine learning datasets are powerful but unwieldy. Despite the fact that\nlarge datasets commonly contain problematic material--whether from a technical,\nlegal, or ethical perspective--datasets are valuable resources when handled\ncarefully and critically. A Critical Field Guide for Working with Machine\nLearning Datasets suggests practical guidance for conscientious dataset\nstewardship. It offers questions, suggestions, strategies, and resources for\nworking with existing machine learning datasets at every phase of their\nlifecycle. It combines critical AI theories and applied data science concepts,\nexplained in accessible language. Equipped with this understanding, students,\njournalists, artists, researchers, and developers can be more capable of\navoiding the problems unique to datasets. They can also construct more\nreliable, robust solutions, or even explore new ways of thinking with machine\nlearning datasets that are more critical and conscientious."
    ],
    "c_categories":[
      [
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-668",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14673",
    "b_title":[
      "Unfolding the Six-Dimensional Tensor Multiplet"
    ],
    "b_abstract":[
      "We derive a manifestly superconformally covariant unfolded formulation of the\nfree (2,0) tensor multiplet. The unfolded system consists of an abelian\ntwo-form and an infinite-dimensional, chiral Weyl zero-form realized using\nsuperoscillators. The construction of the cocycle gluing these forms on a\ngeneral superconformal background goes one step beyond previous results in\nsuper-Poincar\\'e backgrounds."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.13910",
    "c_title":[
      "Localization and wall-crossing of giant graviton expansions in AdS$_5$"
    ],
    "c_abstract":[
      "The $\\frac12$-BPS indices of $\\mathcal{N}=4$ Super Yang-Mills theory with\nunitary, orthogonal, and symplectic groups all admit $q$-expansions suggesting\nan interpretation in terms of D-branes in the dual bulk AdS$_5$ string\ntheories. We present a derivation of these expansions in the corresponding bulk\nduals by quantizing the moduli space of $\\frac12$-BPS giant gravitons using\nsupersymmetric localization, extending and clarifying our study in\narxiv:2312.14921. We perform a detailed analysis of the one-loop fluctuations\naround the maximal giants (the fixed points), and show how the Hamiltonian\nanalysis is recovered from the functional integral for the equivariant index.\nWe show that the analytic continuation for these giant graviton expansions\nobserved in the literature maps precisely to a wall-crossing phenomenon for the\nindex. In the case of orthogonal and symplectic gauge groups, the\n$\\mathbb{Z}_2$ quotient in the bulk leads to a corresponding projection in the\n$q$-expansion. Additional terms in the expansion related to the Pfaffian\noperator arise from topologically stable branes in the bulk dual on AdS$_5\n\\times \\mathbb{RP}^5$."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-669",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13743",
    "b_title":[
      "MonoCT: Overcoming Monocular 3D Detection Domain Shift with Consistent\n  Teacher Models"
    ],
    "b_abstract":[
      "We tackle the problem of monocular 3D object detection across different\nsensors, environments, and camera setups. In this paper, we introduce a novel\nunsupervised domain adaptation approach, MonoCT, that generates highly accurate\npseudo labels for self-supervision. Inspired by our observation that accurate\ndepth estimation is critical to mitigating domain shifts, MonoCT introduces a\nnovel Generalized Depth Enhancement (GDE) module with an ensemble concept to\nimprove depth estimation accuracy. Moreover, we introduce a novel Pseudo Label\nScoring (PLS) module by exploring inner-model consistency measurement and a\nDiversity Maximization (DM) strategy to further generate high-quality pseudo\nlabels for self-training. Extensive experiments on six benchmarks show that\nMonoCT outperforms existing SOTA domain adaptation methods by large margins\n(~21% minimum for AP Mod.) and generalizes well to car, traffic camera and\ndrone views."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05757",
    "c_title":[
      "Locality-aware Gaussian Compression for Fast and High-quality Rendering"
    ],
    "c_abstract":[
      "We present LocoGS, a locality-aware 3D Gaussian Splatting (3DGS) framework\nthat exploits the spatial coherence of 3D Gaussians for compact modeling of\nvolumetric scenes. To this end, we first analyze the local coherence of 3D\nGaussian attributes, and propose a novel locality-aware 3D Gaussian\nrepresentation that effectively encodes locally-coherent Gaussian attributes\nusing a neural field representation with a minimal storage requirement. On top\nof the novel representation, LocoGS is carefully designed with additional\ncomponents such as dense initialization, an adaptive spherical harmonics\nbandwidth scheme and different encoding schemes for different Gaussian\nattributes to maximize compression performance. Experimental results\ndemonstrate that our approach outperforms the rendering quality of existing\ncompact Gaussian representations for representative real-world 3D datasets\nwhile achieving from 54.6$\\times$ to 96.6$\\times$ compressed storage size and\nfrom 2.1$\\times$ to 2.4$\\times$ rendering speed than 3DGS. Even our approach\nalso demonstrates an averaged 2.4$\\times$ higher rendering speed than the\nstate-of-the-art compression method with comparable compression performance."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-670",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01759",
    "b_title":[
      "Spinning generalizations of Majumdar-Papapetrou multi-black hole\n  spacetimes: light rings, lensing and shadows"
    ],
    "b_abstract":[
      "A generalization of the Majumdar-Papapetrou multi-black hole spacetime was\nrecently constructed by Teo and Wan [1], describing charged and spinning\n(extremal) balanced black holes in asymptotically flat spacetime. We explore\nthe dynamics of null geodesics on this geometry, focusing on the two-center\nsolution. Using the topological charge formalism, we show that various light\nring arrangements arise from different choices of individual angular momenta:\nlight rings with opposite topological charges can merge and annihilate each\nother, resulting in configurations with a total of 4, 6, or 8 light rings.\nUsing backward ray-tracing, we obtained the shadow and lensing of these\nspacetimes. The former, in particular, closely resembles those for the\ndouble-Kerr metric."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.10066",
    "c_title":[
      "Probing quantum criticality near the BTZ black hole horizon: Insights\n  from coupled fermion-antifermion pairs"
    ],
    "c_abstract":[
      "In this study, we analytically examine the behavior of a fermion-antifermion\npair near the horizon of a static BTZ black hole using a fully covariant\ntwo-body Dirac equation with a position-dependent mass. This formulation leads\nto a set of four first-order equations that can be reduced to a second-order\nwave equation, enabling the analysis of gravitational effects on quantum\ninteractions. Two mass modifications are considered: (i) \\(m \\rightarrow m -\na\/r\\), representing an attractive Coulomb interaction, and (ii) \\(m \\rightarrow\nm - a\/r + b r\\), corresponding to a Cornell potential. For case (i), an exact\nanalytical solution is obtained, while for case (ii), conditionally exact\nsolutions involving biconfluent Heun functions are derived. For the lowest mode\n(\\(n=0\\)), the results indicate that real oscillations without energy loss\noccur when \\(a > 0.25\\) in scenario (i) and \\(a > 0.75\\) in scenario (ii),\nsuggesting stable oscillatory behavior. When \\(a < 0.25\\) in scenario (i) or\n\\(a < 0.75\\) in scenario (ii), the state exhibits decay, indicating instability\nbelow these critical thresholds. At \\(a = 0.25\\) (scenario (i)) and \\(a =\n0.75\\) (scenario (ii)), the system reaches a state where its evolution ceases\nover time. These findings provide insights into the stability conditions of\nfermion-antifermion pairs near the black hole horizon and may have relevance\nfor determining critical coupling strengths in systems such as holographic\nsuperconductors. Furthermore, this work adopts an effective semi-classical\nquantum gravity approach, offering a practical framework for incorporating\ngravitational effects."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-671",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15232",
    "b_title":[
      "Gate tunable Dirac mass and Berry phase in Trilayer graphene"
    ],
    "b_abstract":[
      "In-situ control over band mass inversion is crucial for developing materials\nwith topologically protected edge modes. In this Letter, we report the direct\nobservation of displacement field $D$ control of band mass and Berry phase in\nBernal stacked trilayer graphene (TLG) in the region where trigonal warping\ndistorts the quadratic band into off-center Dirac points, referred to as `Dirac\nGullies.' Using Shubnikov-de-Haas (SdH) oscillations, we map the Fermi surface\ncontours of the Dirac gullies and the $D$-dependent band structure. With\nincreasing $D$-field, the Berry phase undergoes multiple transitions from\n$\\Phi_B=2\\pi$ $\\rightarrow$ $\\pi$ $\\rightarrow$ $2\\pi$ as $D$ is varied.\nConcurrently, measurement of the effective mass reveals a series of transitions\nbetween massless and massive bands, signaling the closure and reopening\n(accompanied by a possible band inversion) of the band gap at a critical value\nof $D$. Interestingly, the expected Dirac-like behavior of the Dirac gullies\n($\\Phi_B=\\pi$) persists only over a narrow range of $D$. Our study directly\nconfirms recent predictions of $ D$-field-induced band inversion in the\nlow-energy regions of TLG. It is a significant step towards achieving control\nover pure valley transport in multilayer graphene."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.11300",
    "c_title":[
      "Overdamped van der Waals Josephson junctions by area engineering"
    ],
    "c_abstract":[
      "Van der Waals (vW) Josephson junctions (JJs) realized by stacking materials\nsuch as few-layered NbSe2, offers a new landscape to realize superconducting\nquantum devices with superior properties owing to its crystalline nature and\ndefect-free junctions. For quantum technology, overdamped JJs are highly\nsought-after, whose realization demands precise control of junction capacitance\nby engineering the junction area using microfabrication techniques. NbSe2 is\nhighly reactive and susceptible to damage during microfabrication processes. In\nthis manuscript, we demonstrate both underdamped and overdamped NbSe2-NbSe2 JJs\nby controlling the junction area. We devise a minimally invasive\nmicrofabrication procedure, post-junction formation, to precisely control the\njunction area. The McCumber parameter characterizing the damping is extracted\nfrom the electrical transport measurements down to 130 mK. The results show\nthat our sample fabrication recipe has preserved the material qualities and\npaved the way for the realization of scalable JJ devices on NbSe2 and similar\nsystems."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-672",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19314",
    "b_title":[
      "An Efficient Approach for Machine Translation on Low-resource Languages:\n  A Case Study in Vietnamese-Chinese"
    ],
    "b_abstract":[
      "Despite the rise of recent neural networks in machine translation, those\nnetworks do not work well if the training data is insufficient. In this paper,\nwe proposed an approach for machine translation in low-resource languages such\nas Vietnamese-Chinese. Our proposed method leveraged the power of the\nmultilingual pre-trained language model (mBART) and both Vietnamese and Chinese\nmonolingual corpus. Firstly, we built an early bird machine translation model\nusing the bilingual training dataset. Secondly, we used TF-IDF technique to\nselect sentences from the monolingual corpus which are the most related to\ndomains of the parallel dataset. Finally, the first model was used to\nsynthesize the augmented training data from the selected monolingual corpus for\nthe translation model. Our proposed scheme showed that it outperformed 8%\ncompared to the transformer model. The augmented dataset also pushed the model\nperformance."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04306",
    "c_title":[
      "ScoreFlow: Mastering LLM Agent Workflows via Score-based Preference\n  Optimization"
    ],
    "c_abstract":[
      "Recent research has leveraged large language model multi-agent systems for\ncomplex problem-solving while trying to reduce the manual effort required to\nbuild them, driving the development of automated agent workflow optimization\nmethods. However, existing methods remain inflexible due to representational\nlimitations, a lack of adaptability, and poor scalability when relying on\ndiscrete optimization techniques. We address these challenges with ScoreFlow, a\nsimple yet high-performance framework that leverages efficient gradient-based\noptimization in a continuous space. ScoreFlow incorporates Score-DPO, a novel\nvariant of the direct preference optimization method that accounts for\nquantitative feedback. Across six benchmarks spanning question answering,\ncoding, and mathematical reasoning, ScoreFlow achieves an 8.2% improvement over\nexisting baselines. Moreover, it empowers smaller models to outperform larger\nones with lower inference costs. Project:\nhttps:\/\/github.com\/Gen-Verse\/ScoreFlow"
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-673",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11187",
    "b_title":[
      "FastVID: Dynamic Density Pruning for Fast Video Large Language Models"
    ],
    "b_abstract":[
      "Video Large Language Models have shown impressive capabilities in video\ncomprehension, yet their practical deployment is hindered by substantial\ninference costs caused by redundant video tokens. Existing pruning techniques\nfail to fully exploit the spatiotemporal redundancy inherent in video data. To\nbridge this gap, we perform a systematic analysis of video redundancy from two\nperspectives: temporal context and visual context. Leveraging this insight, we\npropose Dynamic Density Pruning for Fast Video LLMs termed FastVID.\nSpecifically, FastVID dynamically partitions videos into temporally ordered\nsegments to preserve temporal structure and applies a density-based token\npruning strategy to maintain essential visual information. Our method\nsignificantly reduces computational overhead while maintaining temporal and\nvisual integrity. Extensive evaluations show that FastVID achieves\nstate-of-the-art performance across various short- and long-video benchmarks on\nleading Video LLMs, including LLaVA-OneVision and LLaVA-Video. Notably, FastVID\neffectively prunes 90% of video tokens while retaining 98.0% of\nLLaVA-OneVision's original performance. The code is available at\nhttps:\/\/github.com\/LunarShen\/FastVID."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.12723",
    "c_title":[
      "myEye2Wheeler: A Two-Wheeler Indian Driver Real-World Eye-Tracking\n  Dataset"
    ],
    "c_abstract":[
      "This paper presents the myEye2Wheeler dataset, a unique resource of\nreal-world gaze behaviour of two-wheeler drivers navigating complex Indian\ntraffic. Most datasets are from four-wheeler drivers on well-planned roads and\nhomogeneous traffic. Our dataset offers a critical lens into the unique visual\nattention patterns and insights into the decision-making of Indian two-wheeler\ndrivers. The analysis demonstrates that existing saliency models, like\nTASED-Net, perform less effectively on the myEye-2Wheeler dataset compared to\nwhen applied on the European 4-wheeler eye tracking datasets (DR(Eye)VE),\nhighlighting the need for models specifically tailored to the traffic\nconditions. By introducing the dataset, we not only fill a significant gap in\ntwo-wheeler driver behaviour research in India but also emphasise the critical\nneed for developing context-specific saliency models. The larger aim is to\nimprove road safety for two-wheeler users and lane-planning to support a\ncost-effective mode of transport."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-674",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09509",
    "b_title":[
      "EQ-VAE: Equivariance Regularized Latent Space for Improved Generative\n  Image Modeling"
    ],
    "b_abstract":[
      "Latent generative models have emerged as a leading approach for high-quality\nimage synthesis. These models rely on an autoencoder to compress images into a\nlatent space, followed by a generative model to learn the latent distribution.\nWe identify that existing autoencoders lack equivariance to semantic-preserving\ntransformations like scaling and rotation, resulting in complex latent spaces\nthat hinder generative performance. To address this, we propose EQ-VAE, a\nsimple regularization approach that enforces equivariance in the latent space,\nreducing its complexity without degrading reconstruction quality. By finetuning\npre-trained autoencoders with EQ-VAE, we enhance the performance of several\nstate-of-the-art generative models, including DiT, SiT, REPA and MaskGIT,\nachieving a 7 speedup on DiT-XL\/2 with only five epochs of SD-VAE fine-tuning.\nEQ-VAE is compatible with both continuous and discrete autoencoders, thus\noffering a versatile enhancement for a wide range of latent generative models.\nProject page and code: https:\/\/eq-vae.github.io\/."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.11213",
    "c_title":[
      "Risk Analysis of Flowlines in the Oil and Gas Sector: A GIS and Machine\n  Learning Approach"
    ],
    "c_abstract":[
      "This paper presents a risk analysis of flowlines in the oil and gas sector\nusing Geographic Information Systems (GIS) and machine learning (ML).\nFlowlines, vital conduits transporting oil, gas, and water from wellheads to\nsurface facilities, often face under-assessment compared to transmission\npipelines. This study addresses this gap using advanced tools to predict and\nmitigate failures, improving environmental safety and reducing human exposure.\nExtensive datasets from the Colorado Energy and Carbon Management Commission\n(ECMC) were processed through spatial matching, feature engineering, and\ngeometric extraction to build robust predictive models. Various ML algorithms,\nincluding logistic regression, support vector machines, gradient boosting\ndecision trees, and K-Means clustering, were used to assess and classify risks,\nwith ensemble classifiers showing superior accuracy, especially when paired\nwith Principal Component Analysis (PCA) for dimensionality reduction. Finally,\na thorough data analysis highlighted spatial and operational factors\ninfluencing risks, identifying high-risk zones for focused monitoring. Overall,\nthe study demonstrates the transformative potential of integrating GIS and ML\nin flowline risk management, proposing a data-driven approach that emphasizes\nthe need for accurate data and refined models to improve safety in petroleum\nextraction."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-675",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04998",
    "b_title":[
      "On Sequential Fault-Intolerant Process Planning"
    ],
    "b_abstract":[
      "We propose and study a planning problem we call Sequential Fault-Intolerant\nProcess Planning (SFIPP). SFIPP captures a reward structure common in many\nsequential multi-stage decision problems where the planning is deemed\nsuccessful only if all stages succeed. Such reward structures are different\nfrom classic additive reward structures and arise in important applications\nsuch as drug\/material discovery, security, and quality-critical product design.\nWe design provably tight online algorithms for settings in which we need to\npick between different actions with unknown success chances at each stage. We\ndo so both for the foundational case in which the behavior of actions is\ndeterministic, and the case of probabilistic action outcomes, where we\neffectively balance exploration for learning and exploitation for planning\nthrough the usage of multi-armed bandit algorithms. In our empirical\nevaluations, we demonstrate that the specialized algorithms we develop, which\nleverage additional information about the structure of the SFIPP instance,\noutperform our more general algorithm."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15580",
    "c_title":[
      "How Well Can AI Build SD Models?"
    ],
    "c_abstract":[
      "Introduction: As system dynamics (SD) embraces automation, AI offers\nefficiency but risks bias from missing data and flawed models. Models that omit\nmultiple perspectives and data threaten model quality, whether created by\nhumans or with the assistance of AI. To reduce uncertainty about how well AI\ncan build SD models, we introduce two metrics for evaluation of AI-generated\ncausal maps: technical correctness (causal translation) and adherence to\ninstructions (conformance).\n  Approach: We developed an open source project called sd-ai to provide a basis\nfor collaboration in the SD community, aiming to fully harness the potential of\nAI based tools like ChatGPT for dynamic modeling. Additionally, we created an\nevaluation theory along with a comprehensive suite of tests designed to\nevaluate any such tools developed within the sd-ai ecosystem.\n  Results: We tested 11 different LLMs on their ability to do causal\ntranslation as well as conform to user instruction. gpt-4.5-preview was the top\nperformer, scoring 92.9% overall, excelling in both tasks. o1 scored 100% in\ncausal translation. gpt-4o identified all causal links but struggled with\npositive polarity in decreasing terms. While gpt-4.5-preview and o1 are most\naccurate, gpt-4o is the cheapest.\n  Discussion: Causal translation and conformance tests applied to the sd-ai\nengine reveal significant variations across lLLMs, underscoring the need for\ncontinued evaluation to ensure responsible development of AI tools for dynamic\nmodeling. To address this, an open collaboration among tool developers,\nmodelers, and stakeholders is launched to standardize measures for evaluating\nthe capacity of AI tools to improve the modeling process."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-676",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06389",
    "b_title":[
      "Heterogeneous network estimation for single-cell transcriptomic data via\n  a joint regularized deep neural network"
    ],
    "b_abstract":[
      "Network estimation has been a critical component of single-cell\ntranscriptomic data analysis, which can provide crucial insights into the\ncomplex interplay among genes, facilitating uncovering the biological basis of\nhuman life at single-cell resolution. Despite notable achievements, existing\nmethodologies often falter in their practicality, primarily due to their narrow\nfocus on simplistic linear relationships and inadequate handling of cellular\nheterogeneity. To bridge these gaps, we propose a joint regularized deep neural\nnetwork method incorporating a Mahalanobis distance-based K-means clustering\n(JRDNN-KM) to estimate multiple networks for various cell subgroups\nsimultaneously, accounting for both unknown cellular heterogeneity and\nzero-inflation and, more importantly, complex nonlinear relationships among\ngenes. We innovatively introduce a selection layer for network construction and\ndevelop homogeneous and heterogeneous hidden layers to accommodate commonality\nand specificity across multiple networks. Through simulations and applications\nto real single-cell transcriptomic data for multiple tissues and species, we\nshow that JRDNN-KM constructs networks with more accuracy and biological\ninterpretability and, meanwhile, identifies more accurate cell subgroups\ncompared to the state-of-the-art methods in the literature. Building on the\nnetwork construction, we further find hub genes with important biological\nimplications and modules with statistical enrichment of biological processes."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.13777",
    "c_title":[
      "Topic Modeling for Free-Response Text Data from a Complex Survey"
    ],
    "c_abstract":[
      "Topic Modeling is a popular statistical tool commonly used on textual data to\nidentify the hidden thematic structure in a document collection based on the\ndistribution of words. Additionally, it can be used to cluster the documents,\nwith clusters representing distinct topics. The Mixture of Unigrams (MoU) is a\nstandard topic model for clustering document-term data and can be particularly\nuseful for analyzing open-ended survey responses to extract meaningful\ninformation from the underlying topics. However, with complex survey designs,\nwhere data is often collected on individual (document) characteristics, it is\nessential to account for the sample design in order to avoid biased estimates.\nTo address this issue, we propose the MoU model under informative sampling\nusing a pseudolikelihood to account for the sample design in the model by\nincorporating survey weights. We evaluate the effectiveness of this approach\nthrough a simulation study and illustrate its application using two datasets\nfrom the American National Election Studies (ANES). We compare our\npseudolikelihood-based MoU model to the traditional MoU and assess its\neffectiveness in extracting meaningful topics from survey data. Additionally,\nwe introduce a hierarchical Mixture of Unigrams (hMoU) accounting for\ninformative sampling where topic proportions are defined as functions of\ndocument-level fixed and random effects. We demonstrate the effectiveness of\nthe proposed model through an application to ANES data comparing topic\nproportions across respondent-level factors such as gender, race, age group,\nand state."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-677",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11653",
    "b_title":[
      "Training Channel Selection for Learning-based 1-bit Precoding in Massive\n  MU-MIMO"
    ],
    "b_abstract":[
      "Learning-based algorithms have gained great popularity in communications\nsince they often outperform even carefully engineered solutions by learning\nfrom training samples. In this paper, we show that the selection of appropriate\ntraining examples can be important for the performance of such learning-based\nalgorithms. In particular, we consider non-linear 1-bit precoding for massive\nmulti-user MIMO systems using the C2PO algorithm. While previous works have\nalready shown the advantages of learning critical coefficients of this\nalgorithm, we demonstrate that straightforward selection of training samples\nthat follow the channel model distribution does not necessarily lead to the\nbest result. Instead, we provide a strategy to generate training data based on\nthe specific properties of the algorithm, which significantly improves its\nerror floor performance."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.11876",
    "c_title":[
      "Channel and Spectrum Consumption Models for Urban Outdoor-to-Outdoor 28\n  GHz Wireless"
    ],
    "c_abstract":[
      "Next generation wireless and mobile networks will utilize millimeter-wave\n(mmWave) communication to achieve significantly increased data rates. However,\nsince mmWave radio signals experience high path loss, the operation of mmWave\nnetworks will require accurate channel models designed for specific deployment\nsites. In this paper, we focus on the deployment area of the PAWR COSMOS\ntestbed in New York City and report extensive 28 GHz channel measurements.\nThese include over 46 million power measurements collected from over 3,000\nlinks on 24 sidewalks at 4 different sites and in different settings. Using\nthese measurements, we study the effects of the setup and environments (e.g.,\ntransmitter height and seasonal effects). We then discuss the obtained path\ngain values and their fitted lines, and the resulting effective azimuth\nbeamforming gain. Based on these results, we also study the link SNR values\nthat can be supported on individual sidewalks and the corresponding\ntheoretically achievable data rates. Finally, we develop a process to transform\nthe measurements and generate Spectrum Consumption Models (SCMs) based on the\nIEEE 1900.5.2 standard. The generated SCMs facilitate the evaluation of\nspectrum sharing and interference management scenarios since they capture all\nthe directional propagation effects reflected in the measurements and provide a\nway to easily share the main propagation characterization results derived from\nthe measurements. We believe that the results can inform the COSMOS testbed\ndeployment process and provide a benchmark for other deployment efforts in\ndense urban areas."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-678",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14722",
    "b_title":[
      "Model-based time super-sampling of turbulent flow field sequences"
    ],
    "b_abstract":[
      "We propose a novel method for model-based time super-sampling of turbulent\nflow fields. The key enabler is the identification of an empirical Galerkin\nmodel from the projection of the Navier-Stokes equations on a data-tailored\nbasis. The basis is obtained from a Proper Orthogonal Decomposition (POD) of\nthe measured fields. Time super-sampling is thus achieved by a time-marching\nintegration of the identified dynamical system, taking the original snapshots\nas initial conditions. Temporal continuity of the reconstructed velocity fields\nis achieved through a forward-backwards integration between consecutive\nmeasured Particle Image Velocimetry measurements of a turbulent jet flow. The\nresults are compared with the interpolation of the POD temporal coefficients\nand the low-order reconstruction of data measured at a higher sampling rate. In\nboth cases, the results obtained show the ability of the method to reconstruct\nthe dynamics of the flow with small errors during several flow characteristic\ntimes."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.05577",
    "c_title":[
      "Model Predictive and Reinforcement Learning Methods for Active Flow\n  Control of an Airfoil with Dual-point Excitation of Plasma Actuators"
    ],
    "c_abstract":[
      "This paper presents an analysis of Model Predictive Control (MPC) and\nReinforcement Learning (RL) approaches for active flow control over a NACA\n(National Advisory Committee for Aeronautics) 4412 airfoil around the static\nstall condition at a Reynolds number of 4*10^5. The Reynolds Averaged\nNavier-Stokes (RANS) equations with the Scale-Adaptive Simulation (SAS)\nturbulence model are utilized for the numerical simulations. The dielectric\nbarrier discharge (DBD) plasma actuators were employed in dual excitation mode\nfor flow separation control. The study systematically evaluates adaptive MPC,\ntemporal difference reinforcement learning (TDRL), and deep Q-learning (DQL)\nbased on optimizing the excitation frequency and expediting the time to\nidentify stable conditions. Moreover, an integrated approach that combines\nsignal processing with DQL is examined. The results demonstrate that while MPC\nand RL significantly improve flow control, RL approaches offer superior\nadaptability and performance. In optimal conditions, a lift coefficient of\naround 1.619 was achieved within less than 2.5 seconds with an excitation\nfrequency of 100 or 200 Hz. This research highlights that RL-based approaches\ncould perform better in flow control applications than MPC."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-679",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00716",
    "b_title":[
      "UPL: Uncertainty-aware Pseudo-labeling for Imbalance Transductive Node\n  Classification"
    ],
    "b_abstract":[
      "Graph-structured datasets often suffer from class imbalance, which\ncomplicates node classification tasks. In this work, we address this issue by\nfirst providing an upper bound on population risk for imbalanced transductive\nnode classification. We then propose a simple and novel algorithm,\nUncertainty-aware Pseudo-labeling (UPL). Our approach leverages pseudo-labels\nassigned to unlabeled nodes to mitigate the adverse effects of imbalance on\nclassification accuracy. Furthermore, the UPL algorithm enhances the accuracy\nof pseudo-labeling by reducing training noise of pseudo-labels through a novel\nuncertainty-aware approach. We comprehensively evaluate the UPL algorithm\nacross various benchmark datasets, demonstrating its superior performance\ncompared to existing state-of-the-art methods."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17009",
    "c_title":[
      "Unbiased and Sign Compression in Distributed Learning: Comparing Noise\n  Resilience via SDEs"
    ],
    "c_abstract":[
      "Distributed methods are essential for handling machine learning pipelines\ncomprising large-scale models and datasets. However, their benefits often come\nat the cost of increased communication overhead between the central server and\nagents, which can become the main bottleneck, making training costly or even\nunfeasible in such systems. Compression methods such as quantization and\nsparsification can alleviate this issue. Still, their robustness to large and\nheavy-tailed gradient noise, a phenomenon sometimes observed in language\nmodeling, remains poorly understood. This work addresses this gap by analyzing\nDistributed Compressed SGD (DCSGD) and Distributed SignSGD (DSignSGD) using\nstochastic differential equations (SDEs). Our results show that DCSGD with\nunbiased compression is more vulnerable to noise in stochastic gradients, while\nDSignSGD remains robust, even under large and heavy-tailed noise. Additionally,\nwe propose new scaling rules for hyperparameter tuning to mitigate performance\ndegradation due to compression. These findings are empirically validated across\nmultiple deep learning architectures and datasets, providing practical\nrecommendations for distributed optimization."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-680",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08792",
    "b_title":[
      "Compression failure of porous ceramics: A computational study about the\n  effect of volume fraction on damage evolution and failure"
    ],
    "b_abstract":[
      "The work describes a numerical method to study the nature of compressive\nfailure of porous ceramics in relation to its volume fraction. The\nmicrostructure of an alumina-based foam material manufactured by mechanical\nstirring of a slurry is studied here. A finite element-based compressive\nfailure simulation of a real microstructure obtained from microtomography\n(micro-CT) scans is conducted. A recently developed microstructure\nreconstruction algorithm is utilized to generate artificial microstructures\nstatistically equivalent to the real one obtained from micro-CT. The accuracy\nof the reconstruction procedure is established by comparing the simulated\ncompression behavior of the reconstructed microstructure with that of the real\none along with the experimentally measured results. The effect of sample size\non the simulated compression behavior is studied by computing compression\nstress-strain behavior for varying sizes of the reconstructed microstructures.\nFurther, artificial microstructures of the porous ceramic with different volume\nfractions are reconstructed along with computing compression stress-strain\nbehavior to establish relationship between ceramic content (volume fraction)\nand compressive strength of this material. The nature of the compressive\nfailure for microstructures with different volume fractions is studied and the\nresults are compared with the analytical models and the experimental\nobservations available in the literature."
    ],
    "b_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.06297",
    "c_title":[
      "Ultra-flexible silicon foils with seamless detachability: the effect of\n  porous multilayered structures prepared through modulated electrolyte\n  composition"
    ],
    "c_abstract":[
      "A comprehensive evaluation of the effect and limitations of variable current\ndensity and electrolyte composition on layer porosity and microstructure\nchanges of porous silicon (pSi) multilayer stacks is reported. Following these\nresults, the development and optimization of a four-layer stack architecture is\nreported through addition of super-low porosity layers (SLPL) on a low\/high\nporosity layer (LPL\/HLP) stack. Thermal treatment of these structures achieved\nexcellent top and bottom surface reconstruction to form sintered porous silicon\n(SPS) detachable foils, enabling direct foil separation using cello tape from a\nsmooth and specular parent substrate without the need to cut or damage it"
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-681",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05524",
    "b_title":[
      "A Starter Kit for Diversity-Oriented Communities for Undergraduates:\n  Near-Peer Mentorship Programs"
    ],
    "b_abstract":[
      "This mentoring resource is a guide to establishing and running near-peer\nmentorship programs. It is based on the working knowledge and best practices\ndeveloped by the Access Network, a collection of nine student-led communities\nat universities across the country working towards a vision of a more diverse,\nequitable, inclusive, and accessible STEM environment. Many of these\ncommunities, also referred to as sites, include a near-peer mentoring program\nthat is developed to best support their local context. The format of these\nprograms vary, ranging from structured classes with peer mentoring groups to\nstudent clubs supporting 1-on-1 relationships. To further support program\nparticipants as both students and as whole people, sites often run additional\nevents such as lecture series, workshops, and social activities guided tailored\nto each student community's needs. Through this process, student leaders have\ngenerated and honed best practices for all aspects of running their sites. This\nguide is an attempt to synthesize those efforts, offering practical advice for\nstudent leaders setting up near-peer mentorship programs in their own\ndepartments. It has been written through the lens of undergraduate near-peer\nmentorship programs, although our framework could easily be extended to other\ndemographics (e.g. high schoolers, graduate students, etc.). Our experience is\nwith STEM mentorship specifically, though these practices can extend to any\ndiscipline. In this document, we outline best practices for designing, running,\nand sustaining near-peer mentorship programs. We provide template resources to\nassist with this work, and lesson plans to run mentor and mentee training\nsessions. We hope you find this guide useful in designing, implementing, and\nre-evaluating community oriented near-peer mentoring programs."
    ],
    "b_categories":[
      [
        "physics.ed-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.02251",
    "c_title":[
      "Visualizing beat phenomenon between two amplitude-modulated (AM) light\n  beams on a solar cell using smartphones"
    ],
    "c_abstract":[
      "We present a new simple experimental setup for demonstrating beat phenomenon.\nWe have combined two amplitude-modulated light beams on a solar cell using two\nsmartphones as signal generators and a third smartphone as an oscilloscope to\nvisualize the resulting wave beats. A very good agreement is obtained between\nthe theoretical model and the experimental result. It is an innovative approach\nto bring physics experimentation to the students and discover the potential\npossibilities of smartphones in basic physics courses."
    ],
    "c_categories":[
      [
        "physics.ed-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-682",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17247",
    "b_title":[
      "\"It makes you think\": Provocations Help Restore Critical Thinking to\n  AI-Assisted Knowledge Work"
    ],
    "b_abstract":[
      "Recent research suggests that the use of Generative AI tools may result in\ndiminished critical thinking during knowledge work. We study the effect on\nknowledge work of provocations: brief textual prompts that offer critiques for\nand propose alternatives to AI suggestions. We conduct a between-subjects study\n(n=24) in which participants completed AI-assisted shortlisting tasks with and\nwithout provocations. We find that provocations can induce critical and\nmetacognitive thinking. We derive five dimensions that impact the user\nexperience of provocations: task urgency, task importance, user expertise,\nprovocation actionability, and user responsibility. We connect our findings to\nrelated work on design frictions, microboundaries, and distributed cognition.\nWe draw design implications for critical thinking interventions in AI-assisted\nknowledge work."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13121",
    "c_title":[
      "Concert Interaction Translation: Augmenting VR Live Concert Experience\n  using Chat-Driven Artificial Collective Reactions"
    ],
    "c_abstract":[
      "Computer-mediated concerts can be enjoyed on various devices, from desktop\nand mobile to VR devices, often supporting multiple devices simultaneously.\nHowever, due to the limited accessibility of VR devices, relatively small\naudience members tend to congregate in VR venues, resulting in diminished\nunique social experiences. To address this gap and enrich VR concert\nexperiences, we present a novel approach that leverages non-VR user interaction\ndata, specifically chat from audiences watching the same content on a\nlive-streaming platform. Based on an analysis of audience reactions in offline\nconcerts, we designed and prototyped a concert interaction translation system\nthat extracts the level of engagement and emotions from chats and translates\nthem to collective movements, cheers, and singalongs of virtual audience\navatars in a VR venue. Our user study (n=48) demonstrates that our system,\nwhich combines both movement and audio reactions, significantly enhances the\nsense of immersion and co-presence than the previous method."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-683",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01217",
    "b_title":[
      "Movable Antenna-Assisted Integrated Sensing and Communication Systems"
    ],
    "b_abstract":[
      "Movable antennas (MAs) enhance flexibility in beamforming gain and\ninterference suppression by adjusting position within certain areas of the\ntransceivers. In this paper, we propose an MA-assisted integrated sensing and\ncommunication framework, wherein MAs are deployed for reconfiguring the channel\narray responses at both the receiver and transmitter of a base station. Then,\nwe develop an optimization framework aimed at maximizing the sensing\nsignal-to-interference-plus-noise-ratio (SINR) by jointly optimizing the\nreceive beamforming vector, the transmit beamforming matrix, and the positions\nof MAs while meeting the minimum SINR requirement for each user. To address\nthis nonconvex problem involving complex coupled variables, we devise an\nalternating optimization-based algorithm that incorporates techniques including\nthe Charnes-Cooper transform, second-order Taylor expansion, and successive\nconvex approximation (SCA). Specifically, the closed form of the received\nvector and the optimal transmit matrix can be first obtained in each iteration.\nSubsequently, the solutions for the positions of the transmit and receive MAs\nare obtained using the SCA method based on the second-order Taylor expansion.\nThe simulation results show that the proposed scheme has significant advantages\nover the other baseline schemes. In particular, the proposed scheme has the\nability to match the performance of the fixed position antenna scheme while\nutilizing fewer resources."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18241",
    "c_title":[
      "Integrated Localization and Communication with Sparse MIMO: Will Virtual\n  Array Technology also Benefit Wireless Communication?"
    ],
    "c_abstract":[
      "For the 6G wireless networks, achieving high-performance integrated\nlocalization and communication (ILAC) is critical to unlock the full potential\nof wireless networks. To simultaneously enhance localization and communication\nperformance cost-effectively, this paper proposes sparse multiple-input\nmultiple-output (MIMO) based ILAC with nested and co-prime sparse arrays\ndeployed at the base station. Sparse MIMO relaxes the traditional\nhalf-wavelength antenna spacing constraint to enlarge the antenna aperture,\nthus enhancing localization degrees of freedom and providing finer spatial\nresolution. However, it also leads to undesired grating lobes, which may cause\nsevere inter-user interference for communication and angular ambiguity for\nlocalization. While the latter issue can be effectively addressed by the\nvirtual array technology, by forming sum or difference co-arrays via signal\n(conjugate) correlation among array elements, it is unclear whether the similar\nvirtual array technology also benefits wireless communications for ILAC\nsystems. In this paper, we first reveal that the answer to the above question\nis negative, by showing that forming virtual arrays for wireless communication\nwill cause destruction of phase information, degradation of signal-to-noise\nratio and aggravation of multi-user interference. Therefore, we propose the\nhybrid processing for sparse MIMO based ILAC, i.e., physical array based\ncommunication while virtual array based localization. To this end, we\ncharacterize the beam pattern of sparse arrays by three metrics, demonstrating\nthat despite of the introduction of grating lobes, sparse arrays can also bring\nbenefits to communications thanks to its narrower main lobe beam width than the\nconventional compact arrays. Extensive simulation results are presented to\ndemonstrate the performance gains of sparse MIMO based ILAC over that based on\nthe conventional compact MIMO."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-684",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14876",
    "b_title":[
      "Atypical vortex lattice and the magnetic penetration depth in\n  superconducting Sr$_2$RuO$_4$ deduced by $\\mu$SR"
    ],
    "b_abstract":[
      "The muon spin rotation ($\\mu$SR) technique has been applied to determine the\nbehavior of the in-plane magnetic penetration depth ($\\lambda_{ab}$) in the\nvortex state of the unconventional superconductor Sr$_2$RuO$_4$ as a means of\ngaining insight into its still unknown superconducting order parameter. A\nrecent $\\mu$SR study of Sr$_2$RuO$_4$ reported a $T$-linear temperature\ndependence for $\\lambda_{ab}$ at low temperatures that was not identified in an\nearlier $\\mu$SR study. Here we show that there is no significant difference\nbetween the data in the early and recent $\\mu$SR studies and both are\ncompatible with the limiting low-temperature $\\lambda_{ab} \\sim T^2$ dependence\nexpected from measurements of the change in $\\lambda_{ab}(T)$ in the Meissner\nstate by other techniques. However, we argue that at this time there is no\nvalid theoretical model for reliably determining the absolute value of\n$\\lambda_{ab}$ in Sr$_2$RuO$_4$ from $\\mu$SR measurements. Instead, we identify\nthe formation of an unusual square vortex lattice that introduces a new\nconstraint on candidate superconducting order parameters for Sr$_2$RuO$_4$."
    ],
    "b_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.00566",
    "c_title":[
      "Anomalous nuclear spin coherence in superconducting Nb$_3$Sn"
    ],
    "c_abstract":[
      "We have investigated the normal and superconducting states of the\ntechnologically important compound Nb$_3$Sn using $^{93}$Nb nuclear magnetic\nresonance. From spin-lattice relaxation we find strong suppression of the\nzero-temperature superconducting order parameter by magnetic field. We have\nidentified an anomalously large electron-nuclear exchange interaction from\nspin-spin relaxation measurements, an order of magnitude beyond that of the\ndipole-dipole interaction, and thereby sensitive to vortex dynamics and vortex\npinning."
    ],
    "c_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-685",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09717",
    "b_title":[
      "Running EFT-hedron with null constraints at loop level"
    ],
    "b_abstract":[
      "Implications of general properties of quantum field theory, such as\ncausality, unitarity, and locality include constraints on the couplings of the\neffective field theory (EFT) coefficients. These constraints follow from the\nconnections between the infrared (IR) and ultraviolet (UV) theory imposed by\ndispersion relations for four-particle amplitudes which formally allow us to\nexpress EFT couplings through the moments of positive-definite functions\n(imaginary parts of partial wave amplitudes) forming the EFT-hedron geometry.\nPrevious studies of these positivity bounds were mainly focused on the weakly\ncoupled EFTs, limiting the analysis to tree-level amplitudes of the IR theory.\nIn this work, we extend the scope of positivity bounds including one-loop\namplitudes, which is essential especially for the loops of massless particles.\nExamining a single scalar theory we found that the presence of massless loops\ncannot be reduced only to the running of EFT couplings because loops modify the\ncrossing symmetry relations (null constraints). Our results demonstrate that\nwhile for small coupling constants, the one-loop bounds are in good agreement\nwith the tree-level results, the allowed EFT parameter ranges can be\nsignificantly modified if a weak coupling assumption is not additionally\nimposed. In particular, we found that an upper bound on dimension-8 coupling\nbecomes significantly stronger, and the dimension-12 coupling can be slightly\nnegative which was thought to be forbidden by tree-level positivity bounds."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05174",
    "c_title":[
      "General expression for three-loop $\\beta$-functions of $\\cal N =$ 1\n  supersymmetric theories with multiple gauge couplings regularized by higher\n  covariant derivatives"
    ],
    "c_abstract":[
      "For $\\cal N =$ 1 supersymmetric theories with multiple gauge couplings\nregularized by higher covariant derivatives, a general expression for\nthree-loop gauge $\\beta$-functions is obtained. For this purpose, using general\nstatements about the validity of the NSVZ relations, a result is constructed\nfor the $\\beta$-functions defined in terms of the bare couplings. It is\ndemonstrated that in the particular case of MSSM, it precisely reproduces the\nknown expressions found earlier in another way. For the case where Yukawa\ncouplings are absent, similar expressions for three-loop $\\beta$-functions are\nalso obtained in terms of the renormalized couplings in an arbitrary\nsubtraction scheme and, in particular, in the $\\overline{\\mbox{DR}}$ scheme."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-686",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12195",
    "b_title":[
      "An Optimal Transport approach to arbitrage correction: Application to\n  volatility Stress-Tests"
    ],
    "b_abstract":[
      "We present a method based on optimal transport to remove arbitrage\nopportunities within a finite set of option prices. The method is notably\nintended for regulatory stress-tests, which impose to apply important local\ndistortions to implied volatility surfaces. The resulting stressed option\nprices are naturally associated to a family of signed marginal measures: we\nformulate the process of removing arbitrage as a projection onto the subset of\nmartingale measures with respect to a Wasserstein metric in the space of signed\nmeasures. We show how this projection problem can be recast as an optimal\ntransport problem; in view of the numerical solution, we apply an entropic\nregularization technique. For the regularized problem, we derive a strong\nduality formula, show convergence results as the regularization parameter\napproaches zero, and formulate a multi-constrained Sinkhorn algorithm, where\neach iteration involves, at worse, finding the root of an explicit scalar\nfunction. The convergence of this algorithm is also established. We compare our\nmethod with the existing approach by [Cohen, Reisinger and Wang, Appl.\\ Math.\\\nFin.\\ 2020] across various scenarios and test cases."
    ],
    "b_categories":[
      [
        "q-fin.MF"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2501.01748",
    "c_title":[
      "On consistency of optimal portfolio choice for state-dependent\n  exponential utilities"
    ],
    "c_abstract":[
      "In an arbitrage-free simple market, we demonstrate that for a class of\nstate-dependent exponential utilities, there exists a unique prediction of the\nrandom risk aversion that ensures the consistency of optimal strategies across\nany time horizon. Our solution aligns with the theory of forward performances,\nwith the added distinction of identifying, among the infinite possible\nsolutions, the one for which the profile remains optimal at all times for the\nmarket-adjusted system of preferences adopted."
    ],
    "c_categories":[
      [
        "q-fin.MF"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-687",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01901",
    "b_title":[
      "Sweeping Orders for Simplicial Complex Reconstruction"
    ],
    "b_abstract":[
      "Simplicial complexes arising from real-world settings may not be directly\nobservable. Hence, for an unknown simplicial complex in Euclidean space, we\nwant to efficiently reconstruct it by querying local structure. In particular,\nwe are interested in queries for the indegree of a simplex $\\sigma$ in some\ndirection: the number of cofacets of $\\sigma$ contained in some halfspace\n\"below\" $\\sigma$. Fasy et al. proposed a method that, given the vertex set of a\nsimplicial complex, uses indegree queries to reconstruct the set of edges. In\nparticular, they use a sweep algorithm through the vertex set, identifying\nedges adjacent to and above each vertex in the sweeping order. The algorithm\nrelies on a natural but crucial property of the sweeping order: at a given\nvertex $v$, all edges adjacent to $v$ contained in the halfspace below $v$ have\nanother endpoint that appeared earlier in the order.\n  The edge reconstruction algorithm does not immediately extend to\nhigher-dimensional simplex reconstruction. In particular, it is not possible to\nsweep through a set of $i$-simplices in a fixed direction and maintain that all\n$(i+1)$-cofacets of a given simplex $\\sigma$ that come below $\\sigma$ are\nknown. We circumvent this by defining a sweeping order on a set of\n$i$-simplices, that additionally pairs each $i$-simplex $\\sigma$ with a\ndirection perpendicular to $\\sigma$. Analogous to Fasy et al., our order has\nthe crucial property that, at any $i$-simplex $\\sigma$ paired with direction\n$s$, each $(i+1)$-dimensional coface of $\\sigma$ that lies in the halfspace\nbelow $\\sigma$ with respect to the direction $s$ has an $i$-dimensional face\nthat appeared earlier in the order. We show how to compute such an order and\nuse it to extend the edge reconstruction algorithm of Fasy et al. to simplicial\ncomplex reconstruction. Our algorithm can reconstruct arbitrary embedded\nsimplicial complexes."
    ],
    "b_categories":[
      [
        "cs.CG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05178",
    "c_title":[
      "On Triangular Separation of Bichromatic Point Sets"
    ],
    "c_abstract":[
      "We address the problem of computing the minimum number of triangles to\nseparate a set of blue points from a set of red points in $\\mathbb{R}^2$. A set\nof triangles is a \\emph{separator} of one color from the other if every point\nof that color is contained in some triangle and no triangle contains points of\nboth colors. We consider several variants of the problem depending on whether\nthe triangles are allowed to overlap or not and whether all points or just the\nblue points need to be contained in a triangle. We show that computing the\nminimum cardinality triangular separator of a set of blue points from a set of\nred points is NP-hard and further investigate worst case bounds on the minimum\ncardinality of triangular separators for a bichromatic set of $n$ points."
    ],
    "c_categories":[
      [
        "cs.CG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-688",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08249",
    "b_title":[
      "GenAI as Digital Plastic: Understanding Synthetic Media Through Critical\n  AI Literacy"
    ],
    "b_abstract":[
      "This paper introduces the conceptual metaphor of 'digital plastic' as a\nframework for understanding the implications of Generative Artificial\nIntelligence (GenAI) content through a multiliteracies lens, drawing parallels\nwith the properties of physical plastic. Similar to its physical counterpart,\nGenAI content offers possibilities for content creation and accessibility while\npotentially contributing to digital pollution and ecosystem degradation.\nDrawing on multiliteracies theory and Conceptual Metaphor Theory, we argue that\nCritical Artificial Intelligence Literacy (CAIL) must be integrated into\neducational frameworks to help learners navigate this synthetic media\nlandscape.\n  We examine how GenAI can simultaneously lower the barriers to creative and\nacademic production while threatening to degrade digital ecosystems through\nmisinformation, bias, and algorithmic homogenization. The digital plastic\nmetaphor provides a theoretical foundation for understanding both the\naffordances and challenges of GenAI, particularly in educational contexts,\nwhere issues of equity and access remain paramount. Our analysis concludes that\ncultivating CAIL through a multiliteracies lens is vital for ensuring the\nequitable development of critical competencies across geographical and cultural\ncontexts, especially for those disproportionately vulnerable to GenAI's\nincreasingly disruptive effects worldwide."
    ],
    "b_categories":[
      [
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15684",
    "c_title":[
      "Student's Use of Generative AI as a Support Tool in an Advanced Web\n  Development Course"
    ],
    "c_abstract":[
      "Various studies have studied the impact of Generative AI on Computing\nEducation. However, they have focused on the implications for novice\nprogrammers. In this experience report, we analyze the use of GenAI as a\nsupport tool for learning, creativity, and productivity in a web development\ncourse for undergraduate students with extensive programming experience. We\ncollected diverse data (assignments, reflections, logs, and a survey) and found\nthat students used GenAI on different tasks (code generation, idea generation,\netc.) with a reported increase in learning and productivity. However, they are\nconcerned about over-reliance and incorrect solutions and want more training in\nprompting strategies."
    ],
    "c_categories":[
      [
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-689",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19699",
    "b_title":[
      "Spatial-Spectral Diffusion Contrastive Representation Network for\n  Hyperspectral Image Classification"
    ],
    "b_abstract":[
      "Although efficient extraction of discriminative spatial-spectral features is\ncritical for hyperspectral images classification (HSIC), it is difficult to\nachieve these features due to factors such as the spatial-spectral\nheterogeneity and noise effect. This paper presents a Spatial-Spectral\nDiffusion Contrastive Representation Network (DiffCRN), based on denoising\ndiffusion probabilistic model (DDPM) combined with contrastive learning (CL)\nfor HSIC, with the following characteristics. First,to improve spatial-spectral\nfeature representation, instead of adopting the UNets-like structure which is\nwidely used for DDPM, we design a novel staged architecture with spatial\nself-attention denoising module (SSAD) and spectral group self-attention\ndenoising module (SGSAD) in DiffCRN with improved efficiency for\nspectral-spatial feature learning. Second, to improve unsupervised feature\nlearning efficiency, we design new DDPM model with logarithmic absolute error\n(LAE) loss and CL that improve the loss function effectiveness and increase the\ninstance-level and inter-class discriminability. Third, to improve feature\nselection, we design a learnable approach based on pixel-level spectral angle\nmapping (SAM) for the selection of time steps in the proposed DDPM model in an\nadaptive and automatic manner. Last, to improve feature integration and\nclassification, we design an Adaptive weighted addition modul (AWAM) and Cross\ntime step Spectral-Spatial Fusion Module (CTSSFM) to fuse time-step-wise\nfeatures and perform classification. Experiments conducted on widely used four\nHSI datasets demonstrate the improved performance of the proposed DiffCRN over\nthe classical backbone models and state-of-the-art GAN, transformer models and\nother pretrained methods. The source code and pre-trained model will be made\navailable publicly."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.01643",
    "c_title":[
      "FruitPAL: An IoT-Enabled Framework for Automatic Monitoring of Fruit\n  Consumption in Smart Healthcare"
    ],
    "c_abstract":[
      "Fruits are rich sources of essential vitamins and nutrients that are vital\nfor human health. This study introduces two fully automated devices, FruitPAL\nand its updated version, FruitPAL 2.0, which aim to promote safe fruit\nconsumption while reducing health risks. Both devices leverage a high-quality\ndataset of fifteen fruit types and use advanced models- YOLOv8 and YOLOv5 V6.0-\nto enhance detection accuracy. The original FruitPAL device can identify\nvarious fruit types and notify caregivers if an allergic reaction is detected,\nthanks to YOLOv8's improved accuracy and rapid response time. Notifications are\ntransmitted via the cloud to mobile devices, ensuring real-time updates and\nimmediate accessibility. FruitPAL 2.0 builds upon this by not only detecting\nfruit but also estimating its nutritional value, thereby encouraging healthy\nconsumption. Trained on the YOLOv5 V6.0 model, FruitPAL 2.0 analyzes fruit\nintake to provide users with valuable dietary insights. This study aims to\npromote fruit consumption by helping individuals make informed choices,\nbalancing health benefits with allergy awareness. By alerting users to\npotential allergens while encouraging the consumption of nutrient-rich fruits,\nthese devices support both health maintenance and dietary awareness."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-690",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12644",
    "b_title":[
      "Computing Efficient Envy-Free Partial Allocations of Indivisible Goods"
    ],
    "b_abstract":[
      "Envy-freeness is one of the most prominent fairness concepts in the\nallocation of indivisible goods. Even though trivial envy-free allocations\nalways exist, rich literature shows this is not true when one additionally\nrequires some efficiency concept (e.g., completeness, Pareto-efficiency, or\nsocial welfare maximization). In fact, in such case even deciding the existence\nof an efficient envy-free allocation is notoriously computationally hard. In\nthis paper, we explore the limits of efficient computability by relaxing\nstandard efficiency concepts and analyzing how this impacts the computational\ncomplexity of the respective problems. Specifically, we allow partial\nallocations (where not all goods are allocated) and impose only very mild\nefficiency constraints, such as ensuring each agent receives a bundle with\npositive utility. Surprisingly, even such seemingly weak efficiency\nrequirements lead to a diverse computational complexity landscape. We identify\nseveral polynomial-time solvable or fixed-parameter tractable cases for binary\nutilities, yet we also find NP-hardness in very restricted scenarios involving\nternary utilities."
    ],
    "b_categories":[
      [
        "cs.GT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14078",
    "c_title":[
      "Learning Bayesian Game Families, with Application to Mechanism Design"
    ],
    "c_abstract":[
      "Learning or estimating game models from data typically entails inducing\nseparate models for each setting, even if the games are parametrically related.\nIn empirical mechanism design, for example, this approach requires learning a\nnew game model for each candidate setting of the mechanism parameter. Recent\nwork has shown the data efficiency benefits of learning a single parameterized\nmodel for families of related games. In Bayesian games - a typical model for\nmechanism design - payoffs depend on both the actions and types of the players.\nWe show how to exploit this structure by learning an interim game-family model\nthat conditions on a single player's type. We compare this approach to the\nbaseline approach of directly learning the ex ante payoff function, which gives\npayoffs in expectation of all player types. By marginalizing over player type,\nthe interim model can also provide ex ante payoff predictions. This dual\ncapability not only facilitates Bayes-Nash equilibrium approximation, but also\nenables new types of analysis using the conditional model. We validate our\nmethod through a case study of a dynamic sponsored search auction. In our\nexperiments, the interim model more reliably approximates equilibria than the\nex ante model and exhibits effective parameter extrapolation. With local search\nover the parameter space, the learned game-family model can be used for\nmechanism design. Finally, without any additional sample data, we leverage the\ninterim model to compute piecewise best-response strategies and refine our\nmodel to incorporate these strategies, enabling an iterative approach to\nempirical mechanism design."
    ],
    "c_categories":[
      [
        "cs.GT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-691",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12900",
    "b_title":[
      "Interplanar magnetic exchange in CoPS$_3$"
    ],
    "b_abstract":[
      "Neutron three-axis spectrometry has been used to determine the interplanar\nmagnetic exchange parameter in the magnetic van der Waals compound CoPS$_3$.\nThe exchange is found to be small and antiferromagnetic, estimated to be 0.020\n$\\pm$ 0.001 meV, which is surprising considering that the magnetic structure is\ncorrelated ferromagnetically between the ab planes. A possible explanation,\ninvolving a small anisotropy in the exchanges, is proposed. The results are\ndiscussed with reference to the other members of the transition metal-PS3\ncompounds."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.11106",
    "c_title":[
      "Point-group symmetry enriched topological orders"
    ],
    "c_abstract":[
      "We study the classification of two-dimensional (2D) topological orders\nenriched by point-group symmetries, by generalizing the folding appraoch which\nwas previously developed for mirror-symmetry-enriched topological orders. We\nfold the 2D plane hosting the topological order into the foundamental domain of\nthe group group, which is a sector with an angle $2\\pi\/n$ for the cyclic point\ngroup $C_n$ and a sector with an angle $\\pi\/n$ for the dihedral point group\n$D_{2n}$, and the point-group symmetries becomes onsite unitary symmetries on\nthe sector. The enrichment of the point-group symmetries is then fully encoded\nat the boundary of the sector and the apex of the section, which forms a\njunction between the two boundaries. The mirror-symmetry enrichment encoded on\nthe boundaries is analyzed by the classification theory of symmetric gapped\nboundaries, and the point-group-symmetry enrichment encoded on the junction is\nanalyzed by a framework for classifying symmetric gapped junctions between\nboundaries which we develop in this work. We show that at the junction, there\nare two potential obstructions, which we refer to as an $H^1$ obstruction and\nan $H^2$ obstruction, respectively. When the obstruction vanishes, the\njunction, and therefore the point-group-symmetry-enriched topological orders,\nare classified by an $H^0$ cohomology class and an $H^1$ cohomology class,\nwhich can be understood as an additional Abelian anyon and a symmetry charge\nattached to the rotation center, respectively. These results are consistent\nwith the classification of onsite-symmetry-enriched topological orders, where\nthe $H^1$ and $H^2$ obstructions and the junction corresponds to the $H^3$ and\n$H^4$ obstructions for onsite symmetries, respectively."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-692",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13029",
    "b_title":[
      "Galactic magnetic fields II. Applying the model to nearby galaxies"
    ],
    "b_abstract":[
      "Many spiral galaxies host magnetic fields with energy densities comparable to\nthose of the turbulent and thermal motions of their interstellar gas. However,\nquantitative comparison between magnetic field properties inferred from\nobservation and those obtained from theoretical modeling has been lacking. In\nPaper I we developed a simple, axisymmetric galactic dynamo model that uses\nvarious observational data as input. Here we apply our model to calculate\nradial profiles of azimuthally and vertically averaged magnetic field strength\nand pitch angle, gas velocity dispersion and scale height, turbulent\ncorrelation time and length, and the sizes of supernova remnants for the\ngalaxies M31, M33, M51, and NGC 6946, using input data collected from the\nliterature. Scaling factors are introduced to account for a lack of precision\nin both theory and observation. Despite the simplicity of our model, its\noutputs agree fairly well with galaxy properties inferred from observation.\nAdditionally, we find that most of the parameter values are similar between\ngalaxies. We extend the model to predict the magnetic field pitch angles\narising from a combination of mean-field dynamo action and the winding up of\nthe random small-scale field owing to the large-scale radial shear. We find\ntheir magnitudes to be much smaller than those of the pitch angles measured in\npolarized radio and far infrared emission. This suggests that effects not\nincluded in our model, such as effects associated with spiral arms, are needed\nto explain the pitch angle values."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.12026",
    "c_title":[
      "Synthetic Modelling of Polarized Dust Emission in Intermediate-Mass\n  YSOs: II: Effects of Radiative Torque Disruption on Dust Grains in\n  Protostellar Jets\/Outflows"
    ],
    "c_abstract":[
      "One of the potential explanations for the existence of very large grains\n(VLGs) in the inner envelope of low\/intermediate-mass Class 0\/I Young Stellar\nObject is the migration of VLGs from the protostellar disk via a protostellar\noutflow. To understand whether the grain migration is prevented by RAdiative\nTorque Disruption (RATD), we perform the numerical modeling of RATD in parallel\nwith the grain propagation, using the gas velocity and density structure inside\nthe jet and outflow from an MHD simulation of an intermediate Class 0\nprotostar. We found that with the bolometric luminosity $\\geq 20L_{\\odot}$,\nRATD can destroy aggregate grains of size $1 \\sim 500\\rm \\mu m$ having maximum\ntensile strength $S_{\\rm max} \\leq 10^{5} \\rm erg cm^{-3}$ inside the\njet\/outflow base after $< 2$ yrs. This effect lets sub-micron grains dominate\nthe outflow and partially prevent the migration of large grains from the inner\ndisk to inner envelope. In contrast, RATD cannot prevent the migration of\ncomposite VLGs and submillimeter grains having $S_{\\rm max}\\geq 10^{7} \\rm erg\ncm^{-3}$. Next, we incorporate RATD into POLARIS, assuming grains are not\nmoving relative to the gas. We found that POLARIS works well in describing the\ndisruption for aggregate grains, but overestimates the disruption efficiency\nfor composite grains. The observed polarization degree can be reduced by twice\nwhen aggregate grains are removed from the outflow cavity wall and inner\nenvelope by RATD. However, RATD is not an important factor controlling dust\npolarization properties as iron inclusions do."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-693",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05482",
    "b_title":[
      "Robustifying Fourier Features Embeddings for Implicit Neural\n  Representations"
    ],
    "b_abstract":[
      "Implicit Neural Representations (INRs) employ neural networks to represent\ncontinuous functions by mapping coordinates to the corresponding values of the\ntarget function, with applications e.g., inverse graphics. However, INRs face a\nchallenge known as spectral bias when dealing with scenes containing varying\nfrequencies. To overcome spectral bias, the most common approach is the Fourier\nfeatures-based methods such as positional encoding. However, Fourier\nfeatures-based methods will introduce noise to output, which degrades their\nperformances when applied to downstream tasks. In response, this paper\ninitially hypothesizes that combining multi-layer perceptrons (MLPs) with\nFourier feature embeddings mutually enhances their strengths, yet\nsimultaneously introduces limitations inherent in Fourier feature embeddings.\nBy presenting a simple theorem, we validate our hypothesis, which serves as a\nfoundation for the design of our solution. Leveraging these insights, we\npropose the use of multi-layer perceptrons (MLPs) without additive"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00426",
    "c_title":[
      "TEST-V: TEst-time Support-set Tuning for Zero-shot Video Classification"
    ],
    "c_abstract":[
      "Recently, adapting Vision Language Models (VLMs) to zero-shot visual\nclassification by tuning class embedding with a few prompts (Test-time Prompt\nTuning, TPT) or replacing class names with generated visual samples\n(support-set) has shown promising results. However, TPT cannot avoid the\nsemantic gap between modalities while the support-set cannot be tuned. To this\nend, we draw on each other's strengths and propose a novel framework namely\nTEst-time Support-set Tuning for zero-shot Video Classification (TEST-V). It\nfirst dilates the support-set with multiple prompts (Multi-prompting\nSupport-set Dilation, MSD) and then erodes the support-set via learnable\nweights to mine key cues dynamically (Temporal-aware Support-set Erosion, TSE).\nSpecifically, i) MSD expands the support samples for each class based on\nmultiple prompts enquired from LLMs to enrich the diversity of the support-set.\nii) TSE tunes the support-set with factorized learnable weights according to\nthe temporal prediction consistency in a self-supervised manner to dig pivotal\nsupporting cues for each class. $\\textbf{TEST-V}$ achieves state-of-the-art\nresults across four benchmarks and has good interpretability for the\nsupport-set dilation and erosion."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-694",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19061",
    "b_title":[
      "Conceptual study on using Doppler backscattering to measure magnetic\n  pitch angle in tokamak plasmas"
    ],
    "b_abstract":[
      "We introduce a new approach to measure the magnetic pitch angle profile in\ntokamak plasmas with Doppler backscattering (DBS), a technique traditionally\nused for measuring flows and density fluctuations. The DBS signal is maximised\nwhen its probe beam's wavevector is perpendicular to the magnetic field at the\ncutoff location, independent of the density fluctuations. Hence, if one could\nisolate this effect, DBS would then yield information about the magnetic pitch\nangle. By varying the toroidal launch angle, the DBS beam reaches cutoff with\ndifferent angles with respect to the magnetic field, but with other properties\nremaining similar. Hence, the toroidal launch angle which gives maximum\nbackscattered power is thus that which is matched to the pitch angle at the\ncutoff location, enabling inference of the magnetic pitch angle. We performed\nsystematic scans of the DBS toroidal launch angle for repeated DIII-D tokamak\ndischarges. Experimental DBS data from this scan were analysed and combined\nwith Gaussian beam-tracing simulations using the Scotty code. The pitch-angle\ninferred from DBS is consistent with that from magnetics-only and\nmotional-Stark-effect-constrained (MSE) equilibrium reconstruction in the edge.\nIn the core, the pitch angles from DBS and magnetics-only reconstructions\ndiffer by one to two degrees, while simultaneous MSE measurements were not\navailable. The uncertainty in these measurements was under a degree; we show\nthat this uncertainty is primarily due to the error in toroidal steering, the\nnumber of toroidally separated measurements, and shot-to-shot repeatability. We\nfind that the error of pitch-angle measurements can be reduced by optimising\nthe poloidal launch angle and initial beam properties."
    ],
    "b_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04934",
    "c_title":[
      "Computation of generalised magnetic coordinates asymptotically close to\n  the separatrix"
    ],
    "c_abstract":[
      "Integrals to calculate generalised magnetic coordinates from an input\nmagnetic flux function asymptotically close to the separatrix are presented,\nand implemented in the GPEC\/DCON code suite. These integrals allow\ncharacterisation of the magnetic equilibrium of a diverted tokamak, in magnetic\ncoordinates, arbitrarily close to the last closed flux surface, avoiding the\nnumerical issues associated with calculating diverging field line integrals\nnear a magnetic x-point. These methods provide an important first step in the\ndevelopment of robust asymptotic equilibrium behaviour for spectral 3D MHD\ncodes at the separatrix."
    ],
    "c_categories":[
      [
        "physics.plasm-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-695",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15290",
    "b_title":[
      "Reinforcement Learning for Robust Athletic Intelligence: Lessons from\n  the 2nd 'AI Olympics with RealAIGym' Competition"
    ],
    "b_abstract":[
      "In the field of robotics many different approaches ranging from classical\nplanning over optimal control to reinforcement learning (RL) are developed and\nborrowed from other fields to achieve reliable control in diverse tasks. In\norder to get a clear understanding of their individual strengths and weaknesses\nand their applicability in real world robotic scenarios is it important to\nbenchmark and compare their performances not only in a simulation but also on\nreal hardware. The '2nd AI Olympics with RealAIGym' competition was held at the\nIROS 2024 conference to contribute to this cause and evaluate different\ncontrollers according to their ability to solve a dynamic control problem on an\nunderactuated double pendulum system with chaotic dynamics. This paper\ndescribes the four different RL methods submitted by the participating teams,\npresents their performance in the swing-up task on a real double pendulum,\nmeasured against various criteria, and discusses their transferability from\nsimulation to real hardware and their robustness to external disturbances."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09636",
    "c_title":[
      "Real-Time Neuromorphic Navigation: Guiding Physical Robots with\n  Event-Based Sensing and Task-Specific Reconfigurable Autonomy Stack"
    ],
    "c_abstract":[
      "Neuromorphic vision, inspired by biological neural systems, has recently\ngained significant attention for its potential in enhancing robotic autonomy.\nThis paper presents a systematic exploration of a proposed Neuromorphic\nNavigation framework that uses event-based neuromorphic vision to enable\nefficient, real-time navigation in robotic systems. We discuss the core\nconcepts of neuromorphic vision and navigation, highlighting their impact on\nimproving robotic perception and decision-making. The proposed reconfigurable\nNeuromorphic Navigation framework adapts to the specific needs of both ground\nrobots (Turtlebot) and aerial robots (Bebop2 quadrotor), addressing the\ntask-specific design requirements (algorithms) for optimal performance across\nthe autonomous navigation stack -- Perception, Planning, and Control. We\ndemonstrate the versatility and the effectiveness of the framework through two\ncase studies: a Turtlebot performing local replanning for real-time navigation\nand a Bebop2 quadrotor navigating through moving gates. Our work provides a\nscalable approach to task-specific, real-time robot autonomy leveraging\nneuromorphic systems, paving the way for energy-efficient autonomous\nnavigation."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-696",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04894",
    "b_title":[
      "The THESAN-ZOOM project: central starbursts and inside-out quenching\n  govern galaxy sizes in the early Universe"
    ],
    "b_abstract":[
      "We explore the evolution of galaxy sizes at high redshift ($3 < z < 13$)\nusing the high-resolution THESAN-ZOOM radiation-hydrodynamics simulations,\nfocusing on the mass range of $10^6\\,\\mathrm{M}_{\\odot} < \\mathrm{M}_{\\ast} <\n10^{10}\\,\\mathrm{M}_{\\odot}$. Our analysis reveals that galaxy size growth is\ntightly coupled to bursty star formation. Galaxies above the star-forming main\nsequence experience rapid central compaction during starbursts, followed by\ninside-out quenching and spatially extended star formation that leads to\nexpansion, causing oscillatory behavior around the size-mass relation. Notably,\nwe find a positive intrinsic size-mass relation at high redshift, consistent\nwith observations but in tension with large-volume simulations. We attribute\nthis discrepancy to the bursty star formation captured by our multi-phase\ninterstellar medium framework, but missing from simulations using the effective\nequation-of-state approach with hydrodynamically decoupled feedback. We also\nfind that the normalization of the size-mass relation follows a double power\nlaw as a function of redshift, with a break at $z\\approx6$, because the\nmajority of galaxies at $z > 6$ show rising star-formation histories, and\ntherefore are in a compaction phase. We demonstrate that H$\\alpha$ emission is\nsystematically extended relative to the UV continuum by a median factor of 1.7,\nconsistent with recent JWST studies. However, in contrast to previous\ninterpretations that link extended H$\\alpha$ sizes to inside-out growth, we\nfind that Lyman-continuum (LyC) emission is spatially disconnected from\nH$\\alpha$. Instead, a simple Str\\\"{o}mgren sphere argument reproduces observed\ntrends, suggesting that extreme LyC production during central starbursts is the\nprimary driver of extended nebular emission."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.11859",
    "c_title":[
      "Examining Turbulence in Galactic Molecular Clouds -- I: A Statistical\n  Analysis of Velocity Structures"
    ],
    "c_abstract":[
      "We present a systematic analysis of the velocity structure functions (VSFs)\nof 167 molecular clouds with angular sizes greater than $\\sim$176 arcmin$^2$ in\nthree sectors of the Galactic mid-plane. We calculated the 1st- to 3rd-order\nVSFs and found that 60\\% of the VSFs exhibit power-law distributions. The\nrelative power-law exponents are consistent with predictions from intermittent\nturbulence models. Column density weighting reduces the proportion of power-law\nVSFs and steepens the VSF slopes, implying a reduction of turbulent energy in\nhigh-density regions. All clouds show small-scale intermittency, with slightly\nstronger intermittency in those molecular clouds showing none power-law VSFs.\nNegative VSF exponents that may indicate gravitational collapse are not\nobserved in our sample. The scaling exponents of the observed VSFs do not\ncorrelate with the virial parameters of the molecular clouds. These two\nobservations suggest that gravity-dominated scales in molecular clouds still\nneed further investigation. Consistent VSF scaling exponents for the molecular\nclouds with significant power-law VSFs suggest large-scale external driving of\nturbulence in these molecular clouds. However, the driving mechanisms are\nlikely not universal, as the power-law scaling coefficients in our results show\nrelatively large scatter. The fact that nearly 40\\% of the VSFs deviate to some\nextent from power-law distributions suggests that the influence of local\nenvironments on the internal turbulence of molecular clouds may not be\nnegligible."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-697",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14981",
    "b_title":[
      "Convex Analysis in Spectral Decomposition Systems"
    ],
    "b_abstract":[
      "This work is concerned with convex analysis of so-called spectral functions\nof matrices that only depend on eigenvalues of the matrix. An abstract\nframework of spectral decomposition systems is proposed that covers a wide\nrange of previously studied settings, including eigenvalue decomposition of\nHermitian matrices and singular value decomposition of rectangular matrices and\nallows deriving new results in more general settings such as Euclidean Jordan\nalgebras. The main results characterize convexity, lower semicontinuity,\nFenchel conjugates, convex subdifferentials, and Bregman proximity operators of\nspectral functions in terms of the reduced functions. As a byproduct, a\ngeneralization of the Ky Fan majorization theorem is obtained."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.14459",
    "c_title":[
      "Algorithms for min-buying in networks"
    ],
    "c_abstract":[
      "The paper is motivated by pricing decisions faced by forecourt fuel retailers\nacross their outlets on a road network. Through our modelling approach we are\nable adapt the network structure to a bipartite graph with demand nodes\nrepresenting volumes of fuel from customers using a specific route that\nconnects to the seller's outlet nodes that intersect that route on the network.\nCustomers may have their demand satisfied at the lowest priced competitor on\ntheir route. However, the seller can satisfy some or all of this demand by\nmatching or beating this price via one of their outlets intersecting the route.\nWe give a practical extension to min-pricing by considering a binary logit\nvariant for buyers evaluating the choice between two sellers. We derive two MIP\nformulations for min-buying in the case of general demand. We also propose\nseveral constructive heuristics, based on insertion and selection operations,\nsuitable for problem instances beyond the scope of the exact methods. The\nperformance of models and algorithms are evaluated in a numerical study and\ndevelop insights from the results. Importantly, we are able to highlight the\nvalue of price-matching decisions under buyer demand sensitivity."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-698",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15456",
    "b_title":[
      "Extremal graphs for disjoint union of vertex-critical graphs"
    ],
    "b_abstract":[
      "For a graph $F$, let ${\\rm EX}(n,F)$ be the set of $F$-free graphs of order\n$n$ with the maximum number of edges. The graph $F$ is called vertex-critical,\nif the deletion of its some vertex induces a graph with smaller chromatic\nnumber. For example, an odd wheel (obtained by connecting a vertex to a cycle\nof even length) is a vertex-critical graph with chromatic number 3. For\n$h\\geq2$, let $F_{1},F_{2},...,F_{h}$ be vertex-critical graphs with the same\nchromatic number. Let $\\cup_{1\\leq i\\leq h}F_{i}$ be the disjoint union of\nthem. In this paper, we characterize the graphs in ${\\rm EX}(n,\\cup_{1\\leq\ni\\leq h}F_{i})$, when there is a proper order among the graphs\n$F_{1},F_{2},...,F_{h}$. This solves a conjecture (on extremal problem for\ndisjoint union of odd wheels) proposed by Xiao and Zamora \\cite{XZ}."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.17203",
    "c_title":[
      "Homogeneous Patterns in Ramsey Theory"
    ],
    "c_abstract":[
      "In the present article, we study a homogeneous version of some nonlinear\nRamsey theoretic results with three applications.\n  As a first application, we prove that for every finite coloring of\n$\\mathbb{Z}^+$, there exists an infinite set $A$ and an arbitrarily large\nfinite set $B$ such that $A\\cup (A+B)\\cup A\\cdot B$ is monochromatic, which\nanswers the finitary version of Kra, Moreira, Richter, and Robertson's question\nasking whether $(A+B)\\cup A\\cdot B$ is partition regular for infinite sets\n$A,B$, closely related to a question of Erd\\H{o}s.\n  As a second application, we made a progress related to a nonlinear extension\nof the partition regularity of Pythagorean triples, where we prove that the\nequation $x^2+y^2=z^2+P(u_1,\\cdots ,u_n)$ is $2$-regular for some suitable\npolynomials $P$ of any desired degree.\n  Finally, as a third application, we prove a nonlinear version of Rado's\nconjecture on the degree of regularity. We prove for every $m,n\\in\n\\mathbb{Z}^+,$ there exists an $m$-degree homogeneous equation which is\n$n$-regular but not $n+1$-regular; the case $m=1$ was Rado's conjecture first\nproved by Alexeev and Tsimerman, and later independently by Golowich."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-699",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01751",
    "b_title":[
      "Clustered unified dark sector cosmology: Background evolution and linear\n  perturbations in light of observations"
    ],
    "b_abstract":[
      "We consider unified dark sector models in which the fluid can collapse and\ncluster into halos, allowing for hierarchical structure formation to proceed as\nin standard cosmology. We show that both background evolution and linear\nperturbations tend towards those in $\\LCDM$ as the clustered fraction $f\n\\rightarrow 1$. We confront such models with various observational datasets,\nwith emphasis on the relatively well motivated standard Chaplygin gas. We show\nthat the strongest constraints come from secondary anisotropies in the CMB\nspectrum, which prefer models with $f \\rightarrow 1$. However, as a larger\nHubble constant is allowed for smaller $f$, values of $f \\simeq 0.99$ (rather\nthan tending to exact unity) are favored when late universe expansion data is\nincluded, with $f \\simeq 0.97$ and $H_0 \\simeq 70 {\\rm km\/s\/Mpc}$ allowed at\nthe 2-$\\sigma$ level. Such values of $f$ imply extremely efficient clustering\ninto nonlinear structures. They may nevertheless be compatible with clustered\nfractions in warm dark matter based cosmologies, which have similar minimal\nhalo mass scales as the models considered here. Tight CMB constraints on $f$\nalso apply to the generalized Chaplygin gas, except for models that are already\nquite close to $\\LCDM$, in which case all values of $0 \\le f \\le 1$ are\nallowed. In contrast to the CMB, large scale structure data, which were\ninitially used to rule out unclustered unified dark matter models, are far less\nconstraining. Indeed, late universe data, including the large scale galaxy\ndistribution, prefer models that are far from $\\LCDM$. But these are in tension\nwith the CMB data."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09476",
    "c_title":[
      "Void spin distribution as a powerful probe of $\\sigma_{8}$"
    ],
    "c_abstract":[
      "We present a numerical proof of the concept that the void spin distributions\ncan in principle provide a tight constraint on the amplitude of matter density\nfluctuation on the scale of $8\\,h^{-1}{\\rm Mpc}$ ($\\sigma_{8}$) without being\nseverely deteriorated by the degeneracies of $\\sigma_{8}$ with cold dark matter\ndensity parameter multiplied by the dimensionless Hubble parameter square\n($\\Omega_{\\rm cdm}h^{2}$), total neutrino mass ($M_{\\nu}$) and dark energy\nequation of state ($w$). Applying the Void-Finder algorithm to a total of $15$\nAbacusSummit $N$-body simulations of $15$ different cosmological models, we\nidentify the giant voids to measure their spins, defined as the magnitudes of\nrescaled specific angular momenta of void halos. The $15$ cosmologies include\nthe Planck $\\Lambda$CDM and $14$ non-Planck models, each of which differs among\none another only in one of $\\{\\sigma_{8},\\ \\Omega_{\\rm cdm}h^{2},\\ M_{\\nu},\\\nw\\}$. The probability density distribution of void spins is determined for each\nmodel and found to be well approximated by the generalized Gamma distribution\nwith two characteristic parameters, $k$ and $\\theta$. It turns out that the\nbest-fit values of $k$ and $\\theta$ exhibit very sensitive dependences only on\n$\\sigma_{8}$, being almost insensitive to $\\Omega_{\\rm cdm}h^{2}$, $M_{\\nu}$,\n$w$. This exclusive $\\sigma_{8}$-dependence of the void spin distributions is\nconfirmed to be robust against the variation of the mass and number cuts of\nvoid halos. We also test an observational feasibility of estimating the void\nspins from real data on the galaxy redshifts."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-700",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08525",
    "b_title":[
      "A class of new complete affine maximal type hypersurfaces"
    ],
    "b_abstract":[
      "In this paper we classify a kind of special Calabi hypersurfaces with\nnegative constant sectional curvature in Calabi affine geometry. Meanwhile, we\nfind a class of new Euclidean complete and Calabi complete affine\nhypersurfaces, which satisfy the affine maximal type equation and the Abreu\nequation with negative constant scalar curvatures."
    ],
    "b_categories":[
      [
        "math.DG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.01170",
    "c_title":[
      "Non-singular weakly symmetric nilmanifolds"
    ],
    "c_abstract":[
      "A Riemannian manifold $M$ is called weakly symmetric if any two points in $M$\ncan be interchanged by an isometry. The compact ones have been well understood,\nand the main remaining case is that of 2-step nilpotent Lie groups. We give a\ncomplete classification of simply connected non-singular weakly symmetric\nnilmanifolds. Besides previously known examples, there are new families with\n3-dimensional center, and a one-parameter family of dimensions 14. The\nclassification is based on the authors classification of non-singular 2-step\nnilpotent Lie groups for which every geodesic is the image of a one parameter\ngroup of isometries."
    ],
    "c_categories":[
      [
        "math.DG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-701",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14700",
    "b_title":[
      "From Density to Void: Why Brain Networks Fail to Reveal Complex\n  Higher-Order Structures"
    ],
    "b_abstract":[
      "In brain network analysis using resting-state fMRI, there is growing interest\nin modeling higher-order interactions beyond simple pairwise connectivity via\npersistent homology. Despite the promise of these advanced topological tools,\nrobust and consistently observed higher-order interactions over time remain\nelusive. In this study, we investigate why conventional analyses often fail to\nreveal complex higher-order structures - such as interactions involving four or\nmore nodes - and explore whether such interactions truly exist in functional\nbrain networks. We utilize a simplicial complex framework often used in\npersistent homology to address this question."
    ],
    "b_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2502.16088",
    "c_title":[
      "Electrophysiological Investigation of Insect Pain Threshold"
    ],
    "c_abstract":[
      "The question of whether insects experience pain has long been debated in\nneuroscience and animal behavior research. Increasing evidence suggests that\ninsects possess the ability to detect and respond to noxious stimuli,\nexhibiting behaviors indicative of pain perception. This study investigates the\nrelationship between pain stimuli and physiological responses in crickets\n(Gryllidae), focusing on heart rate (ECG) and brain wave (EEG) patterns. We\napplied a range of mechanical, chemical, thermal, and electrical stimuli to\ncrickets, recording ECG and EEG data while employing a deep learning-based\nmodel to classify pain levels. Our findings revealed significant heart rate\nchanges and EEG fluctuations in response to various stimuli, with the highest\nintensity stimuli inducing marked physiological stress. The AI-based analysis,\nutilizing AlexNet for EEG signal classification, achieved 90% accuracy in\ndistinguishing between resting, low-pain, and high-pain states. While no social\nsharing of pain was observed through ECG measurements, these results contribute\nto the growing body of evidence supporting insect nociception and offer new\ninsights into their physiological responses to external stressors. This\nresearch advances the understanding of insect pain mechanisms and demonstrates\nthe potential for AI-driven analysis in entomological studies."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-702",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05275",
    "b_title":[
      "Interpretable Failure Detection with Human-Level Concepts"
    ],
    "b_abstract":[
      "Reliable failure detection holds paramount importance in safety-critical\napplications. Yet, neural networks are known to produce overconfident\npredictions for misclassified samples. As a result, it remains a problematic\nmatter as existing confidence score functions rely on category-level signals,\nthe logits, to detect failures. This research introduces an innovative\nstrategy, leveraging human-level concepts for a dual purpose: to reliably\ndetect when a model fails and to transparently interpret why. By integrating a\nnuanced array of signals for each category, our method enables a finer-grained\nassessment of the model's confidence. We present a simple yet highly effective\napproach based on the ordinal ranking of concept activation to the input image.\nWithout bells and whistles, our method significantly reduce the false positive\nrate across diverse real-world image classification benchmarks, specifically by\n3.7% on ImageNet and 9% on EuroSAT."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16793",
    "c_title":[
      "Restoring Forgotten Knowledge in Non-Exemplar Class Incremental Learning\n  through Test-Time Semantic Evolution"
    ],
    "c_abstract":[
      "Continual learning aims to accumulate knowledge over a data stream while\nmitigating catastrophic forgetting. In Non-exemplar Class Incremental Learning\n(NECIL), forgetting arises during incremental optimization because old classes\nare inaccessible, hindering the retention of prior knowledge. To solve this,\nprevious methods struggle in achieving the stability-plasticity balance in the\ntraining stages. However, we note that the testing stage is rarely considered\namong them, but is promising to be a solution to forgetting. Therefore, we\npropose RoSE, which is a simple yet effective method that\n\\textbf{R}est\\textbf{o}res forgotten knowledge through test-time\n\\textbf{S}emantic \\textbf{E}volution. Specifically designed for minimizing\nforgetting, RoSE is a test-time semantic drift compensation framework that\nenables more accurate drift estimation in a self-supervised manner. Moreover,\nto avoid incomplete optimization during online testing, we derive an analytical\nsolution as an alternative to gradient descent. We evaluate RoSE on CIFAR-100,\nTinyImageNet, and ImageNet100 datasets, under both cold-start and warm-start\nsettings. Our method consistently outperforms most state-of-the-art (SOTA)\nmethods across various scenarios, validating the potential and feasibility of\ntest-time evolution in NECIL."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-703",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15100",
    "b_title":[
      "Quark: Implementing Convolutional Neural Networks Entirely on\n  Programmable Data Plane"
    ],
    "b_abstract":[
      "The rapid development of programmable network devices and the widespread use\nof machine learning (ML) in networking have facilitated efficient research into\nintelligent data plane (IDP). Offloading ML to programmable data plane (PDP)\nenables quick analysis and responses to network traffic dynamics, and efficient\nmanagement of network links. However, PDP hardware pipeline has significant\nresource limitations. For instance, Intel Tofino ASIC has only 10Mb SRAM in\neach stage, and lacks support for multiplication, division and floating-point\noperations. These constraints significantly hinder the development of IDP. This\npaper presents \\quark, a framework that fully offloads convolutional neural\nnetwork (CNN) inference onto PDP. \\quark employs model pruning to simplify the\nCNN model, and uses quantization to support floating-point operations.\nAdditionally, \\quark divides the CNN into smaller units to improve resource\nutilization on the PDP. We have implemented a testbed prototype of \\quark on\nboth P4 hardware switch (Intel Tofino ASIC) and software switch (i.e., BMv2).\nExtensive evaluation results demonstrate that \\quark achieves 97.3\\% accuracy\nin anomaly detection task while using only 22.7\\% of the SRAM resources on the\nIntel Tofino ASIC switch, completing inference tasks at line rate with an\naverage latency of 42.66$\\mu s$."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07420",
    "c_title":[
      "The Interplay of AI-and-RAN: Dynamic Resource Allocation for Converged\n  6G Platform"
    ],
    "c_abstract":[
      "The concept of AI-RAN as specified by the AI-RAN alliance is geared to\nexplore a converged 6G platform that can support management, orchestration, and\ndeployment of both AI and RAN workloads. This concept is central to the\ndevelopment of a 6G architecture that aims to exploit the accelerated compute\ncapabilities for supporting both real-time signal processing and offloading of\nGenerative AI (GenAI) workloads. However, both the architectural framework\nrequired to support this vision and the dynamic resource allocation strategy\nare still in their infancy. The O-RAN architecture intrinsically allows\ncloud-native disaggregated implementation. Consequently, we explore a framework\nthat can allow orchestration of AI-and-RAN workloads by expanding the Near\nReal-Time RAN Intelligent Controller (NRT-RIC) within O-RAN. The framework\nincorporates a monitoring xApp that tracks RAN KPIs and exposes radio analytics\nto the proposed E2E orchestrator via a recently introduced Y1 interface. The\norchestrator implements a Soft Actor-Critic (SAC) reinforcement learning\nalgorithm to dynamically allocate critical computing resources, e.g.,\nMulti-Instance GPUs (MIGs), between latency-sensitive RAN network functions and\ncomputationally intensive AI workloads on shared RAN infrastructure. The\nproposed framework provides insight on how the traditional RAN architecture can\nbe evolved to inherently support emerging GenAI workloads. Our framework\nprioritizes the real-time requirements of RAN workloads while maintaining\nefficient resource sharing for AI applications. The simulation results\ndemonstrate the benefits of the proposed framework, as it meets nearly 99% of\nthe requests for RAN workload while effectively supporting AI workloads and\nachieving 100% utilization of the RAN infrastructure resources in a dynamic\nenvironment."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-704",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09890",
    "b_title":[
      "Symmetry-Preserving Diffusion Models via Target Symmetrization"
    ],
    "b_abstract":[
      "Diffusion models are powerful tools for capturing complex distributions, but\nmodeling data with inherent symmetries, such as molecular structures, remains\nchallenging. Equivariant denoisers are commonly used to address this, but they\nintroduce architectural complexity and optimization challenges, including noisy\ngradients and convergence issues. We propose a novel approach that enforces\nequivariance through a symmetrized loss function, which applies a\ntime-dependent weighted averaging operation over group actions to the model's\nprediction target. This ensures equivariance without explicit architectural\nconstraints and reduces gradient variance, leading to more stable and efficient\noptimization. Our method uses Monte Carlo sampling to estimate the average,\nincurring minimal computational overhead. We provide theoretical guarantees of\nequivariance for the minimizer of our loss function and demonstrate its\neffectiveness on synthetic datasets and the molecular conformation generation\ntask using the GEOM-QM9 dataset. Experiments show improved sample quality\ncompared to existing methods, highlighting the potential of our approach to\nenhance the scalability and practicality of equivariant diffusion models in\ngenerative tasks."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06145",
    "c_title":[
      "Adaptive UAV-Assisted Hierarchical Federated Learning: Optimizing\n  Energy, Latency, and Resilience for Dynamic Smart IoT"
    ],
    "c_abstract":[
      "A key application of HFL lies in smart Internet of Things (IoT) systems,\nincluding remote monitoring and battlefield operations, where cellular\nconnectivity is often unavailable. In such scenarios, UAVs can act as mobile\naggregators, dynamically providing connectivity to terrestrial IoT devices.\nSubsequently, this paper investigates an HFL architecture enabled by\nenergy-constrained, dynamically deployed UAVs that are susceptible to\ncommunication disruptions. We propose a novel approach to minimize global\ntraining costs in such environments by formulating a joint optimization problem\nthat integrates learning configuration, bandwidth allocation, and IoT\ndevice-to-UAV association, ensuring timely global aggregation before UAV\ndisconnections and redeployments. The problem explicitly captures the dynamic\nnature of IoT devices and their intermittent connectivity to UAVs and is shown\nto be NP-hard. To address its complexity, we decompose the problem into three\ninterrelated subproblems. First, we optimize learning configuration and\nbandwidth allocation using an augmented Lagrangian function to reduce training\ncosts. Second, we introduce a device fitness score that accounts for data\nheterogeneity (via Kullback-Leibler divergence), device-to-UAV proximity, and\ncomputational resources, leveraging a Twin Delayed Deep Deterministic Policy\nGradient (TD3)-based algorithm for adaptive device-to-UAV assignment. Third, we\ndevelop a low-complexity two-stage greedy strategy for UAV redeployment and\nglobal aggregator selection, ensuring efficient model aggregation despite UAV\ndisconnections."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-705",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17467",
    "b_title":[
      "Functors Associated to Relations on Hypergroups and Hypermodules"
    ],
    "b_abstract":[
      "If H is a strongly regular hypergroup, we show that the set of regular\nrelations on H and the set of subhypergroups containing $0_{H}$ are two\nlattices that are isomorphic to each other. In the next step, we introduce and\nstudy the properties of functors that are constructed by a sequence of strongly\nregular relations. This helps us to define a specific type of free objects and\ntensor products on the category of regular hypergroups."
    ],
    "b_categories":[
      [
        "math.GM"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.14872",
    "c_title":[
      "Newton-Mandelbrot set and Murase-Mandelbrot set"
    ],
    "c_abstract":[
      "We obtain four extended Newton's methods and three extended Mandelbrot's\nrecurrence formulas from the Wasan (Japanese mathematics in the Edo period\n(1603-1868)). Furthermore, two extended Newton's methods relate to one of the\nextended Mandelbrot's recurrence formulas. We lead four types of extended\nMandelbrot recurrence formulas. Next, we show that these become the same\nextended Mandelbrot set, and connected, closed set. These show the originality\nof Wasan."
    ],
    "c_categories":[
      [
        "math.GM"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-706",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10239",
    "b_title":[
      "I Can Tell Your Secrets: Inferring Privacy Attributes from Mini-app\n  Interaction History in Super-apps"
    ],
    "b_abstract":[
      "Super-apps have emerged as comprehensive platforms integrating various\nmini-apps to provide diverse services. While super-apps offer convenience and\nenriched functionality, they can introduce new privacy risks. This paper\nreveals a new privacy leakage source in super-apps: mini-app interaction\nhistory, including mini-app usage history (Mini-H) and operation history\n(Op-H). Mini-H refers to the history of mini-apps accessed by users, such as\ntheir frequency and categories. Op-H captures user interactions within\nmini-apps, including button clicks, bar drags, and image views. Super-apps can\nnaturally collect these data without instrumentation due to the web-based\nfeature of mini-apps. We identify these data types as novel and unexplored\nprivacy risks through a literature review of 30 papers and an empirical\nanalysis of 31 super-apps. We design a mini-app interaction history-oriented\ninference attack (THEFT), to exploit this new vulnerability. Using THEFT, the\ninsider threats within the low-privilege business department of the super-app\nvendor acting as the adversary can achieve more than 95.5% accuracy in\ninferring privacy attributes of over 16.1% of users. THEFT only requires a\nsmall training dataset of 200 users from public breached databases on the\nInternet. We also engage with super-app vendors and a standards association to\nincrease industry awareness and commitment to protect this data. Our\ncontributions are significant in identifying overlooked privacy risks,\ndemonstrating the effectiveness of a new attack, and influencing industry\npractices toward better privacy protection in the super-app ecosystem."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04648",
    "c_title":[
      "Toward Automated Potential Primary Asset Identification in Verilog\n  Designs"
    ],
    "c_abstract":[
      "With greater design complexity, the challenge to anticipate and mitigate\nsecurity issues provides more responsibility for the designer. As hardware\nprovides the foundation of a secure system, we need tools and techniques that\nsupport engineers to improve trust and help them address security concerns.\nKnowing the security assets in a design is fundamental to downstream security\nanalyses, such as threat modeling, weakness identification, and verification.\nThis paper proposes an automated approach for the initial identification of\npotential security assets in a Verilog design. Taking inspiration from manual\nasset identification methodologies, we analyze open-source hardware designs in\nthree IP families and identify patterns and commonalities likely to indicate\nstructural assets. Through iterative refinement, we provide a potential set of\nprimary security assets and thus help to reduce the manual search space."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-707",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17190",
    "b_title":[
      "Type semigroups for twisted groupoids and a dichotomy for groupoid\n  C*-algebras"
    ],
    "b_abstract":[
      "We develop a theory of type semigroups for arbitrary twisted, not necessarily\nHausdorff \\'etale groupoids. The type semigroup is a dynamical version of the\nCuntz semigroup. We relate it to traces, ideals, pure infiniteness, and stable\nfiniteness of the reduced and essential C*-algebras. If the reduced C*-algebra\nof a twisted groupoid is simple and the type semigroup satisfies a weak version\nof almost unperforation, then the C*-algebra is either stably finite or purely\ninfinite. We apply our theory to Cartan inclusions. We calculate the type\nsemigroup for the possibly non-Hausdorff groupoids associated to self-similar\ngroup actions on graphs and deduce a dichotomy for the resulting Exel-Pardo\nalgebras."
    ],
    "b_categories":[
      [
        "math.OA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.01975",
    "c_title":[
      "Pseudo-Cartan Inclusions"
    ],
    "c_abstract":[
      "We define a new class of regular inclusions, the pseudo-Cartan inclusions. We\nshow this class coincides with the class of regular inclusions having a Cartan\nenvelope and also with the class of regular inclusions with the faithful unique\npseudo-expectation property. We describe the twisted groupoid associated with\nthe Cartan envelope of a pseudo-Cartan inclusion. These results significantly\nextend previous results obtained for the unital setting.\n  We explore properties of pseudo-Cartan inclusions and the relationship\nbetween a pseudo-Cartan inclusion and its Cartan envelope. For example, if $D\n\\subseteq C$ is a pseudo-Cartan inclusion with Cartan envelope $B \\subseteq A$,\nthen $C$ is simple if and only if $A$ is simple. We show how to construct\npseudo-Cartan inclusions from a given Cartan inclusion, that the inductive\nlimit of pseudo-Cartan inclusions with suitable connecting maps is a\npseudo-Cartan inclusion, and the minimal tensor product of pseudo-Cartan\ninclusions is a pseudo-Cartan inclusion. Further, we describe the Cartan\nenvelope of pseudo-Cartan inclusions arising from these constructions. We give\nsome applications and conclude with a few open questions."
    ],
    "c_categories":[
      [
        "math.OA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-708",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15625",
    "b_title":[
      "EarthScape: A Multimodal Dataset for Surficial Geologic Mapping and\n  Earth Surface Analysis"
    ],
    "b_abstract":[
      "Surficial geologic mapping is essential for understanding Earth surface\nprocesses, addressing modern challenges such as climate change and national\nsecurity, and supporting common applications in engineering and resource\nmanagement. However, traditional mapping methods are labor-intensive, limiting\nspatial coverage and introducing potential biases. To address these\nlimitations, we introduce EarthScape, a novel, AI-ready multimodal dataset\nspecifically designed for surficial geologic mapping and Earth surface\nanalysis. EarthScape integrates high-resolution aerial RGB and near-infrared\n(NIR) imagery, digital elevation models (DEM), multi-scale DEM-derived terrain\nfeatures, and hydrologic and infrastructure vector data. The dataset provides\ndetailed annotations for seven distinct surficial geologic classes encompassing\nvarious geological processes. We present a comprehensive data processing\npipeline using open-sourced raw data and establish baseline benchmarks using\ndifferent spatial modalities to demonstrate the utility of EarthScape. As a\nliving dataset with a vision for expansion, EarthScape bridges the gap between\ncomputer vision and Earth sciences, offering a valuable resource for advancing\nresearch in multimodal learning, geospatial analysis, and geological mapping.\nOur code is available at https:\/\/github.com\/masseygeo\/earthscape."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03410",
    "c_title":[
      "ScaleMAI: Accelerating the Development of Trusted Datasets and AI Models"
    ],
    "c_abstract":[
      "Building trusted datasets is critical for transparent and responsible Medical\nAI (MAI) research, but creating even small, high-quality datasets can take\nyears of effort from multidisciplinary teams. This process often delays AI\nbenefits, as human-centric data creation and AI-centric model development are\ntreated as separate, sequential steps. To overcome this, we propose ScaleMAI,\nan agent of AI-integrated data curation and annotation, allowing data quality\nand AI performance to improve in a self-reinforcing cycle and reducing\ndevelopment time from years to months. We adopt pancreatic tumor detection as\nan example. First, ScaleMAI progressively creates a dataset of 25,362 CT scans,\nincluding per-voxel annotations for benign\/malignant tumors and 24 anatomical\nstructures. Second, through progressive human-in-the-loop iterations, ScaleMAI\nprovides Flagship AI Model that can approach the proficiency of expert\nannotators (30-year experience) in detecting pancreatic tumors. Flagship Model\nsignificantly outperforms models developed from smaller, fixed-quality\ndatasets, with substantial gains in tumor detection (+14%), segmentation (+5%),\nand classification (72%) on three prestigious benchmarks. In summary, ScaleMAI\ntransforms the speed, scale, and reliability of medical dataset creation,\npaving the way for a variety of impactful, data-driven applications."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-709",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12611",
    "b_title":[
      "Who Writes What: Unveiling the Impact of Author Roles on AI-generated\n  Text Detection"
    ],
    "b_abstract":[
      "The rise of Large Language Models (LLMs) necessitates accurate AI-generated\ntext detection. However, current approaches largely overlook the influence of\nauthor characteristics. We investigate how sociolinguistic attributes-gender,\nCEFR proficiency, academic field, and language environment-impact\nstate-of-the-art AI text detectors. Using the ICNALE corpus of human-authored\ntexts and parallel AI-generated texts from diverse LLMs, we conduct a rigorous\nevaluation employing multi-factor ANOVA and weighted least squares (WLS). Our\nresults reveal significant biases: CEFR proficiency and language environment\nconsistently affected detector accuracy, while gender and academic field showed\ndetector-dependent effects. These findings highlight the crucial need for\nsocially aware AI text detection to avoid unfairly penalizing specific\ndemographic groups. We offer novel empirical evidence, a robust statistical\nframework, and actionable insights for developing more equitable and reliable\ndetection systems in real-world, out-of-domain contexts. This work paves the\nway for future research on bias mitigation, inclusive evaluation benchmarks,\nand socially responsible LLM detectors."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.01341",
    "c_title":[
      "AlignVLM: Bridging Vision and Language Latent Spaces for Multimodal\n  Understanding"
    ],
    "c_abstract":[
      "Aligning visual features with language embeddings is a key challenge in\nvision-language models (VLMs). The performance of such models hinges on having\na good connector that maps visual features generated by a vision encoder to a\nshared embedding space with the LLM while preserving semantic similarity.\nExisting connectors, such as multilayer perceptrons (MLPs), often produce\nout-of-distribution or noisy inputs, leading to misalignment between the\nmodalities. In this work, we propose a novel vision-text alignment method,\nAlignVLM, that maps visual features to a weighted average of LLM text\nembeddings. Our approach leverages the linguistic priors encoded by the LLM to\nensure that visual features are mapped to regions of the space that the LLM can\neffectively interpret. AlignVLM is particularly effective for document\nunderstanding tasks, where scanned document images must be accurately mapped to\ntheir textual content. Our extensive experiments show that AlignVLM achieves\nstate-of-the-art performance compared to prior alignment methods. We provide\nfurther analysis demonstrating improved vision-text feature alignment and\nrobustness to noise."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-710",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09612",
    "b_title":[
      "Prioritizing Computing Research to Empower and Protect Vulnerable\n  Populations"
    ],
    "b_abstract":[
      "Technology can pose signicant risks to a wide array of vulnerable\npopulations. However, by addressing the challenges and opportunities in\ntechnology design, research, and deployment, we can create systems that benet\neveryone, fostering a society where even the most vulnerable are empowered and\nsupported."
    ],
    "b_categories":[
      [
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.00959",
    "c_title":[
      "IGGA: A Dataset of Industrial Guidelines and Policy Statements for\n  Generative AIs"
    ],
    "c_abstract":[
      "This paper introduces IGGA, a dataset of 160 industry guidelines and policy\nstatements for the use of Generative AIs (GAIs) and Large Language Models\n(LLMs) in industry and workplace settings, collected from official company\nwebsites, and trustworthy news sources. The dataset contains 104,565 words and\nserves as a valuable resource for natural language processing tasks commonly\napplied in requirements engineering, such as model synthesis, abstraction\nidentification, and document structure assessment. Additionally, IGGA can be\nfurther annotated to function as a benchmark for various tasks, including\nambiguity detection, requirements categorization, and the identification of\nequivalent requirements. Our methodologically rigorous approach ensured a\nthorough examination, with a selection of reputable and influential companies\nthat represent a diverse range of global institutions across six continents.\nThe dataset captures perspectives from fourteen industry sectors, including\ntechnology, finance, and both public and private institutions, offering a broad\nspectrum of insights into the integration of GAIs and LLMs in industry."
    ],
    "c_categories":[
      [
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-711",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08644",
    "b_title":[
      "Extension of indoor mmW link radio coverage in non line-of-sight\n  conditions"
    ],
    "b_abstract":[
      "In future wireless communication systems, millimeter waves (mmWaves) will\nplay an important role in meeting high data rates. However, due to their short\nwavelengths, these mmWaves present high propagation losses and are highly\nattenuated by blocking. In this chapter, we seek to increase the indoor radio\ncoverage at 60 GHz in non line-of-sight (NLOS) environments. Firstly, a\nmetallic passive reflector is used in an L-shaped corridor. Secondly, an array\nof grooved metallic antennas of size 20 cm x 20 cm (corresponding to 80\ngrooves) is used in a T-shaped corridor. Next, the study focuses on the\nblockage losses caused by the human body. The results obtained in these\ndifferent configurations show that it is possible to use beamforming to exploit\na reflected path when the direct path is blocked."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.08752",
    "c_title":[
      "Opportunities and Challenges for Virtual Reality Streaming over\n  Millimeter-Wave: An Experimental Analysis"
    ],
    "c_abstract":[
      "Achieving extremely high-quality and truly immersive interactive Virtual\nReality (VR) is expected to require a wireless link to the cloud, providing\nmulti-gigabit throughput and extremely low latency. A prime candidate for\nfulfilling these requirements is millimeter-wave (mmWave) communications,\noperating in the 30 to 300 GHz bands, rather than the traditional sub-6 GHz.\nEvaluations with first-generation mmWave Wi-Fi hardware, based on the IEEE\n802.11ad standard, have so far largely remained limited to lower-layer metrics.\nIn this work, we present the first experimental analysis of the capabilities of\nmmWave for streaming VR content, using a novel testbed capable of repeatably\ncreating blockage through mobility. Using this testbed, we show that (a) motion\nmay briefly interrupt transmission, (b) a broken line of sight may degrade\nthroughput unpredictably, and (c) TCP-based streaming frameworks need careful\ntuning to behave well over mmWave."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-712",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08608",
    "b_title":[
      "Injective envelopes for locally C*-algebras"
    ],
    "b_abstract":[
      "We introduce the notion of admissible injective envelope for a locally\nC*-algebra and show that each object in the category whose objects are unital\nFr\\'{e}chet locally C*-algebras and whose morphisms are unital admissible local\ncompletely positive maps has a unique admissible injective envelope. The\nconcept of admissible injectivity is stronger than that of injectivity. As a\nconsequence, we show that a unital Fr\\'{e}chet locally W*-algebras is injective\nif and only if the C*-algebras from its Arens-Michael decomposition are\ninjective."
    ],
    "b_categories":[
      [
        "math.OA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.01516",
    "c_title":[
      "Almost almost periodic type $\\mathrm{III}_1$ factors and their\n  3-cohomology obstructions"
    ],
    "c_abstract":[
      "We construct an exemple of a full factor $M$ such that its canonical outer\nmodular flow $\\sigma^M : \\mathbb{R} \\rightarrow \\mathrm{Out}(M)$ is almost\nperiodic but $M$ has no almost periodic state. This can only happen if the\ndiscrete spectrum of $\\sigma^M$ contains a nontrivial integral quadratic\nrelation. We show how such a nontrivial relation can produce a 3-cohomological\nobstruction to the existence of an almost periodic state. To obtain our main\ntheorem, we first strengthen a recent result of Bischoff and Karmakar by\nshowing that for any compact connected abelian group $K$, every cohomology\nclass in $ H^3(K,\\mathbb{T})$ can be realized as an obstruction of a $K$-kernel\non the hyperfinite $\\mathrm{II}_1$ factor. We also prove a positive result : if\nfor a full factor $M$ the outer modular flow $\\sigma^M : \\mathbb{R} \\rightarrow\n\\mathrm{Out}(M)$ is almost periodic, then $M \\otimes R$ has an almost periodic\nstate, where $R$ is the hyperfinite $\\mathrm{II}_1$ factor. Finally, we prove a\npositive result for crossed product factors associated to strongly ergodic\nactions of hyperbolic groups."
    ],
    "c_categories":[
      [
        "math.OA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-713",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05547",
    "b_title":[
      "Radio Frequency from Optical with Instabilities below $10^{-15}$-\n  Generation and Measurement"
    ],
    "b_abstract":[
      "This paper presents a frequency synthesis that achieves exceptional stability\nby transferring optical signals to the radio frequency (RF) domain at 100 MHz.\nWe describe and characterize two synthesis chains composed of a cryogenic\nsilicon cavity-stabilized laser at 1542 nm and an ultra-low expansion (ULE)\nglass cavity at 1157 nm, both converted to 10 GHz signals via Ti:Sapphire and\nEr\/Yb:glass optical frequency combs (OFCs). The 10 GHz microwave outputs are\nfurther divided down to 100 MHz using a commercial microwave prescaler, which\nexhibits a residual frequency instability of $\\sigma_y(1~\\text{s})<10^{-15}$\nand low $10^{-18}$ level at a few thousand seconds. Measurements are performed\nusing a newly developed custom ultra-low-noise digital measurement system and\nare compared to the carrier-suppression technique. The new system enables\nhigh-sensitivity evaluation across the entire synthesis chain, from the optical\nand microwave heterodynes as well as the direct RF signals. Results show an\nabsolute instability of $\\sigma_y(1~\\text{s})~\\approx~4.7\\times10^{-16}$ at 100\nMHz. This represents the first demonstration of such low instability at 100\nMHz, corresponding to a phase noise of -140 dBc\/Hz at a 1 Hz offset and\nsignificantly surpassing earlier systems. These advancements open new\nopportunities for precision metrology and timing systems."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.17048",
    "c_title":[
      "Alignment-Tolerant Optical Fi-Wi-Fi Bridge Assisted by a Focal Plane\n  Array Beamformer as Air Interface"
    ],
    "c_abstract":[
      "Terrestrial free-space optical (FSO) links are an ideal candidate to extend\nthe bandwidth continuum offered by fiber networks, yet at the expense of\nunfavorable cost credentials due to highly complex opto-mechanical setups. As a\nresponse to this challenge, we present a simple fiber-based focal plane array\n(FPA) architecture which contributes beamforming functionality to an FSO link\nthat bridges the gap between two single-mode fiber ports. Through use of\nspace-switched and wavelength-routed beamforming networks, which together with\na photonic lantern provide a compact arrangement of up to 61 fine-pitched\noptical antenna elements on a fiber tip, we experimentally demonstrate that our\nFPA can assist the channel optimization of an FSO link after rough initial beam\npointing. We show that favorable coupling conditions can be accomplished\nbetween two standard single-mode fibers, which enables us to successfully\nretain the fiber continuum by achieving error-free 10 Gb\/s\/{\\lambda} data\ntransmission in a space-switched out-door fiber-wireless-fiber scenario."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-714",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16256",
    "b_title":[
      "Exploiting Epistemic Uncertainty in Cold-Start Recommendation Systems"
    ],
    "b_abstract":[
      "The cold-start problem remains a significant challenge in recommendation\nsystems based on generative models. Current methods primarily focus on\nenriching embeddings or inputs by gathering more data, often overlooking the\neffectiveness of how existing training knowledge is utilized. This inefficiency\ncan lead to missed opportunities for improving cold-start recommendations. To\naddress this, we propose the use of epistemic uncertainty, which reflects a\nlack of certainty about the optimal model, as a tool to measure and enhance the\nefficiency with which a recommendation system leverages available knowledge. By\nconsidering epistemic uncertainty as a reducible component of overall\nuncertainty, we introduce a new approach to refine model performance. The\neffectiveness of this approach is validated through extensive offline\nexperiments on publicly available datasets, demonstrating its superior\nperformance and robustness in tackling the cold-start problem."
    ],
    "b_categories":[
      [
        "cs.IR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15183",
    "c_title":[
      "Generating Negative Samples for Multi-Modal Recommendation"
    ],
    "c_abstract":[
      "Multi-modal recommender systems (MMRS) have gained significant attention due\nto their ability to leverage information from various modalities to enhance\nrecommendation quality. However, existing negative sampling techniques often\nstruggle to effectively utilize the multi-modal data, leading to suboptimal\nperformance. In this paper, we identify two key challenges in negative sampling\nfor MMRS: (1) producing cohesive negative samples contrasting with positive\nsamples and (2) maintaining a balanced influence across different modalities.\nTo address these challenges, we propose NegGen, a novel framework that utilizes\nmulti-modal large language models (MLLMs) to generate balanced and contrastive\nnegative samples. We design three different prompt templates to enable NegGen\nto analyze and manipulate item attributes across multiple modalities, and then\ngenerate negative samples that introduce better supervision signals and ensure\nmodality balance. Furthermore, NegGen employs a causal learning module to\ndisentangle the effect of intervened key features and irrelevant item\nattributes, enabling fine-grained learning of user preferences. Extensive\nexperiments on real-world datasets demonstrate the superior performance of\nNegGen compared to state-of-the-art methods in both negative sampling and\nmulti-modal recommendation."
    ],
    "c_categories":[
      [
        "cs.IR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-715",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08305",
    "b_title":[
      "Benchmarking Graph Representations and Graph Neural Networks for\n  Multivariate Time Series Classification"
    ],
    "b_abstract":[
      "Multivariate Time Series Classification (MTSC) enables the analysis if\ncomplex temporal data, and thus serves as a cornerstone in various real-world\napplications, ranging from healthcare to finance. Since the relationship among\nvariables in MTS usually contain crucial cues, a large number of graph-based\nMTSC approaches have been proposed, as the graph topology and edges can\nexplicitly represent relationships among variables (channels), where not only\nvarious MTS graph representation learning strategies but also different Graph\nNeural Networks (GNNs) have been explored. Despite such progresses, there is no\ncomprehensive study that fairly benchmarks and investigates the performances of\nexisting widely-used graph representation learning strategies\/GNN classifiers\nin the application of different MTSC tasks. In this paper, we present the first\nbenchmark which systematically investigates the effectiveness of the\nwidely-used three node feature definition strategies, four edge feature\nlearning strategies and five GNN architecture, resulting in 60 different\nvariants for graph-based MTSC. These variants are developed and evaluated with\na standardized data pipeline and training\/validation\/testing strategy on 26\nwidely-used suspensor MTSC datasets. Our experiments highlight that node\nfeatures significantly influence MTSC performance, while the visualization of\nedge features illustrates why adaptive edge learning outperforms other edge\nfeature learning methods. The code of the proposed benchmark is publicly\navailable at\n\\url{https:\/\/github.com\/CVI-yangwn\/Benchmark-GNN-for-Multivariate-Time-Series-Classification}."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18847",
    "c_title":[
      "TabGLM: Tabular Graph Language Model for Learning Transferable\n  Representations Through Multi-Modal Consistency Minimization"
    ],
    "c_abstract":[
      "Handling heterogeneous data in tabular datasets poses a significant challenge\nfor deep learning models. While attention-based architectures and\nself-supervised learning have achieved notable success, their application to\ntabular data remains less effective over linear and tree based models. Although\nseveral breakthroughs have been achieved by models which transform tables into\nuni-modal transformations like image, language and graph, these models often\nunderperform in the presence of feature heterogeneity. To address this gap, we\nintroduce TabGLM (Tabular Graph Language Model), a novel multi-modal\narchitecture designed to model both structural and semantic information from a\ntable. TabGLM transforms each row of a table into a fully connected graph and\nserialized text, which are then encoded using a graph neural network (GNN) and\na text encoder, respectively. By aligning these representations through a\njoint, multi-modal, self-supervised learning objective, TabGLM leverages\ncomplementary information from both modalities, thereby enhancing feature\nlearning. TabGLM's flexible graph-text pipeline efficiently processes\nheterogeneous datasets with significantly fewer parameters over existing Deep\nLearning approaches. Evaluations across 25 benchmark datasets demonstrate\nsubstantial performance gains, with TabGLM achieving an average AUC-ROC\nimprovement of up to 5.56% over State-of-the-Art (SoTA) tabular learning\nmethods."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-716",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12303",
    "b_title":[
      "Towards Self-Improving Systematic Cognition for Next-Generation\n  Foundation MLLMs"
    ],
    "b_abstract":[
      "Despite their impressive capabilities, Multimodal Large Language Models\n(MLLMs) face challenges with fine-grained perception and complex reasoning.\nPrevalent multimodal pre-training approaches in MLLM construction focus on\nenhancing perception by training on high-quality image captions. While\nleveraging advanced MLLMs for caption generation enhances scalability, their\noutputs often lack comprehensiveness and accuracy. In this paper, we introduce\nSelf-Improving cognition (SIcog), a self-learning framework designed to\nconstruct next-generation foundation MLLMs by enhancing their systematic\ncognitive capabilities through multimodal pre-training with self-generated\ndata. Specifically, we propose Chain-of-Description (CoD), an approach that\nimproves an MLLM's systematic perception by enabling step-by-step visual\nunderstanding. CoD sequentially focuses on salient content, fine-grained\ndetails, relational attributes, and peripheral context, before generating a\ncoherent description, ensuring greater accuracy and comprehensiveness.\nAdditionally, we adopt a structured chain-of-thought (CoT) reasoning technique\nto enable MLLMs to integrate in-depth multimodal reasoning. To construct a\nnext-generation foundation MLLM with self-improved cognition, SIcog first\nequips an MLLM with systematic perception and reasoning abilities using minimal\nexternal annotations. The enhanced models then generate detailed captions and\nCoT reasoning data, which are further curated through self-consistency. This\ncurated data is ultimately used for multimodal pre-training to develop\nnext-generation foundation models. Extensive experiments on both low- and\nhigh-resolution MLLMs across diverse benchmarks demonstrate that, SIcog\nproduces next-generation foundation MLLMs with significantly improved\ncognition, achieving benchmark-leading performance compared to prevalent\npre-training approaches."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09960",
    "c_title":[
      "Discrete Prior-based Temporal-coherent Content Prediction for Blind Face\n  Video Restoration"
    ],
    "c_abstract":[
      "Blind face video restoration aims to restore high-fidelity details from\nvideos subjected to complex and unknown degradations. This task poses a\nsignificant challenge of managing temporal heterogeneity while at the same time\nmaintaining stable face attributes. In this paper, we introduce a Discrete\nPrior-based Temporal-Coherent content prediction transformer to address the\nchallenge, and our model is referred to as DP-TempCoh. Specifically, we\nincorporate a spatial-temporal-aware content prediction module to synthesize\nhigh-quality content from discrete visual priors, conditioned on degraded video\ntokens. To further enhance the temporal coherence of the predicted content, a\nmotion statistics modulation module is designed to adjust the content, based on\ndiscrete motion priors in terms of cross-frame mean and variance. As a result,\nthe statistics of the predicted content can match with that of real videos over\ntime. By performing extensive experiments, we verify the effectiveness of the\ndesign elements and demonstrate the superior performance of our DP-TempCoh in\nboth synthetically and naturally degraded video restoration."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-717",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09887",
    "b_title":[
      "The global representation fibered ring"
    ],
    "b_abstract":[
      "In this paper, we combine the concepts of the fibered Burnside ring and the\ncharacter ring, viewing them as fibered biset functors, into what we call the\nglobal representation fibered ring of a finite group. We compute all ring\nhomomorphisms from this ring to the complex numbers, determine its spectrum and\nits connected components, and identify the primitive idempotents of this ring\ntensor with $\\mathbb{Q}$ and its conductors."
    ],
    "b_categories":[
      [
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.17801",
    "c_title":[
      "A uniform construction of Chevalley normal forms for automorphic Lie\n  algebras on the Riemann sphere"
    ],
    "c_abstract":[
      "For a finite subgroup $G$ of $SU(2)$ and one of its ground forms\n$P\\in\\mathbb{C}[X,Y]$, we show that the space of invariants\n$\\mathbb{C}[X,Y,P^{-1}]^{G}_k$ of degree $k\\in2\\mathbb{Z}$ is a cyclic module\nover the algebra of invariants of degree zero. We find a generator for this\nmodule, uniformly for all finite subgroups of $SU(2)$. Then we construct a\nuniform intertwiner sending the scalar invariants to vector-valued invariants.\nWith these tools we construct all automorphic Lie algebras\n$\\mathfrak{g}[X,Y,P^{-1}]^{G}_0$ defined by a homomorphism from the symmetry\ngroup $G$ into the automorphism group of a finite dimensional Lie algebra\n$\\mathfrak g$, which factors through $SU(2)$. When the Lie algebra $\\mathfrak\ng$ is simple, we present a set of generators for the automorphic Lie algebra\nwhich is analogous to the Chevalley basis for $\\mathfrak g$. Previous\nobservations of isomorphisms between automorphic Lie algebras with distinct\nsymmetry groups $G$ are explained in terms of the Coxeter number of $\\mathfrak\ng$ and the orders appearing in $G$. Finally, we compute the structure constants\nfor automorphic Lie algebras of all exceptional Lie types."
    ],
    "c_categories":[
      [
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-718",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07071",
    "b_title":[
      "Value Compass Leaderboard: A Platform for Fundamental and Validated\n  Evaluation of LLMs Values"
    ],
    "b_abstract":[
      "As Large Language Models (LLMs) achieve remarkable breakthroughs, aligning\ntheir values with humans has become imperative for their responsible\ndevelopment and customized applications. However, there still lack evaluations\nof LLMs values that fulfill three desirable goals. (1) Value Clarification: We\nexpect to clarify the underlying values of LLMs precisely and comprehensively,\nwhile current evaluations focus narrowly on safety risks such as bias and\ntoxicity. (2) Evaluation Validity: Existing static, open-source benchmarks are\nprone to data contamination and quickly become obsolete as LLMs evolve.\nAdditionally, these discriminative evaluations uncover LLMs' knowledge about\nvalues, rather than valid assessments of LLMs' behavioral conformity to values.\n(3) Value Pluralism: The pluralistic nature of human values across individuals\nand cultures is largely ignored in measuring LLMs value alignment. To address\nthese challenges, we presents the Value Compass Leaderboard, with three\ncorrespondingly designed modules. It (i) grounds the evaluation on\nmotivationally distinct \\textit{basic values to clarify LLMs' underlying values\nfrom a holistic view; (ii) applies a \\textit{generative evolving evaluation\nframework with adaptive test items for evolving LLMs and direct value\nrecognition from behaviors in realistic scenarios; (iii) propose a metric that\nquantifies LLMs alignment with a specific value as a weighted sum over multiple\ndimensions, with weights determined by pluralistic values."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09890",
    "c_title":[
      "Exploring the Implementation of AI in Early Onset Interviews to Help\n  Mitigate Bias"
    ],
    "c_abstract":[
      "This paper investigates the application of artificial intelligence (AI) in\nearly-stage recruitment interviews in order to reduce inherent bias,\nspecifically sentiment bias. Traditional interviewers are often subject to\nseveral biases, including interviewer bias, social desirability effects, and\neven confirmation bias. In turn, this leads to non-inclusive hiring practices,\nand a less diverse workforce. This study further analyzes various AI\ninterventions that are present in the marketplace today such as multimodal\nplatforms and interactive candidate assessment tools in order to gauge the\ncurrent market usage of AI in early-stage recruitment. However, this paper aims\nto use a unique AI system that was developed to transcribe and analyze\ninterview dynamics, which emphasize skill and knowledge over emotional\nsentiments. Results indicate that AI effectively minimizes sentiment-driven\nbiases by 41.2%, suggesting its revolutionizing power in companies' recruitment\nprocesses for improved equity and efficiency."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-719",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05065",
    "b_title":[
      "Multicenter higher-derivative BPS black holes"
    ],
    "b_abstract":[
      "We consider the reduction of four-derivative heterotic supergravity on a\ntorus and construct two-charge multicenter BPS black hole solutions. In $d=5$,\nthe three-form field can be dualized to a gauge field and we correspondingly\nconstruct three-charge multicenter BPS black hole solutions to the dualized\nBergshoeff-de Roo action. This makes precise the embedding of known solutions\ninto five-dimensional $\\alpha'$-corrected STU supergravity."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05805",
    "c_title":[
      "Conformal blocks from celestial graviton amplitudes"
    ],
    "c_abstract":[
      "Four-point gluon and graviton correlators in celestial holography are\nfamously non-analytic, having distributional support. In this work, we propose\nan alternative graviton correlator that is analytic and displays several\ndesirable properties. We compute the four-point correlator involving one\ngraviton shadow operator and three graviton primary operators from the\ncelestial four-point graviton amplitudes at tree-level. We perform the\nconformal block decomposition for the shadow correlator in the compatible\nchannel. For the case when the shadow operator is conformally soft, we compute\nthe single-valued completion of the shadow correlator and perform the conformal\nblock decomposition of the single-valued shadow correlator in all channels. We\nfind an integral representation of the single-valued shadow correlator, which\nallows us to invert the shadow transform to find the single-valued celestial\ngraviton amplitude. We study various properties of the single-valued celestial\ngraviton amplitude. Interestingly, it exhibits a double copy structure in\nrelation to its counterpart gluon amplitude."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-720",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20053",
    "b_title":[
      "Efficient solution strategy to couple micromagnetic simulations with\n  ballistic transport in magnetic tunnel junctions"
    ],
    "b_abstract":[
      "We present a computationally efficient strategy that allows to simulate\nmagnetization switching driven by spin-transfer torque in magnetic tunnel\njunctions within a micromagnetic model coupled with a matrix-based\nnon-equilibrium Green's function algorithm. Exemplary simulation for a\nrealistic set of parameters are carried out and show switching times below 4 ns\nfor voltages above 300 mV or around 2*10^{10} A m^{-2} for the P to AP\n(parallel to anti-parallel) direction. For AP to P switching, a trend-reversal\nin the switching time is seen i.e. the time for magnetization reversal first\ndecreases with increasing bias voltage but then starts to rise again."
    ],
    "b_categories":[
      [
        "physics.comp-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.10588",
    "c_title":[
      "EVODMs: variational learning of PDEs for stochastic systems via\n  diffusion models with quantified epistemic uncertainty"
    ],
    "c_abstract":[
      "We present Epistemic Variational Onsager Diffusion Models (EVODMs), a machine\nlearning framework that integrates Onsager's variational principle with\ndiffusion models to enable thermodynamically consistent learning of free energy\nand dissipation potentials (and associated evolution equations) from noisy,\nstochastic data in a robust manner. By further combining the model with\nEpinets, EVODMs quantify epistemic uncertainty with minimal computational cost.\nThe framework is validated through two examples: (1) the phase transformation\nof a coiled-coil protein, modeled via a stochastic partial differential\nequation, and (2) a lattice particle process (the symmetric simple exclusion\nprocess) modeled via Kinetic Monte Carlo simulations. In both examples, we aim\nto discover the thermodynamic potentials that govern their dynamics in the\ndeterministic continuum limit. EVODMs demonstrate a superior accuracy in\nrecovering free energy and dissipation potentials from noisy data, as compared\nto traditional machine learning frameworks. Meanwhile, the epistemic\nuncertainty is quantified efficiently via Epinets and knowledge distillation.\nThis work highlights EVODMs' potential for advancing data-driven modeling of\nnon-equilibrium phenomena and uncertainty quantification for stochastic\nsystems."
    ],
    "c_categories":[
      [
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-721",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17026",
    "b_title":[
      "Modelling the Climate Change Debate in Italy through Information Supply\n  and Demand"
    ],
    "b_abstract":[
      "Climate change is one of the most critical challenges of the twenty-first\ncentury. Public understanding of climate issues and of the goals regarding the\nclimate transition is essential to translate awareness into concrete actions.\nSocial media platforms play a crucial role in disseminating information about\nclimate change and climate policy. In this context, we propose a model that\nanalyses the Supply and Demand of information to better understand information\ncirculation and information voids within the Italian climate-transition\ndiscourse. We conceptualise information supply as the production of content on\nFacebook and Instagram while leveraging Google searches to capture information\ndemand. Our findings highlight the persistence of information voids, which can\nhinder informed decision-making and collective action. Furthermore, we observe\nthat the dynamics of information supply and demand on climate-related topics\ntend to intensify in response to significant external events, shaping public\nattention and social media discourse."
    ],
    "b_categories":[
      [
        "cs.SI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05502",
    "c_title":[
      "A systemic and cybernetic perspective on causality, big data and social\n  networks in tourism"
    ],
    "c_abstract":[
      "Purpose - The purpose of this paper is to propose a mathematical model to\ndetermine invariant sets, set covering, orbits and, in particular, attractors\nin the set of tourism variables. Analysis was carried out based on an algorithm\nand applying an interpretation of chaos theory developed in the context of\nGeneral Systems Theory and Big Data. Design\/methodology\/approach - Tourism is\none of the most digitalized sectors of the economy, and social networks are an\nimportant source of data for information gathering. However, the high levels of\nredundant information on the Web and the appearance of contradictory opinions\nand facts produce undesirable effects that must be cross-checked against real\ndata. This paper sets out the causal relationships associated with tourist\nflows to enable the formulation of appropriate strategies. Findings - The\nresults can be applied to numerous cases, for example, in the analysis of\ntourist flows, these findings can be used to determine whether the behaviour of\ncertain groups affects that of other groups, as well as analysing tourist\nbehaviour in terms of the most relevant variables. Originality\/value - The\ntechnique presented here breaks with the usual treatment of the tourism topics.\nUnlike statistical analyses that merely provide information on current data,\nthe authors use orbit analysis to forecast, if attractors are found, the\nbehaviour of tourist variables in the immediate future."
    ],
    "c_categories":[
      [
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-722",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16064",
    "b_title":[
      "Single Domain Generalization with Model-aware Parametric Batch-wise\n  Mixup"
    ],
    "b_abstract":[
      "Single Domain Generalization (SDG) remains a formidable challenge in the\nfield of machine learning, particularly when models are deployed in\nenvironments that differ significantly from their training domains. In this\npaper, we propose a novel data augmentation approach, named as Model-aware\nParametric Batch-wise Mixup (MPBM), to tackle the challenge of SDG. MPBM\ndeploys adversarial queries generated with stochastic gradient Langevin\ndynamics, and produces model-aware augmenting instances with a parametric\nbatch-wise mixup generator network that is carefully designed through an\ninnovative attention mechanism. By exploiting inter-feature correlations, the\nparameterized mixup generator introduces additional versatility in combining\nfeatures across a batch of instances, thereby enhancing the capacity to\ngenerate highly adaptive and informative synthetic instances for specific\nqueries. The synthetic data produced by this adaptable generator network,\nguided by informative queries, is expected to significantly enrich the\nrepresentation space covered by the original training dataset and subsequently\nenhance the prediction model's generalizability across diverse and previously\nunseen domains. To prevent excessive deviation from the training data, we\nfurther incorporate a real-data alignment-based adversarial loss into the\nlearning process of MPBM, regularizing any tendencies toward undesirable\nexpansions. We conduct extensive experiments on several benchmark datasets. The\nempirical results demonstrate that by augmenting the training set with\ninformative synthesis data, our proposed MPBM method achieves the\nstate-of-the-art performance for single domain generalization."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17254",
    "c_title":[
      "REINFORCE Adversarial Attacks on Large Language Models: An Adaptive,\n  Distributional, and Semantic Objective"
    ],
    "c_abstract":[
      "To circumvent the alignment of large language models (LLMs), current\noptimization-based adversarial attacks usually craft adversarial prompts by\nmaximizing the likelihood of a so-called affirmative response. An affirmative\nresponse is a manually designed start of a harmful answer to an inappropriate\nrequest. While it is often easy to craft prompts that yield a substantial\nlikelihood for the affirmative response, the attacked model frequently does not\ncomplete the response in a harmful manner. Moreover, the affirmative objective\nis usually not adapted to model-specific preferences and essentially ignores\nthe fact that LLMs output a distribution over responses. If low attack success\nunder such an objective is taken as a measure of robustness, the true\nrobustness might be grossly overestimated. To alleviate these flaws, we propose\nan adaptive and semantic optimization problem over the population of responses.\nWe derive a generally applicable objective via the REINFORCE policy-gradient\nformalism and demonstrate its efficacy with the state-of-the-art jailbreak\nalgorithms Greedy Coordinate Gradient (GCG) and Projected Gradient Descent\n(PGD). For example, our objective doubles the attack success rate (ASR) on\nLlama3 and increases the ASR from 2% to 50% with circuit breaker defense."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-723",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04907",
    "b_title":[
      "Optical skyrmion lattices accelerating in free space"
    ],
    "b_abstract":[
      "Generation and propagation of optical skyrmions provide a versatile plalform\nfor topologically nontrivial optical informatics and light-matter interactions,\nbut their acceleration along curved trajectories is to be studied. In this\nstudy, we experimentally demonstrate the first accelerating skyrmion lattices\nconveyed by Airy structured light, characterized by topologically stable\nskyrmion textures with self-acceleration along parabolic trajectories. We show\nthat the skyrmion unit cell can maintain a Skyrme number $|N_\\text{sk}|>0.9$\nwithin a propagation range of $\\pm1.22\\ z_R$ upon parabolic acceleration.\nNotably, the meron structure remains $|N_\\text{sk}|$ stable within $0.5\\pm0.02$\nover a significantly extended range of $\\pm3.06\\ z_R$. Our work provides a new\npotential carrier for topologically robust information distribution, particle\nsorting and manipulation."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11581",
    "c_title":[
      "Nonlinear optical metasurfaces empowered by bound-states in the\n  continuum"
    ],
    "c_abstract":[
      "Optical bound-states in the continuum (BICs) have greatly enriched the field\nof nonlinear optics with novel ways to control and manipulate light-matter\ninteraction at the nanoscale. This has been made possible by their unique\nphysical properties, including effective confinement of light, non-trivial\ntopological features, and robustness upon the propagation of the optical field\nboth in the real and momentum space. Regarding the exploration of nonlinear\noptical response in various photonic nanostructures supporting BICs, particular\nattention has been paid to optical metasurfaces, chiefly due to their ability\nto control the light flow at subwavelength scale, design and fabrication\nflexibility, and convenient phase-matching conditions. In this review, we\noutline and discuss recent advances in metasurface-based frequency conversion\nprocesses utilizing the versatile physics of BICs, with a particular emphasis\non the main physics background pertaining to nonlinear optical phenomena and\noptics of BICs, as well as state-of-the-art functionalities enabled by\nBIC-driven nonlinear metasurfaces. These applications include harmonic\ngeneration, harmonic chiroptical effects, generation of complex quantum states,\nand broadband terahertz generation. In addition, several emerging research\nfields and the existing challenges of photonic nanodevices relying on BICs are\ndiscussed."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-724",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03204",
    "b_title":[
      "Find Matching Faces Based On Face Parameters"
    ],
    "b_abstract":[
      "This paper presents an innovative approach that enables the user to find\nmatching faces based on the user-selected face parameters. Through gradio-based\nuser interface, the users can interactively select the face parameters they\nwant in their desired partner. These user-selected face parameters are\ntransformed into a text prompt which is used by the Text-To-Image generation\nmodel to generate a realistic face image. Further, the generated image along\nwith the images downloaded from the Jeevansathi.com are processed through face\ndetection and feature extraction model, which results in high dimensional\nvector embedding of 512 dimensions. The vector embeddings generated from the\ndownloaded images are stored into vector database. Now, the similarity search\nis carried out between the vector embedding of generated image and the stored\nvector embeddings. As a result, it displays the top five similar faces based on\nthe user-selected face parameters. This contribution holds a significant\npotential to turn into a high-quality personalized face matching tool."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18783",
    "c_title":[
      "RUN: Reversible Unfolding Network for Concealed Object Segmentation"
    ],
    "c_abstract":[
      "Existing concealed object segmentation (COS) methods frequently utilize\nreversible strategies to address uncertain regions. However, these approaches\nare typically restricted to the mask domain, leaving the potential of the RGB\ndomain underexplored. To address this, we propose the Reversible Unfolding\nNetwork (RUN), which applies reversible strategies across both mask and RGB\ndomains through a theoretically grounded framework, enabling accurate\nsegmentation. RUN first formulates a novel COS model by incorporating an extra\nresidual sparsity constraint to minimize segmentation uncertainties. The\niterative optimization steps of the proposed model are then unfolded into a\nmultistage network, with each step corresponding to a stage. Each stage of RUN\nconsists of two reversible modules: the Segmentation-Oriented Foreground\nSeparation (SOFS) module and the Reconstruction-Oriented Background Extraction\n(ROBE) module. SOFS applies the reversible strategy at the mask level and\nintroduces Reversible State Space to capture non-local information. ROBE\nextends this to the RGB domain, employing a reconstruction network to address\nconflicting foreground and background regions identified as distortion-prone\nareas, which arise from their separate estimation by independent modules. As\nthe stages progress, RUN gradually facilitates reversible modeling of\nforeground and background in both the mask and RGB domains, directing the\nnetwork's attention to uncertain regions and mitigating false-positive and\nfalse-negative results. Extensive experiments demonstrate the superior\nperformance of RUN and highlight the potential of unfolding-based frameworks\nfor COS and other high-level vision tasks. We will release the code and models."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-725",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05648",
    "b_title":[
      "Physics-based machine learning framework for predicting NOx emissions\n  from compression ignition engines using on-board diagnostics data"
    ],
    "b_abstract":[
      "This work presents a physics-based machine learning framework to predict and\nanalyze oxides of nitrogen (NOx) emissions from compression-ignition\nengine-powered vehicles using on-board diagnostics (OBD) data as input.\nAccurate NOx prediction from OBD datasets is difficult because NOx formation\ninside an engine combustion chamber is governed by complex processes occurring\non timescales much shorter than the data collection rate. Thus, emissions\ngenerally cannot be predicted accurately using simple empirically derived\nphysics models. Black box models like genetic algorithms or neural networks can\nbe more accurate, but have poor interpretability. The transparent model\npresented in this paper has both high accuracy and can explain potential\nsources of high emissions. The proposed framework consists of two major steps:\na physics-based NOx prediction model combined with a novel Divergent Window\nCo-occurrence (DWC) Pattern detection algorithm to analyze operating conditions\nthat are not adequately addressed by the physics-based model. The proposed\nframework is validated for generalizability with a second vehicle OBD dataset,\na sensitivity analysis is performed, and model predictions are compared with\nthat from a deep neural network. The results show that NOx emissions\npredictions using the proposed model has around 55% better root mean square\nerror, and around 60% higher mean absolute error compared to the baseline NOx\nprediction model from previously published work. The DWC Pattern Detection\nAlgorithm identified low engine power conditions to have high statistical\nsignificance, indicating an operating regime where the model can be improved.\nThis work shows that the physics-based machine learning framework is a viable\nmethod for predicting NOx emissions from engines that do not incorporate NOx\nsensing."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.10481",
    "c_title":[
      "Chronic Diseases Prediction Using ML"
    ],
    "c_abstract":[
      "The recent increase in morbidity is primarily due to chronic diseases\nincluding Diabetes, Heart disease, Lung cancer, and brain tumours. The results\nfor patients can be improved, and the financial burden on the healthcare system\ncan be lessened, through the early detection and prevention of certain\ndisorders. In this study, we built a machine-learning model for predicting the\nexistence of numerous diseases utilising datasets from various sources,\nincluding Kaggle, Dataworld, and the UCI repository, that are relevant to each\nof the diseases we intended to predict.\n  Following the acquisition of the datasets, we used feature engineering to\nextract pertinent features from the information, after which the model was\ntrained on a training set and improved using a validation set. A test set was\nthen used to assess the correctness of the final model. We provide an\neasy-to-use interface where users may enter the parameters for the selected\nailment. Once the right model has been run, it will indicate whether the user\nhas a certain ailment and offer suggestions for how to treat or prevent it."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-726",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12707",
    "b_title":[
      "A weak Hilbert space that is a twisted HIlbert space"
    ],
    "b_abstract":[
      "We construct a weak Hilbert space that is a twisted Hilbert space."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.10162",
    "c_title":[
      "Bounded Composition Operators on Hilbert Space of Complex-Valued\n  Harmonic Functions"
    ],
    "c_abstract":[
      "In this paper, we study composition operators on Hilbert space of\ncomplex-valued harmonic functions. In particular, we explore isometries, the\ntype of self-map that generate bounded composition operator, and characterize\nthe boundedness of composition operator in terms of Poisson integral.\nFurthermore, we establish the relation between reproducing kernels and\ncomposition operators on Hilbert space of complex-valued harmonic functions."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-727",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19294",
    "b_title":[
      "The Cost of Balanced Training-Data Production in an Online Data Market"
    ],
    "b_abstract":[
      "Many ethical issues in machine learning are connected to the training data.\nOnline data markets are an important source of training data, facilitating both\nproduction and distribution. Recently, a trend has emerged of for-profit\n\"ethical\" participants in online data markets. This trend raises a fascinating\nquestion: Can online data markets sustainably and efficiently address ethical\nissues in the broader machine-learning economy?\n  In this work, we study this question in a stylized model of an online data\nmarket. We investigate the effects of intervening in the data market to achieve\nbalanced training-data production. The model reveals the crucial role of market\nconditions. In small and emerging markets, an intervention can drive the data\nproducers out of the market, so that the cost of fairness is maximal. Yet, in\nlarge and established markets, the cost of fairness can vanish (as a fraction\nof overall welfare) as the market grows.\n  Our results suggest that \"ethical\" online data markets can be economically\nfeasible under favorable market conditions, and motivate more models to\nconsider the role of data production and distribution in mediating the impacts\nof ethical interventions."
    ],
    "b_categories":[
      [
        "cs.GT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.19388",
    "c_title":[
      "Learning Contracts in Hierarchical Multi-Agent Systems"
    ],
    "c_abstract":[
      "The emergence of Machine Learning systems everywhere raises new challenges,\nsuch as dealing with interactions or competition between multiple learners. In\nthat goal, we study multi-agent sequential decision-making by considering\nprincipal-agent interactions in a tree structure. In this problem, the reward\nof a player is influenced by the actions of her children, who are all\nself-interested and non-cooperative. Our main finding is that it is possible to\nsteer all the players towards the globally optimal set of actions by simply\nallowing single-step contracts between them. A contract is established between\na principal and one of her agents: the principal actually offers the proposed\npayment if the agent picks the recommended action. The analysis poses specific\nchallenges due to the intricate interactions between the nodes of the tree.\nWithin a bandit setup, we propose algorithmic solutions for the players to end\nup being no-regret with respect to the optimal pair of actions and contracts.\nIn the long run, allowing contracts makes the players act as if they were\ncollaborating together, although they remain non-cooperative."
    ],
    "c_categories":[
      [
        "cs.GT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-728",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12544",
    "b_title":[
      "LEGOS-SLEEC: Tool for Formalizing and Analyzing Normative Requirements"
    ],
    "b_abstract":[
      "Systems interacting with humans, such as assistive robots or chatbots, are\nincreasingly integrated into our society. To prevent these systems from causing\nsocial, legal, ethical, empathetic, or cultural (SLEEC) harms, normative\nrequirements specify the permissible range of their behaviors. These\nrequirements encompass both functional and non-functional aspects and are\ndefined with respect to time. Typically, these requirements are specified by\nstakeholders from a broad range of fields, such as lawyers, ethicists, or\nphilosophers, who may lack technical expertise. Because such stakeholders often\nhave different goals, responsibilities, and objectives, ensuring that these\nrequirements are well-formed is crucial. SLEEC DSL, a domain-specific language\nresembling natural language, has been developed to formalize these requirements\nas SLEEC rules. In this paper, we present LEGOS-SLEEC, a tool designed to\nsupport interdisciplinary stakeholders in specifying normative requirements as\nSLEEC rules, and in analyzing and debugging their well-formedness. LEGOS-SLEEC\nis built using four previously published components, which have been shown to\nbe effective and usable across nine case studies. Reflecting on this\nexperience, we have significantly improved the user interface of LEGOS-SLEEC\nand its diagnostic support, and demonstrate the effectiveness of these\nimprovements using four interdisciplinary stakeholders. Showcase video URL is:\nhttps:\/\/youtu.be\/LLaBLGxSi8A"
    ],
    "b_categories":[
      [
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19423",
    "c_title":[
      "Are Large Language Models Ready for Business Integration? A Study on\n  Generative AI Adoption"
    ],
    "c_abstract":[
      "The explorations and applications of Artificial Intelligence (AI) in various\ndomains becomes increasingly vital as it continues to evolve. While much\nattention has been focused on Large Language Models (LLMs) such as ChatGPT,\nthis research examines the readiness of other LLMs such as Google Gemini\n(previously Google BARD), a conversational AI chatbot, for potential business\napplications. Gemini is an example of a Generative AI (Gen AI) that\ndemonstrates capabilities encompassing content generation, language\ntranslation, and information retrieval. This study aims to assess its efficacy\nfor text simplification in catering to the demands of modern businesses. A\ndataset of 42,654 reviews from distinct Disneyland branches was employed. The\nchatbot's API was utilised with a uniform prompt to generate simplified\nre-views. Results presented a spectrum of responses, including 75% successful\nsimplifications, 25% errors, and instances of model self-reference.\nQuantitative analysis encompassing response categorisation, error prevalence,\nand response length distribution was conducted. Furthermore, Natural Language\nProcessing (NLP) metrics were applied to gauge the quality of the generated\ncontent with the original reviews. The findings offer insights into Gen AI\nmodels performance, highlighting proficiency in simplifying re-views while\nunveiling certain limitations in coherence and consistency since only about\n7.79% of the datasets was simplified. This research contributes to the ongoing\ndiscourse on AI adoption in business contexts. The study's out-comes provide\nimplications for future development and implementation of AI-driven tools in\nbusinesses seeking to enhance content creation and communication processes. As\nAI continues to transform industries, an understanding of the readiness and\nlimitations of AI models is essential for informed decision-making, automations\nand effective integration."
    ],
    "c_categories":[
      [
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-729",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01153",
    "b_title":[
      "What is the symmetry group of a d-${\\text{P}_{\\mathrm{II}}}$ discrete\n  Painlev\\'e equation?"
    ],
    "b_abstract":[
      "The symmetry group of a (discrete) Painlev\\'e equation provides crucial\ninformation on the properties of the equation. In this paper we argue against\nthe commonly-held belief that the symmetry group of a given equation is solely\ndetermined by its surface type as given in the famous Sakai classification. We\nwill dispel this misconception on a specific example of a\nd-${\\text{P}_{\\mathrm{II}}}$ equation which corresponds to a half-translation\non the root lattice dual to its surface-type root lattice, but which becomes a\ngenuine translation on a sub-lattice thereof that corresponds to its real\nsymmetry group. The latter fact is shown in two different ways: first by a\nbrute force calculation and second through the use of normalizer theory, which\nwe believe to be an extremely useful tool for this purpose. We finish the paper\nwith the analysis of a sub-case of our main example which arises in the study\nof gap probabilities for Freud unitary ensembles, and the symmetry group of\nwhich is even further restricted due to the appearance of a nodal curve on the\nsurface on which the equation is regularized."
    ],
    "b_categories":[
      [
        "nlin.SI"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17327",
    "c_title":[
      "The Tsarev Generalized Hodograph Method and Isomonodromic Solutions of\n  Integrable Dispersive Systems"
    ],
    "c_abstract":[
      "General and particular solutions of the so called semi-Hamiltonian\nhydrodynamic type systems can be obtained by the Tsarev Generalized Hodograph\nMethod. Here we show that a natural extension of this approach applied to\ndispersive integrable systems is determined by isomonodromic deformations."
    ],
    "c_categories":[
      [
        "nlin.SI"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-730",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10481",
    "b_title":[
      "Chronic Diseases Prediction Using ML"
    ],
    "b_abstract":[
      "The recent increase in morbidity is primarily due to chronic diseases\nincluding Diabetes, Heart disease, Lung cancer, and brain tumours. The results\nfor patients can be improved, and the financial burden on the healthcare system\ncan be lessened, through the early detection and prevention of certain\ndisorders. In this study, we built a machine-learning model for predicting the\nexistence of numerous diseases utilising datasets from various sources,\nincluding Kaggle, Dataworld, and the UCI repository, that are relevant to each\nof the diseases we intended to predict.\n  Following the acquisition of the datasets, we used feature engineering to\nextract pertinent features from the information, after which the model was\ntrained on a training set and improved using a validation set. A test set was\nthen used to assess the correctness of the final model. We provide an\neasy-to-use interface where users may enter the parameters for the selected\nailment. Once the right model has been run, it will indicate whether the user\nhas a certain ailment and offer suggestions for how to treat or prevent it."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18576",
    "c_title":[
      "Token-Hungry, Yet Precise: DeepSeek R1 Highlights the Need for\n  Multi-Step Reasoning Over Speed in MATH"
    ],
    "c_abstract":[
      "This study investigates the performance of the DeepSeek R1 language model on\n30 challenging mathematical problems derived from the MATH dataset, problems\nthat previously proved unsolvable by other models under time constraints.\nUnlike prior work, this research removes time limitations to explore whether\nDeepSeek R1's architecture, known for its reliance on token-based reasoning,\ncan achieve accurate solutions through a multi-step process. The study compares\nDeepSeek R1 with four other models (gemini-1.5-flash-8b,\ngpt-4o-mini-2024-07-18, llama3.1:8b, and mistral-8b-latest) across 11\ntemperature settings. Results demonstrate that DeepSeek R1 achieves superior\naccuracy on these complex problems but generates significantly more tokens than\nother models, confirming its token-intensive approach. The findings highlight a\ntrade-off between accuracy and efficiency in mathematical problem-solving with\nlarge language models: while DeepSeek R1 excels in accuracy, its reliance on\nextensive token generation may not be optimal for applications requiring rapid\nresponses. The study underscores the importance of considering task-specific\nrequirements when selecting an LLM and emphasizes the role of temperature\nsettings in optimizing performance."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-731",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17453",
    "b_title":[
      "Feature-Based Dual Visual Feature Extraction Model for Compound\n  Multimodal Emotion Recognition"
    ],
    "b_abstract":[
      "This article presents our results for the eighth Affective Behavior Analysis\nin-the-wild (ABAW) competition.Multimodal emotion recognition (ER) has\nimportant applications in affective computing and human-computer interaction.\nHowever, in the real world, compound emotion recognition faces greater issues\nof uncertainty and modal conflicts. For the Compound Expression (CE)\nRecognition Challenge,this paper proposes a multimodal emotion recognition\nmethod that fuses the features of Vision Transformer (ViT) and Residual Network\n(ResNet). We conducted experiments on the C-EXPR-DB and MELD datasets. The\nresults show that in scenarios with complex visual and audio cues (such as\nC-EXPR-DB), the model that fuses the features of ViT and ResNet exhibits\nsuperior performance.Our code are avalible on\nhttps:\/\/github.com\/MyGitHub-ax\/8th_ABAW"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02195",
    "c_title":[
      "HyperGCT: A Dynamic Hyper-GNN-Learned Geometric Constraint for 3D\n  Registration"
    ],
    "c_abstract":[
      "Geometric constraints between feature matches are critical in 3D point cloud\nregistration problems. Existing approaches typically model unordered matches as\na consistency graph and sample consistent matches to generate hypotheses.\nHowever, explicit graph construction introduces noise, posing great challenges\nfor handcrafted geometric constraints to render consistency among matches. To\novercome this, we propose HyperGCT, a flexible dynamic Hyper-GNN-learned\ngeometric constraint that leverages high-order consistency among 3D\ncorrespondences. To our knowledge, HyperGCT is the first method that mines\nrobust geometric constraints from dynamic hypergraphs for 3D registration. By\ndynamically optimizing the hypergraph through vertex and edge feature\naggregation, HyperGCT effectively captures the correlations among\ncorrespondences, leading to accurate hypothesis generation. Extensive\nexperiments on 3DMatch, 3DLoMatch, KITTI-LC, and ETH show that HyperGCT\nachieves state-of-the-art performance. Furthermore, our method is robust to\ngraph noise, demonstrating a significant advantage in terms of generalization.\nThe code will be released."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-732",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08668",
    "b_title":[
      "SSVQ: Unleashing the Potential of Vector Quantization with\n  Sign-Splitting"
    ],
    "b_abstract":[
      "Vector Quantization (VQ) has emerged as a prominent weight compression\ntechnique, showcasing substantially lower quantization errors than uniform\nquantization across diverse models, particularly in extreme compression\nscenarios. However, its efficacy during fine-tuning is limited by the\nconstraint of the compression format, where weight vectors assigned to the same\ncodeword are restricted to updates in the same direction. Consequently, many\nquantized weights are compelled to move in directions contrary to their local\ngradient information. To mitigate this issue, we introduce a novel VQ paradigm,\nSign-Splitting VQ (SSVQ), which decouples the sign bit of weights from the\ncodebook. Our approach involves extracting the sign bits of uncompressed\nweights and performing clustering and compression on all-positive weights. We\nthen introduce latent variables for the sign bit and jointly optimize both the\nsigns and the codebook. Additionally, we implement a progressive freezing\nstrategy for the learnable sign to ensure training stability. Extensive\nexperiments on various modern models and tasks demonstrate that SSVQ achieves a\nsignificantly superior compression-accuracy trade-off compared to conventional\nVQ. Furthermore, we validate our algorithm on a hardware accelerator, showing\nthat SSVQ achieves a 3$\\times$ speedup over the 8-bit compressed model by\nreducing memory access."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17727",
    "c_title":[
      "Can Score-Based Generative Modeling Effectively Handle Medical Image\n  Classification?"
    ],
    "c_abstract":[
      "The remarkable success of deep learning in recent years has prompted\napplications in medical image classification and diagnosis tasks. While\nclassification models have demonstrated robustness in classifying simpler\ndatasets like MNIST or natural images such as ImageNet, this resilience is not\nconsistently observed in complex medical image datasets where data is more\nscarce and lacks diversity. Moreover, previous findings on natural image\ndatasets have indicated a potential trade-off between data likelihood and\nclassification accuracy. In this study, we explore the use of score-based\ngenerative models as classifiers for medical images, specifically mammographic\nimages. Our findings suggest that our proposed generative classifier model not\nonly achieves superior classification results on CBIS-DDSM, INbreast and Vin-Dr\nMammo datasets, but also introduces a novel approach to image classification in\na broader context. Our code is publicly available at\nhttps:\/\/github.com\/sushmitasarker\/sgc_for_medical_image_classification"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-733",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01355",
    "b_title":[
      "Magnetic frustration and weak Mn magnetic ordering in EuMn$_2$P$_2$"
    ],
    "b_abstract":[
      "We report on the electron spin resonance (ESR), heat capacity, magnetization,\nnuclear magnetic resonance (NMR), magnetic circular and linear dichroism (XMCD,\nXMLD), as well as the electrical resistivity of EuMn$_{2}$P$_{2}$ single\ncrystals. Antiferromagnetic order of Eu was observed in several quantities at\n$T^{\\rm Eu}_{\\rm N}\\,=\\,18\\,\\rm K$. The temperature dependencies of ESR\nlinewidth and resonance shift show, when approaching the Eu-ordered state, a\ndivergence towards $T^{\\rm Eu}_{\\rm N}$, indicating the growing importance of\nmagnetic correlations and the build-up of internal magnetic fields. An\nadditional temperature scale of $\\approx 47\\,\\rm K$ has considerable impact on\nlinewidth, resonance field and intensity. This points to the presence of weak\nMn-based ordering. The observed ESR line is interpreted as an Eu$^{2+}$\nresonance, which probes the weak magnetic background of the Mn subsystem. Such\npicture is suggested by the lineshape which keeps to be Lorentzian across the\n$47\\,\\rm K$ scale and by the ESR intensity which can be described by the same\nCurie-Weiss temperature above and below $47\\,\\rm K$. In the same temperature\nrange anomalies were observed at $48.5\\,\\rm K$ and $51\\,\\rm K$ in the heat\ncapacity data as well as a pronounced broadening of the NMR signal of the\nEuMn$_{2}$P$_{2}$ samples. In XMCD and XMLD measurements, this weak magnetic\norder could not be detected in the same temperature range which might be due to\nthe small magnetic moment, with a potential $c$-component or frustration."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.19474",
    "c_title":[
      "Band Renormalization, Quarter Metals, and Chiral Superconductivity in\n  Rhombohedral Tetralayer Graphene"
    ],
    "c_abstract":[
      "Recently, exotic superconductivity emerging from a spin-and-valley-polarized\nmetallic phase has been observed in rhombohedral tetralayer graphene. To\nexplain this finding, we study the role of electron-electron interactions in\ndetermining flavor symmetry breaking, using the Hartree Fock (HF)\napproximation, and also superconductivity driven by repulsive interactions.\nThough mean field HF correctly predicts the isospin flavors and reproduces the\nexperimental phase diagram, it overestimates the band renormalization near the\nFermi energy and suppresses superconducting instabilities. To address this, we\nintroduce a physically motivated scheme that includes internal screening in the\nHF calculation. Superconductivity arises in the spin-valley polarized phase for\na range of electric fields and electron doping. Our findings reproduce the\nexperimental observations and reveal a $p$-wave, finite-momentum, time-reversal\nsymmetry broken superconducting state, encouraging further investigation into\nexotic phases in graphene multilayers."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-734",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16255",
    "b_title":[
      "Some reducible and irreducible Brill-Noether loci"
    ],
    "b_abstract":[
      "We investigate limit linear series on chains of elliptic curves, giving a\nsimple proof of a conjecture of Farkas stating the existence of curves with a\ntheta-characteristic with a given number of sections for the expected range of\ngenera. Using the additional structure afforded by considering limit linear\nseries on chains of elliptic curves, we find examples of reducible\nBrill-Noether loci, admitting at least two components, with and without a\ntheta-characteristic respectively. This allows us to display reducible Hilbert\nschemes for $r\\ge 3$ and the largest possible value of $d$, namely $d=g-1$. We\nalso give examples of Brill-Noether loci with three components. On the positive\nside, we provide optimal bounds on the degree under which Brill-Noether loci\nare irreducible when $r=2$."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11080",
    "c_title":[
      "Boundedness of toric foliations"
    ],
    "c_abstract":[
      "We discuss boundedness of toric Fano foliations and connectedness of its\ndicritical and singular loci. Moreover, we show the set of interpolated\n$\\delta$-lcts for the toric foliations satisfies the descending chain\ncondition."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-735",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12598",
    "b_title":[
      "Characterizations of positive operators via their powers"
    ],
    "b_abstract":[
      "In this paper, we present new characterizations of normal and positive\noperators in terms of their powers. Among other things, we show that if $T^2$\nis normal, $\\mathcal{W}(T^{2k+1})$ lies on one side of a line passing through\nthe origin (possibly including some points on the line) for some\n$k\\in\\mathbb{N}$, and $\\mathrm{asc\\,}(T)= 1$ (or $\\mathrm{dsc\\,}(T)=1$), then\n$T$ must be normal. This complements the previous result due to Putnam [28].\nFurthermore, we prove that $T$ is normal (positive) if and only if\n$\\mathrm{asc\\,}(T)= 1$ and there exist coprime numbers $p,q\\geq 2$ such that\n$T^p$ and $T^q$ are normal (positive). Finally, we also show that $T$ is\npositive if and only if $T^k$ is accretive for all $k\\in\\mathbb{N}$, which\nanswers the question from [22] in the affirmative."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.04255",
    "c_title":[
      "A Constructive Approach for Building Wavelet Bases in \\(\n  L^2(\\mathbb{R}^d, \\mathbb{R}^m) \\) with Optimal Properties"
    ],
    "c_abstract":[
      "The main contribution of this paper is a constructive method for building\nseparable multivariate vector-valued wavelet bases in the general framework of\n\\( L^2(\\mathbb{R}^d, \\mathbb{R}^m) \\) for any \\( d, m \\geq 1 \\). While\nseparable wavelet bases in \\( L^2(\\mathbb{R}^d, \\mathbb{R}) \\) are\nwell-established and widely applied, the explicit construction of truly\nvector-valued wavelet bases remains an open problem, even in the simplest case\nof \\( L^2(\\mathbb{R}, \\mathbb{R}^2) \\), let alone in \\( L^2(\\mathbb{R}^2,\n\\mathbb{R}^2) \\). In practice, the conventional approach applies standard\nseparable wavelet bases of \\( L^2(\\mathbb{R}^2, \\mathbb{R}) \\) independently to\neach component of vector-valued signals in \\( L^2(\\mathbb{R}^2, \\mathbb{R}^2)\n\\). However, this approach fails to capture the intrinsic vectorial structure\nof the signals. To address this limitation, we propose a constructive approach\nwithin the vector-valued wavelet framework, providing a systematic method for\nconstructing such bases in the general case of \\( L^2(\\mathbb{R}^d,\n\\mathbb{R}^m) \\). By linking \\( m \\)-multiwavelets to vector-valued wavelets,\nour approach not only enables the systematic construction of separable\nmultivariate bases in \\( L^2(\\mathbb{R}^d, \\mathbb{R}^m) \\) that satisfy the\nvector-valued multiresolution analysis but also ensures that these bases\ninherit key structural properties, making them well-suited for practical\napplications."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-736",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16616",
    "b_title":[
      "Few-Shot Optimized Framework for Hallucination Detection in\n  Resource-Limited NLP Systems"
    ],
    "b_abstract":[
      "Hallucination detection in text generation remains an ongoing struggle for\nnatural language processing (NLP) systems, frequently resulting in unreliable\noutputs in applications such as machine translation and definition modeling.\nExisting methods struggle with data scarcity and the limitations of unlabeled\ndatasets, as highlighted by the SHROOM shared task at SemEval-2024. In this\nwork, we propose a novel framework to address these challenges, introducing\nDeepSeek Few-shot optimization to enhance weak label generation through\niterative prompt engineering. We achieved high-quality annotations that\nconsiderably enhanced the performance of downstream models by restructuring\ndata to align with instruct generative models. We further fine-tuned the\nMistral-7B-Instruct-v0.3 model on these optimized annotations, enabling it to\naccurately detect hallucinations in resource-limited settings. Combining this\nfine-tuned model with ensemble learning strategies, our approach achieved 85.5%\naccuracy on the test set, setting a new benchmark for the SHROOM task. This\nstudy demonstrates the effectiveness of data restructuring, few-shot\noptimization, and fine-tuning in building scalable and robust hallucination\ndetection frameworks for resource-constrained NLP systems."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.19316",
    "c_title":[
      "Reverse Probing: Evaluating Knowledge Transfer via Finetuned Task\n  Embeddings for Coreference Resolution"
    ],
    "c_abstract":[
      "In this work, we reimagine classical probing to evaluate knowledge transfer\nfrom simple source to more complex target tasks. Instead of probing frozen\nrepresentations from a complex source task on diverse simple target probing\ntasks (as usually done in probing), we explore the effectiveness of embeddings\nfrom multiple simple source tasks on a single target task. We select\ncoreference resolution, a linguistically complex problem requiring contextual\nunderstanding, as focus target task, and test the usefulness of embeddings from\ncomparably simpler tasks tasks such as paraphrase detection, named entity\nrecognition, and relation extraction. Through systematic experiments, we\nevaluate the impact of individual and combined task embeddings.\n  Our findings reveal that task embeddings vary significantly in utility for\ncoreference resolution, with semantic similarity tasks (e.g., paraphrase\ndetection) proving most beneficial. Additionally, representations from\nintermediate layers of fine-tuned models often outperform those from final\nlayers. Combining embeddings from multiple tasks consistently improves\nperformance, with attention-based aggregation yielding substantial gains. These\ninsights shed light on relationships between task-specific representations and\ntheir adaptability to complex downstream tasks, encouraging further exploration\nof embedding-level task transfer."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-737",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17679",
    "b_title":[
      "Protocol For An Observational Study On The Effects Of Combinations Of\n  Adverse Childhood Experiences On Adult Depression"
    ],
    "b_abstract":[
      "Adverse childhood experiences (ACEs) have been linked to a wide range of\nnegative health outcomes in adulthood. However, few studies have investigated\nwhat specific combinations of ACEs most substantially impact mental health. In\nthis article, we provide the protocol for our observational study of the\neffects of combinations of ACEs on adult depression. We use data from the 2023\nBehavioral Risk Factor Surveillance System (BRFSS) to assess these effects. We\nwill evaluate the replicability of our findings by splitting the sample into\ntwo discrete subpopulations of individuals. We employ data turnover for this\nanalysis, enabling a single team of statisticians and domain experts to\ncollaboratively evaluate the strength of evidence, and also integrating both\nqualitative and quantitative insights from exploratory data analysis. We\noutline our analysis plan using this method and conclude with a brief\ndiscussion of several specifics for our study."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02128",
    "c_title":[
      "Transfer Learning for Individualized Treatment Rules: Application to\n  Sepsis Patients Data from eICU-CRD and MIMIC-III Databases"
    ],
    "c_abstract":[
      "Modern precision medicine aims to utilize real-world data to provide the best\ntreatment for an individual patient. An individualized treatment rule (ITR)\nmaps each patient's characteristics to a recommended treatment scheme that\nmaximizes the expected outcome of the patient. A challenge precision medicine\nfaces is population heterogeneity, as studies on treatment effects are often\nconducted on source populations that differ from the populations of interest in\nterms of the distribution of patient characteristics. Our research goal is to\nexplore a transfer learning algorithm that aims to address the population\nheterogeneity problem and obtain targeted, optimal, and interpretable ITRs. The\nalgorithm incorporates a calibrated augmented inverse probability weighting\n(CAIPW) estimator for the average treatment effect (ATE) and employs value\nfunction maximization for the target population using Genetic Algorithm (GA) to\nproduce our desired ITR. To demonstrate its practical utility, we apply this\ntransfer learning algorithm to two large medical databases, Electronic\nIntensive Care Unit Collaborative Research Database (eICU-CRD) and Medical\nInformation Mart for Intensive Care III (MIMIC-III). We first identify the\nimportant covariates, treatment options, and outcomes of interest based on the\ntwo databases, and then estimate the optimal linear ITRs for patients with\nsepsis. Our research introduces and applies new techniques for data fusion to\nobtain data-driven ITRs that cater to patients' individual medical needs in a\npopulation of interest. By emphasizing generalizability and personalized\ndecision-making, this methodology extends its potential application beyond\nmedicine to fields such as marketing, technology, social sciences, and\neducation."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-738",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01048",
    "b_title":[
      "Personalize Your LLM: Fake it then Align it"
    ],
    "b_abstract":[
      "Personalizing large language models (LLMs) is essential for delivering\ntailored interactions that improve user experience. Many existing\npersonalization methods require fine-tuning LLMs for each user, rendering them\nprohibitively expensive for widespread adoption. Although retrieval-based\napproaches offer a more compute-efficient alternative, they still depend on\nlarge, high-quality datasets that are not consistently available for all users.\nTo address this challenge, we propose CHAMELEON, a scalable and efficient\npersonalization approach that uses (1) self-generated personal preference data\nand (2) representation editing to enable quick and cost-effective\npersonalization. Our experiments on various tasks, including those from the\nLaMP personalization benchmark, show that CHAMELEON efficiently adapts models\nto personal preferences, improving instruction-tuned models and outperforms two\npersonalization baselines by an average of 40% across two model architectures."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15801",
    "c_title":[
      "Disentangling Uncertainties by Learning Compressed Data Representation"
    ],
    "c_abstract":[
      "We study aleatoric and epistemic uncertainty estimation in a learned\nregressive system dynamics model. Disentangling aleatoric uncertainty (the\ninherent randomness of the system) from epistemic uncertainty (the lack of\ndata) is crucial for downstream tasks such as risk-aware control and\nreinforcement learning, efficient exploration, and robust policy transfer.\nWhile existing approaches like Gaussian Processes, Bayesian networks, and model\nensembles are widely adopted, they suffer from either high computational\ncomplexity or inaccurate uncertainty estimation. To address these limitations,\nwe propose the Compressed Data Representation Model (CDRM), a framework that\nlearns a neural network encoding of the data distribution and enables direct\nsampling from the output distribution. Our approach incorporates a novel\ninference procedure based on Langevin dynamics sampling, allowing CDRM to\npredict arbitrary output distributions rather than being constrained to a\nGaussian prior. Theoretical analysis provides the conditions where CDRM\nachieves better memory and computational complexity compared to bin-based\ncompression methods. Empirical evaluations show that CDRM demonstrates a\nsuperior capability to identify aleatoric and epistemic uncertainties\nseparately, achieving AUROCs of 0.8876 and 0.9981 on a single test set\ncontaining a mixture of both uncertainties. Qualitative results further show\nthat CDRM's capability extends to datasets with multimodal output\ndistributions, a challenging scenario where existing methods consistently fail.\nCode and supplementary materials are available at\nhttps:\/\/github.com\/ryeii\/CDRM."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-739",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16920",
    "b_title":[
      "SS-MPC: A Sequence-Structured Multi-Party Conversation System"
    ],
    "b_abstract":[
      "Recent Multi-Party Conversation (MPC) models typically rely on graph-based\napproaches to capture dialogue structures. However, these methods have\nlimitations, such as information loss during the projection of utterances into\nstructural embeddings and constraints in leveraging pre-trained language models\ndirectly. In this paper, we propose \\textbf{SS-MPC}, a response generation\nmodel for MPC that eliminates the need for explicit graph structures. Unlike\nexisting models that depend on graphs to analyze conversation structures,\nSS-MPC internally encodes the dialogue structure as a sequential input,\nenabling direct utilization of pre-trained language models. Experimental\nresults show that \\textbf{SS-MPC} achieves \\textbf{15.60\\% BLEU-1} and\n\\textbf{12.44\\% ROUGE-L} score, outperforming the current state-of-the-art MPC\nresponse generation model by \\textbf{3.91\\%p} in \\textbf{BLEU-1} and\n\\textbf{0.62\\%p} in \\textbf{ROUGE-L}. Additionally, human evaluation confirms\nthat SS-MPC generates more fluent and accurate responses compared to existing\nMPC models."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19361",
    "c_title":[
      "Can Large Language Models Detect Errors in Long Chain-of-Thought\n  Reasoning?"
    ],
    "c_abstract":[
      "Recently, o1-like models have drawn significant attention, where these models\nproduce the long Chain-of-Thought (CoT) reasoning steps to improve the\nreasoning abilities of existing Large Language Models (LLMs). In this paper, to\nunderstand the qualities of these long CoTs and measure the critique abilities\nof existing LLMs on these long CoTs, we introduce the DeltaBench, including the\ngenerated long CoTs from different o1-like models (e.g., QwQ, DeepSeek-R1) for\ndifferent reasoning tasks (e.g., Math, Code, General Reasoning), to measure the\nability to detect errors in long CoT reasoning. Based on DeltaBench, we first\nperform fine-grained analysis of the generated long CoTs to discover the\neffectiveness and efficiency of different o1-like models. Then, we conduct\nextensive evaluations of existing process reward models (PRMs) and critic\nmodels to detect the errors of each annotated process, which aims to\ninvestigate the boundaries and limitations of existing PRMs and critic models.\nFinally, we hope that DeltaBench could guide developers to better understand\nthe long CoT reasoning abilities of their models."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-740",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02557",
    "b_title":[
      "Coalgebras, bialgebras and Rota-Baxter algebras from shuffles of rooted\n  forests"
    ],
    "b_abstract":[
      "We construct and study new generalisations to rooted trees and forests of\nsome properties of shuffles of words. First, we build a coproduct on rooted\ntrees which, together with their shuffle, endow them with bialgebra structure.\nWe then caracterize the coproduct dual to the shuffle product of rooted forests\nand build a product on rooted trees to obtain the bialgebra dual to the shuffle\nbialgebra. We then characterize and enumerate primitive trees for the dual\ncoproduct. Finally, using modified shuffles of rooted forests, we prove a\nproperty in the category of Rota-Baxter algebras."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.13781",
    "c_title":[
      "Hermitian adjacency matrices with at most three distinct eigenvalues"
    ],
    "c_abstract":[
      "We study oriented graphs whose Hermitian adjacency matrices of the second\nkind have few eigenvalues. We give a complete characterization of the oriented\ngraphs with two distinct eigenvalues, showing that there are only four such\ngraphs. We show that there are infinitely many regular tournaments with three\ndistinct eigenvalues. We extend our main results to Hermitian adjacency\nmatrices defined over other roots of unity."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-741",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11840",
    "b_title":[
      "Large Language Models with Human-In-The-Loop Validation for Systematic\n  Review Data Extraction"
    ],
    "b_abstract":[
      "Systematic reviews are time-consuming endeavors. Historically speaking,\nknowledgeable humans have had to screen and extract data from studies before it\ncan be analyzed. However, large language models (LLMs) hold promise to greatly\naccelerate this process. After a pilot study which showed great promise, we\ninvestigated the use of freely available LLMs for extracting data for\nsystematic reviews. Using three different LLMs, we extracted 24 types of data,\n9 explicitly stated variables and 15 derived categorical variables, from 112\nstudies that were included in a published scoping review. Overall we found that\nGemini 1.5 Flash, Gemini 1.5 Pro, and Mistral Large 2 performed reasonably\nwell, with 71.17%, 72.14%, and 62.43% of data extracted being consistent with\nhuman coding, respectively. While promising, these results highlight the dire\nneed for a human-in-the-loop (HIL) process for AI-assisted data extraction. As\na result, we present a free, open-source program we developed (AIDE) to\nfacilitate user-friendly, HIL data extraction with LLMs."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05324",
    "c_title":[
      "Atlas of AI Risks: Enhancing Public Understanding of AI Risks"
    ],
    "c_abstract":[
      "The prevailing methodologies for visualizing AI risks have focused on\ntechnical issues such as data biases and model inaccuracies, often overlooking\nbroader societal risks like job loss and surveillance. Moreover, these\nvisualizations are typically designed for tech-savvy individuals, neglecting\nthose with limited technical skills. To address these challenges, we propose\nthe Atlas of AI Risks-a narrative-style tool designed to map the broad risks\nassociated with various AI technologies in a way that is understandable to\nnon-technical individuals as well. To both develop and evaluate this tool, we\nconducted two crowdsourcing studies. The first, involving 40 participants,\nidentified the design requirements for visualizing AI risks for decision-making\nand guided the development of the Atlas. The second study, with 140\nparticipants reflecting the US population in terms of age, sex, and ethnicity,\nassessed the usability and aesthetics of the Atlas to ensure it met those\nrequirements. Using facial recognition technology as a case study, we found\nthat the Atlas is more user-friendly than a baseline visualization, with a more\nclassic and expressive aesthetic, and is more effective in presenting a\nbalanced assessment of the risks and benefits of facial recognition. Finally,\nwe discuss how our design choices make the Atlas adaptable for broader use,\nallowing it to generalize across the diverse range of technology applications\nrepresented in a database that reports various AI incidents."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-742",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03415",
    "b_title":[
      "The Jordan decomposition and Kaplansky's second test problem for\n  Hermitian holomorphic vector bundles"
    ],
    "b_abstract":[
      "In 1954, I. Kaplansky proposed three test problems for deciding the strength\nof structural understanding of a class of mathematical objects in his treatise\n\"Infinite abelian groups\", which can be formulated for very general\nmathematical systems. In this paper, we focus on Kaplansky's second test\nproblem in a context of complex geometry. Let $H^2_{\\beta}$ be a weighted Hardy\nspace. The Cowen-Douglas operator theory tells us that each\n$h\\in\\textrm{Hol}(\\overline{\\mathbb{D}})$ induces a Hermitian holomorphic\nvector bundle on $H^2_{\\beta}$, denoted by $E_{h(S_\\beta)}(\\Omega)$, where\n$\\Omega$ is a domain. We show that the vector bundle $E_{h(S_\\beta)}$ is a\npush-forwards Hermitian holomorphic vector bundle and study the similarity\ndeformation problems. Our main theorem is that if $H^2_{\\beta}$ is a weighted\nHardy space of polynomial growth, then for any $f\\in\n\\textrm{Hol}(\\overline{\\mathbb{D}})$, there exists a unique positive integer\n$m$ and an function $h\\in\\textrm{Hol}(\\overline{\\mathbb{D}})$ inducing an\nindecomposable vector bundle $E_{h(S_{\\beta})}$, such that $E_{f(S_\\beta)}$ is\nsimilar to $\\bigoplus_1^m E_{h(S_\\beta)}$, where $h$ is unique in the sense of\nanalytic automorphism group action. That could be seemed as a Jordan\ndecomposition theorem for the push-forwards Hermitian holomorphic vector\nbundles. Furthermore, we give the similarity classification of those\npush-forwards Hermitian holomorphic vector bundles induced by analytic\nfunctions, and give an affirmative answer to Kaplansky's second test problem\nfor those objects. We also give an affirmative answer to the geometric version\nand generalized version of a problem proposed by R. Douglas in 2007, and obtain\nthe $K_0$-group of the commutant algebra of a multiplication operator on a\nweighted Hardy space of polynomial growth. In addition, we give an example to\nshow the setting of polynomial growth condition is necessary."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.05610",
    "c_title":[
      "Minimal Spacing of Eigenvalues on Fractals"
    ],
    "c_abstract":[
      "On the unit interval (I), and the Sierpinski Gasket ($\\mathcal{SG}$), the\nspectral decimation function of the Laplacian has similar properties that\nresult in positive minimum spacing of eigenvalues. Other fractals, for example\nthe level-3 Sierpinski Gasket, $\\mathcal{SG}_3$, may not necessarily enjoy\nthese properties. Our goal is to obtain an easy and sufficient criterion for\npositive infimum spacing of eigenvalues in the spectrum based on the properties\nof the spectral decimation function for the appropriate fractal. We also give a\nsufficient condition for zero infimum spacing of eigenvalues."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-743",
    "date":"",
    "fields":[
      "Economics and Quantitative Finance"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11164",
    "b_title":[
      "A statistical technique for cleaning option price data"
    ],
    "b_abstract":[
      "Recorded option pricing datasets are not always freely available.\nAdditionally, these datasets often contain numerous prices which are either\nhigher or lower than can reasonably be expected. Various reasons for these\nunexpected observations are possible, including human error in the recording of\nthe details associated with the option in question. In order for the analyses\nperformed on these datasets to be reliable, it is necessary to identify and\nremove these options from the dataset. In this paper, we list three distinct\nproblems often found in recorded option price datasets alongside means of\naddressing these. The methods used are justified using sound statistical\nreasoning and remove option prices violating the standard assumption of no\narbitrage. An attractive aspect of the proposed technique is that no option\npricing model-based assumptions are used. Although the discussion is restricted\nto European options, the procedure is easily modified for use with exotic\noptions as well. As a final contribution, the paper contains a link to six\noption pricing datasets which have already been cleaned using the proposed\nmethods and can be freely used by researchers."
    ],
    "b_categories":[
      [
        "q-fin.CP"
      ]
    ],
    "b_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "c_id":"2503.14646",
    "c_title":[
      "Determining a credit transition matrix from cumulative default\n  probabilities"
    ],
    "c_abstract":[
      "To quantify the changes in the credit rating of a bond is an important\nmathematical problem for the credit rating industry. To think of the credit\nrating as the state a Markov chain is an interesting proposal leading to\nchallenges in mathematical modeling. Since cumulative default rates are more\nreadily measurable than credit migrations, a natural question is whether the\ncredit transition matrix (CTM) can be determined from the knowledge of the\ncumulative default probabilities.\n  Here we use a connection between the CTM and the cumulative default\nprobabilities to setup an ill-posed, linear inverse problem with box\nconstraints, which we solve by an entropy minimization procedure. This approach\nis interesting on several counts. On the one hand, we may have less data that\nunknowns, and on the other hand, even when we have as much data as unknowns,\nthe matrix connecting them may not be invertible, which makes the problem\nill-posed.\n  Besides developing the tools to solve the problem, we apply it to several\ntest cases to check the performance of the method. The results are quite\nsatisfactory."
    ],
    "c_categories":[
      [
        "q-fin.CP"
      ]
    ],
    "c_fields":[
      [
        "Economics and Quantitative Finance"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-744",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03003",
    "b_title":[
      "Non-uniqueness of the shockwave dynamics in effective loop quantum\n  gravity"
    ],
    "b_abstract":[
      "Spherically symmetric effective dust collapse inspired by effective loop\nquantum cosmology predicts a bounce when the stellar energy density becomes\nplanckian, which in turn inevitably leads to shell-crossing singularity\nformation. An extension of the spacetime beyond such singularities is possible\nthrough weak solutions of the equations of motion in integral form, leading to\nthe shockwave model. In this work, we show explicitly that such an extension is\nnot unique, and that relevant features like the black hole life-time strongly\ndepend on the choice of the integral form of the equation of motion."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.15846",
    "c_title":[
      "Revisiting black holes surrounded by cloud and fluid of strings in\n  general relativity"
    ],
    "c_abstract":[
      "This paper revisits black hole solutions surrounded by clouds and fluids of\nstrings within the framework of general relativity. We introduce a generalized\nequation of state for a fluid of strings with a variable parameter and derive a\ngeneral solution to Einstein field equations for this system. We allow the\nparameter $\\alpha$ in the equation of state for a fluid of strings ($\\rho\/p =\n\\alpha$) to vary as a function of the radial coordinate. A particular solution\nwith $M=0$ is explored, focusing on positive ranges of the equation of state\nparameter in analogy with the reduced Kiselev solution. Furthermore, we present\na novel regular black hole solution that reduces to the Schwarzschild solution\nwith a cloud of strings when the radial coordinate is much larger than a\ncontrol parameter $r_0$. As an additional contribution of this work, we show\nthat the energy-momentum tensor for the fluid of strings can be decomposed into\ncontributions from three components: an isotropic perfect fluid, an\nelectromagnetic field, and a scalar field minimally coupled. The paper examines\nthe connection between the fluid of strings and Kiselev anisotropic fluid,\nrevealing structural similarities through their energy-momentum tensors. The\nstudy also highlights how the obtained solutions influence the horizons and\nthermodynamic properties of black holes. The new solutions allow for the\nemergence of geometries with multiple horizons and non-trivial temperature\nbehaviors. As an additional test of the general solution, it is shown that\nparticular choices for the function $\\alpha(r)$ reproduce well-known results in\nthe literature. Finally, we study geodesic motion of particles, geodesic\ncompleteness and shadows in the geometry of the novel regular black hole."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-745",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04089",
    "b_title":[
      "Streams, Shells, and Substructures in the Accretion-Built Stellar Halo\n  of NGC 300"
    ],
    "b_abstract":[
      "We present deep optical observations of the stellar halo of NGC 300, an\nLMC-mass galaxy, acquired with the DEEP sub-component of the DECam Local Volume\nExploration survey (DELVE) using the 4 m Blanco Telescope. Our resolved star\nanalysis reveals a large, low surface brightness stellar stream\n($M_{V}\\sim-8.5$; [Fe\/H] $= -1.4\\pm0.15$) extending more than 40 kpc north from\nthe galaxy's center. We also find other halo structures, including potentially\nan additional stream wrap to the south, which may be associated with the main\nstream. The morphology and derived low metallicities of the streams and shells\ndiscovered surrounding NGC 300 are highly suggestive of a past accretion event.\nAssuming a single progenitor, the accreted system is approximately Fornax-like\nin luminosity, with an inferred mass ratio to NGC 300 of approximately $1:15$.\nWe also present the discovery of a metal-poor globular cluster\n($R_{\\rm{proj}}=23.3$~kpc; $M_{V}=-8.99\\pm0.16$; [Fe\/H] $\\approx-1.6\\pm0.6$) in\nthe halo of NGC 300, the furthest identified globular cluster associated with\nNGC 300. The stellar structures around NGC 300 represent the richest features\nobserved in a Magellanic Cloud analog to date, strongly supporting the idea\nthat accretion and subsequent disruption is an important mechanism in the\nassembly of dwarf galaxy stellar halos."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.14368",
    "c_title":[
      "The Distance to the Magellanic Stream: Constraints from Optical\n  Absorption along Stellar Sightlines"
    ],
    "c_abstract":[
      "The Magellanic Stream (MS) is a large tail of neutral and ionized gas\noriginating from tidal and hydrodynamical interactions between the Magellanic\nClouds as they orbit the Milky Way (MW). It carries a significant gas reservoir\nthat could impact the future evolution of the MW. Despite its importance, no\ndirect observational constraints on the Stream's distance have been previously\npublished. In this study, we analyze Very Large Telescope\/Ultraviolet and\nVisual Echelle Spectrograph (VLT\/UVES) spectra of five blue horizontal branch\n(BHB) stars in the MW halo located at distances ranging from 13 to 56 kpc near\ntwo regions of the Stream, with the aim of detecting Ca II and Na I absorption.\nNo Ca II or Na I absorption is detected at Stream velocities in any of the\nindividual spectra, or in higher signal-to-noise stacks of the spectra. The\nresulting limits on the Ca II absorption are significantly lower than the Ca II\ncolumns measured in the Stream along extragalactic directions. These\nnon-detections establish a firm lower distance limit of 20 kpc for the two\nregions of the Stream studied. Ca II non-detections in the most distant stars\nyield tentative lower distance limits of 42 kpc and 55 kpc for the two regions,\nbut deeper spectra are needed to confirm this. Our results provide the first\nobservational constraints on the gaseous Stream's distance."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-746",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10525",
    "b_title":[
      "Efficient Precoding in XL-MIMO-AFDM System"
    ],
    "b_abstract":[
      "This paper explores the potential of affine frequency division multiplexing\n(AFDM) to mitigate the multiuser interference (MUI) problem by employing\ntime-domain precoding in extremely-large-scale multiple-input multiple-output\n(XL-MIMO) systems. In XL-MIMO systems, user mobility significantly improves\nnetwork capacity and transmission quality. Meanwhile, the robustness of AFDM to\nDoppler shift is enhanced in user mobility scenarios, which further improves\nthe system performance. However, the multicarrier nature of AFDM has attracted\nmuch attention, and it leads to a significant increase in precoding complexity.\nHowever, the serious problem is that the multicarrier use of AFDM leads to a\nsharp increase in precoding complexity. Therefore, we employ efficient\nprecoding randomized Kaczmarz (rKA) to reduce the complexity overhead. Through\nsimulation analysis, we compare the performance of XL-MIMO-AFDM and XL-MIMO\northogonal frequency division multiplexing (XL-MIMO-OFDM) in mobile scenarios,\nand the results show that our proposed AFDM-based XL-MIMO precoding design can\nbe more efficient."
    ],
    "b_categories":[
      [
        "cs.DC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15921",
    "c_title":[
      "SPIN: Accelerating Large Language Model Inference with Heterogeneous\n  Speculative Models"
    ],
    "c_abstract":[
      "Speculative decoding has been shown as an effective way to accelerate Large\nLanguage Model (LLM) inference by using a Small Speculative Model (SSM) to\ngenerate candidate tokens in a so-called speculation phase, which are\nsubsequently verified by the LLM in a verification phase. However, current\nstate-of-the-art speculative decoding approaches have three key limitations:\nhandling requests with varying difficulty using homogeneous SSMs, lack of\nrobust support for batch processing, and insufficient holistic optimization for\nboth speculation and verification phases. In this paper, we introduce SPIN, an\nefficient LLM inference serving system based on speculative decoding, designed\nto address these challenges through three main innovations. First, SPIN\nimproves token speculation by using multiple heterogeneous SSMs, with a\nlearning-based algorithm for SSM selection that operates without prior\nknowledge of request difficulty. Second, SPIN employs a request decomposition\nmethod to minimize batching overhead during LLM verification. Finally, SPIN\norchestrates speculation and verification phases by pipelining their executions\non GPUs to achieve further acceleration. Experimental results demonstrate that\nSPIN significantly outperforms state-of-the-art methods, achieving a\nperformance increase of approximately 2.28X."
    ],
    "c_categories":[
      [
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-747",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14760",
    "b_title":[
      "Validation of Human Pose Estimation and Human Mesh Recovery for\n  Extracting Clinically Relevant Motion Data from Videos"
    ],
    "b_abstract":[
      "This work aims to discuss the current landscape of kinematic analysis tools,\nranging from the state-of-the-art in sports biomechanics such as inertial\nmeasurement units (IMUs) and retroreflective marker-based optical motion\ncapture (MoCap) to more novel approaches from the field of computing such as\nhuman pose estimation and human mesh recovery. Primarily, this comparative\nanalysis aims to validate the use of marker-less MoCap techniques in a clinical\nsetting by showing that these marker-less techniques are within a reasonable\nrange for kinematics analysis compared to the more cumbersome and less portable\nstate-of-the-art tools. Not only does marker-less motion capture using human\npose estimation produce results in-line with the results of both the IMU and\nMoCap kinematics but also benefits from a reduced set-up time and reduced\npractical knowledge and expertise to set up. Overall, while there is still room\nfor improvement when it comes to the quality of the data produced, we believe\nthat this compromise is within the room of error that these low-speed actions\nthat are used in small clinical tests."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06352",
    "c_title":[
      "LANTERN++: Enhanced Relaxed Speculative Decoding with Static Tree\n  Drafting for Visual Auto-regressive Models"
    ],
    "c_abstract":[
      "Speculative decoding has been widely used to accelerate autoregressive (AR)\ntext generation. However, its effectiveness in visual AR models remains limited\ndue to token selection ambiguity, where multiple tokens receive similarly low\nprobabilities, reducing acceptance rates. While dynamic tree drafting has been\nproposed to improve speculative decoding, we show that it fails to mitigate\ntoken selection ambiguity, resulting in shallow draft trees and suboptimal\nacceleration. To address this, we introduce LANTERN++, a novel framework that\nintegrates static tree drafting with a relaxed acceptance condition, allowing\ndrafts to be selected independently of low-confidence predictions. This enables\ndeeper accepted sequences, improving decoding efficiency while preserving image\nquality. Extensive experiments on state-of-the-art visual AR models demonstrate\nthat LANTERN++ significantly accelerates inference, achieving up to\n$\\mathbf{\\times 2.56}$ speedup over standard AR decoding while maintaining high\nimage quality."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-748",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04381",
    "b_title":[
      "Data fusion of complementary data sources using Machine Learning enables\n  higher accuracy Solar Resource Maps"
    ],
    "b_abstract":[
      "In the present work, we collect solar irradiance and atmospheric condition\ndata from several products, obtained from both numerical models (ERA5 and\nNORA3) and satellite observations (CMSAF-SARAH3). We then train simple\nsupervised Machine Learning (ML) data fusion models, using these products as\npredictors and direct in-situ Global Horizontal Irradiance (GHI) measurements\nover Norway as ground-truth. We show that combining these products by applying\nour trained ML models provides a GHI estimate that is significantly more\naccurate than that obtained from any product taken individually. Using the\ntrained models, we generate a 30-year ML-corrected map of GHI over Norway,\nwhich we release as a new open data product. Our ML-based data fusion\nmethodology could be applied, after suitable training and input data selection,\nto any geographic area on Earth."
    ],
    "b_categories":[
      [
        "physics.ao-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.00276",
    "c_title":[
      "Chinese Historical Documents Reveal Multi-Century Seasonal Shifts in\n  Tropical Cyclone Landfalls"
    ],
    "c_abstract":[
      "Paleoclimate records reveal a fuller range of natural climate variability\nthan modern records and are essential for better understanding the modern\nclimate change. However, most paleoclimate records are point-based proxies and\nlack the temporal resolution needed to analyze spatiotemporal changes in\ndestructive extremes like tropical cyclones (TCs). Here we show that historical\nrecords by pre-industrial Chinese intellectuals help investigate long-term\nvariability of TC landfalls in East Asia. Despite inherent limitations, these\nrecords show a landfalling TC climatology resembling modern observations in\nspatial-temporal distributions. Comparisons between the pre-industrial records\n(1776-1850), modern observations (1946-2020), and climate simulations reveal an\nearlier seasonal occurrence of modern TCs. However, the variations of\nseasonally aggregated landfall time show pronounced multi-century variations.\nThe modern changes and multi-decade trends appear moderate compared to\nlong-term variability in pre-industrial TC records, suggesting that an\noverreliance on modern data may lead to an underestimation of the full range of\nTC activity potentially arising from natural variability alone. Analyses of\nnewly available climate data reveal associations between past landfalling TC\nactivity and the large-scale climate variability of tropical ocean and\nextratropical land. These findings demonstrate the value of paleoclimate data\nfor exploring natural variability in TC activity and inform the development of\neffective adaptation strategies for future climate change."
    ],
    "c_categories":[
      [
        "physics.ao-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-749",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06738",
    "b_title":[
      "Resurrecting saturated LLM benchmarks with adversarial encoding"
    ],
    "b_abstract":[
      "Recent work showed that small changes in benchmark questions can reduce LLMs'\nreasoning and recall. We explore two such changes: pairing questions and adding\nmore answer options, on three benchmarks: WMDP-bio, GPQA, and MMLU variants. We\nfind that for more capable models, these predictably reduce performance,\nessentially heightening the performance ceiling of a benchmark and unsaturating\nit again. We suggest this approach can resurrect old benchmarks."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10347",
    "c_title":[
      "ColNet: Collaborative Optimization in Decentralized Federated Multi-task\n  Learning Systems"
    ],
    "c_abstract":[
      "The integration of Federated Learning (FL) and Multi-Task Learning (MTL) has\nbeen explored to address client heterogeneity, with Federated Multi-Task\nLearning (FMTL) treating each client as a distinct task. However, most existing\nresearch focuses on data heterogeneity (e.g., addressing non-IID data) rather\nthan task heterogeneity, where clients solve fundamentally different tasks.\nAdditionally, much of the work relies on centralized settings with a server\nmanaging the federation, leaving the more challenging domain of decentralized\nFMTL largely unexplored. Thus, this work bridges this gap by proposing ColNet,\na framework designed for heterogeneous tasks in decentralized federated\nenvironments. ColNet divides models into the backbone and task-specific layers,\nforming groups of similar clients, with group leaders performing\nconflict-averse cross-group aggregation. A pool of experiments with different\nfederations demonstrated ColNet outperforms the compared aggregation schemes in\ndecentralized settings with label and task heterogeneity scenarios."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-750",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15300",
    "b_title":[
      "Modified Dai-Liao Spectral Conjugate Gradient Method with Application to\n  Signal Processing"
    ],
    "b_abstract":[
      "In this article, we present a modified variant of the Dai-Liao spectral\nconjugate gradient method, developed through an analysis of eigenvalues and\ninspired by a modified secant condition. We show that the proposed method is\nglobally convergent for general nonlinear functions under standard assumptions.\nBy incorporating the new secant condition and a quasi-Newton direction, we\nintroduce updated spectral parameters. These changes ensure that the resulting\nsearch direction satisfies the sufficient descent property without relying on\nany line search. Numerical experiments show that the proposed algorithm\nperforms better than several existing methods in terms of convergence speed and\ncomputational efficiency. Its effectiveness is further demonstrated through an\napplication in signal processing."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.19310",
    "c_title":[
      "How to project onto SL($n$)"
    ],
    "c_abstract":[
      "We consider the closest-point projection with respect to the Frobenius norm\nof a general real square matrix to the set SL($n$) of matrices with unit\ndeterminant. As it turns out, it is sufficient to consider diagonal matrices\nonly. We investigate the structure of the problem both in Euclidean coordinates\nand in an $n$-dimensional generalization of the classical hyperbolic\ncoordinates of the positive quadrant. Using symmetry arguments we show that the\nglobal minimizer is contained in a particular cone. Based on different views of\nthe problem, we propose four different iterative algorithms, and we give\nconvergence results for all of them. Numerical tests show that computing the\nprojection costs essentially as much as a singular value decomposition.\nFinally, we give an explicit formula for the first derivative of the\nprojection."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-751",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06973",
    "b_title":[
      "Indoor Light and Heat Estimation from a Single Panorama"
    ],
    "b_abstract":[
      "This paper presents a novel application for directly estimating indoor light\nand heat maps from captured indoor-outdoor High Dynamic Range (HDR) panoramas.\nIn our image-based rendering method, the indoor panorama is used to estimate\nthe 3D room layout, while the corresponding outdoor panorama serves as an\nenvironment map to infer spatially-varying light and material properties. We\nestablish a connection between indoor light transport and heat transport and\nimplement transient heat simulation to generate indoor heat panoramas. The\nsensitivity analysis of various thermal parameters is conducted, and the\nresulting heat maps are compared with the images captured by the thermal camera\nin real-world scenarios. This digital application enables automatic indoor\nlight and heat estimation without manual inputs and cumbersome field\nmeasurements."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10049",
    "c_title":[
      "Enhancing Multi-Agent Systems via Reinforcement Learning with LLM-based\n  Planner and Graph-based Policy"
    ],
    "c_abstract":[
      "Multi-agent systems (MAS) have shown great potential in executing complex\ntasks, but coordination and safety remain significant challenges. Multi-Agent\nReinforcement Learning (MARL) offers a promising framework for agent\ncollaboration, but it faces difficulties in handling complex tasks and\ndesigning reward functions. The introduction of Large Language Models (LLMs)\nhas brought stronger reasoning and cognitive abilities to MAS, but existing\nLLM-based systems struggle to respond quickly and accurately in dynamic\nenvironments. To address these challenges, we propose LLM-based Graph\nCollaboration MARL (LGC-MARL), a framework that efficiently combines LLMs and\nMARL. This framework decomposes complex tasks into executable subtasks and\nachieves efficient collaboration among multiple agents through graph-based\ncoordination. Specifically, LGC-MARL consists of two main components: an LLM\nplanner and a graph-based collaboration meta policy. The LLM planner transforms\ncomplex task instructions into a series of executable subtasks, evaluates the\nrationality of these subtasks using a critic model, and generates an action\ndependency graph. The graph-based collaboration meta policy facilitates\ncommunication and collaboration among agents based on the action dependency\ngraph, and adapts to new task environments through meta-learning. Experimental\nresults on the AI2-THOR simulation platform demonstrate the superior\nperformance and scalability of LGC-MARL in completing various complex tasks."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-752",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02239",
    "b_title":[
      "The SRG\/eROSITA all-sky survey: The morphologies of clusters of galaxies\n  I: A catalogue of morphological parameters"
    ],
    "b_abstract":[
      "The first SRG\/eROSITA all-sky X-ray survey, eRASS1, resulted in a catalogue\nof over twelve thousand optically-confirmed galaxy groups and clusters in the\nwestern Galactic hemisphere. Using the eROSITA images of these objects, we\nmeasure and study their morphological properties, including their\nconcentration, central density and slope, ellipticity, power ratios, photon\nasymmetry, centroid shift and Gini coefficient. We also introduce new\nforward-modelled parameters which take account of the instrument point spread\nfunction (PSF), which are slosh, which measures how asymmetric the surface\nbrightness distribution is, and multipole magnitudes, which are analogues to\npower ratios. Using simulations, we find some non forward-modelled parameters\nare strongly biased due to PSF and data quality. For the same clusters, we find\nsimilar values of concentration and central density compared to results by\nourselves using Chandra and previous results from XMM-Newton. The population as\na whole has log concentrations which are typically around 0.3 dex larger than\nSouth Pole Telescope or Planck-selected samples and the deeper eFEDS sample.\nThe exposure time, detection likelihood threshold, extension likelihood\nthreshold and number of counts affect the concentration distribution, but\ngenerally not enough to reduce the concentration to match the other samples.\nThe concentration of clusters in the survey strongly affects whether they are\ndetected as a function of redshift and luminosity. We introduce a combined\ndisturbance score based on a Gaussian mixture model fit to several of the\nparameters. For brighter clusters, around 1\/4 of objects are classified as\ndisturbed using this score, which may be due to our sensitivity to concentrated\nobjects."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.01751",
    "c_title":[
      "Clustered unified dark sector cosmology: Background evolution and linear\n  perturbations in light of observations"
    ],
    "c_abstract":[
      "We consider unified dark sector models in which the fluid can collapse and\ncluster into halos, allowing for hierarchical structure formation to proceed as\nin standard cosmology. We show that both background evolution and linear\nperturbations tend towards those in $\\LCDM$ as the clustered fraction $f\n\\rightarrow 1$. We confront such models with various observational datasets,\nwith emphasis on the relatively well motivated standard Chaplygin gas. We show\nthat the strongest constraints come from secondary anisotropies in the CMB\nspectrum, which prefer models with $f \\rightarrow 1$. However, as a larger\nHubble constant is allowed for smaller $f$, values of $f \\simeq 0.99$ (rather\nthan tending to exact unity) are favored when late universe expansion data is\nincluded, with $f \\simeq 0.97$ and $H_0 \\simeq 70 {\\rm km\/s\/Mpc}$ allowed at\nthe 2-$\\sigma$ level. Such values of $f$ imply extremely efficient clustering\ninto nonlinear structures. They may nevertheless be compatible with clustered\nfractions in warm dark matter based cosmologies, which have similar minimal\nhalo mass scales as the models considered here. Tight CMB constraints on $f$\nalso apply to the generalized Chaplygin gas, except for models that are already\nquite close to $\\LCDM$, in which case all values of $0 \\le f \\le 1$ are\nallowed. In contrast to the CMB, large scale structure data, which were\ninitially used to rule out unclustered unified dark matter models, are far less\nconstraining. Indeed, late universe data, including the large scale galaxy\ndistribution, prefer models that are far from $\\LCDM$. But these are in tension\nwith the CMB data."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-753",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09442",
    "b_title":[
      "The Diophantine problem in iterated wreath products of free abelian\n  groups is undecidable"
    ],
    "b_abstract":[
      "In this paper we prove that the Diophantine problem in iterated restricted\nwreath products $G$ of arbitrary non-trivial free abelian groups $A_1,\\ldots,\nA_k$, $k>1$ of finite ranks is undecidable, i.e., there is no algorithm that\ngiven a finite system of group equations with coefficients in $G$ decides\nwhether or not the system has a solution in $G$."
    ],
    "b_categories":[
      [
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.11808",
    "c_title":[
      "On the $1$-cohomology of $\\mathrm{SL}(n,{\\mathbb K})$ on the dual of its\n  adjoint module"
    ],
    "c_abstract":[
      "Given a field $\\mathbb K$, for any $n\\geq 3$ the first cohomology group\n$H^1(G_n,A^*_n)$ of the special linear group $G_n = \\mathrm{SL}(n,{\\mathbb K})$\nover the dual $A^*_n$ of its adjoint module $A_n$ is isomorphic to the space\n$\\mathrm{Der}({\\mathbb K})$ of the derivations of $\\mathbb K$, except possibly\nwhen $|{\\mathbb K}| \\in \\{2, 4\\}$ and $n$ is even. This fact is stated by S.\nSmith and H. V\\\"{o}lklein in their paper \"A geometric presentation for the\nadjont module of $\\mathrm{SL}_3(k)$\" (J. Algebra 127 (1989), 127--138). They\nclaim that when $|{\\mathbb K}| > 9$ this fact follows from the main result of\nV\\\"{o}lklein's paper \"The 1-cohomology of the adjoint module of a Chevalley\ngroup\" (Forum Math. 1 (1989), 1--13), but say nothing that can help the reader\nto deduce it from that result. When $|{\\mathbb K}| \\leq 9$ they obtain the\nisomorphism $H^1(G_n,A^*_n) \\cong \\mathrm{Der}({\\mathbb K})$ by means of other\nresults from homological algebra, which however miss the case $|{\\mathbb K}|\n\\in\\{2, 4\\}$ with $n $ even. In the present paper we shall provide a\nstraightforward proof of the isomorphism $H^1(G_n,A^*_n) \\cong\n\\mathrm{Der}({\\mathbb K})$ under the hypothesis $n > 3$. Our proof also covers\nthe above mentioned missing case."
    ],
    "c_categories":[
      [
        "math.GR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-754",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01063",
    "b_title":[
      "FAPL-DM-BC: A Secure and Scalable FL Framework with Adaptive Privacy and\n  Dynamic Masking, Blockchain, and XAI for the IoVs"
    ],
    "b_abstract":[
      "The FAPL-DM-BC solution is a new FL-based privacy, security, and scalability\nsolution for the Internet of Vehicles (IoV). It leverages Federated Adaptive\nPrivacy-Aware Learning (FAPL) and Dynamic Masking (DM) to learn and adaptively\nchange privacy policies in response to changing data sensitivity and state in\nreal-time, for the optimal privacy-utility tradeoff. Secure Logging and\nVerification, Blockchain-based provenance and decentralized validation, and\nCloud Microservices Secure Aggregation using FedAvg (Federated Averaging) and\nSecure Multi-Party Computation (SMPC). Two-model feedback, driven by\nModel-Agnostic Explainable AI (XAI), certifies local predictions and\nexplanations to drive it to the next level of efficiency. Combining local\nfeedback with world knowledge through a weighted mean computation, FAPL-DM-BC\nassures federated learning that is secure, scalable, and interpretable.\nSelf-driving cars, traffic management, and forecasting, vehicular network\ncybersecurity in real-time, and smart cities are a few possible applications of\nthis integrated, privacy-safe, and high-performance IoV platform."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15313",
    "c_title":[
      "I Know What You Did Last Summer: Identifying VR User Activity Through VR\n  Network Traffic"
    ],
    "c_abstract":[
      "Virtual Reality (VR) technology has gained substantial traction and has the\npotential to transform a number of industries, including education,\nentertainment, and professional sectors. Nevertheless, concerns have arisen\nabout the security and privacy implications of VR applications and the impact\nthat they might have on users. In this paper, we investigate the following\noverarching research question: can VR applications and VR user activities in\nthe context of such applications (e.g., manipulating virtual objects, walking,\ntalking, flying) be identified based on the (potentially encrypted) network\ntraffic that is generated by VR headsets during the operation of VR\napplications? To answer this question, we collect network traffic data from 25\nVR applications running on the Meta Quest Pro headset and identify\ncharacteristics of the generated network traffic, which we subsequently use to\ntrain off-the-shelf Machine Learning (ML) models. Our results indicate that\nthrough the use of ML models, we can identify the VR applications being used\nwith an accuracy of 92.4F% and the VR user activities performed with an\naccuracy of 91%. Furthermore, our results demonstrate that an attacker does not\nneed to collect large amounts of network traffic data for each VR application\nto carry out such an attack. Specifically, an attacker only needs to collect\nless than 10 minutes of network traffic data for each VR application in order\nto identify applications with an accuracy higher than 90% and VR user\nactivities with an accuracy higher than 88%."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-755",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18417",
    "b_title":[
      "GHOST 2.0: generative high-fidelity one shot transfer of heads"
    ],
    "b_abstract":[
      "While the task of face swapping has recently gained attention in the research\ncommunity, a related problem of head swapping remains largely unexplored. In\naddition to skin color transfer, head swap poses extra challenges, such as the\nneed to preserve structural information of the whole head during synthesis and\ninpaint gaps between swapped head and background. In this paper, we address\nthese concerns with GHOST 2.0, which consists of two problem-specific modules.\nFirst, we introduce enhanced Aligner model for head reenactment, which\npreserves identity information at multiple scales and is robust to extreme pose\nvariations. Secondly, we use a Blender module that seamlessly integrates the\nreenacted head into the target background by transferring skin color and\ninpainting mismatched regions. Both modules outperform the baselines on the\ncorresponding tasks, allowing to achieve state of the art results in head\nswapping. We also tackle complex cases, such as large difference in hair styles\nof source and target. Code is available at\nhttps:\/\/github.com\/ai-forever\/ghost-2.0"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16981",
    "c_title":[
      "Modulating CNN Features with Pre-Trained ViT Representations for\n  Open-Vocabulary Object Detection"
    ],
    "c_abstract":[
      "Owing to large-scale image-text contrastive training, pre-trained vision\nlanguage model (VLM) like CLIP shows superior open-vocabulary recognition\nability. Most existing open-vocabulary object detectors attempt to utilize the\npre-trained VLMs to attain generalized representation. F-ViT uses the\npre-trained visual encoder as the backbone network and freezes it during\ntraining. However, its frozen backbone doesn't benefit from the labeled data to\nstrengthen the representation for detection. Therefore, we propose a novel\ntwo-branch backbone network, named as \\textbf{V}iT-Feature-\\textbf{M}odulated\nMulti-Scale \\textbf{C}onvolutional Network (VMCNet), which consists of a\ntrainable convolutional branch, a frozen pre-trained ViT branch and a VMC\nmodule. The trainable CNN branch could be optimized with labeled data while the\nfrozen pre-trained ViT branch could keep the representation ability derived\nfrom large-scale pre-training. Then, the proposed VMC module could modulate the\nmulti-scale CNN features with the representations from ViT branch. With this\nproposed mixed structure, the detector is more likely to discover objects of\nnovel categories. Evaluated on two popular benchmarks, our method boosts the\ndetection performance on novel category and outperforms state-of-the-art\nmethods. On OV-COCO, the proposed method achieves 44.3\nAP$_{50}^{\\mathrm{novel}}$ with ViT-B\/16 and 48.5 AP$_{50}^{\\mathrm{novel}}$\nwith ViT-L\/14. On OV-LVIS, VMCNet with ViT-B\/16 and ViT-L\/14 reaches 27.8 and\n38.4 mAP$_{r}$."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-756",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14042",
    "b_title":[
      "Flavour Physics and CP Violation"
    ],
    "b_abstract":[
      "These lectures provide a concise introduction to flavor physics, within and\nbeyond the Standard Model, with main focus on B-physics phenomenology and some\nrecent developments. The first lecture is an introduction to the flavor sector\nof the Standard Model. The second lecture is devoted to B-meson mixing and rare\nB decays. The last lecture contains a general discussion about flavor physics\nbeyond the Standard Model, with a highlighting of recent developments related\nto the idea of flavor deconstruction."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.15465",
    "c_title":[
      "Revisiting gluon density from the BK equation with kinematical\n  constraint and large x terms"
    ],
    "c_abstract":[
      "We perform analysis of the small x non-linear evolution equation formulated\nin momentum space supplemented by higher order terms. The equation is defined\nin wide range of transverse momentum and longitudinal momentum fraction\nextending previous studies performed in \\cite{Kutak:2003bd,Kutak:2004ym}. The\nlinear part of the equation is motivated by the renormalization group improved\nsmall x approach which accounts for resummation of higher orders, and includes\ncollinear splitting function and kinematical constraint. The solution to the\nequation is then used to perform the fit to Deep Inelastic Scattering reduced\ncross section data."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-757",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01942",
    "b_title":[
      "Hybrid-z: Enhancing Kilo-Degree Survey bright galaxy sample photometric\n  redshifts with deep learning"
    ],
    "b_abstract":[
      "We employ deep learning (DL) to improve photometric redshifts (photo-$z$s) in\nthe Kilo-Degree Survey Data Release 4 Bright galaxy sample (KiDS-Bright DR4).\nThis dataset, used as a foreground for KiDS lensing and clustering studies, is\nflux-limited to $r<20$ mag with mean $z=0.23$ and covers 1000 deg$^2$. Its\nphoto-$z$s were previously derived with artificial neural networks from the\nANNz2 package, trained on the Galaxy And Mass Assembly (GAMA) spectroscopy.\nHere we considerably improve over these previous redshift estimations by\nbuilding a DL model, Hybrid-z, which combines four-band KiDS images with\nnine-band magnitudes from KiDS+VIKING. The Hybrid-z framework provides\nphoto-$z$s for KiDS-Bright, with negligible mean residuals of O($10^{-4}$) and\nscatter at the level of $0.014(1+z)$ -- reduction by 20% over the previous\nnine-band derivations with ANNz2. We check our photo-$z$ model performance on\ntest data drawn from GAMA, as well as from other KiDS-overlapping wide-angle\nspectroscopic surveys, namely SDSS, 2dFLenS, and 2dFGRS. We find stable\nbehavior and consistent improvement over ANNz2 throughout. We finally apply\nHybrid-z trained on GAMA to the entire KiDS-Bright DR4 sample of 1.2 million\ngalaxies. For these final predictions, we design a method of smoothing the\ninput redshift distribution of the training set, to avoid propagation of\nfeatures present in GAMA, related to its small sky area and large-scale\nstructure imprint in its fields. Our work paves the way towards the\nbest-possible photo-$z$s achievable with machine learning for any galaxy type\nboth for the final KiDS-Bright DR5 data and for future deeper imaging, such as\nfrom the Legacy Survey of Space and Time."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03288",
    "c_title":[
      "A semi-cosmographic approach to study cosmological evolution in phase\n  space"
    ],
    "c_abstract":[
      "The signature of Baryon Acoustic Oscillation in the clustering of dark-matter\ntracers allows us to measure $(D_A(z), H(z))$ independently. Treating these as\nconjugate variables, we are motivated to study cosmological evolution in the\nphase space of dimensionless variables $x = H_0 D_A\/c$ and $p = dx\/dz$. The\ndynamical system $(x(z),p(z))$ can be integrated for a known set of equation of\nstate parameters for different matter\/energy components. However, to avoid any\npreference for specific dark energy models, we adopt a cosmographic approach.\nWe consider two scenarios where the Luminosity distance is expanded as Pad\\'e\nrational approximants using expansion in terms of $z$ and $(1+z)^{1\/2}$\nrespectively. However, instead of directly using the Pad\\'e ratios to fit\nkinematic quantities with data, we adopt an alternative approach where the\nevolution of the cold dark matter sector is incorporated in our analysis\nthrough a semi-cosmographic equation of state, which is then, used to solve the\ndynamical problem in the phase space. The semi-cosmographic $(D_A(z), H(z))$,\nthus obtained, is fitted with BAO and SNIa data from DESI DR1 + eBOSS and\nPantheon+ respectively. We also consider a futuristic 21-cm intensity mapping\nexperiment for error projections. We further use the semi-cosmographic fitting\nto reconstruct some diagnostics of background cosmology and compare our results\nfor the two scenarios of Pad\\'e expansions."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-758",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05600",
    "b_title":[
      "The Multifaceted Nature of Mentoring in OSS: Strategies, Qualities, and\n  Ideal Outcomes"
    ],
    "b_abstract":[
      "Mentorship in open source software (OSS) is a vital, multifaceted process\nthat includes onboarding newcomers, fostering skill development, and enhancing\ncommunity building. This study examines task-focused mentoring strategies that\nhelp mentees complete their tasks and the ideal personal qualities and outcomes\nof good mentorship in OSS communities. We conducted two surveys to gather\ncontributor perceptions: the first survey, with 70 mentors, mapped 17 mentoring\nchallenges to 21 strategies that help support mentees. The second survey, with\n85 contributors, assessed the importance of personal qualities and ideal\nmentorship outcomes. Our findings not only provide actionable strategies to\nhelp mentees overcome challenges and become successful contributors but also\nguide current and future mentors and OSS communities in understanding the\npersonal qualities that are the cornerstone of good mentorship and the outcomes\nthat mentor-mentee pairs should aspire to achieve."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09204",
    "c_title":[
      "3D Printed Maps and Icons for Inclusion: Testing in the Wild by People\n  who are Blind or have Low Vision"
    ],
    "c_abstract":[
      "The difficulty and consequent fear of travel is one of the most disabling\nconsequences of blindness and severe vision impairment, affecting confidence\nand quality of life. Traditional tactile graphics are vital in the Orientation\nand Mobility training process, however 3D printing may have the capacity to\nenable production of more meaningful and inclusive maps. This study explored\nthe use of 3D printed maps on site at a public event to examine their\nsuitability and to identify guidelines for the design of future 3D maps. An\niterative design process was used in the production of the 3D maps, with\nfeedback from visitors who are blind or have low vision informing the\nrecommendations for their design and use. For example, it was found that many\nrepresentational 3D icons could be recognised by touch without the need for a\nkey and that such a map helped form mental models of the event space. Complex\nmaps, however, require time to explore and should be made available before an\nevent or at the entrance in a comfortable position. The maps were found to\nsupport the orientation and mobility process, and importantly to also promote a\npositive message about inclusion and accessibility."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-759",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.21027",
    "b_title":[
      "A RISC-V Multicore and GPU SoC Platform with a Qualifiable Software\n  Stack for Safety Critical Systems"
    ],
    "b_abstract":[
      "In the context of the Horizon Europe project, METASAT, a hardware platform\nwas developed as a prototype of future space systems. The platform is based on\na multiprocessor NOEL-V, an established space-grade processor, which is\nintegrated with the SPARROW AI accelerator and connected to a GPU, Vortex. Both\nprocessing systems follow the RISC-V specification. This is a novel hardware\narchitecture for the space domain as the use of massive parallel processing\nunits, such as GPUs, is starting to be considered for upcoming space missions\ndue to the increased performance required to future space-related workloads, in\nparticular, related to AI. However, such solutions are only currently adopted\nfor New Space, since their limitations come not only from the hardware, but\nalso from the software, which needs to be qualified before being deployed on an\ninstitutional mission. For this reason, the METASAT platform is one of the\nfirst endeavors towards enabling the use of high performance hardware in a\nqualifiable environment for safety critical systems. The software stack is\nbased on baremetal, RTEMS and the XtratuM hypervisor, providing different\noptions for applications of various degrees of criticality."
    ],
    "b_categories":[
      [
        "cs.AR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02608",
    "c_title":[
      "SWAPPER: Dynamic Operand Swapping in Non-commutative Approximate\n  Circuits for Online Error Reduction"
    ],
    "c_abstract":[
      "Error-tolerant applications, such as multimedia processing, machine learning,\nsignal processing, and scientific computing, can produce satisfactory outputs\neven when approximate computations are performed. Approximate computing (AxC)\nis nowadays a well-established design and computing paradigm that produces more\nefficient computation systems by judiciously reducing their computation\nquality. AxC has been applied to arithmetic circuits, modifying their logic\nbehavior. Depending on the approximation process, arithmetic properties, such\nas commutativity, are not consistently maintained. When such properties are\nabsent, error accumulation and application outputs depend on the order in which\ndata is processed. In this work, we show that controlling the operand order in\nnon-commutative approximate circuits can greatly reduce computational errors.\nWe propose SWAPPER, a lightweight approach that drastically reduces the\napproximation error by dynamically changing the order of the input operands\nusing only a single bit for the decision. To explore and identify the most\nsuitable bit for the swapping choice, we propose a framework that can be\napplied at different granularities, leading to large error reductions and\nsignificant accuracy improvements. Experimental results at both component and\napplication levels show error reductions of up to 50% for Mean Absolute Error\nat the component level and more than 90% at the application level on the\nAxBench application suite."
    ],
    "c_categories":[
      [
        "cs.AR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-760",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09953",
    "b_title":[
      "X-Cross: Image Encryption Featuring Novel Dual-Layer Block Permutation\n  and Dynamic Substitution Techniques"
    ],
    "b_abstract":[
      "In this digital age, ensuring the security of digital data, especially the\nimage data is critically important. Image encryption plays an important role in\nsecuring the online transmission\/storage of images from unauthorized access. In\nthis regard, this paper presents a novel diffusion-confusion-based image\nencryption algorithm named as X-CROSS. The diffusion phase involves a\ndual-layer block permutation. It involves a bit-level permutation termed\nInter-Bit Transference (IBT) using a Bit-Extraction key, and pixel permutation\nwith a unique X-crosspermutation algorithm to effectively scramble the pixels\nwithin an image. The proposed algorithm utilizes a resilient 2D chaotic map\nwith non-linear dynamical behavior, assisting in generating complex Extraction\nKeys. After the permutation phase, the confusion phase proceeds with a dynamic\nsubstitution technique on the permuted images, establishing the final\nencryption layer. This combination of novel permutation and confusion results\nin the removal of the image's inherent patterns and increases its resistance to\ncyber-attacks. The close to ideal statistical security results for information\nentropy, correlation, homogeneity, contrast, and energy validate the proposed\nscheme's effectiveness in hiding the information within the image."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03067",
    "c_title":[
      "Design and implementation of tools to build an ontology of Security\n  Requirements for Internet of Medical Things"
    ],
    "c_abstract":[
      "When developing devices, architectures and services for the Internet of\nMedical Things (IoMT) world, manufacturers or integrators must be aware of the\nsecurity requirements expressed by both laws and specifications. To provide\ntools guiding through these requirements and to assure a third party of the\ncorrect compliance, an ontology charting the relevant laws and specifications\n(for the European context) is very useful. We here address the development of\nthis ontology. Due to the very high number and size of the considered\nspecification documents, we have put in place a methodology and tools to\nsimplify the transition from natural text to an ontology. The first step is a\nmanual highlighting of relevant concepts in the corpus, then a manual\ntranslation to XML\/XSD is operated. We have developed a tool allowing us to\nconvert this semi-structured data into an ontology. Because the different\nspecifications use similar but different wording, our approach favors the\ncreation of similar instances in the ontology. To improve the ontology\nsimplification through instance merging, we consider the use of LLMs. The\nresponses of the LLMs are compared against our manually defined correct\nresponses. The quality of the responses of the automated system does not prove\nto be good enough to be trusted blindly, and should only be used as a starting\npoint for a manual correction."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-761",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12860",
    "b_title":[
      "Every $2k$-connected $(P_2\\cup kP_1)$-free graph with toughness greater\n  than one is hamiltonian-connected"
    ],
    "b_abstract":[
      "Given a graph $H$, a graph $G$ is $H$-free if $G$ does not contain $H$ as an\ninduced subgraph. Shi and Shan conjectured that every $1$-tough $2k$-connected\n$(P_2 \\cup kP_1)$-free graph is hamiltonian for $k \\geq 4$. This conjecture has\nbeen independently confirmed by Xu, Li, and Zhou, as well as by Ota and Sanka.\nInspired by this, we prove that every $2k$-connected $(P_2\\cup kP_1)$-free\ngraph with toughness greater than one is hamiltonian-connected."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.17552",
    "c_title":[
      "Partial permutations and character evaluations"
    ],
    "c_abstract":[
      "Let $I = (i_1, \\dots, i_k)$ and $J = (j_1, \\dots, j_k)$ be two length $k$\nsequences drawn from $\\{1, \\dots, n \\}$. We have the group algebra element\n$[I,J] := \\sum_{w(I) = J} w \\in \\mathbb{C}[\\mathfrak{S}_n]$ where the sum is\nover permutations $w \\in \\mathfrak{S}_n$ which satisfy $w(i_p) = j_p$ for $p =\n1, \\dots, k$. We give an algorithm for evaluating irreducible characters\n$\\chi^\\lambda: \\mathbb{C}[\\mathfrak{S}_n] \\to \\mathbb{C}$ of the symmetric\ngroup on the elements $[I,J]$. This algorithm is a hybrid of the classical\nMurnaghan--Nakayama rule and a new path Murnaghan--Nakayama rule which reflects\nthe decomposition of a partial permutation into paths and cycles.\n  These results first appeared in arXiv:2206.06567, which is no longer intended\nfor publication. We originally used the character theoretic results in this\npaper to prove asymptotic results on moments of certain permutation statistics\nrestricted to conjugacy classes. A referee generously shared a combinatorial\nargument which is strong enough to prove these results without recourse to\ncharacter theory. These results now appear in our companion\npaper~\\cite{HRMoment}. However, the approach in this paper is more explicit, as\nwe demonstrate with several examples."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-762",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19259",
    "b_title":[
      "U(1) Dirac quantum spin liquid candidate in triangular-lattice\n  antiferromagnet CeMgAl$_{11}$O$_{19}$"
    ],
    "b_abstract":[
      "Quantum spin liquid represents an intriguing state where electron spins are\nhighly entangled yet spin fluctuation persists even at 0 K. Recently, the\nhexaaluminates \\textit{R}MgAl$_{11}$O$_{19}$ (\\textit{R} = rare earth) have\nbeen proposed to be a platform for realizing the quantum spin liquid state with\ndominant Ising anisotropic correlations. Here, we report detailed\nlow-temperature magnetic susceptibility, muon spin relaxation, and\nthermodynamic studies on the CeMgAl$_{11}$O$_{19}$ single crystal. Ising\nanisotropy is revealed by magnetic susceptibility measurements. Muon spin\nrelaxation and ac susceptibility measurements rule out any long-range magnetic\nordering or spin freezing down to 50 mK despite the onset of spin correlations\nbelow $\\sim$0.8 K. Instead, the spins keep fluctuating at a rate of 1.0(2) MHz\nat 50 mK. Specific heat results indicate a gapless excitation with a power-law\ndependence on temperature, $C_m(T) \\propto T^{\\alpha}$. The quasi-quadratic\ntemperature dependence with $\\alpha$ = 2.28(4) in zero field and linear\ntemperature dependence in 0.25 T support the possible realization of the U(1)\nDirac quantum spin liquid state."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.13272",
    "c_title":[
      "Uniaxial Pressure Effects, Phase Diagram, and Tricritical Point in the\n  Centrosymmetric Skyrmion Lattice Magnet GdRu$_2$Si$_2$"
    ],
    "c_abstract":[
      "The magnetic phase diagram, magnetoelastic coupling, and uniaxial pressure\neffects of centrosymmetric magnetic skyrmion-hosting GdRu$_2$Si$_2$ are\ninvestigated by means of high-resolution capacitance dilatometry in fields up\nto 15\\,T supported by specific heat and magnetisation studies. In addition to\nthe previously reported phases in the $H$-$T$ phase diagram, we observe a third\nantiferromagnetic phase in zero magnetic field. We present the magnetic phase\ndiagram and find two unreported phases, one of which features a comparably\ngiant uniaxial pressure dependence. Our dilatometric measurements show\nmagnetoelastic effects associated with the various magnetic ordering phenomena.\nWe determine the uniaxial pressure dependencies of the various phases, in\nparticular of the skyrmion lattice phase which is enhanced at higher fields and\ntemperatures and also widens at a rate of 0.07~T\/GPa when uniaxial pressure is\napplied along the $c$ axis. The relevance of fluctuations is further\nhighlighted by the presence of tricritical point indicated by our thermodynamic\ndata at the phase boundary separating two double-\\textit{Q} magnetic\nconfigurations between which the skyrmion pocket phase evolves upon further\ncooling."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-763",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15943",
    "b_title":[
      "Chemistry and ro-vibrational excitation of HeH$^+$ in the Planetary\n  Nebula NGC 7027"
    ],
    "b_abstract":[
      "HeH$^+$ belongs to the class of \"reactive\" ions that can be destroyed so\nquickly that chemical formation and destruction rates may compete with\ninelastic rates and should be considered when solving the statistical\nequilibrium equations. This so-called chemical \"pumping\" or \"excitation\" effect\nis investigated here for the first time in HeH$^+$. The chemical evolution of\nHeH$^+$ in NGC 7027 is modeled with the CLOUDY photoionization code using\nupdated reaction rate coefficients. The non-LTE analysis of the three observed\nHeH$^+$ emission lines is then performed with the CLOUDY and RADEX codes using\nan extensive set of spectroscopic and inelastic collisional data suitable for\nthe specific high-temperature environment of NGC 7027. In a second approach,\nchemical formation and destruction rates of HeH$^+$ are implemented in RADEX.\nThis code is combined with MCMC sampling (performed on the RADEX-parameters\nspace) to extract the best-fit HeH$^+$ column density and physical conditions\nfrom the observed line fluxes. The CLOUDY and RADEX non-LTE results are found\nto be in good agreement, and the $\\upsilon=1-0 \\ P(2)\/P(1)$ line ratio is\nbetter than 20%. Agreement to better than a factor of 2.3 is obtained when\nincluding the reaction between He($2^3S$) and H as an additional source of\nHeH$^+$. The RADEX\/MCMC model with chemical pumping is found to reproduce both\nthe observed line fluxes and the line ratio to 20%. Our results suggest that\nadditional HeH$^+$ lines must be detected in NGC 7027 to better constrain the\nphysical conditions via non-LTE models. Uncertainties in collisional (reactive\nand inelastic) data of HeH$^+$ have been largely reduced in this work. The\nthree observed lines are not sensitive to chemical pumping while excited\n\"short-lived\" levels are significantly overpopulated with respect to a non-LTE\nmodel neglecting chemical excitation."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.05924",
    "c_title":[
      "Comparing radial migration in dark matter and MOND regimes"
    ],
    "c_abstract":[
      "Multiple studies on radial migration in disc galaxies have proven the\nimportance of the effect of resonances with non-axisymmetric components on the\nevolution of galactic discs. However, the dynamical effects of classic\nNewtonian dynamics with dark matter (DM) differ from MOdified Newtonian\nDynamics (MOND) and might trigger different radial migration. A thorough\nanalysis of radial migration considering these two gravitational regimes might\nshed some light on different predictions of DM and MOND theories. We aim to\nquantitatively and qualitatively compare the effects of resonances and stellar\nradial migration (churning) in a Milky Way-like (MW-like) galaxy in the DM and\nMOND regimes. We performed simulations of a MW-like galaxy to analyse the\neffect of non-axisymmetric structures (galactic bar and spiral arms)\nconsidering various parameters of the spiral structure. We conducted a\ntwo-dimensional numerical simulation consisting of the integration of $2 \\cdot\n10^6$ stars in a static rotating galactic potential for $6~\\mbox{Gyr}$. We\nanalysed the change in the star's position, the guiding radius, as well as the\nfrequency phase space. We investigated DM and MOND approaches. The outcome of\nthe simulation shows that the radial migration is much more pronounced in the\nMOND regime compared to the DM one. Compared to the DM approach, in the MOND\nregime, we observe up to five times as many stars with a maximum change in the\nguiding radius of more than $1.5~\\mbox{kpc}$ during the time interval from\n$2-6~\\mbox{Gyr}$.Analysis of the frequency phase space reveals that the most\nprominent resonances in all DM and MOND configurations are the co-rotation\nresonance with the spiral arms ($m=p=1$), outer Lindblad resonance with the\ngalactic bar and spiral arms, and the co-rotation resonance ($m=2$, $p=1$) with\nthe superposition of the galactic bar and spiral arms, $2 \\Omega = \\Omega_b +\n\\Omega_{sp}$."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-764",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13886",
    "b_title":[
      "On the Almost Sure Convergence of the Stochastic Three Points Algorithm"
    ],
    "b_abstract":[
      "The stochastic three points (STP) algorithm is a derivative-free optimization\ntechnique designed for unconstrained optimization problems in $\\mathbb{R}^d$.\nIn this paper, we analyze this algorithm for three classes of functions: smooth\nfunctions that may lack convexity, smooth convex functions, and smooth\nfunctions that are strongly convex. Our work provides the first almost sure\nconvergence results of the STP algorithm, alongside some convergence results in\nexpectation. For the class of smooth functions, we establish that the best\ngradient iterate of the STP algorithm converges almost surely to zero at a rate\narbitrarily close to $o(\\frac{1}{\\sqrt{T}})$, where $T$ is the number of\niterations. Furthermore, within the same class of functions, we establish both\nalmost sure convergence and convergence in expectation of the final gradient\niterate towards zero. For the class of smooth convex functions, we establish\nthat $f(\\theta^T)$ converges to $\\inf_{\\theta \\in \\mathbb{R}^d} f(\\theta)$\nalmost surely at a rate arbitrarily close to $o(\\frac{1}{T})$, and in\nexpectation at a rate of $O(\\frac{d}{T})$ where $d$ is the dimension of the\nspace. Finally, for the class of smooth functions that are strongly convex, we\nestablish that when step sizes are obtained by approximating the directional\nderivatives of the function, $f(\\theta^T)$ converges to $\\inf_{\\theta \\in\n\\mathbb{R}^d} f(\\theta)$ in expectation at a rate of $O((1-\\frac{\\mu}{dL})^T)$,\nand almost surely at a rate arbitrarily close to $o((1-\\frac{\\mu}{dL})^T)$,\nwhere $\\mu$ and $L$ are the strong convexity and smoothness parameters of the\nfunction."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.02752",
    "c_title":[
      "Douglas-Rachford algorithm for nonmonotone multioperator inclusion\n  problems"
    ],
    "c_abstract":[
      "The Douglas-Rachford algorithm is a classic splitting method for finding a\nzero of the sum of two maximal monotone operators. It has also been applied to\nsettings that involve one weakly and one strongly monotone operator. In this\nwork, we extend the Douglas-Rachford algorithm to address multioperator\ninclusion problems involving $m$ ($m\\geq 2$) weakly and strongly monotone\noperators, reformulated as a two-operator inclusion in a product space. By\nselecting appropriate parameters, we establish the convergence of the algorithm\nto a fixed point, from which solutions can be extracted. Furthermore, we\nillustrate its applicability to sum-of-$m$-functions minimization problems\ncharacterized by weakly convex and strongly convex functions. For general\nnonconvex problems in finite-dimensional spaces, comprising Lipschitz\ncontinuously differentiable functions and a proper closed function, we provide\nglobal subsequential convergence guarantees."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-765",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04180",
    "b_title":[
      "Advancing sustainable energy solutions with microfluidic porous media"
    ],
    "b_abstract":[
      "The transition to a sustainable, low-carbon energy future requires\ntransformative advancements in energy and environmental technologies. Carbon\ncapture and sequestration, underground hydrogen storage, and nuclear waste\ngeological disposal will be central aspects of a sustainable energy future,\nboth for mitigating CO2 emissions and providing green energy. A comprehensive\nunderstanding of multiphase flow through porous media, along with reactive\ntransport and microbial activities, is essential for assessing the feasibility\nand managing the risks of these technologies. Microfluidic porous media\nplatforms have emerged as powerful tools for the direct visualization of\nmultiphase reactive flow in porous media and eventually optimizing these\nmultiple physicochemical and biological processes. This review highlights\ncritical scientific challenges associated with these sustainable energy\nsolutions and summarizes the state-of-the-art microfluidic techniques for\nstudying the interplay between multiphase flow, reactive transport, and\nbiological effects in porous media. We provide a comprehensive overview of how\nthese microfluidic approaches enhance the understanding of fundamental\npore-scale dynamics and bridge the gap between pore-scale events and\nlarge-scale processes. This review is expected to promote both experimental and\ntheoretical understanding of multiphase reactive flow in porous media, thereby\ninforming material design, process optimization, and predictive modeling for\nscalable implementation. By fostering interdisciplinary collaboration across\nmicrofluidics, fluid mechanics, geophysics, materials science, and subsurface\nengineering, we hope to accelerate innovation and advance sustainable energy\nsolutions."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.21168",
    "c_title":[
      "Numerical investigation of the flow induced by a transcatheter\n  intra-aortic entrainment pump"
    ],
    "c_abstract":[
      "This study evaluates the fluid dynamics inside and outside transcatheter\nblood pump positioned in the aorta. We focus on the pump's impact on blood\ncomponent damage and arterial wall stress. CFD simulations were performed for\nrotational speeds ranging from 6000 to 15000 rpm, with a blood flow rate of 1.6\nL\/min. Results show that significant blood damage may occur at speeds as low as\n12000 rpm, and the pump's outflow jet induces elevated wall shear stress,\npotentially leading to arterial aneurysms. These findings suggest the need for\nfurther design improvements to reduce risks when used in prolonged or\ntransplant-related applications."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-766",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10186",
    "b_title":[
      "A primordial radius valley as a consequence of planet formation"
    ],
    "b_abstract":[
      "The radius distribution of close-in planets has been observed to have a\nbimodal distribution with a dearth of planets around ~1.5-2.0 $R_\\oplus$\ncommonly referred to as the ''radius valley''. The origin of the valley is\nnormally attributed to mass-loss process such as photoevaporation or\ncore-powered mass loss. Recent work, however, has suggested that the radius\nvalley may instead arise as a consequence of gas accretion by low-mass planets.\nIn this work we therefore aim to investigate the formation of a primordial\nradius valley from the formation of planet cores through pebble accretion up\nuntil the dissipation of the protoplanetary disc and subsequent contraction of\naccreted atmospheres. The goal of this work is to explore the conditions for\nforming a primordial radius valley from first principles of planet formation\ntheory, rather than attempting to explain the detailed structure of the\nobserved valley. We use an analytical model with minimal assumptions to\nestimate the contraction rate of atmospheres and, indeed, find the formation of\na primordial radius valley. The planets smaller than the valley did not reach\nthe pebble isolation mass, which is required for the planets to cool down\nsufficiently to be able to accrete a significant amount of gas. We also\nestimate the slopes of the radius gap as a function of orbital period for the\nintrinsic population as well as for planets with orbital periods <100 days. For\nthe intrinsic population, the radius gap follows the pebble isolation mass and\nincreases with increasing orbital period, while for close-in planets the\ndirection of the slope reverses and decreases with increasing orbital period.\nWe find that planets smaller than the radius valley are predominantly rocky\nwhile the population of planets larger than the valley consists of a mixture of\nrocky and water-rich planets."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.11667",
    "c_title":[
      "A One-Dimensional Energy Balance Model Parameterization for the\n  Formation of CO2 Ice on the Surfaces of Eccentric Extrasolar Planets"
    ],
    "c_abstract":[
      "Eccentric planets may spend a significant portion of their orbits at large\ndistances from their host stars, where low temperatures can cause atmospheric\nCO2 to condense out onto the surface, similar to the polar ice caps on Mars.\nThe radiative effects on the climates of these planets throughout their orbits\nwould depend on the wavelength-dependent albedo of surface CO2 ice that may\naccumulate at or near apoastron and vary according to the spectral energy\ndistribution of the host star. To explore these possible effects, we\nincorporated a CO2 ice-albedo parameterization into a one-dimensional energy\nbalance climate model. With the inclusion of this parameterization, our\nsimulations demonstrated that F-dwarf planets require 29% more orbit-averaged\nflux to thaw out of global water ice cover compared with simulations that\nsolely use a traditional pure water ice-albedo parameterization. When no\neccentricity is assumed, and host stars are varied, F-dwarf planets with higher\nbond albedos relative to their M-dwarf planet counterparts require 30% more\norbit-averaged flux to exit a water snowball state. Additionally, the intense\nheat experienced at periastron aids eccentric planets in exiting a snowball\nstate with a smaller increase in instellation compared with planets on circular\norbits; this enables eccentric planets to exhibit warmer conditions along a\nbroad range of instellation. This study emphasizes the significance of\nincorporating an albedo parameterization for the formation of CO2 ice into\nclimate models to accurately assess the habitability of eccentric planets, as\nwe show that, even at moderate eccentricities, planets with Earth-like\natmospheres can reach surface temperatures cold enough for the condensation of\nCO2 onto their surfaces, as can planets receiving low amounts of instellation\non circular orbits."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-767",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04522",
    "b_title":[
      "In-Context Reverse Classification Accuracy: Efficient Estimation of\n  Segmentation Quality without Ground-Truth"
    ],
    "b_abstract":[
      "Assessing the quality of automatic image segmentation is crucial in clinical\npractice, but often very challenging due to the limited availability of ground\ntruth annotations. In this paper, we introduce In-Context Reverse\nClassification Accuracy (In-Context RCA), a novel framework for automatically\nestimating segmentation quality in the absence of ground-truth annotations. By\nleveraging recent in-context learning segmentation models and incorporating\nretrieval-augmentation techniques to select the most relevant reference images,\nour approach enables efficient quality estimation with minimal reference data.\nValidated across diverse medical imaging modalities, our method demonstrates\nrobust performance and computational efficiency, offering a promising solution\nfor automated quality control in clinical workflows, where fast and reliable\nsegmentation assessment is essential. The code is available at\nhttps:\/\/github.com\/mcosarinsky\/In-Context-RCA."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15847",
    "c_title":[
      "Can Location Embeddings Enhance Super-Resolution of Satellite Imagery?"
    ],
    "c_abstract":[
      "Publicly available satellite imagery, such as Sentinel- 2, often lacks the\nspatial resolution required for accurate analysis of remote sensing tasks\nincluding urban planning and disaster response. Current super-resolution\ntechniques are typically trained on limited datasets, leading to poor\ngeneralization across diverse geographic regions. In this work, we propose a\nnovel super-resolution framework that enhances generalization by incorporating\ngeographic context through location embeddings. Our framework employs\nGenerative Adversarial Networks (GANs) and incorporates techniques from\ndiffusion models to enhance image quality. Furthermore, we address tiling\nartifacts by integrating information from neighboring images, enabling the\ngeneration of seamless, high-resolution outputs. We demonstrate the\neffectiveness of our method on the building segmentation task, showing\nsignificant improvements over state-of-the-art methods and highlighting its\npotential for real-world applications."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-768",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13045",
    "b_title":[
      "All You Need to Know About Training Image Retrieval Models"
    ],
    "b_abstract":[
      "Image retrieval is the task of finding images in a database that are most\nsimilar to a given query image. The performance of an image retrieval pipeline\ndepends on many training-time factors, including the embedding model\narchitecture, loss function, data sampler, mining function, learning rate(s),\nand batch size. In this work, we run tens of thousands of training runs to\nunderstand the effect each of these factors has on retrieval accuracy. We also\ndiscover best practices that hold across multiple datasets. The code is\navailable at https:\/\/github.com\/gmberton\/image-retrieval"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.08927",
    "c_title":[
      "Dynamic watermarks in images generated by diffusion models"
    ],
    "c_abstract":[
      "High-fidelity text-to-image diffusion models have revolutionized visual\ncontent generation, but their widespread use raises significant ethical\nconcerns, including intellectual property protection and the misuse of\nsynthetic media. To address these challenges, we propose a novel multi-stage\nwatermarking framework for diffusion models, designed to establish copyright\nand trace generated images back to their source. Our multi-stage watermarking\ntechnique involves embedding: (i) a fixed watermark that is localized in the\ndiffusion model's learned noise distribution and, (ii) a human-imperceptible,\ndynamic watermark in generates images, leveraging a fine-tuned decoder. By\nleveraging the Structural Similarity Index Measure (SSIM) and cosine\nsimilarity, we adapt the watermark's shape and color to the generated content\nwhile maintaining robustness. We demonstrate that our method enables reliable\nsource verification through watermark classification, even when the dynamic\nwatermark is adjusted for content-specific variations. Source model\nverification is enabled through watermark classification. o support further\nresearch, we generate a dataset of watermarked images and introduce a\nmethodology to evaluate the statistical impact of watermarking on generated\ncontent.Additionally, we rigorously test our framework against various attack\nscenarios, demonstrating its robustness and minimal impact on image quality.\nOur work advances the field of AI-generated content security by providing a\nscalable solution for model ownership verification and misuse prevention."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-769",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08377",
    "b_title":[
      "Not All Frame Features Are Equal: Video-to-4D Generation via Decoupling\n  Dynamic-Static Features"
    ],
    "b_abstract":[
      "Recently, the generation of dynamic 3D objects from a video has shown\nimpressive results. Existing methods directly optimize Gaussians using whole\ninformation in frames. However, when dynamic regions are interwoven with static\nregions within frames, particularly if the static regions account for a large\nproportion, existing methods often overlook information in dynamic regions and\nare prone to overfitting on static regions. This leads to producing results\nwith blurry textures. We consider that decoupling dynamic-static features to\nenhance dynamic representations can alleviate this issue. Thus, we propose a\ndynamic-static feature decoupling module (DSFD). Along temporal axes, it\nregards the regions of current frame features that possess significant\ndifferences relative to reference frame features as dynamic features.\nConversely, the remaining parts are the static features. Then, we acquire\ndecoupled features driven by dynamic features and current frame features.\nMoreover, to further enhance the dynamic representation of decoupled features\nfrom different viewpoints and ensure accurate motion prediction, we design a\ntemporal-spatial similarity fusion module (TSSF). Along spatial axes, it\nadaptively selects similar information of dynamic regions. Hinging on the\nabove, we construct a novel approach, DS4D. Experimental results verify our\nmethod achieves state-of-the-art (SOTA) results in video-to-4D. In addition,\nthe experiments on a real-world scenario dataset demonstrate its effectiveness\non the 4D scene. Our code will be publicly available."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04317",
    "c_title":[
      "Factorized Implicit Global Convolution for Automotive Computational\n  Fluid Dynamics Prediction"
    ],
    "c_abstract":[
      "Computational Fluid Dynamics (CFD) is crucial for automotive design,\nrequiring the analysis of large 3D point clouds to study how vehicle geometry\naffects pressure fields and drag forces. However, existing deep learning\napproaches for CFD struggle with the computational complexity of processing\nhigh-resolution 3D data. We propose Factorized Implicit Global Convolution\n(FIGConv), a novel architecture that efficiently solves CFD problems for very\nlarge 3D meshes with arbitrary input and output geometries. FIGConv achieves\nquadratic complexity $O(N^2)$, a significant improvement over existing 3D\nneural CFD models that require cubic complexity $O(N^3)$. Our approach combines\nFactorized Implicit Grids to approximate high-resolution domains, efficient\nglobal convolutions through 2D reparameterization, and a U-shaped architecture\nfor effective information gathering and integration. We validate our approach\non the industry-standard Ahmed body dataset and the large-scale DrivAerNet\ndataset. In DrivAerNet, our model achieves an $R^2$ value of 0.95 for drag\nprediction, outperforming the previous state-of-the-art by a significant\nmargin. This represents a 40% improvement in relative mean squared error and a\n70% improvement in absolute mean squared error over previous methods."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-770",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13910",
    "b_title":[
      "Localization and wall-crossing of giant graviton expansions in AdS$_5$"
    ],
    "b_abstract":[
      "The $\\frac12$-BPS indices of $\\mathcal{N}=4$ Super Yang-Mills theory with\nunitary, orthogonal, and symplectic groups all admit $q$-expansions suggesting\nan interpretation in terms of D-branes in the dual bulk AdS$_5$ string\ntheories. We present a derivation of these expansions in the corresponding bulk\nduals by quantizing the moduli space of $\\frac12$-BPS giant gravitons using\nsupersymmetric localization, extending and clarifying our study in\narxiv:2312.14921. We perform a detailed analysis of the one-loop fluctuations\naround the maximal giants (the fixed points), and show how the Hamiltonian\nanalysis is recovered from the functional integral for the equivariant index.\nWe show that the analytic continuation for these giant graviton expansions\nobserved in the literature maps precisely to a wall-crossing phenomenon for the\nindex. In the case of orthogonal and symplectic gauge groups, the\n$\\mathbb{Z}_2$ quotient in the bulk leads to a corresponding projection in the\n$q$-expansion. Additional terms in the expansion related to the Pfaffian\noperator arise from topologically stable branes in the bulk dual on AdS$_5\n\\times \\mathbb{RP}^5$."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.10524",
    "c_title":[
      "Higher-Dimensional Fermionic SYK Model in IR Region"
    ],
    "c_abstract":[
      "We study the 2D fermionic SYK model with Majorana fermions, featuring a\nkinetic term with a quartic expression and a $2q$-body interaction with\nGaussian disorder. By minimizing the effective action or solving the SD\nequation for $q=1$, we determine that the appropriate ansatz involves zero\nspins. Our computation of the Lyapunov exponent shows violations of chaos and\nunitarity bounds. The gravitational dual corresponds to AdS$_3$ Einstein\ngravity with a finite radial cut-off even if we lose the non-zero spins. We\nalso extend the SYK model to higher dimensions while maintaining a similar SD\nequation in the IR."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-771",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06451",
    "b_title":[
      "Looking To The Horizon: Probing Evolution in the Black Hole Spectrum\n  With GW Catalogs"
    ],
    "b_abstract":[
      "The population of black holes observed via gravitational waves currently\ncovers the local universe up to a redshift $z\\lesssim 1$, for the most massive\nmerging binaries, or $z\\lesssim 0.25$ for low-mass BH binaries (BBH). Evolution\nof the BBH mass spectrum over cosmic time will be a significant probe of\nformation channels and environments. We demonstrate a reconstruction of the BBH\nmerger rate, allowing for general dependence on binary masses and luminosity\ndistance or redshift and accounting for selection effects, via iterative kernel\ndensity estimation (KDE) with optimized multidimensional bandwidths. Performing\nsuch reconstructions under a range of detailed assumptions, we see no\nsignificant evidence for the evolution of BBH masses with redshift, over the\nrange where detected events are available; at most, a possible trend towards\nincreasing merger rate with redshift for primary masses $m_1\\gtrsim\n50\\,M_\\odot$ is supported. We compare these findings with previous\ninvestigations and caution against over-interpreting the current, sparse, data.\nSignificantly upgraded detectors and\/or facilities, and longer observing times,\nare required to harness any correlations of the BBH mass distribution with\nredshift."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.15745",
    "c_title":[
      "Higher order analysis of the gravitational wave velocity memory effect\n  between two free-falling gyroscopes in the plane wave spacetime"
    ],
    "c_abstract":[
      "In the plane wave spacetime, when gravitational waves pass by, an angular\ndeviation exists between two free-falling gyroscopes, which naturally\ncorresponds to the velocity memory effect.\n  In the shackwave spacetime background, the angular deviation between two\nfree-falling gyroscopes is calculated, which is also found to correspond to the\nvelocity memory effect.\n  In the plane wave spacetime, with linear polarization taken into account, no\ncontribution is made by the first-order terms of the initial separation\ndistance \\(L\\) (or the initial separation velocity \\(v_0\\)),\n  \\(\\bm{P}\\) (or \\(\\bm{M}\\)) of two free-falling gyroscopes to the velocity\nmemory effect, while contributions are initiated from the second-order terms.\n  Under certain circumstances, the second-order contribution of the initial\nseparation distance \\(L\\) is of the same order of magnitude as the first-order\ncontribution of the initial separation velocity \\(v_0\\).\n  When both + polarization and \\(\\times\\) polarization are taken into account,\nin the context of the merger of supermassive black holes and with the initial\nseparation velocity approaching the speed of light, the order of magnitude of\nthe angle is \\(10^{-16}\\) rads."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-772",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08582",
    "b_title":[
      "LoRS: Efficient Low-Rank Adaptation for Sparse Large Language Model"
    ],
    "b_abstract":[
      "Existing low-rank adaptation (LoRA) methods face challenges on sparse large\nlanguage models (LLMs) due to the inability to maintain sparsity. Recent works\nintroduced methods that maintain sparsity by augmenting LoRA techniques with\nadditional masking mechanisms. Despite these successes, such approaches suffer\nfrom an increased memory and computation overhead, which affects efficiency of\nLoRA methods. In response to this limitation, we introduce LoRS, an innovative\nmethod designed to achieve both memory and computation efficiency when\nfine-tuning sparse LLMs. To mitigate the substantial memory and computation\ndemands associated with preserving sparsity, our approach incorporates\nstrategies of weight recompute and computational graph rearrangement. In\naddition, we also improve the effectiveness of LoRS through better adapter\ninitialization. These innovations lead to a notable reduction in memory and\ncomputation consumption during the fine-tuning phase, all while achieving\nperformance levels that outperform existing LoRA approaches."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18050",
    "c_title":[
      "Uncertainty-aware abstention in medical diagnosis based on medical texts"
    ],
    "c_abstract":[
      "This study addresses the critical issue of reliability for AI-assisted\nmedical diagnosis. We focus on the selection prediction approach that allows\nthe diagnosis system to abstain from providing the decision if it is not\nconfident in the diagnosis. Such selective prediction (or abstention)\napproaches are usually based on the modeling predictive uncertainty of machine\nlearning models involved.\n  This study explores uncertainty quantification in machine learning models for\nmedical text analysis, addressing diverse tasks across multiple datasets. We\nfocus on binary mortality prediction from textual data in MIMIC-III,\nmulti-label medical code prediction using ICD-10 codes from MIMIC-IV, and\nmulti-class classification with a private outpatient visits dataset.\nAdditionally, we analyze mental health datasets targeting depression and\nanxiety detection, utilizing various text-based sources, such as essays, social\nmedia posts, and clinical descriptions.\n  In addition to comparing uncertainty methods, we introduce HUQ-2, a new\nstate-of-the-art method for enhancing reliability in selective prediction\ntasks. Our results provide a detailed comparison of uncertainty quantification\nmethods. They demonstrate the effectiveness of HUQ-2 in capturing and\nevaluating uncertainty, paving the way for more reliable and interpretable\napplications in medical text analysis."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-773",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06974",
    "b_title":[
      "Higher-rank GBS groups: non-positive curvature and biautomaticity"
    ],
    "b_abstract":[
      "We characterise when a rank $n$ generalised Baumslag-Solitar group is CAT(0)\nand when it is biautomatic."
    ],
    "b_categories":[
      [
        "math.GR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.17342",
    "c_title":[
      "On the subgroup separability of the free product of groups"
    ],
    "c_abstract":[
      "Suppose that $\\mathcal{C}$ is a root class of groups (i.e., a class of groups\nthat contains non-trivial groups and is closed under taking subgroups and\nunrestricted wreath products), $G$ is the free product of residually\n$\\mathcal{C}$-groups $A_{i}$ ($i \\in \\mathcal{I}$), and $H$ is a subgroup of\n$G$ satisfying a non-trivial identity. We prove a criterion for the\n$\\mathcal{C}$-separability of $H$ in $G$. It follows from this criterion that,\nif $\\{\\mathcal{V}_{j} \\mid j \\in \\mathcal{J}\\}$ is a family of group varieties,\neach $\\mathcal{V}_{j}$ ($j \\in \\mathcal{J}$) is distinct from the variety of\nall groups, and $\\mathcal{V} = \\bigcup_{j \\in \\mathcal{J}} \\mathcal{V}_{j}$,\nthen one can give a description of $\\mathcal{C}$-separable\n$\\mathcal{V}$-subgroups of $G$ provided such a description is known for every\ngroup $A_{i}$ ($i \\in \\mathcal{I}$)."
    ],
    "c_categories":[
      [
        "math.GR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-774",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12476",
    "b_title":[
      "Strengthening the Link Between Fullerenes and a Subset of Diffuse\n  Interstellar Bands"
    ],
    "b_abstract":[
      "A debate persists regarding the correlation between the DIBs 9577 and 9632\n\\r{A}, and whether they share a common molecular carrier (i.e., C$_{60}^{+}$).\nA robust high correlation determination emerges after bridging the baseline\nacross an order of magnitude ($\\simeq 50 - 700$ m\\r{A}, $r=0.93\\pm0.02$), and\nnearly doubling the important higher equivalent width domain by adding new Mg\nII-corrected sightlines. Moreover, additional evidence is presented of possible\nDIB linkages to fullerenes, whereby attention is drawn to DIBs at 7470.38,\n7558.44, and 7581.47 \\r{A}, which match the Campbell experimental results for\nC$_{70}^{+}$ within 1 \\r{A}, and the same is true of 6926.48 and 7030.26 \\r{A}\nfor C$_{70}^{2+}$. Yet their current correlation uncertainties are\nunsatisfactory and exacerbated by expectedly low EWs (e.g., $\\overline{EW}=4$\nm\\r{A} for 6926.48 \\r{A}), and thus further observations are required to assess\nwhether they represent a bona fide connection or numerical coincidence."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.01024",
    "c_title":[
      "The Gravitational Wave Background from Massive Black Holes in the ASTRID\n  Simulation"
    ],
    "c_abstract":[
      "Recent pulsar timing array (PTA) observations have detected nanohertz\ngravitational waves, likely originating from massive black hole binaries\n(MBHBs). The detected amplitude is unexpectedly higher than inferred from the\nelectromagnetic measurements. We present new gravitational wave background\n(GWB) results from the ASTRID simulation. Its large volume and on-the-fly\ndynamical friction for MBHs provide new insights into the MBHB population,\noffering a more accurate assessment of its contribution to the observed GWB.\nASTRID predicts a GWB from MBHBs of $h_c=2.8\\times10^{-15}$, or $\\sim45\\%$ of\nthe observed amplitude at $\\sim 4\\,{\\rm nHz}$ and $h_c=2.5\\times10^{-16}$\n($5\\%$) with $h_c\\propto f^{-1.6}$ at $\\sim 30\\,{\\rm nHz}$. These predictions\nremain below current PTA constraints but align with previous empirical models\nbased on the observed MBH mass functions. By comparison, TNG300 with\npost-processed MBH dynamics yields a range between $70-90\\%$ ($20\\% - 30\\%$) of\nthe observed levels at low (high) frequencies. At low frequencies, ASTRID\npredicts that the bulk of the GWB originates from MBHB with masses $M_{\\rm\ntot}=1-3\\times 10^9\\,M_\\odot$ peaking at $z\\approx 0.3$, consistent with\nTNG300. Notably, both simulations predict significant GWB contribution from\nminor mergers ($q<0.2$) by up to $\\sim 40\\%$. By tracing the full merger trees\nof local MBHs in ASTRID, we show that they generate GWs at $\\sim 10\\%-80\\%$ of\nthe maximum signal assuming no accretion and recent equal-mass mergers.\nFinally, we demonstrate the importance of on-the-fly MBH dynamics, the lack of\nwhich leads to $3- 5$ times excessive mass growth by merger, and a similar\nboost to the GWB prediction."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-775",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09874",
    "b_title":[
      "Phase-Shifted Bell States"
    ],
    "b_abstract":[
      "Inspired by previous studies and pioneers of the field, we present new\nresults on an extensive EPR-Bell experiment using photons generated by\nparametric down conversion, where one of the photons is deliberately\nphase-shifted. Our experiments show some surprising results for particular\nangles of this phase shift."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03164",
    "c_title":[
      "Machine Learning for Estimation and Control of Quantum Systems"
    ],
    "c_abstract":[
      "The development of quantum technologies relies on creating and manipulating\nquantum systems of increasing complexity, with key applications in computation,\nsimulation, and sensing. This poses severe challenges in efficient control,\ncalibration, and validation of quantum states and their dynamics. Machine\nlearning methods have emerged as powerful tools owing to their remarkable\ncapability to learn from data, and thus have been extensively utilized for\ndifferent quantum tasks. This paper reviews several significant topics related\nto machine learning-aided quantum estimation and control. In particular, we\ndiscuss neural networks-based learning for quantum state estimation,\ngradient-based learning for optimal control of quantum systems, evolutionary\ncomputation for learning control of quantum systems, machine learning for\nquantum robust control, and reinforcement learning for quantum control. This\nreview provides a brief background of key concepts recurring across many of\nthese approaches with special emphasis on neural networks, evolutionary\ncomputation, and reinforcement learning."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-776",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17180",
    "b_title":[
      "Chlorine abundances in star-forming regions of the local Universe"
    ],
    "b_abstract":[
      "Aims. We study the behaviour of Cl abundance and its ratios with respect to\nO, S and Ar abundances in a sample of more than 200 spectra of Galactic and\nextragalactic H ii regions and star-forming galaxies (SFGs) of the local\nUniverse. Methods. We use the DEep Spectra of Ionised REgions Database\n(DESIRED) Extended project (DESIRED-E) that comprises more than 2000 spectra of\nH ii regions and SFGs with direct determinations of electron temperature\n($T_e$). From this database we select those spectra where it is possible to\ndetermine the Cl$^{2+}$ abundance and whose line ratios meet certain\nobservational criteria. We calculate the physical conditions and Cl, O, S and\nAr abundances in an homogeneous manner for all the spectra. We compare with\nresults of photoionisation models to carry out an analysis of which is the most\nappropriate $T_e$ indicator for the nebular volume where Cl$^{2+}$ lies,\nproposing a scheme that improves the determination of the Cl$^{2+}$ abundance.\nWe compare the Cl\/O ratios obtained using two different ionisation correction\nfactor (ICF) schemes. We also compare the nebular Cl\/O distribution with\nstellar determinations. Results. Our analysis indicates that the ICF scheme\nproposed by Izotov et al. (2006) better reproduces the observed distributions\nof the Cl\/O ratio. We find that the log(Cl\/O) vs. 12+log(O\/H) and log(Cl\/Ar)\nvs. 12+log(Ar\/H) distributions are not correlated in the whole metallicity\nrange covered by our objects indicating a lockstep evolution of those elements.\nIn contrast, the log(Cl\/S) vs. 12+log(S\/H) distribution shows a weak\ncorrelation with a slight negative slope."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.15335",
    "c_title":[
      "Euclid: Quick Data Release (Q1) -- A census of dwarf galaxies across a\n  range of distances and environments"
    ],
    "c_abstract":[
      "The Euclid Q1 fields were selected for calibration purposes in cosmology and\nare therefore relatively devoid of nearby galaxies. However, this is precisely\nwhat makes them interesting fields in which to search for dwarf galaxies in\nlocal density environments. We take advantage of the unprecedented depth,\nspatial resolution, and field of view of the Euclid Quick Release (Q1) to build\na census of dwarf galaxies in these regions. We have identified dwarfs in a\nrepresentative sample of 25 contiguous tiles in the Euclid Deep Field North\n(EDF-N), covering an area of 14.25 sq. deg. The dwarf candidates were\nidentified using a semi-automatic detection method, based on properties\nmeasured by the Euclid pipeline and listed in the MER catalogue. A selection\ncut in surface brightness and magnitude was used to produce an initial dwarf\ncandidate catalogue, followed by a cut in morphology and colour. This catalogue\nwas visually classified to produce a final sample of dwarf candidates,\nincluding their morphology, number of nuclei, globular cluster (GC) richness,\nand presence of a blue compact centre. We identified 2674 dwarf candidates,\ncorresponding to 188 dwarfs per sq. deg. The visual classification of the\ndwarfs reveals a slightly uneven morphological mix of 58% ellipticals and 42%\nirregulars, with very few potentially GC-rich (1.0%) and nucleated (4.0%)\ncandidates but a noticeable fraction (6.9%) of dwarfs with blue compact\ncentres. The distance distribution of 388 (15%) of the dwarfs with\nspectroscopic redshifts peaks at about 400 Mpc. Their stellar mass distribution\nconfirms that our selection effectively identifies dwarfs while minimising\ncontamination. The most prominent dwarf overdensities are dominated by dEs,\nwhile dIs are more evenly distributed. This work highlights Euclid's remarkable\nability to detect and characterise dwarf galaxies across diverse masses,\ndistances, and environments."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-777",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10921",
    "b_title":[
      "Semicomplete multipartite weakly distance-regular digraphs"
    ],
    "b_abstract":[
      "A digraph is semicomplete multipartite if its underlying graph is a complete\nmultipartite graph. As a special case of semicomplete multipartite digraphs,\nJ{\\o}rgensen et al. \\cite{JG14} initiated the study of doubly regular team\ntournaments. As a natural extension, we introduce doubly regular team\nsemicomplete multipartite digraphs and show that such digraphs fall into three\ntypes. Furthermore, we give a characterization of all semicomplete multipartite\ncommutative weakly distance-regular digraphs."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.05123",
    "c_title":[
      "D-Antimagic Labelings of Oriented 2-Regular Graphs"
    ],
    "c_abstract":[
      "Given an oriented graph $\\overrightarrow{G}$ and $D$ a distance set of\n$\\overrightarrow{G}$, $\\overrightarrow{G}$ is $D$-antimagic if there exists a\nbijective vertex labeling such that the sum of all labels of the\n$D$-out-neighbors of each vertex is distinct.\n  This paper investigates $D$-antimagic labelings of 2-regular oriented graphs.\nWe characterize $D$-antimagic oriented cycles, when $|D|=1$; $D$-antimagic\nunidirectional odd cycles, when $|D|=2$; and $D$-antimagic $\\Theta$-oriented\ncycles. Finally, we characterize $D$-antimagic oriented 2-regular graphs, when\n$|D|=1$, and $D$-antimagic $\\Theta$-oriented 2-regular graphs."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-778",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17997",
    "b_title":[
      "COSMIC's Large-Scale Search for Technosignatures during the VLA sky\n  Survey: Survey Description and First Results"
    ],
    "b_abstract":[
      "Developing algorithms to search through data efficiently is a challenging\npart of searching for signs of technology beyond our solar system. We have\nbuilt a digital signal processing system and computer cluster on the backend of\nthe Karl G. Jansky Very Large Array (VLA) in New Mexico in order to search for\nsignals throughout the Galaxy consistent with our understanding of artificial\nradio emissions. In our first paper, we described the system design and\nsoftware pipelines. In this paper, we describe a postprocessing pipeline to\nidentify persistent sources of interference, filter out false positives, and\nsearch for signals not immediately identifiable as anthropogenic radio\nfrequency interference during the VLA Sky Survey. As of 01 September 2024, the\nCommensal Open-source Multi-mode Interferometric Cluster had observed more than\n950,000 unique pointings. This paper presents the strategy we employ when\ncommensally observing during the VLA Sky Survey and a postprocessing strategy\nfor the data collected during the survey. To test this postprocessing pipeline,\nwe searched toward 511 stars from the $Gaia$ catalog with coherent beams. This\nrepresents about 30 minutes of observation during VLASS, where we typically\nobserve about 2000 sources per hour in the coherent beamforming mode. We did\nnot detect any unidentifiable signals, setting isotropic power limits ranging\nfrom 10$^{11}$ to 10$^{16}$W."
    ],
    "b_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.12499",
    "c_title":[
      "Multiband Embeddings of Light Curves"
    ],
    "c_abstract":[
      "In this work, we propose a novel ensemble of recurrent neural networks (RNNs)\nthat considers the multiband and non-uniform cadence without having to compute\ncomplex features. Our proposed model consists of an ensemble of RNNs, which do\nnot require the entire light curve to perform inference, making the inference\nprocess simpler. The ensemble is able to adapt to varying numbers of bands,\ntested on three real light curve datasets, namely Gaia, Pan-STARRS1, and ZTF,\nto demonstrate its potential for generalization. We also show the capabilities\nof deep learning to perform not only classification, but also regression of\nphysical parameters such as effective temperature and radius. Our ensemble\nmodel demonstrates superior performance in scenarios with fewer observations,\nthus providing potential for early classification of sources from facilities\nsuch as Vera C. Rubin Observatory's LSST. The results underline the model's\neffectiveness and flexibility, making it a promising tool for future\nastronomical surveys. Our research has shown that a multitask learning approach\ncan enrich the embeddings obtained by the models, making them instrumental to\nsolve additional tasks, such as determining the orbital parameters of binary\nsystems or estimating parameters for object types beyond periodic ones."
    ],
    "c_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-779",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06985",
    "b_title":[
      "\"It's Great Because It's Ran By Us\": Empowering Teen Volunteer Discord\n  Moderators to Design Healthy and Engaging Youth-Led Online Communities"
    ],
    "b_abstract":[
      "Online communities can offer many benefits for youth including peer learning,\ncultural expression, and skill development. However, most HCI research on\nyouth-focused online communities has centered communities developed by adults\nfor youth rather than by the youth themselves. In this work, we interviewed 11\nteenagers (ages 13-17) who moderate online Discord communities created by\nyouth, for youth. Participants were identified by Discord platform staff as\nleaders of well-moderated servers through an intensive exam and\napplication-based process. We also interviewed 2 young adults who volunteered\nas mentors of some of our teen participants. We present our findings about the\nbenefits, motivations, and risks of teen-led online communities, as well as the\nrole of external stakeholders of these youth spaces. We contextualize our work\nwithin the broader teen online safety landscape to provide recommendations to\nbetter support, encourage, and protect teen moderators and their online\ncommunities. This empirical work contributes one of the first studies to date\nwith teen Discord moderators and aims to empower safe youth-led online\ncommunities."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09204",
    "c_title":[
      "3D Printed Maps and Icons for Inclusion: Testing in the Wild by People\n  who are Blind or have Low Vision"
    ],
    "c_abstract":[
      "The difficulty and consequent fear of travel is one of the most disabling\nconsequences of blindness and severe vision impairment, affecting confidence\nand quality of life. Traditional tactile graphics are vital in the Orientation\nand Mobility training process, however 3D printing may have the capacity to\nenable production of more meaningful and inclusive maps. This study explored\nthe use of 3D printed maps on site at a public event to examine their\nsuitability and to identify guidelines for the design of future 3D maps. An\niterative design process was used in the production of the 3D maps, with\nfeedback from visitors who are blind or have low vision informing the\nrecommendations for their design and use. For example, it was found that many\nrepresentational 3D icons could be recognised by touch without the need for a\nkey and that such a map helped form mental models of the event space. Complex\nmaps, however, require time to explore and should be made available before an\nevent or at the entrance in a comfortable position. The maps were found to\nsupport the orientation and mobility process, and importantly to also promote a\npositive message about inclusion and accessibility."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-780",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07999",
    "b_title":[
      "Infrastructures for Inspiration: The Routine Construction of Creative\n  Identity and Inspiration"
    ],
    "b_abstract":[
      "Online, visual artists have more places than ever to routinely share their\ncreative work and connect with other artists. These interactions support the\nroutine enactment of creative identity in artists and provide inspirational\nopportunities for artists. As creative work shifts online, interactions between\nartists and routines around how these artists get inspired to do creative work\nare mediated by and through the logics of the online platforms where they take\nplace. In an interview study of 22 artists, this paper explores the interplay\nbetween the development of artists' creative identities and the, at times,\ncontradictory practices they have around getting inspired. We find platforms\nwhich support the disciplined practice of creative work while supporting\nspontaneous moments of inspiration, play an increasing role in passive\napproaches to searching for inspiration, and foster numerous small community\nspaces for artists to negotiate their creative identities. We discuss how\nplatforms can better support and embed mechanisms for inspiration into their\ninfrastructures into their design and platform policy."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04543",
    "c_title":[
      "The Impostor is Among Us: Can Large Language Models Capture the\n  Complexity of Human Personas?"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) created new opportunities for generating\npersonas, which are expected to streamline and accelerate the human-centered\ndesign process. Yet, AI-generated personas may not accurately represent actual\nuser experiences, as they can miss contextual and emotional insights critical\nto understanding real users' needs and behaviors. This paper examines the\ndifferences in how users perceive personas created by LLMs compared to those\ncrafted by humans regarding their credibility for design. We gathered ten\nhuman-crafted personas developed by HCI experts according to relevant\nattributes established in related work. Then, we systematically generated ten\npersonas and compared them with human-crafted ones in a survey. The results\nshowed that participants differentiated between human-created and AI-generated\npersonas, with the latter being perceived as more informative and consistent.\nHowever, participants noted that the AI-generated personas tended to follow\nstereotypes, highlighting the need for a greater emphasis on diversity when\nutilizing LLMs for persona creation."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-781",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17526",
    "b_title":[
      "Amplified quantum battery via dynamical modulation"
    ],
    "b_abstract":[
      "We investigate the charging dynamics of a frequency-modulated quantum battery\n(QB) placed within a dissipative cavity environment. Our study focuses on the\ninteraction of such a battery under both weak and strong coupling regimes,\nemploying a model in which the quantum battery and charger are represented as\nfrequency-modulated qubits indirectly coupled through a zero-temperature\nenvironment. It is demonstrated that both the modulation frequency and\namplitude are crucial for optimizing the charging process and the ergotropy of\nthe quantum battery. Specifically, high-amplitude, low-frequency modulation\nsignificantly enhances charging performance and work extraction in the strong\ncoupling regime. As an intriguing result, it is deduced that modulation at very\nlow frequencies leads to the emergence of energy storage and work extraction in\nthe weak coupling regime. Such a result can never be achieved without\nmodulation in the weak coupling regime. These results highlight the importance\nof adjusting modulation parameters to optimize the performance of quantum\nbatteries for real-world applications in quantum technologies."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07770",
    "c_title":[
      "Quantum learning advantage on a scalable photonic platform"
    ],
    "c_abstract":[
      "Recent advancements in quantum technologies have opened new horizons for\nexploring the physical world in ways once deemed impossible. Central to these\nbreakthroughs is the concept of quantum advantage, where quantum systems\noutperform their classical counterparts in solving specific tasks. While much\nattention has been devoted to computational speedups, quantum advantage in\nlearning physical systems remains a largely untapped frontier. Here, we present\na photonic implementation of a quantum-enhanced protocol for learning the\nprobability distribution of a multimode bosonic displacement process. By\nharnessing the unique properties of continuous-variable quantum entanglement,\nwe obtain a massive advantage in sample complexity with respect to conventional\nmethods without entangled resources. With approximately 5 dB of two-mode\nsqueezing -- corresponding to imperfect Einstein--Podolsky--Rosen (EPR)\nentanglement -- we learn a 100-mode bosonic displacement process using 11.8\norders of magnitude fewer samples than a conventional scheme. Our results\ndemonstrate that even with non-ideal, noisy entanglement, a significant quantum\nadvantage can be realized in continuous-variable quantum systems. This marks an\nimportant step towards practical quantum-enhanced learning protocols with\nimplications for quantum metrology, certification, and machine learning."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-782",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09281",
    "b_title":[
      "Crowdsourced Homophily Ties Based Graph Annotation Via Large Language\n  Model"
    ],
    "b_abstract":[
      "Accurate graph annotation typically requires substantial labeled data, which\nis often challenging and resource-intensive to obtain. In this paper, we\npresent Crowdsourced Homophily Ties Based Graph Annotation via Large Language\nModel (CSA-LLM), a novel approach that combines the strengths of crowdsourced\nannotations with the capabilities of large language models (LLMs) to enhance\nthe graph annotation process. CSA-LLM harnesses the structural context of graph\ndata by integrating information from 1-hop and 2-hop neighbors. By emphasizing\nhomophily ties - key connections that signify similarity within the graph -\nCSA-LLM significantly improves the accuracy of annotations. Experimental\nresults demonstrate that this method enhances the performance of Graph Neural\nNetworks (GNNs) by delivering more precise and reliable annotations."
    ],
    "b_categories":[
      [
        "cs.SI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09585",
    "c_title":[
      "Hierarchical community detection benchmark for heterogeneous\n  inter-community connectivity"
    ],
    "c_abstract":[
      "Here, we introduce a new tool for community detection, a generator of\nnetworks, which uses parameters to control the structure of created networks.\nTypically, network scientists designing novel community detection algorithms\nuse synthetically generated benchmarks with community structures that they\nintend to detect and scale the benchmark networks across size and density.\nCurrently, available benchmarks use generators limited to the properties of the\nLFR and GLFR networks. We improve on these previous benchmarks with a new\nhierarchical benchmark, the HGLFR, that preserves the properties of the LFR and\nGLFR while extending them to include heterogeneous inter-community\nconnectivity. Networks generated by this benchmark are shown to produce\nnetworks with structures triggering the resolution limit while maintaining\nassortative connectivity."
    ],
    "c_categories":[
      [
        "cs.SI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-783",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02356",
    "b_title":[
      "Efficient Long Context Fine-tuning with Chunk Flow"
    ],
    "b_abstract":[
      "Long context fine-tuning of large language models(LLMs) involves training on\ndatasets that are predominantly composed of short sequences and a small\nproportion of longer sequences. However, existing approaches overlook this\nlong-tail distribution and employ training strategies designed specifically for\nlong sequences. Moreover, these approaches also fail to address the challenges\nposed by variable sequence lengths during distributed training, such as load\nimbalance in data parallelism and severe pipeline bubbles in pipeline\nparallelism. These issues lead to suboptimal training performance and poor GPU\nresource utilization. To tackle these problems, we propose a chunk-centric\ntraining method named ChunkFlow. ChunkFlow reorganizes input sequences into\nuniformly sized chunks by consolidating short sequences and splitting longer\nones. This approach achieves optimal computational efficiency and balance among\ntraining inputs. Additionally, ChunkFlow incorporates a state-aware chunk\nscheduling mechanism to ensure that the peak memory usage during training is\nprimarily determined by the chunk size rather than the maximum sequence length\nin the dataset. Integrating this scheduling mechanism with existing pipeline\nscheduling algorithms further enhances the performance of distributed training.\nExperimental results demonstrate that, compared with Megatron-LM, ChunkFlow can\nbe up to 4.53x faster in the long context fine-tuning of LLMs. Furthermore, we\nbelieve that ChunkFlow serves as an effective solution for a broader range of\nscenarios, such as long context continual pre-training, where datasets contain\nvariable-length sequences."
    ],
    "b_categories":[
      [
        "cs.DC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07391",
    "c_title":[
      "Availability Modeling for Blockchain Provisioning in Private Clouds"
    ],
    "c_abstract":[
      "Blockchain technology has emerged, and many previous studies have assessed\nits performance issues. However, less attention has been paid to the\ndependability attributes, which have been a critical topic in service\nprovisioning, considering public or private infrastructures. This paper\nintroduces analytical models to assess the availability of private blockchain\ninfrastructure for Hyperledger Fabric-based applications. Furthermore, a case\nstudy will be presented to demonstrate the feasibility of the proposed model,\nwhich may assist stakeholders in deciding whether to migrate from old to new\ntechnology. Some of the obtained results indicate that, unlike most\nconventional systems, general availability may decrease as new nodes are added\nto the environment. This phenomenon occurs due to the adopted endorsement\npolicy, which determines the proportion of required nodes to sign the\nauthenticity of a transaction."
    ],
    "c_categories":[
      [
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-784",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08712",
    "b_title":[
      "The AURORA Survey: The Evolution of Multi-phase Electron Densities at\n  High Redshift"
    ],
    "b_abstract":[
      "We present an analysis of deep $\\textit{JWST}$\/NIRSpec spectra of\nstar-forming galaxies at $z\\simeq1.4-10$, observed as part of the AURORA\nsurvey. We infer median low-ionization electron densities of\n$268_{-49}^{+45}~\\rm cm^{-3}$, $350_{-76}^{+140}~\\rm cm^{-3}$, and\n$480_{-310}^{+390}~\\rm cm^{-3}$ at redshifts z$=2.3$, $z=3.2$, and $z=5.3$,\nrespectively, revealing an evolutionary trend following $(1+z)^{1.5\\pm0.6}$. We\nidentify weak positive correlations between electron density and star formation\nrate (SFR) as well as SFR surface density, but no significant trends with\nstellar mass or specific SFR. Correlations with rest-optical emission line\nratios show densities increasing with $\\rm [NeIII]\\lambda3869\/[OII]\\lambda3727$\nand, potentially, $\\rm [OIII]\\lambda5007\/[OII]\\lambda3727$, although variations\nin dust attenuation complicate the latter. Additionally, electron density is\nmore strongly correlated with distance from the local BPT sequence than can be\nexplained by simple photoionization models. We further derive electron\ndensities from the CIII] doublet probing higher-ionization gas, and find a\nmedian value of $1.4_{-0.5}^{+0.7}\\times10^4~\\rm cm^{-3}$, $\\sim30$ times\nhigher than densities inferred from [SII]. This comparison suggests a\nconsistent HII region structure across cosmic time with dense, high-ionization\ninteriors surrounded by less dense, low-ionization gas. We compare measurements\nof AURORA galaxies to predictions from the SPHINX galaxy formations,\nhighlighting the interplay between residual molecular cloud pressure in young\ngalaxies and feedback from stellar winds and supernovae as galaxies mature."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.14174",
    "c_title":[
      "Discovery of a Giant Molecular Cloud at the Midpoint of the Galactic Bar\n  Dust Lanes: M4.7-0.8"
    ],
    "c_abstract":[
      "We present the detection of a previously unknown giant molecular cloud (GMC)\nlocated at the midpoint of the Galactic Bar Dust Lanes (M4.7--0.8), using\nspectral line observations taken with the Green Bank Telescope (GBT). This\n$\\sim$60 pc long GMC is associated with accreting material that is\ntransitioning from the quieter Galactic disk environment to the more extreme\ncentral molecular zone (CMZ) environment. Our 24 GHz single-dish radio\nobservations targeted the NH$_3$ (1,1)$-$(4,4) and HC$_5$N (9$-$8), known dense\ngas tracers. The observations reveal the main features of the GMC, which we\nhave dubbed the `Nexus' and `Filament', covering a\n0$.\\!\\!^\\circ$5$\\times$0$.\\!\\!^\\circ$25 area at 31$''$ angular resolution. In\nthis publication we investigate the gas kinematics within the observed region\nand compare the distribution of molecular emission to previous infrared surveys\nto better understand the dust component. The observed gas tracers show\ncentrally condensed cores corresponding to the positions of high dust column\ndensities and low dust temperatures. We report the detection of a previously\nunknown NH$_3$ (3,3) maser, along with a 70$\\mu$m source association, which\nsupports the identification of this region as being actively star-forming. Gas\nemission in this region shows broad linewidths, comparable to values seen in\nCMZ clouds. The overall description of this cloud that we present is that of a\nhighly dynamic region comprising dense gas and dust. This encapsulates a wide\nrange of features associated with star formation, in addition to material\ntransport related to the CMZ."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-785",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14482",
    "b_title":[
      "ICE-Bench: A Unified and Comprehensive Benchmark for Image Creating and\n  Editing"
    ],
    "b_abstract":[
      "Image generation has witnessed significant advancements in the past few\nyears. However, evaluating the performance of image generation models remains a\nformidable challenge. In this paper, we propose ICE-Bench, a unified and\ncomprehensive benchmark designed to rigorously assess image generation models.\nIts comprehensiveness could be summarized in the following key features: (1)\nCoarse-to-Fine Tasks: We systematically deconstruct image generation into four\ntask categories: No-ref\/Ref Image Creating\/Editing, based on the presence or\nabsence of source images and reference images. And further decompose them into\n31 fine-grained tasks covering a broad spectrum of image generation\nrequirements, culminating in a comprehensive benchmark. (2) Multi-dimensional\nMetrics: The evaluation framework assesses image generation capabilities across\n6 dimensions: aesthetic quality, imaging quality, prompt following, source\nconsistency, reference consistency, and controllability. 11 metrics are\nintroduced to support the multi-dimensional evaluation. Notably, we introduce\nVLLM-QA, an innovative metric designed to assess the success of image editing\nby leveraging large models. (3) Hybrid Data: The data comes from real scenes\nand virtual generation, which effectively improves data diversity and\nalleviates the bias problem in model evaluation. Through ICE-Bench, we conduct\na thorough analysis of existing generation models, revealing both the\nchallenging nature of our benchmark and the gap between current model\ncapabilities and real-world generation requirements. To foster further\nadvancements in the field, we will open-source ICE-Bench, including its\ndataset, evaluation code, and models, thereby providing a valuable resource for\nthe research community."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16022",
    "c_title":[
      "SketchYourSeg: Mask-Free Subjective Image Segmentation via Freehand\n  Sketches"
    ],
    "c_abstract":[
      "We introduce SketchYourSeg, a novel framework that establishes freehand\nsketches as a powerful query modality for subjective image segmentation across\nentire galleries through a single exemplar sketch. Unlike text prompts that\nstruggle with spatial specificity or interactive methods confined to\nsingle-image operations, sketches naturally combine semantic intent with\nstructural precision. This unique dual encoding enables precise visual\ndisambiguation for segmentation tasks where text descriptions would be\ncumbersome or ambiguous -- such as distinguishing between visually similar\ninstances, specifying exact part boundaries, or indicating spatial\nrelationships in composed concepts. Our approach addresses three fundamental\nchallenges: (i) eliminating the need for pixel-perfect annotation masks during\ntraining with a mask-free framework; (ii) creating a synergistic relationship\nbetween sketch-based image retrieval (SBIR) models and foundation models\n(CLIP\/DINOv2) where the former provides training signals while the latter\ngenerates masks; and (iii) enabling multi-granular segmentation capabilities\nthrough purpose-made sketch augmentation strategies. Our extensive evaluations\ndemonstrate superior performance over existing approaches across diverse\nbenchmarks, establishing a new paradigm for user-guided image segmentation that\nbalances precision with efficiency."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-786",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01206",
    "b_title":[
      "PerfSeer: An Efficient and Accurate Deep Learning Models Performance\n  Predictor"
    ],
    "b_abstract":[
      "Predicting the performance of deep learning (DL) models, such as execution\ntime and resource utilization, is crucial for Neural Architecture Search (NAS),\nDL cluster schedulers, and other technologies that advance deep learning. The\nrepresentation of a model is the foundation for its performance prediction.\nHowever, existing methods cannot comprehensively represent diverse model\nconfigurations, resulting in unsatisfactory accuracy. To address this, we\nrepresent a model as a graph that includes the topology, along with the node,\nedge, and global features, all of which are crucial for effectively capturing\nthe performance of the model. Based on this representation, we propose\nPerfSeer, a novel predictor that uses a Graph Neural Network (GNN)-based\nperformance prediction model, SeerNet. SeerNet fully leverages the topology and\nvarious features, while incorporating optimizations such as Synergistic\nMax-Mean aggregation (SynMM) and Global-Node Perspective Boost (GNPB) to\ncapture the critical performance information more effectively, enabling it to\npredict the performance of models accurately. Furthermore, SeerNet can be\nextended to SeerNet-Multi by using Project Conflicting Gradients (PCGrad),\nenabling efficient simultaneous prediction of multiple performance metrics\nwithout significantly affecting accuracy. We constructed a dataset containing\nperformance metrics for 53k+ model configurations, including execution time,\nmemory usage, and Streaming Multiprocessor (SM) utilization during both\ntraining and inference. The evaluation results show that PerfSeer outperforms\nnn-Meter, Brp-NAS, and DIPPM."
    ],
    "b_categories":[
      [
        "cs.PF"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00408",
    "c_title":[
      "A Microbenchmark Framework for Performance Evaluation of OpenMP Target\n  Offloading"
    ],
    "c_abstract":[
      "We present a framework based on Catch2 to evaluate performance of OpenMP's\ntarget offload model via micro-benchmarks. The compilers supporting OpenMP's\ntarget offload model for heterogeneous architectures are currently undergoing\nrapid development. These developments influence performance of various complex\napplications in different ways. This framework can be employed to track the\nimpact of compiler upgrades and compare their performance with the native\nprogramming models. We use the framework to benchmark performance of a few\ncommonly used operations on leadership class supercomputers such as Perlmutter\nat National Energy Research Scientific Computing (NERSC) Center and Frontier at\nOak Ridge Leadership Computing Facility (OLCF). Such a framework will be useful\nfor compiler developers to gain insights into the overall impact of many small\nchanges, as well as for users to decide which compilers and versions are\nexpected to yield best performance for their applications."
    ],
    "c_categories":[
      [
        "cs.PF"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-787",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03850",
    "b_title":[
      "Code in Motion: Integrating Computational Thinking with Kinematics\n  Exploration"
    ],
    "b_abstract":[
      "Although physics has become increasingly computational, with computing even\nbeing considered the third pillar of physics [1], it is still not well\nintegrated into physics education [2]. Research suggests that integrating\nComputational Thinking (CT) into physics enhances conceptual understanding and\nstrengthens students ability to model and analyze phenomena [3]. Building on\nthis, we designed a didactic sequence for K9 students to foster specific CT\npractices while reinforcing fundamental kinematics concepts. Assessments\nhighlight student's ability to apply CT skills to analyze accelerated motion.\nThis activity can be seamlessly integrated into introductory kinematics\ncourses."
    ],
    "b_categories":[
      [
        "physics.ed-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.01893",
    "c_title":[
      "Adding an Einsteinian motivation to key discussions in an\n  electromagnetism course"
    ],
    "c_abstract":[
      "This paper aims to provide physics teachers with tools to help deepen the\nunderstanding of the laws of electromagnetism. The fundamental contributions of\nour proposal are: a) to use quotes from mythical characters in the history of\nscience as a motivating educational resource; b) to promote the discussion of\nstriking and fundamental topics; c) to mention diverse approaches and stimulate\nthe search for correct answers to provocative questions. Citations from\nEinstein refer to principal contributions made by Newton, Maxwell and himself.\nEmphasis is placed on the cognitive value of differential (local,\ninfinitesimal) analysis of fundamental concepts (field structure, causality,\nfield relativistic transformations). The unity of electromagnetism is analyzed\nfrom the point of view of special relativity. It is clarified that descriptions\nsuggesting that the magnetic field is dispensable are contrary to the\nEinstenian approach: they assume that, to describe the interaction between\nmoving charges, there is a preferred coordinate system for each particular\nproblem. An introductory presentation of the tensor form of Maxwell equations\nis provided."
    ],
    "c_categories":[
      [
        "physics.ed-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-788",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15917",
    "b_title":[
      "RIS Assisted Wireless Communication: Advanced Modeling, Simulation, and\n  Analytical Insights"
    ],
    "b_abstract":[
      "This article presents a novel perspective to model and simulate\nreconfigurable intelligent surface (RIS)-assisted communication systems.\nTraditional methods in antenna design often rely on array method to simulate,\nwhereas communication system modeling tends to idealize antenna behavior.\nNeither approach sufficiently captures the detailed characteristics of\nRIS-assisted communication. To address this limitation, we propose a\ncomprehensive simulation framework that jointly models RIS antenna design and\nthe communication process. This framework simulates the entire communication\npipeline, encompassing signal generation, modulation, propagation, RIS-based\nradiation, signal reception, alignment, demodulation, decision, and processing.\nUsing a QPSK-modulated signal for validation, we analyze system performance and\ninvestigate the relationship between bit error rate (BER), aperture fill time,\narray size, and baseband symbol frequency. The results indicate that larger\narray sizes and higher baseband symbol frequencies exacerbate aperture fill\ntime effects, leading to increased BER. Furthermore, we examine BER variation\nwith respect to signal-to-noise ratio (SNR) and propose an optimal\nmatching-based alignment algorithm, which significantly reduces BER compared to\nconventional pilot-based alignment methods. This work demonstrates the entire\nprocess of RIS communication, and reveals the source of bit errors, which\nprovides valuable insights into the design and performance optimization of\nRIS-assisted communication systems."
    ],
    "b_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.13741",
    "c_title":[
      "Real-Time Cure Monitoring via Carbon Nanotube Networks Enables\n  Mechanical Property Optimization in Post-Cured Epoxy Resins"
    ],
    "c_abstract":[
      "This research presents a single-walled carbon nanotube (SWCNT)-enabled\nreal-time monitoring system to optimize post-curing conditions (temperature and\nduration) for epoxy resin. This method can serve as an alternative to\ntraditional methods like Differential Scanning Calorimetry (DSC), which is\neffective in measuring the degree of cure in polymers during industrial curing\n(manufacturer-recommended cure cycle). Two different programs using SWCNTs were\nemployed to design the cure cycles for investigating the development of\nmechanical properties: Program A as the comparison of effects of varied\nduration of high-temperature curing and Program B as high-temperature curing\nfollowed by the varied duration of low-temperature post-curing. By correlating\nvariation in the electrical resistance of SWCNT with curing stages, we\nillustrate that extending post-curing at 100{\\deg}C for 24 hours after an\ninitial 3-hour cure at 130{\\deg}C increases tensile strength by 60% and\nelongation by 164% compared to industry standards. This approach not only\nimproves mechanical performance but also enables precise, non-destructive\ncure-state detection, offering a scalable solution for high-performance\ncomposites in the aerospace and automotive sectors."
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-789",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04916",
    "b_title":[
      "Classification or Prompting: A Case Study on Legal Requirements\n  Traceability"
    ],
    "b_abstract":[
      "New regulations are continuously introduced to ensure that software\ndevelopment complies with the ethical concerns and prioritizes public safety. A\nprerequisite for demonstrating compliance involves tracing software\nrequirements to legal provisions. Requirements traceability is a fundamental\ntask where requirements engineers are supposed to analyze technical\nrequirements against target artifacts, often under limited time budget. Doing\nthis analysis manually for complex systems with hundreds of requirements is\ninfeasible. The legal dimension introduces additional challenges that only\nexacerbate manual effort.\n  In this paper, we investigate two automated solutions based on large language\nmodels (LLMs) to predict trace links between requirements and legal provisions.\nThe first solution, Kashif, is a classifier that leverages sentence\ntransformers. The second solution prompts a recent generative LLM based on\nRice, a prompt engineering framework.\n  On a benchmark dataset, we empirically evaluate Kashif and compare it against\na baseline classifier from the literature. Kashif can identify trace links with\nan average recall of ~67%, outperforming the baseline with a substantial gain\nof 54 percentage points (pp) in recall. However, on unseen, more complex\nrequirements documents traced to the European general data protection\nregulation (GDPR), Kashif performs poorly, yielding an average recall of 15%.\nOn the same documents, however, our Rice-based solution yields an average\nrecall of 84%, with a remarkable gain of about 69 pp over Kashif. Our results\nsuggest that requirements traceability in the legal context cannot be simply\naddressed by building classifiers, as such solutions do not generalize and fail\nto perform well on complex regulations and requirements. Resorting to\ngenerative LLMs, with careful prompt engineering, is thus a more promising\nalternative."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06549",
    "c_title":[
      "How Does Users' App Knowledge Influence the Preferred Level of Detail\n  and Format of Software Explanations?"
    ],
    "c_abstract":[
      "Context and Motivation: Due to their increasing complexity, everyday software\nsystems are becoming increasingly opaque for users. A frequently adopted method\nto address this difficulty is explainability, which aims to make systems more\nunderstandable and usable. Question\/problem: However, explanations can also\nlead to unnecessary cognitive load. Therefore, adapting explanations to the\nactual needs of a user is a frequently faced challenge. Principal\nideas\/results: This study investigates factors influencing users' preferred the\nlevel of detail and the form of an explanation (e.g., short text or video\ntutorial) in software. We conducted an online survey with 58 participants to\nexplore relationships between demographics, software usage, app-specific\nknowledge, as well as their preferred explanation form and level of detail. The\nresults indicate that users prefer moderately detailed explanations in short\ntext formats. Correlation analyses revealed no relationship between\napp-specific knowledge and the preferred level of detail of an explanation, but\nan influence of demographic aspects (like gender) on app-specific knowledge and\nits impact on application confidence were observed, pointing to a possible\nmediated relationship between knowledge and preferences for explanations.\nContribution: Our results show that explanation preferences are weakly\ninfluenced by app-specific knowledge but shaped by demographic and\npsychological factors, supporting the development of adaptive explanation\nsystems tailored to user expertise. These findings support requirements\nanalysis processes by highlighting important factors that should be considered\nin user-centered methods such as personas."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-790",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07861",
    "b_title":[
      "ReARTeR: Retrieval-Augmented Reasoning with Trustworthy Process\n  Rewarding"
    ],
    "b_abstract":[
      "Retrieval-Augmented Generation (RAG) systems for Large Language Models (LLMs)\nhold promise in knowledge-intensive tasks but face limitations in complex\nmulti-step reasoning. While recent methods have integrated RAG with\nchain-of-thought reasoning or test-time search using Process Reward Models\n(PRMs), these approaches encounter challenges such as a lack of explanations,\nbias in PRM training data, early-step bias in PRM scores, and insufficient\npost-training optimization of reasoning potential. To address these issues, we\npropose Retrieval-Augmented Reasoning through Trustworthy Process Rewarding\n(ReARTeR), a framework that enhances RAG systems' reasoning capabilities\nthrough post-training and test-time scaling. At test time, ReARTeR introduces\nTrustworthy Process Rewarding via a Process Reward Model for accurate scalar\nscoring and a Process Explanation Model (PEM) for generating natural language\nexplanations, enabling step refinement. During post-training, it utilizes Monte\nCarlo Tree Search guided by Trustworthy Process Rewarding to collect\nhigh-quality step-level preference data, optimized through Iterative Preference\nOptimization. ReARTeR addresses three core challenges: (1) misalignment between\nPRM and PEM, tackled through off-policy preference learning; (2) bias in PRM\ntraining data, mitigated by balanced annotation methods and stronger\nannotations for challenging examples; and (3) early-step bias in PRM, resolved\nthrough a temporal-difference-based look-ahead search strategy. Experimental\nresults on multi-step reasoning benchmarks demonstrate significant\nimprovements, underscoring ReARTeR's potential to advance the reasoning\ncapabilities of RAG systems."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15718",
    "c_title":[
      "Am I eligible? Natural Language Inference for Clinical Trial Patient\n  Recruitment: the Patient's Point of View"
    ],
    "c_abstract":[
      "Recruiting patients to participate in clinical trials can be challenging and\ntime-consuming. Usually, participation in a clinical trial is initiated by a\nhealthcare professional and proposed to the patient. Promoting clinical trials\ndirectly to patients via online recruitment might help to reach them more\nefficiently. In this study, we address the case where a patient is initiating\ntheir own recruitment process and wants to determine whether they are eligible\nfor a given clinical trial, using their own language to describe their medical\nprofile. To study whether this creates difficulties in the patient trial\nmatching process, we design a new dataset and task, Natural Language Inference\nfor Patient Recruitment (NLI4PR), in which patient language profiles must be\nmatched to clinical trials. We create it by adapting the TREC 2022 Clinical\nTrial Track dataset, which provides patients' medical profiles, and rephrasing\nthem manually using patient language. We also use the associated clinical trial\nreports where the patients are either eligible or excluded. We prompt several\nopen-source Large Language Models on our task and achieve from 56.5 to 71.8 of\nF1 score using patient language, against 64.7 to 73.1 for the same task using\nmedical language. When using patient language, we observe only a small loss in\nperformance for the best model, suggesting that having the patient as a\nstarting point could be adopted to help recruit patients for clinical trials.\nThe corpus and code bases are all freely available on our Github and\nHuggingFace repositories."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-791",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05956",
    "b_title":[
      "Divided powers and K\\\"ahler differentials"
    ],
    "b_abstract":[
      "Divided power algebras form an important variety of non-binary universal\nalgebras. We identify the universal enveloping algebra and K\\\"ahler\ndifferentials associated to a divided power algebra over a general commutative\nring, simplifying and generalizing work of Roby and Dokas."
    ],
    "b_categories":[
      [
        "math.AC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.02830",
    "c_title":[
      "Generic Local Duality and Purity Exponents"
    ],
    "c_abstract":[
      "We prove a form of generic local duality that generalizes a result of Karen\nE. Smith. Specifically, let $R$ be a Noetherian ring, let $P$ be a prime ideal\nof $R$ of height $h$, let $A:=R\/P$, and $W$ be a subset of $R$ that maps onto\n$A\\setminus \\{0\\}$. Suppose that $R_P$ is Cohen-Macaulay, and that $\\omega$ is\na finitely generated $R$-module such that $\\omega_P$ is a canonical module for\n$R_P$. Let $E:=H^h_P(\\omega)$. We show that for every finitely generated\n$R$-module $M$ there exists $g \\in W$ such that for all $j\\geq 0$, $H_P^j(M)_g\n\\cong \\mathrm{Hom}_R(\\mathrm{Ext}_R^{h-j}(M,\\, \\omega),\\, E)_g$, and that,\nmoreover, every $H_P^j(M)_g$ has an ascending filtration by a countable\nsequence of finitely generated submodules such that the factors are finitely\ngenerated free $A_g$-modules. In fact, this sequence may be taken to be\n$\\{\\mathrm{Ann}_{H_P^j(M)_g}P^n\\}_n$. We use this result to study the purity\nexponent for a nonzerodivisor $c$ in a reduced excellent Noetherian ring $R$ of\nprime characteristic $p$, which is the least $e \\in \\mathbb{N}$ such that the\nmap $R \\to R^{1\/p^e}$ with $1 \\mapsto c^{1\/p^e}$ is pure. In particular, in the\ncase where $R$ is a homomorphic image of an excellent Cohen-Macaulay ring and\nis S$_2$, we establish an upper semicontinuity result for the function\n$\\mathfrak{e}_c:\\mathrm{Spec}(R) \\to \\mathbb{N}$, where $\\mathfrak{e}_c(P)$ is\nthe purity exponent for the image of $c$ in $R_P$. This result enables us to\nprove that excellent strongly F-regular rings are very strongly F-regular (also\ncalled F-pure regular). Another consequence is that the F-pure locus is open in\nan S$_2$ ring that is a homomorphic image of an excellent Cohen-Macxaulay ring."
    ],
    "c_categories":[
      [
        "math.AC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-792",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02726",
    "b_title":[
      "Connectivity and matching extendability of optimal $1$-embedded graphs\n  on the torus"
    ],
    "b_abstract":[
      "In this paper, we discuss optimal $1$-toroidal graphs (abbreviated as O1TG),\nwhich are drawn on the torus so that every edge crosses another edge at most\nonce, and has $n$ vertices and exactly $4n$ edges. We first consider\nconnectivity of O1TGs, and give the characterization of O1TGs having\nconnectivity exactly $k$ for each $k\\in \\{4, 5, 6, 8\\}$. In our argument, we\nalso show that there exists no O1TG having connectivity exactly $7$.\nFurthermore, using the result above, we discuss extendability of matchings, and\ngive the characterization of $1$-, $2$- and $3$-extendable O1TGs in turn."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.11675",
    "c_title":[
      "Forcing Quasirandomness in a Regular Tournament"
    ],
    "c_abstract":[
      "A tournament $H$ is said to force quasirandomness if it has the property that\na sequence $(T_n)_{n\\in \\mathbb{N}}$ of tournaments of increasing orders is\nquasirandom if and only if the homomorphism density of $H$ in $T_n$ tends to\n$(1\/2)^{\\binom{v(H)}{2}}$ as $n\\to\\infty$. It was recently shown that there is\nonly one non-transitive tournament with this property. This is in contrast to\nthe analogous problem for graphs, where there are numerous graphs that are\nknown to force quasirandomness and the well known Forcing Conjecture suggests\nthat there are many more. To obtain a richer family of characterizations of\nquasirandomness in tournaments, we propose a variant in which the tournaments\n$(T_n)_{n\\in \\mathbb{N}}$ are assumed to be \"nearly regular.\" We characterize\nthe tournaments on at most 5 vertices which force quasirandomness under this\nstronger assumption."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-793",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11032",
    "b_title":[
      "Exact variance estimation for model-assisted survey estimators using U-\n  and V-statistics"
    ],
    "b_abstract":[
      "Model-assisted estimation combines sample survey data with auxiliary\ninformation to increase precision when estimating finite population quantities.\nAccurately estimating the variance of model-assisted estimators is challenging:\nthe classical approach ignores uncertainty from estimating the working model\nfor the functional relationship between survey and auxiliary variables. This\napproach may be asymptotically valid, but can underestimate variance in\npractical settings with limited sample sizes. In this work, we develop a\nconnection between model-assisted estimation and the theory of U- and\nV-statistics. We demonstrate that when predictions from the working model for\nthe variable of interest can be represented as a U- or V-statistic, the\nresulting model-assisted estimator also admits a U- or V-statistic\nrepresentation. We exploit this connection to derive an improved estimator of\nthe exact variance of such model-assisted estimators. The class of working\nmodels for which this strategy can be used is broad, ranging from linear models\nto modern ensemble methods. We apply our approach to the model-assisted\nestimator constructed with a linear regression working model, commonly referred\nto as the generalized regression estimator, show that it can be re-written as a\nU-statistic, and propose an estimator of its exact variance. We illustrate our\nproposal and compare it against the classical asymptotic variance estimator\nusing household survey data from the American Community Survey."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.10591",
    "c_title":[
      "Analysis and sample-size determination for $2^K$ audit experiments with\n  binary response and application to identification of effect of racial\n  discrimination on access to justice"
    ],
    "c_abstract":[
      "Social scientists have increasingly turned to audit experiments to\ninvestigate discrimination in the market for jobs, loans, housing and other\nopportunities. In a typical audit experiment, researchers assign ``signals''\n(the treatment) to subjects at random and compare success rates across\ntreatment conditions. In the recent past there has been increased interest in\nusing randomized multifactor designs for audit experiments, popularly called\nfactorial experiments, in which combinations of multiple signals are assigned\nto subjects. Although social scientists have manipulated multiple factors like\nrace, gender and income, the analyses have been mostly exploratory in nature.\nIn this paper we lay out a comprehensive methodology for design and analysis of\n$2^K$ factorial designs with binary response using model-free,\nrandomization-based Neymanian inference and demonstrate its application by\nanalyzing the audit experiment reported in Libgober (2020). Specifically, we\nintegrate and extend several sections of the randomization-based,\nfinite-population literature for binary outcomes, including sample size and\npower calculations, and non-linear factorial estimators, extending results."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-794",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12195",
    "b_title":[
      "GeneralizeFormer: Layer-Adaptive Model Generation across Test-Time\n  Distribution Shifts"
    ],
    "b_abstract":[
      "We consider the problem of test-time domain generalization, where a model is\ntrained on several source domains and adjusted on target domains never seen\nduring training. Different from the common methods that fine-tune the model or\nadjust the classifier parameters online, we propose to generate multiple layer\nparameters on the fly during inference by a lightweight meta-learned\ntransformer, which we call \\textit{GeneralizeFormer}. The layer-wise parameters\nare generated per target batch without fine-tuning or online adjustment. By\ndoing so, our method is more effective in dynamic scenarios with multiple\ntarget distributions and also avoids forgetting valuable source distribution\ncharacteristics. Moreover, by considering layer-wise gradients, the proposed\nmethod adapts itself to various distribution shifts. To reduce the\ncomputational and time cost, we fix the convolutional parameters while only\ngenerating parameters of the Batch Normalization layers and the linear\nclassifier. Experiments on six widely used domain generalization datasets\ndemonstrate the benefits and abilities of the proposed method to efficiently\nhandle various distribution shifts, generalize in dynamic scenarios, and avoid\nforgetting."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14018",
    "c_title":[
      "I Want 'Em All (At Once) -- Ultrametric Cluster Hierarchies"
    ],
    "c_abstract":[
      "Hierarchical clustering is a powerful tool for exploratory data analysis,\norganizing data into a tree of clusterings from which a partition can be\nchosen. This paper generalizes these ideas by proving that, for any reasonable\nhierarchy, one can optimally solve any center-based clustering objective over\nit (such as $k$-means). Moreover, these solutions can be found exceedingly\nquickly and are themselves necessarily hierarchical. Thus, given a cluster\ntree, we show that one can quickly access a plethora of new, equally meaningful\nhierarchies. Just as in standard hierarchical clustering, one can then choose\nany desired partition from these new hierarchies. We conclude by verifying the\nutility of our proposed techniques across datasets, hierarchies, and\npartitioning schemes."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-795",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10397",
    "b_title":[
      "Large Model Empowered Metaverse: State-of-the-Art, Challenges and\n  Opportunities"
    ],
    "b_abstract":[
      "The Metaverse represents a transformative shift beyond traditional mobile\nInternet, creating an immersive, persistent digital ecosystem where users can\ninteract, socialize, and work within 3D virtual environments. Powered by large\nmodels such as ChatGPT and Sora, the Metaverse benefits from precise\nlarge-scale real-world modeling, automated multimodal content generation,\nrealistic avatars, and seamless natural language understanding, which enhance\nuser engagement and enable more personalized, intuitive interactions. However,\nchallenges remain, including limited scalability, constrained responsiveness,\nand low adaptability in dynamic environments. This paper investigates the\nintegration of large models within the Metaverse, examining their roles in\nenhancing user interaction, perception, content creation, and service quality.\nTo address existing challenges, we propose a generative AI-based framework for\noptimizing Metaverse rendering. This framework includes a cloud-edge-end\ncollaborative model to allocate rendering tasks with minimal latency, a\nmobility-aware pre-rendering mechanism that dynamically adjusts to user\nmovement, and a diffusion model-based adaptive rendering strategy to fine-tune\nvisual details. Experimental results demonstrate the effectiveness of our\napproach in enhancing rendering efficiency and reducing rendering overheads,\nadvancing large model deployment for a more responsive and immersive Metaverse."
    ],
    "b_categories":[
      [
        "cs.CY"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05698",
    "c_title":[
      "A Conceptual Exploration of Generative AI-Induced Cognitive Dissonance\n  and its Emergence in University-Level Academic Writing"
    ],
    "c_abstract":[
      "The integration of Generative Artificial Intelligence (GenAI) into\nuniversity-level academic writing presents both opportunities and challenges,\nparticularly in relation to cognitive dissonance (CD). This work explores how\nGenAI serves as both a trigger and amplifier of CD, as students navigate\nethical concerns, academic integrity, and self-efficacy in their writing\npractices. By synthesizing empirical evidence and theoretical insights, we\nintroduce a hypothetical construct of GenAI-induced CD, illustrating the\npsychological tension between AI-driven efficiency and the principles of\noriginality, effort, and intellectual ownership. We further discuss strategies\nto mitigate this dissonance, including reflective pedagogy, AI literacy\nprograms, transparency in GenAI use, and discipline-specific task redesigns.\nThese approaches reinforce critical engagement with AI, fostering a balanced\nperspective that integrates technological advancements while safeguarding human\ncreativity and learning. Our findings contribute to ongoing discussions on AI\nin education, self-regulated learning, and ethical AI use, offering a\nconceptual framework for institutions to develop guidelines that align AI\nadoption with academic values."
    ],
    "c_categories":[
      [
        "cs.CY"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-796",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07330",
    "b_title":[
      "Occamy: A 432-Core Dual-Chiplet Dual-HBM2E 768-DP-GFLOP\/s RISC-V System\n  for 8-to-64-bit Dense and Sparse Computing in 12nm FinFET"
    ],
    "b_abstract":[
      "ML and HPC applications increasingly combine dense and sparse memory access\ncomputations to maximize storage efficiency. However, existing CPUs and GPUs\nstruggle to flexibly handle these heterogeneous workloads with consistently\nhigh compute efficiency. We present Occamy, a 432-Core, 768-DP-GFLOP\/s,\ndual-HBM2E, dual-chiplet RISC-V system with a latency-tolerant hierarchical\ninterconnect and in-core streaming units (SUs) designed to accelerate dense and\nsparse FP8-to-FP64 ML and HPC workloads. We implement Occamy's compute chiplets\nin 12 nm FinFET, and its passive interposer, Hedwig, in a 65 nm node. On dense\nlinear algebra (LA), Occamy achieves a competitive FPU utilization of 89%. On\nstencil codes, Occamy reaches an FPU utilization of 83% and a\ntechnology-node-normalized compute density of 11.1 DP-GFLOP\/s\/mm2,leading\nstate-of-the-art (SoA) processors by 1.7x and 1.2x, respectively. On\nsparse-dense linear algebra (LA), it achieves 42% FPU utilization and a\nnormalized compute density of 5.95 DP-GFLOP\/s\/mm2, surpassing the SoA by 5.2x\nand 11x, respectively. On, sparse-sparse LA, Occamy reaches a throughput of up\nto 187 GCOMP\/s at 17.4 GCOMP\/s\/W and a compute density of 3.63 GCOMP\/s\/mm2.\nFinally, we reach up to 75% and 54% FPU utilization on and dense (LLM) and\ngraph-sparse (GCN) ML inference workloads. Occamy's RTL is freely available\nunder a permissive open-source license."
    ],
    "b_categories":[
      [
        "cs.AR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06588",
    "c_title":[
      "Optimizing Energy Efficiency in Subthreshold RISC-V Cores"
    ],
    "c_abstract":[
      "Our goal in this paper is to understand how to maximize energy efficiency\nwhen designing standard-ISA processor cores for subthreshold operation. We\nhence develop a custom subthreshold library and use it to synthesize the\nopen-source RISC-V cores SERV, QERV, PicoRV32, Ibex, Rocket, and two variants\nof Vex, targeting a supply voltage of 300 mV in a commercial 130 nm process.\nSERV, QERV, and PicoRV32 are multi-cycle architectures, while Ibex, Vex, and\nRocket are pipelined architectures.\n  We find that SERV, QERV, PicoRV32, and Vex are Pareto optimal in one or more\nof performance, power, and area. The 2-stage Vex (Vex-2) is the most energy\nefficient core overall, mainly because it uses fewer cycles per instruction\nthan multi-cycle SERV, QERV, and PicoRV32 while retaining similar power\nconsumption. Pipelining increases core area, and we observe that for\nsubthreshold operation, the longer wires of pipelined designs require adding\nbuffers to maintain a cycle time that is low enough to achieve high energy\nefficiency. These buffers limit the performance gains achievable by deeper\npipelining because they result in cycle time no longer scaling proportionally\nwith pipeline stages. The added buffers and the additional area required for\npipelining logic however increase power consumption, and Vex-2 therefore\nprovides similar performance and lower power consumption than the 5-stage cores\nVex-5 and Rocket. A key contribution of this paper is therefore to demonstrate\nthat limited-depth pipelined RISC-V designs hit the sweet spot in balancing\nperformance and power consumption when optimizing for energy efficiency in\nsubthreshold operation."
    ],
    "c_categories":[
      [
        "cs.AR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-797",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13518",
    "b_title":[
      "Rubik's Abstract Polytopes"
    ],
    "b_abstract":[
      "We generalize the Rubik's cube, together with its group of configurations, to\nany abstract regular polytope. After discussing general aspects, we study the\nRubik's simplex of arbitrary dimension and provide a complete description of\nthe associated group. We sketch an analogous argument for the Rubik's hypercube\nas well."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.01020",
    "c_title":[
      "Quadratic Embedding Constants of Strongly Regular Graphs"
    ],
    "c_abstract":[
      "We obtain an explicit formula for the quadratic embedding constant (QEC) of a\nstrongly regular graph $\\mathrm{srg}(n,k,\\lambda,\\mu)$ with $\\mu\\ge1$. By using\nQEC we give a necessary and sufficient condition for a strongly regular graph\nto admit a quadratic embeddingin a Euclidean space."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-798",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00831",
    "b_title":[
      "Waste Not, Want Not; Recycled Gumbel Noise Improves Consistency in\n  Natural Language Generation"
    ],
    "b_abstract":[
      "Consistency in the output of language models is critical for their\nreliability and practical utility. Due to their training objective, language\nmodels learn to model the full space of possible continuations, leading to\noutputs that can vary significantly in style and content, even for similar or\nrepeated inputs. To address this, we propose a novel decoding algorithm that\nenhances response consistency across different prompts with no degradation in\nresponse quality. By incorporating a latent variable into the next-token\nsampling process based on the Gumbel reparametrisation trick, our method\noutperforms standard sampling by up to 10% across semantic and stylistic\nconsistency benchmarks. Additionally, our approach integrates seamlessly with\nexisting sampling methods with negligible computational overhead, providing a\npractical solution for improving the reliability of language model outputs."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15754",
    "c_title":[
      "Weight-based Analysis of Detokenization in Language Models:\n  Understanding the First Stage of Inference Without Inference"
    ],
    "c_abstract":[
      "According to the stages-of-inference hypothesis, early layers of language\nmodels map their subword-tokenized input, which does not necessarily correspond\nto a linguistically meaningful segmentation, to more meaningful representations\nthat form the model's \"inner vocabulary\". Prior analysis of this detokenization\nstage has predominantly relied on probing and interventions such as path\npatching, which involve selecting particular inputs, choosing a subset of\ncomponents that will be patched, and then observing changes in model behavior.\nHere, we show that several important aspects of the detokenization stage can be\nunderstood purely by analyzing model weights, without performing any model\ninference steps. Specifically, we introduce an analytical decomposition of\nfirst-layer attention in GPT-2. Our decomposition yields interpretable terms\nthat quantify the relative contributions of position-related, token-related,\nand mixed effects. By focusing on terms in this decomposition, we discover\nweight-based explanations of attention bias toward close tokens and attention\nfor detokenization."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-799",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07403",
    "b_title":[
      "Opening Krylov space to access all-time dynamics via dynamical\n  symmetries"
    ],
    "b_abstract":[
      "Solving short and long time dynamics of closed quantum many-body systems is\none of the main challenges of both atomic and condensed matter physics. For\nlocally interacting closed systems, the dynamics of local observables can\nalways be expanded into (pseudolocal) eigenmodes of the Liouvillian, so called\ndynamical symmetries. They come in two classes - transient operators, which\ndecay in time and perpetual operators, which either oscillate forever or stay\nthe same (conservation laws). These operators provide a full characterization\nof the dynamics of the system. Deriving these operators, apart from a very\nlimited class of models, has not been possible. Here, we present a method to\nnumerically and analytically derive some of these dynamical symmetries in\ninfinite closed systems by introducing a naturally emergent open boundary\ncondition on the Krylov chain. This boundary condition defines a partitioning\nof the Krylov space into system and environment degrees of freedom, where\nnon-local operators make up an effective bath for the local operators. We\ndemonstrate the practicality of the method on some numerical examples and\nderive analytical results in two idealized cases. Our approach lets us directly\nrelate the operator growth hypothesis to thermalization and exponential decay\nof observables in chaotic systems."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.19137",
    "c_title":[
      "A perturbation theory for multi-time correlation functions in open\n  quantum systems"
    ],
    "c_abstract":[
      "Dynamical maps are the principal subject of the open system theory. Formally,\nthe dynamical map of a given open quantum system is a density matrix\ntransformation that takes any initial state and sends it to the state at a\nlater time. Physically, it encapsulates the system's evolution due to coupling\nwith its environment.\n  Hence, the theory provides a flexible and accurate framework for computing\nexpectation values of open system observables. However, expectation values --\nor more generally, single-time correlation functions -- capture only the\nsimplest aspects of a quantum system's dynamics. A complete characterization\nrequires access to multi-time correlation functions as well. For closed\nsystems, such correlations are well-defined, even though knowledge of the\nsystem's state alone is insufficient to determine them fully. In contrast, the\nstandard dynamical map formalism for open systems does not account for\nmulti-time correlations, as it is fundamentally limited to describing state\nevolution. Here, we extend the scope of open quantum system theory by\ndeveloping a systematic perturbation theory for computing multi-time\ncorrelation functions."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-800",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06377",
    "b_title":[
      "Sets of equiangular lines in dimension $18$ constructed from $A_9 \\oplus\n  A_9 \\oplus A_1$"
    ],
    "b_abstract":[
      "In 2023, Greaves et~al.\\ constructed several sets of 57 equiangular lines in\ndimension 18. Using the concept of switching root introduced by Cao et~al.\\ in\n2021, these sets of equiangular lines are embedded in a lattice of rank 19\nspanned by norm 3 vectors together with a switching root. We characterize this\nlattice as an overlattice of the root lattice $A_9\\oplus A_9\\oplus A_1$, and\nshow that there are at least $246896$ sets of 57 equiangular lines in dimension\n$18$ arising in this way, up to isometry. Additionally, we prove that all of\nthese sets of equiangular lines are strongly maximal. Here, a set of\nequiangular lines is said to be strongly maximal if there is no set of\nequiangular lines properly containing it even if the dimension of the\nunderlying space is increased. Among these sets, there are ones with only six\ndistinct Seidel eigenvalues."
    ],
    "b_categories":[
      [
        "math.CO"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.03193",
    "c_title":[
      "Saturation of 0-1 Matrices"
    ],
    "c_abstract":[
      "A 0-1 matrix $M$ contains a 0-1 matrix $P$ if $M$ has a submatrix $P'$ which\ncan be turned into $P$ by changing some of the ones to zeroes. Matrix $M$ is\n$P$-saturated if $M$ does not contain $P$, but any matrix $M'$ derived from $M$\nby changing a zero to a one must contain $P$. The saturation function\n$sat(n,P)$ is defined as the minimum number of ones of an $n \\times n$\n$P$-saturated 0-1 matrix. Fulek and Keszegh showed that each pattern $P$ has\n$sat(n,P) = O(1)$ or $sat(n,P) = \\Theta(n)$. This leads to the natural problem\nof classifying forbidden 0-1 matrices according to whether they have linear or\nbounded saturation functions. Some progress has been made on this problem:\nmultiple infinite families of matrices with bounded saturation function and\nother families with linear saturation function have been identified. We answer\nthis question for all patterns with at most four ones, as well as several\nspecific patterns with more ones, including multiple new infinite families. We\nalso consider the effects of certain matrix operations, including the Kronecker\nproduct and insertion of empty rows and columns. Additionally, we consider the\nsimpler case of fixing one dimension, extending results of (Fulek and Keszegh,\n2021) and (Berendsohn, 2021). We also generalize some results to\n$d$-dimensional saturation."
    ],
    "c_categories":[
      [
        "math.CO"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-801",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09169",
    "b_title":[
      "Two-party entanglement distribution in XXZ spin chains with the\n  exponential and power-law long-range interactions"
    ],
    "b_abstract":[
      "Entanglement distribution is a fundamental property in quantum many-body\nphysics, but the effect of long-range interactions on the distribution has not\nbeen fully understood. Here, we study long-range two-party entanglement (TPE)\nand explore its distribution properties in XXZ spin chains with the exponential\nand power-law long-range interactions(ELRIs and PLRIs). In the thermodynamic\nlimit case with the ELRIs, the TPE quantified by two-qubit concurrence decays\nexponentially along with two-site distance and the long-range concurrences can\nindicate the paramagnetic-ferromagnetic phase transition. We present a\nfine-grained entanglement distribution relations among the entanglement\ntruncation length, total concurrences and two-tangles in the infinite spin\nchains. Moreover, in the finite XXZ chain with the more common PLRIs, the TPE\ndecays algebraically along with the two-spin distance, and the total\nconcurrence can exhibit a piecewise function with respect to total two-tangles.\nThese new presented TPE distribution relations can be regarded as the\ngeneralization of Koashi-Bu\\v{z}ek-and-Imoto bound for the long-range quantum\nmodels, and have potential applications in quantum information processing."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04425",
    "c_title":[
      "Tensor-Programmable Quantum Circuits for Solving Differential Equations"
    ],
    "c_abstract":[
      "We present a quantum solver for partial differential equations based on a\nflexible matrix product operator representation. Utilizing mid-circuit\nmeasurements and a state-dependent norm correction, this scheme overcomes the\nrestriction of unitary operators. Hence, it allows for the direct\nimplementation of a broad class of differential equations governing the\ndynamics of classical and quantum systems. The capabilities of the framework\nare demonstrated for an example system governed by Euler equations with\nabsorbing boundaries."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-802",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03527",
    "b_title":[
      "Heisenberg and Heisenberg-Like Representations via Hilbert Space Bundle\n  Geometry in the Non-Hermitian Regime"
    ],
    "b_abstract":[
      "The equivalence between the Schr\\\"odinger and Heisenberg representations is a\ncornerstone of quantum mechanics. However, this relationship remains unclear in\nthe non-Hermitian regime, particularly when the Hamiltonian is time-dependent.\nIn this study, we address this gap by establishing the connection between the\ntwo representations, incorporating the metric of the Hilbert space bundle. We\nnot only demonstrate the consistency between the Schr\\\"odinger and Heisenberg\nrepresentations but also present a Heisenberg-like representation grounded in\nthe generalized vielbein formalism, which provides a clear and intuitive\ngeometric interpretation. Unlike the standard Heisenberg representation, where\nthe metric of the Hilbert space is encoded solely in the dual states, the\nHeisenberg-like representation distributes the metric information between both\nthe states and the dual states. Despite this distinction, it retains the same\nHeisenberg equation of motion for operators. Within this formalism, the\nHamiltonian is replaced by a Hermitian counterpart, while the \"non-Hermiticity\"\nis transferred to the operators. Moreover, this approach extends to regimes\nwith a dynamical metric (beyond the pseudo-Hermitian framework) and to systems\ngoverned by time-dependent Hamiltonians."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.14781",
    "c_title":[
      "Cavity polariton blockade for non-local entangling gates with trapped\n  atoms"
    ],
    "c_abstract":[
      "We propose a scheme for realizing multi-qubit entangled W-state and non-local\n$CZ$ and $C_2Z$ gates via a cavity polariton blockade mechanism with a system\nof atomic qubits coupled to a common cavity mode. The polariton blockade is\nachieved by tuning the system, an $N-$qubit register, such that no two atoms\nare simultaneously excited to the qubit excited state, and there is an\neffective coupling only between the ground state and a singly-excited W state\nof the qubit register. The control step requires only an external drive of the\ncavity mode and a global qubit pulse and no individual qubit addressing. We\nanalytically obtain the state preparation error for an $N-$qubit W state which\nscales as $\\sqrt{(1-1\/N)}\/\\sqrt{C}$ where $C$ is the single particle\ncooperativity. We additionally show the application of the polariton blockade\nmechanism in realizing a non-local $CZ$ and $C_2Z$ gate by using a different\nset of computational qubit states, and characterize the gate errors which scale\nas $\\sim 1\/\\sqrt{C}$."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-803",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13855",
    "b_title":[
      "MagicGeo: Training-Free Text-Guided Geometric Diagram Generation"
    ],
    "b_abstract":[
      "Geometric diagrams are critical in conveying mathematical and scientific\nconcepts, yet traditional diagram generation methods are often manual and\nresource-intensive. While text-to-image generation has made strides in\nphotorealistic imagery, creating accurate geometric diagrams remains a\nchallenge due to the need for precise spatial relationships and the scarcity of\ngeometry-specific datasets. This paper presents MagicGeo, a training-free\nframework for generating geometric diagrams from textual descriptions. MagicGeo\nformulates the diagram generation process as a coordinate optimization problem,\nensuring geometric correctness through a formal language solver, and then\nemploys coordinate-aware generation. The framework leverages the strong\nlanguage translation capability of large language models, while formal\nmathematical solving ensures geometric correctness. We further introduce\nMagicGeoBench, a benchmark dataset of 220 geometric diagram descriptions, and\ndemonstrate that MagicGeo outperforms current methods in both qualitative and\nquantitative evaluations. This work provides a scalable, accurate solution for\nautomated diagram generation, with significant implications for educational and\nacademic applications."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.06219",
    "c_title":[
      "VLScene: Vision-Language Guidance Distillation for Camera-Based 3D\n  Semantic Scene Completion"
    ],
    "c_abstract":[
      "Camera-based 3D semantic scene completion (SSC) provides dense geometric and\nsemantic perception for autonomous driving. However, images provide limited\ninformation making the model susceptible to geometric ambiguity caused by\nocclusion and perspective distortion. Existing methods often lack explicit\nsemantic modeling between objects, limiting their perception of 3D semantic\ncontext. To address these challenges, we propose a novel method VLScene:\nVision-Language Guidance Distillation for Camera-based 3D Semantic Scene\nCompletion. The key insight is to use the vision-language model to introduce\nhigh-level semantic priors to provide the object spatial context required for\n3D scene understanding. Specifically, we design a vision-language guidance\ndistillation process to enhance image features, which can effectively capture\nsemantic knowledge from the surrounding environment and improve spatial context\nreasoning. In addition, we introduce a geometric-semantic sparse awareness\nmechanism to propagate geometric structures in the neighborhood and enhance\nsemantic information through contextual sparse interactions. Experimental\nresults demonstrate that VLScene achieves rank-1st performance on challenging\nbenchmarks--SemanticKITTI and SSCBench-KITTI-360, yielding remarkably mIoU\nscores of 17.52 and 19.10, respectively."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-804",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07586",
    "b_title":[
      "Hyperplane sections of cubic threefolds"
    ],
    "b_abstract":[
      "Let X be a smooth cubic hypersurface. We prove that a general cubic surface\nis isomorphic to a hyperplane section of X ."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.00696",
    "c_title":[
      "On Almost Strong Approximation in Reductive Algebraic Groups"
    ],
    "c_abstract":[
      "We investigate a slight weakening of the classical property of strong\napproximation, which we call almost strong approximation, for connected\nreductive algebraic group over global fields with respect to special sets of\nvaluations. While nonsimply connected groups (in particular, all algebraic\ntori) always fail to have strong approximation - and even almost strong\napproximation -- with respect to any finite set of valuations, we show that\nunder appropriate assumptions they do have almost strong approximation with\nrespect to (infinite) tractable sets of valuations, i.e. those sets that\ncontain all archimedean valuations and a generalized arithmetic progression\nminus a set having Dirichlet density zero. Almost strong approximation is\nlikely to have a variety of applications, and as an example we use almost\nstrong approximation for tori to extend the essential part of the result of\nRadhika and Raghunathan on the congruence subgroup problem for inner forms of\ntype $\\textsf{A}_n$ to all absolutely almost simple simply connected groups."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-805",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11591",
    "b_title":[
      "Morphological Neuron Classification Using Machine Learning"
    ],
    "b_abstract":[
      "Classification and quantitative characterization of neuronal morphologies\nfrom histological neuronal reconstruction is challenging since it is still\nunclear how to delineate a neuronal cell class and which are the best features\nto define them by. The morphological neuron characterization represents a\nprimary source to address anatomical comparisons, morphometric analysis of\ncells, or brain modeling. The objectives of this paper are (i) to develop and\nintegrate a pipeline that goes from morphological feature extraction to\nclassification and (ii) to assess and compare the accuracy of machine learning\nalgorithms to classify neuron morphologies. The algorithms were trained on 430\ndigitally reconstructed neurons subjectively classified into layers and\/or\nm-types using young and\/or adult development state population of the\nsomatosensory cortex in rats. For supervised algorithms, linear discriminant\nanalysis provided better classification results in comparison with others. For\nunsupervised algorithms, the affinity propagation and the Ward algorithms\nprovided slightly better results."
    ],
    "b_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2502.08694",
    "c_title":[
      "Neuronal Correlates of Semantic Event Classes during Presentation of\n  Complex Naturalistic Stimuli: Anatomical Patterns, Context-Sensitivity, and\n  Potential Impact on shared Human-Robot Ontologies"
    ],
    "c_abstract":[
      "The present study forms part of a research project that aims to develop\ncognition-enabled robotic agents with environmental interaction capabilities\nclose to human proficiency. This approach is based on human-derived neuronal\ndata in combination with a shared ontology to enable robots to learn from human\nexperiences. To gain further insight into the relation between human neuronal\nactivity patterns and ontological classes, we introduced General Linear Model\n(GLM) analyses on fMRI data of participants who were presented with complex\nnaturalistic video stimuli comparable to the robot tasks. We modeled four event\nclasses (pick, place, fetch and deliver) attached to different environmental\nand object-related context and employed a Representational Similarity Analysis\n(RSA) on associated brain activity patterns as a starting point for an\nautomatic hierarchical clustering. Based on the default values for the\nHemodynamic Response Function (HRF), the activity patterns were reliably\ngrouped according to their parent classes of object interaction and navigation.\nAlthough fetch and deliver events were also distinguished by neuronal patterns,\npick and place events demonstrated higher ambiguity with respect to neuronal\nactivation patterns. Introducing a shorter HRF time-to-peak leads to a more\nreliable grouping of all four semantic classes, despite contextual factors.\nThese data might give novel insights into the neuronal representation of\ncomplex stimuli and may enable further research in ontology validation in\ncognition-enabled robotics."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-806",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08642",
    "b_title":[
      "SwiftSketch: A Diffusion Model for Image-to-Vector Sketch Generation"
    ],
    "b_abstract":[
      "Recent advancements in large vision-language models have enabled highly\nexpressive and diverse vector sketch generation. However, state-of-the-art\nmethods rely on a time-consuming optimization process involving repeated\nfeedback from a pretrained model to determine stroke placement. Consequently,\ndespite producing impressive sketches, these methods are limited in practical\napplications. In this work, we introduce SwiftSketch, a diffusion model for\nimage-conditioned vector sketch generation that can produce high-quality\nsketches in less than a second. SwiftSketch operates by progressively denoising\nstroke control points sampled from a Gaussian distribution. Its\ntransformer-decoder architecture is designed to effectively handle the discrete\nnature of vector representation and capture the inherent global dependencies\nbetween strokes. To train SwiftSketch, we construct a synthetic dataset of\nimage-sketch pairs, addressing the limitations of existing sketch datasets,\nwhich are often created by non-artists and lack professional quality. For\ngenerating these synthetic sketches, we introduce ControlSketch, a method that\nenhances SDS-based techniques by incorporating precise spatial control through\na depth-aware ControlNet. We demonstrate that SwiftSketch generalizes across\ndiverse concepts, efficiently producing sketches that combine high fidelity\nwith a natural and visually appealing style."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10992",
    "c_title":[
      "Rethinking Rotation-Invariant Recognition of Fine-grained Shapes from\n  the Perspective of Contour Points"
    ],
    "c_abstract":[
      "Rotation-invariant recognition of shapes is a common challenge in computer\nvision. Recent approaches have significantly improved the accuracy of\nrotation-invariant recognition by encoding the rotational invariance of shapes\nas hand-crafted image features and introducing deep neural networks. However,\nthe methods based on pixels have too much redundant information, and the\ncritical geometric information is prone to early leakage, resulting in weak\nrotation-invariant recognition of fine-grained shapes. In this paper, we\nreconsider the shape recognition problem from the perspective of contour points\nrather than pixels. We propose an anti-noise rotation-invariant convolution\nmodule based on contour geometric aware for fine-grained shape recognition. The\nmodule divides the shape contour into multiple local geometric regions(LGA),\nwhere we implement finer-grained rotation-invariant coding in terms of point\ntopological relations. We provide a deep network composed of five such cascaded\nmodules for classification and retrieval experiments. The results show that our\nmethod exhibits excellent performance in rotation-invariant recognition of\nfine-grained shapes. In addition, we demonstrate that our method is robust to\ncontour noise and the rotation centers. The source code is available at\nhttps:\/\/github.com\/zhenguonie\/ANRICN_CGA."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-807",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07436",
    "b_title":[
      "Microscopic Theory of Nonlinear Rheology and Double Yielding in Dense\n  Attractive Glass Forming Colloidal Suspensions"
    ],
    "b_abstract":[
      "Yielding of amorphous glasses and gels is a mechanically driven\ntransformation of a material from the solid to liquid state on the experimental\ntimescale. It is a ubiquitous fundamental problem of nonequilibrium physics of\nhigh importance in material science, biology, and engineering applications such\nas processing, ink printing, and manufacturing. However, the underlying\nmicroscopic mechanisms and degree of universality of the yielding problem\nremain theoretically poorly understood. We address this problem for dense\nBrownian suspensions of nanoparticles or colloids that interact via repulsions\nthat induce steric caging and tunable short range attractions that drive\nphysical bond formation. In the absence of deformation, these competing forces\ncan result in fluids, repulsive glasses, attractive glasses, and dense gels of\nwidely varying elastic rigidity and viscosity. Building on a quiescent\nmicroscopic theoretical approach that explicitly treats attractive bonding and\nthermally-induced activated hopping, we formulate a self-consistent theory for\nthe coupled evolution of the transient and steady state mechanical response,\nand structure as a function of stress, strain, and deformation rate over a wide\nrange of high packing fractions and attraction strengths and ranges. Depending\non the latter variables, under step rate shear the theory predicts three\nqualitatively different transient responses: plastic-like (of two distinct\ntypes), static yielding via a single elastic-viscous stress overshoot, and\ndouble or 2-step yielding due to an intricate competition between\ndeformation-induced bond breaking and de-caging. A predictive understanding of\nmultiple puzzling experimental observations is achieved, and the approach can\nbe extended to other nonlinear rheological protocols and soft matter systems."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.07850",
    "c_title":[
      "Tuning the Size and Stiffness of Inflatable Particles"
    ],
    "c_abstract":[
      "We describe size-varying cylindrical particles made from silicone elastomers\nthat can serve as building blocks for robotic granular materials. The particle\nsize variation, which is achieved by inflation, gives rise to changes in\nstiffness under compression. We design and fabricate inflatable particles that\ncan become stiffer or softer during inflation, depending on key parameters of\nthe particle geometry, such as the ratio of the fillet radius to the wall\nthickness, r\/t. We also conduct numerical simulations of the inflatable\nparticles and show that they only soften during inflation when localization of\nlarge strains occurs in the regime r\/t -> 0. This work introduces novel\nparticle systems with tunable size and stiffness that can be implemented in\nnumerous soft robotic applications."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-808",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14451",
    "b_title":[
      "Optimal word order for non-causal text generation with Large Language\n  Models: the Spanish case"
    ],
    "b_abstract":[
      "Natural Language Generation (NLG) popularity has increased owing to the\nprogress in Large Language Models (LLMs), with zero-shot inference\ncapabilities. However, most neural systems utilize decoder-only causal\n(unidirectional) transformer models, which are effective for English but may\nreduce the richness of languages with less strict word order, subject omission,\nor different relative clause attachment preferences. This is the first work\nthat analytically addresses optimal text generation order for non-causal\nlanguage models. We present a novel Viterbi algorithm-based methodology for\nmaximum likelihood word order estimation. We analyze the non-causal\nmost-likelihood order probability for NLG in Spanish and, then, the probability\nof generating the same phrases with Spanish causal NLG. This comparative\nanalysis reveals that causal NLG prefers English-like SVO structures. We also\nanalyze the relationship between optimal generation order and causal\nleft-to-right generation order using Spearman's rank correlation. Our results\ndemonstrate that the ideal order predicted by the maximum likelihood estimator\nis not closely related to the causal order and may be influenced by the\nsyntactic structure of the target sentence."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19279",
    "c_title":[
      "CritiQ: Mining Data Quality Criteria from Human Preferences"
    ],
    "c_abstract":[
      "Language model heavily depends on high-quality data for optimal performance.\nExisting approaches rely on manually designed heuristics, the perplexity of\nexisting models, training classifiers, or careful prompt engineering, which\nrequire significant expert experience and human annotation effort while\nintroduce biases. We introduce CritiQ, a novel data selection method that\nautomatically mines criteria from human preferences for data quality with only\n$\\sim$30 human-annotated pairs and performs efficient data selection. The main\ncomponent, CritiQ Flow, employs a manager agent to evolve quality criteria and\nworker agents to make pairwise judgments. We build a knowledge base that\nextracts quality criteria from previous work to boost CritiQ Flow. Compared to\nperplexity- and classifier- based methods, verbal criteria are more\ninterpretable and possess reusable value. After deriving the criteria, we train\nthe CritiQ Scorer to give quality scores and perform efficient data selection.\nWe demonstrate the effectiveness of our method in the code, math, and logic\ndomains, achieving high accuracy on human-annotated test sets. To validate the\nquality of the selected data, we continually train Llama 3.1 models and observe\nimproved performance on downstream tasks compared to uniform sampling. Ablation\nstudies validate the benefits of the knowledge base and the reflection process.\nWe analyze how criteria evolve and the effectiveness of majority voting."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-809",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12952",
    "b_title":[
      "Performance Analysis and Industry Deployment of Post-Quantum\n  Cryptography Algorithms"
    ],
    "b_abstract":[
      "As quantum computing advances, modern cryptographic standards face an\nexistential threat, necessitating a transition to post-quantum cryptography\n(PQC). The National Institute of Standards and Technology (NIST) has selected\nCRYSTALS-Kyber and CRYSTALS-Dilithium as standardized PQC algorithms for secure\nkey exchange and digital signatures, respectively. This study conducts a\ncomprehensive performance analysis of these algorithms by benchmarking\nexecution times across cryptographic operations such as key generation,\nencapsulation, decapsulation, signing, and verification. Additionally, the\nimpact of AVX2 optimizations is evaluated to assess hardware acceleration\nbenefits. Our findings demonstrate that Kyber and Dilithium achieve efficient\nexecution times, outperforming classical cryptographic schemes such as RSA and\nECDSA at equivalent security levels. Beyond technical performance, the\nreal-world deployment of PQC introduces challenges in telecommunications\nnetworks, where large-scale infrastructure upgrades, interoperability with\nlegacy systems, and regulatory constraints must be addressed. This paper\nexamines the feasibility of PQC adoption in telecom environments, highlighting\nkey transition challenges, security risks, and implementation strategies.\nThrough industry case studies, we illustrate how telecom operators are\nintegrating PQC into 5G authentication, subscriber identity protection, and\nsecure communications. Our analysis provides insights into the computational\ntrade-offs, deployment considerations, and standardization efforts shaping the\nfuture of quantum-safe cryptographic infrastructure."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.20791",
    "c_title":[
      "Cyber Defense Reinvented: Large Language Models as Threat Intelligence\n  Copilots"
    ],
    "c_abstract":[
      "The exponential growth of cyber threat knowledge, exemplified by the\nexpansion of databases such as MITRE-CVE and NVD, poses significant challenges\nfor cyber threat analysis. Security professionals are increasingly burdened by\nthe sheer volume and complexity of information, creating an urgent need for\neffective tools to navigate, synthesize, and act on large-scale data to counter\nevolving threats proactively. However, conventional threat intelligence tools\noften fail to scale with the dynamic nature of this data and lack the\nadaptability to support diverse threat intelligence tasks.\n  In this work, we introduce CYLENS, a cyber threat intelligence copilot\npowered by large language models (LLMs). CYLENS is designed to assist security\nprofessionals throughout the entire threat management lifecycle, supporting\nthreat attribution, contextualization, detection, correlation, prioritization,\nand remediation. To ensure domain expertise, CYLENS integrates knowledge from\n271,570 threat reports into its model parameters and incorporates six\nspecialized NLP modules to enhance reasoning capabilities. Furthermore, CYLENS\ncan be customized to meet the unique needs of different or ganizations,\nunderscoring its adaptability. Through extensive evaluations, we demonstrate\nthat CYLENS consistently outperforms industry-leading LLMs and state-of-the-art\ncybersecurity agents. By detailing its design, development, and evaluation,\nthis work provides a blueprint for leveraging LLMs to address complex,\ndata-intensive cybersecurity challenges."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-810",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04034",
    "b_title":[
      "Mirror Descent Methods with Weighting Scheme for Outputs for Constrained\n  Variational Inequality Problems"
    ],
    "b_abstract":[
      "This paper is devoted to the variational inequality problems. We consider two\nclasses of problems, the first is classical constrained variational inequality\nand the second is the same problem with functional (inequality type)\nconstraints. To solve these problems, we propose mirror descent-type methods\nwith a weighting scheme for the generated points in each iteration of the\nalgorithms. This scheme assigns smaller weights to the initial points and\nlarger weights to the most recent points, thus it improves the convergence rate\nof the proposed methods. For the variational inequality problem with functional\nconstraints, the proposed method switches between adaptive and non-adaptive\nsteps in the dependence on the values of the functional constraints at\niterations. We analyze the proposed methods for the time-varying step sizes and\nprove the optimal convergence rate for variational inequality problems with\nbounded and monotone operators. The results of numerical experiments of the\nproposed methods for classical constrained variational inequality problems show\na significant improvement over the modified projection method."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.07390",
    "c_title":[
      "Nonlinear Open-Loop Mean field Stackelberg Stochastic Differential Game"
    ],
    "c_abstract":[
      "This paper studies a nonlinear open-loop mean field Stackelberg stochastic\ndifferential game by using the probabilistic method through the FBSDE system\nand the idea of taking control as the fixed point. We successively construct\nthe decentralized optimal control problems for the followers and the leader,\namong which the leader's decentralized optimal control problem is a partial\ninformation optimal control problem with the fully coupled conditional\nmean-field forward-backward stochastic differential equation (FBSDE, in short)\nas the state equation. We successively derive the maximum principles for the\ncorresponding decentralized optimal control problems of the followers and the\nleader. To obtain the existence, uniqueness and estimations of solutions of the\nstate equation, the variational equation and the adjoint equation for the\nleader's decentralized optimal control problem, we study the well-posedness of\na new form of conditional mean-field FBSDE. Finally, the decentralized optimal\ncontrols of the leader and followers are proved to be the approximate\nStackelberg equilibrium of the nonlinear mean field Stackelberg game."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-811",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18056",
    "b_title":[
      "Escaping The Big Data Paradigm in Self-Supervised Representation\n  Learning"
    ],
    "b_abstract":[
      "The reliance on large-scale datasets and extensive computational resources\nhas become a major barrier to advancing representation learning in vision,\nespecially in data-scarce domains. In this paper, we address the critical\nquestion: Can we escape the big data paradigm in self-supervised representation\nlearning from images? We introduce SCOTT (Sparse Convolutional Tokenizer for\nTransformers), a shallow tokenization architecture that is compatible with\nMasked Image Modeling (MIM) tasks. SCOTT injects convolutional inductive biases\ninto Vision Transformers (ViTs), enhancing their efficacy in small-scale data\nregimes. Alongside, we propose to train on a Joint-Embedding Predictive\nArchitecture within a MIM framework (MIM-JEPA), operating in latent\nrepresentation space to capture more semantic features. Our approach enables\nViTs to be trained from scratch on datasets orders of magnitude smaller than\ntraditionally required --without relying on massive external datasets for\npretraining. We validate our method on three small-size, standard-resoultion,\nfine-grained datasets: Oxford Flowers-102, Oxford IIIT Pets-37, and\nImageNet-100. Despite the challenges of limited data and high intra-class\nsimilarity, frozen SCOTT models pretrained with MIM-JEPA significantly\noutperform fully supervised methods and achieve competitive results with SOTA\napproaches that rely on large-scale pretraining, complex image augmentations\nand bigger model sizes. By demonstrating that robust off-the-shelf\nrepresentations can be learned with limited data, compute, and model sizes, our\nwork paves the way for computer applications in resource constrained\nenvironments such as medical imaging or robotics. Our findings challenge the\nprevailing notion that vast amounts of data are indispensable for effective\nrepresentation learning in vision, offering a new pathway toward more\naccessible and inclusive advancements in the field."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09439",
    "c_title":[
      "SuperCarver: Texture-Consistent 3D Geometry Super-Resolution for\n  High-Fidelity Surface Detail Generation"
    ],
    "c_abstract":[
      "Traditional production workflow of high-precision 3D mesh assets necessitates\na cumbersome and laborious process of manual sculpting by specialized modelers.\nThe recent years have witnessed remarkable advances in AI-empowered 3D content\ncreation. However, although the latest state-of-the-arts are already capable of\ngenerating plausible structures and intricate appearances from images or text\nprompts, the actual mesh surfaces are typically over-smoothing and lack\ngeometric details. This paper introduces SuperCarver, a 3D geometry\nsuper-resolution framework particularly tailored for adding texture-consistent\nsurface details to given coarse meshes. Technically, we start by rendering the\noriginal textured mesh into the image domain from multiple viewpoints. To\nachieve geometric detail generation, we develop a deterministic prior-guided\nnormal diffusion model fine-tuned on a carefully curated dataset of paired\nlow-poly and high-poly normal renderings. To optimize mesh structures from\npotentially imperfect normal map predictions, we design a simple yet effective\nnoise-resistant inverse rendering scheme based on distance field deformation.\nExtensive experiments show that SuperCarver generates realistic and expressive\nsurface details as depicted by specific texture appearances, making it a\npowerful tool for automatically upgrading massive outdated low-quality assets\nand shortening the iteration cycle of high-quality mesh production in practical\napplications."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-812",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19045",
    "b_title":[
      "Scaling for count-in-cell and factorial moment analysis"
    ],
    "b_abstract":[
      "The investigation of remnants associated with the QCD chiral critical point\nis a primary objective in high-energy ion collision experiments. Numerous\nstudies indicate that a scaling relation between higher-order factorial moments\nof hadron multiplicity distributions and the second factorial moment may serve\nas a diagnostic tool for identifying the QCD critical point. However, we\ndemonstrate that this scaling behavior is not exclusive to critical phenomena\nbut rather arises as a general consequence of the phase-space partitioning\nprocedure employed in the analysis. This finding is examined in the context of\nrecent intermittency analyses conducted by the STAR experiment at RHIC."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.18130",
    "c_title":[
      "Lepton flavor violating decays $l_j\\rightarrow l_i\\gamma$, $l_j\n  \\rightarrow 3l_i$ and $\\mu\\rightarrow e+ q\\bar q$ in the N-B-LSSM"
    ],
    "c_abstract":[
      "The N-B-LSSM is an extension of the minimal supersymmetric standard model\n(MSSM) with the addition of three singlet new Higgs superfields and\nright-handed neutrinos, whose local gauge group is $SU(3)_C\\times SU(2)_L\\times\nU(1)_Y\\times U(1)_{B-L}$. In the N-B-LSSM, we study lepton flavor violating\ndecays $l_j\\rightarrow l_i\\gamma$, $l_j \\rightarrow 3l_i$ and $\\mu\\rightarrow\ne+ q\\bar q$ $(j=\\tau,\\mu,~i=\\mu,e$ and $i\\neq j)$. Based on the current\nexperimental limitations, we carry out detailed parameter scanning and\nnumerical calculations to analyse the effects of different sensitive parameters\non lepton flavor violation (LFV) in the N-B-LSSM. The numerical results show\nthat the non-diagonal elements involving the initial and final leptons are main\nsensitive parameters and LFV sources. This work can provide a strong basis for\nexploring new physics (NP) beyond the Standard Model (SM)."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-813",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07554",
    "b_title":[
      "An Empirical Comparison of Cost Functions in Inductive Logic Programming"
    ],
    "b_abstract":[
      "Recent inductive logic programming (ILP) approaches learn optimal hypotheses.\nAn optimal hypothesis minimises a given cost function on the training data.\nThere are many cost functions, such as minimising training error, textual\ncomplexity, or the description length of hypotheses. However, selecting an\nappropriate cost function remains a key question. To address this gap, we\nextend a constraint-based ILP system to learn optimal hypotheses for seven\nstandard cost functions. We then empirically compare the generalisation error\nof optimal hypotheses induced under these standard cost functions. Our results\non over 20 domains and 1000 tasks, including game playing, program synthesis,\nand image reasoning, show that, while no cost function consistently outperforms\nthe others, minimising training error or description length has the best\noverall performance. Notably, our results indicate that minimising the size of\nhypotheses does not always reduce generalisation error."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18028",
    "c_title":[
      "KNN and K-means in Gini Prametric Spaces"
    ],
    "c_abstract":[
      "This paper introduces innovative enhancements to the K-means and K-nearest\nneighbors (KNN) algorithms based on the concept of Gini prametric spaces.\nUnlike traditional distance metrics, Gini-based measures incorporate both\nvalue-based and rank-based information, improving robustness to noise and\noutliers. The main contributions of this work include: proposing a Gini-based\nmeasure that captures both rank information and value distances; presenting a\nGini K-means algorithm that is proven to converge and demonstrates resilience\nto noisy data; and introducing a Gini KNN method that performs competitively\nwith state-of-the-art approaches such as Hassanat's distance in noisy\nenvironments. Experimental evaluations on 14 datasets from the UCI repository\ndemonstrate the superior performance and efficiency of Gini-based algorithms in\nclustering and classification tasks. This work opens new avenues for leveraging\nrank-based measures in machine learning and statistical analysis."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-814",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12874",
    "b_title":[
      "Testing for Causal Fairness"
    ],
    "b_abstract":[
      "Causality is widely used in fairness analysis to prevent discrimination on\nsensitive attributes, such as genders in career recruitment and races in crime\nprediction. However, the current data-based Potential Outcomes Framework (POF)\noften leads to untrustworthy fairness analysis results when handling\nhigh-dimensional data. To address this, we introduce a distribution-based POF\nthat transform fairness analysis into Distributional Closeness Testing (DCT) by\nintervening on sensitive attributes. We define counterfactual closeness\nfairness as the null hypothesis of DCT, where a sensitive attribute is\nconsidered fair if its factual and counterfactual potential outcome\ndistributions are sufficiently close. We introduce the Norm-Adaptive Maximum\nMean Discrepancy Treatment Effect (N-TE) as a statistic for measuring\ndistributional closeness and apply DCT using the empirical estimator of NTE,\nreferred to Counterfactual Fairness-CLOseness Testing ($\\textrm{CF-CLOT}$). To\nensure the trustworthiness of testing results, we establish the testing\nconsistency of N-TE through rigorous theoretical analysis. $\\textrm{CF-CLOT}$\ndemonstrates sensitivity in fairness analysis through the flexibility of the\ncloseness parameter $\\epsilon$. Unfair sensitive attributes have been\nsuccessfully tested by $\\textrm{CF-CLOT}$ in extensive experiments across\nvarious real-world scenarios, which validate the consistency of the testing."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.00311",
    "c_title":[
      "Sparse Gradient Compression for Fine-Tuning Large Language Models"
    ],
    "c_abstract":[
      "Fine-tuning large language models (LLMs) for downstream tasks has become\nincreasingly crucial due to their widespread use and the growing availability\nof open-source models. However, the high memory costs associated with\nfine-tuning remain a significant challenge, especially as models increase in\nsize. To address this, parameter efficient fine-tuning (PEFT) methods have been\nproposed to minimize the number of parameters required for fine-tuning LLMs.\nHowever, these approaches often tie the number of optimizer states to\ndimensions of model parameters, limiting flexibility and control during\nfine-tuning. In this paper, we propose sparse gradient compression (SGC), a\ntraining regime designed to address these limitations. Our approach leverages\ninherent sparsity in gradients to compress optimizer states by projecting them\nonto a low-dimensonal subspace, with dimensionality independent of the original\nmodel's parameters. By enabling optimizer state updates in an arbitrary\nlow-dimensional subspace, SGC offers a flexible tradeoff between memory\nefficiency and performance. We demonstrate through experiments that SGC can\ndecrease memory usage in optimizer states more effectively than existing PEFT\nmethods. Furthermore, by fine-tuning LLMs on various downstream tasks, we show\nthat SGC can deliver superior performance while substantially lowering\noptimizer state memory requirements, particularly in both data-limited and\nmemory-limited settings."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-815",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10730",
    "b_title":[
      "Semiconducting behaviors at epitaxial Ca0.5TaO3 interfaces"
    ],
    "b_abstract":[
      "Emergent phenomena take place in symmetry-breaking systems, notably the\nrecently discovered two-dimensional electron gas and its tunable\nsuperconductivities near the KTaO3 interfaces. Here, we synthesized perovskite\nCa0.5TaO3 films along both [001] and [111] orientations. Different from the\nKTaO3 system, Ca0.5TaO3 films show semiconducting behaviors when capped with\nLaAlO3 films in both [001] and [111] orientations. By growing films at higher\ntemperatures, more oxygen vacancies can be introduced, and the carrier density\ncan be tuned from ~ 1014 cm-2 to ~ 1016 cm-2. Another difference is that the\nsuperconducting transition temperature Tc in KTaO3 (111) increases linearly\nalong with its carrier density, while the Ca0.5TaO3 (111) remains\nsemiconducting when carrier density ranges from ~ 1014 cm-2 to ~ 1016 cm-2.\nBased on the density function theory calculation, Ca0.5TaO3 and KTaO3 show\nsimilar electronic band structures. According to the energy-dispersive X-ray\nspectroscopy, we found heavy Sr diffusion from the substrate to the Ca0.5TaO3\nlayer, which may destroy the interfacial conductivity. Our work demonstrates\nthat besides the oxygen vacancies, electronic transport is sensitive to the\natomic intermixing near the interface in tantulates."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.12852",
    "c_title":[
      "Charging of quantum emitters in hexagonal boron nitride - graphene\n  heterostructures due to electrostatic screening"
    ],
    "c_abstract":[
      "Defect color centers in hexagonal boron nitride (hBN) have gained significant\ninterest as single-photon emitters and spin qubits for applications in a wide\nrange of quantum technologies. As the integration of these solid-state quantum\nemitters into electronic devices necessitates electrical control, it is\nessential to gain a deeper understanding of the mechanisms of charge control\nfor these defect color centers in hBN\/graphene heterostructures. In this\nLetter, we show that screening due to the encapsulation of hBN with graphene\nmodifies the electrical levels of hBN, leading to charge transfer. Furthermore,\nwe show that the charged defects have low-energy barriers for defect\nreorientation which can be overcome by moderate gate voltages. This study shows\nthat accurate modeling of the charge state of the defect is necessary to be\nable to electrically control defects."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-816",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09748",
    "b_title":[
      "PyPLUTO: a data analysis Python package for the PLUTO code"
    ],
    "b_abstract":[
      "In recent years, numerical simulations have become indispensable for\naddressing complex astrophysical problems. The MagnetoHydroDynamics (MHD)\nframework represents a key tool for investigating the dynamical evolution of\nastrophysical plasmas, which are described as a set of partial differential\nequations that enforce the conservation of mass, momentum, and energy, along\nwith Maxwell's equation for the evolution of the electromagnetic fields. Due to\nthe high nonlinearity of the MHD equations (regardless of their specifications,\ne.g., classical\/relativistic or ideal\/resistive), a general analytical solution\nis precluded, making the numerical approach crucial. Numerical simulations\nusually end up producing large sets of data files and their scientific analysis\nleans on dedicated software designed for data visualization. However, in order\nto encompass all of the code output features, specialized tools focusing on the\nnumerical code may represent a more versatile and built-in tool. Here, we\npresent PyPLUTO, a Python package tailored for efficient loading, manipulation,\nand visualization of outputs produced with the PLUTO code (Mignone et al.,\n2007; Mignone et al., 2012). PyPLUTO uses memory mapping to optimize data\nloading and provides general routines for data manipulation and visualization.\nPyPLUTO also supports the particle modules of the PLUTO code, enabling users to\nload and visualize particles, such as cosmic rays (Mignone et al., 2018),\nLagrangian (Vaidya et al., 2018), or dust (Mignone et al., 2019) particles,\nfrom hybrid simulations. A dedicated Graphical User Interface (GUI) simplifies\nthe generation of single-subplot figures, making PyPLUTO a powerful yet\nuser-friendly toolkit for astrophysical data analysis."
    ],
    "b_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04486",
    "c_title":[
      "An Alternate Method for Minimizing $\\chi^2$"
    ],
    "c_abstract":[
      "In this paper, we describe an algorithm and associated software package\n(sfit_minimize) for maximizing the likelihood function of a set of parameters\nby minimizing $\\chi^2$. The key element of this method is that the algorithm\nestimates the second derivative of the $\\chi^2$ function using first\nderivatives of the function to be fitted. These same derivatives can also be\nused to calculate the uncertainties in each parameter. We test this algorithm\nagainst several standard minimization algorithms in SciPy.optimize.minimize()\nby fitting point lens models to light curves from the 2018 Korea Microlensing\nTelescope Network event database. We show that for fitting microlensing events,\nSFit works faster than the Nelder-Mead simplex method and is more reliable than\nthe BFGS gradient method; we also find that the Newton-CG method is not\neffective for fitting microlensing events."
    ],
    "c_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-817",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05621",
    "b_title":[
      "Predictive Modeling of Classical and Quantum Mechanics Using Machine\n  Learning: A Case Study with TensorFlow"
    ],
    "b_abstract":[
      "In this paper, we present several machine learning approaches for predicting\nthe behavior of both classical and quantum systems. For the classical domain,\nwe model a pendulum subject to multiple forces using both a standard artificial\nneural network (ANN) and a physics-informed neural network (PINN). For the\nquantum domain, we predict the ground state energy of a quantum anharmonic\noscillator from discretized potential data using an ANN with convolutional\nlayers (CNN), a long short-term memory (LSTM) network, and a PINN that\nincorporates the Schr\\\"odinger equation. Detailed training outputs and\ncomparisons are provided."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.11494",
    "c_title":[
      "Bridging wire and gate cutting with ZX-calculus"
    ],
    "c_abstract":[
      "Quantum circuit cutting refers to a series of techniques that allow one to\npartition a quantum computation on a large quantum computer into several\nquantum computations on smaller devices. This usually comes at the price of a\nsampling overhead, that is quantified by the $1$-norm of the associated\ndecomposition. The applicability of these techniques relies on the possibility\nof finding decompositions of the ideal, global unitaries into quantum\noperations that can be simulated onto each sub-register, which should ideally\nminimize the $1$-norm. In this work, we show how these decompositions can be\nobtained diagrammatically using ZX-calculus expanding on the work of Ufrecht et\nal. [arXiv:2302.00387]. The central idea of our work is that since in\nZX-calculus only connectivity matters, it should be possible to cut wires in\nZX-diagrams by inserting known decompositions of the identity in standard\nquantum circuits. We show how, using this basic idea, many of the gate\ndecompositions known in the literature can be re-interpreted as an instance of\nwire cuts in ZX-diagrams. Furthermore, we obtain improved decompositions for\nmulti-qubit controlled-Z (MCZ) gates with $1$-norm equal to $3$ for any number\nof qubits and any partition, which we argue to be optimal. Our work gives new\nways of thinking about circuit cutting that can be particularly valuable for\nfinding decompositions of large unitary gates. Besides, it sheds light on the\nquestion of why exploiting classical communication decreases the 1-norm of a\nwire cut but does not do so for certain gate decompositions. In particular,\nusing wire cuts with classical communication, we obtain gate decompositions\nthat do not require classical communication."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-818",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02074",
    "b_title":[
      "Rethinking stance detection: A theoretically-informed research agenda\n  for user-level inference using language models"
    ],
    "b_abstract":[
      "Stance detection has emerged as a popular task in natural language processing\nresearch, enabled largely by the abundance of target-specific social media\ndata. While there has been considerable research on the development of stance\ndetection models, datasets, and application, we highlight important gaps\npertaining to (i) a lack of theoretical conceptualization of stance, and (ii)\nthe treatment of stance at an individual- or user-level, as opposed to\nmessage-level. In this paper, we first review the interdisciplinary origins of\nstance as an individual-level construct to highlight relevant attributes (e.g.,\npsychological features) that might be useful to incorporate in stance detection\nmodels. Further, we argue that recent pre-trained and large language models\n(LLMs) might offer a way to flexibly infer such user-level attributes and\/or\nincorporate them in modelling stance. To better illustrate this, we briefly\nreview and synthesize the emerging corpus of studies on using LLMs for\ninferring stance, and specifically on incorporating user attributes in such\ntasks. We conclude by proposing a four-point agenda for pursuing stance\ndetection research that is theoretically informed, inclusive, and practically\nimpactful."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02659",
    "c_title":[
      "LoRA-Null: Low-Rank Adaptation via Null Space for Large Language Models"
    ],
    "c_abstract":[
      "Low-Rank Adaptation (LoRA) is the leading parameter-efficient fine-tuning\nmethod for Large Language Models (LLMs). However, the fine-tuned LLMs encounter\nthe issue of catastrophic forgetting of the pre-trained world knowledge. To\naddress this issue, inspired by theoretical insights of null space, we propose\nLoRA-Null, i.e., Low-Rank Adaptation via null space, which builds adapters\ninitialized from the null space of the pre-trained knowledge activation.\nConcretely, we randomly collect a few data samples and capture their\nactivations after passing through the LLM layer. We perform Singular Value\nDecomposition on the input activations to obtain their null space. We use the\nprojection of the pre-trained weights onto the null space as the initialization\nfor adapters. Experimental results demonstrate that this initialization\napproach can effectively preserve the original pre-trained world knowledge of\nthe LLMs during fine-tuning. Additionally, if we freeze the values of the\ndown-projection matrices during fine-tuning, it achieves even better\npreservation of the pre-trained world knowledge. LoRA-Null effectively\npreserves pre-trained world knowledge while maintaining strong fine-tuning\nperformance, as validated by extensive experiments on LLaMA series (LLaMA2,\nLLaMA3, LLaMA3.1, and LLaMA3.2) across Code, Math, and Instruction Following\ntasks. We also provide a theoretical guarantee for the capacity of LoRA-Null to\nretain pre-trained knowledge. Code is in\nhttps:\/\/github.com\/HungerPWAY\/LoRA-Null."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-819",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11523",
    "b_title":[
      "Fractional Lane-Emden Hamiltonian systems"
    ],
    "b_abstract":[
      "In this work, our interest lies in proving the existence of solutions to the\nfollowing Fractional Lane-Emden Hamiltonian system: $$ \\begin{cases}\n(-\\Delta)^s u = H_v(x,u,v) & \\text{in }\\Omega,\\\\ (-\\Delta)^s v = H_u(x,u,v) &\n\\text{in }\\Omega,\\\\ u=v=0 & \\text{in } \\R^n\\setminus\\Omega. \\end{cases} $$ The\nmethod, that can be traced back to the work of De Figueiredo and Felmer\n\\cite{DF-F}, is flexible enough to deal with more general nonlocal operators\nand make use of a combination of fractional order Sobolev spaces together with\nfunctional calculus for self-adjoint operators."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.02742",
    "c_title":[
      "Potential-based versus non potential-based cohesive models accounting\n  for loading and unloading with application to sliding elastic laminates"
    ],
    "c_abstract":[
      "A rigorous unified perspective of cohesive zone models is presented,\nincluding and comparing potential-based and non potential-based formulations,\nand encompassing known examples studied in literature. The main novelty of the\nwork consists in the natural inclusion of loading and unloading effects in a\ngeneral mixed-mode framework, incorporated through an intrinsic construction of\nenergy densities or tensions. The proposed mathematical investigation\nidentifies and proves the limitations of variational models with respect to\nnon-variational ones, the latter yielding a feasible description of real\ninstances in all relevant situations and regimes. This validates existing\nempirical and numerical observations. An application to a mechanical process of\ntwo elastic laminates sliding one on each other along their cohesive interface\nis finally analyzed, and existence results in both potential-based and non\npotential-based versions are obtained, extending previous contributions."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-820",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07797",
    "b_title":[
      "The News Says, the Bot Says: How Immigrants and Locals Differ in\n  Chatbot-Facilitated News Reading"
    ],
    "b_abstract":[
      "News reading helps individuals stay informed about events and developments in\nsociety. Local residents and new immigrants often approach the same news\ndifferently, prompting the question of how technology, such as LLM-powered\nchatbots, can best enhance a reader-oriented news experience. The current paper\npresents an empirical study involving 144 participants from three groups in\nVirginia, United States: local residents born and raised there (N=48), Chinese\nimmigrants (N=48), and Vietnamese immigrants (N=48). All participants read\nlocal housing news with the assistance of the Copilot chatbot. We collected\ndata on each participant's Q&A interactions with the chatbot, along with their\ntakeaways from news reading. While engaging with the news content, participants\nin both immigrant groups asked the chatbot fewer analytical questions than the\nlocal group. They also demonstrated a greater tendency to rely on the chatbot\nwhen formulating practical takeaways. These findings offer insights into\ntechnology design that aims to serve diverse news readers."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16557",
    "c_title":[
      "CARING-AI: Towards Authoring Context-aware Augmented Reality INstruction\n  through Generative Artificial Intelligence"
    ],
    "c_abstract":[
      "Context-aware AR instruction enables adaptive and in-situ learning\nexperiences. However, hardware limitations and expertise requirements constrain\nthe creation of such instructions. With recent developments in Generative\nArtificial Intelligence (Gen-AI), current research tries to tackle these\nconstraints by deploying AI-generated content (AIGC) in AR applications.\nHowever, our preliminary study with six AR practitioners revealed that the\ncurrent AIGC lacks contextual information to adapt to varying application\nscenarios and is therefore limited in authoring. To utilize the strong\ngenerative power of GenAI to ease the authoring of AR instruction while\ncapturing the context, we developed CARING-AI, an AR system to author\ncontext-aware humanoid-avatar-based instructions with GenAI. By navigating in\nthe environment, users naturally provide contextual information to generate\nhumanoid-avatar animation as AR instructions that blend in the context\nspatially and temporally. We showcased three application scenarios of\nCARING-AI: Asynchronous Instructions, Remote Instructions, and Ad Hoc\nInstructions based on a design space of AIGC in AR Instructions. With two user\nstudies (N=12), we assessed the system usability of CARING-AI and demonstrated\nthe easiness and effectiveness of authoring with Gen-AI."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-821",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.19083",
    "b_title":[
      "MotionPCM: Real-Time Motion Synthesis with Phased Consistency Model"
    ],
    "b_abstract":[
      "Diffusion models have become a popular choice for human motion synthesis due\nto their powerful generative capabilities. However, their high computational\ncomplexity and large sampling steps pose challenges for real-time applications.\nFortunately, the Consistency Model (CM) provides a solution to greatly reduce\nthe number of sampling steps from hundreds to a few, typically fewer than four,\nsignificantly accelerating the synthesis of diffusion models. However, applying\nCM to text-conditioned human motion synthesis in latent space yields\nunsatisfactory generation results. In this paper, we introduce\n\\textbf{MotionPCM}, a phased consistency model-based approach designed to\nimprove the quality and efficiency for real-time motion synthesis in latent\nspace. Experimental results on the HumanML3D dataset show that our model\nachieves real-time inference at over 30 frames per second in a single sampling\nstep while outperforming the previous state-of-the-art with a 38.9\\%\nimprovement in FID. The code will be available for reproduction."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16257",
    "c_title":[
      "Plug-and-Play 1.x-Bit KV Cache Quantization for Video Large Language\n  Models"
    ],
    "c_abstract":[
      "Video large language models (VideoLLMs) have demonstrated the capability to\nprocess longer video inputs and enable complex reasoning and analysis. However,\ndue to the thousands of visual tokens from the video frames, key-value (KV)\ncache can significantly increase memory requirements, becoming a bottleneck for\ninference speed and memory usage. KV cache quantization is a widely used\napproach to address this problem. In this paper, we find that 2-bit KV\nquantization of VideoLLMs can hardly hurt the model performance, while the\nlimit of KV cache quantization in even lower bits has not been investigated. To\nbridge this gap, we introduce VidKV, a plug-and-play KV cache quantization\nmethod to compress the KV cache to lower than 2 bits. Specifically, (1) for\nkey, we propose a mixed-precision quantization strategy in the channel\ndimension, where we perform 2-bit quantization for anomalous channels and 1-bit\nquantization combined with FFT for normal channels; (2) for value, we implement\n1.58-bit quantization while selectively filtering semantically salient visual\ntokens for targeted preservation, for a better trade-off between precision and\nmodel performance. Importantly, our findings suggest that the value cache of\nVideoLLMs should be quantized in a per-channel fashion instead of the per-token\nfashion proposed by prior KV cache quantization works for LLMs. Empirically,\nextensive results with LLaVA-OV-7B and Qwen2.5-VL-7B on six benchmarks show\nthat VidKV effectively compresses the KV cache to 1.5-bit and 1.58-bit\nprecision with almost no performance drop compared to the FP16 counterparts."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-822",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08718",
    "b_title":[
      "Pixelization effects in cosmic shear angular power spectra"
    ],
    "b_abstract":[
      "We conduct a comprehensive study into the impact of pixelization on cosmic\nshear, uncovering several sources of bias in standard pseudo-$C_\\ell$\nestimators based on discrete catalogues. We derive models that can bring\nresidual biases to the percent level on small scales. We elucidate the impact\nof aliasing and the varying shape of HEALPix pixels on power spectra and show\nhow the HEALPix pixel window function approximation is made in the discrete\nspin-2 setting. We propose several improvements to the standard estimator and\nits modelling, based on the principle that source positions and weights are to\nbe considered fixed. We show how empty pixels can be accounted for either by\nmodifying the mixing matrices or applying correction factors that we derive. We\nintroduce an approximate interlacing scheme for the HEALPix grid and show that\nit can mitigate the effects of aliasing. We introduce bespoke pixel window\nfunctions adapted to the survey footprint and show that, for band-limited\nspectra, biases from using an isotropic window function can be effectively\nreduced to zero. This work partly intends to serve as a useful reference for\npixel-related effects in angular power spectra, which are of relevance for\nongoing and forthcoming lensing and clustering surveys."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.15619",
    "c_title":[
      "Light in the dark forest -- I. An efficient optimal estimator for 3D\n  Lyman-alpha forest power spectrum"
    ],
    "c_abstract":[
      "The highly anisotropic nature of the Lyman-alpha (Ly$\\alpha$) forest data\nintroduces a complex survey window function that complicates the measurement of\nthe three-dimensional power spectrum ($P_{\\mathrm{3D}}$). In this paper, we\npresent the first fully optimal estimator for $P_{\\mathrm{3D}}$, which exactly\ndeconvolves the survey window function and marginalizes contaminated modes that\ndistort the power spectrum. Our approach adapts optimal estimator techniques\ndeveloped for the 2D cosmic microwave background data to the 3D case. To\nachieve computational feasibility, we employ the conjugate gradient method and\nimplement the P$^3$M formalism to handle large-scale and small-scale operations\nseparately and efficiently. We validate our estimator using Monte Carlo mocks\nand Gaussian simulations, demonstrating its accuracy and computational\nefficiency. We confirm that mode marginalization eliminates distortions arising\nfrom quasar continuum errors and delivers robust power spectrum estimation,\nthough it also inflates errors at large scales. This first implementation works\nin the flat sky case; we discuss the remaining steps needed to generalize to\nthe curved sky. This formalism offers a foundation for the Ly$\\alpha$ forest\n$P_{\\mathrm{3D}}$ measurements and a new path toward cosmological constraints\nfrom the Ly$\\alpha$ forest data."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-823",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15216",
    "b_title":[
      "Non-Markovian dynamics with ${\\Lambda}$-type atomic systems in a single\n  end photonic waveguide"
    ],
    "b_abstract":[
      "In this work, we investigate the non-Markovian dynamical evolution of a\n${\\Lambda}$-type atom interacting with a semi-infinite one-dimensional photonic\nwaveguide via two atomic transitions. The waveguide terminates at a perfect\nmirror, which reflects the light and introduces boundary effects. We derive\nexact analytical expressions and show that, under suitable conditions, the\ninstantaneous and retarded decay rates reach equilibrium, leading to the\nformation of an atom-photon bound state that suppresses dissipation.\nConsequently, the atom retains a long-lived population in the asymptotic time\nlimit. Furthermore, we analyze the output field intensity and demonstrate that\nblocking one of the coupling channels forces the atomic system to emit photons\nof a single frequency. Finally, we extend the model to a two-atom system and\nexamine the disentanglement dynamics of the two spatially separated atoms.\nThese findings elucidate the dynamic process of spontaneous emission involving\nmulti-frequency photons from multi-level atoms and provide insights into the\ncomplex interference between different decay pathways."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.11253",
    "c_title":[
      "The Q-Spellbook: Crafting Surface Code Layouts and Magic State Protocols\n  for Large-Scale Quantum Computing"
    ],
    "c_abstract":[
      "Quantum error correction is a cornerstone of reliable quantum computing, with\nsurface codes emerging as a prominent method for protecting quantum\ninformation. Surface codes are efficient for Clifford gates but require magic\nstate distillation protocols to process non-Clifford gates, such as T gates,\nessential for universal quantum computation. In large-scale quantum\narchitectures capable of correcting arbitrary circuits, specialized surface\ncodes for data qubits and distinct codes for magic state distillation are\nneeded. These architectures can be organized into data blocks and distillation\nblocks. The system works by having distillation blocks produce magic states and\ndata blocks consume them, causing stalls due to either a shortage or excess of\nmagic states. This bottleneck presents an opportunity to optimize quantum space\nby balancing data and distillation blocks. While prior research offers insights\ninto selecting distillation protocols and estimating qubit requirements, it\nlacks a tailored optimization approach. We present a framework for optimizing\nlarge-scale quantum architectures, focusing on data block layouts and magic\nstate distillation protocols. We evaluate three data block layouts and four\ndistillation protocols under three optimization strategies: minimizing tiles,\nminimizing steps, and achieving a balanced trade-off. Through a comparative\nanalysis of brute force, dynamic programming, greedy, and random algorithms, we\nfind that brute force delivers optimal results, while greedy deviates by 7% for\nminimizing steps and dynamic programming matches brute force in tile\nminimization. We observe that total steps increase with columns, while total\ntiles scale with qubits. Finally, we propose a heuristic to help users select\nalgorithms suited to their objectives, enabling scalable and efficient quantum\narchitectures."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-824",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18580",
    "b_title":[
      "Node Classification and Search on the Rubik's Cube Graph with GNNs"
    ],
    "b_abstract":[
      "This study focuses on the application of deep geometric models to solve the\n3x3x3 Rubik's Cube. We begin by discussing the cube's graph representation and\ndefining distance as the model's optimization objective. The distance\napproximation task is reformulated as a node classification problem,\neffectively addressed using Graph Neural Networks (GNNs). After training the\nmodel on a random subgraph, the predicted classes are used to construct a\nheuristic for $A^*$ search. We conclude with experiments comparing our\nheuristic to that of the DeepCubeA model."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11340",
    "c_title":[
      "S2TX: Cross-Attention Multi-Scale State-Space Transformer for Time\n  Series Forecasting"
    ],
    "c_abstract":[
      "Time series forecasting has recently achieved significant progress with\nmulti-scale models to address the heterogeneity between long and short range\npatterns. Despite their state-of-the-art performance, we identify two potential\nareas for improvement. First, the variates of the multivariate time series are\nprocessed independently. Moreover, the multi-scale (long and short range)\nrepresentations are learned separately by two independent models without\ncommunication. In light of these concerns, we propose State Space Transformer\nwith cross-attention (S2TX). S2TX employs a cross-attention mechanism to\nintegrate a Mamba model for extracting long-range cross-variate context and a\nTransformer model with local window attention to capture short-range\nrepresentations. By cross-attending to the global context, the Transformer\nmodel further facilitates variate-level interactions as well as local\/global\ncommunications. Comprehensive experiments on seven classic long-short range\ntime-series forecasting benchmark datasets demonstrate that S2TX can achieve\nhighly robust SOTA results while maintaining a low memory footprint."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-825",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15851",
    "b_title":[
      "Zero-1-to-A: Zero-Shot One Image to Animatable Head Avatars Using Video\n  Diffusion"
    ],
    "b_abstract":[
      "Animatable head avatar generation typically requires extensive data for\ntraining. To reduce the data requirements, a natural solution is to leverage\nexisting data-free static avatar generation methods, such as pre-trained\ndiffusion models with score distillation sampling (SDS), which align avatars\nwith pseudo ground-truth outputs from the diffusion model. However, directly\ndistilling 4D avatars from video diffusion often leads to over-smooth results\ndue to spatial and temporal inconsistencies in the generated video. To address\nthis issue, we propose Zero-1-to-A, a robust method that synthesizes a spatial\nand temporal consistency dataset for 4D avatar reconstruction using the video\ndiffusion model. Specifically, Zero-1-to-A iteratively constructs video\ndatasets and optimizes animatable avatars in a progressive manner, ensuring\nthat avatar quality increases smoothly and consistently throughout the learning\nprocess. This progressive learning involves two stages: (1) Spatial Consistency\nLearning fixes expressions and learns from front-to-side views, and (2)\nTemporal Consistency Learning fixes views and learns from relaxed to\nexaggerated expressions, generating 4D avatars in a simple-to-complex manner.\nExtensive experiments demonstrate that Zero-1-to-A improves fidelity, animation\nquality, and rendering speed compared to existing diffusion-based methods,\nproviding a solution for lifelike avatar creation. Code is publicly available\nat: https:\/\/github.com\/ZhenglinZhou\/Zero-1-to-A."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.18337",
    "c_title":[
      "Coeff-Tuning: A Graph Filter Subspace View for Tuning Attention-Based\n  Large Models"
    ],
    "c_abstract":[
      "Transformer-based large pre-trained models have shown remarkable\ngeneralization ability, and various parameter-efficient fine-tuning (PEFT)\nmethods have been proposed to customize these models on downstream tasks with\nminimal computational and memory budgets. Previous PEFT methods are primarily\ndesigned from a tensor-decomposition perspective that tries to effectively tune\nthe linear transformation by finding the smallest subset of parameters to\ntrain. Our study adopts an orthogonal view by representing the attention\noperation as a graph convolution and formulating the multi-head attention maps\nas a convolutional filter subspace, with each attention map as a subspace\nelement. In this paper, we propose to tune the large pre-trained transformers\nby learning a small set of combination coefficients that construct a more\nexpressive filter subspace from the original multi-head attention maps. We show\nanalytically and experimentally that the tuned filter subspace can effectively\nexpand the feature space of the multi-head attention and further enhance the\ncapacity of transformers. We further stabilize the fine-tuning with a residual\nparameterization of the tunable subspace coefficients, and enhance the\ngeneralization with a regularization design by directly applying dropout on the\ntunable coefficient during training. The tunable coefficients take a tiny\nnumber of parameters and can be combined with previous PEFT methods in a\nplug-and-play manner. Extensive experiments show that our approach achieves\nsuperior performances than PEFT baselines with neglectable additional\nparameters."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-826",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14718",
    "b_title":[
      "Gland Segmentation Using SAM With Cancer Grade as a Prompt"
    ],
    "b_abstract":[
      "Cancer grade is a critical clinical criterion that can be used to determine\nthe degree of cancer malignancy. Revealing the condition of the glands, a\nprecise gland segmentation can assist in a more effective cancer grade\nclassification. In machine learning, binary classification information about\nglands (i.e., benign and malignant) can be utilized as a prompt for gland\nsegmentation and cancer grade classification. By incorporating prior knowledge\nof the benign or malignant classification of the gland, the model can\nanticipate the likely appearance of the target, leading to better segmentation\nperformance. We utilize Segment Anything Model to solve the segmentation task,\nby taking advantage of its prompt function and applying appropriate\nmodifications to the model structure and training strategies. We improve the\nresults from fine-tuned Segment Anything Model and produce SOTA results using\nthis approach."
    ],
    "b_categories":[
      [
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.08675",
    "c_title":[
      "Improving Lesion Segmentation in Medical Images by Global and Regional\n  Feature Compensation"
    ],
    "c_abstract":[
      "Automated lesion segmentation of medical images has made tremendous\nimprovements in recent years due to deep learning advancements. However,\naccurately capturing fine-grained global and regional feature representations\nremains a challenge. Many existing methods obtain suboptimal performance on\ncomplex lesion segmentation due to information loss during typical downsampling\noperations and the insufficient capture of either regional or global features.\nTo address these issues, we propose the Global and Regional Compensation\nSegmentation Framework (GRCSF), which introduces two key innovations: the\nGlobal Compensation Unit (GCU) and the Region Compensation Unit (RCU). The\nproposed GCU addresses resolution loss in the U-shaped backbone by preserving\nglobal contextual features and fine-grained details during multiscale\ndownsampling. Meanwhile, the RCU introduces a self-supervised learning (SSL)\nresidual map generated by Masked Autoencoders (MAE), obtained as pixel-wise\ndifferences between reconstructed and original images, to highlight regions\nwith potential lesions. These SSL residual maps guide precise lesion\nlocalization and segmentation through a patch-based cross-attention mechanism\nthat integrates regional spatial and pixel-level features. Additionally, the\nRCU incorporates patch-level importance scoring to enhance feature fusion by\nleveraging global spatial information from the backbone. Experiments on two\npublicly available medical image segmentation datasets, including brain stroke\nlesion and coronary artery calcification datasets, demonstrate that our GRCSF\noutperforms state-of-the-art methods, confirming its effectiveness across\ndiverse lesion types and its potential as a generalizable lesion segmentation\nsolution."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-827",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09145",
    "b_title":[
      "Charting 5G Energy Efficiency: Flexible Energy Modeling for Sustainable\n  Networks"
    ],
    "b_abstract":[
      "Despite the rapid advancements in 5G technology, accurately assessing the\nenergy consumption of its Radio Access Networks (RANs) remains a challenge due\nto the diverse range of applicable technologies and implementation solutions.\nDesigning a versatile power model for estimating the 5G RANspecific power\nconsumption requires extensive data collection and experimental studies to\ncapture the diverse range of technologies and implementation solutions. The\nobjective is to outline a versatile energy model capable of estimating\nRAN-specific energy consumption, encompassing both mobile terminals and the\nphysical layer (PHY) of base stations. In this paper, we focus on the\ncomputational complexity of the baseband part of the model. The developed (part\nof the) model is compared with the estimation of the number of cycles (and\nenergy per cycle) used by a specific implementation (here a Matlab code ported\non an Intel target), enabling the assessment of the model with the estimation\nof energy consumed on a real target. The study's results show a good agreement\nbetween the model and the implementation, even if some parts need to be refined\nto take specific algorithms into account. The key contribution is the\ndevelopment of an initial flexible energy model with finer granularity,\nenabling comparisons of energy use across various applications and contexts,\nand offering a comprehensive tool for optimizing 5G network energy consumption."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.13508",
    "c_title":[
      "IoT Performance for Maritime Passenger Evacuation"
    ],
    "c_abstract":[
      "The safe and swift evacuation of passengers from Maritime Vessels, requires\nan effective Internet of Things(IoT) as well as an information and\ncommunication technology(ICT) infrastructure. However, during emergencies,\ndelays in IoT and ICT systems that guide evacuees, can impair the evacuation\nprocess. This paper presents explores the impact of the key IoT and ICT\nelements. The methodology builds upon the deadline-aware adaptive navigation\nstrategy (ANT), which offers the path segment that minimizes the evacuation\ntime for each evacuee at each decision instant. The simulations on a real\ncruise ship configuration, show that delays in the delivery of correct\ninstructions to evacuees can significantly hinder the effectiveness of the\nevacuation. Our findings stress the need to design robust and computationally\nfast IoT and ICT systems to support the evacuation of passengers in ships, and\nunderscores the key role played by the IoT in the success of passenger\nevacuation and safety."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-828",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17210",
    "b_title":[
      "Depth Separable architecture for Sentinel-5P Super-Resolution"
    ],
    "b_abstract":[
      "Sentinel-5P (S5P) satellite provides atmospheric measurements for air quality\nand climate monitoring. While the S5P satellite offers rich spectral\nresolution, it inherits physical limitations that restricts its spatial\nresolution. Super-resolution (SR) techniques can overcome these limitations and\nenhance the spatial resolution of S5P data. In this work, we introduce a novel\nSR model specifically designed for S5P data that have eight spectral bands with\naround 500 channels for each band. Our proposed S5-DSCR model relies on Depth\nSeparable Convolution (DSC) architecture to effectively perform spatial SR by\nexploiting cross-channel correlations. Quantitative evaluation demonstrates\nthat our model outperforms existing methods for the majority of the spectral\nbands. This work highlights the potential of leveraging DSC architecture to\naddress the challenges of hyperspectral SR. Our model allows for capturing fine\ndetails necessary for precise analysis and paves the way for advancements in\nair quality monitoring as well as remote sensing applications."
    ],
    "b_categories":[
      [
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.03079",
    "c_title":[
      "Poisson Flow Joint Model for Multiphase contrast-enhanced CT"
    ],
    "c_abstract":[
      "In clinical practice, multiphase contrast-enhanced CT (MCCT) is important for\nphysiological and pathological imaging with contrast injection, which undergoes\nnon-contrast, venous, and delayed phases. Inevitably, the accumulated radiation\ndose to a patient is higher for multiphase scans than for a plain CT scan.\nLow-dose CECT is thus highly desirable, but it often leads to suboptimal image\nquality due to reduced radiation dose. Recently, a generalized Poisson flow\ngenerative model (PFGM++) was proposed to unify the diffusion model and the\nPoisson flow generative models (PFGM), and outperform either of them with an\noptimized dimensionality of the augmentation data space, holding a significant\npromise for generic or conditional image generation. In this paper, we propose\na Poisson flow joint model (PFJM) for low-dose MCCT to suppress image noise and\npreserve clinical features. Our model is built on the PFGM++ architecture to\ntransform the multiphase imaging problem into learning the joint distribution\nof routine-dose MCCT images by optimizing a task-specific generation path with\nrespect to the dimensionality D of the augmented data space. Then, our PFJM\nmodel takes the joint low-dose MCCT images as the condition and robustly drives\nthe generative trajectory towards the solution in the routine-dose MCCT domain.\nExtensive experiments demonstrate that our model is favorably compared with\ncompeting models, with MAE of 8.99 HU, SSIM of 98.75% and PSNR of 48.24db, as\naveraged over all the phases."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-829",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08610",
    "b_title":[
      "Multi-view Correlation-aware Network Traffic Detection on Flow\n  Hypergraph"
    ],
    "b_abstract":[
      "As the Internet rapidly expands, the increasing complexity and diversity of\nnetwork activities pose significant challenges to effective network governance\nand security regulation. Network traffic, which serves as a crucial data\ncarrier of network activities, has become indispensable in this process.\nNetwork traffic detection aims to monitor, analyze, and evaluate the data flows\ntransmitted across the network to ensure network security and optimize\nperformance. However, existing network traffic detection methods generally\nsuffer from several limitations: 1) a narrow focus on characterizing traffic\nfeatures from a single perspective; 2) insufficient exploration of\ndiscriminative features for different traffic; 3) poor generalization to\ndifferent traffic scenarios. To address these issues, we propose a multi-view\ncorrelation-aware framework named FlowID for network traffic detection. FlowID\ncaptures multi-view traffic features via temporal and interaction awareness,\nwhile a hypergraph encoder further explores higher-order relationships between\nflows. To overcome the challenges of data imbalance and label scarcity, we\ndesign a dual-contrastive proxy task, enhancing the framework's ability to\ndifferentiate between various traffic flows through traffic-to-traffic and\ngroup-to-group contrast. Extensive experiments on five real-world datasets\ndemonstrate that FlowID significantly outperforms existing methods in accuracy,\nrobustness, and generalization across diverse network scenarios, particularly\nin detecting malicious traffic."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14291",
    "c_title":[
      "A Note on Efficient Privacy-Preserving Similarity Search for Encrypted\n  Vectors"
    ],
    "c_abstract":[
      "Traditional approaches to vector similarity search over encrypted data rely\non fully homomorphic encryption (FHE) to enable computation without decryption.\nHowever, the substantial computational overhead of FHE makes it impractical for\nlarge-scale real-time applications. This work explores a more efficient\nalternative: using additively homomorphic encryption (AHE) for\nprivacy-preserving similarity search. We consider scenarios where either the\nquery vector or the database vectors remain encrypted, a setting that\nfrequently arises in applications such as confidential recommender systems and\nsecure federated learning. While AHE only supports addition and scalar\nmultiplication, we show that it is sufficient to compute inner product\nsimilarity--one of the most widely used similarity measures in vector\nretrieval. Compared to FHE-based solutions, our approach significantly reduces\ncomputational overhead by avoiding ciphertext-ciphertext multiplications and\nbootstrapping, while still preserving correctness and privacy. We present an\nefficient algorithm for encrypted similarity search under AHE and analyze its\nerror growth and security implications. Our method provides a scalable and\npractical solution for privacy-preserving vector search in real-world machine\nlearning applications."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-830",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05288",
    "b_title":[
      "Revealing the hidden cosmic feast: A z=4.3 galaxy group hosting two\n  optically dark, efficiently star-forming galaxies"
    ],
    "b_abstract":[
      "We present the confirmation of a compact galaxy group candidate, CGG-z4, at\n$z=4.3$ in the COSMOS field. This structure was identified by two\nspectroscopically confirmed $z=4.3$ $K_s$-dropout galaxies with ALMA $870\\rm\\,\n\\mu m$ and 3 mm continuum detections, surrounded by an overdensity of\nNIR-detected galaxies with consistent photometric redshifts of $4.0<z<4.6$. The\ntwo ALMA sources, CGG-z4.a and CGG-z4.b, are detected with both CO(4-3) and\nCO(5-4) lines. [CI](1-0) is detected on CGG-z4.a, and\nH$_{2}$O($1_{1,0}-1_{0,1}$) absorption is detected on CGG-z4.b. We model an\nintegrated spectral energy distribution by combining the FIR-to-radio\nphotometry of this group and estimate a total star formation rate of\n$\\rm\\sim2000\\, M_{\\odot}$ yr$^{-1}$, making it one of the most star-forming\ngroups known at $z>4$. Their high CO(5-4)\/CO(4-3) ratios indicate that the\ninter-stellar mediums (ISMs) are close to thermalization, suggesting either\nhigh gas temperatures, densities, and\/or pressure, while the low\n[CI](1-0)\/CO(4-3) line ratios indicate high star formation efficiencies. With\n[CI]-derived gas masses we found the two galaxies have extremely short gas\ndepletion times of $99$ Myr and $<63$ Myr respectively, suggesting the onset of\nquenching. With an estimated halo mass of $\\rm log (M_{\\rm\nhalo}[M_{\\odot}])\\sim12.8$, we suggest that this structure is likely in the\nprocess of forming a massive galaxy cluster."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04607",
    "c_title":[
      "Starburst Galaxies in Their Last Billion Years: An H${\\delta}$\n  Absorption Line Selected Sample"
    ],
    "c_abstract":[
      "In this paper, we focus on the study of starburst galaxies in their final\nbillion years. Our galaxy selection is based solely on the presence of the\nH${\\delta}$ absorption line, which permits tracing the later evolution of\nstarburst galaxies, coinciding with the emergence of A-type stars in these\ngalaxies. We propose a novel method that utilizes star formation rate and UVJ\ncolors to classify galaxies in the sample, and use the spectral features to\nmark their evolution stages. Our in-depth analysis of the MgII line indicates\nthe substantial increasing of F- and G-type stars when a galaxy evolves from\nstar forming to quiescent phase. Furthermore, we identify AGNs in this sample\nto explore their roles in the later stage of galaxy star formation history."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-831",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04676",
    "b_title":[
      "Refined regularity for nonlocal elliptic equations and applications"
    ],
    "b_abstract":[
      "In this paper, we establish refined regularity estimates for nonnegative\nsolutions to the fractional Poisson equation $$ (-\\Delta)^s u(x) =f(x),\\,\\,\nx\\in B_1(0). $$ Specifically, we have derived H\\\"{o}lder, Schauder, and\nLn-Lipschitz regularity estimates for any nonnegative solution $u,$ provided\nthat only the local $L^\\infty$ norm of $u$ is bounded. These estimates stand in\nsharp contrast to the existing results where the global $L^\\infty$ norm of $u$\nis required. Our findings indicate that the local values of the solution $u$\nand $f$ are sufficient to control the local values of higher order derivatives\nof $u$. Notably, this makes it possible to establish a priori estimates in\nunbounded domains by using blowing up and re-scaling argument.\n  As applications, we derive singularity and decay estimates for solutions to\nsome super-linear nonlocal problems in unbounded domains, and in particular, we\nobtain a priori estimates for a family of fractional Lane-Emden type equations\nin $\\mathbb{R}^n.$ This is achieved by adopting a different method using\nauxiliary functions, which is applicable to both local and nonlocal problems."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.17950",
    "c_title":[
      "The regularity of electronic wave functions in Barron spaces"
    ],
    "c_abstract":[
      "The electronic Schr\\\"odinger equation describes the motion of $N$ electrons\nunder Coulomb interaction forces in a field of clamped nuclei. It is proved\nthat its solutions for eigenvalues below the essential spectrum lie in the\nspectral Barron spaces $\\mathcal{B}^s(\\mathbb{R}^{3N})$ for $s<1$. The example\nof the hydrogen ground state shows that this result cannot be improved."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-832",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10742",
    "b_title":[
      "The Philosophical Foundations of Growing AI Like A Child"
    ],
    "b_abstract":[
      "Despite excelling in high-level reasoning, current language models lack\nrobustness in real-world scenarios and perform poorly on fundamental\nproblem-solving tasks that are intuitive to humans. This paper argues that both\nchallenges stem from a core discrepancy between human and machine cognitive\ndevelopment. While both systems rely on increasing representational power, the\nabsence of core knowledge-foundational cognitive structures in humans-prevents\nlanguage models from developing robust, generalizable abilities, where complex\nskills are grounded in simpler ones within their respective domains. It\nexplores empirical evidence of core knowledge in humans, analyzes why language\nmodels fail to acquire it, and argues that this limitation is not an inherent\narchitectural constraint. Finally, it outlines a workable proposal for\nsystematically integrating core knowledge into future multi-modal language\nmodels through the large-scale generation of synthetic training data using a\ncognitive prototyping strategy."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10782",
    "c_title":[
      "ML-SceGen: A Multi-level Scenario Generation Framework"
    ],
    "c_abstract":[
      "Current scientific research witnesses various attempts at applying Large\nLanguage Models for scenario generation but is inclined only to comprehensive\nor dangerous scenarios. In this paper, we seek to build a three-stage framework\nthat not only lets users regain controllability over the generated scenarios\nbut also generates comprehensive scenarios containing danger factors in\nuncontrolled intersection settings. In the first stage, LLM agents will\ncontribute to translating the key components of the description of the expected\nscenarios into Functional Scenarios. For the second stage, we use Answer Set\nProgramming (ASP) solver Clingo to help us generate comprehensive logical\ntraffic within intersections. During the last stage, we use LLM to update\nrelevant parameters to increase the critical level of the concrete scenario."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-833",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01197",
    "b_title":[
      "LayeringDiff: Layered Image Synthesis via Generation, then Disassembly\n  with Generative Knowledge"
    ],
    "b_abstract":[
      "Layers have become indispensable tools for professional artists, allowing\nthem to build a hierarchical structure that enables independent control over\nindividual visual elements. In this paper, we propose LayeringDiff, a novel\npipeline for the synthesis of layered images, which begins by generating a\ncomposite image using an off-the-shelf image generative model, followed by\ndisassembling the image into its constituent foreground and background layers.\nBy extracting layers from a composite image, rather than generating them from\nscratch, LayeringDiff bypasses the need for large-scale training to develop\ngenerative capabilities for individual layers. Furthermore, by utilizing a\npretrained off-the-shelf generative model, our method can produce diverse\ncontents and object scales in synthesized layers. For effective layer\ndecomposition, we adapt a large-scale pretrained generative prior to estimate\nforeground and background layers. We also propose high-frequency alignment\nmodules to refine the fine-details of the estimated layers. Our comprehensive\nexperiments demonstrate that our approach effectively synthesizes layered\nimages and supports various practical applications."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14129",
    "c_title":[
      "SketchFusion: Learning Universal Sketch Features through Fusing\n  Foundation Models"
    ],
    "c_abstract":[
      "While foundation models have revolutionised computer vision, their\neffectiveness for sketch understanding remains limited by the unique challenges\nof abstract, sparse visual inputs. Through systematic analysis, we uncover two\nfundamental limitations: Stable Diffusion (SD) struggles to extract meaningful\nfeatures from abstract sketches (unlike its success with photos), and exhibits\na pronounced frequency-domain bias that suppresses essential low-frequency\ncomponents needed for sketch understanding. Rather than costly retraining, we\naddress these limitations by strategically combining SD with CLIP, whose strong\nsemantic understanding naturally compensates for SD's spatial-frequency biases.\nBy dynamically injecting CLIP features into SD's denoising process and\nadaptively aggregating features across semantic levels, our method achieves\nstate-of-the-art performance in sketch retrieval (+3.35%), recognition\n(+1.06%), segmentation (+29.42%), and correspondence learning (+21.22%),\ndemonstrating the first truly universal sketch feature representation in the\nera of foundation models."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-834",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03760",
    "b_title":[
      "RAMOTS: A Real-Time System for Aerial Multi-Object Tracking based on\n  Deep Learning and Big Data Technology"
    ],
    "b_abstract":[
      "Multi-object tracking (MOT) in UAV-based video is challenging due to\nvariations in viewpoint, low resolution, and the presence of small objects.\nWhile other research on MOT dedicated to aerial videos primarily focuses on the\nacademic aspect by developing sophisticated algorithms, there is a lack of\nattention to the practical aspect of these systems. In this paper, we propose a\nnovel real-time MOT framework that integrates Apache Kafka and Apache Spark for\nefficient and fault-tolerant video stream processing, along with\nstate-of-the-art deep learning models YOLOv8\/YOLOv10 and BYTETRACK\/BoTSORT for\naccurate object detection and tracking. Our work highlights the importance of\nnot only the advanced algorithms but also the integration of these methods with\nscalable and distributed systems. By leveraging these technologies, our system\nachieves a HOTA of 48.14 and a MOTA of 43.51 on the Visdrone2019-MOT test set\nwhile maintaining a real-time processing speed of 28 FPS on a single GPU. Our\nwork demonstrates the potential of big data technologies and deep learning for\naddressing the challenges of MOT in UAV applications."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.05800",
    "c_title":[
      "MicroViT: A Vision Transformer with Low Complexity Self Attention for\n  Edge Device"
    ],
    "c_abstract":[
      "The Vision Transformer (ViT) has demonstrated state-of-the-art performance in\nvarious computer vision tasks, but its high computational demands make it\nimpractical for edge devices with limited resources. This paper presents\nMicroViT, a lightweight Vision Transformer architecture optimized for edge\ndevices by significantly reducing computational complexity while maintaining\nhigh accuracy. The core of MicroViT is the Efficient Single Head Attention\n(ESHA) mechanism, which utilizes group convolution to reduce feature redundancy\nand processes only a fraction of the channels, thus lowering the burden of the\nself-attention mechanism. MicroViT is designed using a multi-stage MetaFormer\narchitecture, stacking multiple MicroViT encoders to enhance efficiency and\nperformance. Comprehensive experiments on the ImageNet-1K and COCO datasets\ndemonstrate that MicroViT achieves competitive accuracy while significantly\nimproving 3.6 faster inference speed and reducing energy consumption with 40%\nhigher efficiency than the MobileViT series, making it suitable for deployment\nin resource-constrained environments such as mobile and edge devices."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-835",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01203",
    "b_title":[
      "Hypergraph Foundation Model"
    ],
    "b_abstract":[
      "Hypergraph neural networks (HGNNs) effectively model complex high-order\nrelationships in domains like protein interactions and social networks by\nconnecting multiple vertices through hyperedges, enhancing modeling\ncapabilities, and reducing information loss. Developing foundation models for\nhypergraphs is challenging due to their distinct data, which includes both\nvertex features and intricate structural information. We present Hyper-FM, a\nHypergraph Foundation Model for multi-domain knowledge extraction, featuring\nHierarchical High-Order Neighbor Guided Vertex Knowledge Embedding for vertex\nfeature representation and Hierarchical Multi-Hypergraph Guided Structural\nKnowledge Extraction for structural information. Additionally, we curate 10\ntext-attributed hypergraph datasets to advance research between HGNNs and LLMs.\nExperiments on these datasets show that Hyper-FM outperforms baseline methods\nby approximately 13.3\\%, validating our approach. Furthermore, we propose the\nfirst scaling law for hypergraph foundation models, demonstrating that\nincreasing domain diversity significantly enhances performance, unlike merely\naugmenting vertex and hyperedge counts. This underscores the critical role of\ndomain diversity in scaling hypergraph models."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.01402",
    "c_title":[
      "Best Transition Matrix Esitimation or Best Label Noise Robustness\n  Classifier? Two Possible Methods to Enhance the Performance of T-revision"
    ],
    "c_abstract":[
      "Label noise refers to incorrect labels in a dataset caused by human errors or\ncollection defects, which is common in real-world applications and can\nsignificantly reduce the accuracy of models. This report explores how to\nestimate noise transition matrices and construct deep learning classifiers that\nare robust against label noise. In cases where the transition matrix is known,\nwe apply forward correction and importance reweighting methods to correct the\nimpact of label noise using the transition matrix. When the transition matrix\nis unknown or inaccurate, we use the anchor point assumption and T-Revision\nseries methods to estimate or correct the noise matrix. In this study, we\nfurther improved the T-Revision method by developing T-Revision-Alpha and\nT-Revision-Softmax to enhance stability and robustness. Additionally, we\ndesigned and implemented two baseline classifiers, a Multi-Layer Perceptron\n(MLP) and ResNet-18, based on the cross-entropy loss function. We compared the\nperformance of these methods on predicting clean labels and estimating\ntransition matrices using the FashionMINIST dataset with known noise transition\nmatrices. For the CIFAR-10 dataset, where the noise transition matrix is\nunknown, we estimated the noise matrix and evaluated the ability of the methods\nto predict clean labels."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-836",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18932",
    "b_title":[
      "Cut edges and Central vertices of zero divisor graph of the ring of\n  integers modulo n"
    ],
    "b_abstract":[
      "The zero divisor graph of a commutative ring $R$ with unity is a graph whose\nvertices are the nonzero zero-divisors of the ring, with two distinct vertices\nbeing adjacent if their product is zero. This graph is denoted by $\\Gamma(R)$.\nIn this article we determine the cut-edges and central vertices in the graph\n$\\Gamma(\\mathbb{Z}_{n})$."
    ],
    "b_categories":[
      [
        "math.RA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.05619",
    "c_title":[
      "On the subalgebra lattice of solvable evolution algebras"
    ],
    "c_abstract":[
      "The main objective of this paper is to study the relationship between a\nsolvable evolution algebra and its subalgebra lattice, emphasizing two of its\nmain properties: distributivity and modularity. First, we will focus on the\nnilpotent case, where distributivity is characterised, and a necessary\ncondition for modularity is deduced. Subsequently, we comment on some results\nfor solvable non-nilpotent evolution algebras, finding that the ones with\nmaximum index of solvability have the best properties. Finally, we characterise\nmodularity in this particular case by introducing supersolvable evolution\nalgebras and computing the terms of the derived series."
    ],
    "c_categories":[
      [
        "math.RA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-837",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06028",
    "b_title":[
      "Improvements of convex-dense factorization of bivariate polynomials"
    ],
    "b_abstract":[
      "We develop a new algorithm for factoring a bivariate polynomial $F\\in\n\\mathbb{K}[x,y]$ which takes fully advantage of the geometry of the Newton\npolygon of $F$. Under a non degeneracy hypothesis, the complexity is\n$\\tilde{\\mathcal{O}}(Vr_0^{\\omega-1} )$ where $V$ is the volume of the polygon\nand $r_0$ is its minimal lower lattice length. This improves the complexity\n$\\tilde{\\mathcal{O}}(d^{\\omega+1})$ of the classical algorithms which consider\nthe total degree $d$ of $F$ as the main complexity indicator. The integer\n$r_0\\le d$ reflects some combinatorial constraints imposed by the Newton\npolygon, giving a reasonable and easy-to-compute upper bound for the number of\nits indecomposable Minkovski summands of positive volume. The proof is based on\na new fast factorization algorithm in $\\mathbb{K}[[x]][y]$ with respect to a\nslope valuation, a result which has its own interest."
    ],
    "b_categories":[
      [
        "math.AC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.04948",
    "c_title":[
      "Low-Rank Reduced Biquaternion Tensor Ring Decomposition and Tensor\n  Completion"
    ],
    "c_abstract":[
      "We define the reduced biquaternion tensor ring (RBTR) decomposition and\nprovide a detailed exposition of the corresponding algorithm RBTR-SVD.\nLeveraging RBTR decomposition, we propose a novel low-rank tensor completion\nalgorithm RBTR-TV integrating RBTR ranks with total variation (TV)\nregularization to optimize the process. Numerical experiments on color image\nand video completion tasks indicate the advantages of our method."
    ],
    "c_categories":[
      [
        "math.AC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-838",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05275",
    "b_title":[
      "Wafer-scale correlated morphology and optoelectronic properties in\n  GaAs\/AlGaAs core-shell nanowires"
    ],
    "b_abstract":[
      "Achieving uniform nanowire size, density, and alignment across a wafer is\nchallenging, as small variations in growth parameters can impact performance in\nenergy harvesting devices like solar cells and photodetectors. This study\ndemonstrates the in-depth characterization of uniformly grown GaAs\/AlGaAs\ncore-shell nanowires on a two-inch Si(111) substrate using Ga-induced\nself-catalyzed molecular beam epitaxy. By integrating Scanning Electron\nMicroscopy and Time Correlated Single-Photon Counting, we establish a detailed\nmodel of structural and optoelectronic properties across wafer and micron\nscales. While emission intensity varies by up to 35%, carrier lifetime shows\nonly 9% variation, indicating stable material quality despite structural\ninhomogeneities. These findings indicate that, for the two-inch GaAs\/AlGaAs\nnanowire wafer, achieving uniform nanowire coverage had a greater impact on\nconsistent optoelectronic properties than variations in material quality,\nhighlighting its significance for scalable III-V semiconductor integration on\nsilicon in advanced optoelectronic devices such as solar cells and\nphotodetectors."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.08012",
    "c_title":[
      "Gigahertz-Frequency, Acousto-Optic Phase Modulation of Visible Light in\n  a CMOS-Fabricated Photonic Circuit"
    ],
    "c_abstract":[
      "Here we present an efficient, visible-light, gigahertz-frequency\nacousto-optic modulator fabricated on a 200 mm wafer in a volume CMOS foundry.\nOur device combines a piezoelectric transducer and a photonic waveguide within\na single microstructure that confines both a propagating optical mode and an\nelectrically excitable breathing-mode mechanical resonance. By tuning the\ndevice's geometry to optimize the optomechanical interaction, we achieve\nmodulation depths exceeding 2 rad with 15 mW applied microwave power at 2.31\nGHz in a 2 mm long device. This corresponds to a modulation figure of merit of\n$V_{\\pi}\\cdot L$ = 0.26 Vcm in a visible-light, integrated acousto-optics\nplatform that can be straightforwardly extended to a wide range of optical\nwavelengths and modulation frequencies. For the important class of\ngigahertz-frequency modulators that can handle hundreds of milliwatts of\nvisible-light optical power, which are critical for scalable quantum control\nsystems, this represents a 15x decrease in $V_{\\pi}$ and a 100x decrease in\nrequired microwave power compared to the commercial state-of-the-art and\nexisting work in the literature."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-839",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10829",
    "b_title":[
      "Linear Relations of Finite Length Modules are Shift Equivalent to Maps"
    ],
    "b_abstract":[
      "Linear relations, defined as submodules of the direct sum of two modules, can\nbe viewed as objects that carry dynamical information and reflect the inherent\nuncertainty of sampled dynamics. These objects also provide an algebraic\nstructure that enables the definition of subtle invariants for dynamical\nsystems. In this paper, we prove that linear relations defined on modules of\nfinite length are shift equivalent to bijective mappings."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.01279",
    "c_title":[
      "On the dynamics of contact Hamiltonian systems II: Variational\n  construction of asymptotic orbits"
    ],
    "c_abstract":[
      "This paper is a continuation of our study of the dynamics of contact\nHamiltonian systems in \\cite{JY}, but without monotonicity assumption. Due to\nthe complexity of general cases, we focus on the behavior of action minimizing\norbits. We pick out certain action minimizing invariant sets\n$\\{\\widetilde{\\mathcal{N}}_u\\}$ in the phase space naturally stratified by\nsolutions $u$ to the corresponding Hamilton-Jacobi equation. Using an extension\nof characteristic method, we establish the existence of semi-infinite orbits\nthat is asymptotic to some $\\widetilde{\\mathcal{N}}_u$ and heteroclinic orbits\nbetween $\\widetilde{\\mathcal{N}}_u$ and $\\widetilde{\\mathcal{N}}_v$ for two\ndifferent solutions $u$ and $v$."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-840",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19875",
    "b_title":[
      "Reduced Basis Model for Compressible Flow"
    ],
    "b_abstract":[
      "Numerical simulations are a valuable research and layout tool for fluid flow\nproblems, yet repeated evaluations of parametrized problems, necessary to solve\noptimization problems, can be very costly. One option to speed up this process\nis to replace the costly CFD model with a cheaper one. These surrogate models\ncan be either data-driven or they can also rely on reduced basis (RB) methods\nto speed up the calculations. In contrast to data-driven surrogate models, the\nlatter are not based on regression techniques but are still aimed at explicitly\nsolving the conservation equations. Their speed-up comes from a strong\nreduction of the solution space, which results in much smaller algebraic\nsystems that need to be solved. Within this work, an RB model, suited for\nslightly compressible flow, is presented and tested on different flow\nconfigurations. The model is stabilized using a Petrov-Galerkin method with\ntrial and test function spaces of different dimensionality to generate stable\nresults for a wide range of Reynolds numbers. The presented model applies to\ngeometrically and physically parametrized flow problems. Finally, a data-driven\napproach was used to extend it to turbulent flows."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.13377",
    "c_title":[
      "Analysis of Brownian coagulation in the spatial mixing layer based on\n  average kernel coupled with iterative direct numerical simulation framework"
    ],
    "c_abstract":[
      "This study investigates the evolution of nanoparticle populations undergoing\nBrownian coagulation in a spatial mixing layer. The dynamics of particle size\ndistribution and number concentration are analyzed using a coupled Eulerian\napproach that combines fluid dynamics with aerosol dynamics. The mixing layer\nserves as a fundamental flow configuration to understand particle-vortex\ninteractions and their effect on coagulation rates. Results demonstrate that\nthe shear-induced spatial mixing significantly influences the spatial\ndistribution of nanoparticles and their subsequent coagulation behavior. The\nenhanced mixing in the shear layer leads to locally increased particle\ncollision frequencies, accelerating the coagulation process compared to laminar\nconditions. The study reveals that the evolution of the particle size\ndistribution is strongly dependent on both the local vorticity intensity and\nthe initial particle concentration gradients across the mixing layer."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-841",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11359",
    "b_title":[
      "Various notions of topological transitivity in non-autonomous and\n  generic dynamical systems"
    ],
    "b_abstract":[
      "We consider two types of dynamical systems namely non-autonomous discrete\ndynamical systems(NDDS) and generic dynamical systems(GDS). In both of them, we\nstudy various notions of transitivity. We give many equivalent conditions for\neach of these notions and present the implications among these in NDDS and GDS.\nFor a given NDDS, we associate a GDS and discuss whether if the given NDDS has\na particular variation of transitivity then the associated GDS also has such a\nvariation and vice versa."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.08077",
    "c_title":[
      "Horizontality of partially hyperbolic foliations"
    ],
    "c_abstract":[
      "We show exactly which Seifert manifolds support partially hyperbolic\ndynamical systems. In particular, a circle bundle over a higher-genus surface\nsupports a partially hyperbolic system if and only if it supports an Anosov\nflow. We also show for these systems that the center-stable and center-unstable\nfoliations can be isotoped so that their leaves are transverse to the circle\nfibering. As a consequence, every partially hyperbolic system defined on the\nunit tangent bundle of a higher-genus surface is a collapsed Anosov flow."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-842",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20314",
    "b_title":[
      "Adversarial Robustness in Parameter-Space Classifiers"
    ],
    "b_abstract":[
      "Implicit Neural Representations (INRs) have been recently garnering\nincreasing interest in various research fields, mainly due to their ability to\nrepresent large, complex data in a compact and continuous manner. Past work\nfurther showed that numerous popular downstream tasks can be performed directly\nin the INR parameter-space. Doing so can substantially reduce the computational\nresources required to process the represented data in their native domain. A\nmajor difficulty in using modern machine-learning approaches, is their high\nsusceptibility to adversarial attacks, which have been shown to greatly limit\nthe reliability and applicability of such methods in a wide range of settings.\nIn this work, we show that parameter-space models trained for classification\nare inherently robust to adversarial attacks -- without the need of any robust\ntraining. To support our claims, we develop a novel suite of adversarial\nattacks targeting parameter-space classifiers, and furthermore analyze\npractical considerations of attacking parameter-space classifiers."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16918",
    "c_title":[
      "On Rollouts in Model-Based Reinforcement Learning"
    ],
    "c_abstract":[
      "Model-based reinforcement learning (MBRL) seeks to enhance data efficiency by\nlearning a model of the environment and generating synthetic rollouts from it.\nHowever, accumulated model errors during these rollouts can distort the data\ndistribution, negatively impacting policy learning and hindering long-term\nplanning. Thus, the accumulation of model errors is a key bottleneck in current\nMBRL methods. We propose Infoprop, a model-based rollout mechanism that\nseparates aleatoric from epistemic model uncertainty and reduces the influence\nof the latter on the data distribution. Further, Infoprop keeps track of\naccumulated model errors along a model rollout and provides termination\ncriteria to limit data corruption. We demonstrate the capabilities of Infoprop\nin the Infoprop-Dyna algorithm, reporting state-of-the-art performance in\nDyna-style MBRL on common MuJoCo benchmark tasks while substantially increasing\nrollout length and data quality."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-843",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03054",
    "b_title":[
      "Federated Learning Meets Fluid Antenna: Towards Robust and Scalable Edge\n  Intelligence"
    ],
    "b_abstract":[
      "Federated learning (FL) is an emerging machine learning paradigm with immense\npotential to support advanced services and applications in future industries.\nHowever, when deployed over wireless communication systems, FL suffers from\nsignificant communication overhead, which can be alleviated by integrating\nover-the-air computation (AirComp). Despite its advantages, AirComp introduces\nlearning inaccuracies due to the inherent randomness of wireless channels,\nwhich can degrade overall learning performance. To address this issue, this\npaper explores the integration of fluid antenna systems (FAS) into\nAirComp-based FL to enhance system robustness and efficiency. Fluid antennas\noffer dynamic spatial diversity by adaptively selecting antenna ports, thereby\nmitigating channel variations and improving signal aggregation. Specifically,\nwe propose an antenna selection rule for fluid-antenna-equipped devices that\noptimally enhances learning robustness or training performance. Building on\nthis, we develop a learning algorithm and provide a theoretical convergence\nanalysis. The simulation results validate the effectiveness of fluid antennas\nin improving FL performance, demonstrating their potential as a key enabler for\nwireless AI applications."
    ],
    "b_categories":[
      [
        "eess.SP"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08851",
    "c_title":[
      "Age of Positioning with Stochastic Motion Models"
    ],
    "c_abstract":[
      "Age of Information (AoI) is a key metric used for evaluating data freshness\nin communication networks, particularly in systems requiring real-time updates.\nIn positioning applications, maintaining low AoI is critical for ensuring\ntimely and accurate position estimation. This paper introduces an age-informed\nmetric, which we term as Age of Positioning (AoP), that captures the temporal\nevolution of positioning accuracy for agents following random trajectories and\nsharing sporadic location updates. Using the widely adopted Random Waypoint\n(RWP) mobility model, which captures stochastic user movement through\nwaypoint-based trajectories, we derive closed-form expressions for this metric\nunder various queuing disciplines and different modes of operation of the\nagent. The analytical results are verified with numerical simulations, and the\nexistence of optimal operating conditions is demonstrated."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-844",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01121",
    "b_title":[
      "PatchRefiner V2: Fast and Lightweight Real-Domain High-Resolution Metric\n  Depth Estimation"
    ],
    "b_abstract":[
      "While current high-resolution depth estimation methods achieve strong\nresults, they often suffer from computational inefficiencies due to reliance on\nheavyweight models and multiple inference steps, increasing inference time. To\naddress this, we introduce PatchRefiner V2 (PRV2), which replaces heavy refiner\nmodels with lightweight encoders. This reduces model size and inference time\nbut introduces noisy features. To overcome this, we propose a Coarse-to-Fine\n(C2F) module with a Guided Denoising Unit for refining and denoising the\nrefiner features and a Noisy Pretraining strategy to pretrain the refiner\nbranch to fully exploit the potential of the lightweight refiner branch.\nAdditionally, we introduce a Scale-and-Shift Invariant Gradient Matching\n(SSIGM) loss to enhance synthetic-to-real domain transfer. PRV2 outperforms\nstate-of-the-art depth estimation methods on UnrealStereo4K in both accuracy\nand speed, using fewer parameters and faster inference. It also shows improved\ndepth boundary delineation on real-world datasets like CityScape, ScanNet++,\nand KITTI, demonstrating its versatility across domains."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10197",
    "c_title":[
      "CSHNet: A Novel Information Asymmetric Image Translation Method"
    ],
    "c_abstract":[
      "Despite advancements in cross-domain image translation, challenges persist in\nasymmetric tasks such as SAR-to-Optical and Sketch-to-Instance conversions,\nwhich involve transforming data from a less detailed domain into one with\nricher content. Traditional CNN-based methods are effective at capturing fine\ndetails but struggle with global structure, leading to unwanted merging of\nimage regions. To address this, we propose the CNN-Swin Hybrid Network\n(CSHNet), which combines two key modules: Swin Embedded CNN (SEC) and CNN\nEmbedded Swin (CES), forming the SEC-CES-Bottleneck (SCB). SEC leverages CNN's\ndetailed feature extraction while integrating the Swin Transformer's structural\nbias. CES, in turn, preserves the Swin Transformer's global integrity,\ncompensating for CNN's lack of focus on structure. Additionally, CSHNet\nincludes two components designed to enhance cross-domain information retention:\nthe Interactive Guided Connection (IGC), which enables dynamic information\nexchange between SEC and CES, and Adaptive Edge Perception Loss (AEPL), which\nmaintains structural boundaries during translation. Experimental results show\nthat CSHNet outperforms existing methods in both visual quality and performance\nmetrics across scene-level and instance-level datasets. Our code is available\nat: https:\/\/github.com\/XduShi\/CSHNet."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-845",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03219",
    "b_title":[
      "The Impact of Expanding HII Regions on Filament G37:Curved Magnetic\n  Field and Multiple Direction Material Flows"
    ],
    "b_abstract":[
      "Filament G37 exhibits a distinctive \"caterpillar\" shape, characterized by two\nsemicircular structures within its 40\\,pc-long body, providing an ideal target\nto investigate the formation and evolution of filaments. By analyzing multiple\nobservational data, such as CO spectral line, the H$\\alpha$\\,RRL, and\nmulti-wavelength continuum, we find that the expanding H\\,{\\scriptsize II}\nregions surrounding filament G37 exert pressure on the structure of the\nfilament body, which kinetic process present as the gas flows in multiple\ndirections along its skeleton. The curved magnetic field structure of filament\nG37 derived by employing the Velocity Gradient Technique with CO is found to be\nparallel to the filament body and keeps against the pressure from expanded\nH\\,{\\scriptsize II} regions. The multi-directional flows in the filament G37\ncould cause the accumulation and subsequent collapse of gas, resulting in the\nformation of massive clumps. The curved structure and star formation observed\nin filament G37 are likely a result of the filament body being squeezed by the\nexpanding H\\,{\\scriptsize II} region. This physical process occurs over a\ntimescale of approximately 5\\,Myr. The filament G37 provides a potential\ncandidate for end-dominated collapse."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.02748",
    "c_title":[
      "Probing the Merger Rates of Supermassive Black Holes and Galaxies with\n  Gravitational Waves"
    ],
    "c_abstract":[
      "The mergers of galaxies and supermassive black holes (SMBHs) are key drivers\nof galaxy evolution, contributing to the growth of both galaxies and their\ncentral black holes. Current projects like Pulsar Timing Arrays (PTAs) and\nupcoming missions such as the Laser Interferometer Space Antenna (LISA), Taiji,\nand Tianqin are designed to detect gravitational waves (GWs) emitted by SMBH\nbinaries during their inspiral and merger phases. We investigate the capability\nto probe the merger rates of SMBHs and their host galaxies by combining current\nPTA detections and mock GW data for LISA-like detectors, while incorporating\nobservational constraints from the $M_{\\bullet}-M_*$ relationship and galaxy\nstellar mass functions. Our findings highlight the critical role of GW\ndetections with LISA-like detectors in exploring the merger rates of galaxies\nand SMBHs and the timescale of SMBH mergers. Additionally, incorporating PTA\nconstraints on the stochastic gravitational wave background further refines\nmodel parameters and reduces uncertainties. Gravitational wave detections offer\nan independent method for estimating galaxy merger rates, providing a valuable\nconsistency check against rates derived from galaxy pair observations and\ncosmological simulations. Furthermore, comparing SMBH mass assembly through\nmergers with growth via accretion provides key insights into the evolutionary\nhistory of SMBHs, with the timescale of SMBH binary mergers playing a\nsignificant role in shaping their merger rates and merger mass assembly."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-846",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.11253",
    "b_title":[
      "The Q-Spellbook: Crafting Surface Code Layouts and Magic State Protocols\n  for Large-Scale Quantum Computing"
    ],
    "b_abstract":[
      "Quantum error correction is a cornerstone of reliable quantum computing, with\nsurface codes emerging as a prominent method for protecting quantum\ninformation. Surface codes are efficient for Clifford gates but require magic\nstate distillation protocols to process non-Clifford gates, such as T gates,\nessential for universal quantum computation. In large-scale quantum\narchitectures capable of correcting arbitrary circuits, specialized surface\ncodes for data qubits and distinct codes for magic state distillation are\nneeded. These architectures can be organized into data blocks and distillation\nblocks. The system works by having distillation blocks produce magic states and\ndata blocks consume them, causing stalls due to either a shortage or excess of\nmagic states. This bottleneck presents an opportunity to optimize quantum space\nby balancing data and distillation blocks. While prior research offers insights\ninto selecting distillation protocols and estimating qubit requirements, it\nlacks a tailored optimization approach. We present a framework for optimizing\nlarge-scale quantum architectures, focusing on data block layouts and magic\nstate distillation protocols. We evaluate three data block layouts and four\ndistillation protocols under three optimization strategies: minimizing tiles,\nminimizing steps, and achieving a balanced trade-off. Through a comparative\nanalysis of brute force, dynamic programming, greedy, and random algorithms, we\nfind that brute force delivers optimal results, while greedy deviates by 7% for\nminimizing steps and dynamic programming matches brute force in tile\nminimization. We observe that total steps increase with columns, while total\ntiles scale with qubits. Finally, we propose a heuristic to help users select\nalgorithms suited to their objectives, enabling scalable and efficient quantum\narchitectures."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.06959",
    "c_title":[
      "Joint Cutting for Hybrid Schr\\\"odinger-Feynman Simulation of Quantum\n  Circuits"
    ],
    "c_abstract":[
      "Despite the continuous advancements in size and robustness of real quantum\ndevices, reliable large-scale quantum computers are not yet available. Hence,\nclassical simulation of quantum algorithms remains crucial for testing new\nmethods and estimating quantum advantage. Pushing classical simulation methods\nto their limit is essential, particularly due to their inherent exponential\ncomplexity. Besides the established Schr\\\"odinger-style full statevector\nsimulation, so-called Hybrid Schr\\\"odinger-Feynman (HSF) approaches have shown\npromise to make simulations more efficient. HSF simulation employs the idea of\n\"cutting\" the circuit into smaller parts, reducing their execution times. This,\nhowever, comes at the cost of an exponential overhead in the number of cuts.\nInspired by the domain of Quantum Circuit Cutting, we propose an HSF simulation\nmethod based on the idea of \"joint cutting\" to significantly reduce the\naforementioned overhead. This means that, prior to the cutting procedure, gates\nare collected into \"blocks\" and all gates in a block are jointly cut instead of\nindividually. We investigate how the proposed refinement can help decrease\nsimulation times and highlight the remaining challenges. Experimental\nevaluations show that \"joint cutting\" can outperform the standard HSF\nsimulation by up to a factor $\\approx 4000\\times$ and the Schr\\\"odinger-style\nsimulation by a factor $\\approx 200\\times$ for suitable instances. The\nimplementation is available at\nhttps:\/\/github.com\/cda-tum\/mqt-qsim-joint-cutting."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-847",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13173",
    "b_title":[
      "Normalizing Flows for Gaussian Process Regression under Hierarchical\n  Shrinkage Priors"
    ],
    "b_abstract":[
      "Gaussian Process Regression (GPR) is a powerful tool for nonparametric\nregression, but its fully Bayesian application in high-dimensional settings is\nhindered by two primary challenges: the computational burden (exacerbated by\nfully Bayesian inference) and the difficulty of variable selection. This paper\nintroduces a novel methodology that combines hierarchical global-local\nshrinkage priors with normalizing flows to address these challenges. The\nhierarchical triple gamma prior offers a principled framework for inducing\nsparsity in high-dimensional GPR, effectively excluding irrelevant covariates\nwhile preserving interpretability and flexibility in model size. Normalizing\nflows are employed within a variational inference framework to approximate the\nposterior distribution of hyperparameters, capturing complex dependencies while\nensuring computational scalability. Simulation studies demonstrate the efficacy\nof the proposed approach, outperforming traditional maximum likelihood\nestimation and mean-field variational methods, particularly in high-sparsity\nand high-dimensional settings. The results highlight the robustness and\nflexibility of hierarchical shrinkage priors and the computational efficiency\nof normalizing flows for Bayesian GPR. This work provides a scalable and\ninterpretable solution for high-dimensional regression, with implications for\nsparse modeling and posterior approximation in broader Bayesian contexts."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.11449",
    "c_title":[
      "Irregular measurement times in estimating time-varying treatment\n  effects: Categorizing biases and comparing adjustment methods"
    ],
    "c_abstract":[
      "To estimate the causal effect of treatments that vary over time from\nobservational data, one must adjust for time-varying confounding. A common\nprocedure to address confounding is the use of inverse probability of treatment\nweighting methods. However, the timing of covariate measurements is often\nirregular, which may introduce additional confounding bias as well as selection\nbias into the causal effect estimate. Two reweighting methods have been\nproposed to adjust for these biases: time-as-confounder and reweighting by\nmeasurement time. However, it is currently not well understood in which\nsituations these irregularly timed measurements induce bias, and how the\navailable reweighting methods compare to each other in different situations. In\nthis work, we provide a complete inventarization of all possible backdoor paths\nthrough which bias is induced. Based on these paths, we distinguish three\ncategories of confounding bias by measurement time: direct confounding (DC),\nconfounding through measured variables (CMV), and confounding through\nunmeasured variables (CUV). These categories differ in the assumptions and\nreweighting methods necessary to adjust for bias and may occur simultaneously\nwith selection bias. Through simulation studies, we illustrate: 1. Reweighting\nby measurement time may be used to adjust for selection bias and confounding\nthrough measured variables; 2. Time-as-confounder may be used to adjust for all\ncategories of confounding bias, but not selection bias; 3. In some cases, the\nuse of a combination of both techniques may be used to adjust for both\nconfounding and selection bias. We finally apply the categorization and\nreweighting methods on the pre-DIVA data set. Adjusting for measurement times\nis crucial in order to avoid bias, and the categorization of biases and\ntechniques that we introduce may help researchers to choose the appropriate\nanalysis."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-848",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07520",
    "b_title":[
      "Three-dimensional transport of solids in a protoplanetary disk\n  containing a growing giant planet"
    ],
    "b_abstract":[
      "We present the results of combined hydrodynamic and particle tracking\npost-processing modeling to study the transport of small dust in a\nprotoplanetary disk containing an embedded embryo in 3D. We use a suite of\nFARGO3D hydrodynamic simulations of disks containing a planetary embryo varying\nin mass up to 300 $M_\\oplus$ on a fixed orbit in both high and low viscosity\ndisks. We then simulate solid particles through the disk as a post-processing\nstep using a Monte Carlo integration, allowing us to track the trajectories of\nindividual particles as they travel throughout the disk. We find that gas\nadvection onto the planet can carry small, well-coupled solids across the gap\nopened in the disk by the embedded planet for planetary masses above the pebble\nisolation mass. This mixing between the inner and outer disk can occur in both\ndirections, with solids in the inner disk mixing to the outer disk as well.\nAdditionally, in low viscosity disks, multiple pile-ups in the outer disk may\npreserve isotopic heterogeneities, possibly providing an outermost tertiary\nisotopic reservoir. Throughout Jupiter's growth, the extent of mixing between\nisotopic reservoirs varied depending on dust size, gas turbulence, and the\nJovian embryo mass."
    ],
    "b_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.17509",
    "c_title":[
      "The current cratering rate on the regular satellites of Jupiter, Saturn,\n  and Uranus"
    ],
    "c_abstract":[
      "We aim to compute the impact rates for objects with a diameter of 1 km onto\nthe regular satellites of Jupiter, Saturn and Uranus using our latest dynamical\nsimulations of the evolution of outer solar system coupled with the best\nestimates of the current population of objects beyond Neptune and their\nsize-frequency distribution. We use the outcome of the last 3.5~Gyr of\nevolution of the outer solar system from our database of simulations and\ncombine this with observational constraints of the population beyond Neptune to\ncompute the flux of objects entering the Centaur region, with uncertainties.\nThe initial conditions resemble the current population rather than a\nnear-circular, near-planar disc usually assumed just before the onset of giant\nplanet migration. We obtain a better estimate of the impact probability of a\nCentaur with the satellites from enacting simulations of planetesimals flying\npast the satellites on hyperbolic orbits, which agree with literature\nprecedents. We find that our impact rate of objects greater than 1 km in\ndiameter with Jupiter is 0.0012\/yr, which is a factor of 3--6 lower than\nprevious estimates of 0.0044\/yr from Nesvorny et al. (2023) and 0.0075\/yr from\nZahnle et al. (2003). On the other hand our impact probabilities with the\nsatellites scaled to the giant planets are consistent with these earlier\nliterature estimates, as is the leakage rate of objects from beyond Neptune\ninto the Centaur region. However, our absolute impact probabilities with the\ngiant planets are lower. We attribute this to our choice of initial conditions."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-849",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11598",
    "b_title":[
      "Thermodynamics of the Hubbard Model on the Bethe Lattice"
    ],
    "b_abstract":[
      "We investigate the thermodynamic properties of the Hubbard model on the Bethe\nlattice with a coordination number of 3 using the thermal canonical tree tensor\nnetwork method. Our findings reveal two distinct thermodynamic phases: a\nlow-temperature antiferromagnetic phase, where spin SU(2) symmetry is broken,\nand a high-temperature paramagnetic phase. A key feature of the system is the\nseparation of energy scales for charge and spin excitations, which is reflected\nin the temperature dependence of thermodynamic quantities and the disparity\nbetween spin and charge gaps extracted from their respective susceptibilities.\nAt the critical point, both spin and charge susceptibilities exhibit\nsingularities, suggesting that charge excitations are not fully decoupled from\ntheir spin counterparts. Additionally, the double occupancy number exhibits a\nnon-monotonic temperature dependence, indicative of an entropy-driven\nPomeranchuk effect. These results demonstrate that the loopless Bethe lattice\neffectively captures the essential physics of the Hubbard model while providing\na computationally efficient framework for studying strongly correlated\nelectronic systems."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.10889",
    "c_title":[
      "Analytic Formulas for the Anomalous Hall Effect in Itinerant Magnets"
    ],
    "c_abstract":[
      "We clarify the origin of what is sometimes called the \"topological anomalous\nHall effect,\" provide analytical formulas to compute all the contributions to\nthe Hall conductivity in the presence of Kondo-coupled spins and spin orbit\ncoupling. The derivation is technical but we emphasize that the results can be\nvery easily applied."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-850",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04718",
    "b_title":[
      "Evaluating Text Style Transfer Evaluation: Are There Any Reliable\n  Metrics?"
    ],
    "b_abstract":[
      "Text Style Transfer (TST) is the task of transforming a text to reflect a\nparticular style while preserving its original content. Evaluating TST outputs\nis a multidimensional challenge, requiring the assessment of style transfer\naccuracy, content preservation, and naturalness. Using human evaluation is\nideal but costly, same as in other natural language processing (NLP) tasks,\nhowever, automatic metrics for TST have not received as much attention as\nmetrics for, e.g., machine translation or summarization. In this paper, we\nexamine both set of existing and novel metrics from broader NLP tasks for TST\nevaluation, focusing on two popular subtasks-sentiment transfer and\ndetoxification-in a multilingual context comprising English, Hindi, and\nBengali. By conducting meta-evaluation through correlation with human\njudgments, we demonstrate the effectiveness of these metrics when used\nindividually and in ensembles. Additionally, we investigate the potential of\nLarge Language Models (LLMs) as tools for TST evaluation. Our findings\nhighlight that certain advanced NLP metrics and experimental-hybrid-techniques,\nprovide better insights than existing TST metrics for delivering more accurate,\nconsistent, and reproducible TST evaluations."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11078",
    "c_title":[
      "DEEPER Insight into Your User: Directed Persona Refinement for Dynamic\n  Persona Modeling"
    ],
    "c_abstract":[
      "To advance personalized applications such as recommendation systems and user\nbehavior prediction, recent research increasingly adopts large language models\n(LLMs) for human -readable persona modeling. In dynamic real -world scenarios,\neffective persona modeling necessitates leveraging streaming behavior data to\ncontinually optimize user personas. However, existing methods -whether\nregenerating personas or incrementally extending them with new behaviors -often\nfail to achieve sustained improvements in persona quality or future behavior\nprediction accuracy. To address this, we propose DEEPER, a novel approach for\ndynamic persona modeling that enables continual persona optimization.\nSpecifically, we enhance the model's direction -search capability through an\niterative reinforcement learning framework, allowing it to automatically\nidentify effective update directions and optimize personas using discrepancies\nbetween user behaviors and model predictions. Extensive experiments on dynamic\npersona modeling involving 4800 users across 10 domains highlight the superior\npersona optimization capabilities of DEEPER, delivering an impressive 32.2%\naverage reduction in user behavior prediction error over four update rounds\n-outperforming the best baseline by a remarkable 22.92%."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-851",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18867",
    "b_title":[
      "Enhanced Transformer-Based Tracking for Skiing Events: Overcoming\n  Multi-Camera Challenges, Scale Variations and Rapid Motion -- SkiTB Visual\n  Tracking Challenge 2025"
    ],
    "b_abstract":[
      "Accurate skier tracking is essential for performance analysis, injury\nprevention, and optimizing training strategies in alpine sports. Traditional\ntracking methods often struggle with occlusions, dynamic movements, and varying\nenvironmental conditions, limiting their effectiveness. In this work, we used\nSTARK (Spatio-Temporal Transformer Network for Visual Tracking), a\ntransformer-based model, to track skiers. We adapted STARK to address\ndomain-specific challenges such as camera movements, camera changes,\nocclusions, etc. by optimizing the model's architecture and hyperparameters to\nbetter suit the dataset."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02510",
    "c_title":[
      "Remote Sensing Image Classification Using Convolutional Neural Network\n  (CNN) and Transfer Learning Techniques"
    ],
    "c_abstract":[
      "This study investigates the classification of aerial images depicting\ntransmission towers, forests, farmland, and mountains. To complete the\nclassification job, features are extracted from input photos using a\nConvolutional Neural Network (CNN) architecture. Then, the images are\nclassified using Softmax. To test the model, we ran it for ten epochs using a\nbatch size of 90, the Adam optimizer, and a learning rate of 0.001. Both\ntraining and assessment are conducted using a dataset that blends\nself-collected pictures from Google satellite imagery with the MLRNet dataset.\nThe comprehensive dataset comprises 10,400 images. Our study shows that\ntransfer learning models and MobileNetV2 in particular, work well for landscape\ncategorization. These models are good options for practical use because they\nstrike a good mix between precision and efficiency; our approach achieves\nresults with an overall accuracy of 87% on the built CNN model. Furthermore, we\nreach even higher accuracies by utilizing the pretrained VGG16 and MobileNetV2\nmodels as a starting point for transfer learning. Specifically, VGG16 achieves\nan accuracy of 90% and a test loss of 0.298, while MobileNetV2 outperforms both\nmodels with an accuracy of 96% and a test loss of 0.119; the results\ndemonstrate the effectiveness of employing transfer learning with MobileNetV2\nfor classifying transmission towers, forests, farmland, and mountains."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-852",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07873",
    "b_title":[
      "Quantum multiphase estimation"
    ],
    "b_abstract":[
      "Quantum phase estimation is fundamental to advancing quantum science and\ntechnology. While much of the research has concentrated on estimating a single\nphase, the simultaneous estimation of multiple phases can yield significantly\nenhanced sensitivities when using specially tailored input quantum states. This\nwork reviews recent theoretical and experimental advancements in the parallel\nestimation of multiple arbitrary phases. We highlight strategies for\nconstructing optimal measurement protocols and discuss the experimental\nplatforms best suited for implementing these techniques."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10597",
    "c_title":[
      "Electrically-triggered spin-photon devices in silicon"
    ],
    "c_abstract":[
      "Quantum networking and computing technologies demand scalable hardware with\nhigh-speed control for large systems of quantum devices. Solid-state platforms\nhave emerged as promising candidates, offering scalable fabrication for a wide\nrange of qubits. Architectures based on spin-photon interfaces allow for\nhighly-connected quantum networks over photonic links, enabling entanglement\ndistribution for quantum networking and distributed quantum computing\nprotocols. With the potential to address these demands, optically-active spin\ndefects in silicon are one proposed platform for building quantum technologies.\nHere, we electrically excite the silicon T centre in integrated optoelectronic\ndevices that combine nanophotonic waveguides and cavities with p-i-n diodes. We\nobserve single-photon electroluminescence from a cavity-coupled T centre with\n$g^{(2)}(0)=0.05(2)$. Further, we use the electrically-triggered emission to\nherald the electron spin state, initializing it with $92(8)\\%$ fidelity. This\nshows, for the first time, electrically-injected single-photon emission from a\nsilicon colour centre and a new method of electrically-triggered spin\ninitialization. These findings present a new telecommunications band light\nsource for silicon and a highly parallel control method for T centre quantum\nprocessors, advancing the T centre as a versatile defect for scalable quantum\ntechnologies."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-853",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.15346",
    "b_title":[
      "Playing against a stationary opponent"
    ],
    "b_abstract":[
      "This paper investigates properties of Blackwell $\\epsilon$-optimal strategies\nin zero-sum stochastic games when the adversary is restricted to stationary\nstrategies, motivated by applications to robust Markov decision processes. For\na class of absorbing games, we show that Markovian Blackwell $\\epsilon$-optimal\nstrategies may fail to exist, yet we prove the existence of Blackwell\n$\\epsilon$-optimal strategies that can be implemented by a two-state automaton\nwhose internal transitions are independent of actions. For more general\nabsorbing games, however, there need not exist Blackwell $\\epsilon$-optimal\nstrategies that are independent of the adversary's decisions. Our findings\npoint to a contrast between absorbing games and generalized Big Match games,\nand provide new insights into the properties of optimal policies for robust\nMarkov decision processes."
    ],
    "b_categories":[
      [
        "cs.GT"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07593",
    "c_title":[
      "Decision-Making Under Complete Uncertainty: You Will Regret Not Being\n  Greedy"
    ],
    "c_abstract":[
      "In this paper, we propose a probabilistic game-theoretic model to study the\nproperties of the worst-case regret of the greedy strategy under complete\n(Knightian) uncertainty. In a game between a decision-maker (DM) and an\nadversarial agent (Nature), the DM observes a realization of product ratings\nfor each product. Upon observation, the DM chooses a strategy, which is a\nfunction from the set of observations to the set of products. We study the\ntheoretical properties, including the worst-case regret of the greedy strategy\nthat chooses the product with the highest observed average rating. We prove\nthat, with respect to the worst-case regret, the greedy strategy is optimal and\nthat, in the limit, the regret of the greedy strategy converges to zero. We\nvalidate the model on data collected from Google reviews for restaurants,\nshowing that the greedy strategy not only performs according to the theoretical\nfindings but also outperforms the uniform strategy and the Thompson Sampling\nalgorithm."
    ],
    "c_categories":[
      [
        "cs.GT"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-854",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11693",
    "b_title":[
      "Nehari-type ground state solutions for asymptotically periodic\n  bi-harmonic Kirchhoff-type problems in $\\mathbb{R}^N$"
    ],
    "b_abstract":[
      "We investigate the following Kirchhoff-type biharmonic equation\n\\begin{equation}\\label{pr} \\left\\{ \\begin{array}{ll} \\Delta^2 u+\n\\left(a+b\\int_{\\mathbb{R}^N}|\\nabla u|^2d x\\right)(-\\Delta\nu+V(x)u)=f(x,u),\\quad x\\in \\mathbb{R}^N,\\\\ u\\in H^{2}(\\mathbb{R}^N),\n\\end{array} \\right. \\end{equation} where $a>0$, $b\\geq 0$ and $V(x)$ and $f(x,\nu)$ are periodic or asymptotically periodic in $x$. We study the existence of\nNehari-type ground state solutions of \\eqref{pr} with $f(x,u)u-4F(x,u)$\nsign-changing, where $F(x,u):=\\int_0^uf(x,s)d s$. We significantly extend some\nresults from the previous literature."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.13333",
    "c_title":[
      "Chain-structure solutions to a Schr\\\"odinger-Poisson system in\n  $\\mathbb{R}^3$"
    ],
    "c_abstract":[
      "We prove the existence of ground states and high-energy solutions to the\nfollowing Schr\\\"odinger-Poisson system\n  \\begin{align*}\n  \\begin{cases}\n  - \\Delta u + a(x) u + u v = 0,\\newline\n  \\Delta v = u^2,\n  \\end{cases}\n  \\quad \\text{in } \\mathbb{R}^3,\n  \\end{align*}\n  where $a \\in L^\\infty(\\mathbb{R}^3)$ is nonnegative and radially symmetric in\nthe first two variables. Differing from the standard approach, our framework\nyields chain-structure solutions, i.e. solutions periodic in the third\nvariable. A central part of this work is the construction of the Green function\nof a Poisson problem subject to periodic boundary conditions and we show that\nits asymptotic profile is tightly related to both the two and three dimensional\nPoisson problems in the entire space. If the potential $a$ is constant along\nthe third variable, we apply symmetry techniques to construct solutions that\nhave nonvanishing derivative in the third variable."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-855",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10005",
    "b_title":[
      "The dual notion of morphic modules over commutative rings"
    ],
    "b_abstract":[
      "Let R be a commutative ring with identity and M be an R-module. The purpose\nof this paper is to introduce and investigate the dual notion of morphic\nmodules over a commutative ring."
    ],
    "b_categories":[
      [
        "math.AC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.03407",
    "c_title":[
      "On finitary power monoids of linearly orderable monoids"
    ],
    "c_abstract":[
      "A commutative monoid $M$ is called a linearly orderable monoid if there\nexists a total order on $M$ that is compatible with the monoid operation. The\nfinitary power monoid of a commutative monoid $M$ is the monoid consisting of\nall nonempty finite subsets of $M$ under the so-called sumset. In this paper,\nwe investigate whether certain atomic and divisibility properties ascend from\nlinearly orderable monoids to their corresponding finitary power monoids."
    ],
    "c_categories":[
      [
        "math.AC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-856",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13598",
    "b_title":[
      "Polarization tensor in spacetime of three dimensions and quantum field\n  theoretical description of the nonequilibrium Casimir force in graphene\n  systems"
    ],
    "b_abstract":[
      "The polarization tensor of graphene derived in the framework of the Dirac\nmodel using the methods of thermal quantum field theory in (2+1) dimensions is\nrecast in a mathematically equivalent but more compact and convenient in\ncomputations form along the real frequency axis. The obtained unified\nexpressions for the components of the polarization tensor are equally\napplicable in the regions of the on- and off-the-mass-shell electromagnetic\nwaves. The advantages of the presented formalism are demonstrated on the\nexample of nonequilibrium Casimir force in the configuration of two parallel\ngraphene-coated dielectric plates one of which is either hotter or colder than\nthe environment. This force is investigated as a function of temperature, the\nenergy gap, and chemical potential of graphene coatings with account of the\neffects of spatial dispersion. Besides the thermodynamically nonequilibrium\nCasimir and Casimir-Polder forces, the obtained form of the polarization tensor\ncan be useful for investigation of many diverse physical phenomena in graphene\nsystems, such as surface plasmons, reflectances, electrical conductivity,\nradiation heat transfer, etc."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.09483",
    "c_title":[
      "Constant Overhead Entanglement Distillation via Scrambling"
    ],
    "c_abstract":[
      "High-fidelity quantum entanglement enables key quantum networking\ncapabilities such as secure communication and distributed quantum computing,\nbut distributing entangled states through optical fibers is limited by noise\nand loss. Entanglement distillation protocols address this problem by\nextracting high-fidelity Bell pairs from multiple noisy ones. The primary\nobjective is minimizing the resource overhead: the number of noisy input pairs\nneeded to distill each high-fidelity output pair. While protocols achieving\noptimal overhead are known in theory, they often require complex decoding\noperations that make practical implementation challenging. We circumvent this\nchallenge by introducing protocols that use quantum scrambling - the spreading\nof quantum information under chaotic dynamics - through random Clifford\noperations. Based on this scrambling mechanism, we design a distillation\nprotocol that maintains asymptotically constant overhead, independent of the\ndesired output error rate $\\bar{\\varepsilon}$, and can be implemented with\nshallow quantum circuits of depth $O(\\operatorname{poly} \\log \\log\n\\bar{\\varepsilon}^{-1})$ and memory $O(\\operatorname{poly} \\log\n\\bar{\\varepsilon}^{-1})$. We show this protocol remains effective even with\nnoisy quantum gates, making it suitable for near-term devices. Furthermore, by\nincorporating partial error correction, our protocol achieves state-of-the-art\nperformance: starting with pairs of 10% initial infidelity, we require only 7\nnoisy inputs per output pair to distill a single Bell pair with infidelity\n$\\bar{\\varepsilon}=10^{-12}$, substantially outperforming existing schemes.\nFinally, we demonstrate the utility of our protocols through applications to\nquantum repeater networks."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-857",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06482",
    "b_title":[
      "PathVQ: Reforming Computational Pathology Foundation Model for Whole\n  Slide Image Analysis via Vector Quantization"
    ],
    "b_abstract":[
      "Computational pathology and whole-slide image (WSI) analysis are pivotal in\ncancer diagnosis and prognosis. However, the ultra-high resolution of WSIs\npresents significant modeling challenges. Recent advancements in pathology\nfoundation models have improved performance, yet most approaches rely on [CLS]\ntoken representation of tile ViT as slide-level inputs (16x16 pixels is\nrefereed as patch and 224x224 pixels as tile). This discards critical spatial\ndetails from patch tokens, limiting downstream WSI analysis tasks. We find that\nleveraging all spatial patch tokens benefits WSI analysis but incurs nearly\n200x higher storage and training costs (e.g., 196 tokens in ViT$_{224}$). To\naddress this, we introduce vector quantized (VQ) distillation on patch feature,\nwhich efficiently compresses spatial patch tokens using discrete indices and a\ndecoder. Our method reduces token dimensionality from 1024 to 16, achieving a\n64x compression rate while preserving reconstruction fidelity. Furthermore, we\nemploy a multi-scale VQ (MSVQ) strategy, which not only enhances VQ\nreconstruction performance but also serves as a Self-supervised Learning (SSL)\nsupervision for a seamless slide-level pretraining objective. Built upon the\nquantized patch features and supervision targets of tile via MSVQ, we develop a\nprogressive convolutional module and slide-level SSL to extract representations\nwith rich spatial-information for downstream WSI tasks. Extensive evaluations\non multiple datasets demonstrate the effectiveness of our approach, achieving\nstate-of-the-art performance in WSI analysis. Code will be available soon."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18984",
    "c_title":[
      "Context Matters: Query-aware Dynamic Long Sequence Modeling of Gigapixel\n  Images"
    ],
    "c_abstract":[
      "Whole slide image (WSI) analysis presents significant computational\nchallenges due to the massive number of patches in gigapixel images. While\ntransformer architectures excel at modeling long-range correlations through\nself-attention, their quadratic computational complexity makes them impractical\nfor computational pathology applications. Existing solutions like local-global\nor linear self-attention reduce computational costs but compromise the strong\nmodeling capabilities of full self-attention. In this work, we propose Querent,\ni.e., the query-aware long contextual dynamic modeling framework, which\nmaintains the expressive power of full self-attention while achieving practical\nefficiency. Our method adaptively predicts which surrounding regions are most\nrelevant for each patch, enabling focused yet unrestricted attention\ncomputation only with potentially important contexts. By using efficient\nregion-wise metadata computation and importance estimation, our approach\ndramatically reduces computational overhead while preserving global perception\nto model fine-grained patch correlations. Through comprehensive experiments on\nbiomarker prediction, gene mutation prediction, cancer subtyping, and survival\nanalysis across over 10 WSI datasets, our method demonstrates superior\nperformance compared to the state-of-the-art approaches. Code will be made\navailable at https:\/\/github.com\/dddavid4real\/Querent."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-858",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09282",
    "b_title":[
      "A Case Study on Model Checking and Runtime Verification for Awkernel"
    ],
    "b_abstract":[
      "In operating system development, concurrency poses significant challenges. It\nis difficult for humans to manually review concurrent behaviors or to write\ntest cases covering all possible executions, often resulting in critical bugs.\nPreemption in schedulers serves as a typical example. This paper proposes a\ndevelopment method for concurrent software, such as schedulers. Our method\nincorporates model checking as an aid for tracing code, simplifying the\nanalysis of concurrent behavior; we refer to this as model checking-assisted\ncode review. While this approach aids in tracing behaviors, the accuracy of the\nresults is limited because of the semantics gap between the modeling language\nand the programming language. Therefore, we also introduce runtime verification\nto address this limitation in model checking-assisted code review. We applied\nour approach to a real-world operating system, Awkernel, as a case study. This\nnew operating system, currently under development for autonomous driving, is\ndesigned for preemptive task execution using asynchronous functions in Rust.\nAfter implementing our method, we identified several bugs that are difficult to\ndetect through manual reviews or simple tests."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.14000",
    "c_title":[
      "LLM-based Unit Test Generation for Dynamically-Typed Programs"
    ],
    "c_abstract":[
      "Automated unit test generation has been widely studied, but generating\neffective tests for dynamically typed programs remains a significant challenge.\nExisting approaches, including search-based software testing (SBST) and recent\nLLM-based methods, often suffer from type errors, leading to invalid inputs and\nassertion failures, ultimately reducing testing effectiveness. To address this,\nwe propose TypeTest, a novel framework that enhances type correctness in test\ngeneration through a vector-based Retrieval-Augmented Generation (RAG) system.\nTypeTest employs call instance retrieval and feature-based retrieval to infer\nparameter types accurately and construct valid test inputs. Furthermore, it\nutilizes the call graph to extract richer contextual information, enabling more\naccurate assertion generation. In addition, TypeTest incorporates a repair\nmechanism and iterative test generation, progressively refining test cases to\nimprove coverage. In an evaluation on 125 real-world Python modules, TypeTest\nachieved an average statement coverage of 86.6% and branch coverage of 76.8%,\noutperforming state-of-theart tools by 5.4% and 9.3%, respectively."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-859",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06338",
    "b_title":[
      "Zero-shot Depth Completion via Test-time Alignment with Affine-invariant\n  Depth Prior"
    ],
    "b_abstract":[
      "Depth completion, predicting dense depth maps from sparse depth measurements,\nis an ill-posed problem requiring prior knowledge. Recent methods adopt\nlearning-based approaches to implicitly capture priors, but the priors\nprimarily fit in-domain data and do not generalize well to out-of-domain\nscenarios. To address this, we propose a zero-shot depth completion method\ncomposed of an affine-invariant depth diffusion model and test-time alignment.\nWe use pre-trained depth diffusion models as depth prior knowledge, which\nimplicitly understand how to fill in depth for scenes. Our approach aligns the\naffine-invariant depth prior with metric-scale sparse measurements, enforcing\nthem as hard constraints via an optimization loop at test-time. Our zero-shot\ndepth completion method demonstrates generalization across various domain\ndatasets, achieving up to a 21\\% average performance improvement over the\nprevious state-of-the-art methods while enhancing spatial understanding by\nsharpening scene details. We demonstrate that aligning a monocular\naffine-invariant depth prior with sparse metric measurements is a proven\nstrategy to achieve domain-generalizable depth completion without relying on\nextensive training data. Project page:\nhttps:\/\/hyoseok1223.github.io\/zero-shot-depth-completion\/."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.04314",
    "c_title":[
      "S2Gaussian: Sparse-View Super-Resolution 3D Gaussian Splatting"
    ],
    "c_abstract":[
      "In this paper, we aim ambitiously for a realistic yet challenging problem,\nnamely, how to reconstruct high-quality 3D scenes from sparse low-resolution\nviews that simultaneously suffer from deficient perspectives and clarity.\nWhereas existing methods only deal with either sparse views or low-resolution\nobservations, they fail to handle such hybrid and complicated scenarios. To\nthis end, we propose a novel Sparse-view Super-resolution 3D Gaussian Splatting\nframework, dubbed S2Gaussian, that can reconstruct structure-accurate and\ndetail-faithful 3D scenes with only sparse and low-resolution views. The\nS2Gaussian operates in a two-stage fashion. In the first stage, we initially\noptimize a low-resolution Gaussian representation with depth regularization and\ndensify it to initialize the high-resolution Gaussians through a tailored\nGaussian Shuffle Split operation. In the second stage, we refine the\nhigh-resolution Gaussians with the super-resolved images generated from both\noriginal sparse views and pseudo-views rendered by the low-resolution\nGaussians. In which a customized blur-free inconsistency modeling scheme and a\n3D robust optimization strategy are elaborately designed to mitigate multi-view\ninconsistency and eliminate erroneous updates caused by imperfect supervision.\nExtensive experiments demonstrate superior results and in particular\nestablishing new state-of-the-art performances with more consistent geometry\nand finer details."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-860",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20909",
    "b_title":[
      "Improved Bound on the Number of Pseudoline Arrangements via the Zone\n  Theorem"
    ],
    "b_abstract":[
      "Pseudoline arrangements are fundamental objects in discrete and computational\ngeometry, and different works have tackled the problem of improving the known\nbounds on the number of simple arrangements of $n$ pseudolines over the past\ndecades. The lower bound in particular has seen two successive improvements in\nrecent years (Dumitrescu and Mandal in 2020 and Cort\\'es K\\\"uhnast et al. in\n2024). Here we focus on the upper bound, and show that for large enough $n$,\nthere are at most $2^{0.6496n^2}$ different simple arrangements of $n$\npseudolines. This follows a series of incremental improvements starting with\nwork by Knuth in 1992 showing a bound of roughly $2^{0.7925n^2},$ then a bound\nof $2^{0.6975n^2}$ by Felsner in 1997, and finally the previous best known\nbound of $2^{0.6572n^2}$ by Felsner and Valtr in 2011. The improved bound\npresented here follows from a simple argument to combine the approach of this\nlatter work with the use of the Zone Theorem."
    ],
    "b_categories":[
      [
        "cs.CG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.10786",
    "c_title":[
      "External Incremental Delaunay Triangulation"
    ],
    "c_abstract":[
      "This paper introduces a Delaunay triangulation algorithm based on the\nexternal incremental method. Unlike traditional random incremental methods,\nthis approach uses convex hull and points as basic operational units instead of\ntriangles. Since each newly added point is outside the convex hull, there is no\nneed to search for which triangle contains the point, simplifying the algorithm\nimplementation. The time complexity for point sorting is $O(n\\log n)$, while\nthe collective complexity for upper\/lower tangent searches is proven to be\n$O(n)$. For uniformly distributed point sets, empirical results demonstrate\nlinear time $O(n)$ for full triangulation construction. The overall time\ncomplexity remains $O(n\\log n)$. This paper details the algorithm's data\nstructures, implementation details, correctness proof, and comparison with\nother methods."
    ],
    "c_categories":[
      [
        "cs.CG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-861",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12663",
    "b_title":[
      "Demystifying Multilingual Chain-of-Thought in Process Reward Modeling"
    ],
    "b_abstract":[
      "Large language models (LLMs) are designed to perform a wide range of tasks.\nTo improve their ability to solve complex problems requiring multi-step\nreasoning, recent research leverages process reward modeling to provide\nfine-grained feedback at each step of the reasoning process for reinforcement\nlearning (RL), but it predominantly focuses on English. In this paper, we\ntackle the critical challenge of extending process reward models (PRMs) to\nmultilingual settings. To achieve this, we train multilingual PRMs on a dataset\nspanning seven languages, which is translated from English. Through\ncomprehensive evaluations on two widely used reasoning benchmarks across 11\nlanguages, we demonstrate that multilingual PRMs not only improve average\naccuracy but also reduce early-stage reasoning errors. Furthermore, our results\nhighlight the sensitivity of multilingual PRMs to both the number of training\nlanguages and the volume of English data, while also uncovering the benefits\narising from more candidate responses and trainable parameters. This work opens\npromising avenues for robust multilingual applications in complex, multi-step\nreasoning tasks. In addition, we release the code to foster research along this\nline."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.12836",
    "c_title":[
      "An LLM-Powered Agent for Physiological Data Analysis: A Case Study on\n  PPG-based Heart Rate Estimation"
    ],
    "c_abstract":[
      "Large language models (LLMs) are revolutionizing healthcare by improving\ndiagnosis, patient care, and decision support through interactive\ncommunication. More recently, they have been applied to analyzing physiological\ntime-series like wearable data for health insight extraction. Existing methods\nembed raw numerical sequences directly into prompts, which exceeds token limits\nand increases computational costs. Additionally, some studies integrated\nfeatures extracted from time-series in textual prompts or applied multimodal\napproaches. However, these methods often produce generic and unreliable outputs\ndue to LLMs' limited analytical rigor and inefficiency in interpreting\ncontinuous waveforms. In this paper, we develop an LLM-powered agent for\nphysiological time-series analysis aimed to bridge the gap in integrating LLMs\nwith well-established analytical tools. Built on the OpenCHA, an open-source\nLLM-powered framework, our agent features an orchestrator that integrates user\ninteraction, data sources, and analytical tools to generate accurate health\ninsights. To evaluate its effectiveness, we implement a case study on heart\nrate (HR) estimation from Photoplethysmogram (PPG) signals using a dataset of\nPPG and Electrocardiogram (ECG) recordings in a remote health monitoring study.\nThe agent's performance is benchmarked against OpenAI GPT-4o-mini and GPT-4o,\nwith ECG serving as the gold standard for HR estimation. Results demonstrate\nthat our agent significantly outperforms benchmark models by achieving lower\nerror rates and more reliable HR estimations. The agent implementation is\npublicly available on GitHub."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-862",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12898",
    "b_title":[
      "The Relationship Between Head Injury and Alzheimer's Disease: A Causal\n  Analysis with Bayesian Networks"
    ],
    "b_abstract":[
      "This study examines the potential causal relationship between head injury and\nthe risk of developing Alzheimer's disease (AD) using Bayesian networks and\nregression models. Using a dataset of 2,149 patients, we analyze key medical\nhistory variables, including head injury history, memory complaints,\ncardiovascular disease, and diabetes. Logistic regression results suggest an\nodds ratio of 0.88 for head injury, indicating a potential but statistically\ninsignificant protective effect against AD. In contrast, memory complaints\nexhibit a strong association with AD, with an odds ratio of 4.59. Linear\nregression analysis further confirms the lack of statistical significance for\nhead injury (coefficient: -0.0245, p = 0.469) while reinforcing the predictive\nimportance of memory complaints. These findings highlight the complex interplay\nof medical history factors in AD risk assessment and underscore the need for\nfurther research utilizing larger datasets and advanced causal modeling\ntechniques."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06300",
    "c_title":[
      "The impact of allocation strategies in subset learning on the expressive\n  power of neural networks"
    ],
    "c_abstract":[
      "In traditional machine learning, models are defined by a set of parameters,\nwhich are optimized to perform specific tasks. In neural networks, these\nparameters correspond to the synaptic weights. However, in reality, it is often\ninfeasible to control or update all weights. This challenge is not limited to\nartificial networks but extends to biological networks, such as the brain,\nwhere the extent of distributed synaptic weight modification during learning\nremains unclear. Motivated by these insights, we theoretically investigate how\ndifferent allocations of a fixed number of learnable weights influence the\ncapacity of neural networks. Using a teacher-student setup, we introduce a\nbenchmark to quantify the expressivity associated with each allocation. We\nestablish conditions under which allocations have maximal or minimal expressive\npower in linear recurrent neural networks and linear multi-layer feedforward\nnetworks. For suboptimal allocations, we propose heuristic principles to\nestimate their expressivity. These principles extend to shallow ReLU networks\nas well. Finally, we validate our theoretical findings with empirical\nexperiments. Our results emphasize the critical role of strategically\ndistributing learnable weights across the network, showing that a more\nwidespread allocation generally enhances the network's expressive power."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-863",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06292",
    "b_title":[
      "Occupancy-SLAM: An Efficient and Robust Algorithm for Simultaneously\n  Optimizing Robot Poses and Occupancy Map"
    ],
    "b_abstract":[
      "Joint optimization of poses and features has been extensively studied and\ndemonstrated to yield more accurate results in feature-based SLAM problems.\nHowever, research on jointly optimizing poses and non-feature-based maps\nremains limited. Occupancy maps are widely used non-feature-based environment\nrepresentations because they effectively classify spaces into obstacles, free\nareas, and unknown regions, providing robots with spatial information for\nvarious tasks. In this paper, we propose Occupancy-SLAM, a novel\noptimization-based SLAM method that enables the joint optimization of robot\ntrajectory and the occupancy map through a parameterized map representation.\nThe key novelty lies in optimizing both robot poses and occupancy values at\ndifferent cell vertices simultaneously, a significant departure from existing\nmethods where the robot poses need to be optimized first before the map can be\nestimated. Evaluations using simulations and practical 2D laser datasets\ndemonstrate that the proposed approach can robustly obtain more accurate robot\ntrajectories and occupancy maps than state-of-the-art techniques with\ncomparable computational time. Preliminary results in the 3D case further\nconfirm the potential of the proposed method in practical 3D applications,\nachieving more accurate results than existing methods."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.05301",
    "c_title":[
      "A Helping (Human) Hand in Kinematic Structure Estimation"
    ],
    "c_abstract":[
      "Visual uncertainties such as occlusions, lack of texture, and noise present\nsignificant challenges in obtaining accurate kinematic models for safe robotic\nmanipulation. We introduce a probabilistic real-time approach that leverages\nthe human hand as a prior to mitigate these uncertainties. By tracking the\nconstrained motion of the human hand during manipulation and explicitly\nmodeling uncertainties in visual observations, our method reliably estimates an\nobject's kinematic model online. We validate our approach on a novel dataset\nfeaturing challenging objects that are occluded during manipulation and offer\nlimited articulations for perception. The results demonstrate that by\nincorporating an appropriate prior and explicitly accounting for uncertainties,\nour method produces accurate estimates, outperforming two recent baselines by\n195% and 140%, respectively. Furthermore, we demonstrate that our approach's\nestimates are precise enough to allow a robot to manipulate even small objects\nsafely."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-864",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14739",
    "b_title":[
      "SuperGPQA: Scaling LLM Evaluation across 285 Graduate Disciplines"
    ],
    "b_abstract":[
      "Large language models (LLMs) have demonstrated remarkable proficiency in\nmainstream academic disciplines such as mathematics, physics, and computer\nscience. However, human knowledge encompasses over 200 specialized disciplines,\nfar exceeding the scope of existing benchmarks. The capabilities of LLMs in\nmany of these specialized fields-particularly in light industry, agriculture,\nand service-oriented disciplines-remain inadequately evaluated. To address this\ngap, we present SuperGPQA, a comprehensive benchmark that evaluates\ngraduate-level knowledge and reasoning capabilities across 285 disciplines. Our\nbenchmark employs a novel Human-LLM collaborative filtering mechanism to\neliminate trivial or ambiguous questions through iterative refinement based on\nboth LLM responses and expert feedback. Our experimental results reveal\nsignificant room for improvement in the performance of current state-of-the-art\nLLMs across diverse knowledge domains (e.g., the reasoning-focused model\nDeepSeek-R1 achieved the highest accuracy of 61.82% on SuperGPQA), highlighting\nthe considerable gap between current model capabilities and artificial general\nintelligence. Additionally, we present comprehensive insights from our\nmanagement of a large-scale annotation process, involving over 80 expert\nannotators and an interactive Human-LLM collaborative system, offering valuable\nmethodological guidance for future research initiatives of comparable scope."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14095",
    "c_title":[
      "Retrieving Versus Understanding Extractive Evidence in Few-Shot Learning"
    ],
    "c_abstract":[
      "A key aspect of alignment is the proper use of within-document evidence to\nconstruct document-level decisions. We analyze the relationship between the\nretrieval and interpretation of within-document evidence for large language\nmodel in a few-shot setting. Specifically, we measure the extent to which model\nprediction errors are associated with evidence retrieval errors with respect to\ngold-standard human-annotated extractive evidence for five datasets, using two\npopular closed proprietary models. We perform two ablation studies to\ninvestigate when both label prediction and evidence retrieval errors can be\nattributed to qualities of the relevant evidence. We find that there is a\nstrong empirical relationship between model prediction and evidence retrieval\nerror, but that evidence retrieval error is mostly not associated with evidence\ninterpretation error--a hopeful sign for downstream applications built on this\nmechanism."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-865",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05826",
    "b_title":[
      "The Fertile Steppe: Computability Logic and the decidability of one of\n  its fragments"
    ],
    "b_abstract":[
      "The present work is devoted to Computability Logic (CoL), the young and\nvolcanic research-project developed by Giorgi Japaridze. Our main goal is to\nprovide the reader with a clear panoramic view of this vast new land, starting\nfrom its core knots and making our way towards the outer threads, in a somewhat\nthree-dimensional, spacial gait. Furthermore, through the present work, we\nprovide a tentative proof for the decidability of one of CoL's numerous\naxiomatisations, namely CL15. Thus, our expedition initially takes off for an\naerial, perusal overview of this fertile steppe. The first chapter introduces\nCoL in a philosophical fashion, exposing and arguing its main key points. We\nthen move over to unfold its semantics and syntax profiles, allowing the reader\nto become increasingly more familiar with this new environment. Landing on to\nthe second chapter, we thoroughly introduce Cirquent Calculus, the new\ndeductive system Japaridze has developed in order to axiomatise Computability\nLogic. Indeed, this new proof-system can also be a useful tool for many other\nlogics. We then review each of the 17 axiomatisations found so far. The third\nchapter zooms-in on CL15, in order to come up with a possible solution to its\nopen problem. We outline its soundness and completeness proofs; then provide\nsome few deductive examples; and, finally, build a tentative proof of its\ndecidability. Lastly, the fourth chapter focuses on the potential and actual\napplications of Computability Logic, both in arithmetic (clarithmetic) and in\nArtificial Intelligence systems (meaning knowledgebase and planning-and-action\nones). We close our journey with some final remarks on the richness of this\nframework and, hence, the research-worthiness it entails."
    ],
    "b_categories":[
      [
        "cs.LO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.09227",
    "c_title":[
      "Bridging Logic Programming and Deep Learning for Explainability through\n  ILASP"
    ],
    "c_abstract":[
      "My research explores integrating deep learning and logic programming to set\nthe basis for a new generation of AI systems. By combining neural networks with\nInductive Logic Programming (ILP), the goal is to construct systems that make\naccurate predictions and generate comprehensible rules to validate these\npredictions. Deep learning models process and analyze complex data, while ILP\ntechniques derive logical rules to prove the network's conclusions. Explainable\nAI methods, like eXplainable Answer Set Programming (XASP), elucidate the\nreasoning behind these rules and decisions. The focus is on applying ILP\nframeworks, specifically ILASP and FastLAS, to enhance explainability in\nvarious domains. My test cases span weather prediction, the legal field, and\nimage recognition. In weather forecasting, the system will predict events and\nprovides explanations using FastLAS, with plans to integrate recurrent neural\nnetworks in the future. In the legal domain, the research focuses on\ninterpreting vague decisions and assisting legal professionals by encoding\nItalian legal articles and learning reasoning patterns from Court of Cassation\ndecisions using ILASP. For biological laboratories, we will collaborate with a\nresearch group to automate spermatozoa morphology classification for Bull\nBreeding Soundness Evaluation using YOLO networks and ILP to explain\nclassification outcomes. This hybrid approach aims to bridge the gap between\nthe high performance of deep learning models and the transparency of symbolic\nreasoning, advancing AI by providing interpretable and trustworthy\napplications."
    ],
    "c_categories":[
      [
        "cs.LO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-866",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01736",
    "b_title":[
      "Energy spectrum and mass composition of cosmic rays from Phase I data\n  measured using the Pierre Auger Observatory"
    ],
    "b_abstract":[
      "The Pierre Auger Observatory concluded its first phase of data taking after\nseventeen years of operation. The dataset collected by its surface and\nfluorescence detectors (FD and SD) provides us with the most precise estimates\nof the energy spectrum and mass composition of ultra-high energy cosmic rays\nyet available. We present measurements of the depth of shower maximum, the main\nquantity used to derive species of primary particles, determined either from\nthe direct observation of longitudinal profiles of showers by the FD, or\nindirectly through the analysis of signals in the SD stations. The energy\nspectrum of primaries is also determined from both FD and SD measurements,\nwhere the former exhibits lower systematic uncertainty in the energy\ndetermination while the latter exploits unprecedentedly large exposure. The\ndata for primaries with energy below 1 EeV are also available thanks to the\nhigh-elevation telescopes of FD and the denser array of SD, making measurements\npossible down to 6 PeV and 60 PeV, respectively."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.17766",
    "c_title":[
      "GRB timing: decoding the hidden slow jets in GRB 060729"
    ],
    "c_abstract":[
      "Gamma-ray bursts (GRBs) are luminous stellar explosions characterized by the\nejection of relativistic jets. This work proposes a novel paradigm to study\nthese GRB jets. By analyzing the timing information of prompt pulses and X-ray\nflares, in conjunction with the multi-wavelength afterglow observations, we\nidentify three distinct jets in the extraordinary GRB 060729, with initial bulk\nLorentz factors ranging from approximately 40 to 80, smaller than typical\nvalues of $> 100$. These three jets undergo two successive collisions,\nproducing the observed pair of X-ray flares. Following these interactions, the\nsystem evolves into a fast, narrow jet and a slower, hollow jet that continues\nto propagate in the circumburst medium, evidenced by the notable twin bumps\nobserved in the X-ray and optical afterglow of GRB 060729. Our findings\ndemonstrate that the timing of the early emission enables us to measure the\nvelocities of the GRB jets. The proposed paradigm enhances our understanding of\njet dynamics and shock interactions and serves as a powerful tool for probing\nthe physics of the central engine with the expanded sample in the current\ngolden era of GRB research."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-867",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16607",
    "b_title":[
      "Predictions for Detecting a Turndown in the Baryonic Tully Fisher\n  Relation"
    ],
    "b_abstract":[
      "The baryonic Tully Fisher relation (bTFR) provides an empirical connection\nbetween baryonic mass and dynamical mass (measured by the maximum rotation\nvelocity) for galaxies. Due to the impact of baryonic feedback in the shallower\npotential wells of dwarf galaxies, the bTFR is predicted to turn down at low\nmasses from the extrapolated power-law relation at high masses. The low-mass\nend of the bTFR is poorly constrained due to small samples and difficulty in\nconnecting the galaxy's gas kinematics to its dark matter halo. Simulations can\nhelp us understand this connection and interpret observations. We measure the\nbTFR with 66 dwarf galaxies from the Marvel-ous and Marvelous Massive Dwarfs\nhydrodynamic simulations. Our sample has M$_\\star = 10^6-10^9$ M$_\\odot$, and\nis mostly gas dominated. We compare five velocity methods: V$_\\text{out,circ}$\n(spatially resolved mass-enclosed), V$_\\text{out,mid}$ (spatially resolved\nmidplane gravitational potential), and unresolved HI linewidths at different\npercentages of the peak flux (W$_\\text{10}$, W$_\\text{20}$, and W$_\\text{50}$).\nWe find an intrinsic turndown in the bTFR for maximum halo speeds $\\lesssim 50$\nkm s$^{-1}$ (or total baryonic mass, M$_\\text{bary}\\lesssim 10^{8.5}$\nM$_\\odot$). We find that observing HI in lower-mass galaxies to the\nconventional surface density limit of 1M$_\\odot$pc$^{-2}$ is not enough to\ndetect a turndown in the bTFR; none of the HI velocity methods (spatially\nresolved or unresolved) recover the turndown, and we find bTFR slopes\nconsistent with observations of higher-mass galaxies. However, we predict that\nthe turndown can be recovered by resolved rotation curves if the HI limit is\n$\\lesssim 0.08$ M$_\\odot$ pc$^{-2}$, which is within the sensitivity of current\nHI surveys like FEASTS and MHONGOOSE."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.15302",
    "c_title":[
      "Euclid Quick Data Release (Q1) -- Data release overview"
    ],
    "c_abstract":[
      "The first Euclid Quick Data Release, Q1, comprises 63.1 sq deg of the Euclid\nDeep Fields (EDFs) to nominal wide-survey depth. It encompasses visible and\nnear-infrared space-based imaging and spectroscopic data, ground-based\nphotometry in the u, g, r, i and z bands, as well as corresponding masks.\nOverall, Q1 contains about 30 million objects in three areas near the ecliptic\npoles around the EDF-North and EDF-South, as well as the EDF-Fornax field in\nthe constellation of the same name. The purpose of this data release -- and its\nassociated technical papers -- is twofold. First, it is meant to inform the\ncommunity of the enormous potential of the Euclid survey data, to describe what\nis contained in these data, and to help prepare expectations for the\nforthcoming first major data release DR1. Second, it enables a wide range of\ninitial scientific projects with wide-survey Euclid data, ranging from the\nearly Universe to the Solar System. The Q1 data were processed with early\nversions of the processing pipelines, which already demonstrate good\nperformance, with numerous improvements in implementation compared to\npre-launch development. In this paper, we describe the sky areas released in\nQ1, the observations, a top-level view of the data processing of Euclid and\nassociated external data, the Q1 photometric masks, and how to access the data.\nWe also give an overview of initial scientific results obtained using the Q1\ndata set by Euclid Consortium scientists, and conclude with important caveats\nwhen using the data. As a complementary product, Q1 also contains observations\nof a star-forming area in Lynd's Dark Nebula 1641 in the Orion~A Cloud,\nobserved for technical purposes during Euclid's performance-verification phase.\nThis is a unique target, of a type not commonly found in Euclid's nominal sky\nsurvey."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-868",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19955",
    "b_title":[
      "RUBIK: A Structured Benchmark for Image Matching across Geometric\n  Challenges"
    ],
    "b_abstract":[
      "Camera pose estimation is crucial for many computer vision applications, yet\nexisting benchmarks offer limited insight into method limitations across\ndifferent geometric challenges. We introduce RUBIK, a novel benchmark that\nsystematically evaluates image matching methods across well-defined geometric\ndifficulty levels. Using three complementary criteria - overlap, scale ratio,\nand viewpoint angle - we organize 16.5K image pairs from nuScenes into 33\ndifficulty levels. Our comprehensive evaluation of 14 methods reveals that\nwhile recent detector-free approaches achieve the best performance (>47%\nsuccess rate), they come with significant computational overhead compared to\ndetector-based methods (150-600ms vs. 40-70ms). Even the best performing method\nsucceeds on only 54.8% of the pairs, highlighting substantial room for\nimprovement, particularly in challenging scenarios combining low overlap, large\nscale differences, and extreme viewpoint changes. Benchmark will be made\npublicly available."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12218",
    "c_title":[
      "Exploring Temporally-Aware Features for Point Tracking"
    ],
    "c_abstract":[
      "Point tracking in videos is a fundamental task with applications in robotics,\nvideo editing, and more. While many vision tasks benefit from pre-trained\nfeature backbones to improve generalizability, point tracking has primarily\nrelied on simpler backbones trained from scratch on synthetic data, which may\nlimit robustness in real-world scenarios. Additionally, point tracking requires\ntemporal awareness to ensure coherence across frames, but using\ntemporally-aware features is still underexplored. Most current methods often\nemploy a two-stage process: an initial coarse prediction followed by a\nrefinement stage to inject temporal information and correct errors from the\ncoarse stage. These approach, however, is computationally expensive and\npotentially redundant if the feature backbone itself captures sufficient\ntemporal information.\n  In this work, we introduce Chrono, a feature backbone specifically designed\nfor point tracking with built-in temporal awareness. Leveraging pre-trained\nrepresentations from self-supervised learner DINOv2 and enhanced with a\ntemporal adapter, Chrono effectively captures long-term temporal context,\nenabling precise prediction even without the refinement stage. Experimental\nresults demonstrate that Chrono achieves state-of-the-art performance in a\nrefiner-free setting on the TAP-Vid-DAVIS and TAP-Vid-Kinetics datasets, among\ncommon feature backbones used in point tracking as well as DINOv2, with\nexceptional efficiency. Project page: https:\/\/cvlab-kaist.github.io\/Chrono\/"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-869",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18343",
    "b_title":[
      "Horoboundaries of coarsely convex spaces"
    ],
    "b_abstract":[
      "A horoboundary is one of the attempts to compactify metric spaces, and is\nconstructed using continuous functions on metric spaces. It is a concept that\nincludes global information of metric spaces, and its correspondence with an\nideal boundary constructed using geodesics has been studied in nonpositive\ncurvature spaces such as CAT(0) spaces and geodesic Gromov hyperbolic spaces.\nWe will introduce a certain correspondence between the horoboundary and the\nideal boundary of coarsely convex spaces, which can be regarded as a\ngeneralization of spaces of nonpositive curvature."
    ],
    "b_categories":[
      [
        "math.MG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.06739",
    "c_title":[
      "Fixed-Point Theorems in $b$-Metric Spaces via a Novel Simulation\n  Function"
    ],
    "c_abstract":[
      "This paper introduces a new type of simulation function within the framework\nof $b$-metric spaces, leading to the derivation of fixed-point results in this\ngeneral setting. We explore the theoretical implications of these results and\ndemonstrate their utility through a concrete example."
    ],
    "c_categories":[
      [
        "math.MG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-870",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12265",
    "b_title":[
      "Clarke Coordinates Are Generalized Improved State Parametrization for\n  Continuum Robots"
    ],
    "b_abstract":[
      "In this letter, we demonstrate that previously proposed improved state\nparameterizations for soft and continuum robots are specific cases of Clarke\ncoordinates. By explicitly deriving these improved parameterizations from a\ngeneralized Clarke transformation matrix, we unify various approaches into one\ncomprehensive mathematical framework. This unified representation provides\nclarity regarding their relationships and generalizes them beyond existing\nconstraints, including arbitrary joint numbers, joint distributions, and\nunderlying modeling assumptions. This unification consolidates prior insights\nand establishes Clarke coordinates as a foundational tool, enabling systematic\nknowledge transfer across different subfields within soft and continuum\nrobotics."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04594",
    "c_title":[
      "Understanding Expectations for a Robotic Guide Dog for Visually Impaired\n  People"
    ],
    "c_abstract":[
      "Robotic guide dogs hold significant potential to enhance the autonomy and\nmobility of blind or visually impaired (BVI) individuals by offering universal\nassistance over unstructured terrains at affordable costs. However, the design\nof robotic guide dogs remains underexplored, particularly in systematic aspects\nsuch as gait controllers, navigation behaviors, interaction methods, and verbal\nexplanations. Our study addresses this gap by conducting user studies with 18\nBVI participants, comprising 15 cane users and three guide dog users.\nParticipants interacted with a quadrupedal robot and provided both quantitative\nand qualitative feedback. Our study revealed several design implications, such\nas a preference for a learning-based controller and a rigid handle, gradual\nturns with asymmetric speeds, semantic communication methods, and\nexplainability. The study also highlighted the importance of customization to\nsupport users with diverse backgrounds and preferences, along with practical\nconcerns such as battery life, maintenance, and weather issues. These findings\noffer valuable insights and design implications for future research and\ndevelopment of robotic guide dogs."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-871",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09652",
    "b_title":[
      "Active particle in a very thin interfacial droplet"
    ],
    "b_abstract":[
      "A single light-driven Janus particle confined in a very thin oil droplet at\nan air--water interface displays intriguing dynamics. While laser activation\ninduces rapid horizontal motion (1mm\/s--1cm\/s) by thermal Marangoni flow, the\nparticle exhibits unexpected periodic circular motions or intermittent\nirregular motions. We show that the periodic trajectories are the result of a\ncoupling between the self-propulsion of the particle and the spatiotemporal\ndroplet thickness changes. We propose a simple model where the properties of\nthe active particle trajectories are governed by capillary forces and torques\ndue to the confinement of the particle in the thin droplet."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.15476",
    "c_title":[
      "Active wetting transitions induced by rotational noise at solid\n  interfaces"
    ],
    "c_abstract":[
      "We investigate the wetting transitions displayed by the collection of active\nBrownian particles (ABPs) confined within rigid, impenetrable, flat walls. In\nour computational study using Brownian dynamics simulations, the wall-particle\ninteractions are implemented with a short-range repulsive potential. An\nenhanced rotational diffusion at the walls is used as a control parameter for\nwetting transitions. Increasing the wall rotational diffusion destabilizes\ncomplete wetting, and the aggregate shows morphological transitions. We observe\na sequence of morphological transitions with an increase in wall rotational\ndiffusion: symmetric complete wetting (SCW), asymmetric complete wetting (ACW),\npartial wetting (PW) with droplet formation, and drying. In the PW state, we\ncompute the contact angle as a function of activity and rotational noise. Our\nanalysis indicates that these transitions are linked to enhanced kinetic energy\nfluctuations of particles and bubble formations in the dense state. We further\ncharacterize the nature of these transitions by systematically analyzing an\norder parameter. Our work shows that modifying local reorientation rates alone\nis sufficient to induce wetting transitions in active systems."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-872",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.03726",
    "b_title":[
      "DICE: Distilling Classifier-Free Guidance into Text Embeddings"
    ],
    "b_abstract":[
      "Text-to-image diffusion models are capable of generating high-quality images,\nbut these images often fail to align closely with the given text prompts.\nClassifier-free guidance (CFG) is a popular and effective technique for\nimproving text-image alignment in the generative process. However, using CFG\nintroduces significant computational overhead and deviates from the established\ntheoretical foundations of diffusion models. In this paper, we present\nDIstilling CFG by enhancing text Embeddings (DICE), a novel approach that\nremoves the reliance on CFG in the generative process while maintaining the\nbenefits it provides. DICE distills a CFG-based text-to-image diffusion model\ninto a CFG-free version by refining text embeddings to replicate CFG-based\ndirections. In this way, we avoid the computational and theoretical drawbacks\nof CFG, enabling high-quality, well-aligned image generation at a fast sampling\nspeed. Extensive experiments on multiple Stable Diffusion v1.5 variants, SDXL\nand PixArt-$\\alpha$ demonstrate the effectiveness of our method. Furthermore,\nDICE supports negative prompts for image editing to improve image quality\nfurther. Code will be available soon."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.00429",
    "c_title":[
      "DADM: Dual Alignment of Domain and Modality for Face Anti-spoofing"
    ],
    "c_abstract":[
      "With the availability of diverse sensor modalities (i.e., RGB, Depth,\nInfrared) and the success of multi-modal learning, multi-modal face\nanti-spoofing (FAS) has emerged as a prominent research focus. The intuition\nbehind it is that leveraging multiple modalities can uncover more intrinsic\nspoofing traces. However, this approach presents more risk of misalignment. We\nidentify two main types of misalignment: (1) \\textbf{Intra-domain modality\nmisalignment}, where the importance of each modality varies across different\nattacks. For instance, certain modalities (e.g., Depth) may be non-defensive\nagainst specific attacks (e.g., 3D mask), indicating that each modality has\nunique strengths and weaknesses in countering particular attacks. Consequently,\nsimple fusion strategies may fall short. (2) \\textbf{Inter-domain modality\nmisalignment}, where the introduction of additional modalities exacerbates\ndomain shifts, potentially overshadowing the benefits of complementary fusion.\nTo tackle (1), we propose a alignment module between modalities based on mutual\ninformation, which adaptively enhances favorable modalities while suppressing\nunfavorable ones. To address (2), we employ a dual alignment optimization\nmethod that aligns both sub-domain hyperplanes and modality angle margins,\nthereby mitigating domain gaps. Our method, dubbed \\textbf{D}ual\n\\textbf{A}lignment of \\textbf{D}omain and \\textbf{M}odality (DADM), achieves\nstate-of-the-art performance in extensive experiments across four challenging\nprotocols demonstrating its robustness in multi-modal domain generalization\nscenarios. The codes will be released soon."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-873",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.10493",
    "b_title":[
      "Pulsational characteristics of mass accreting stars in close binary\n  systems"
    ],
    "b_abstract":[
      "Eclipsing binaries with pulsating components are a distinct subclass of\nbinaries, merging orbital and pulsational analyses. In recent years, that\nsubclass led to the definition of a newly formed branch of tidal\nasteroseismology. While single-star pulsators are well understood, the effects\nof binarity and possible mass transfer on pulsational characteristics,\nparticularly in mass-gaining stars, remain to be systematically explored. Here,\nI present preliminary results on the asteroseismic properties of a\nmass-accreting model for a 10 $M_{\\odot}$ $\\beta$ Cephei-type star"
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04807",
    "c_title":[
      "Orbits of Six Triple Systems"
    ],
    "c_abstract":[
      "Joint analysis of position measurements and radial velocities of six triple\nstellar systems is conducted to determine their inner and\/or outer orbits.\nAccumulation of such data is needed to study the architecture of stellar\nhierarchies and its relation to the formation mechanisms. The inner periods in\nthe six systems (HIP 11783, 64836, 72423, 84720, 89234, and 105404) range from\n0.5 days to 44 yr. The shortest outer period of 3.34 yr is found in the compact\ntriple HIP~105404 (BS Ind). The resolved triple system HIP 64836 has comparable\ninner and outer periods (5 and 30 yr), placing it near the limit of dynamical\nstability, while its quasi-circular and coplanar orbits suggest a 1:6 mean\nmotion resonance. The periods in HIP 89234 (44 and ~450 yr) are also\ncomparable, but the mutual orbit inclination is large, 54 degrees. Masses of\nthe components are estimated and each system is discussed individually."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-874",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09829",
    "b_title":[
      "Sur certains faisceaux de formes m\\'eromorphes sur un espace complexe\n  r\\'eduit"
    ],
    "b_abstract":[
      "The purpose of this is the study of certain coherent sheaves of meromorphic\nforms on reduced complex space and particularly their behavior with respect to\npull back and higher direct image."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.17996",
    "c_title":[
      "A new proof of monomialisation from 3-folds to surfaces"
    ],
    "c_abstract":[
      "In this paper, we give a new proof of the foundational result, due to S.\nCutkosky, on the existence of a monomialisation of a morphism from a 3-fold to\na surface. Our proof brings to the fore the notion of log-Fitting ideals, and\nrequires us to develop new methods related to Rank Theorems and log-Fitting\nideals."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-875",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18150",
    "b_title":[
      "Realistic Clothed Human and Object Joint Reconstruction from a Single\n  Image"
    ],
    "b_abstract":[
      "Recent approaches to jointly reconstruct 3D humans and objects from a single\nRGB image represent 3D shapes with template-based or coarse models, which fail\nto capture details of loose clothing on human bodies. In this paper, we\nintroduce a novel implicit approach for jointly reconstructing realistic 3D\nclothed humans and objects from a monocular view. For the first time, we model\nboth the human and the object with an implicit representation, allowing to\ncapture more realistic details such as clothing. This task is extremely\nchallenging due to human-object occlusions and the lack of 3D information in 2D\nimages, often leading to poor detail reconstruction and depth ambiguity. To\naddress these problems, we propose a novel attention-based neural implicit\nmodel that leverages image pixel alignment from both the input human-object\nimage for a global understanding of the human-object scene and from local\nseparate views of the human and object images to improve realism with, for\nexample, clothing details. Additionally, the network is conditioned on semantic\nfeatures derived from an estimated human-object pose prior, which provides 3D\nspatial information about the shared space of humans and objects. To handle\nhuman occlusion caused by objects, we use a generative diffusion model that\ninpaints the occluded regions, recovering otherwise lost details. For training\nand evaluation, we introduce a synthetic dataset featuring rendered scenes of\ninter-occluded 3D human scans and diverse objects. Extensive evaluation on both\nsynthetic and real-world datasets demonstrates the superior quality of the\nproposed human-object reconstructions over competitive methods."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19671",
    "c_title":[
      "Test-Time Modality Generalization for Medical Image Segmentation"
    ],
    "c_abstract":[
      "Generalizable medical image segmentation is essential for ensuring consistent\nperformance across diverse unseen clinical settings. However, existing methods\noften overlook the capability to generalize effectively across arbitrary unseen\nmodalities. In this paper, we introduce a novel Test-Time Modality\nGeneralization (TTMG) framework, which comprises two core components:\nModality-Aware Style Projection (MASP) and Modality-Sensitive Instance\nWhitening (MSIW), designed to enhance generalization in arbitrary unseen\nmodality datasets. The MASP estimates the likelihood of a test instance\nbelonging to each seen modality and maps it onto a distribution using\nmodality-specific style bases, guiding its projection effectively. Furthermore,\nas high feature covariance hinders generalization to unseen modalities, the\nMSIW is applied during training to selectively suppress modality-sensitive\ninformation while retaining modality-invariant features. By integrating MASP\nand MSIW, the TTMG framework demonstrates robust generalization capabilities\nfor medical image segmentation in unseen modalities a challenge that current\nmethods have largely neglected. We evaluated TTMG alongside other domain\ngeneralization techniques across eleven datasets spanning four modalities\n(colonoscopy, ultrasound, dermoscopy, and radiology), consistently achieving\nsuperior segmentation performance across various modality combinations."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-876",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.17564",
    "b_title":[
      "HI Intensity Mapping with the MIGHTEE Survey: First Results of the HI\n  Power Spectrum"
    ],
    "b_abstract":[
      "We present the first results of the HI intensity mapping power spectrum\nanalysis with the MeerKAT International GigaHertz Tiered Extragalactic\nExploration (MIGHTEE) survey. We use data covering $\\sim$ 4 square degrees in\nthe COSMOS field using a frequency range 962.5 MHz to 1008.42 MHz, equivalent\nto HI emission in $0.4<z<0.48$. The data consists of 15 pointings with a total\nof 94.2 hours on-source. We verify the suitability of the MIGHTEE data for HI\nintensity mapping by testing for residual systematics across frequency,\nbaselines and pointings. We also vary the window used for HI signal\nmeasurements and find no significant improvement using stringent Fourier mode\ncuts. Averaging in the power spectrum domain, i.e. using incoherent averaging,\nwe calculate the first upper limits from MIGHTEE on the HI power spectrum at\nscales $0.5 Mpc^{-1} \\lesssim k \\lesssim 10 Mpc^{-1}$. We obtain the best\n1$\\sigma$ upper limit of 28.6 mK$^{2}$Mpc${^3}$ on $k\\sim$2 Mpc$^{-1}$. Our\nresults are consistent with the power spectrum detected with observations in\nthe DEEP2 field with MeerKAT. The data we use here constitutes a small fraction\nof the MIGHTEE survey and demonstrates that combined analysis of the full\nMIGHTEE survey can potentially detect the HI power spectrum at $z\\lesssim0.5$\nin the range $0.1 Mpc^{-1} \\lesssim k \\lesssim 10 Mpc^{-1}$ or quasi-linear\nscales."
    ],
    "b_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.03750",
    "c_title":[
      "Halo spin and orientation in Interacting Dark Matter Dark Energy\n  Cosmology"
    ],
    "c_abstract":[
      "In recent years, the interaction between dark matter (DM) and dark energy has\nbecome a topic of interest in cosmology. Interacting dark matter-dark energy\n(IDE) models have a substantial impact on the formation of cosmological\nlarge-scale structures, which serve as the background for DM halo evolution.\nThis impact can be examined through the shape and spin orientation of halos in\nnumerical simulations incorporating IDE effects. In our work, we use the N-body\nsimulation pipeline ME-GADGET to simulate and study the halo spin and\norientation in IDE models. We found that in models where DM transfers into DE\n(IDE I), the alignment of halo shapes with the surrounding tidal field is\nenhanced, while the alignment of halo spins with the tidal field is decreased\ncompared to {\\Lambda}CDM. Conversely, in models where DE transfers into DM (IDE\nII), the opposite occurs. We have provided fitted functions to describe these\nalignment signals. Our study provides the foundation for more accurate modeling\nof observations in the future such as China Space Station Telescope."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-877",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12783",
    "b_title":[
      "Cost Optimization for Serverless Edge Computing with Budget Constraints\n  using Deep Reinforcement Learning"
    ],
    "b_abstract":[
      "Serverless computing adopts a pay-as-you-go billing model where applications\nare executed in stateless and shortlived containers triggered by events,\nresulting in a reduction of monetary costs and resource utilization. However,\nexisting platforms do not provide an upper bound for the billing model which\nmakes the overall cost unpredictable, precluding many organizations from\nmanaging their budgets. Due to the diverse ranges of serverless functions and\nthe heterogeneous capacity of edge devices, it is challenging to receive\nnear-optimal solutions for deployment cost in a polynomial time. In this paper,\nwe investigated the function scheduling problem with a budget constraint for\nserverless computing in wireless networks. Users and IoT devices are sending\nrequests to edge nodes, improving the latency perceived by users. We propose\ntwo online scheduling algorithms based on reinforcement learning, incorporating\nseveral important characteristics of serverless functions. Via extensive\nsimulations, we justify the superiority of the proposed algorithm by comparing\nwith an ILP solver (Midaco). Our results indicate that the proposed algorithms\nefficiently approximate the results of Midaco within a factor of 1.03 while our\ndecision-making time is 5 orders of magnitude less than that of Midaco."
    ],
    "b_categories":[
      [
        "cs.NI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.02886",
    "c_title":[
      "Advancements in Mobile Edge Computing and Open RAN: Leveraging\n  Artificial Intelligence and Machine Learning for Wireless Systems"
    ],
    "c_abstract":[
      "Mobile Edge Computing (MEC) and Open Radio Access Networks (ORAN) are\ntransformative technologies in the development of next-generation wireless\ncommunication systems. MEC pushes computational resources closer to end-users,\nenabling low latency and efficient processing, while ORAN promotes\ninteroperability and openness in radio networks, thereby fostering innovation.\nThis paper explores recent advancements in these two domains, with a particular\nfocus on how Artificial Intelligence (AI) and Machine Learning (ML) techniques\nare being utilized to solve complex wireless challenges. In MEC, Deep\nReinforcement Learning (DRL) is leveraged for optimizing computation\noffloading, ensuring energy-efficient solutions, and meeting Quality of Service\n(QoS) requirements. In ORAN, AI\/ML is used to develop intelligent xApps for\nnetwork slicing, scheduling, and online training to enhance network\nadaptability. This reading report provides an in-depth analysis of multiple key\npapers, discusses the methodologies employed, and highlights the impact of\nthese technologies in improving network efficiency and scalability."
    ],
    "c_categories":[
      [
        "cs.NI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-878",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18717",
    "b_title":[
      "Fractional elliptic reaction-diffusion systems with coupled gradient\n  terms and different diffusion"
    ],
    "b_abstract":[
      "In this work, we study the existence and nonexistence of nonnegative\nsolutions to a class of nonlocal elliptic systems set in a bounded open subset\nof $\\mathbb{R}^N$. The diffusion operators are of type $u_i\\mapsto\nd_i(-\\Delta)^{s_i}u_i$ where $0<s_1\\neq s_2<1$, and the gradients of the\nunknowns act as source terms. Existence results are obtained by proving some\nfine estimates when data belong to weighted Lebesgue spaces. Those estimates\nare new and interesting in themselves."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.04467",
    "c_title":[
      "A Short Survey of the Well-posedness of the Two-dimensional Burgers'\n  Equation"
    ],
    "c_abstract":[
      "In this paper, we establish the existence and uniqueness of solutions to the\ntwo-dimensional Burgers equation using the framework of infinite-dimensional\ndynamical systems. The two-dimensional Burgers equation, which models the\ninterplay between nonlinear advection and viscous dissipation, is given by: $$\nu_{t} + u \\cdot \\nabla u = \\nu \\Delta u + f, $$ where $ u = (u_1, u_2) $ is the\nvelocity field, $ \\nu > 0 $ is the viscosity coefficient, and $ f $ represents\nan external force. We primarily employed Galerkin method to transform the\npartial differential equation into an ordinary differential equation. In\naddition, by employing Sobolev spaces, energy estimates, and compactness\narguments, we rigorously prove the existence of global solutions and their\nuniqueness under appropriate initial and boundary conditions."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-879",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09910",
    "b_title":[
      "Chatbot apologies: Beyond bullshit"
    ],
    "b_abstract":[
      "Apologies serve essential functions for moral agents such as expressing\nremorse, taking responsibility, and repairing trust. LLM-based chatbots\nroutinely produce output that has the linguistic form of an apology. However,\nthey do this simply because they are echoing the kinds of things that humans\nsay. Moreover, there are reasons to think that chatbots are not the kind of\nlinguistic or moral agents capable of apology. To put the point bluntly:\nChatbot apologies are bullshit. This paper offers several arguments for this\nconclusion, drawing on the nature of morally-serious apologies, the linguistic\nagency required to perform them, and the moral agency required for them to\nmatter. We conclude by considering some consequences for how chatbots should be\ndesigned and how we ought to think about them."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.02880",
    "c_title":[
      "Learning not cheating: AI assistance can enhance rather than hinder\n  skill development"
    ],
    "c_abstract":[
      "It is widely believed that outsourcing cognitive work to AI boosts immediate\nproductivity at the expense of long-term human capital development. An\noverlooked possibility is that AI tools can support skill development by\nproviding just-in-time, high-quality, personalized examples. In this\ninvestigation, lay forecasters predicted that practicing writing cover letters\nwith an AI tool would impair learning compared to practicing writing letters\nwithout the tool. However, in a highly-powered pre-registered experiment,\nparticipants randomly assigned to practice writing with AI improved more on a\nwriting test one day later compared to writers assigned to practice without AI.\nNotably, writers given access to the AI tool improved more despite exerting\nless effort, whether measured by time on task, keystrokes, or subjective\nratings. We replicated and extended these results in a second pre-registered\nexperiment, showing that writers given access to the AI tool again outperformed\nthose who practiced on their own -- but performed no better than writers merely\nshown an AI-generated cover letter that they could not edit. Collectively,\nthese findings constitute an existence proof that by providing personalized\nexamples of high-quality work, AI tools can improve, rather than undermine,\nlearning."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-880",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07906",
    "b_title":[
      "Painting with Words: Elevating Detailed Image Captioning with Benchmark\n  and Alignment Learning"
    ],
    "b_abstract":[
      "Image captioning has long been a pivotal task in visual understanding, with\nrecent advancements in vision-language models (VLMs) significantly enhancing\nthe ability to generate detailed image captions. However, the evaluation of\ndetailed image captioning remains underexplored due to outdated evaluation\nmetrics and coarse annotations. In this paper, we introduce DeCapBench along\nwith a novel metric, DCScore, specifically designed for detailed captioning\ntasks. DCScore evaluates hallucinations and fine-grained comprehensiveness by\ndeconstructing responses into the smallest self-sufficient units, termed\nprimitive information units, and assessing them individually. Our evaluation\nshows that DCScore aligns more closely with human judgment than other\nrule-based or model-based metrics. Concurrently, DeCapBench exhibits a high\ncorrelation with VLM arena results on descriptive tasks, surpassing existing\nbenchmarks for vision-language models. Additionally, we present an automatic\nfine-grained feedback collection method, FeedQuill, for preference optimization\nbased on our advanced metric, showing robust generalization capabilities across\nauto-generated preference data. Extensive experiments on multiple VLMs\ndemonstrate that our method not only significantly reduces hallucinations but\nalso enhances performance across various benchmarks, achieving superior detail\ncaptioning performance while surpassing GPT-4o."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.05228",
    "c_title":[
      "Harnessing Large Language and Vision-Language Models for Robust\n  Out-of-Distribution Detection"
    ],
    "c_abstract":[
      "Out-of-distribution (OOD) detection has seen significant advancements with\nzero-shot approaches by leveraging the powerful Vision-Language Models (VLMs)\nsuch as CLIP. However, prior research works have predominantly focused on\nenhancing Far-OOD performance, while potentially compromising Near-OOD\nefficacy, as observed from our pilot study. To address this issue, we propose a\nnovel strategy to enhance zero-shot OOD detection performances for both Far-OOD\nand Near-OOD scenarios by innovatively harnessing Large Language Models (LLMs)\nand VLMs. Our approach first exploit an LLM to generate superclasses of the ID\nlabels and their corresponding background descriptions followed by feature\nextraction using CLIP. We then isolate the core semantic features for ID data\nby subtracting background features from the superclass features. The refined\nrepresentation facilitates the selection of more appropriate negative labels\nfor OOD data from a comprehensive candidate label set of WordNet, thereby\nenhancing the performance of zero-shot OOD detection in both scenarios.\nFurthermore, we introduce novel few-shot prompt tuning and visual prompt tuning\nto adapt the proposed framework to better align with the target distribution.\nExperimental results demonstrate that the proposed approach consistently\noutperforms current state-of-the-art methods across multiple benchmarks, with\nan improvement of up to 2.9% in AUROC and a reduction of up to 12.6% in FPR95.\nAdditionally, our method exhibits superior robustness against covariate shift\nacross different domains, further highlighting its effectiveness in real-world\nscenarios."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-881",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.21187",
    "b_title":[
      "SYN-LUNGS: Towards Simulating Lung Nodules with Anatomy-Informed Digital\n  Twins for AI Training"
    ],
    "b_abstract":[
      "AI models for lung cancer screening are limited by data scarcity, impacting\ngeneralizability and clinical applicability. Generative models address this\nissue but are constrained by training data variability. We introduce SYN-LUNGS,\na framework for generating high-quality 3D CT images with detailed annotations.\nSYN-LUNGS integrates XCAT3 phantoms for digital twin generation, X-Lesions for\nnodule simulation (varying size, location, and appearance), and DukeSim for CT\nimage formation with vendor and parameter variability. The dataset includes\n3,072 nodule images from 1,044 simulated CT scans, with 512 lesions and 174\ndigital twins. Models trained on clinical + simulated data outperform clinical\nonly models, achieving 10% improvement in detection, 2-9% in segmentation and\nclassification, and enhanced synthesis.By incorporating anatomy-informed\nsimulations, SYN-LUNGS provides a scalable approach for AI model development,\nparticularly in rare disease representation and improving model reliability."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.16392",
    "c_title":[
      "HMCGeo: IP Region Prediction Based on Hierarchical Multi-label\n  Classification"
    ],
    "c_abstract":[
      "Fine-grained IP geolocation plays a critical role in applications such as\nlocation-based services and cybersecurity. Most existing fine-grained IP\ngeolocation methods are regression-based; however, due to noise in the input\ndata, these methods typically encounter kilometer-level prediction errors and\nprovide incorrect region information for users. To address this issue, this\npaper proposes a novel hierarchical multi-label classification framework for IP\nregion prediction, named HMCGeo. This framework treats IP geolocation as a\nhierarchical multi-label classification problem and employs residual\nconnection-based feature extraction and attention prediction units to predict\nthe target host region across multiple geographical granularities. Furthermore,\nwe introduce probabilistic classification loss during training, combining it\nwith hierarchical cross-entropy loss to form a composite loss function. This\napproach optimizes predictions by utilizing hierarchical constraints between\nregions at different granularities. IP region prediction experiments on the New\nYork, Los Angeles, and Shanghai datasets demonstrate that HMCGeo achieves\nsuperior performance across all geographical granularities, significantly\noutperforming existing IP geolocation methods."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-882",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16912",
    "b_title":[
      "Construction and sample path properties of diffusion house-moving\n  between two curves"
    ],
    "b_abstract":[
      "The purpose of this paper is to introduce the construction of a stochastic\nprocess called ``diffusion house-moving'' and to explore its properties. We\nstudy the weak convergence of diffusion bridges conditioned to stay between two\ncurves, and we refer to this limit as diffusion house-moving. Applying this\nweak convergence result, we give the sample path properties of diffusion\nhouse-moving."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.12189",
    "c_title":[
      "Stein's method for models with general clocks: A tutorial"
    ],
    "c_abstract":[
      "Diffusion approximations are widely used in the analysis of service systems,\nproviding tractable insights into complex models. While heavy-traffic limit\ntheorems justify these approximations asymptotically, they do not quantify the\nerror when the system is not in the limit regime. This paper presents a\ntutorial on the generator comparison approach of Stein's method for analyzing\ndiffusion approximations in Markovian models where state transitions are\ngoverned by general clocks, which extends the well-established theory for\ncontinuous-time Markov chains and enables non-asymptotic error bounds for these\napproximations. Building on recent work that applies this method to\nsingle-clock systems, we develop a framework for handling models with multiple\ngeneral clocks. Our approach is illustrated through canonical queueing systems,\nincluding the G\/G\/1 queue, the join-the-shortest-queue system, and the tandem\nqueue. We highlight the role of the Palm inversion formula and the compensated\nqueue-length process in extracting the diffusion generator. Most of our error\nterms depend only on the first three moments of the general clock distribution.\nThe rest require deeper, model-specific, insight to bound, but could in theory\nalso depend on only the first three moments."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-883",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07314",
    "b_title":[
      "Recognizing Numbers"
    ],
    "b_abstract":[
      "The use of monoids in the study of word languages recognized by finite-state\nautomata has been quite fruitful. In this work, we look at the same idea of\n\"recognizability by finite monoids\" for other monoids. In particular, we\nattempt to characterize recognizable subsets of various additive and\nmultiplicative monoids over integers, rationals, reals, and complex numbers.\nWhile these recognizable sets satisfy properties such as closure under Boolean\noperations and inverse morphisms, they do not enjoy many of the nice properties\nthat recognizable word languages do."
    ],
    "b_categories":[
      [
        "cs.FL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.08040",
    "c_title":[
      "On Constructing Finite Automata by Relational Programming"
    ],
    "c_abstract":[
      "We consider ways to construct a transducer for a given set of input word to\noutput symbol pairs. This is motivated by the need for representing game\nplaying programs in a low-level mathematical format that can be analyzed by\nalgebraic tools. This is different from the classical applications of finite\nstate automata, thus the usual optimization techniques are not directly\napplicable. Therefore, we use relational programming tools to find minimal\ntransducers realizing a given set of input-output pairs."
    ],
    "c_categories":[
      [
        "cs.FL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-884",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01137",
    "b_title":[
      "Computational fluid dynamics-based structure optimization of\n  ultra-high-pressure water-jet nozzle using approximation method"
    ],
    "b_abstract":[
      "Since the geometry structure of ultra-high-pressure (UHP) water-jet nozzle is\na critical factor to enhance its hydrodynamic performance, it is critical to\nobtain a suitable geometry for a UHP water jet nozzle. In this study, a\nCFD-based optimization loop for UHP nozzle structure has been developed by\nintegrating an approximate model to optimize nozzle structure for increasing\nthe radial peak wall shear stress. In order to improve the optimization\naccuracy of the sparrow search algorithm (SSA), an enhanced version called the\nLogistic-Tent chaotic sparrow search algorithm (LTC-SSA) is proposed. The\nLTC-SSA algorithm utilizes the Logistic-Tent Chaotic (LTC) map, which is\ndesigned by combining the Logistic and Tent maps. This new approach aims to\novercome the shortcoming of \"premature convergence\" for the SSA algorithm by\nincreasing the diversity of the sparrow population. In addition, to improve the\nprediction accuracy of peak wall shear stress, a data prediction method based\non LTC-SSA-support vector machine (SVM) is proposed. Herein, LTC-SSA algorithm\nis used to train the penalty coefficient C and parameter gamma g of SVM model.\nIn order to build LTC-SSA-SVM model, optimal Latin hypercube design (Opt LHD)\nis used to design the sampling nozzle structures, and the peak wall shear\nstress (objective function) of these nozzle structures are calculated by CFD\nmethod. For the purpose of this article, this optimization framework has been\nemployed to optimize original nozzle structure. The results show that the\noptimization framework developed in this study can be used to optimize nozzle\nstructure with significantly improved its hydrodynamic performance."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02268",
    "c_title":[
      "A simplified digital twin of a pressure swing adsorption plant for air\n  separation"
    ],
    "c_abstract":[
      "The pressure swing adsorption (PSA) process is one of the widely utilized\ntechniques for air separation. Operating on the Skarstrom cycle, the porous\nadsorbent columns of a PSA system alternate between adsorption and desorption\nphases to selectively enrich the desired component in a gas mixture. The\ncurrent work presents a robust and generalizable digital twin CFD model of a\nPSA system that can significantly help in design and device characterization.\nUsing an axisymmetric representation, the digital twin accurately mimics all\nthe key components of an air separation plant, including the air reservoir,\nadsorbent columns, product buffer tank, pressure regulator, solenoidal valves,\nand mesh filters. The model simulates the flow and adsorption processes in the\nsystem by solving the conservation equations for mass, momentum, energy, and\nspecies, along with the equation for adsorption kinetics. The cyclic operation\nof the PSA plants, typically controlled by solenoid valves, is emulated by\ndynamically modifying the boundary conditions of different subdomains. Such an\nintegrated approach is shown here to closely replicate the performance of an\nin-house PSA pilot setup producing oxygen in terms of purity and pressure\ntransience. Also, both the numerical and the experimental results yield an\noptimum performance for the same process parameters, such as pressurization\ntime (26 s), purge time (2 s), and equalization time (4 s). The proposed\nnumerical model is versatile and can be adapted to various industrial\napplications of PSA technology, such as hydrogen purification and carbon\ncapture. Thus, it offers a cost-effective tool for designing and optimizing PSA\nsystems."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-885",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12684",
    "b_title":[
      "A detailed study on spectroscopic performance of SOI pixel detector with\n  a pinned depleted diode structure for X-ray astronomy"
    ],
    "b_abstract":[
      "We have been developing silicon-on-insulator (SOI) pixel detectors with a\npinned depleted diode (PDD) structure, named \"XRPIX\", for X-ray astronomy. In\nour previous study, we successfully optimized the design of the PDD structure,\nachieving both the suppression of large leakage current and satisfactory X-ray\nspectroscopic performance. Here, we report a detailed study on the X-ray\nspectroscopic performance of the XRPIX with the optimized PDD structure. The\ndata were obtained at $-60^\\circ\\mathrm{C}$ with the \"event-driven readout\nmode\", in which only a triggering pixel and its surroundings are read out. The\nenergy resolutions in full width at half maximum at 6.4 keV are $178\\pm1$ eV\nand $291\\pm1$ eV for single-pixel and all-pixel event spectra, respectively.\nThe all-pixel events include charge-sharing pixel events as well as the\nsingle-pixel events. These values are the best achieved in the history of our\ndevelopment. We argue that the gain non-linearity in the low energy side due to\nexcessive charge injection to the charge-sensitive amplifier is a major factor\nto limit the current spectroscopic performance. Optimization of the amount of\nthe charge injection is expected to lead to further improvement in the\nspectroscopic performance of XRPIX, especially for the all-pixel event\nspectrum."
    ],
    "b_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09894",
    "c_title":[
      "Intensity Interferometer Results on Sirius with 0.25 m Telescopes"
    ],
    "c_abstract":[
      "We present the successful measurement of the squared visibility of Sirius at\na telescope separation of 3.3 m using small 0.25 m Newtonian-style telescopes\nin an urban backyard setting. The primary science goal for small-scale\nintensity interferometers has been to measure the angular diameters of stars.\nRecent advances in low jitter time-tagging equipment and Single Photon\nAvalanche Detectors have made the detection of second-order photon correlation\nsignals feasible with small low-cost telescopes. Using Sirius as a target star,\nwe observe a photon count rate of $\\sim$1.9 Mcps per detector with matched 1.2\nnm wide filters at 589.3 nm and measured the spatial squared visibility at a\ntelescope separation of 3.3 m to be $|V_{12}(3.3\\text{m})|^2 = 0.94\\pm0.16$.\nThe measured detection significance is $\\sim7 \\sigma$ after 13.55 h of\nintegration. The uncertainty in the measured visibility includes uncertainty in\nthe instrument response function.The squared visibility agrees closely with the\nexpected value of $0.94\\pm0.01$. These results demonstrate that using small\nlow-cost telescopes is feasible for intensity interferometry of bright stars.\nThis enables a simple scaling in sensitivity by further realistic improvements\nin the instrument response jitter as well as increasing both the number of\nspectral bands and the number of telescopes towards systems capable of\nresolving objects such as quasars, white dwarfs, and galactic Cepheid variable\nstars."
    ],
    "c_categories":[
      [
        "astro-ph.IM"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-886",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07302",
    "b_title":[
      "CASC-AI: Consensus-aware Self-corrective Learning for Noise Cell\n  Segmentation"
    ],
    "b_abstract":[
      "Multi-class cell segmentation in high-resolution gigapixel whole slide images\n(WSIs) is crucial for various clinical applications. However, training such\nmodels typically requires labor-intensive, pixel-wise annotations by domain\nexperts. Recent efforts have democratized this process by involving lay\nannotators without medical expertise. However, conventional non-corrective\napproaches struggle to handle annotation noise adaptively because they lack\nmechanisms to mitigate false positives (FP) and false negatives (FN) at both\nthe image-feature and pixel levels. In this paper, we propose a consensus-aware\nself-corrective AI agent that leverages the Consensus Matrix to guide its\nlearning process. The Consensus Matrix defines regions where both the AI and\nannotators agree on cell and non-cell annotations, which are prioritized with\nstronger supervision. Conversely, areas of disagreement are adaptively weighted\nbased on their feature similarity to high-confidence consensus regions, with\nmore similar regions receiving greater attention. Additionally, contrastive\nlearning is employed to separate features of noisy regions from those of\nreliable consensus regions by maximizing their dissimilarity. This paradigm\nenables the model to iteratively refine noisy labels, enhancing its robustness.\nValidated on one real-world lay-annotated cell dataset and two reasoning-guided\nsimulated noisy datasets, our method demonstrates improved segmentation\nperformance, effectively correcting FP and FN errors and showcasing its\npotential for training robust models on noisy datasets. The official\nimplementation and cell annotations are publicly available at\nhttps:\/\/github.com\/ddrrnn123\/CASC-AI."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12390",
    "c_title":[
      "GPS as a Control Signal for Image Generation"
    ],
    "c_abstract":[
      "We show that the GPS tags contained in photo metadata provide a useful\ncontrol signal for image generation. We train GPS-to-image models and use them\nfor tasks that require a fine-grained understanding of how images vary within a\ncity. In particular, we train a diffusion model to generate images conditioned\non both GPS and text. The learned model generates images that capture the\ndistinctive appearance of different neighborhoods, parks, and landmarks. We\nalso extract 3D models from 2D GPS-to-image models through score distillation\nsampling, using GPS conditioning to constrain the appearance of the\nreconstruction from each viewpoint. Our evaluations suggest that our\nGPS-conditioned models successfully learn to generate images that vary based on\nlocation, and that GPS conditioning improves estimated 3D structure."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-887",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.03162",
    "b_title":[
      "Charged Gravastar Solutions in the Finch-Skea Framework with\n  f(\\mathbb{Q}) Gravity"
    ],
    "b_abstract":[
      "In this study, we investigate the features of a charged gravastar within the\nframework of $f(\\mathbb{Q})$ gravity ($\\mathbb{Q}$ represents non-metricity)\nusing the Finch-Skea metric. This metric is applied to both the interior and\nshell regions of the charged gravastar and the field equations are derived\naccordingly. For the exterior regions, we consider various black holes, i.e.,\nReissner-Nordstr$\\ddot{o}$m, Bardeen and Hayward regular black holes. The\ninterior and exterior layers are matched using the Israel junction conditions,\nwhich help to determine the surface energy density and surface pressure for\nthese black holes. We examine some physical properties such as proper length,\nentropy, energy and the equation of state parameter. The stability of the\ndeveloped gravastar model is discussed through the effective potential, the\ncausality condition and adiabatic index. We conclude that the compact gravastar\nstructure could be a viable alternative to black holes within this framework."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04779",
    "c_title":[
      "Exact multiblack hole spacetimes in Einstein-ModMax theory"
    ],
    "c_abstract":[
      "Exact solutions describing multiple, electrically charged black holes (BHs)\nin a model of nonlinear electrodynamics (NLE) minimally coupled to Einstein's\ngravity are presented. The NLE model is ModMax theory, that has attracted much\nattention due to its duality and conformal invariance, features shared with\nstandard (linear) electrodynamics. In the nonextremal case, the solution has\nconical singularities, similarly to the multi Reissner-Nordstr\\\"om solution in\nEinstein-Maxwell theory. In the extremal case the solution is regular on and\noutside the event horizon; it is isometric to the Majumdar-Papapetrou solution,\nalthough the individual BHs have a nonunitary charge to mass ratio, due to\nscreening effects. Using the ModMax electromagnetic duality invariance,\nmagnetically charged and dyonic generalizations are also obtained. Finally, we\nconstruct multi-BH solutions with a positive cosmological constant."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-888",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18767",
    "b_title":[
      "Ptychographic Image Reconstruction from Limited Data via Score-Based\n  Diffusion Models with Physics-Guidance"
    ],
    "b_abstract":[
      "Ptychography is a computational imaging technique that achieves high spatial\nresolution over large fields of view. It involves scanning a coherent beam\nacross overlapping regions and recording diffraction patterns. Conventional\nreconstruction algorithms require substantial overlap, increasing data volume\nand experimental time. We propose a reconstruction method employing a\nphysics-guided score-based diffusion model. Our approach trains a diffusion\nmodel on representative object images to learn an object distribution prior.\nDuring reconstruction, we modify the reverse diffusion process to enforce data\nconsistency, guiding reverse diffusion toward a physically plausible solution.\nThis method requires a single pretraining phase, allowing it to generalize\nacross varying scan overlap ratios and positions. Our results demonstrate that\nthe proposed method achieves high-fidelity reconstructions with only a 20%\noverlap, while the widely employed rPIE method requires a 62% overlap to\nachieve similar accuracy. This represents a significant reduction in data\nrequirements, offering an alternative to conventional techniques."
    ],
    "b_categories":[
      [
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13257",
    "c_title":[
      "Anatomically and Metabolically Informed Diffusion for Unified Denoising\n  and Segmentation in Low-Count PET Imaging"
    ],
    "c_abstract":[
      "Positron emission tomography (PET) image denoising, along with lesion and\norgan segmentation, are critical steps in PET-aided diagnosis. However,\nexisting methods typically treat these tasks independently, overlooking\ninherent synergies between them as correlated steps in the analysis pipeline.\nIn this work, we present the anatomically and metabolically informed diffusion\n(AMDiff) model, a unified framework for denoising and lesion\/organ segmentation\nin low-count PET imaging. By integrating multi-task functionality and\nexploiting the mutual benefits of these tasks, AMDiff enables direct\nquantification of clinical metrics, such as total lesion glycolysis (TLG), from\nlow-count inputs. The AMDiff model incorporates a semantic-informed denoiser\nbased on diffusion strategy and a denoising-informed segmenter utilizing\nnnMamba architecture. The segmenter constrains denoised outputs via a\nlesion-organ-specific regularizer, while the denoiser enhances the segmenter by\nproviding enriched image information through a denoising revision module. These\ncomponents are connected via a warming-up mechanism to optimize multitask\ninteractions. Experiments on multi-vendor, multi-center, and multi-noise-level\ndatasets demonstrate the superior performance of AMDiff. For test cases below\n20% of the clinical count levels from participating sites, AMDiff achieves TLG\nquantification biases of -26.98%, outperforming its ablated versions which\nyield biases of -35.85% (without the lesion-organ-specific regularizer) and\n-40.79% (without the denoising revision module)."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-889",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03423",
    "b_title":[
      "SoK: A Review of Cross-Chain Bridge Hacks in 2023"
    ],
    "b_abstract":[
      "Blockchain technology has revolutionized industries by enabling secure and\ndecentralized transactions. However, the isolated nature of blockchain\necosystems hinders the seamless transfer of digital assets across different\nchains. Cross-chain bridges have emerged as vital web3 infrastructure to\naddress this challenge by facilitating interoperability between distinct\nblockchains. Cross-chain bridges remain vulnerable to various attacks despite\nsophisticated designs and security measures. The industry has experienced a\nsurge in bridge attacks, resulting in significant financial losses. The largest\nhack impacted Axie Infinity Ronin Bridge, with a loss of almost \\$600 million\nUSD. This paper analyzes recent cross-chain bridge hacks in 2022 and 2023 and\nexamines the exploited vulnerabilities. By understanding the attack nature and\nunderlying weaknesses, the paper aims to enhance bridge security and propose\npotential countermeasures. The findings contribute to developing industry-wide\nstandards for bridge security and operational resilience. Addressing the\nvulnerabilities and weaknesses exploited in recent cross-chain bridge hacks\nfosters trust and confidence in cross-chain interoperability."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18631",
    "c_title":[
      "XTS mode revisited: high hopes for key scopes?"
    ],
    "c_abstract":[
      "This paper concisely summarizes the XTS block encryption mode for storage\nsector-based encryption applications and clarifies its limitations. In\nparticular, we aim to provide a unified basis for much needed discussions about\nthe newly proposed key scope change to the IEEE 1619 standard."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-890",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02392",
    "b_title":[
      "Synthetic Random Environmental Time Series Generation with Similarity\n  Control, Preserving Original Signal's Statistical Characteristics"
    ],
    "b_abstract":[
      "Synthetic datasets are widely used in many applications, such as missing data\nimputation, examining non-stationary scenarios, in simulations, training\ndata-driven models, and analyzing system robustness. Typically, synthetic data\nare based on historical data obtained from the observed system. The data needs\nto represent a specific behavior of the system, yet be new and diverse enough\nso that the system is challenged with a broad range of inputs. This paper\npresents a method, based on discrete Fourier transform, for generating\nsynthetic time series with similar statistical moments for any given signal.\nThe suggested method makes it possible to control the level of similarity\nbetween the given signal and the generated synthetic signals. Proof shows\nanalytically that this method preserves the first two statistical moments of\nthe input signal, and its autocorrelation function. The method is compared to\nknown methods, ARMA, GAN, and CoSMoS. A large variety of environmental datasets\nwith different temporal resolutions, and from different domains are used,\ntesting the generality and flexibility of the method. A Python library\nimplementing this method is made available as open-source software."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.16504",
    "c_title":[
      "Local Information for Global Network Estimation in Latent Space Models"
    ],
    "c_abstract":[
      "In social networks, neighborhood is crucial for understanding individual\nbehavior in response to environments, and thus it is essential to analyze an\nindividual's local perspective within the global network. This paper studies\nhow to utilize a partial information network centered around a given individual\nfor global network estimation by fitting a general latent space model. Compared\nto the entire network, the partial information network contains a significant\nproportion of missing edges with its structure depending on a random,\npotentially sparse neighborhood, posing significant challenges for estimation.\nWe address the challenges by proposing a projected gradient descent algorithm\nfor maximizing the likelihood of the observed data and develop theoretical\nguarantees for its convergence under different neighborhood structures. Our\nconvergence rates and estimation error bounds highlight the impact of bias in\nan individual's local view of the global network, and we further show that the\nbias can be quantified with an imbalance measure. Using simulated and real\nnetworks, we demonstrate the performance of our estimation method and how our\napproach enables researchers to gain additional insights into the structure of\nsocial networks, such as the tradeoff between degrees and imbalance."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-891",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05595",
    "b_title":[
      "Data efficient Robotic Object Throwing with Model-Based Reinforcement\n  Learning"
    ],
    "b_abstract":[
      "Pick-and-place (PnP) operations, featuring object grasping and trajectory\nplanning, are fundamental in industrial robotics applications. Despite many\nadvancements in the field, PnP is limited by workspace constraints, reducing\nflexibility. Pick-and-throw (PnT) is a promising alternative where the robot\nthrows objects to target locations, leveraging extrinsic resources like gravity\nto improve efficiency and expand the workspace. However, PnT execution is\ncomplex, requiring precise coordination of high-speed movements and object\ndynamics. Solutions to the PnT problem are categorized into analytical and\nlearning-based approaches. Analytical methods focus on system modeling and\ntrajectory generation but are time-consuming and offer limited generalization.\nLearning-based solutions, in particular Model-Free Reinforcement Learning\n(MFRL), offer automation and adaptability but require extensive interaction\ntime. This paper introduces a Model-Based Reinforcement Learning (MBRL)\nframework, MC-PILOT, which combines data-driven modeling with policy\noptimization for efficient and accurate PnT tasks. MC-PILOT accounts for model\nuncertainties and release errors, demonstrating superior performance in\nsimulations and real-world tests with a Franka Emika Panda manipulator. The\nproposed approach generalizes rapidly to new targets, offering advantages over\nanalytical and Model-Free methods."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01471",
    "c_title":[
      "Aerial Gym Simulator: A Framework for Highly Parallelized Simulation of\n  Aerial Robots"
    ],
    "c_abstract":[
      "This paper contributes the Aerial Gym Simulator, a highly parallelized,\nmodular framework for simulation and rendering of arbitrary multirotor\nplatforms based on NVIDIA Isaac Gym. Aerial Gym supports the simulation of\nunder-, fully- and over-actuated multirotors offering parallelized geometric\ncontrollers, alongside a custom GPU-accelerated rendering framework for\nray-casting capable of capturing depth, segmentation and vertex-level\nannotations from the environment. Multiple examples for key tasks, such as\ndepth-based navigation through reinforcement learning are provided. The\ncomprehensive set of tools developed within the framework makes it a powerful\nresource for research on learning for control, planning, and navigation using\nstate information as well as exteroceptive sensor observations. Extensive\nsimulation studies are conducted and successful sim2real transfer of trained\npolicies is demonstrated. The Aerial Gym Simulator is open-sourced at:\nhttps:\/\/github.com\/ntnu-arl\/aerial_gym_simulator."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-892",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02560",
    "b_title":[
      "Weighted-amenability and percolation"
    ],
    "b_abstract":[
      "The automorphism group of a transitive graph defines a weight function on the\nvertices through the Haar modulus. Benjamini, Lyons, Peres, and Schramm\nintroduced the notion of weighted-amenability for a transitive graph, which is\nequivalent to the amenability of its automorphism group. We prove that this\nproperty is equivalent to level-amenability, that is, the property that the\ncollection of vertices of weights in a given finite set always induces an\namenable graph. We then use this to prove a version of Hutchcroft's conjecture\nabout $p_h<p_u$, relaxed \\`a la Pak-Smirnova-Nagnibeda, where $p_h$ is the\ncritical probability for the regime where clusters of infinite total weight\narise, and $p_u$ is the uniqueness threshold. Further characterizations are\ngiven in terms of the spectral radius and invariant spanning forests. One\nconsequence is the continuity of the phase transition at $p_h$ for\nweighted-nonamenable graphs."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.03712",
    "c_title":[
      "SDEs with subcritical Lebesgue--H\\\"{o}lder drifts and driven by\n  $\\alpha$-stable processes"
    ],
    "c_abstract":[
      "We obtain the unique weak and strong solvability for time inhomogeneous\nstochastic differential equations with the drifts in subcritical\nLebesgue--H\\\"{o}lder spaces $L^p([0,T];{\\mathcal C}_b^{\\beta}({\\mathbb\nR}^d;{\\mathbb R}^d))$ and driven by $\\alpha$-stable processes for $\\alpha\\in\n(0,2)$. The weak well-posedness is derived for $\\beta\\in (0,1)$,\n$\\alpha+\\beta>1$ and $p>\\alpha\/(\\alpha+\\beta-1)$ through the Prohorov theorem,\nSkorohod representation and the regularity estimates of solutions for a class\nof fractional parabolic partial differential equations. The pathwise uniqueness\nand Davie's type uniqueness are proved for $\\beta>1- \\alpha\/2$ by using\nIt\\^{o}--Tanaka's trick. Moreover, we give a counterexample to the pathwise\nuniqueness for the supercritical Lebesgue--H\\\"{o}lder drifts to explain the\npresent result is sharp."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-893",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08837",
    "b_title":[
      "Particle Systems and McKean--Vlasov Dynamics with Singular Interaction\n  through Local Times"
    ],
    "b_abstract":[
      "We study a system of reflecting Brownian motions on the positive half-line in\nwhich each particle has a drift toward the origin determined by the local times\nat the origin of all the particles. We show that if this local time drift is\ntoo strong, such systems can exhibit a breakdown in their solutions in that\nthere is a time beyond which the system cannot be extended. In the finite\nparticle case we give a complete characterization of the finite time breakdown,\nrelying on a novel dynamic graph structure. We consider the mean-field limit of\nthe system in the symmetric case and show that there is a McKean--Vlasov\nrepresentation. If the drift is too strong, the solution to the corresponding\nFokker--Planck equation has a blow up in its solution. We also establish the\nexistence of stationary and self-similar solutions to the McKean--Vlasov\nequation in the case where there is no breakdown of the system. This work is\nmotivated by models for liquidity in financial markets, the supercooled Stefan\nproblem, and a toy model for cell polarization."
    ],
    "b_categories":[
      [
        "math.PR"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.12128",
    "c_title":[
      "Dirichlet heat kernel estimates for isotropic Levy processes with\n  Gaussian components in Lipschitz open sets"
    ],
    "c_abstract":[
      "In this paper, the two-sided Dirichlet heat kernel estimates are obtained for\na class of discontinuous isotropic Levy processes with Gaussian components in\nLipschitz open sets. Furthermore, the necessary and sufficient conditions for\nthe Varopoulos-type Dirichlet heat kernel estimates holding for such processes\nin Lipschitz open sets are derived."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-894",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.05164",
    "b_title":[
      "Tree Models Machine Learning to Identify Liquid Metal based Alloy\n  Superconductor"
    ],
    "b_abstract":[
      "Superconductors, which are crucial for modern advanced technologies due to\ntheir zero-resistance properties, are limited by low Tc and the difficulty of\naccurate prediction. This article made the initial endeavor to apply machine\nlearning to predict the critical temperature (Tc) of liquid metal (LM) alloy\nsuperconductors. Leveraging the SuperCon dataset, which includes extensive\nsuperconductor property data, we developed a machine learning model to predict\nTc. After addressing data issues through preprocessing, we compared multiple\nmodels and found that the Extra Trees model outperformed others with an R2 of\n0.9519 and an RMSE of 6.2624 K. This model is subsequently used to predict Tc\nfor LM alloys, revealing In0.5Sn0.5 as having the highest Tc at 7.01 K.\nFurthermore, we extended the prediction to 2,145 alloys binary and 45,670\nternary alloys across 66 metal elements and promising results were achieved.\nThis work demonstrates the advantages of tree-based models in predicting Tc and\nwould help accelerate the discovery of high-performance LM alloy\nsuperconductors in the coming time."
    ],
    "b_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.11601",
    "c_title":[
      "Weak coupling approach to magnetic and orbital susceptibilities for\n  superconducting states in multiorbital electron-phonon coupled model"
    ],
    "c_abstract":[
      "Alkali-doped fullerides are molecular-based superconductors with multiple\nactive orbitals. In this paper, using the Eliashberg theory with the\nretardation effect of Jahn-Teller phonons, we study the response of the\nspin-singlet superconducting state relevant to fulleride materials. The spin\nZeeman field is not active for the singlet pairing state, and the magnetic\norbital field, which physically generates a circular electron motion inside the\nfullerene molecule, is also shown to be inactive. On the other hand, the\nelectric orbital (or quadrupolar) field, which corresponds to a uniaxial\ndistortion, remains active across the superconducting phase transition. This is\nunderstood by the orbital-symmetric structure of the Cooper pair, which is\nsusceptible to the electric orbital field, while it is not the case for the\nmagnetic orbital field which tends to create an antisymmetric part."
    ],
    "c_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-895",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09951",
    "b_title":[
      "Discord's Design Encourages \"Third Place\" Social Media Experiences"
    ],
    "b_abstract":[
      "In light of the diminishing presence of physical third places -- informal\ngathering spaces essential for social connection -- this study explores how the\nsocial media platform Discord fosters third-place experiences. Drawing on\nOldenburg's conceptual framework, we analyze how Discord's design elements\nsupport the creation of virtual third places that foster both dyadic and\ncommunity-based relationships. Through 25 semi-structured interviews with\nactive Discord users, we identified 21 design elements aligned with Oldenburg's\nthird-place characteristics. These elements cluster around four core\nprinciples: providing themed spaces for repeated interactions, supporting user\nautonomy and customization, facilitating mutually engaging activities, and\nenabling casual, low-pressure interactions. This work contributes to\nunderstanding how intentional platform design can cultivate virtual spaces that\nsupport meaningful social connections. The findings have implications for\ndesigning future social technologies that can help address growing concerns\nabout social isolation in an increasingly digital world."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.11018",
    "c_title":[
      "An LLM's Attempts to Adapt to Diverse Software Engineers'\n  Problem-Solving Styles: More Inclusive & Equitable?"
    ],
    "c_abstract":[
      "Software engineers use code-fluent large language models (LLMs) to help\nexplain unfamiliar code, yet LLM explanations are not adapted to engineers'\ndiverse problem-solving needs. We prompted an LLM to adapt to five\nproblem-solving style types from an inclusive design method, the Gender\nInclusiveness Magnifier (GenderMag). We ran a user study with software\nengineers to examine the impact of explanation adaptations on software\nengineers' perceptions, both for explanations which matched and mismatched\nengineers' problem-solving styles. We found that explanations were more\nfrequently beneficial when they matched problem-solving style, but not every\nmatching adaptation was equally beneficial; in some instances, diverse\nengineers found as much (or more) benefit from mismatched adaptations. Through\nan equity and inclusivity lens, our work highlights the benefits of having an\nLLM adapt its explanations to match engineers' diverse problem-solving style\nvalues, the potential harms when matched adaptations were not perceived well by\nengineers, and a comparison of how matching and mismatching LLM adaptations\nimpacted diverse engineers."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-896",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14037",
    "b_title":[
      "Intra and Inter Parser-Prompted Transformers for Effective Image\n  Restoration"
    ],
    "b_abstract":[
      "We propose Intra and Inter Parser-Prompted Transformers (PPTformer) that\nexplore useful features from visual foundation models for image restoration.\nSpecifically, PPTformer contains two parts: an Image Restoration Network\n(IRNet) for restoring images from degraded observations and a Parser-Prompted\nFeature Generation Network (PPFGNet) for providing IRNet with reliable parser\ninformation to boost restoration. To enhance the integration of the parser\nwithin IRNet, we propose Intra Parser-Prompted Attention (IntraPPA) and Inter\nParser-Prompted Attention (InterPPA) to implicitly and explicitly learn useful\nparser features to facilitate restoration. The IntraPPA re-considers cross\nattention between parser and restoration features, enabling implicit perception\nof the parser from a long-range and intra-layer perspective. Conversely, the\nInterPPA initially fuses restoration features with those of the parser,\nfollowed by formulating these fused features within an attention mechanism to\nexplicitly perceive parser information. Further, we propose a parser-prompted\nfeed-forward network to guide restoration within pixel-wise gating modulation.\nExperimental results show that PPTformer achieves state-of-the-art performance\non image deraining, defocus deblurring, desnowing, and low-light enhancement."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.07002",
    "c_title":[
      "Taking Notes Brings Focus? Towards Multi-Turn Multimodal Dialogue\n  Learning"
    ],
    "c_abstract":[
      "Multimodal large language models (MLLMs), built on large-scale pre-trained\nvision towers and language models, have shown great capabilities in multimodal\nunderstanding. However, most existing MLLMs are trained on single-turn vision\nquestion-answering tasks, which do not accurately reflect real-world human\nconversations. In this paper, we introduce MMDiag, a multi-turn multimodal\ndialogue dataset. This dataset is collaboratively generated through\ndeliberately designed rules and GPT assistance, featuring strong correlations\nbetween questions, between questions and images, and among different image\nregions; thus aligning more closely with real-world scenarios. MMDiag serves as\na strong benchmark for multi-turn multimodal dialogue learning and brings more\nchallenges to the grounding and reasoning capabilities of MLLMs. Further,\ninspired by human vision processing, we present DiagNote, an MLLM equipped with\nmultimodal grounding and reasoning capabilities. DiagNote consists of two\nmodules (Deliberate and Gaze) interacting with each other to perform\nChain-of-Thought and annotations respectively, throughout multi-turn dialogues.\nWe empirically demonstrate the advantages of DiagNote in both grounding and\njointly processing and reasoning with vision and language information over\nexisting MLLMs."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-897",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14874",
    "b_title":[
      "Waveguide QED with dissipative light-matter couplings"
    ],
    "b_abstract":[
      "Dissipative light-matter coupling plays a vital role in non-Hermitian\nphysics, but it remains largely unexplored in waveguide QED systems. In this\nwork, we find that by employing pseudo-Hermitian symmetry rather than anti-PT\nsymmetry, the concept of dissipative coupling could be generalized and applied\nto the field of waveguide QED. This leads to a series of intriguing results,\nsuch as spontaneous breaking of pseudo-Hermitian symmetry across the\nexceptional points (EPs), level attraction between the bound states, and\ncritical transition across the EPs for the population of quantum emitters in\nthe bound state. Thanks to the tunability of photonic bands in crystal\nwaveguides, we also demonstrate that dissipative light-matter coupling leads to\nthe emergence of nonstandard third-order exceptional points with chiral spatial\nprofiles in a topological waveguide QED system. This work provides a promising\nparadigm for studying non-Hermitian quantum phenomena in waveguide QED systems."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.03093",
    "c_title":[
      "Stabilizer Entropy and entanglement complexity in the Sachdev-Ye-Kitaev\n  model"
    ],
    "c_abstract":[
      "The Sachdev-Ye-Kitaev (SYK) model is of paramount importance for the\nunderstanding of both strange metals and a microscopic theory of\ntwo-dimensional gravity. We study the interplay between Stabilizer R\\'enyi\nEntropy (SRE) and entanglement entropy in both the ground state and highly\nexcited states of the SYK4+SYK2 model interpolating the highly chaotic\nfour-body interactions model with the integrable two-body interactions one. The\ninterplay between these quantities is assessed also through universal\nstatistics of the entanglement spectrum and its anti-flatness. We find that\nSYK4 is indeed characterized by a complex pattern of both entanglement and\nnon-stabilizer resources while SYK2 is non-universal and not complex. We\ndiscuss the fragility and robustness of these features depending on the\ninterpolation parameter."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-898",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09812",
    "b_title":[
      "Presence of $^{236}$U and $^{237}$Np in a marine ecosystem: the northern\n  Benguela Upwelling System, a case study"
    ],
    "b_abstract":[
      "The Benguela Upwelling System (BUS), off the south-western African coast, is\none of the four major eastern boundary upwelling ecosystems in the oceans.\nHowever, despite its very interesting characteristics, this area has been\nalmost overlooked in the field of environmental radioactivity. In this work, it\nhas been carried out for the first time the combined study of $^{236}$U and\n$^{237}$Np in the coast of Namibia within the northern BUS. Surface seawater\nexhibited similar $^{236}$U and $^{237}$Np concentrations, ranging from\n$3.9\\times10^6$ to $5.6\\times10^6$ atoms\/kg and from $4.6\\times10^6$ to\n$8.5\\times10^6$ atoms\/kg, respectively. The observed inventories in a water\ncolumn from the continental margin, of $(2.10 \\pm 0.11)\\times10^12$ atoms\nm$^{-2}$ for $^{236}$U and $(3.48 \\pm 0.13)\\times10^{12}$ atoms\/m$^{-2}$ for\n$^{237}$Np, were in agreement with the global fallout (GF) source term in the\nSouthern Hemisphere, which was recognized as the main source of actinides to\nthe region. A pattern was observed in the surface samples, with $^{237}$Np\nconcentrations that decreased by 25-30% when moving from inshore to offshore\nstations, but such an effect could not be clearly discerned in the case of\n$^{236}$U within the data uncertainties. An explanation based on the larger\nparticle reactivity of GF $^{237}$Np compared to GF $^{236}$U was proposed.\nSuch an effect would have been important at the studied site due to the enhance\npresence of particles in the continental shelf triggered by the upwelling\nphenomenon. A value of $1.77 \\pm 0.20$ was obtained for the\n$^{237}$Np\/$^{236}$U atom ratio for the GF source term in the marine\nenvironment."
    ],
    "b_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.04391",
    "c_title":[
      "Real-Time 3D Magnetic Field Camera for a Spherical Volume"
    ],
    "c_abstract":[
      "Accurate and efficient volumetric magnetic field measurements are essential\nfor a wide range of applications. Conventional methods are often limited in\nterms of measurement speed and applicability, or suffer from scaling problems\nat larger volumes. This work presents the development of a magnetometer array\ndesigned to measure magnetic fields within a spherical volume at a frame rate\nof 10 Hz. The array consists of 3D Hall magnetometers positioned according to a\nspherical $t$-design, allowing simultaneous magnetic field data acquisition\nfrom the surface of the sphere. The approach enables the efficient\nrepresentation of all three components of the magnetic field inside the sphere\nusing a sixth-degree polynomial, significantly reducing measurement time\ncompared to sequential methods. This work details the design, calibration, and\nmeasurement methods of the array. To evaluate its performance, we compare it to\na sequential single-sensor measurement by examining a magnetic gradient field.\nThe obtained measurement uncertainties of approx. 1% show the applicability for\na variety of applications."
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-899",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04425",
    "b_title":[
      "Tensor-Programmable Quantum Circuits for Solving Differential Equations"
    ],
    "b_abstract":[
      "We present a quantum solver for partial differential equations based on a\nflexible matrix product operator representation. Utilizing mid-circuit\nmeasurements and a state-dependent norm correction, this scheme overcomes the\nrestriction of unitary operators. Hence, it allows for the direct\nimplementation of a broad class of differential equations governing the\ndynamics of classical and quantum systems. The capabilities of the framework\nare demonstrated for an example system governed by Euler equations with\nabsorbing boundaries."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.09503",
    "c_title":[
      "Frequency-noise-insensitive universal control of Kerr-cat qubits"
    ],
    "c_abstract":[
      "We theoretically study the influence of frequency uncertainties on the\noperation of a Kerr-cat qubit. As the mean photon number increases, Kerr-cat\nqubits provide an increasing level of protection against phase errors induced\nby unknown frequency shifts during idling and X rotations. However, realizing\nrotations about the other principal axes (e.g., Y and Z axes) while preserving\nrobustness is nontrivial. To address this challenge, we propose a universal set\nof gate schemes which circumvents the tradeoff between protection and\ncontrollability in Kerr-cat qubits and retains robustness to unknown frequency\nshifts to at least first order. Assuming an effective Kerr oscillator model, we\ntheoretically and numerically analyze the robustness of elementary gates on\nKerr-cat qubits, with special focus on gates along nontrivial rotation axes. An\nappealing application of this qubit design would include tunable\nsuperconducting platforms, where the induced protection against frequency noise\nwould allow for a more flexible choice of operating point and thus the\npotential mitigation of the impact of spurious two-level systems."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-900",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04936",
    "b_title":[
      "On the optimal control of initial velocity in a hyperbolic beam equation\n  by the variational method"
    ],
    "b_abstract":[
      "We study the problem of controlling the initial condition of a vibrating\nbeam. The optimal control problem seeks to determine solutions of initial\nvelocity that assure the approach of the state of the beam to a given target\nfunction in the $L^2-$norm. We prove both the existence and uniqueness of the\noptimal solution. Employing identities based on the adjoint and difference\nproblems, we determine the Fr\\'echet derivative of the cost functional. We\nfurther derive the necessary optimality conditions of this control problem.\nFinally, we provide a sketch of a gradient-based algorithm, that rests on the\nexplicit formula of the gradient of the cost functional, to obtain numerical\nsolutions."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.05619",
    "c_title":[
      "Comparative Analysis of Two-Stage Distributionally Robust Optimization\n  over 1-Wasserstein and 2-Wasserstein Balls"
    ],
    "c_abstract":[
      "This paper investigates advantages of using 2-Wasserstein ambiguity sets over\n1-Wasserstein sets in two-stage distributionally robust optimization with\nright-hand side uncertainty. We examine the worst-case distributions within 1-\nand 2-Wasserstein balls under both unrestricted and nonnegative orthant\nsupports, highlighting a pathological behavior arising in 1-Wasserstein balls.\nClosed-form solutions for a single-scenario newsvendor problem illustrate that\n2-Wasserstein balls enable more informed decisions. Additionally, a\npenalty-based dual interpretation suggests that 2-Wasserstein balls may\noutperform 1-Wasserstein balls across a broader range of Wasserstein radii,\neven with general support sets."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-901",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05452",
    "b_title":[
      "Curvature-Controlled Polarization in Adaptive Ferroelectric Membranes"
    ],
    "b_abstract":[
      "In this study, we explore the ferroelectric domain structure and mechanical\nproperties of PbTiO$_3$-based membranes, which develops a well-ordered and\ncrystallographic-oriented ripple pattern upon release from their growth\nsubstrate. The ferrolectric domain structure of the PbTiO$_3$ layer was\nexamined at various length scales using optical second harmonic generation,\npiezoresponse force microscopy, and scanning transmission electron microscopy.\nThese methods reveal the presence of purely in-plane domains organized into\nsuperdomains at the crest of the ripples, while an in-plane\/out-of-plane domain\nstructure was observed in the flat regions separating the ripples, in agreement\nwith phase-field simulations. The mechanical properties of the membrane were\nassessed using contact resonance force microscopy, which identified distinct\nmechanical behaviors at the ripples compared to the flat regions. This study\nshows that the physical properties of the ferroelectric layer in membranes can\nbe locally controlled within an ordered array of ripples, with well-defined\ngeometric characteristics."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.09458",
    "c_title":[
      "Tunable spin and orbital torques in Cu-based magnetic heterostructures"
    ],
    "c_abstract":[
      "Current-induced torques originating from earth-abundant 3d elements offer a\npromising avenue for low-cost and sustainable spintronic memory and logic\napplications. Recently, orbital currents -- transverse orbital angular momentum\nflow in response to an electric field -- have been in the spotlight since they\nallow current-induced torque generation from 3d transition metals. Here, we\nreport a comprehensive study of the current-induced spin and orbital torques in\nCu-based magnetic heterostructures. We show that high torque efficiencies can\nbe achieved in engineered Ni80Fe20\/Cu bilayers where Cu is naturally oxidized,\nexceeding the ones found in the archetypical Co\/Pt. Furthermore, we demonstrate\nsign and amplitude control of the damping-like torque by manipulating the\noxidation state of Cu via solid-state gating. Our findings provide insights\ninto the interplay between charge, spin, and orbital transport in Cu-based\nheterostructures and open the door to the development of gate-tunable\nspin-orbitronic devices."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-902",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14079",
    "b_title":[
      "Testing Uniform Random Samplers: Methods, Datasets and Protocols"
    ],
    "b_abstract":[
      "Boolean formulae compactly encode huge, constrained search spaces. Thus,\nvariability-intensive systems are often encoded with Boolean formulae. The\nsearch space of a variability-intensive system is usually too large to explore\nwithout statistical inference (e.g. testing). Testing every valid configuration\nis computationally expensive (if not impossible) for most systems. This leads\nmost testing approaches to sample a few configurations before analyzing them. A\ndesirable property of such samples is uniformity: Each solution should have the\nsame selection probability. Uniformity is the property that facilitates\nstatistical inference. This property motivated the design of uniform random\nsamplers, relying on SAT solvers and counters and achieving different\ntrade-offs between uniformity and scalability. Though we can observe their\nperformance in practice, judging the quality of the generated samples is\ndifferent. Assessing the uniformity of a sampler is similar in nature to\nassessing the uniformity of a pseudo-random number (PRNG) generator. However,\nsampling is much slower and the nature of sampling also implies that the\nhyperspace containing the samples is constrained. This means that testing PRNGs\nis subject to fewer constraints than testing samplers. We propose a framework\nthat contains five statistical tests which are suited to test uniform random\nsamplers. Moreover, we demonstrate their use by testing seven samplers.\nFinally, we demonstrate the influence of the Boolean formula given as input to\nthe samplers under test on the test results."
    ],
    "b_categories":[
      [
        "cs.LO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14465",
    "c_title":[
      "Coverage Types for Resource-Based Policies"
    ],
    "c_abstract":[
      "Coverage Types provide a suitable type mechanism that integrates\nunder-approximation logic to support Property-Based Testing. They are used to\ntype the return value of a function that represents an input test generator.\nThis allows us to statically assert that an input test generator not only\nproduces valid input tests but also generates all possible ones, ensuring\ncompleteness. In this paper, we extend the coverage framework to guarantee the\ncorrectness of Property-Based Testing with respect to resource usage in the\ninput test generator. This is achieved by incorporating into Coverage Types a\nnotion of effect, which represents an over-approximation of operations on\nrelevant resources. Programmers can define resource usage policies through\nlogical annotations, which are then verified against the effect associated with\nthe Coverage Type."
    ],
    "c_categories":[
      [
        "cs.LO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-903",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06663",
    "b_title":[
      "EfficientLLM: Scalable Pruning-Aware Pretraining for\n  Architecture-Agnostic Edge Language Models"
    ],
    "b_abstract":[
      "Modern large language models (LLMs) driven by scaling laws, achieve\nintelligence emergency in large model sizes. Recently, the increasing concerns\nabout cloud costs, latency, and privacy make it an urgent requirement to\ndevelop compact edge language models. Distinguished from direct pretraining\nthat bounded by the scaling law, this work proposes the pruning-aware\npretraining, focusing on retaining performance of much larger optimized models.\nIt features following characteristics: 1) Data-scalable: we introduce minimal\nparameter groups in LLM and continuously optimize structural pruning, extending\npost-training pruning methods like LLM-Pruner and SparseGPT into the\npretraining phase. 2) Architecture-agnostic: the LLM architecture is\nauto-designed using saliency-driven pruning, which is the first time to exceed\nSoTA human-designed LLMs in modern pretraining. We reveal that it achieves\ntop-quality edge language models, termed EfficientLLM, by scaling up LLM\ncompression and extending its boundary. EfficientLLM significantly outperforms\nSoTA baselines with $100M \\sim 1B$ parameters, such as MobileLLM, SmolLM,\nQwen2.5-0.5B, OLMo-1B, Llama3.2-1B in common sense benchmarks. As the first\nattempt, EfficientLLM bridges the performance gap between traditional LLM\ncompression and direct pretraining methods, and we will fully open source at\nhttps:\/\/github.com\/Xingrun-Xing2\/EfficientLLM."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.10216",
    "c_title":[
      "The Relevance of AWS Chronos: An Evaluation of Standard Methods for Time\n  Series Forecasting with Limited Tuning"
    ],
    "c_abstract":[
      "A systematic comparison of Chronos, a transformer-based time series\nforecasting framework, against traditional approaches including ARIMA and\nProphet. We evaluate these models across multiple time horizons and user\ncategories, with a focus on the impact of historical context length. Our\nanalysis reveals that while Chronos demonstrates superior performance for\nlonger-term predictions and maintains accuracy with increased context,\ntraditional models show significant degradation as context length increases. We\nfind that prediction quality varies systematically between user classes,\nsuggesting that underlying behavior patterns always influence model\nperformance. This study provides a case for deploying Chronos in real-world\napplications where limited model tuning is feasible, especially in scenarios\nrequiring longer prediction."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-904",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11888",
    "b_title":[
      "Probing negative differential resistance in silicon with a P-I-N\n  diode-integrated T center ensemble"
    ],
    "b_abstract":[
      "The T center in silicon has recently emerged as a promising candidate for\nscalable quantum technologies, due to its telecommunications band optical\ntransition and microwave addressable ground state spin. The immense promise of\nthe T center is driven by its silicon host material; silicon is by far the most\nmature, manufacturable semiconductor material for integrated photonic and\nelectronic devices. Here, we present the first study of T-centers in an\nelectrical device. We study an ensemble of T centers coupled to a buried\nlateral P-I-N diode in silicon, observing the T-center's optical response to\nstatic and dynamic electric fields. We utilize the defect's optical response as\na probe of device nonlinearity, observing a phase transition of the carrier\ndensity into a stable oscillatory regime characteristic of negative\ndifferential resistance. These findings provide fundamental insight into the\nphysics of the T-center for improved quantum device performance and open a\npromising new direction for defect-based local quantum sensing in semiconductor\ndevices."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.01467",
    "c_title":[
      "On Exact Sizes of Minimal CNOT Circuits"
    ],
    "c_abstract":[
      "Computing a minimum-size circuit that implements a certain function is a\nstandard optimization task. We consider circuits of CNOT gates, which are\nfundamental binary gates in reversible and quantum computing. Algebraically,\nCNOT circuits on $n$ qubits correspond to $GL(n,2)$, the general linear group\nover the field of two elements, and circuit minimization reduces to computing\ndistances in the Cayley graph $G_n$ of $GL(n,2)$ generated by transvections.\nHowever, the super-exponential size of $GL(n,2)$ has made its exploration\ncomputationally challenging.\n  In this paper, we develop a new approach for computing distances in $G_n$,\nallowing us to synthesize minimum circuits that were previously beyond reach\n(e.g., we can synthesize optimally all circuits over $n=7$ qubits). Towards\nthis, we establish two theoretical results that may be of independent interest.\nFirst, we give a complete characterization of all isometries in $G_n$ in terms\nof (i) permuting qubits and (ii) swapping the arguments of all CNOT gates.\nSecond, for any fixed $d$, we establish polynomials in $n$ of degree $2d$ that\ncharacterize the size of spheres in $G_n$ at distance $d$, as long as $n\\geq\n2d$. With these tools, we revisit an open question of [Bataille, 2022]\nregarding the smallest number $n_0$ for which the diameter of $G_{n_0}$ exceeds\n$3(n_0-1)$. It was previously shown that $6\\leq n_0 \\leq 30$, a gap that we\ntighten considerably to $8\\leq n_0 \\leq 20$. We also confirm a conjecture that\nlong cycle permutations lie at distance $3(n-1)$, for all $n\\leq 8$, extending\nthe previous bound of $n\\leq 5$."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-905",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01815",
    "b_title":[
      "Analytical modeling of laminated composite rings on nonreciprocal\n  elastic foundations under non-axisymmetric loading"
    ],
    "b_abstract":[
      "A mechanical model of a laminated composite ring on a nonreciprocal elastic\nfoundation is a valuable engineering tool during the early design stages of\nvarious applications, such as non-pneumatic wheels, flexible bearings,\nexpandable tubulars in oil wells, and vascular stents interacting with blood\nvessel linings, especially under non-axisymmetric loadings. Despite its\nimportance, limited research has focused on the interaction between laminated\ncomposite rings and nonreciprocal elastic foundations. Moreover, no\nquantitative studies have yet explored the influence of foundation stiffness on\nthe ring deformation. This work aims to develop an analytical framework for a\nlaminated composite ring supported by a nonreciprocal elastic foundation under\nnon-axisymmetric loading conditions. The model generates a design map that\ncorrelates the foundation stiffness with the ring deformation, accounting for\nring dimensions, laminate layup architecture, and lamina anisotropy. The\nclosed-form solution provides an efficient design tool for analyzing\nnon-axisymmetric and nonuniform loadings at a low computational cost. The\nresulting design map provides a valuable resource for exploring the interaction\nbetween the nonreciprocal foundation and the laminated ring. The proposed\nanalytical framework and design map hold broad potential applications in\nautomotive, mechanical, civil, and biomedical engineering fields."
    ],
    "b_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.13736",
    "c_title":[
      "Near-zero Temperature Coefficient of Resistance for a Single-Walled\n  Carbon Nanotube Polymer Nanocomposite"
    ],
    "c_abstract":[
      "Temperature dependence of electrical resistance of single-walled carbon\nnanotube (SWCNTs)\/epoxy nanocomposites, which is characterized by a temperature\ncoefficient of resistance (TCR), is experimentally investigated. In the\nexisting literature, there are biased TCR values with non-monotonic temperature\ndependence, including both negative and positive values. In this study, we\ndemonstrate that the influence of environment temperature can be greatly\nminimized by ensuring the CNT\/epoxy nanocomposite is fully cured along with\ncontrolling CNT concentration and selecting an appropriate polymer matrix. In\naddition, agglomeration of CNTs significantly influences the performance of\nCNT\/polymer nanocomposites. Resistance values remained nearly constant at a CNT\nconcentration of approximately 1 wt.% below the glass transition temperature.\nIt is also observed that in a fully cured CNT\/epoxy nanocomposite with the\nmicroscale conductive pathway as the main conductance mechanism, the\ncoefficient of thermal expansion (CTE) of the matrix is a critical\ncharacteristic, resulting in a consistent increasing trend in TCR."
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-906",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.10049",
    "b_title":[
      "PandaSkill - Player Performance and Skill Rating in Esports: Application\n  to League of Legends"
    ],
    "b_abstract":[
      "To take the esports scene to the next level, we introduce PandaSkill, a\nframework for assessing player performance and skill rating. Traditional rating\nsystems like Elo and TrueSkill often overlook individual contributions and face\nchallenges in professional esports due to limited game data and fragmented\ncompetitive scenes. PandaSkill leverages machine learning to estimate in-game\nplayer performance from individual player statistics. Each in-game role is\nmodeled independently, ensuring a fair comparison between them. Then, using\nthese performance scores, PandaSkill updates the player skill ratings using the\nBayesian framework OpenSkill in a free-for-all setting. In this setting, skill\nratings are updated solely based on performance scores rather than game\noutcomes, hightlighting individual contributions. To address the challenge of\nisolated rating pools that hinder cross-regional comparisons, PandaSkill\nintroduces a dual-rating system that combines players' regional ratings with a\nmeta-rating representing each region's overall skill level. Applying PandaSkill\nto five years of professional League of Legends matches worldwide, we show that\nour method produces skill ratings that better predict game outcomes and align\nmore closely with expert opinions compared to existing methods."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.20807",
    "c_title":[
      "Digital Player: Evaluating Large Language Models based Human-like Agent\n  in Games"
    ],
    "c_abstract":[
      "With the rapid advancement of Large Language Models (LLMs), LLM-based\nautonomous agents have shown the potential to function as digital employees,\nsuch as digital analysts, teachers, and programmers. In this paper, we develop\nan application-level testbed based on the open-source strategy game \"Unciv\",\nwhich has millions of active players, to enable researchers to build a \"data\nflywheel\" for studying human-like agents in the \"digital players\" task. This\n\"Civilization\"-like game features expansive decision-making spaces along with\nrich linguistic interactions such as diplomatic negotiations and acts of\ndeception, posing significant challenges for LLM-based agents in terms of\nnumerical reasoning and long-term planning. Another challenge for \"digital\nplayers\" is to generate human-like responses for social interaction,\ncollaboration, and negotiation with human players. The open-source project can\nbe found at https:\/github.com\/fuxiAIlab\/CivAgent."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-907",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16114",
    "b_title":[
      "The Impact of Revealing Large Language Model Stochasticity on Trust,\n  Reliability, and Anthropomorphization"
    ],
    "b_abstract":[
      "Interfaces for interacting with large language models (LLMs) are often\ndesigned to mimic human conversations, typically presenting a single response\nto user queries. This design choice can obscure the probabilistic and\npredictive nature of these models, potentially fostering undue trust and\nover-anthropomorphization of the underlying model. In this paper, we\ninvestigate (i) the effect of displaying multiple responses simultaneously as a\ncountermeasure to these issues, and (ii) how a cognitive support\nmechanism-highlighting structural and semantic similarities across\nresponses-helps users deal with the increased cognitive load of that\nintervention. We conducted a within-subjects study in which participants\ninspected responses generated by an LLM under three conditions: one response,\nten responses with cognitive support, and ten responses without cognitive\nsupport. Participants then answered questions about workload, trust and\nreliance, and anthropomorphization. We conclude by reporting the results of\nthese studies and discussing future work and design opportunities for future\nLLM interfaces."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.14229",
    "c_title":[
      "Feedforward in Generative AI: Opportunities for a Design Space"
    ],
    "c_abstract":[
      "Generative AI (GenAI) models have become more capable than ever at augmenting\nproductivity and cognition across diverse contexts. However, a fundamental\nchallenge remains as users struggle to anticipate what AI will generate. As a\nresult, they must engage in excessive turn-taking with the AI's feedback to\nclarify their intent, leading to significant cognitive load and time\ninvestment. Our goal is to advance the perspective that in order for users to\nseamlessly leverage the full potential of GenAI systems across various\ncontexts, we must design GenAI systems that not only provide informative\nfeedback but also informative feedforward -- designs that tell users what AI\nwill generate before the user submits their prompt. To spark discussion on\nfeedforward in GenAI, we designed diverse instantiations of feedforward across\nfour GenAI applications: conversational UIs, document editors, malleable\ninterfaces, and automation agents, and discussed how these designs can\ncontribute to a more rigorous investigation of a design space and a set of\nguidelines for feedforward in all GenAI systems."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-908",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04248",
    "b_title":[
      "Nonreciprocal Optical Routing in Multi-port Magneto-Optical Devices on\n  Silicon"
    ],
    "b_abstract":[
      "Nonreciprocal optical devices are key components in photonic integrated\ncircuits for light reflection blocking and routing. Most reported silicon\nintegrated nonreciprocal optical devices to date were unit devices. To allow\ncomplex signal routing between multi-ports in photonic networks, multi-port\nmagneto-optical (MO) nonreciprocal photonic devices are desired. In this study,\nwe report experimental demonstration of a silicon integrated 5*5 multiport\nnonreciprocal photonic device based on magneto-optical waveguides. By\nintroducing different nonreciprocal phase shift effect to planar photonic\nwaveguides, the device focuses light to different ports for both forward and\nbackward propagation. The device shows designable nonreciprocal transmission\nbetween 5*5 ports, achieving 16 dB isolation ratio and -18 dB crosstalk."
    ],
    "b_categories":[
      [
        "physics.optics"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.14547",
    "c_title":[
      "Dichroism of coupled multipolar plasmonic modes in twisted triskelion\n  stacks"
    ],
    "c_abstract":[
      "We present a systematic investigation of the optical response to circularly\npolarized illumination in twisted stacked plasmonic nanostructures. The system\nconsissts in two identical, parallel gold triskelia centrally aligned and\nrotated at a central angle relative to each other. Sample fabrication was\nacomplished through a double electron beam lithograpy process. This stack holds\ntwo plasmonic modes of multipolar character in the near-infrared range, showing\na strong dependence of their excitation intensities on the handedness of the\ncircularly polarized incident light. This translates in a large circular\ndicrhoism which can be modulated by adjusting the twist angle of the stack.\nFourier-transform infrared spectroscopy and numerical simulations were employed\nto characterize the spectral features of the modes. Remarkable, in contrast to\nprevious results in other stacked nanostructures, the system's response\nexhibits a behavious analogous to that of two interacting dipoles only at small\nangles. As the angle approaches 15 degrees, where the maximum dichroism is\nobserved, more complex modes of the stack emerge. These modes evolve towards\ntwo in-phase multipolar excitations of the two triskelia as the angle increases\nuo to 60 degrees. Finally, simulations for a triangular array of such stacked\nelements show a sharp mode arising from the hybridization of a surface lattice\nresonance with the low-energy mode of the stack."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-909",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07702",
    "b_title":[
      "A Reliable Self-Organized Distributed Complex Network for Communication\n  of Smart Agents"
    ],
    "b_abstract":[
      "Collaboration is a fundamental and essential characteristic of many complex\nsystems, ranging from ant colonies to human societies. Each component within a\ncomplex system interacts with others, even at a distance, to accomplish a given\ntask. A network of collaboration can be defined to study the collective\nbehavior of such systems within the framework of complex networks. The nodes in\nthese networks may represent simple organisms or more sophisticated intelligent\nagents, such as humans. In this study, we utilize intelligent agents (nodes)\ntrained through reinforcement learning techniques to establish connections with\ntheir neighbors, ultimately leading to the emergence of a large-scale\ncommunication cluster. Notably, there is no centralized administrator; instead,\nagents must adjust their connections based on information obtained from local\nobservations. The connection strategy is formulated using a physical\nHamiltonian, thereby categorizing this intelligent system under the paradigm of\n\"Physics-Guided Machine Learning\"."
    ],
    "b_categories":[
      [
        "cs.MA"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.19025",
    "c_title":[
      "Recognize then Resolve: A Hybrid Framework for Understanding Interaction\n  and Cooperative Conflict Resolution in Mixed Traffic"
    ],
    "c_abstract":[
      "A lack of understanding of interactions and the inability to effectively\nresolve conflicts continue to impede the progress of Connected Autonomous\nVehicles (CAVs) in their interactions with Human-Driven Vehicles (HDVs). To\naddress this challenge, we propose the Recognize then Resolve (RtR) framework.\nFirst, a Bilateral Intention Progression Graph (BIPG) is constructed based on\nCAV-HDV interaction data to model the evolution of interactions and identify\npotential HDV intentions. Three typical interaction breakdown scenarios are\nthen categorized, and key moments are defined for triggering cooperative\nconflict resolution. On this basis, a constrained Monte Carlo Tree Search\n(MCTS) algorithm is introduced to determine the optimal passage order while\naccommodating HDV intentions. Experimental results demonstrate that the\nproposed RtR framework outperforms other cooperative approaches in terms of\nsafety and efficiency across various penetration rates, achieving results close\nto consistent cooperation while significantly reducing computational resources.\nOur code and data are available at:\nhttps:\/\/github.com\/FanGShiYuu\/RtR-Recognize-then-Resolve\/."
    ],
    "c_categories":[
      [
        "cs.MA"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-910",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09189",
    "b_title":[
      "The Kieker Observability Framework Version 2"
    ],
    "b_abstract":[
      "Observability of a software system aims at allowing its engineers and\noperators to keep the system robust and highly available. With this paper, we\npresent the Kieker Observability Framework Version 2, the successor of the\nKieker Monitoring Framework.\n  In this tool artifact paper, we do not just present the Kieker framework, but\nalso a demonstration of its application to the TeaStore benchmark, integrated\nwith the visual analytics tool ExplorViz. This demo is provided both as an\nonline service and as an artifact to deploy it yourself."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.11787",
    "c_title":[
      "Semantic Dependency in Microservice Architecture: A Framework for\n  Definition and Detection"
    ],
    "c_abstract":[
      "Microservices have been a key architectural approach for over a decade,\ntransforming system design by promoting decentralization and allowing\ndevelopment teams to work independently on specific microservices. While\nloosely coupled microservices are ideal, dependencies between them are\ninevitable. Often, these dependencies go unnoticed by development teams.\nAlthough syntactic dependencies can be identified, tracking semantic\ndependencies - when multiple microservices share similar logic - poses a\ngreater challenge. As systems evolve, changes made to one microservice can\ntrigger ripple effects, jeopardizing system consistency and requiring updates\nto dependent services, which increases maintenance and operational complexity.\nEffectively tracking different types of dependencies across microservices is\nessential for anticipating the impact of such changes. This paper introduces\nthe Semantic Dependency Matrix as an instrument to address these challenges\nfrom a semantic perspective. We propose an automated approach to extract and\nrepresent these dependencies and demonstrate its effectiveness through a case\nstudy. This paper takes a step further by demonstrating the significance of\nsemantic dependencies, even in cases where there are no direct dependencies\nbetween microservices. It shows that these hidden dependencies can exist\nindependently of endpoint or data dependencies, revealing critical connections\nthat might otherwise be overlooked."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-911",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16864",
    "b_title":[
      "A methodology and a platform for high-quality rich personal data\n  collection"
    ],
    "b_abstract":[
      "In the last years the pervasive use of sensors, as they exist in smart\ndevices, e.g., phones, watches, medical devices, has increased dramatically the\navailability of personal data. However, existing research on data collection\nprimarily focuses on the objective view of reality, as provided, for instance,\nby sensors, often neglecting the integration of subjective human input, as\nprovided, for instance, by user answers to questionnaires. This limits\nsubstantially the exploitability of the collected data. In this paper we\npresent a methodology and a platform specifically designed for the collection\nof a combination of large-scale sensor data and qualitative human feedback. The\nmethodology has been designed to be deployed on top, and enriches the\nfunctionalities of, an existing data collection APP, called iLog, which has\nbeen used in large scale, worldwide data collection experiments. The main goal\nis to put the key actors involved in an experiment, i.e., the researcher in\ncharge, the participant, and iLog in better control of the experiment itself,\nthus enabling a much improved quality and richness of the data collected. The\nnovel functionalities of the resulting platform are: (i) a time-wise\nrepresentation of the situational context within which the data collection is\nperformed, (ii) an explicit representation of the temporal context within which\nthe data collection is performed, (iii) a calendar-based dashboard for the\nreal-time monitoring of the data collection context(s), and, finally, (iv) a\nmechanism for the run-time revision of the data collection plan. The\npracticality and utility of the proposed functionalities are demonstrated by\nshowing how they apply to a case study involving 350 University students."
    ],
    "b_categories":[
      [
        "cs.HC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06985",
    "c_title":[
      "\"It's Great Because It's Ran By Us\": Empowering Teen Volunteer Discord\n  Moderators to Design Healthy and Engaging Youth-Led Online Communities"
    ],
    "c_abstract":[
      "Online communities can offer many benefits for youth including peer learning,\ncultural expression, and skill development. However, most HCI research on\nyouth-focused online communities has centered communities developed by adults\nfor youth rather than by the youth themselves. In this work, we interviewed 11\nteenagers (ages 13-17) who moderate online Discord communities created by\nyouth, for youth. Participants were identified by Discord platform staff as\nleaders of well-moderated servers through an intensive exam and\napplication-based process. We also interviewed 2 young adults who volunteered\nas mentors of some of our teen participants. We present our findings about the\nbenefits, motivations, and risks of teen-led online communities, as well as the\nrole of external stakeholders of these youth spaces. We contextualize our work\nwithin the broader teen online safety landscape to provide recommendations to\nbetter support, encourage, and protect teen moderators and their online\ncommunities. This empirical work contributes one of the first studies to date\nwith teen Discord moderators and aims to empower safe youth-led online\ncommunities."
    ],
    "c_categories":[
      [
        "cs.HC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-912",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.07605",
    "b_title":[
      "Kinetic inductance coupling for circuit QED with spins"
    ],
    "b_abstract":[
      "In contrast to the commonly used qubit resonator transverse coupling via the\n$\\sigma_{xy}$-degree of freedom, longitudinal coupling through $\\sigma_z$\npresents a tantalizing alternative: it does not hybridize the modes,\neliminating Purcell decay, and it enables quantum-non-demolishing qubit readout\nindependent of the qubit-resonator frequency detuning. Here, we demonstrate\nlongitudinal coupling between a {Cr$_7$Ni} molecular spin qubit ensemble and\nthe kinetic inductance of a granular aluminum superconducting microwave\nresonator. The inherent frequency-independence of this coupling allows for the\nutilization of a 7.8 GHz readout resonator to measure the full {Cr$_7$Ni}\nmagnetization curve spanning 0-600 mT, corresponding to a spin frequency range\nof $f_\\text{spin}=$0-15 GHz. For 2 GHz detuning from the readout resonator, we\nmeasure a $1\/e$ spin relaxation time $\\tau=$0.38 s, limited by phonon decay to\nthe substrate. Based on these results, we propose a path towards longitudinal\ncoupling of single spins to a superconducting fluxonium qubit."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10274",
    "c_title":[
      "Genuine Multipartite Nonlocality sharing under sequential measurement"
    ],
    "c_abstract":[
      "The study of quantum nonlocality sharing has garnered significant attention,\nparticularly for two-qubit and three-qubit entangled systems. In this paper, we\nextend the investigation to $n$-qubit Greenberger-Horne-Zeilinger (GHZ)\nsystems, analyzing nonlocality sharing under unbiased unsharp measurements.\nEmploying the Seevink and Svetlichny inequalities, we explore both unilateral\nand multilateral sequential measurement scenarios. In the unilateral scenario,\nwe derive the range for which an observer's multiple copies can share genuine\n$n$-partite nonlocality with single copies of the remaining parties. In the\nmultilateral scenario, we identify the maximum number of independent observers\non $m$ sides who can share genuine $n$-partite nonlocality with other parties.\nA crucial aspect of our results is that all findings stem from a measurement\nstrategy where each sequential observer utilizes unbiased unsharp measurements.\nAs a specific case, for the four-qubit maximally entangled GHZ state, we\ndemonstrate that at most two copies of an observer (e.g., Alice) can share\nnonlocality in the unilateral sequential measurement scenario. However, in the\nmultilateral scenario, no additional sharing is possible compared to the\nunilateral case. This finding highlights the significance of unsharp\nmeasurements in optimizing the recycling of qubits for generating quantum\nnonlocality."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-913",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02725",
    "b_title":[
      "Artificial Intelligence in Creative Industries: Advances Prior to 2025"
    ],
    "b_abstract":[
      "The rapid advancements in artificial intelligence (AI), particularly in\ngenerative AI and large language models (LLMs), have profoundly impacted the\ncreative industries by enabling innovative content creation, enhancing\nworkflows, and democratizing access to creative tools. This paper explores the\nsignificant technological shifts since our previous review in 2022,\nhighlighting how these developments have expanded creative opportunities and\nefficiency. These technological advancements have enhanced the capabilities of\ntext-to-image, text-to-video, and multimodal generation technologies. In\nparticular, key breakthroughs in LLMs have established new benchmarks in\nconversational AI, while advancements in image generators have revolutionized\ncontent creation. We also discuss AI integration into post-production\nworkflows, which has significantly accelerated and refined traditional\nprocesses. Despite these innovations, challenges remain, particularly for the\nmedia industry, due to the demands on communication traffic from creative\ncontent. We therefore include data compression and quality assessment in this\npaper. Furthermore, we highlight the trend toward unified AI frameworks capable\nof addressing multiple creative tasks and underscore the importance of human\noversight to mitigate AI-generated inaccuracies. Finally, we explore AI's\nfuture potential in the creative sector, stressing the need to navigate\nemerging challenges to maximize its benefits while addressing associated risks."
    ],
    "b_categories":[
      [
        "cs.AI"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15655",
    "c_title":[
      "R$^2$: A LLM Based Novel-to-Screenplay Generation Framework with Causal\n  Plot Graphs"
    ],
    "c_abstract":[
      "Automatically adapting novels into screenplays is important for the TV, film,\nor opera industries to promote products with low costs. The strong performances\nof large language models (LLMs) in long-text generation call us to propose a\nLLM based framework Reader-Rewriter (R$^2$) for this task. However, there are\ntwo fundamental challenges here. First, the LLM hallucinations may cause\ninconsistent plot extraction and screenplay generation. Second, the\ncausality-embedded plot lines should be effectively extracted for coherent\nrewriting. Therefore, two corresponding tactics are proposed: 1) A\nhallucination-aware refinement method (HAR) to iteratively discover and\neliminate the affections of hallucinations; and 2) a causal plot-graph\nconstruction method (CPC) based on a greedy cycle-breaking algorithm to\nefficiently construct plot lines with event causalities. Recruiting those\nefficient techniques, R$^2$ utilizes two modules to mimic the human screenplay\nrewriting process: The Reader module adopts a sliding window and CPC to build\nthe causal plot graphs, while the Rewriter module generates first the scene\noutlines based on the graphs and then the screenplays. HAR is integrated into\nboth modules for accurate inferences of LLMs. Experimental results demonstrate\nthe superiority of R$^2$, which substantially outperforms three existing\napproaches (51.3%, 22.6%, and 57.1% absolute increases) in pairwise comparison\nat the overall win rate for GPT-4o."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-914",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09296",
    "b_title":[
      "Causal Spike Timing Dependent Plasticity Prevents Assembly Fusion in\n  Recurrent Networks"
    ],
    "b_abstract":[
      "The organization of neurons into functionally related assemblies is a\nfundamental feature of cortical networks, yet our understanding of how these\nassemblies maintain distinct identities while sharing members remains limited.\nHere we analyze how spike-timing-dependent plasticity (STDP) shapes the\nformation and stability of overlapping neuronal assemblies in recurrently\ncoupled networks of spiking neuron models. Using numerical simulations and an\nassociated mean-field theory, we demonstrate that the temporal structure of the\nSTDP rule, specifically its degree of causality, critically determines whether\nassemblies that share neurons maintain segregation or merge together after\ntraining is completed. We find that causal STDP rules, where\npotentiation\/depression occurs strictly when presynaptic spikes precede\/proceed\npostsynaptic spikes, allow assemblies to remain distinct even with substantial\noverlap in membership. This stability arises because causal STDP effectively\ncancels the symmetric correlations introduced by common inputs from shared\nneurons. In contrast, acausal STDP rules lead to assembly fusion when overlap\nexceeds a critical threshold, due to unchecked growth of common input\ncorrelations. Our results provide theoretical insight into how\nspike-timing-dependent learning rules can support distributed representation\nwhere individual neurons participate in multiple assemblies while maintaining\nfunctional specificity."
    ],
    "b_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2502.21217",
    "c_title":[
      "Dynamic Markov Blanket Detection for Macroscopic Physics Discovery"
    ],
    "c_abstract":[
      "The free energy principle (FEP), along with the associated constructs of\nMarkov blankets and ontological potentials, have recently been presented as the\ncore components of a generalized modeling method capable of mathematically\ndescribing arbitrary objects that persist in random dynamical systems; that is,\na mathematical theory of ``every'' ``thing''. Here, we leverage the FEP to\ndevelop a mathematical physics approach to the identification of objects,\nobject types, and the macroscopic, object-type-specific rules that govern their\nbehavior. We take a generative modeling approach and use variational Bayesian\nexpectation maximization to develop a dynamic Markov blanket detection\nalgorithm that is capable of identifying and classifying macroscopic objects,\ngiven partial observation of microscopic dynamics. This unsupervised algorithm\nuses Bayesian attention to explicitly label observable microscopic elements\naccording to their current role in a given system, as either the internal or\nboundary elements of a given macroscopic object; and it identifies macroscopic\nphysical laws that govern how the object interacts with its environment.\nBecause these labels are dynamic or evolve over time, the algorithm is capable\nof identifying complex objects that travel through fixed media or exchange\nmatter with their environment. This approach leads directly to a flexible class\nof structured, unsupervised algorithms that sensibly partition complex\nmany-particle or many-component systems into collections of interacting\nmacroscopic subsystems, namely, ``objects'' or ``things''. We derive a few\nexamples of this kind of macroscopic physics discovery algorithm and\ndemonstrate its utility with simple numerical experiments, in which the\nalgorithm correctly labels the components of Newton's cradle, a burning fuse,\nthe Lorenz attractor, and a simulated cell."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-915",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.06445",
    "b_title":[
      "Benchmarking Vision-Language Models on Optical Character Recognition in\n  Dynamic Video Environments"
    ],
    "b_abstract":[
      "This paper introduces an open-source benchmark for evaluating Vision-Language\nModels (VLMs) on Optical Character Recognition (OCR) tasks in dynamic video\nenvironments. We present a curated dataset containing 1,477 manually annotated\nframes spanning diverse domains, including code editors, news broadcasts,\nYouTube videos, and advertisements. Three state of the art VLMs - Claude-3,\nGemini-1.5, and GPT-4o are benchmarked against traditional OCR systems such as\nEasyOCR and RapidOCR. Evaluation metrics include Word Error Rate (WER),\nCharacter Error Rate (CER), and Accuracy. Our results highlight the strengths\nand limitations of VLMs in video-based OCR tasks, demonstrating their potential\nto outperform conventional OCR models in many scenarios. However, challenges\nsuch as hallucinations, content security policies, and sensitivity to occluded\nor stylized text remain. The dataset and benchmarking framework are publicly\navailable to foster further research."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.12293",
    "c_title":[
      "Data-Efficient Limited-Angle CT Using Deep Priors and Regularization"
    ],
    "c_abstract":[
      "Reconstructing an image from its Radon transform is a fundamental computed\ntomography (CT) task arising in applications such as X-ray scans. In many\npractical scenarios, a full 180-degree scan is not feasible, or there is a\ndesire to reduce radiation exposure. In these limited-angle settings, the\nproblem becomes ill-posed, and methods designed for full-view data often leave\nsignificant artifacts. We propose a very low-data approach to reconstruct the\noriginal image from its Radon transform under severe angle limitations. Because\nthe inverse problem is ill-posed, we combine multiple regularization methods,\nincluding Total Variation, a sinogram filter, Deep Image Prior, and a\npatch-level autoencoder. We use a differentiable implementation of the Radon\ntransform, which allows us to use gradient-based techniques to solve the\ninverse problem. Our method is evaluated on a dataset from the Helsinki\nTomography Challenge 2022, where the goal is to reconstruct a binary disk from\nits limited-angle sinogram. We only use a total of 12 data points--eight for\nlearning a prior and four for hyperparameter selection--and achieve results\ncomparable to the best synthetic data-driven approaches."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-916",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04384",
    "b_title":[
      "On the geodesics of the Szeg\\\"o metric"
    ],
    "b_abstract":[
      "We explore the existence of closed geodesics and geodesic spirals for the\nSzeg\\\"o metric in a $C^{\\infty}$-smoothly bounded strongly pseudoconvex domain\n$\\Omega\\subset\\mathbb{C}^n$, which is not simply connected for $n \\geq 2$."
    ],
    "b_categories":[
      [
        "math.CV"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.02898",
    "c_title":[
      "Results on Logarithmic Coefficients for the Class of Bounded Turning\n  Functions"
    ],
    "c_abstract":[
      "It is crucial to explore the sharp bounds of logarithmic coefficients and the\nHankel determinant involving logarithmic coefficients as part of coefficient\nproblems in various function classes. Our primary objective in this study is to\ndetermine the sharp bounds for logarithmic coefficients as well as logarithmic\ninverse coefficients of bounded analytic functions associated with a\nbean-shaped domain in the class $\\mathcal{BT_\\mathfrak{B}}$. For this class, we\nalso establish the sharp bounds for the second Hankel determinant involving\nlogarithmic coefficients as well as logarithmic inverse coefficients. In\naddition, we establish sharp bounds for the generalized Zalcman conjecture\ninequality and the moduli differences of logarithmic coefficients for the class\n$\\mathcal{BT_\\mathfrak{B}}$."
    ],
    "c_categories":[
      [
        "math.CV"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-917",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13882",
    "b_title":[
      "Grain-size dependence of plastic-brittle transgranular fracture"
    ],
    "b_abstract":[
      "The role of grain size in determining fracture toughness in metals is\nincompletely understood with apparently contradictory experimental\nobservations. We study this grain-size dependence computationally by building a\nmodel that combines the phase-field formulation of fracture mechanics with\ndislocation density-based crystal plasticity. We apply the model to cleavage\nfracture of body-centered cubic materials in plane strain conditions, and find\nnon-monotonic grain-size dependence of plastic-brittle transgranular fracture.\nWe find two mechanisms at play. The first is the nucleation of failure due to\ncross-slip in critically located grains within transgranular band of localized\ndeformation, and this follows the classical Hall-Petch law that predicts a\nhigher failure stress for smaller grains. The second is the resistance to the\npropagation of a mode I crack, where grain boundaries can potentially pin a\ncrack, and this follows an inverse Hall-Petch law with higher toughness for\nlarger grains. The result of the competition between the two mechanisms gives\nrise to non-monotonic behavior and reconciles the apparently contradictory\nexperimental observations."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.11728",
    "c_title":[
      "Double-tough ceramics: Optimization-supported multiscale computational\n  design"
    ],
    "c_abstract":[
      "To overcome the brittleness limitation of ceramics, various toughening\nmechanisms have been proposed. Some of the most remarkable, especially for\noxides, include the tetragonal-to-monoclinic phase transformation leading to\ncrack shielding in zirconia, and bioinspired brick-and-mortar microstructures\nfostering crack deflection. It has, however, proven challenging to incorporate\nboth these mechanisms into a single all-ceramic material. In this work, we\npropose a computational methodology for the design of a material that combines\nthese two toughening strategies, using a multiscale modeling approach that\ncaptures both their individual contributions and the overall fracture\nperformance. This is achieved by developing an all-ceramic composite with a\nbrick-and-mortar microstructure, in which the nanocrystalline mortar is\ntransformation-toughened. Key factors influencing phase transformation, such as\ngrain boundary properties, grain orientations, and kinetic coefficients, are\nanalyzed, and the resulting transformation stress-strain behavior is\nincorporated into the microscale mortar constitutive model. We demonstrate that\nthe synergistic effect of the two toughening mechanisms is achievable, and that\nit is an extremely effective strategy to boost fracture performance. The\ninfluence of brick size, mortar thickness, and properties of the constituent\nmaterials is then systematically investigated. Finally, a gradient-free\noptimization algorithm is employed to identify optimal geometric and material\nparameters, revealing that longer, thinner bricks with minimal mortar thickness\nprovide the best fracture resistance. Optimal combinations of material\nproperties are identified for given brick sizes and mortar thicknesses."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-918",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.14899",
    "b_title":[
      "Speed Optimization Algorithm based on Deterministic Markov Decision\n  Process for Automated Highway Merge"
    ],
    "b_abstract":[
      "This study presents a robust optimization algorithm for automated highway\nmerge. The merging scenario is one of the challenging scenes in automated\ndriving, because it requires adjusting ego vehicle's speed to match other\nvehicles before reaching the end point. Then, we model the speed planning\nproblem as a deterministic Markov decision process. The proposed scheme is able\nto compute each state value of the process and reliably derive the optimal\nsequence of actions. In our approach, we adopt jerk as the action of the\nprocess to prevent a sudden change of acceleration. However, since this expands\nthe state space, we also consider ways to achieve a real-time operation. We\ncompared our scheme with a simple algorithm with the Intelligent Driver Model.\nWe not only evaluated the scheme in a simulation environment but also conduct a\nreal world testing."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17221",
    "c_title":[
      "A Reinforcement Learning Approach to Non-prehensile Manipulation through\n  Sliding"
    ],
    "c_abstract":[
      "Although robotic applications increasingly demand versatile and dynamic\nobject handling, most existing techniques are predominantly focused on\ngrasp-based manipulation, limiting their applicability in non-prehensile tasks.\nTo address this need, this study introduces a Deep Deterministic Policy\nGradient (DDPG) reinforcement learning framework for efficient non-prehensile\nmanipulation, specifically for sliding an object on a surface. The algorithm\ngenerates a linear trajectory by precisely controlling the acceleration of a\nrobotic arm rigidly coupled to the horizontal surface, enabling the relative\nmanipulation of an object as it slides on top of the surface. Furthermore, two\ndistinct algorithms have been developed to estimate the frictional forces\ndynamically during the sliding process. These algorithms provide online\nfriction estimates after each action, which are fed back into the actor model\nas critical feedback after each action. This feedback mechanism enhances the\npolicy's adaptability and robustness, ensuring more precise control of the\nplatform's acceleration in response to varying surface condition. The proposed\nalgorithm is validated through simulations and real-world experiments. Results\ndemonstrate that the proposed framework effectively generalizes sliding\nmanipulation across varying distances and, more importantly, adapts to\ndifferent surfaces with diverse frictional properties. Notably, the trained\nmodel exhibits zero-shot sim-to-real transfer capabilities."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-919",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.18135",
    "b_title":[
      "Single-Source Localization as an Eigenvalue Problem"
    ],
    "b_abstract":[
      "This paper introduces a novel method for solving the single-source\nlocalization problem, specifically addressing the case of trilateration. We\nformulate the problem as a weighted least-squares problem in the squared\ndistances and demonstrate how suitable weights are chosen to accommodate\ndifferent noise distributions. By transforming this formulation into an\neigenvalue problem, we leverage existing eigensolvers to achieve a fast,\nnumerically stable, and easily implemented solver. Furthermore, our theoretical\nanalysis establishes that the globally optimal solution corresponds to the\nlargest real eigenvalue, drawing parallels to the existing literature on the\ntrust-region subproblem. Unlike previous works, we give special treatment to\ndegenerate cases, where multiple and possibly infinitely many solutions exist.\nWe provide a geometric interpretation of the solution sets and design the\nproposed method to handle these cases gracefully. Finally, we validate against\na range of state-of-the-art methods using synthetic and real data,\ndemonstrating how the proposed method is among the fastest and most numerically\nstable."
    ],
    "b_categories":[
      [
        "math.OC"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.17645",
    "c_title":[
      "A modified Bellman-Ford Algorithm for Application in Symbolic Optimal\n  Control and Plan and Goal Recognition"
    ],
    "c_abstract":[
      "The contributions of this short technical note are two-fold. Firstly, we\nintroduce a modified version of a generalized Bellman-Ford algorithm\ncalculating the value function of optimal control problems defined on\nhyper-graphs. Those Bellman-Ford algorithms can be used in particular for the\nsynthesis of near-optimal controllers by the principle of symbolic control. Our\nmodification causes less nodes of the hyper-graph being iterated during the\nexecution compared to our initial version of the algorithm published in 2020.\nOur second contribution lies in the field of Plan recognition applied to drone\nmissions driven by symbolic controllers. We address and resolve the Plan and\nGoal Recognition monitor's dependence on a pre-defined initial guess for a\ndrone's task allocation and mission execution. To validate the enhanced\nimplementation, we use a more challenging scenario for UAV-based aerial\nfirefighting, demonstrating the practical applicability and robustness of the\nsystem architecture."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-920",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.03985",
    "b_title":[
      "Exploring the evolution of a dwarf spheroidal galaxy with SPH\n  simulations: II. AGN feedback"
    ],
    "b_abstract":[
      "We investigate AGN feedback from an intermediate-mass black hole at the\ncenter of a dwarf spheroidal galaxy, by performing isolated galaxy simulations\nusing a modified version of the GADGET-3 code. We consider Leo II (PGC 34176)\nin the Local Group as our simulation reference model. Beginning with black hole\nseeds ranging from $10^3$ to $10^6$ M$_{\\odot}$, our simulations focus on\ncomparing stellar-only feedback with AGN+stellar\/SN feedback over 13.7 Gyr of\ngalactic evolution. Our results indicate that a low-mass AGN in a dwarf galaxy\ninfluences the star formation history under specific physical conditions. While\nAGN feedback is generally negative on star formation, instances of positive\nfeedback were also identified. Despite measurable effects on the evolution of\nthe dwarf host galaxy, black hole seeds exhibited only marginal growth. We\ntested several physical scenarios as modified models in our simulations,\nprimarily concerning the dynamics of the central black holes, which may wander\nwithin dwarf galaxies rather than being centrally located. However, none of\nthese adjustments significantly impacted the growth of the black hole seeds.\nThis suggests that intermediate-mass black holes may struggle to achieve higher\nmasses in isolated environments, with mergers and interactions likely playing\ncrucial roles in their growth. Nevertheless, AGN feedback exhibited\nnon-negligible effects in our simulated dwarf spheroidal galaxies, despite the\nassumed dominant role of stellar feedback in the low-mass regime."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03547",
    "c_title":[
      "Exploring the physical properties of Type II Quasar candidates at\n  intermediate redshifts with CIGALE"
    ],
    "c_abstract":[
      "Active Galactic Nuclei (AGN) significantly influence galaxy evolution.\nSpecific sources such as obscured AGNs, especially Type II quasars (QSO2),\nstill remain understudied. We characterise 366 QSO2 candidates in the redshift\ndesert (median z~1.1) identified via machine learning from SDSS\/WISE\nphotometry, analysing their spectral energy distributions (SEDs) and deriving\ntheir physical properties. Using CIGALE, we estimated star formation rate\n(SFR), stellar mass (M), AGN luminosity, and AGN fraction. We compared these\nwith SPRITZ simulations and the literature, placing results in the galaxy\nevolution context. Our QSO2 candidates show diverse evolutionary stages. The\nSFR-M diagram reveals high-SFR sources above the main sequence, linking AGN\nactivity to enhanced star formation. Quenched galaxies may indicate obscured\nstar formation or AGN feedback. Additionally, the physical properties align\nwith SPRITZ composite systems and AGN2, endorsing our obscured AGN\nclassification. This study validates machine learning for identifying AGN-host\ngalaxies, beyond traditional colour-colour selections. Diverse candidate\nproperties highlight this method's ability to identify complex AGN systems.\nThis advances our understanding of AGN-driven galaxy evolution with new target\nselection."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-921",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06556",
    "b_title":[
      "The Orbital Angular Momentum of Azimuthal Spin-Waves"
    ],
    "b_abstract":[
      "In the context of a growing interdisciplinary interest in the angular\nmomentum of wave fields, the spin-wave case has yet to be fully explored, with\nthe extensively studied notion of spin transport being only part of the broader\npicture. Here we report experimental evidence for magnon orbital angular\nmomentum, demonstrating that the mode exhibits rotation rather than remaining\nstationary. This conclusion is drawn from observations of the lifted degeneracy\nof waves with counter-rotating wave fronts. This requires an unambiguous\nformulation of spin and orbital angular momenta for spin waves, which we\nprovide in full generality based on a systematic application of quantum field\ntheory techniques. The results unequivocally establish magnetic dipole-dipole\ninteractions as a magnetic-field controllable spin-orbit interaction for\nmagnons. Our findings open a new research direction, leveraging the\nspectroscopic readability of angular momentum for azimuthal spin waves and\nother related systems."
    ],
    "b_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.18765",
    "c_title":[
      "Pseudo-Hermitian physics from dynamically coupled macrospins"
    ],
    "c_abstract":[
      "We consider two classical macrospins with dynamical (frequency-dependent)\ncoupling, modeled by a generalized Landau-Lifshitz-Gilbert equation. We show\nthat, in the absence of local damping, the resulting dynamics are\npseudo-Hermitian. When two precessional modes hybridize near a crossing, the\nspectral behavior takes the form either of an anticrossing or level attraction,\nwith the latter formalized in terms of spontaneous $\\mathcal{PT}$-symmetry\nbreaking. Near equilibrium, mixing due to nondissipative interactions results\nin repulsion, while dissipative mixing results in attraction. In contrast, when\nthe fluctuating degrees of freedom form a free-energy saddle point, we find\nthat nondissipative interactions result in level attraction, while dissipative\ninteractions produce level repulsion. Accounting for the effects of local\nGilbert damping, we examine the cases in which approximate\n$\\mathcal{PT}$-symmetry breaking is still possible and determine the degree to\nwhich the qualitative spectral properties still persist."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-922",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.00653",
    "b_title":[
      "Towards Robust Multimodal Large Language Models Against Jailbreak\n  Attacks"
    ],
    "b_abstract":[
      "While multimodal large language models (MLLMs) have achieved remarkable\nsuccess in recent advancements, their susceptibility to jailbreak attacks has\ncome to light. In such attacks, adversaries exploit carefully crafted prompts\nto coerce models into generating harmful or undesirable content. Existing\ndefense mechanisms often rely on external inference steps or safety alignment\ntraining, both of which are less effective and impractical when facing\nsophisticated adversarial perturbations in white-box scenarios. To address\nthese challenges and bolster MLLM robustness, we introduce SafeMLLM by adopting\nan adversarial training framework that alternates between an attack step for\ngenerating adversarial noise and a model updating step. At the attack step,\nSafeMLLM generates adversarial perturbations through a newly proposed\ncontrastive embedding attack (CoE-Attack), which optimizes token embeddings\nunder a contrastive objective. SafeMLLM then updates model parameters to\nneutralize the perturbation effects while preserving model utility on benign\ninputs. We evaluate SafeMLLM across six MLLMs and six jailbreak methods\nspanning multiple modalities. Experimental results show that SafeMLLM\neffectively defends against diverse attacks, maintaining robust performance and\nutilities."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16023",
    "c_title":[
      "BadToken: Token-level Backdoor Attacks to Multi-modal Large Language\n  Models"
    ],
    "c_abstract":[
      "Multi-modal large language models (MLLMs) extend large language models (LLMs)\nto process multi-modal information, enabling them to generate responses to\nimage-text inputs. MLLMs have been incorporated into diverse multi-modal\napplications, such as autonomous driving and medical diagnosis, via\nplug-and-play without fine-tuning. This deployment paradigm increases the\nvulnerability of MLLMs to backdoor attacks. However, existing backdoor attacks\nagainst MLLMs achieve limited effectiveness and stealthiness. In this work, we\npropose BadToken, the first token-level backdoor attack to MLLMs. BadToken\nintroduces two novel backdoor behaviors: Token-substitution and Token-addition,\nwhich enable flexible and stealthy attacks by making token-level modifications\nto the original output for backdoored inputs. We formulate a general\noptimization problem that considers the two backdoor behaviors to maximize the\nattack effectiveness. We evaluate BadToken on two open-source MLLMs and various\ntasks. Our results show that our attack maintains the model's utility while\nachieving high attack success rates and stealthiness. We also show the\nreal-world threats of BadToken in two scenarios, i.e., autonomous driving and\nmedical diagnosis. Furthermore, we consider defenses including fine-tuning and\ninput purification. Our results highlight the threat of our attack."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-923",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06894",
    "b_title":[
      "Analyzing the Evolution and Maintenance of Quantum Computing\n  Repositories"
    ],
    "b_abstract":[
      "Quantum computing is an emerging field with significant potential, yet\nsoftware development and maintenance challenges limit its accessibility and\nmaturity. This work investigates the current state, evolution, and maintenance\npractices in the quantum computing community by conducting a large-scale mining\nanalysis of over 21,000 quantum software repositories on GitHub, containing\nmore than 1.2 million commits contributed by over 10,000 unique developers.\nSpecifically, the focus of this paper is to: (i) assess the community's status\nand growth by examining the popularity of quantum computing, trends in\nprogramming languages and framework usage, growth of contributors, and insights\nfrom repository documentation; and (ii) analyze maintenance practices through\ncommit patterns, issue classification, and maintenance levels. Our findings\nindicate rapid growth in the quantum computing community, with a 200% increase\nin the number of repositories and a 150% rise in contributors since 2017. Our\nanalysis of commits shows a strong focus on perfective updates, while the\nrelatively low number of corrective commits highlights potential gaps in bug\nresolution. Furthermore, one-third of the quantum computing issues highlight\nthe need for specialized tools in addition to general software infrastructure.\nIn summary, this work provides a foundation for targeted improvements in\nquantum software to support sustained growth and technical advancement. Based\non our analysis of development activity, community structure, and maintenance\npractices, this study offers actionable recommendations to enhance quantum\nprogramming tools, documentation, and resources. We are also open-sourcing our\ndataset to support further analysis by the community and to guide future\nresearch and tool development for quantum computing."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.07204",
    "c_title":[
      "Containers as the Quantum Leap in Software Development"
    ],
    "c_abstract":[
      "The goal of the project QLEAP (2022-24), funded by Business Finland and\nparticipating organizations, was to study using containers as elements of\narchitecture design. Such systems include containerized AI systems, using\ncontainers in a hybrid setup (public\/hybrid\/private clouds), and related\nsecurity concerns. The consortium consists of four companies that represent\ndifferent concerns over using containers (Bittium, M-Files, Solita\/ADE\nInsights, Vaadin) and one research organization (University of Jyv\\\"askyl\\\"a).\nIn addition, it has received support from two Veturi companies - Nokia and\nTietoevry - who have also participated in steering the project. Moreover, the\nSW4E ecosystem has participated in the project. This document gathers the key\nlessons learned from the project."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-924",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15246",
    "b_title":[
      "End-to-end localized deep learning for Cryo-ET"
    ],
    "b_abstract":[
      "Cryo-electron tomography (cryo-ET) enables 3D visualization of cellular\nenvironments. Accurate reconstruction of high-resolution volumes is complicated\nby the very low signal-to-noise ratio and a restricted range of sample tilts,\ncreating a missing wedge of Fourier information. Recent self-supervised deep\nlearning approaches, which post-process initial reconstructions done by\nfiltered backprojection (FBP), have significantly improved reconstruction\nquality, but they are computationally expensive, demand large memory, and\nrequire retraining for each new dataset. End-to-end supervised learning is an\nappealing alternative but is impeded by the lack of ground truth and the large\nmemory demands of high-resolution volumetric data. Training on synthetic data\noften leads to overfitting and poor generalization to real data, and, to date,\nno general end-to-end deep learning reconstructors exist for cryo-ET. In this\nwork, we introduce CryoLithe, a local, memory-efficient reconstruction network\nthat directly estimates the volume from an aligned tilt-series, overcoming the\nsuboptimal FBP. We demonstrate that leveraging transform-domain locality makes\nour network robust to distribution shifts, enabling effective supervised\ntraining and giving excellent results on real data -- without retraining or\nfine-tuning."
    ],
    "b_categories":[
      [
        "eess.IV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.15212",
    "c_title":[
      "Context-Aware Vision Language Foundation Models for Ocular Disease\n  Screening in Retinal Images"
    ],
    "c_abstract":[
      "Foundation models are large-scale versatile systems trained on vast\nquantities of diverse data to learn generalizable representations. Their\nadaptability with minimal fine-tuning makes them particularly promising for\nmedical imaging, where data variability and domain shifts are major challenges.\nCurrently, two types of foundation models dominate the literature:\nself-supervised models and more recent vision-language models. In this study,\nwe advance the application of vision-language foundation (VLF) models for\nocular disease screening using the OPHDIAT dataset, which includes nearly\n700,000 fundus photographs from a French diabetic retinopathy (DR) screening\nnetwork. This dataset provides extensive clinical data (patient-specific\ninformation such as diabetic health conditions, and treatments), labeled\ndiagnostics, ophthalmologists text-based findings, and multiple retinal images\nfor each examination. Building on the FLAIR model $\\unicode{x2013}$ a VLF model\nfor retinal pathology classification $\\unicode{x2013}$ we propose novel\ncontext-aware VLF models (e.g jointly analyzing multiple images from the same\nvisit or taking advantage of past diagnoses and contextual data) to fully\nleverage the richness of the OPHDIAT dataset and enhance robustness to domain\nshifts. Our approaches were evaluated on both in-domain (a testing subset of\nOPHDIAT) and out-of-domain data (public datasets) to assess their\ngeneralization performance. Our model demonstrated improved in-domain\nperformance for DR grading, achieving an area under the curve (AUC) ranging\nfrom 0.851 to 0.9999, and generalized well to ocular disease detection on\nout-of-domain data (AUC: 0.631-0.913)."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-925",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18200",
    "b_title":[
      "Characterization of Permanent Magnet Synchronous Machines based on\n  semi-analytic model reduction for drive cycle analysis"
    ],
    "b_abstract":[
      "The characterization of an interior permanent magnet synchronous machine\n(IPMSM) requires numerical analysis of the nonlinear magnetic motor model in\ndifferent load conditions. To obtain the case-specific best machine behavior, a\nstrategy for the determination of stator input current amplitude and angle is\nemployed for all possible load torques given a limited terminal current\namplitude and DC bus voltage. Various losses are calculated using state of the\nart loss models. The electromagnetic performance of the electric machine is\nstored in lookup tables. These can then be used for the drive cycle analysis of\nthe electric drive train in the design and optimization stages.\n  To avoid the use of a dedicated mesh generator in the numerical analysis,\nvolumetric spline-based models are suggested.With this approach, the mesh can\nbe generated directly from the Computer Aided Design (CAD) geometry. This\nenables an automatic adaption of the grid following a geometry perturbation.\nWith this the approximated solution is kept consistent over the different\niterations of an overlying optimization, improving its convergence behavior."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.12350",
    "c_title":[
      "Mamute: high-performance computing for geophysical methods"
    ],
    "c_abstract":[
      "Due to their high computational cost, geophysical applications are typically\ndesigned to run in large computing systems. Because of that, such applications\nmust implement several high-performance techniques to use the computational\nresources better. In this paper, we present Mamute, a software that delivers\nwave equation-based geophysical methods. Mamute implements two geophysical\nmethods: seismic modeling and full waveform inversion (FWI). It also supports\nhigh-performance strategies such as fault tolerance, automatic parallel looping\nscheduling, and distributed systems workload balancing. We demonstrate Mamute's\noperation using both seismic modeling and FWI. Mamute is a C++ software readily\navailable under the MIT license."
    ],
    "c_categories":[
      [
        "cs.CE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-926",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13658",
    "b_title":[
      "What Skills Do Cyber Security Professionals Need?"
    ],
    "b_abstract":[
      "Purpose: The increasing number of cyber-attacks has elevated the importance\nof cybersecurity for organizations. This has also increased the demand for\nprofessionals with the necessary skills to protect these organizations. As a\nresult, many individuals are looking to enter the field of cybersecurity.\nHowever, there is a lack of clear understanding of the skills required for a\nsuccessful career in this field. In this paper, we identify the skills required\nfor cybersecurity professionals. We also determine how the demand for cyber\nskills relates to various cyber roles such as security analyst and security\narchitect. Furthermore, we identify the programming languages that are\nimportant for cybersecurity professionals. Design\/Methodology: For this study,\nwe have collected and analyzed data from 12,161 job ads and 49,002 Stack\nOverflow posts. By examining this, we identified patterns and trends related to\nskill requirements, role-specific demands, and programming languages in\ncybersecurity. Findings: Our results reveal that (i) communication skills and\nproject management skills are the most important soft skills, (ii) as compared\nto soft skills, the demand for technical skills varies more across various\ncyber roles, and (iii) Java is the most commonly used programming language.\nOriginality: Our findings serve as a guideline for individuals aiming to get\ninto the field of cybersecurity. Moreover, our findings are useful in terms of\ninforming educational institutes to teach the correct set of skills to students\ndoing degrees in cybersecurity."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.18631",
    "c_title":[
      "XTS mode revisited: high hopes for key scopes?"
    ],
    "c_abstract":[
      "This paper concisely summarizes the XTS block encryption mode for storage\nsector-based encryption applications and clarifies its limitations. In\nparticular, we aim to provide a unified basis for much needed discussions about\nthe newly proposed key scope change to the IEEE 1619 standard."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-927",
    "date":"",
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13661",
    "b_title":[
      "Long-term follow-up of DYT1 dystonia patients treated by deep brain\n  stimulation: an open-label study"
    ],
    "b_abstract":[
      "Long-term efficacy of internal globus pallidus (GPi) deep-brain stimulation\n(DBS) in DYT1 dystonia and disease progression under DBS was studied.\nTwenty-six patients of this open-label study were divided into two groups: (A)\nwith single bilateral GPi lead, (B) with a second bilateral GPi lead implanted\nowning to subsequent worsening of symptomatology. Dystonia was assessed with\nthe Burke Scale. Appearance of new symptoms and distribution according to body\nregion were recorded. In the whole cohort, significant decreases in motor and\ndisability subscores (P < 0.0001) were observed at 1 year and maintained up to\n10 years. Group B showed worsening of the symptoms. At 1 year, there were no\nsignificant differences between Groups A (without subsequent worsening) and B;\nat 5 years, a significant difference was found for motor and disability scores.\nWithin Group B, four patients exhibited additional improvement after the second\nDBS surgery. In the 26 patients, significant difference (P = 0.001) was found\nbetween the number of body regions affected by dystonia preoperatively and over\nthe whole follow-up. DBS efficacy in DYT1 dystonia can be maintained up to 10\nyears (two patients). New symptoms appear with long-term follow-up and may\nimprove with additional leads in a subgroup of patients."
    ],
    "b_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "b_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "c_id":"2501.09296",
    "c_title":[
      "Causal Spike Timing Dependent Plasticity Prevents Assembly Fusion in\n  Recurrent Networks"
    ],
    "c_abstract":[
      "The organization of neurons into functionally related assemblies is a\nfundamental feature of cortical networks, yet our understanding of how these\nassemblies maintain distinct identities while sharing members remains limited.\nHere we analyze how spike-timing-dependent plasticity (STDP) shapes the\nformation and stability of overlapping neuronal assemblies in recurrently\ncoupled networks of spiking neuron models. Using numerical simulations and an\nassociated mean-field theory, we demonstrate that the temporal structure of the\nSTDP rule, specifically its degree of causality, critically determines whether\nassemblies that share neurons maintain segregation or merge together after\ntraining is completed. We find that causal STDP rules, where\npotentiation\/depression occurs strictly when presynaptic spikes precede\/proceed\npostsynaptic spikes, allow assemblies to remain distinct even with substantial\noverlap in membership. This stability arises because causal STDP effectively\ncancels the symmetric correlations introduced by common inputs from shared\nneurons. In contrast, acausal STDP rules lead to assembly fusion when overlap\nexceeds a critical threshold, due to unchecked growth of common input\ncorrelations. Our results provide theoretical insight into how\nspike-timing-dependent learning rules can support distributed representation\nwhere individual neurons participate in multiple assemblies while maintaining\nfunctional specificity."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      [
        "Quantitative Biology"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-928",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17220",
    "b_title":[
      "InfraFix: Technology-Agnostic Repair of Infrastructure as Code"
    ],
    "b_abstract":[
      "Infrastructure as Code (IaC) enables scalable and automated IT infrastructure\nmanagement but is prone to errors that can lead to security vulnerabilities,\noutages, and data loss. While prior research has focused on detecting IaC\nissues, Automated Program Repair (APR) remains underexplored, largely due to\nthe lack of suitable specifications. In this work, we propose InfraFix, the\nfirst technology-agnostic framework for repairing IaC scripts. Unlike prior\napproaches, InfraFix allows APR techniques to be guided by diverse information\nsources.\n  Additionally, we introduce a novel approach for generating repair scenarios,\nenabling large-scale evaluation of APR techniques for IaC. We implement and\nevaluate InfraFix using an SMT-based repair module and a state inference module\nthat uses system calls, demonstrating its effectiveness across 254,755 repair\nscenarios with a success rate of 95.5%. Our work provides a foundation for\nadvancing APR in IaC by enabling researchers to experiment with new state\ninference and repair techniques using InfraFix and to evaluate their approaches\nat scale with our repair scenario generation method."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.06459",
    "c_title":[
      "Enhancing The Open Network: Definition and Automated Detection of Smart\n  Contract Defects"
    ],
    "c_abstract":[
      "The Open Network (TON), designed to support Telegram's extensive user base of\nhundreds of millions, has garnered considerable attention since its launch in\n2022. FunC is the most popular programming language for writing smart contracts\non TON. It is distinguished by a unique syntax compared to other smart contract\nlanguages. Despite growing interest, research on the practical defects of TON\nsmart contracts is still in its early stages. In this paper, we summarize eight\nsmart contract defects identified from TON's official blogs and audit reports,\neach with detailed definitions and code examples. Furthermore, we propose a\nstatic analysis framework called TONScanner to facilitate the detection of\nthese defects. Specifically, TONScanner reuses FunC compiler's frontend code to\ntransform the FunC source code into FunC intermediate representation (IR) in\nthe form of a directed acyclic graph (DAG). Based on this IR, TONScanner\nconstructs a control flow graph (CFG), then transforms it into a static single\nassignment (SSA) form to simplify further analysis. TONScanner also integrates\nData Dependency, Call Graph, Taint Analysis, and Cell Construct, which are\nspecifically tailored for TON blockchain's unique data structures. These\ncomponents finally facilitate the identification of the eight defects. We\nevaluate the effectiveness of TONScanner by applying it to 1,640 smart\ncontracts and find a total of 14,995 defects. Through random sampling and\nmanual labeling, we find that TONScanner achieves an overall precision of\n97.49%. The results reveal that current TON contracts contain numerous defects,\nindicating that developers are prone to making errors. TONScanner has proven\nits ability to accurately identify these defects, thereby aiding in their\ncorrection."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-929",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04983",
    "b_title":[
      "Leveraging Large Language Models For Scalable Vector Graphics\n  Processing: A Review"
    ],
    "b_abstract":[
      "In recent years, rapid advances in computer vision have significantly\nimproved the processing and generation of raster images. However, vector\ngraphics, which is essential in digital design, due to its scalability and ease\nof editing, have been relatively understudied. Traditional vectorization\ntechniques, which are often used in vector generation, suffer from long\nprocessing times and excessive output complexity, limiting their usability in\npractical applications. The advent of large language models (LLMs) has opened\nnew possibilities for the generation, editing, and analysis of vector graphics,\nparticularly in the SVG format, which is inherently text-based and well-suited\nfor integration with LLMs.\n  This paper provides a systematic review of existing LLM-based approaches for\nSVG processing, categorizing them into three main tasks: generation, editing,\nand understanding. We observe notable models such as IconShop, StrokeNUWA, and\nStarVector, highlighting their strengths and limitations. Furthermore, we\nanalyze benchmark datasets designed for assessing SVG-related tasks, including\nSVGEditBench, VGBench, and SGP-Bench, and conduct a series of experiments to\nevaluate various LLMs in these domains. Our results demonstrate that for vector\ngraphics reasoning-enhanced models outperform standard LLMs, particularly in\ngeneration and understanding tasks. Furthermore, our findings underscore the\nneed to develop more diverse and richly annotated datasets to further improve\nLLM capabilities in vector graphics tasks."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.17850",
    "c_title":[
      "A Novel Retinial Image Contrast Enhancement -- Fuzzy-Based Method"
    ],
    "c_abstract":[
      "The vascular structure in retinal images plays a crucial role in ophthalmic\ndiagnostics, and its accuracies are directly influenced by the quality of the\nretinal image. Contrast enhancement is one of the crucial steps in any\nsegmentation algorithm - the more so since the retinal images are related to\nmedical diagnosis. Contrast enhancement is a vital step that not only\nintensifies the darkness of the blood vessels but also prevents minor\ncapillaries from being disregarded during the process. This paper proposes a\nnovel model that utilizes the linear blending of Fuzzy Contrast Enhancement\n(FCE) and Contrast Limited Adaptive Histogram Equalization (CLAHE) to enhance\nthe retinal image for retinal vascular structure segmentation. The scheme is\ntested using the Digital Retinal Images for Vessel Extraction (DRIVE) dataset.\nThe assertion was then evaluated through performance comparison among other\nmethodologies which are Gray-scaling, Histogram Equalization (HE), FCE, and\nCLAHE. It was evident in this paper that the combination of FCE and CLAHE\nmethods showed major improvement. Both FCE and CLAHE methods dominating with\n88% as better enhancement methods proved that preprocessing through fuzzy logic\nis effective."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-930",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18668",
    "b_title":[
      "Geometric Preference Elicitation for Minimax Regret Optimization in\n  Uncertainty Matroids"
    ],
    "b_abstract":[
      "This paper presents an efficient preference elicitation framework for\nuncertain matroid optimization, where precise weight information is\nunavailable, but insights into possible weight values are accessible. The core\ninnovation of our approach lies in its ability to systematically elicit user\npreferences, aligning the optimization process more closely with\ndecision-makers' objectives. By incrementally querying preferences between\npairs of elements, we iteratively refine the parametric uncertainty regions,\nleveraging the structural properties of matroids. Our method aims to achieve\nthe exact optimum by reducing regret with a few elicitation rounds.\nAdditionally, our approach avoids the computation of Minimax Regret and the use\nof Linear programming solvers at every iteration, unlike previous methods.\nExperimental results on four standard matroids demonstrate that our method\nreaches optimality more quickly and with fewer preference queries than existing\ntechniques."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.02668",
    "c_title":[
      "Recovering Imbalanced Clusters via Gradient-Based Projection Pursuit"
    ],
    "c_abstract":[
      "Projection Pursuit is a classic exploratory technique for finding interesting\nprojections of a dataset. We propose a method for recovering projections\ncontaining either Imbalanced Clusters or a Bernoulli-Rademacher distribution\nusing a gradient-based technique to optimize the projection index. As sample\ncomplexity is a major limiting factor in Projection Pursuit, we analyze our\nalgorithm's sample complexity within a Planted Vector setting where we can\nobserve that Imbalanced Clusters can be recovered more easily than balanced\nones. Additionally, we give a generalized result that works for a variety of\ndata distributions and projection indices. We compare these results to\ncomputational lower bounds in the Low-Degree-Polynomial Framework. Finally, we\nexperimentally evaluate our method's applicability to real-world data using\nFashionMNIST and the Human Activity Recognition Dataset, where our algorithm\noutperforms others when only a few samples are available."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-931",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.00996",
    "b_title":[
      "Pure Shape Dynamics: Relational General Relativity"
    ],
    "b_abstract":[
      "We present a Pure Shape Dynamics (PSD) formulation of General Relativity\n(GR), which implements full relationalism by eliminating absolute scale and\nexternal time references from the fundamental description of gravity. Starting\nfrom the Arnowitt-Deser-Misner (ADM) formulation, we derive a decoupled\ndynamical system that governs the evolution of the spatial conformal geometry\nand relational matter degrees of freedom, while eliminating the total volume\nand York time as independent dynamical variables. This results in an autonomous\nsubsystem describing an unparametrized trajectory in the conformal superspace\nof metric and matter configurations, with its evolution encoded in an equation\nof state that characterises the intrinsic geometric properties of the curve in\nshape space. We show that this equation of state is structurally analogous to\nthe corresponding PSD description of the Newtonian $N$-body problem,\nreinforcing the fundamental similarity between gravity and relational particle\ndynamics. Our framework is applied to the homogeneous Bianchi IX cosmological\nmodel, demonstrating that the Janus point evolution through the Big Bang, as\npreviously found in a symmetry-reduced setting, is a generic feature of the\nfull inhomogeneous PSD description. This work establishes PSD as a fully scale-\nand reparametrization-invariant formulation of classical gravity and lays the\nfoundation for addressing key open questions that are discussed at the end of\nthe paper."
    ],
    "b_categories":[
      [
        "gr-qc"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.15995",
    "c_title":[
      "The transition to phenomenological behaviour of static solutions of the\n  Einstein-Dirac system for an increasing number of fermions"
    ],
    "c_abstract":[
      "Static spherically symmetric solutions to the Einstein-Dirac system were\nconstructed numerically for the first time in 1999 by Finster, Smoller and Yau\n\\cite{FSY1} in the case of two fermions. In 2020 this result was generalized by\nLeith, Hooley, Horne and Dritschel \\cite{LHHD} to a system consisting of an\neven number $\\kappa$ of fermions. They constructed solutions for\n$2\\leq\\kappa\\leq 90$. The purpose of the present investigation is to compare\nthe properties of static solutions of the Einstein-Dirac system with static\nsolutions of the Einstein,-Vlasov system as the number of fermions increases,\nthat is, for $2\\leq\\kappa \\leq 180$. Since the Einstein-Vlasov system is a\nfully classical physical model, whereas the Einstein-Dirac system is\nsemiclassical and thus has a quantum signature, this framework provides an\nexcellent opportunity to study the transition from quantum to classical\nbehaviour. It turns out that even for a comparatively small number of\nparticles, the features of the solutions are remarkably similar. For both\nsystems, we find highly relativistic solutions having a multi-peak structure\nwith strikingly similar characteristics. We also investigate the maximum\ncompactness ratio $\\sup 2m\/r$ of the solutions. The solutions of both systems\nshare the fundamental properties regarding the maximum compactness ratio and\nobey the inequality derived in \\cite{A2}. Furthermore, we investigate the sign\nof the pressure components of solutions of the Einstein-Dirac system. For small\nvalues of $\\kappa$, there are regions where the radial pressure is negative.\nThese regions disappear as $\\kappa$ increases. This supports the interpretation\nwe make as a transition from quantum to classical behaviour as the number of\nfermions increases."
    ],
    "c_categories":[
      [
        "gr-qc"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-932",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13970",
    "b_title":[
      "CoreDPPL: Towards a Sound Composition of Differentiation, ODE Solving,\n  and Probabilistic Programming"
    ],
    "b_abstract":[
      "In recent years, there has been extensive research on how to extend\ngeneral-purpose programming language semantics with domain-specific modeling\nconstructs. Two areas of particular interest are (i) universal probabilistic\nprogramming where Bayesian probabilistic models are encoded as programs, and\n(ii) differentiable programming where differentiation operators are first class\nor differential equations are part of the language semantics. These kinds of\nlanguages and their language constructs are usually studied separately or\ncomposed in restrictive ways. In this paper, we study and formalize the\ncombination of probabilistic programming constructs, first-class\ndifferentiation, and ordinary differential equations in a higher-order setting.\nWe propose formal semantics for a core of such differentiable probabilistic\nprogramming language (DPPL), where the type system tracks random computations\nand rejects unsafe compositions during type checking. The semantics and its\ntype system are formalized, mechanized, and proven sound in Agda with respect\nto abstract language constructs."
    ],
    "b_categories":[
      [
        "cs.PL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.16971",
    "c_title":[
      "Nofl: A Precise Immix"
    ],
    "c_abstract":[
      "Can a memory manager be built with fast bump-pointer allocation, single-pass\nheap tracing, and a low upper bound on memory overhead? The Immix collector\nanswered in the affirmative for the first two, but the granularity at which it\nreclaims memory means that in the worst case a tiny object can keep two\n128-byte lines of memory from being re-used for allocation.\n  This paper takes Immix to an extreme of precision, allowing all free space\nbetween objects to be reclaimed, down to the limit of the allocator's minimum\nalignment. We present the design of this Nofl layout, build a collector library\naround it, and build a new Scheme-to-C compiler as a workbench. We make a first\nevaluation of the Nofl-based mostly-marking collector when compared to standard\ncopying and mark-sweep collectors and run against a limited set of\nmicrobenchmarks, finding that Nofl outperforms the others for tight-to-adequate\nheap sizes."
    ],
    "c_categories":[
      [
        "cs.PL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-933",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.18753",
    "b_title":[
      "Self-Supervised Learning based on Transformed Image Reconstruction for\n  Equivariance-Coherent Feature Representation"
    ],
    "b_abstract":[
      "The equivariant behaviour of features is essential in many computer vision\ntasks, yet popular self-supervised learning (SSL) methods tend to constrain\nequivariance by design. We propose a self-supervised learning approach where\nthe system learns transformations independently by reconstructing images that\nhave undergone previously unseen transformations. Specifically, the model is\ntasked to reconstruct intermediate transformed images, e.g. translated or\nrotated images, without prior knowledge of these transformations. This\nauxiliary task encourages the model to develop equivariance-coherent features\nwithout relying on predefined transformation rules. To this end, we apply\ntransformations to the input image, generating an image pair, and then split\nthe extracted features into two sets per image. One set is used with a usual\nSSL loss encouraging invariance, the other with our loss based on the auxiliary\ntask to reconstruct the intermediate transformed images. Our loss and the SSL\nloss are linearly combined with weighted terms. Evaluating on synthetic tasks\nwith natural images, our proposed method strongly outperforms all competitors,\nregardless of whether they are designed to learn equivariance. Furthermore,\nwhen trained alongside augmentation-based methods as the invariance tasks, such\nas iBOT or DINOv2, we successfully learn a balanced combination of invariant\nand equivariant features. Our approach performs strong on a rich set of\nrealistic computer vision downstream tasks, almost always improving over all\nbaselines."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08218",
    "c_title":[
      "MVD-HuGaS: Human Gaussians from a Single Image via 3D Human Multi-view\n  Diffusion Prior"
    ],
    "c_abstract":[
      "3D human reconstruction from a single image is a challenging problem and has\nbeen exclusively studied in the literature. Recently, some methods have\nresorted to diffusion models for guidance, optimizing a 3D representation via\nScore Distillation Sampling(SDS) or generating one back-view image for\nfacilitating reconstruction. However, these methods tend to produce\nunsatisfactory artifacts (\\textit{e.g.} flattened human structure or\nover-smoothing results caused by inconsistent priors from multiple views) and\nstruggle with real-world generalization in the wild. In this work, we present\n\\emph{MVD-HuGaS}, enabling free-view 3D human rendering from a single image via\na multi-view human diffusion model. We first generate multi-view images from\nthe single reference image with an enhanced multi-view diffusion model, which\nis well fine-tuned on high-quality 3D human datasets to incorporate 3D geometry\npriors and human structure priors. To infer accurate camera poses from the\nsparse generated multi-view images for reconstruction, an alignment module is\nintroduced to facilitate joint optimization of 3D Gaussians and camera poses.\nFurthermore, we propose a depth-based Facial Distortion Mitigation module to\nrefine the generated facial regions, thereby improving the overall fidelity of\nthe reconstruction.Finally, leveraging the refined multi-view images, along\nwith their accurate camera poses, MVD-HuGaS optimizes the 3D Gaussians of the\ntarget human for high-fidelity free-view renderings. Extensive experiments on\nThuman2.0 and 2K2K datasets show that the proposed MVD-HuGaS achieves\nstate-of-the-art performance on single-view 3D human rendering."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-934",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01371",
    "b_title":[
      "CLIP-UP: CLIP-Based Unanswerable Problem Detection for Visual Question\n  Answering"
    ],
    "b_abstract":[
      "Recent Vision-Language Models (VLMs) have demonstrated remarkable\ncapabilities in visual understanding and reasoning, and in particular on\nmultiple-choice Visual Question Answering (VQA). Still, these models can make\ndistinctly unnatural errors, for example, providing (wrong) answers to\nunanswerable VQA questions, such as questions asking about objects that do not\nappear in the image. To address this issue, we propose CLIP-UP: CLIP-based\nUnanswerable Problem detection, a novel lightweight method for equipping VLMs\nwith the ability to withhold answers to unanswerable questions. By leveraging\nCLIP to extract question-image alignment information, CLIP-UP requires only\nefficient training of a few additional layers, while keeping the original VLMs'\nweights unchanged. Tested across LLaVA models, CLIP-UP achieves\nstate-of-the-art results on the MM-UPD benchmark for assessing unanswerability\nin multiple-choice VQA, while preserving the original performance on other\ntasks."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.17530",
    "c_title":[
      "FMDConv: Fast Multi-Attention Dynamic Convolution via Speed-Accuracy\n  Trade-off"
    ],
    "c_abstract":[
      "Spatial convolution is fundamental in constructing deep Convolutional Neural\nNetworks (CNNs) for visual recognition. While dynamic convolution enhances\nmodel accuracy by adaptively combining static kernels, it incurs significant\ncomputational overhead, limiting its deployment in resource-constrained\nenvironments such as federated edge computing. To address this, we propose Fast\nMulti-Attention Dynamic Convolution (FMDConv), which integrates input\nattention, temperature-degraded kernel attention, and output attention to\noptimize the speed-accuracy trade-off. FMDConv achieves a better balance\nbetween accuracy and efficiency by selectively enhancing feature extraction\nwith lower complexity. Furthermore, we introduce two novel quantitative\nmetrics, the Inverse Efficiency Score and Rate-Correct Score, to systematically\nevaluate this trade-off. Extensive experiments on CIFAR-10, CIFAR-100, and\nImageNet demonstrate that FMDConv reduces the computational cost by up to\n49.8\\% on ResNet-18 and 42.2\\% on ResNet-50 compared to prior multi-attention\ndynamic convolution methods while maintaining competitive accuracy. These\nadvantages make FMDConv highly suitable for real-world, resource-constrained\napplications."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-935",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14819",
    "b_title":[
      "Learning from Reward-Free Offline Data: A Case for Planning with Latent\n  Dynamics Models"
    ],
    "b_abstract":[
      "A long-standing goal in AI is to build agents that can solve a variety of\ntasks across different environments, including previously unseen ones. Two\ndominant approaches tackle this challenge: (i) reinforcement learning (RL),\nwhich learns policies through trial and error, and (ii) optimal control, which\nplans actions using a learned or known dynamics model. However, their relative\nstrengths and weaknesses remain underexplored in the setting where agents must\nlearn from offline trajectories without reward annotations. In this work, we\nsystematically analyze the performance of different RL and control-based\nmethods under datasets of varying quality. On the RL side, we consider\ngoal-conditioned and zero-shot approaches. On the control side, we train a\nlatent dynamics model using the Joint Embedding Predictive Architecture (JEPA)\nand use it for planning. We study how dataset properties-such as data\ndiversity, trajectory quality, and environment variability-affect the\nperformance of these approaches. Our results show that model-free RL excels\nwhen abundant, high-quality data is available, while model-based planning\nexcels in generalization to novel environment layouts, trajectory stitching,\nand data-efficiency. Notably, planning with a latent dynamics model emerges as\na promising approach for zero-shot generalization from suboptimal data."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.19301",
    "c_title":[
      "Rethinking LLM Unlearning Objectives: A Gradient Perspective and Go\n  Beyond"
    ],
    "c_abstract":[
      "Large language models (LLMs) should undergo rigorous audits to identify\npotential risks, such as copyright and privacy infringements. Once these risks\nemerge, timely updates are crucial to remove undesirable responses, ensuring\nlegal and safe model usage. It has spurred recent research into LLM unlearning,\nfocusing on erasing targeted undesirable knowledge without compromising the\nintegrity of other, non-targeted responses. Existing studies have introduced\nvarious unlearning objectives to pursue LLM unlearning without necessitating\ncomplete retraining. However, each of these objectives has unique properties,\nand no unified framework is currently available to comprehend them thoroughly.\nTo fill the gap, we propose a toolkit of the gradient effect (G-effect),\nquantifying the impacts of unlearning objectives on model performance from a\ngradient perspective. A notable advantage is its broad ability to detail the\nunlearning impacts from various aspects across instances, updating steps, and\nLLM layers. Accordingly, the G-effect offers new insights into identifying\ndrawbacks of existing unlearning objectives, further motivating us to explore a\nseries of new solutions for their mitigation and improvements. Finally, we\noutline promising directions that merit further studies, aiming at contributing\nto the community to advance this important field."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-936",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05591",
    "b_title":[
      "Towards Round-Optimal Approximate Agreement on Trees"
    ],
    "b_abstract":[
      "Ensuring consistency in distributed systems, especially in adversarial\nenvironments, is a fundamental challenge in theoretical computing. Approximate\nAgreement (AA) is a key consensus primitive that allows honest parties to\nachieve close but not necessarily identical outputs, even in the presence of\nbyzantine faults. While the optimal round complexity of synchronous AA on real\nnumbers is well understood, its extension to tree-structured spaces remains an\nopen problem.\n  We present a protocol achieving AA on trees, with round complexity\n$O\\left(\\frac{\\log |V(T)|}{\\log \\log |V(T)|} \\right)$, where $V(T)$ is the set\nof vertices in the input tree $T$. Our protocol non-trivially reduces the\nproblem of AA on trees to AA on real values.\n  Additionally, we extend the impossibility results regarding the round\ncomplexity of AA protocols on real numbers to trees: we prove a lower bound of\n$\\Omega\\left(\\frac{\\log D(T)}{\\log \\log D(T)} \\right)$ rounds, where $D(T)$\ndenotes the diameter of the tree. This establishes the asymptotic optimality of\nour protocol for trees with large diameters $D(T) \\in \\Theta(|V(T)|)$."
    ],
    "b_categories":[
      [
        "cs.DC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17732",
    "c_title":[
      "Gateways for Institutional-Grade Commerce and Interoperability of\n  Digital Assets"
    ],
    "c_abstract":[
      "It is time for the legacy financial infrastructure to seamlessly connect with\nmodern, decentralized infrastructure. Although it is increasingly evident that\ndecentralized infrastructure for finance (namely distributed ledgers) will\ncoexist with and complement legacy infrastructure, it is also clear that such\ninteroperability efforts carry new risks and concerns. In particular, managing\nthe range of heterogeneous (and not well-established) infrastructure brings\nsecurity, privacy, and regulatory issues. The first step to overcome some of\nthese challenges is to recognize that in many deployment instances using\ndistributed ledgers, the purpose of the ledger is to share resources among the\ncommunity members. The second step after recognizing that borders exist is to\nunderstand that interoperability across systems can be best achieved through\nthe use of standardized service interfaces (or application programming\ninterfaces (API)). In this paper we use the term ledger gateways (or simply\ngateways) to denote the computer and software systems that implement the\nstandardized service interfaces into a distributed ledger. The main purpose of\na gateway is to communicate with other peer gateways that implement the same\nstandardized service interface. Among others, peer gateways perform the\ntransfer of data and value across borders (legal or national borders). Gateways\nalso become a mechanism to manage a permissioned environment, where abiding by\nlaws and regulations is crucial for business compliance (e.g., EU General Data\nProtection Regulations (GDPR), EU MiCa regulation on digital assets, FAFT\nRecommendation 15, ISO 27001."
    ],
    "c_categories":[
      [
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-937",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.17305",
    "b_title":[
      "`Generalization is hallucination' through the lens of tensor completions"
    ],
    "b_abstract":[
      "In this short position paper, we introduce tensor completions and artifacts\nand make the case that they are a useful theoretical framework for\nunderstanding certain types of hallucinations and generalizations in language\nmodels."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.04405",
    "c_title":[
      "Comparative Study of Zero-Shot Cross-Lingual Transfer for Bodo POS and\n  NER Tagging Using Gemini 2.0 Flash Thinking Experimental Model"
    ],
    "c_abstract":[
      "Named Entity Recognition (NER) and Part-of-Speech (POS) tagging are critical\ntasks for Natural Language Processing (NLP), yet their availability for\nlow-resource languages (LRLs) like Bodo remains limited. This article presents\na comparative empirical study investigating the effectiveness of Google's\nGemini 2.0 Flash Thinking Experiment model for zero-shot cross-lingual transfer\nof POS and NER tagging to Bodo. We explore two distinct methodologies: (1)\ndirect translation of English sentences to Bodo followed by tag transfer, and\n(2) prompt-based tag transfer on parallel English-Bodo sentence pairs. Both\nmethods leverage the machine translation and cross-lingual understanding\ncapabilities of Gemini 2.0 Flash Thinking Experiment to project English POS and\nNER annotations onto Bodo text in CONLL-2003 format. Our findings reveal the\ncapabilities and limitations of each approach, demonstrating that while both\nmethods show promise for bootstrapping Bodo NLP, prompt-based transfer exhibits\nsuperior performance, particularly for NER. We provide a detailed analysis of\nthe results, highlighting the impact of translation quality, grammatical\ndivergences, and the inherent challenges of zero-shot cross-lingual transfer.\nThe article concludes by discussing future research directions, emphasizing the\nneed for hybrid approaches, few-shot fine-tuning, and the development of\ndedicated Bodo NLP resources to achieve high-accuracy POS and NER tagging for\nthis low-resource language."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-938",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.02499",
    "b_title":[
      "Attack Tree Distance: a practical examination of tree difference\n  measurement within cyber security"
    ],
    "b_abstract":[
      "CONTEXT. Attack treesare a recommended threat modeling tool, but there is no\nestablished method to compare them. OBJECTIVE. We aim to establish a method to\ncompare \"real\" attack trees, based on both the structure of the tree itself and\nthe meaning of the node labels. METHOD. We define four methods of comparison\n(three novel and one established) and compare them to a dataset of attack trees\ncreated from a study run on students (n = 39). These attack trees all follow\nfrom the same scenario, but have slightly different labels. RESULTS. We find\nthat applying semantic similarity as a means of comparing node labels is a\nvalid approach. Further, we find that treeedit distance (established) and\nradical distance (novel) are themost promising methods of comparison in most\ncircumstances. CONCLUSION. We show that these two methods are valid as means of\ncomparing attack trees, and suggest a novel technique for using semantic\nsimilarity to compare node labels. We further suggest that these methods can be\nused to compare attack trees in a real-world scenario, and that they can be\nused to identify similar attack trees."
    ],
    "b_categories":[
      [
        "cs.CR"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18549",
    "c_title":[
      "CryptoDNA: A Machine Learning Paradigm for DDoS Detection in Healthcare\n  IoT, Inspired by crypto jacking prevention Models"
    ],
    "c_abstract":[
      "The rapid integration of the Internet of Things (IoT) and Internet of Medical\n(IoM) devices in the healthcare industry has markedly improved patient care and\nhospital operations but has concurrently brought substantial risks. Distributed\nDenial-of-Service (DDoS) attacks present significant dangers, jeopardizing\noperational stability and patient safety. This study introduces CryptoDNA, an\ninnovative machine learning detection framework influenced by cryptojacking\ndetection methods, designed to identify and alleviate DDoS attacks in\nhealthcare IoT settings. The proposed approach relies on behavioral analytics,\nincluding atypical resource usage and network activity patterns. Key features\nderived from cryptojacking-inspired methodologies include entropy-based\nanalysis of traffic, time-series monitoring of device performance, and dynamic\nanomaly detection. A lightweight architecture ensures inter-compatibility with\nresource-constrained IoT devices while maintaining high detection accuracy. The\nproposed architecture and model were tested in real-world and synthetic\ndatasets to demonstrate the model's superior performance, achieving over 96%\naccuracy with minimal computational overhead. Comparative analysis reveals its\nresilience against emerging attack vectors and scalability across diverse\ndevice ecosystems. By bridging principles from cryptojacking and DDoS\ndetection, CryptoDNA offers a robust, innovative solution to fortify the\nhealthcare IoT landscape against evolving cyber threats and highlights the\npotential of interdisciplinary approaches in adaptive cybersecurity defense\nmechanisms for critical healthcare infrastructures."
    ],
    "c_categories":[
      [
        "cs.CR"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-939",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09937",
    "b_title":[
      "Spin density matrix for neutral $\\rho$ mesons in a pion gas in linear\n  response theory"
    ],
    "b_abstract":[
      "We calculate the spin density matrix for neutral $\\rho$ mesons from the\nspectral function and thermal shear tensor by Kubo formula in the linear\nresponse theory, which contributes to the $\\gamma$ correlator for the CME\nsearch. We derive the spectral function of neutral $\\rho$ mesons with\n$\\rho\\pi\\pi$ and $\\rho\\rho\\pi\\pi$ interactions using the Dyson-Schwinger\nequation. The thermal shear tensor contribution is obtained from the Kubo\nformula in the linear response theory. We numerically calculate $\\rho_{00}-1\/3$\nand $\\mathrm{Re}\\rho_{-1,1}$ using the simulation results for the thermal shear\ntensor by the hydrodynamical model, which are of the order\n$10^{-3}\\sim10^{-2}$."
    ],
    "b_categories":[
      [
        "hep-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.06574",
    "c_title":[
      "Studying the VBF Hjj and Hjjj Higgs Boson Production in QCD and EFT\n  Theory"
    ],
    "c_abstract":[
      "The discovery of the Higgs boson made it possible not only to study its\nphysical properties and update its search strategies, but also to apply new\ntheoretical constructs to explain its properties. Within the framework of the\nVBF Higgs boson production process in association with two, Hjj and three jets,\nHjjj, we modeled its kinematic properties and calculated its production\ncross-sections. The calculations were carried out within two theories, QCD and\nEFT for both SM processes and for the MSSM and NMSSM models within the\nframework of the BSM physics searches."
    ],
    "c_categories":[
      [
        "hep-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-940",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.14695",
    "b_title":[
      "Quasiclassical quantization of the Boussinesq breather emerging from the\n  kink localized mode"
    ],
    "b_abstract":[
      "The breather solution found by M. Tajiri and Y. Murakami for the Boussinesq\nequation is studied analytically. The new parameterization of the solution is\nproposed, allowing us to find exactly the existence boundary of the Boussinesq\nbreather and to show that such a nonlinear excitation emerges from the linear\nlocalized mode of the kink solution corresponding to a shock wave analog in a\ncrystal. We explicitly find the first integrals, namely the energy and the\nfield momentum, and faithfully construct the adiabatic invariant for the\nBoussinesq breather. As a result, we carry out the quasiclassical quantization\nof the nonlinear oscillating solution, obtaining its energy spectrum, i.e., the\nenergy dependence on the momentum and the number of states, and reveal the\nHamiltonian equations for this particle-like excitation."
    ],
    "b_categories":[
      [
        "nlin.PS"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.09264",
    "c_title":[
      "Defects, parcellation, and renormalized negative diffusivities in\n  non-homogeneous oscillatory media"
    ],
    "c_abstract":[
      "Coupling among oscillators in spatially-extended systems tends to lock their\nfrequency at a common value. In the presence of spatial non-homogeneities,\nlocking of different regions at different frequencies leads to parcellation,\ni.e., a series of synchronized clusters (plateaus). Motivated by rhythmic\ndynamics in physiological systems, we consider a Ginzburg-Landau (GL) model\nwith a gradient of natural frequencies. We determine the scaling of the number\nof plateaus and their typical length {\\it vs} dynamical parameters. Plateaus\nare separated by defects, where the amplitude of the GL field vanishes and\nphase differences are reset. For Dirichlet boundary conditions, we use\nasymptotic methods to determine the field profile around defects. For Neumann\nboundary conditions, we relate the stability phase diagram and defects'\nprecursors to the spectrum of the non-Hermitian Bloch-Torrey equation,\noriginally introduced for nuclear magnetic resonance. In the non-linear regime,\nwe trace the formation of defects to a non-linear renormalization of the\ndiffusivity, which leads to spatially-modulated negative values and an\ninstability that drives amplitude modulation."
    ],
    "c_categories":[
      [
        "nlin.PS"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-941",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01329",
    "b_title":[
      "Benchmarking Different QP Formulations and Solvers for Dynamic\n  Quadrupedal Walking"
    ],
    "b_abstract":[
      "Quadratic Programs (QPs) are widely used in the control of walking robots,\nespecially in Model Predictive Control (MPC) and Whole-Body Control (WBC). In\nboth cases, the controller design requires the formulation of a QP and the\nselection of a suitable QP solver, both requiring considerable time and\nexpertise. While computational performance benchmarks exist for QP solvers,\nstudies comparing optimal combinations of computational hardware (HW), QP\nformulation, and solver performance are lacking. In this work, we compare dense\nand sparse QP formulations, and multiple solving methods on different HW\narchitectures, focusing on their computational efficiency in dynamic walking of\nfour legged robots using MPC. We introduce the Solve Frequency per Watt (SFPW)\nas a performance measure to enable a cross hardware comparison of the\nefficiency of QP solvers. We also benchmark different QP solvers for WBC that\nwe use for trajectory stabilization in quadrupedal walking. As a result, this\npaper provides recommendations for the selection of QP formulations and solvers\nfor different HW architectures in walking robots and indicates which problems\nshould be devoted the greater technical effort in this domain in future."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.14147",
    "c_title":[
      "HAMMER: Heterogeneous, Multi-Robot Semantic Gaussian Splatting"
    ],
    "c_abstract":[
      "3D Gaussian Splatting offers expressive scene reconstruction, modeling a\nbroad range of visual, geometric, and semantic information. However, efficient\nreal-time map reconstruction with data streamed from multiple robots and\ndevices remains a challenge. To that end, we propose HAMMER, a server-based\ncollaborative Gaussian Splatting method that leverages widely available ROS\ncommunication infrastructure to generate 3D, metric-semantic maps from\nasynchronous robot data-streams with no prior knowledge of initial robot\npositions and varying on-device pose estimators. HAMMER consists of (i) a frame\nalignment module that transforms local SLAM poses and image data into a global\nframe and requires no prior relative pose knowledge, and (ii) an online module\nfor training semantic 3DGS maps from streaming data. HAMMER handles mixed\nperception modes, adjusts automatically for variations in image pre-processing\namong different devices, and distills CLIP semantic codes into the 3D scene for\nopen-vocabulary language queries. In our real-world experiments, HAMMER creates\nhigher-fidelity maps (2x) compared to competing baselines and is useful for\ndownstream tasks, such as semantic goal-conditioned navigation (e.g., ``go to\nthe couch\"). Accompanying content available at hammer-project.github.io."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-942",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12218",
    "b_title":[
      "Exploring Temporally-Aware Features for Point Tracking"
    ],
    "b_abstract":[
      "Point tracking in videos is a fundamental task with applications in robotics,\nvideo editing, and more. While many vision tasks benefit from pre-trained\nfeature backbones to improve generalizability, point tracking has primarily\nrelied on simpler backbones trained from scratch on synthetic data, which may\nlimit robustness in real-world scenarios. Additionally, point tracking requires\ntemporal awareness to ensure coherence across frames, but using\ntemporally-aware features is still underexplored. Most current methods often\nemploy a two-stage process: an initial coarse prediction followed by a\nrefinement stage to inject temporal information and correct errors from the\ncoarse stage. These approach, however, is computationally expensive and\npotentially redundant if the feature backbone itself captures sufficient\ntemporal information.\n  In this work, we introduce Chrono, a feature backbone specifically designed\nfor point tracking with built-in temporal awareness. Leveraging pre-trained\nrepresentations from self-supervised learner DINOv2 and enhanced with a\ntemporal adapter, Chrono effectively captures long-term temporal context,\nenabling precise prediction even without the refinement stage. Experimental\nresults demonstrate that Chrono achieves state-of-the-art performance in a\nrefiner-free setting on the TAP-Vid-DAVIS and TAP-Vid-Kinetics datasets, among\ncommon feature backbones used in point tracking as well as DINOv2, with\nexceptional efficiency. Project page: https:\/\/cvlab-kaist.github.io\/Chrono\/"
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.04322",
    "c_title":[
      "Eve: Efficient Multimodal Vision Language Models with Elastic Visual\n  Experts"
    ],
    "c_abstract":[
      "Multimodal vision language models (VLMs) have made significant progress with\nthe support of continuously increasing model sizes and data volumes. Running\nVLMs on edge devices has become a challenge for their widespread application.\nThere are several efficient VLM efforts, but they often sacrifice linguistic\ncapabilities to enhance multimodal abilities, or require extensive training. To\naddress this quandary,we introduce the innovative framework of Efficient Vision\nLanguage Models with Elastic Visual Experts (Eve). By strategically\nincorporating adaptable visual expertise at multiple stages of training, Eve\nstrikes a balance between preserving linguistic abilities and augmenting\nmultimodal capabilities. This balanced approach results in a versatile model\nwith only 1.8B parameters that delivers significant improvements in both\nmultimodal and linguistic tasks. Notably, in configurations below 3B\nparameters, Eve distinctly outperforms in language benchmarks and achieves\nstate-of-the-art results 68.87% in VLM Benchmarks. Additionally, its multimodal\naccuracy outstrips that of the larger 7B LLaVA-1.5 model. Our code is available\nat https:\/\/github.com\/rangmiao\/Eve."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-943",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11130",
    "b_title":[
      "Efficient and accurate simulation of the Smith-Zener pinning mechanism\n  during grain growth using a front-tracking numerical framework"
    ],
    "b_abstract":[
      "This study proposes a new full-field approach for modeling grain boundary\npinning by second phase particles in two-dimensional polycrystals. These\nparticles are of great importance during thermomechanical treatments, as they\nproduce deviations from the microstructural evolution that the alloy produces\nin the absence of particles. This phenomenon, well-known as Smith-Zener\npinning, is widely used by metallurgists to control the grain size during the\nmetal forming process of many alloys. Predictive tools are then needed to\naccurately model this phenomenon. This article introduces a new methodology for\nthe simulation of microstructural evolutions subjected to the presence of\nsecond phase particles. The methodology employs a Lagrangian 2D front-tracking\nmethodology, while the particles are modeled using discretized circular shapes\nor pinning nodes. The evolution of the particles can be considered and modeled\nusing a constant velocity of particle shrinking. This approach has the\nadvantages of improving the limited description made of the phenomenon in\nvertex approaches, to be usable for a wide range of second-phase particle sizes\nand to improve calculation times compared to front-capturing type approaches."
    ],
    "b_categories":[
      [
        "cs.CE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.01248",
    "c_title":[
      "Computational modelling of cancer nanomedicine: Integrating hyperthermia\n  treatment into a multiphase porous-media tumour model"
    ],
    "c_abstract":[
      "Heat-based cancer treatment, so-called hyperthermia, can be used to destroy\ntumour cells directly or to make them more susceptible to chemotherapy or\nradiation therapy. To apply heat locally, iron oxide nanoparticles are injected\ninto the bloodstream and accumulate at the tumour site, where they generate\nheat when exposed to an alternating magnetic field. However, the temperature\nmust be precisely controlled to achieve therapeutic benefits while avoiding\ndamage to healthy tissue. We therefore present a computational model for\nnanoparticle-mediated hyperthermia treatment fully integrated into a multiphase\nporous-media model of the tumour and its microenvironment. We study how the\ntemperature depends on the amount of nanoparticles accumulated in the tumour\narea and the specific absorption rate of the nanoparticles. Our results show\nthat host tissue surrounding the tumour is also exposed to considerable doses\nof heat due to the high thermal conductivity of the tissue, which may cause\npain or even unnecessary irreversible damage. Further, we include a lumped and\na discrete model for the cooling effect of blood perfusion. Using a discrete\nmodel of a realistic microvasculature reveals that the small capillaries do not\nhave a significant cooling effect during hyperthermia treatment and that the\ncommonly used lumped model based on Pennes' bioheat equation overestimates the\neffect: within the specific conditions analysed, the difference between lumped\nand discrete approaches is approximatively 0.75{\\deg}C, which could influence\nthe therapeutic intervention outcome. Such a comprehensive computational model,\nas presented here, can provide insights into the optimal treatment parameters\nfor nanoparticle-mediated hyperthermia and can be used to design more efficient\ntreatment strategies."
    ],
    "c_categories":[
      [
        "cs.CE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-944",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.07843",
    "b_title":[
      "Robust triple-q magnetic order with trainable spin vorticity in\n  Na$_2$Co$_2$TeO$_6$"
    ],
    "b_abstract":[
      "Recent studies suggest that the candidate Kitaev magnet Na$_2$Co$_2$TeO$_6$\npossesses novel triple-$\\mathbf{q}$ magnetic order instead of conventional\nsingle-$\\mathbf{q}$ zigzag order. Here we present dedicated experiments in\nsearch for distinct properties expected of the triple-$\\mathbf{q}$ order,\nnamely, insensitivity of the magnetic domains to weak $C_3$ symmetry-breaking\nfields and fictitious magnetic fields generated by the spin vorticity. In\nstructurally pristine single crystals, we show that $C_3$ symmetry-breaking\nin-plane uniaxial strains do not affect the order's magnetic neutron\ndiffraction signals. We further show that $\\mathbf{c}$-axis propagating light\nexhibits large Faraday rotations in the ordered state due to the spin\nvorticity, the sign of which can be trained via the system's ferrimagnetic\nmoment. These results are in favor of the triple-$\\mathbf{q}$ order in\nNa$_2$Co$_2$TeO$_6$ and reveal its unique emerging behavior."
    ],
    "b_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.08362",
    "c_title":[
      "Altermagnetism and beyond in the $t$-$t^\\prime$-$\\delta$ Fermi-Hubbard\n  model"
    ],
    "c_abstract":[
      "In this work, we revisit the phase diagram of the $t$-$t^\\prime$-$\\delta$\nFermi-Hubbard model on the square lattice to gain a more comprehensive\nunderstanding of this correlated model at half filling. This model has recently\nbecome a prominent topic of research because it hosts altermagnetic phases.\nUsing mean-field analysis, we identify four metallic phases and two insulating\nphases with nontrivial magnetic orders at an intermediate value of $\\delta =\n0.5$, presenting a rich ground-state phase diagram in the $U$-$t^\\prime$ plane.\nWe also highlight the distinct features of the Fermi surface topology for each\nmetallic phase. To go beyond the mean-field theory, we employ the\ndensity-matrix renormalization group method to simulate the ground state\nnumerically. The phase boundaries are determined from the discontinuities and\npeaks in the entanglement entropy and magnetizations. In addition to the phases\nidentified in the mean-field theory, we find a valence-bond solid state in a\nnarrow intermediate-$t'$ region. Our work offers a firm step forward in\nunderstanding the complex behaviors of correlated electrons in the\n$t$-$t^\\prime$-$\\delta$ Hubbard model over a large parameter space."
    ],
    "c_categories":[
      [
        "cond-mat.str-el"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-945",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.12650",
    "b_title":[
      "Probing superconductivity with tunneling spectroscopy in rhombohedral\n  graphene"
    ],
    "b_abstract":[
      "Motivated by experiments on rhombohedral tetralayer graphene showing signs of\nsuperconductivity emerging from a valley-polarized normal state, we here\nanalyze theoretically how scanning tunneling spectroscopy can be used to probe\nthe superconducting order parameter of the system. To describe different\npairing scenarios on equal footing, we develop a microscopic tunneling approach\nthat can capture arbitrary, including finite-momentum, superconducting order\nparameters and low-symmetry normal-state Hamiltonians. Our analysis shows that\nthe broken time-reversal symmetry in a single valley leads to unique features\nin the weak-tunneling regime that are different for commensurate and\nincommensurate Cooper pair momenta. We further uncover an unconventional\nspatial dependence of the Andreev conductance, allowing to distinguish between\nthree topologically distinct classes of single-$\\mathbf{q}$ pairing states in\nthe system, and compute the signatures of a competing translational-symmetry\nbreaking three-$\\mathbf{q}$ ''moir\\'e superconductor''."
    ],
    "b_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.04255",
    "c_title":[
      "The effect of Carrier Doping and Thickness on the Electronic Structures\n  of La$3$Ni$2$O$7$ Thin Films"
    ],
    "c_abstract":[
      "Recently, the superconductivity of bilayer nickelate La3Ni2O7 has been\nobserved in the thin film at ambient pressure, facilitated by epitaxial strain.\nHere, we investigate the effects of film thickness and carrier doping on the\nelectronic structure of La3Ni2O7 thin films with thickness of 0.5-3 unit cells\n(UC) using first-principles calculations. At an optimal doping concentration of\n0.4 holes per formula unit for 2UC film, the Ni-\"d\" _(\"z\" ^\"2\" ) interlayer\nbonding state metallizes, leading to the formation of {\\gamma} pockets at the\nFermi surface, which quantitatively matches the experimental results of\nangle-resolved photoemission spectroscopy (ARPES). These findings provide\ntheoretical support for recent experimental observations of ambient-pressure\nsuperconductivity in La3Ni2O7 thin films and highlight the crucial role of film\nthickness and carrier doping in modulating electronic properties."
    ],
    "c_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-946",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.19256",
    "b_title":[
      "Some musings on erythrogigantoacoustics"
    ],
    "b_abstract":[
      "Observations of stars other than the Sun are sensitive to oscillations of\nonly low degree. Many are high-order acoustic modes. Acoustic frequencies of\nmain-sequence stars, for example, satisfy a well-known pattern, which some\nastronomers have adopted even for red-giant stars. That is not wise, because\nthe internal structures of these stars can be quite different from those on the\nMain Sequence, which is populated by stars whose structure is regular. Here I\nreport on pondering this matter, and point out two fundamental deviations from\nthe commonly adopted relation. There are aspects of the regular relation that\nare connected in a simple way to gross properties of the star, such as the\ndependence of the eigenfrequencies on the linear combination\n$n+\\textstyle{\\frac {1}{2}}l$ of the order $n$ and degree $l$, which is\ncharacteristic of a regular spherical acoustic cavity. That is not a feature of\nred-giant frequencies, because, as experienced by the waves, red-giant stars\nappear to have (phantom) singular centres, which substantially modify the\npropagation of waves. That requires a generalization of the eigenfrequency\nrelation, which I present here. When fitted to the observed frequencies of the\nSun, the outcome is consistent with the Sun being round, with no singularity in\nthe core. That is hardly novel, but at least it provides some assurance that\nour understanding of stellar acoustic wave dynamics is on a sound footing."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.04103",
    "c_title":[
      "VLTI\/GRAVITY enables the determination of the first dynamical masses of\n  a classical Be + stripped and bloated pre-subdwarf binary"
    ],
    "c_abstract":[
      "HR~6819 is the first post-mass transfer binary system composed of a classical\nBe star and a bloated pre-subdwarf stripped star directly confirmed by\ninterferometry. While the Be star is already spun up to near-critical rotation\nand possesses a self-ejected viscous Keplerian disk, the stripped star is found\nin a short-lived evolutionary stage, in which it retains the spectral\nappearance of a B-type main-sequence star while contracting into a faint\nsubdwarf OB-type star. In order to understand the evolution of\nintermediate-mass interacting binaries, the fundamental parameters of\ncornerstone objects such as HR~6819 need to be known. We aim to obtain orbital\nparameters and model-independent dynamical masses of this binary system to\nquantitatively characterize this rarely observed evolutionary stage. We\nanalyzed a time series of 12 interferometric near-IR $K$-band observations from\nVLTI\/GRAVITY with the help of the geometrical model-fitting tool PMOIRED. We\nincluded recently published radial velocities based on FEROS high-resolution\nspectroscopy for the binary orbital solution. With the GRAVITY data, we\nobtained the astrometric orbit, relative fluxes of the components, and\nparameters of the circumstellar disk of the Be star; we also detected helium\nline signatures from the stripped star. Using the published radial velocities\nenabled us to obtain the dynamical masses of the components as well as the\ndynamical parallax. The Be star is the slightly brighter component in the $K$\nband and is almost 16 times as massive as the bloated stripped star, with the\nindividual dynamical masses being $4.24\\pm0.31 {\\rm M}_{\\odot}$ for the Be star\nand $0.270\\pm0.056 {\\rm M}_{\\odot}$ for the stripped star. The orbit is\nslightly eccentric, with $e=0.0289\\pm0.0058$, and the semimajor axis of the\norbit is $0.3800\\pm0.0093$ AU. (Abstract continues but does not fit here)"
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-947",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.07142",
    "b_title":[
      "A Systematic Comparison of Syntactic Representations of Dependency\n  Parsing"
    ],
    "b_abstract":[
      "We compare the performance of a transition-based parser in regards to\ndifferent annotation schemes. We pro-pose to convert some specific syntactic\nconstructions observed in the universal dependency treebanks into a so-called\nmore standard representation and to evaluate parsing performances over all the\nlanguages of the project. We show that the ``standard'' constructions do not\nlead systematically to better parsing performance and that the scores vary\nconsiderably according to the languages."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.18512",
    "c_title":[
      "Streaming DiLoCo with overlapping communication: Towards a Distributed\n  Free Lunch"
    ],
    "c_abstract":[
      "Training of large language models (LLMs) is typically distributed across a\nlarge number of accelerators to reduce training time. Since internal states and\nparameter gradients need to be exchanged at each and every single gradient\nstep, all devices need to be co-located using low-latency high-bandwidth\ncommunication links to support the required high volume of exchanged bits.\nRecently, distributed algorithms like DiLoCo have relaxed such co-location\nconstraint: accelerators can be grouped into ``workers'', where\nsynchronizations between workers only occur infrequently. This in turn means\nthat workers can afford being connected by lower bandwidth communication links\nwithout affecting learning quality. However, in these methods, communication\nacross workers still requires the same peak bandwidth as before, as the\nsynchronizations require all parameters to be exchanged across all workers. In\nthis paper, we improve DiLoCo in three ways. First, we synchronize only subsets\nof parameters in sequence, rather than all at once, which greatly reduces peak\nbandwidth. Second, we allow workers to continue training while synchronizing,\nwhich decreases wall clock time. Third, we quantize the data exchanged by\nworkers, which further reduces bandwidth across workers. By properly combining\nthese modifications, we show experimentally that we can distribute training of\nbillion-scale parameters and reach similar quality as before, but reducing\nrequired bandwidth by two orders of magnitude."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-948",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09557",
    "b_title":[
      "Core Hours and Carbon Credits: Incentivizing Sustainability in HPC"
    ],
    "b_abstract":[
      "Realizing a shared responsibility between providers and consumers is critical\nto manage the sustainability of HPC. However, while cost may motivate\nefficiency improvements by infrastructure operators, broader progress is\nimpeded by a lack of user incentives. We conduct a survey of HPC users that\nreveals fewer than 30 percent are aware of their energy consumption, and that\nenergy efficiency is among users' lowest priority concerns. One explanation is\nthat existing pricing models may encourage users to prioritize performance over\nenergy efficiency. We propose two transparent multi-resource pricing schemes,\nEnergy- and Carbon-Based Accounting, that seek to change this paradigm by\nincentivizing more efficient user behavior. These two schemes charge for\ncomputations based on their energy consumption or carbon footprint,\nrespectively, rewarding users who leverage efficient hardware and software. We\nevaluate these two pricing schemes via simulation, in a prototype, and a user\nstudy."
    ],
    "b_categories":[
      [
        "cs.DC"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.01035",
    "c_title":[
      "Balanced segmentation of CNNs for multi-TPU inference"
    ],
    "c_abstract":[
      "In this paper, we propose different alternatives for convolutional neural\nnetworks (CNNs) segmentation, addressing inference processes on computing\narchitectures composed by multiple Edge TPUs. Specifically, we compare the\ninference performance for a number of state-of-the-art CNN models taking as a\nreference inference times on one TPU and a compiler-based pipelined inference\nimplementation as provided by the Google's Edge TPU compiler. Departing from a\nprofiled-based segmentation strategy, we provide further refinements to balance\nthe workload across multiple TPUs, leveraging their cooperative computing\npower, reducing work imbalance and alleviating the memory access bottleneck due\nto the limited amount of on-chip memory per TPU. The observed performance\nresults compared with a single TPU yield superlinear speedups and accelerations\nup to 2.60x compared with the segmentation offered by the compiler targeting\nmultiple TPUs."
    ],
    "c_categories":[
      [
        "cs.DC"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-949",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.13492",
    "b_title":[
      "Quantized Spike-driven Transformer"
    ],
    "b_abstract":[
      "Spiking neural networks are emerging as a promising energy-efficient\nalternative to traditional artificial neural networks due to their spike-driven\nparadigm. However, recent research in the SNN domain has mainly focused on\nenhancing accuracy by designing large-scale Transformer structures, which\ntypically rely on substantial computational resources, limiting their\ndeployment on resource-constrained devices. To overcome this challenge, we\npropose a quantized spike-driven Transformer baseline (QSD-Transformer), which\nachieves reduced resource demands by utilizing a low bit-width parameter.\nRegrettably, the QSD-Transformer often suffers from severe performance\ndegradation. In this paper, we first conduct empirical analysis and find that\nthe bimodal distribution of quantized spike-driven self-attention (Q-SDSA)\nleads to spike information distortion (SID) during quantization, causing\nsignificant performance degradation. To mitigate this issue, we take\ninspiration from mutual information entropy and propose a bi-level optimization\nstrategy to rectify the information distribution in Q-SDSA. Specifically, at\nthe lower level, we introduce an information-enhanced LIF to rectify the\ninformation distribution in Q-SDSA. At the upper level, we propose a\nfine-grained distillation scheme for the QSD-Transformer to align the\ndistribution in Q-SDSA with that in the counterpart ANN. By integrating the\nbi-level optimization strategy, the QSD-Transformer can attain enhanced energy\nefficiency without sacrificing its high-performance advantage. For instance,\nwhen compared to the prior SNN benchmark on ImageNet, the QSD-Transformer\nachieves 80.3% top-1 accuracy, accompanied by significant reductions of\n6.0$\\times$ and 8.1$\\times$ in power consumption and model size, respectively.\nCode is available at https:\/\/github.com\/bollossom\/QSD-Transformer."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.06119",
    "c_title":[
      "An Appearance Defect Detection Method for Cigarettes Based on\n  C-CenterNet"
    ],
    "c_abstract":[
      "Due to the poor adaptability of traditional methods in the cigarette\ndetection task on the automatic cigarette production line, it is difficult to\naccurately identify whether a cigarette has defects and the types of defects;\nthus, a cigarette appearance defect detection method based on C-CenterNet is\nproposed. This detector uses keypoint estimation to locate center points and\nregresses all other defect properties. Firstly, Resnet50 is used as the\nbackbone feature extraction network, and the convolutional block attention\nmechanism (CBAM) is introduced to enhance the network's ability to extract\neffective features and reduce the interference of non-target information. At\nthe same time, the feature pyramid network is used to enhance the feature\nextraction of each layer. Then, deformable convolution is used to replace part\nof the common convolution to enhance the learning ability of different shape\ndefects. Finally, the activation function ACON (ActivateOrNot) is used instead\nof the ReLU activation function, and the activation operation of some neurons\nis adaptively selected to improve the detection accuracy of the network. The\nexperimental results are mainly acquired via the mean Average Precision (mAP).\nThe experimental results show that the mAP of the C-CenterNet model applied in\nthe cigarette appearance defect detection task is 95.01%. Compared with the\noriginal CenterNet model, the model's success rate is increased by 6.14%, so it\ncan meet the requirements of precision and adaptability in cigarette detection\ntasks on the automatic cigarette production line."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-950",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.21302",
    "b_title":[
      "Impact of Quantum Well Thickness on Efficiency Loss in InGaN\/GaN LEDs:\n  Challenges for Thin-Well Designs"
    ],
    "b_abstract":[
      "We investigate the impact of quantum well (QW) thickness on efficiency loss\nin c-plane InGaN\/GaN LEDs using a small-signal electroluminescence (SSEL)\ntechnique. Multiple mechanisms related to efficiency loss are independently\nexamined, including injection efficiency, carrier density vs. current density\nrelationship, phase space filling (PSF), quantum confined stark effect (QCSE),\nand Coulomb enhancement. An optimal QW thickness of around 2.7 nm in these\nInGaN\/GaN LEDs was determined for quantum wells having constant In composition.\nDespite better control of deep-level defects and lower carrier density at a\ngiven current density, LEDs with thin QWs still suffer from an imbalance of\nenhancement effects on the radiative and intrinsic Auger-Meitner recombination\ncoefficients. The imbalance of enhancement effects results in a decline in\ninternal quantum efficiency (IQE) and radiative efficiency with decreasing QW\nthickness at low current density in LEDs with QW thicknesses below 2.7 nm. We\nalso investigate how LED modulation bandwidth varies with quantum well\nthickness, identifying the key trends and their implications for device\nperformance."
    ],
    "b_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02949",
    "c_title":[
      "The physics of oscillating surfaces and sounds"
    ],
    "c_abstract":[
      "The longitudinal oscillations of air columns composed of contractions and\nrarefaction make up sound. Sound amplification is widely used in medical,\nelectronic and communication fields. A simplistic technique for producing and\namplifying can be rewarding. In this study, we investigate a simplistic DIY\nspeaker configuration that can be utilized for sound creation and modulation by\nimplementing response of magnets and a solenoid to an oscillating input signal.\nWe use steady state solution of forced simple harmonic oscillator with damping\nparameters to analyze our design and show its characteristic frequencies. We\npresent an analytical way of obtaining optimal parameters of the setup to\ntheoretically obtain experimental characteristic frequencies and provide an\nin-depth investigation of the setup."
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-951",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02148",
    "b_title":[
      "Can linear algebra create perfect knockoffs?"
    ],
    "b_abstract":[
      "As new Model-X knockoff construction techniques are developed, primarily\nconcerned with determining the correct conditional distribution from which to\nsample, we focus less on deriving the correct multivariate distribution and\ninstead ask if ``perfect'' knockoffs can be constructed using linear algebra.\nUsing mean absolute correlation between knockoffs and features as a measure of\nquality, we do produce knockoffs that are pseudo-perfect, however, the\noptimization algorithm is computationally very expensive. We outline a series\nof methods to significantly reduce the computation time of the algorithm."
    ],
    "b_categories":[
      [
        "stat.ME"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.15297",
    "c_title":[
      "Stochastic Volatility under Informative Missingness"
    ],
    "c_abstract":[
      "Stochastic volatility models that treat the variance of a time series as a\nstochastic process have proven to be important tools for analyzing dynamic\nvariability. Current methods for fitting and conducting inference on stochastic\nvolatility models are limited by the assumption that any missing data are\nmissing at random. With a recent explosion in technology to facilitate the\ncollection of dynamic self-response data for which mechanisms underlying\nmissing data are inherently scientifically informative, this limitation in\nstatistical methodology also limits scientific advancement. The goal of this\narticle is to develop the first statistical methodology for modeling, fitting,\nand conducting inference on stochastic volatility with data that are missing\nnot at random. The approach is based upon a novel imputation method derived\nusing Tukey's representation, which utilizes the Markovian nature of stochastic\nvolatility models to overcome unidentifiable components often faced when\nmodeling informative missingness in other settings. This imputation method is\ncombined with a new conditional particle filtering with ancestor sampling\nprocedure that accounts for variability in imputation to formulate a complete\nparticle Gibbs sampling scheme. The use of the method is illustrated through\nthe analysis of mobile phone self-reported mood from individuals being\nmonitored after unsuccessful suicide attempts."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-952",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.16893",
    "b_title":[
      "Emergent Dynamical Ising Transition in Diffusive Sandpiles"
    ],
    "b_abstract":[
      "Minimally stable site (MSS) clusters play a dominant role in shaping\navalanches in the self-organized critical (SOC) systems. The manipulation of\nMSS clusters through local smoothings (diffusion) alter the MSS landscape,\nsuppressing rare avalanches and postponing them until they manifest as spanning\navalanches. By leveraging the Inverse Ising problem, we uncover a duality\nbetween diffusive sandpiles and equilibrium statistical physics. Our analysis\nreveals an emergent magnetic instability in the dual Ising model, coinciding\nwith the formation of spanning avalanches and marking a transition to a\ncorrelated percolation regime. At this point, the MSS loop soups exhibit\nfractal self-similarity and power-law distributions, while the effective\npairwise interactions in the dual system vanish, signaling a magnetic\ntransition characterized by abrupt changes in magnetization and spin\nsusceptibility. Crucially, we show that diffusion fundamentally reshapes\navalanche dynamics: the spatial anti-correlations of MSSs in standard SOC\nsystems transform into positive correlations when diffusion is introduced.\nThese findings bridge self-organized criticality, percolation theory, and\nequilibrium phase transitions, shedding new light on emergent criticality and\nlarge-scale correlations in non-equilibrium systems."
    ],
    "b_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.16999",
    "c_title":[
      "Stable time rondeau crystals in dissipative many-body systems"
    ],
    "c_abstract":[
      "Driven systems offer the potential to realize a wide range of non-equilibrium\nphenomena that are inaccessible in static systems, such as the discrete time\ncrystals. Time rondeau crystals with a partial temporal order have been\nproposed as a distinctive prethermal phase of matter in systems driven by\nstructured random protocols. Yet, heating is inevitable in closed systems and\ntime rondeau crystals eventually melt. We introduce dissipation to counteract\nheating and demonstrate stable time rondeau crystals, which persist\nindefinitely, in a many-body interacting system. A key ingredient is\nsynchronization in the non-interacting limit, which allows for stable time\nrondeau order without generating excessive heating. The presence of many-body\ninteraction competes with synchronization and a de-synchronization phase\ntransition occurs at a finite interaction strength. This transition is well\ncaptured via a linear stability analysis of the underlying stochastic\nprocesses."
    ],
    "c_categories":[
      [
        "cond-mat.stat-mech"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-953",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02875",
    "b_title":[
      "METFORD -- Mutation tEsTing Framework fOR anDroid"
    ],
    "b_abstract":[
      "Mutation testing may be used to guide test case generation and as a technique\nto assess the quality of test suites. Despite being used frequently, mutation\ntesting is not so commonly applied in the mobile world. One critical challenge\nin mutation testing is dealing with its computational cost. Generating mutants,\nrunning test cases over each mutant, and analyzing the results may require\nsignificant time and resources. This research aims to contribute to reducing\nAndroid mutation testing costs. It implements mutation testing operators\n(traditional and Android-specific) according to mutant schemata (implementing\nmultiple mutants into a single code file). It also describes an Android\nmutation testing framework developed to execute test cases and determine\nmutation scores. Additional mutation operators can be implemented in JavaScript\nand easily integrated into the framework. The overall approach is validated\nthrough case studies showing that mutant schemata have advantages over the\ntraditional mutation strategy (one file per mutant). The results show mutant\nschemata overcome traditional mutation in all evaluated aspects with no\nadditional cost: it takes 8.50% less time for mutant generation, requires\n99.78% less disk space, and runs, on average, 6.45% faster than traditional\nmutation. Moreover, considering sustainability metrics, mutant schemata have\n8,18% less carbon footprint than traditional strategy."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.12904",
    "c_title":[
      "A Functional Software Reference Architecture for LLM-Integrated Systems"
    ],
    "c_abstract":[
      "The integration of large language models into software systems is\ntransforming capabilities such as natural language understanding,\ndecision-making, and autonomous task execution. However, the absence of a\ncommonly accepted software reference architecture hinders systematic reasoning\nabout their design and quality attributes. This gap makes it challenging to\naddress critical concerns like privacy, security, modularity, and\ninteroperability, which are increasingly important as these systems grow in\ncomplexity and societal impact. In this paper, we describe our\n\\textit{emerging} results for a preliminary functional reference architecture\nas a conceptual framework to address these challenges and guide the design,\nevaluation, and evolution of large language model-integrated systems. We\nidentify key architectural concerns for these systems, informed by current\nresearch and practice. We then evaluate how the architecture addresses these\nconcerns and validate its applicability using three open-source large language\nmodel-integrated systems in computer vision, text processing, and coding."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-954",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.01532",
    "b_title":[
      "Federated Learning with Discriminative Naive Bayes Classifier"
    ],
    "b_abstract":[
      "Federated Learning has emerged as a promising approach to train machine\nlearning models on decentralized data sources while preserving data privacy.\nThis paper proposes a new federated approach for Naive Bayes (NB)\nclassification, assuming discrete variables. Our approach federates a\ndiscriminative variant of NB, sharing meaningless parameters instead of\nconditional probability tables. Therefore, this process is more reliable\nagainst possible attacks. We conduct extensive experiments on 12 datasets to\nvalidate the efficacy of our approach, comparing federated and non-federated\nsettings. Additionally, we benchmark our method against the generative variant\nof NB, which serves as a baseline for comparison. Our experimental results\ndemonstrate the effectiveness of our method in achieving accurate\nclassification."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.09412",
    "c_title":[
      "FASP: Fast and Accurate Structured Pruning of Large Language Models"
    ],
    "c_abstract":[
      "The rapid increase in the size of large language models (LLMs) has\nsignificantly escalated their computational and memory demands, posing\nchallenges for efficient deployment, especially on resource-constrained\ndevices. Structured pruning has emerged as an effective model compression\nmethod that can reduce these demands while preserving performance. In this\npaper, we introduce FASP (Fast and Accurate Structured Pruning), a novel\nstructured pruning framework for LLMs that emphasizes both speed and accuracy.\nFASP employs a distinctive pruning structure that interlinks sequential layers,\nallowing for the removal of columns in one layer while simultaneously\neliminating corresponding rows in the preceding layer without incurring\nadditional performance loss. The pruning metric, inspired by Wanda, is\ncomputationally efficient and effectively selects components to prune.\nAdditionally, we propose a restoration mechanism that enhances model fidelity\nby adjusting the remaining weights post-pruning. We evaluate FASP on the OPT\nand LLaMA model families, demonstrating superior performance in terms of\nperplexity and accuracy on downstream tasks compared to state-of-the-art\nmethods. Our approach achieves significant speed-ups, pruning models such as\nOPT-125M in 17 seconds and LLaMA-30B in 15 minutes on a single NVIDIA RTX 4090\nGPU, making it a highly practical solution for optimizing LLMs."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-955",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.04324",
    "b_title":[
      "Paper self-citation: An unexplored phenomenon"
    ],
    "b_abstract":[
      "In this study, we investigated a phenomenon that one intuitively would assume\ndoes not exist: self-citations on the paper basis. Actually, papers citing\nthemselves do exist in the Web of Science (WoS) database. In total, we obtained\n44,857 papers that have self-citation relations in the WoS raw dataset. In\npart, they are database artefacts but in part they are due to papers citing\nthemselves in the conclusion or appendix. We also found cases where paper\nself-citations occur due to publisher-made highlights promoting and citing the\npaper. We analyzed the self-citing papers according to selected metadata. We\nobserved accumulations of the number of self-citing papers across publication\nyears. We found a skewed distribution across countries, journals, authors,\nfields, and document types. Finally, we discuss the implications of paper\nself-citations for bibliometric indicators."
    ],
    "b_categories":[
      [
        "cs.DL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.13460",
    "c_title":[
      "Self-Citations in Academic Excellence: Analysis of the Top 1% Highly\n  Cited India-Affiliated Research Papers"
    ],
    "c_abstract":[
      "Citations demonstrate the credibility, impact, and connection of a paper with\nthe academic community. Self-citations support research continuity but, if\nexcessive, may inflate metrics and raise bias concerns. The aim of the study is\nto examine the role of self-citations towards the research impact of India. To\nstudy this, 3.58 million papers affiliated with India from 1947 to 2024 in the\nScopus database were downloaded, and 2.96 million were filtered according to\ndocument type and publication year up to 2023. Further filtering based on high\ncitation counts identified the top 1% of highly cited papers, totaling 29,556.\nThe results indicate that the impact of Indian research, measured by highly\ncited papers, has grown exponentially since 2000, reaching a peak during the\n2011-2020 decade. Among the citations received by these 29,556 papers, 6% are\nself-citations. Papers with a high proportion of self-citations (>90%) are\npredominantly from recent decades and are associated with smaller team sizes.\nThe findings also reveal that smaller teams are primarily domestic, whereas\nlarger teams are more likely to involve international collaborations. Domestic\ncollaborations dominate smaller team sizes in terms of both self-citations and\npublications, whereas international collaborations gain prominence as team\nsizes increase. The results indicate that while domestic collaborations produce\na higher number of highly cited papers, international collaborations are more\nlikely to generate self-citations. The top international collaborators in\nhighly cited papers are the USA, followed by UK, and Germany."
    ],
    "c_categories":[
      [
        "cs.DL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-956",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.08263",
    "b_title":[
      "Drinfeld Quasi-Modular Forms of Higher Level"
    ],
    "b_abstract":[
      "We study the twofold structure of the vector space of Drinfeld quasi-modular\nforms for Hecke congruence subgroups. We provide representations as polynomials\nin the false Eisenstein series with coefficients in the space of Drinfeld\nmodular forms, and as sums of hyperderivatives of Drinfeld modular forms\n(whenever possible). Moreover, we offer a well-defined formula (i.e.\nindependent of the chosen representatives) for Hecke operators, and prove that\nthey preserve the space of Drinfeld quasi-modular forms of given weight and\ntype."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.00845",
    "c_title":[
      "Counting Imaginary Quadratic Fields with an Ideal Class Group of 5-rank\n  at least 2"
    ],
    "c_abstract":[
      "We prove that there are $\\gg\\frac{X^{\\frac{1}{3}}}{(\\log X)^2}$ imaginary\nquadratic fields $k$ with discriminant $|d_k|\\leq X$ and an ideal class group\nof $5$-rank at least $2$. This improves a result of Byeon, who proved the lower\nbound $\\gg X^{\\frac{1}{4}}$ in the same setting. We use a method of Howe,\nLepr\\'{e}vost, and Poonen to construct a genus $2$ curve $C$ over $\\mathbb{Q}$\nsuch that $C$ has a rational Weierstrass point and the Jacobian of $C$ has a\nrational torsion subgroup of $5$-rank $2$. We deduce the main result from the\nexistence of the curve $C$ and a quantitative result of Kulkarni and the second\nauthor."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-957",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08630",
    "b_title":[
      "On principal eigenvalues of linear time-periodic parabolic systems:\n  symmetric mutation case"
    ],
    "b_abstract":[
      "The paper is concerned with the effect of the spatio-temporal heterogeneity\non the principal eigenvalue of some linear time-periodic parabolic system.\nVarious asymptotic behaviors of the principal eigenvalue and its monotonicity,\nas a function of the diffusion rate and frequency, are first derived. In\nparticular, some singular behaviors of the principal eigenvalues are observed\nwhen both diffusion rate and frequency approach zero, with some scalar\ntime-periodic Hamilton-Jacobi equation as the limiting equation. Furthermore,\nwe completely classify the topological structures of the level sets for the\nprincipal eigenvalues in the plane of frequency and diffusion rate. Our results\nnot only generalize most of the findings in [S. Liu and Y. Lou, J. Funct.\nAnal., 282 (2022), 109338] for scalar periodic-parabolic operators, but also\nreveal more rich global information, for time-periodic parabolic systems, on\nthe dependence of the principal eigenvalues upon the spatio-temporal\nheterogeneity."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.20042",
    "c_title":[
      "Global existence of martingale solutions to stochastic keller-segel\n  system with degenerate diffusion"
    ],
    "c_abstract":[
      "In this paper, we study the stochastic degenerate Keller-Segel system\nperturbed by linear multiplicative noise in a bounded domain $\\mathcal{O}$. We\nestablish the global existence of martingale solutions for this model with any\nnonnegative initial data in $H_{2}^{-1}(\\mathcal{O})$. The main challenge in\nproving the existence of solutions arises from the degeneracy of the porous\nmedia diffusion and the lack of coercivity in the nonlinear chemotactic term.\nTo overcome these difficulties, we construct a solution operator and apply the\nSchauder fixed point theorem within the variational framework."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-958",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15486",
    "b_title":[
      "Tauberian theorems for sequences and the Katznelson--Tzafriri theorem"
    ],
    "b_abstract":[
      "In this note, we present an alternative proof of a quantified Tauberian\ntheorem for vector-valued sequences first proved in \\cite{Sei15_Tauberian}. The\ntheorem relates the decay rate of a bounded sequence with properties of a\ncertain boundary function. We present a slightly strengthened version of this\nresult, and illustrate how it can be used to obtain quantified versions of the\nKatznelson--Tzafriri theorem as well as results on Ritt operators."
    ],
    "b_categories":[
      [
        "math.FA"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.16341",
    "c_title":[
      "An algebraic characterization of linearity for additive maps preserving\n  orthogonality"
    ],
    "c_abstract":[
      "We study when an additive mapping preserving orthogonality between two\ncomplex inner product spaces is automatically complex-linear or\nconjugate-linear. Concretely, let $H$ and $K$ be complex inner product spaces\nwith dim$(H)\\geq 2$, and let $A: H\\to K$ be an additive map preserving\northogonality. We obtain that $A$ is zero or a positive scalar multiple of a\nreal-linear isometry from $H$ into $K$. We further prove that the following\nstatements are equivalent:\n  $(a)$ $A$ is complex-linear or conjugate-linear.\n  $(b)$ For every $z\\in H$ we have $A(i z) \\in \\{\\pm i A(z)\\}$.\n  $(c)$ There exists a non-zero point $z\\in H$ such that $A(i z) \\in \\{\\pm i\nA(z)\\}$.\n  $(d)$ There exists a non-zero point $z\\in H$ such that $i A(z) \\in A(H)$.\n  The mapping $A$ neither is complex-linear nor conjugate-linear if, and only\nif, there exists a non-zero $x\\in H$ such that $i A(x)\\notin A(H)$\n(equivalently, for every non-zero $x\\in H$, $i A(x)\\notin A(H)$).\n  Among the consequences we show that, under the hypothesis above, the mapping\n$A$ is automatically complex-linear or conjugate-linear if $A$ has dense range,\nor if $H$ and $K$ are finite dimensional with dim$(K)< 2\\hbox{dim}(H)$."
    ],
    "c_categories":[
      [
        "math.FA"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-959",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.13889",
    "b_title":[
      "Investigation of effects of pairing correlations on calculated\n  $\\beta$-decay half-lives of fp-shell nuclei"
    ],
    "b_abstract":[
      "Pairing of nucleons plays a key role in solving various nuclear physics\nproblems. We investigate the probable effects of pairing correlations on the\ncalculated Gamow-Teller (GT) strength distributions and the associated\n$\\beta$-decay half-lives. Computations are performed for a total of 35 fp-shell\nnuclei using the proton-neutron quasiparticle random phase approximation\n(pn-QRPA) model. The nuclei were selected because of their importance in\nvarious astrophysical environments. Pairing gaps are one of the key parameters\nin the pn-QRPA model to compute GT transitions. We employed three different\nvalues of the pairing gaps obtained from three different empirical formulae in\nour calculation. The GT strength distributions changed significantly as the\npairing gap values changed. This in turn resulted in contrasting centroid and\ntotal strength values of the calculated GT distributions and led to differences\nin calculated half-lives using the three schemes. The half-life values computed\nvia the three-term pairing formula, based on separation energies of nucleons,\nwere in best agreement with the measured data. We conclude that the traditional\nchoice of pairing gap values, $\\Delta_p = \\Delta_n = 12\/\\sqrt{A}$, may not lead\nto half-life values in good agreement with measured data. The findings of this\nstudy are interesting but warrant further investigation."
    ],
    "b_categories":[
      [
        "nucl-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.10925",
    "c_title":[
      "$^{106}$Pd: a typical spherical-like nucleus"
    ],
    "c_abstract":[
      "To solve the Cd puzzle (spherical nucleus puzzle), I proposed the concept of\na sphere-like nucleus. Since shape coexistence often occurs in such nuclei,\nexplicit spherical-like spectra are not easily identified. In this letter, I\nfinally find the direct evidence for the existence of the spherical-like\nnucleus. $^{106}$Pd is a typical spherical-like nucleus. The low-lying parts,\nup to the $10_{1}^{+}$ state, under 4000 keV, of the spherical-like spectra are\nverified. By comparison, new theory outperforms the IBM-2. This result\ncompletely disproves the possibility of the phonon excitations of the spherical\nnucleus in the Cd-Pd nuclei region."
    ],
    "c_categories":[
      [
        "nucl-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-960",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08072",
    "b_title":[
      "Anisotropic response of defect bound states to magnetic field in\n  epitaxial FeSn films"
    ],
    "b_abstract":[
      "Crystal defects, whether intrinsic or engineered, drive many fundamental\nphenomena and novel functionalities of quantum materials. Here, we report\nsymmetry-breaking phenomena induced by Sn-vacancy defects on the surface of\nepitaxial Kagome antiferromagnet FeSn films using low-temperature scanning\ntunneling microscopy and spectroscopy. Near the Sn-vacancy defects, anisotropic\nquasiparticle interference patterns are observed in the differential\nconductance dI\/dV maps, indicating two-fold electronic states that break the\n6-fold rotational symmetry of the Kagome layer. Furthermore, the Sn-vacancy\ndefects induce bound states that exhibit anomalous Zeeman shifts under an\nout-of-plane magnetic field, where their energy shifts linearly towards higher\nenergy independent of the direction of the magnetic field. Under an in-plane\nmagnetic field, the shift of the bound state energy also shows a two-fold\noscillating behavior as a function of the azimuth angle. These findings\ndemonstrate defect-enabled new functionalities in Kagome antiferromagnets for\npotential applications in nanoscale spintronic devices."
    ],
    "b_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.10594",
    "c_title":[
      "van der Waals epitaxy of $\\alpha$-MoO$_3$ films on f-mica by pulsed\n  sputter deposition"
    ],
    "c_abstract":[
      "This study examines the growth characteristics and structural properties of\n$\\alpha$-MoO$_3$ thin films with thicknesses ranging from 2.5 to 160 nm,\ndeposited on f-mica and c-sapphire substrates at 400 {\\deg}C. X-ray diffraction\nanalysis reveals that the films are predominantly orthorhombic $\\alpha$-MoO$_3$\nwith a preferred 0k0 orientation along the out-of-plane direction on both\nsubstrates. The d-spacing for the 060 reflection shows a slight reduction with\nincreased thickness, particularly on f-mica, which suggests minimal\nout-of-plane strain in the film and a stabilization of lattice parametes over\nlarger thicknesses. Furthermore, full-width at half maximum measurements\nindicate improved stacking and crystal quality on f-mica compared to\nc-sapphire. The films on f-mica exhibit epitaxial growth with specific\norientation relationships, while films on c-sapphire display a fiber texture.\nThe near-thickness-independent nature of the peak positions on f-mica suggests\nstable lattice parameters and reduced strain accumulation, could be attributed\nto the van der Waals epitaxy. These results highlight the role of substrate\nchoice in $\\alpha$-MoO$_3$ film growth and minimizing strain, providing\nvaluable insights into the tuning of thin-film properties."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-961",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.11444",
    "b_title":[
      "On the concept of center for geometric objects and related problems"
    ],
    "b_abstract":[
      "In this work, we review the concept of center of a geometric object as an\nequivariant map, unifying and generalizing different approaches followed by\nauthors such as C. Kimberling or A. Edmonds. We provide examples to illustrate\nthat this general approach encompasses many interesting spaces of geometric\nobjects arising from different settings. Additionally, we discuss two results\nthat characterize centers for some particular spaces of geometric objects, and\nwe pose five open questions related to the generalization of these\ncharacterizations to other spaces. Finally, we conclude this article by briefly\ndiscussing other central objects and their relation to this concept of center."
    ],
    "b_categories":[
      [
        "math.MG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.09245",
    "c_title":[
      "On the kissing number of the cross-polytope"
    ],
    "c_abstract":[
      "A new upper bound $\\kappa_T(K_n)\\leq 2.9162^{(1+o(1))n}$ for the translative\nkissing number of the $n$-dimensional cross-polytope $K_n$ is proved, improving\non Hadwiger's bound $\\kappa_T(K_n)\\leq 3^n-1$ from 1957. Furthermore, it is\nshown that there exist kissing configurations satisfying $\\kappa_T(K_n)\\geq\n1.1637^{(1-o(1))n}$, which improves on the previous best lower bound $\n\\kappa_T(K_n)\\geq 1.1348^{(1-o(1))n}$ by Talata. It is also shown that the\nlattice kissing number satisfies $\\kappa_L(K_n)< 12(2^n-1)$ for all $n\\geq 1$,\nand that the lattice $D_4^+$ is the unique lattice, up to signed permutations\nof coordinates, attaining the maximum lattice kissing number $\\kappa_L(K_4)=40$\nin four dimensions."
    ],
    "c_categories":[
      [
        "math.MG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-962",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.11530",
    "b_title":[
      "Validating and improving two-fluid simulations of the magnetic field\n  evolution in neutron star cores"
    ],
    "b_abstract":[
      "This paper addresses the evolution of an axially symmetric magnetic field in\nthe core of a neutron star. The matter in the core is modeled as a system of\ntwo fluids, namely neutrons and charged particles, with slightly different\nvelocity fields, controlled by their mutual collisional friction. This problem\nwas addressed in our previous work through the so-called ``fictitious\nfriction'' approach. We study the validity of our previous work and improve it\nby comparing the fictitious friction approach to alternatives, making\napproximations that allow it to be applied to arbitrary magnetic field\nstrengths and using realistic equations of state. We assume the neutron star\ncrust to be perfectly resistive, so its magnetic field reacts instantaneously\nto changes in the core, in which we neglect the effects of Cooper pairing. We\nexplore different approaches to solve the equations to obtain the velocities\nand chemical potential perturbations induced by a given, fixed magnetic field\nconfiguration in the core. We also present a new version of our code to perform\ntime-evolving simulations and discuss the results obtained with it. Our\ncalculations without fictitious friction further confirm that bulk velocity is\ngenerally much greater than ambipolar velocity, leading to faster evolution.\nThese findings align with those with fictitious friction, validating this\napproach. We also find that, in the long term, the star evolves towards a\nbarotropic ``Grad-Shafranov equilibrium,'' where the magnetic force is fully\nbalanced by charged particle fluid forces. Qualitatively, the evolution and the\nfinal equilibrium are independent of the magnetic field strength $B$ and the\nequation of state considered. The timescale to reach this equilibrium is\nproportional to $B^{-2}$ and becomes shorter for equations of state with a\nsmaller gradient of the ratio between the densities of protons and neutrons."
    ],
    "b_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.03811",
    "c_title":[
      "Late-Time Evolution of Magnetized Disks in Tidal Disruption Events"
    ],
    "c_abstract":[
      "In classic time-dependent 1D accretion disk models, the inner radiation\npressure dominated regime is viscously unstable. However, late-time\nobservations of accretion disks formed in tidal disruption events (TDEs) do not\nexhibit evidence of such instabilities. The common theoretical response is to\nmodify the viscosity parametrization, but typically used viscosity\nparametrization are generally ad hoc. In this study, we take a different\napproach, and investigate a time-dependent 1D $\\alpha$-disk model in which the\npressure is dominated by magnetic fields rather than photons. We compare the\ntime evolution of thermally stable, strongly magnetized TDE disks to the\nsimpler linear viscosity model. We find that the light curves of magnetized\ndisks evolve as $L_{\\rm UV}\\propto t^{-5\/6}$ for decades to centuries, and that\nthis same evolution can be reproduced by the linear viscosity model for\nspecific parameter choices. Additionally, we show that TDEs remain UV-bright\nfor many years, suggesting we could possibly find fossil TDEs decades after\ntheir bursts. We estimate that ULTRASAT could detect hundreds of such events,\nproviding an opportunity to study late-stage TDE physics and supermassive black\nhole (SMBH) properties. Finally, we explore the connection between TDE disks\nand quasi-periodic eruptions (QPEs) suggested by recent observations. One\ntheoretical explanation involves TDE disks expanding to interact with extreme\nmass ratio inspirals (EMRIs), which produce X-ray flares as the EMRI passes\nthrough the disk. Our estimates indicate that magnetized TDE disks should\nexhibit QPEs earlier than those observed in AT2019qiz, suggesting that the QPEs\nmay have begun before their first detection."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-963",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.01742",
    "b_title":[
      "Building Safe GenAI Applications: An End-to-End Overview of Red Teaming\n  for Large Language Models"
    ],
    "b_abstract":[
      "The rapid growth of Large Language Models (LLMs) presents significant\nprivacy, security, and ethical concerns. While much research has proposed\nmethods for defending LLM systems against misuse by malicious actors,\nresearchers have recently complemented these efforts with an offensive approach\nthat involves red teaming, i.e., proactively attacking LLMs with the purpose of\nidentifying their vulnerabilities. This paper provides a concise and practical\noverview of the LLM red teaming literature, structured so as to describe a\nmulti-component system end-to-end. To motivate red teaming we survey the\ninitial safety needs of some high-profile LLMs, and then dive into the\ndifferent components of a red teaming system as well as software packages for\nimplementing them. We cover various attack methods, strategies for\nattack-success evaluation, metrics for assessing experiment outcomes, as well\nas a host of other considerations. Our survey will be useful for any reader who\nwants to rapidly obtain a grasp of the major red teaming concepts for their own\nuse in practical applications."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.02893",
    "c_title":[
      "Lowering the Barrier of Machine Learning: Achieving Zero Manual Labeling\n  in Review Classification Using LLMs"
    ],
    "c_abstract":[
      "With the internet's evolution, consumers increasingly rely on online reviews\nfor service or product choices, necessitating that businesses analyze extensive\ncustomer feedback to enhance their offerings. While machine learning-based\nsentiment classification shows promise in this realm, its technical complexity\noften bars small businesses and individuals from leveraging such advancements,\nwhich may end up making the competitive gap between small and large businesses\neven bigger in terms of improving customer satisfaction. This paper introduces\nan approach that integrates large language models (LLMs), specifically\nGenerative Pre-trained Transformer (GPT) and Bidirectional Encoder\nRepresentations from Transformers (BERT)-based models, making it accessible to\na wider audience. Our experiments across various datasets confirm that our\napproach retains high classification accuracy without the need for manual\nlabeling, expert knowledge in tuning and data annotation, or substantial\ncomputational power. By significantly lowering the barriers to applying\nsentiment classification techniques, our methodology enhances competitiveness\nand paves the way for making machine learning technology accessible to a\nbroader audience."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-964",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01519",
    "b_title":[
      "Holonomicity from a Heegaard-Floer Perspective"
    ],
    "b_abstract":[
      "We construct $S^r$-colored knot Floer homologies and prove that they satisfy\ncategorified recurrence relations. The associated Euler characteristic implies\n$q$-holonomicity of the corresponding sequence of colored Alexander\npolynomials, in analogy with the AJ conjecture for colored Jones polynomials."
    ],
    "b_categories":[
      [
        "math.GT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.20728",
    "c_title":[
      "Adjunction inequality for spatially refined $s$-invariants"
    ],
    "c_abstract":[
      "We note an adjunction inequality in $k\\overline{\\mathbb{CP}^2}$ for the\n$s$-version of the $Sq^1$-refinement of Rasmussen's $s$-invariant. This does\nnot hold for general spatial refinements of $s$-invariants."
    ],
    "c_categories":[
      [
        "math.GT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-965",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.12710",
    "b_title":[
      "Cavity Mode Initialization via a Rabi Driven Qubit"
    ],
    "b_abstract":[
      "Microwave cavity modes with long coherence times are used in many different\nquantum computing systems. During normal operation of such systems, these\nmodes, called memory modes, often need to be set to different coherent photonic\noccupations. In this work we present a novel technique we call Rabi Driven\nReset in which the state of a memory mode is transferred into a decaying mode.\nThis is done through a Rabi driven qubit which is coupled to both modes via\nsideband driving tones. The outcome of the method is the initialization of the\nmemory mode at any required coherent state. Simulations are presented to\ndemonstrate the effectiveness of this technique, along with a comparison to an\nexisting coupling method. Our simulations predict an improvement of an order of\nmagnitude in initialization times compared to existing methods."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.07691",
    "c_title":[
      "Time-resolved second-order autocorrelation function of parametric\n  downconversion"
    ],
    "c_abstract":[
      "We study a possibility of measuring the time-resolved second-order\nautocorrelation function of one of two beams generated in type-II parametric\ndownconversion by means of temporal magnification of this beam, bringing its\ncorrelation time from the picosecond to the nanosecond scale, which can be\nresolved by modern photodetectors. We show that such a measurement enables one\nto infer directly the degree of global coherence of that beam, which is linked\nby a simple relation to the number of modes characterizing the entanglement\nbetween the two generated beams. We illustrate the proposed method by an\nexample of photon pairs generated in a periodically poled KTP crystal with a\nsymmetric group velocity matching for various durations of the pump pulse,\nresulting in different numbers of modes. Our theoretical model also shows that\nthe magnified double-heralded autocorrelation function of one beam exhibits a\nlocal maximum around zero delay time, corresponding to photon bunching at a\nshort time scale."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-966",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09496",
    "b_title":[
      "Robust Multimodal Survival Prediction with the Latent Differentiation\n  Conditional Variational AutoEncoder"
    ],
    "b_abstract":[
      "The integrative analysis of histopathological images and genomic data has\nreceived increasing attention for survival prediction of human cancers.\nHowever, the existing studies always hold the assumption that full modalities\nare available. As a matter of fact, the cost for collecting genomic data is\nhigh, which sometimes makes genomic data unavailable in testing samples. A\ncommon way of tackling such incompleteness is to generate the genomic\nrepresentations from the pathology images. Nevertheless, such strategy still\nfaces the following two challenges: (1) The gigapixel whole slide images (WSIs)\nare huge and thus hard for representation. (2) It is difficult to generate the\ngenomic embeddings with diverse function categories in a unified generative\nframework. To address the above challenges, we propose a Conditional Latent\nDifferentiation Variational AutoEncoder (LD-CVAE) for robust multimodal\nsurvival prediction, even with missing genomic data. Specifically, a\nVariational Information Bottleneck Transformer (VIB-Trans) module is proposed\nto learn compressed pathological representations from the gigapixel WSIs. To\ngenerate different functional genomic features, we develop a novel Latent\nDifferentiation Variational AutoEncoder (LD-VAE) to learn the common and\nspecific posteriors for the genomic embeddings with diverse functions. Finally,\nwe use the product-of-experts technique to integrate the genomic common\nposterior and image posterior for the joint latent distribution estimation in\nLD-CVAE. We test the effectiveness of our method on five different cancer\ndatasets, and the experimental results demonstrate its superiority in both\ncomplete and missing modality scenarios."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.09187",
    "c_title":[
      "Polygonizing Roof Segments from High-Resolution Aerial Images Using\n  Yolov8-Based Edge Detection"
    ],
    "c_abstract":[
      "This study presents a novel approach for roof detail extraction and\nvectorization using remote sensing images. Unlike previous\ngeometric-primitive-based methods that rely on the detection of corners, our\nmethod focuses on edge detection as the primary mechanism for roof\nreconstruction, while utilizing geometric relationships to define corners and\nfaces. We adapt the YOLOv8 OBB model, originally designed for rotated object\ndetection, to extract roof edges effectively. Our method demonstrates\nrobustness against noise and occlusion, leading to precise vectorized\nrepresentations of building roofs. Experiments conducted on the SGA and\nMelville datasets highlight the method's effectiveness. At the raster level,\nour model outperforms the state-of-the-art foundation segmentation model (SAM),\nachieving a mIoU between 0.85 and 1 for most samples and an ovIoU close to\n0.97. At the vector level, evaluation using the Hausdorff distance, PolyS\nmetric, and our raster-vector-metric demonstrates significant improvements\nafter polygonization, with a close approximation to the reference data. The\nmethod successfully handles diverse roof structures and refines edge gaps, even\non complex roof structures of new, excluded from training datasets. Our\nfindings underscore the potential of this approach to address challenges in\nautomatic roof structure vectorization, supporting various applications such as\nurban terrain reconstruction."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-967",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.09411",
    "b_title":[
      "Towards Robust and Realistic Human Pose Estimation via WiFi Signals"
    ],
    "b_abstract":[
      "Robust WiFi-based human pose estimation is a challenging task that bridges\ndiscrete and subtle WiFi signals to human skeletons. This paper revisits this\nproblem and reveals two critical yet overlooked issues: 1) cross-domain gap,\ni.e., due to significant variations between source-target domain pose\ndistributions; and 2) structural fidelity gap, i.e., predicted skeletal poses\nmanifest distorted topology, usually with misplaced joints and disproportionate\nbone lengths. This paper fills these gaps by reformulating the task into a\nnovel two-phase framework dubbed DT-Pose: Domain-consistent representation\nlearning and Topology-constrained Pose decoding. Concretely, we first propose a\ntemporal-consistent contrastive learning strategy with uniformity\nregularization, coupled with self-supervised masking-reconstruction operations,\nto enable robust learning of domain-consistent and motion-discriminative\nWiFi-specific representations. Beyond this, we introduce a simple yet effective\npose decoder with task prompts, which integrates Graph Convolution Network\n(GCN) and Transformer layers to constrain the topology structure of the\ngenerated skeleton by exploring the adjacent-overarching relationships among\nhuman joints. Extensive experiments conducted on various benchmark datasets\nhighlight the superior performance of our method in tackling these fundamental\nchallenges in both 2D\/3D human pose estimation tasks."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.15616",
    "c_title":[
      "IPVTON: Image-based 3D Virtual Try-on with Image Prompt Adapter"
    ],
    "c_abstract":[
      "Given a pair of images depicting a person and a garment separately,\nimage-based 3D virtual try-on methods aim to reconstruct a 3D human model that\nrealistically portrays the person wearing the desired garment. In this paper,\nwe present IPVTON, a novel image-based 3D virtual try-on framework. IPVTON\nemploys score distillation sampling with image prompts to optimize a hybrid 3D\nhuman representation, integrating target garment features into diffusion priors\nthrough an image prompt adapter. To avoid interference with non-target areas,\nwe leverage mask-guided image prompt embeddings to focus the image features on\nthe try-on regions. Moreover, we impose geometric constraints on the 3D model\nwith a pseudo silhouette generated by ControlNet, ensuring that the clothed 3D\nhuman model retains the shape of the source identity while accurately wearing\nthe target garments. Extensive qualitative and quantitative experiments\ndemonstrate that IPVTON outperforms previous methods in image-based 3D virtual\ntry-on tasks, excelling in both geometry and texture."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-968",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15265",
    "b_title":[
      "Self-assembly of Dipolar Crystals from Magnetic Colloids"
    ],
    "b_abstract":[
      "We study the self-assembly of magnetic colloids using the Stockmayer (SM)\nmodel characterized by short-range Lennard-Jones interactions and long-range\ndipole-dipole interactions. Using molecular dynamics simulations, we design\ncooling protocols that yield perfectly assembled single-domain magnetic\ncrystals. We identify cooling rates at which the system transforms from an\namorphous glass to a crystal, where magnetic ordering promotes crystalline\norder. Remarkably, we observe that the latter develops via a spontaneous\ntransition rather than through the traditional nucleation and growth mechanism.\nFor a weakly dipolar fluid ($\\mu=1$), this self-assembly results in a\nface-centered cubic (FCC) colloidal crystal with dipole moments chained along\nthe (111) direction. For fluids with higher dipole moment ($\\mu = 2.5$), the\ncrystal structure shifts towards a body-centered orthorhombic (BCO) arrangement\ndue to the compression of chains from strong dipolar attractions. These results\nprovide valuable insights into the mechanisms driving crystallization in\nmagnetic fluids, opening new avenues for understanding the formation of\nmagnetically responsive colloidal magnetic crystals with promising\napplications."
    ],
    "b_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.13386",
    "c_title":[
      "Neuromorphic Computing with Microfluidic Memristors"
    ],
    "c_abstract":[
      "Conical microfluidic channels filled with electrolytes exhibit volatile\nmemristive behavior, offering a promising foundation for energy-efficient,\nneuromorphic computing. Here, we integrate these iontronic channels as\nadditional nonlinear element in nonlinear Shinriki-inspired oscillators and\ndemonstrate that they exhibit alternating chaotic and non-chaotic dynamics\nacross a broad frequency range. Exploiting this behavior, we construct XOR and\nNAND gates by coupling three \"Memriki\" oscillators, and we further realize the\nfull set of standard logic gates through combinations of NAND gates. Our\nresults establish a new paradigm for iontronic computing and open avenues for\nscalable, low-power logical operations in microfluidic and bio-inspired\nsystems."
    ],
    "c_categories":[
      [
        "cond-mat.soft"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-969",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16068",
    "b_title":[
      "Poisson kernels on the half-plane are bell-shaped"
    ],
    "b_abstract":[
      "Consider a second-order elliptic operator $L$ in the half-plane $\\mathbb R\n\\times (0, \\infty)$ with coefficients depending only on the second coordinate.\nThe Poisson kernel for $L$ is used in the representation of positive\n$L$-harmonic functions, that is, solutions of $L u = 0$. In probabilistic\nterms, the Poisson kernel is the density function of the distribution of the\ndiffusion in $\\mathbb R \\times (0, \\infty)$ with generator $L$ at the hitting\ntime of the boundary. We prove that the Poisson kernel for $L$ is bell-shaped:\nits $n$th derivative changes sign $n$ times. In particular, it is unimodal and\nit has two inflection points (it is concave, then convex, then concave again)."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.14468",
    "c_title":[
      "Non-radiating elastic sources in inhomogeneous elastic media at corners\n  with applications"
    ],
    "c_abstract":[
      "This paper is concerned with non-radiating elastic sources in inhomogeneous\nelastic media. We demonstrate that the value of non-radiating elastic sources\nmust vanish at convex corners of their support, provided the sources exhibit\nH\\\"older continuous regularity near the corner. Additionally, their gradient\nmust satisfy intricate algebraic relationships with the angles defining the\nunderlying corners, assuming the sources have $C^{1,\\alpha}$ regularity with\n$\\alpha\\in (0,1)$ in the neighborhood of the corners. To perform microlocal\nanalysis around the corners, we employ the so-called complex geometrical optics\n(CGO) solutions as test functions within a partial differential system. These\ncharacterizations of non-radiating elastic sources in inhomogeneous elastic\nmedia at corners enable us to establish the unique identifiability results for\ndetermining the position and shape of radiating elastic sources by a single\nfar-field measurement, both locally and globally. The uniqueness result by a\nsingle far-field measurement is a challenging problem with a colorful history\nin inverse scattering. Indeed, when the support of a radiating elastic source\nis a convex polygon, we can simultaneously determine the shape of the elastic\nsource and its values at the corners, provided the source is H\\\"older\ncontinuous at the corner. Furthermore, when the source function exhibits\n$C^{1,\\alpha}$ regularity in the neighborhood of a corner, the gradient of the\nsource function at that corner can also be generically determined."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-970",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15449",
    "b_title":[
      "Breaking the SSL-AL Barrier: A Synergistic Semi-Supervised Active\n  Learning Framework for 3D Object Detection"
    ],
    "b_abstract":[
      "To address the annotation burden in LiDAR-based 3D object detection, active\nlearning (AL) methods offer a promising solution. However, traditional active\nlearning approaches solely rely on a small amount of labeled data to train an\ninitial model for data selection, overlooking the potential of leveraging the\nabundance of unlabeled data. Recently, attempts to integrate semi-supervised\nlearning (SSL) into AL with the goal of leveraging unlabeled data have faced\nchallenges in effectively resolving the conflict between the two paradigms,\nresulting in less satisfactory performance. To tackle this conflict, we propose\na Synergistic Semi-Supervised Active Learning framework, dubbed as S-SSAL.\nSpecifically, from the perspective of SSL, we propose a Collaborative\nPseudoScene Pre-training (CPSP) method that effectively learns from unlabeled\ndata without introducing adverse effects. From the perspective of AL, we design\na Collaborative Active Learning (CAL) method, which complements the uncertainty\nand diversity methods by model cascading. This allows us to fully exploit the\npotential of the CPSP pre-trained model. Extensive experiments conducted on\nKITTI and Waymo demonstrate the effectiveness of our S-SSAL framework. Notably,\non the KITTI dataset, utilizing only 2% labeled data, S-SSAL can achieve\nperformance comparable to models trained on the full dataset. The code has been\nreleased at https:\/\/github.com\/LandDreamer\/S_SSAL."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.08994",
    "c_title":[
      "RepVideo: Rethinking Cross-Layer Representation for Video Generation"
    ],
    "c_abstract":[
      "Video generation has achieved remarkable progress with the introduction of\ndiffusion models, which have significantly improved the quality of generated\nvideos. However, recent research has primarily focused on scaling up model\ntraining, while offering limited insights into the direct impact of\nrepresentations on the video generation process. In this paper, we initially\ninvestigate the characteristics of features in intermediate layers, finding\nsubstantial variations in attention maps across different layers. These\nvariations lead to unstable semantic representations and contribute to\ncumulative differences between features, which ultimately reduce the similarity\nbetween adjacent frames and negatively affect temporal coherence. To address\nthis, we propose RepVideo, an enhanced representation framework for\ntext-to-video diffusion models. By accumulating features from neighboring\nlayers to form enriched representations, this approach captures more stable\nsemantic information. These enhanced representations are then used as inputs to\nthe attention mechanism, thereby improving semantic expressiveness while\nensuring feature consistency across adjacent frames. Extensive experiments\ndemonstrate that our RepVideo not only significantly enhances the ability to\ngenerate accurate spatial appearances, such as capturing complex spatial\nrelationships between multiple objects, but also improves temporal consistency\nin video generation."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-971",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.15373",
    "b_title":[
      "Vertex correction for the linear and nonlinear optical responses in\n  superconductors: multiband effect and topological superconductivity"
    ],
    "b_abstract":[
      "Intensive research has revealed intriguing optical responses in topological\nmaterials. This paper focuses on the optical responses in $s$-wave\nsuperconductors with a Rashba spin-orbit coupling and a magnetic field, one of\nthe platforms of topological superconductivity. On the one hand, to satisfy\nsome conservation laws in superconducting responses, it is essential to take\ninto account collective excitation modes. On the other hand, the optical\nresponse is a promising phenomenon for detecting hidden collective modes in\nsuperconductors. In this paper, we investigate the effect of collective\nexcitation modes on the linear and second-order optical responses based on the\nself-consistent response approximation, which is formulated using the\nKadanoff-Baym method. Our main results reveal that the Higgs mode enhances the\noptical responses when the Fermi level is close to the Dirac point. The\nenhancement is due to the multiband effects characterized by interband pairing.\nWe also demonstrate the sign reversal of the photocurrent conductivity around\nthe topological transition with increasing the Zeeman field. This finding\nsupports the prediction in our previous work without considering collective\nexcitation modes [H. Tanaka, et al., Phys. Rev. B 110, 014520 (2024)]. The sign\nreversal phenomenon is attributed to the magnetic injection current modified by\nthe Higgs mode, and is proposed for a bulk probe of topological\nsuperconductors. We also discuss the interplay of quantum geometry and\ncollective modes."
    ],
    "b_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.02706",
    "c_title":[
      "Critical Current, Lengthwise Fluctuations, and Flux Jumps in REBCO CC: A\n  Torque Magnetometry Study up to 45 T"
    ],
    "c_abstract":[
      "Rare Earth Barium Copper Oxide (REBCO) coated conductors (CCs) have emerged\nfor future high field magnets in fields and temperatures inaccessible for Nb\nbased superconductors. However, their exceptionally high current densities pose\nchallenges for low temperature characterization. This paper presents the design\nand implementation of a simple torque magnetometer that is particularly\nsuitable for characterizing REBCO CC. It details the construction and\nunderlying physics, with a particular emphasis on its capability to assess the\nangular critical currents Ic in high magnetic fields and low temperatures. The\nstudy includes characterizations of multiple REBCO samples from different\nmanufacturers, performed under magnetic fields up to 45 T, demonstrating the\nexceptional capabilities of REBCO CCs in extreme fields. The results revealed\nsignificant lengthwise Ic variations, especially in tapes cut from the edges of\n12 mm-wide production tapes compared to those cut from the center. These\nvariations are most pronounced when the field is near the ab plane.\nImportantly, flux jumps are observed in samples with thick REBCO layers and\nthin stabilizers, underscoring the potential thermal instabilities. These\nfindings provide valuable insights into the performance of REBCO tapes under\nextreme magnetic fields, highlighting their relevance for high-field magnet and\nnuclear fusion applications."
    ],
    "c_categories":[
      [
        "cond-mat.supr-con"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-972",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.02799",
    "b_title":[
      "Hausdorffness of certain nilpotent cohomology spaces"
    ],
    "b_abstract":[
      "Let $(\\pi,V)$ be a smooth representation of a compact Lie group $G$ on a\nquasi-complete locally convex complex topological vector space. We show that\nthe Lie algebra cohomology space $\\mathrm{H} ^\\bullet(\\mathfrak{u}, V)$ and the\nLie algebra homology space $\\mathrm{H}_\\bullet(\\mathfrak{u}, V)$ are both\nHausdorff, where $\\mathfrak{u}$ is the nilpotent radical of a parabolic\nsubalgebra of the complexified Lie algebra $\\mathfrak{g}$ of $G$."
    ],
    "b_categories":[
      [
        "math.RT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.09406",
    "c_title":[
      "Permutation modules of the walled Brauer algebras"
    ],
    "c_abstract":[
      "In this article, we study the permutation modules and Young modules of the\ngroup algebras of the direct product of symmetric groups $K\\mathfrak{S}_{a,b}$,\nand the walled Brauer algebras $\\B_{r,t}(\\delta)$. In the category of dual\nSpecht-filtered modules, if the characteristic of the field is neither $2$ nor\n$3$, then the permutation modules are dual Specht filtered, and the Young\nmodules are relative projective cover of the dual Specht modules. We prove that\nthe restriction of the cell modules of $\\B_{r,t}(\\delta)$ to the group algebras\nof the direct product of the symmetric groups is dual Specht filtered, and the\nYoung modules act as the relative projective cover of the cell modules of\n$\\B_{r,t}(\\delta)$. Finally, we prove that if $\\mathrm{char}~K \\neq 2,3$, then\nthe permutation module of $\\B_{r,t}(\\delta)$ can be written as a direct sum of\nindecomposable Young modules."
    ],
    "c_categories":[
      [
        "math.RT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-973",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16362",
    "b_title":[
      "Global well-posedness for the Navier-Stokes system in new critical\n  mixed-norm Besov spaces"
    ],
    "b_abstract":[
      "In this work, we proved the existence of a unique global mild solution of the\nd-dimensional incompressible Navier-Stokes equations, for small initial data in\nBesov type spaces based on mixed-Lebesgue spaces; namely, mixed-norm\nBesov-Lebesgue spaces and also mixed-norm Fourier-Besov-Lebesgue spaces. The\nmain tools are the Bernstein's type inequalities, Bony's paraproduct to\nestimate the bilinear term and a fixed point scheme in order to get the\nwell-posedness. Our results complement and cover previous and recents result on\n(Fourier-)Besov spaces and, for instance, provide a new class of initial data\npossibly not included in BMO^{-1}(R^3) but continuously included in\n\\dot{B}^{-1}_{\\infty,infty}(R^3)."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.06015",
    "c_title":[
      "Nonlinear partial differential equations in neuroscience: from modelling\n  to mathematical theory"
    ],
    "c_abstract":[
      "Many systems of partial differential equations have been proposed as\nsimplified representations of complex collective behaviours in large networks\nof neurons. In this survey, we briefly discuss their derivations and then\nreview the mathematical methods developed to handle the unique features of\nthese models, which are often nonlinear and non-local. The first part focuses\non parabolic Fokker-Planck equations: the Nonlinear Noisy Leaky Integrate and\nFire neuron model, stochastic neural fields in PDE form with applications to\ngrid cells, and rate-based models for decision-making. The second part concerns\nhyperbolic transport equations, namely the model of the Time Elapsed since the\nlast discharge and the jump-based Leaky Integrate and Fire model. The last part\ncovers some kinetic mesoscopic models, with particular attention to the kinetic\nVoltage-Conductance model and FitzHugh-Nagumo kinetic Fokker-Planck systems."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-974",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09818",
    "b_title":[
      "On the robustness of multimodal language model towards distractions"
    ],
    "b_abstract":[
      "Although vision-language models (VLMs) have achieved significant success in\nvarious applications such as visual question answering, their resilience to\nprompt variations remains an under-explored area. Understanding how\ndistractions affect VLMs is crucial for improving their real-world\napplicability, as inputs could have noisy and irrelevant information in many\npractical scenarios. This paper aims to assess the robustness of VLMs against\nboth visual and textual distractions in the context of science question\nanswering. Built on the ScienceQA dataset, we developed a new benchmark that\nintroduces distractions in both the visual and textual contexts to evaluate the\nreasoning capacity of VLMs amid these distractions. Our findings reveal that\nmost-of-the-art VLMs, including GPT-4, are vulnerable to various types of\ndistractions, experiencing noticeable degradation in reasoning capabilities\nwhen confronted with distractions. Notably, models such as InternVL2\ndemonstrate a higher degree of robustness to these distractions. We also found\nthat models exhibit greater sensitivity to textual distractions than visual\nones. Additionally, we explored various mitigation strategies, such as prompt\nengineering, to counteract the impact of distractions. While these strategies\nimproved solution accuracy, our analysis shows that there remain significant\nopportunities for improvement."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.03675",
    "c_title":[
      "SMIR: Efficient Synthetic Data Pipeline To Improve Multi-Image Reasoning"
    ],
    "c_abstract":[
      "Vision-Language Models (VLMs) excel at understanding single images, aided by\nhigh-quality instruction datasets. However, multi-image reasoning remains\nunderexplored in the open-source community due to two key challenges: (1)\nscaling datasets with correlated images and complex reasoning instructions is\nresource-intensive, and (2) robust evaluation benchmarks for multi-image tasks\nare lacking. To address this, we introduce SMiR, a synthetic data-generation\npipeline for multi-image reasoning, along with a high-quality dataset generated\nusing this pipeline. SMiR efficiently extracts correlated images via multimodal\nembeddings, integrates visual and descriptive information, and leverages\nopen-source LLMs to generate quality instructions. Using this approach, we\nproduce 160K synthetic training samples, offering a cost-effective alternative\nto closed-source solutions. Additionally, we present SMiR-Bench, a multi-image\nreasoning benchmark comprising 200 diverse examples across seven complex\nreasoning tasks. SMiR-Bench is multi-turn and employs a VLM judge to evaluate\nfree-form responses, providing a comprehensive assessment of model\nexpressiveness and reasoning capability across modalities. We demonstrate the\neffectiveness of SMiR by fine-tuning open-source VLMs and evaluating them on\nSMiR-Bench."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-975",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.15913",
    "b_title":[
      "A Tutorial on Stream-based Monitoring"
    ],
    "b_abstract":[
      "Stream-based runtime monitoring frameworks are safety assurance tools that\ncheck the runtime behavior of a system against a formal specification. This\ntutorial provides a hands-on introduction to RTLola, a real-time monitoring\ntoolkit for cyber-physical systems and networks. RTLola processes, evaluates,\nand aggregates streams of input data, such as sensor readings, and provides a\nreal-time analysis in the form of comprehensive statistics and logical\nassessments of the system's health. RTLola has been applied successfully in\nmonitoring autonomous systems such as unmanned aircraft. The tutorial guides\nthe reader through the development of a stream-based specification for an\nautonomous drone observing other flying objects in its flight path. Each\ntutorial section provides an intuitive introduction, highlighting useful\nlanguage features and specification patterns, and gives a more in-depth\nexplanation of technical details for the advanced reader. Finally, we discuss\nhow runtime monitors generated from RTLola specifications can be integrated\ninto a variety of systems and discuss different monitoring applications."
    ],
    "b_categories":[
      [
        "cs.LO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.04761",
    "c_title":[
      "Infinite State Model Checking by Learning Transitive Relations"
    ],
    "c_abstract":[
      "We propose a new approach for proving safety of infinite state systems. It\nextends the analyzed system by transitive relations until its diameter D\nbecomes finite, i.e., until constantly many steps suffice to cover all\nreachable states, irrespective of the initial state. Then we can prove safety\nby checking that no error state is reachable in D steps. To deduce transitive\nrelations, we use recurrence analysis. While recurrence analyses can usually\nfind conjunctive relations only, our approach also discovers disjunctive\nrelations by combining recurrence analysis with projections. An empirical\nevaluation of the implementation of our approach in our tool LoAT shows that it\nis highly competitive with the state of the art."
    ],
    "c_categories":[
      [
        "cs.LO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-976",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16559",
    "b_title":[
      "Design of Reward Function on Reinforcement Learning for Automated\n  Driving"
    ],
    "b_abstract":[
      "This paper proposes a design scheme of reward function that constantly\nevaluates both driving states and actions for applying reinforcement learning\nto automated driving. In the field of reinforcement learning, reward functions\noften evaluate whether the goal is achieved by assigning values such as +1 for\nsuccess and -1 for failure. This type of reward function can potentially obtain\na policy that achieves the goal, but the process by which the goal is reached\nis not evaluated. However, process to reach a destination is important for\nautomated driving, such as keeping velocity, avoiding risk, retaining distance\nfrom other cars, keeping comfortable for passengers. Therefore, the reward\nfunction designed by the proposed scheme is suited for automated driving by\nevaluating driving process. The effects of the proposed scheme are demonstrated\non simulated circuit driving and highway cruising. Asynchronous Advantage\nActor-Critic is used, and models are trained under some situations for\ngeneralization. The result shows that appropriate driving positions are\nobtained, such as traveling on the inside of corners, and rapid deceleration to\nturn along sharp curves. In highway cruising, the ego vehicle becomes able to\nchange lane in an environment where there are other vehicles with suitable\ndeceleration to avoid catching up to a front vehicle, and acceleration so that\na rear vehicle does not catch up to the ego vehicle."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.08858",
    "c_title":[
      "SICNav-Diffusion: Safe and Interactive Crowd Navigation with Diffusion\n  Trajectory Predictions"
    ],
    "c_abstract":[
      "To navigate crowds without collisions, robots must interact with humans by\nforecasting their future motion and reacting accordingly. While learning-based\nprediction models have shown success in generating likely human trajectory\npredictions, integrating these stochastic models into a robot controller\npresents several challenges. The controller needs to account for interactive\ncoupling between planned robot motion and human predictions while ensuring both\npredictions and robot actions are safe (i.e. collision-free). To address these\nchallenges, we present a receding horizon crowd navigation method for\nsingle-robot multi-human environments. We first propose a diffusion model to\ngenerate joint trajectory predictions for all humans in the scene. We then\nincorporate these multi-modal predictions into a SICNav Bilevel MPC problem\nthat simultaneously solves for a robot plan (upper-level) and acts as a safety\nfilter to refine the predictions for non-collision (lower-level). Combining\nplanning and prediction refinement into one bilevel problem ensures that the\nrobot plan and human predictions are coupled. We validate the open-loop\ntrajectory prediction performance of our diffusion model on the commonly used\nETH\/UCY benchmark and evaluate the closed-loop performance of our robot\nnavigation method in simulation and extensive real-robot experiments\ndemonstrating safe, efficient, and reactive robot motion."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-977",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.06632",
    "b_title":[
      "Analytic Computation of Vibrational Circular Dichroism Spectra Using\n  Second-Order M{\\o}ller-Plesset Perturbation Theory"
    ],
    "b_abstract":[
      "We present the first analytic-derivative-based formulation of vibrational\ncircular dichroism (VCD) atomic axial tensors for second-order Moller-Plesset\n(MP2) perturbation theory. We compare our implementation to our recently\nreported finite-difference approach and find close agreement, thus validating\nthe new formulation. The new approach is dramatically less computationally\nexpensive than the numerical-derivative method with an overall computational\nscaling of $O(N^6)$. In addition, we report the first fully analytic VCD\nspectrum for (S)-methyloxirane at the MP2 level of theory."
    ],
    "b_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.06409",
    "c_title":[
      "Quadrupolar NMR Relaxation as a Local Probe of Collective Dynamics in\n  Aqueous Alcaline and Alcaline-Earth Chlorides Solutions"
    ],
    "c_abstract":[
      "While nuclear magnetic resonance (NMR) provides valuable insights into the\nlocal environment of many nuclei, the unambiguous interpretation of the signal\nin terms of microscopic dynamics is often difficult, particularly when the\nquadrupolar relaxation mechanism comes into play. Here, we investigate the\nquadrupolar NMR relaxation of cations and anions in aqueous alcaline and\nalcaline-earth chlorides solutions, across a broad range of salt\nconcentrations. Using a combination of DFT calculations and classical molecular\ndynamics simulations, we compute the electric field gradient (EFG) fluctuations\nover the relevant time scales. Predicted NMR relaxation rates are in good\nagreement with experiments from the literature. As previously reported for\nNaCl, we find that the increase in relaxation rate with salt concentration is\nprimarily driven by the slowing of EFG fluctuations, while changes in the\nstatic variance of the EFG play a minor role. We highlight some specific\nfeatures for smaller and divalent cations compared to the other monovalent\nones. Additionally, we assess the relevance of the Stokes-Einstein-Debye model,\nfrequently used to analyze NMR relaxation experiments, for these aqueous\nelectrolytes, and highlight the link between the collective dynamics of the\nliquid underlying the EFG fluctuations at the ion positions and the stress\nfluctuations. Our results generalize observations for Na$^+$ in aqueous NaCl\nsolutions, showing that models assuming a viscous model of the solvent dynamics\nare insufficient to describe EFG fluctuations in these systems and illustrate\nthe relevance of molecular simulations to interpret NMR relaxation experiments\nin terms of microscopic dynamics."
    ],
    "c_categories":[
      [
        "physics.chem-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-978",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.13501",
    "b_title":[
      "Yang-Mills theories at finite temperature quantized in linear covariant\n  gauges: gauge copies and semi-non-perturbative effects"
    ],
    "b_abstract":[
      "We consider four-dimensional Euclidean Yang-Mills theories quantized in the\nmaximal Abelian and linear covariant gauges at finite temperature.\nNon-perturbatively, the Faddeev-Popov procedure must be improved to take into\naccount the existence of the so-called Gribov copies. Tapping on previous\nresults about the elimination of infinitesimal Gribov copies in maximal Abelian\nand linear covariant gauges at zero temperature, we explore the interplay\nbetween finite temperature effects and the removal of gauge copies. We focus in\na hybrid approach where the thermal masses are derived through perturbative\npropagators as a stepping stone for a self-consistent treatment. The resulting\naction collects the effects of the elimination of infinitesimal Gribov copies\nas well as the thermal masses. We verify the existence of three different\nphases for the gluonic degrees of freedom; one of complete confinement at low\ntemperatures, an intermediate one of partial confinement, and one of complete\ndeconfinement at high temperatures."
    ],
    "b_categories":[
      [
        "hep-th"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.17107",
    "c_title":[
      "Bound states around vacuum in scalar ModMax model"
    ],
    "c_abstract":[
      "In this work, we consider a two-dimensional scalar field model inspired by\nthe dimensional reduction of a four-dimensional ModMax theory. Upon projecting\nout the 4D theory down to a 2D theory we obtain a theory which presents a\nconstant electric field and two scalar fields. In order to investigate kinks,\nwe include the presence of a potential and consider the static case with one of\nthe fields in the vacuum, showing that the solutions for the non-uniform field\ncan be mapped into the ones arising from the canonical model. By studying the\nlinear stability of the model, we show that fluctuations around the uniform\nfield are described by a Sturm-Liouville eigenvalue equation whose weight\nfunction depends on the non-uniform solution and the parameter of the ModMax\nmodel. Remarkably, the presence of the aforementioned weight may bring bound\nstates to light, contrary to what occurs in the canonical model."
    ],
    "c_categories":[
      [
        "hep-th"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-979",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.20620",
    "b_title":[
      "Rectifying Belief Space via Unlearning to Harness LLMs' Reasoning"
    ],
    "b_abstract":[
      "Large language models (LLMs) can exhibit advanced reasoning yet still\ngenerate incorrect answers. We hypothesize that such errors frequently stem\nfrom spurious beliefs, propositions the model internally considers true but are\nincorrect. To address this, we propose a method to rectify the belief space by\nsuppressing these spurious beliefs while simultaneously enhancing true ones,\nthereby enabling more reliable inferences. Our approach first identifies the\nbeliefs that lead to incorrect or correct answers by prompting the model to\ngenerate textual explanations, using our Forward-Backward Beam Search (FBBS).\nWe then apply unlearning to suppress the identified spurious beliefs and\nenhance the true ones, effectively rectifying the model's belief space.\nEmpirical results on multiple QA datasets and LLMs show that our method\ncorrects previously misanswered questions without harming overall model\nperformance. Furthermore, our approach yields improved generalization on unseen\ndata, suggesting that rectifying a model's belief space is a promising\ndirection for mitigating errors and enhancing overall reliability."
    ],
    "b_categories":[
      [
        "cs.CL"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.08825",
    "c_title":[
      "Examining and Adapting Time for Multilingual Classification via Mixture\n  of Temporal Experts"
    ],
    "c_abstract":[
      "Time is implicitly embedded in classification process: classifiers are\nusually built on existing data while to be applied on future data whose\ndistributions (e.g., label and token) may change. However, existing\nstate-of-the-art classification models merely consider the temporal variations\nand primarily focus on English corpora, which leaves temporal studies less\nexplored, let alone under multilingual settings. In this study, we fill the gap\nby treating time as domains (e.g., 2024 vs. 2025), examining temporal effects,\nand developing a domain adaptation framework to generalize classifiers over\ntime on multiple languages. Our framework proposes Mixture of Temporal Experts\n(MoTE) to leverage both semantic and data distributional shifts to learn and\nadapt temporal trends into classification models. Our analysis shows\nclassification performance varies over time across different languages, and we\nexperimentally demonstrate that MoTE can enhance classifier generalizability\nover temporal data shifts. Our study provides analytic insights and addresses\nthe need for time-aware models that perform robustly in multilingual scenarios."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-980",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17273",
    "b_title":[
      "Real subrank of order-three tensors"
    ],
    "b_abstract":[
      "We study the subrank of real order-three tensors and give an upper bound to\nthe subrank of a real tensor given its complex subrank. Using similar arguments\nto those used by Bernardi-Blekherman-Ottaviani, we show that all subranks\nbetween the minimal typical subrank and the maximal typical subrank, which\nequals the generic subrank, are also typical. We then study small tensor\nformats with more than one typical subrank. In particular, we construct a $3\n\\times 3 \\times 5$-tensor with subrank $2$ and show that the subrank of the $4\n\\times 4 \\times 4$-quaternion multiplication tensor is $2$. Finally, we\nconsider the tensor associated to componentwise complex multiplication in\n$\\mathbb{C}^n$ and show that this tensor has real subrank $n$ - informally, no\nmore than $n$ real scalar multiplications can be carried out using a device\nthat does $n$ complex scalar multiplications. We also prove a version of this\nresult for other real division algebras."
    ],
    "b_categories":[
      [
        "math.AG"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.16255",
    "c_title":[
      "Some reducible and irreducible Brill-Noether loci"
    ],
    "c_abstract":[
      "We investigate limit linear series on chains of elliptic curves, giving a\nsimple proof of a conjecture of Farkas stating the existence of curves with a\ntheta-characteristic with a given number of sections for the expected range of\ngenera. Using the additional structure afforded by considering limit linear\nseries on chains of elliptic curves, we find examples of reducible\nBrill-Noether loci, admitting at least two components, with and without a\ntheta-characteristic respectively. This allows us to display reducible Hilbert\nschemes for $r\\ge 3$ and the largest possible value of $d$, namely $d=g-1$. We\nalso give examples of Brill-Noether loci with three components. On the positive\nside, we provide optimal bounds on the degree under which Brill-Noether loci\nare irreducible when $r=2$."
    ],
    "c_categories":[
      [
        "math.AG"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-981",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.16987",
    "b_title":[
      "Dielectronic recombination studies on Fe$^{2+}$"
    ],
    "b_abstract":[
      "Dielectronic recombination resonance strengths, energy-differential cross\nsections, and recombination rate coefficients are calculated fully\nrelativistically for Fe$^{2+}$ ions. The ground-state and resonance energies\nare determined using the multiconfiguration Dirac-Hartree-Fock method.\nRadiative and auto-ionization rates are computed with a relativistic\nconfiguration interaction method. For the calculation of Auger widths and\nresonance strengths, the continuum electron is treated within the framework of\nthe relativistic distorted-wave model. Notably, the calculated level energies\nfor Fe$^{2+}$ not only align well with experimental results but also show\nimprovements compared to earlier theoretical studies. These fully relativistic\ncalculations provide a more accurate and comprehensive understanding of the\nrecombination process. This is particularly important in astrophysics and\nplasma physics, especially for studying phenomena such as kilonova events."
    ],
    "b_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.06096",
    "c_title":[
      "Theory for the Rydberg states of helium: Comparison with experiment for\n  the $1s24p\\;^1P_1$ state ($n=24$)"
    ],
    "c_abstract":[
      "Recent measurements of the ionization energies of the Rydberg $^1P$ states of\nhelium for principal quantum number $n = 24$ and higher present a new challenge\nto theoretical atomic physics. A long-standing obstacle to high precision\natomic theory for three-body systems is a rapid loss of accuracy for\nvariational calculations with increasing principal quantum number $n$. We show\nthat this problem can be overcome with the use of a ``triple\" basis set in\nHylleraas coordinates. Nonrelativistic energies accurate to 23 significant\nfigures are obtained with basis sets of relatively modest size (6744 terms).\nRelativistic and quantum electrodynamic effects are calculated, including an\nestimate of terms of order $m\\alpha^6$ from a $1\/n^3$ extrapolation, resulting\nin an estimated accuracy of $\\pm$1 kHz. The calculated ionization energy of\n5704 980.348(1) MHz is in excellent agreement with the experimental value 5704\n980.312(95) MHz. These results establish the ionization energy of the\n$1s24p\\;^1P_1$ state as an absolute point of reference for transitions to\nlower-lying states, and they confirm an $11\\sigma$ disagreement between theory\nand experiment in the triplet spectrum of helium. Results are also given for\nthe $1s24p\\;^3P_J$ states in agreement with a recent experiment on the triplet\nRydberg series, thereby confirming a discrepancy of of $0.468 \\pm 0.055$ MHz\nfor the ionization energy of the $1s2s\\;^3S_1$ state."
    ],
    "c_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-982",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.02212",
    "b_title":[
      "A mixed-precision quantum-classical algorithm for solving linear systems"
    ],
    "b_abstract":[
      "We address the problem of solving a system of linear equations via the\nQuantum Singular Value Transformation (QSVT). One drawback of the QSVT\nalgorithm is that it requires huge quantum resources if we want to achieve an\nacceptable accuracy. To reduce the quantum cost, we propose a hybrid\nquantum-classical algorithm that improves the accuracy and reduces the cost of\nthe QSVT by adding iterative refinement in mixed-precision A first quantum\nsolution is computed using the QSVT, in low precision, and then refined in\nhigher precision until we get a satisfactory accuracy. For this solver, we\npresent an error and complexity analysis, and first experiments using the\nquantum software stack myQLM."
    ],
    "b_categories":[
      [
        "quant-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.14366",
    "c_title":[
      "QuGStep: Refining Step Size Selection in Gradient Estimation for\n  Variational Quantum Algorithms"
    ],
    "c_abstract":[
      "Variational quantum algorithms (VQAs) offer a promising approach to solving\ncomputationally demanding problems by combining parameterized quantum circuits\nwith classical optimization. Estimating probabilistic outcomes on quantum\nhardware requires repeated measurements (shots). However, in practice, the\nlimited shot budget introduces significant noise in the evaluation of the\nobjective function. Gradient estimation in VQAs often relies on the\nfinite-difference, which evaluates the noisy objective function at perturbed\ncircuit parameter values. The accuracy of this estimation is highly dependent\non the choice of step size for these perturbations. An inappropriate step size\ncan exacerbate the impact of noise, causing inaccurate gradient estimates and\nhindering the classical optimization in VQAs. This paper proposes QuGStep, an\nalgorithm that addresses the challenge of determining the appropriate step size\nfor finite-difference gradient estimation under a shot budget. QuGStep is\ngrounded in a theorem that proves the optimal step size, which accounts for the\nshot budget, minimizes the error bound in gradient estimation using finite\ndifferences. Numerical experiments approximating the ground state energy of\nseveral molecules demonstrate that QuGStep can identify the appropriate step\nsize for the given shot budget to obtain effective gradient estimation.\nNotably, the step size identified by QuGStep achieved convergence to the ground\nstate energy with over 96% fewer shots compared to using a default step size.\nThese findings highlight the potential of QuGStep to improve the practical\ndeployment and scalability of quantum computing technologies."
    ],
    "c_categories":[
      [
        "quant-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-983",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.09088",
    "b_title":[
      "Derivation and Well-Posedness Analysis of the Higher-Order\n  Benjamin-Bona-Mahony Equation"
    ],
    "b_abstract":[
      "This paper studies the derivation and well-posedness of a class of high -\norder water wave equations, the fifth - order Benjamin - Bona - Mahony (BBM)\nequation. Low - order models have limitations in describing strong nonlinear\nand high - frequency dispersion effects. Thus, it is proposed to improve the\nmodeling accuracy of water wave dynamics on long - time scales through high -\norder correction models. By making small - parameter corrections to the\n$abcd-$system, then performing approximate estimations, the fifth - order BBM\nequation is finally derived.For local well - posedness, the equation is first\ntransformed into an equivalent integral equation form. With the help of\nmultilinear estimates and the contraction mapping principle, it is proved that\nwhen $s\\geq1$, for a given initial value $\\eta_{0}\\in H^{s}(\\mathbb{R})$, the\nequation has a local solution $\\eta \\in C([0, T];H^{s})$, and the solution\ndepends continuously on the initial value. Meanwhile, the maximum existence\ntime of the solution and its growth restriction are given.For global well -\nposedness, when $s\\geq2$, through energy estimates and local theory, combined\nwith conservation laws, it is proved that the initial - value problem of the\nequation is globally well - posed in $H^{s}(\\mathbb{R})$. When $1\\leq s<2$, the\ninitial value is decomposed into a rough small part and a smooth part, and\nevolution equations are established respectively. It is proved that the\ncorresponding integral equation is locally well - posed in $H^{2}$ and the\nsolution can be extended, thus concluding that the initial - value problem of\nthe equation is globally well - posed in $H^{s}$."
    ],
    "b_categories":[
      [
        "math.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.03840",
    "c_title":[
      "Beyond uniqueness: Relaxation calculus of junction conditions for\n  coercive Hamilton-Jacobi equations"
    ],
    "c_abstract":[
      "A junction is a particular network given by the collection of $N\\ge 1$ half\nlines $[0,+\\infty)$ glued together at the origin. On such a junction, we\nconsider evolutive Hamilton-Jacobi equations with $N$ coercive Hamiltonians.\nFurthermore,we consider a general desired junction condition at the origin,\ngiven by some monotone function $F_0:\\R^N\\to \\R$.There is existence and\nuniqueness of solutions which only satisfy weakly the junction condition (at\nthe origin, they satisfy either the desired junction condition or the PDE).We\nshow that those solutions satisfy strongly a relaxed junction condition $\\frak\nR F_0$ (that we can recognize as an effective junction condition). It is\nremarkable that this relaxed condition can be computed in three different but\nequivalent ways: 1) using viscosity inequalities, 2) using Godunov fluxes, 3)\nusing Riemann problems.Our result goes beyond uniqueness theory, in the\nfollowing sense: solutions to two different desired junction conditions $F_0$\nand $F_1$ do coincide if $\\frak R F_0=\\frak R F_1$."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-984",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.05964",
    "b_title":[
      "Hybrid Reduced-Order Models for Turbulent Flows Using Recurrent Neural\n  Architectures"
    ],
    "b_abstract":[
      "Proper-orthogonal decomposition (POD) based reduced-order models (ROM) of\nstructurally dominant fluid flow can support a wide range of engineering\napplications. Yet, although they perform well for unsteady laminar flows, their\nstraightforward extension to turbulent flows fails to capture the effects of\nsmall scale eddies and often leads to divergent solutions. Several approaches\nto mimic nonlinear closure terms modeling techniques within ROM frameworks have\nbeen employed to include the effect of higher modes that are often neglected.\nRecent success of neural network based models show promising results in\nmodeling the effects of turbulence. In this study, we augment POD-ROM with a\nrecurrent neural network (RNN) to develop ROM for turbulent flows. We simulate\na three dimensional flow past a circular cylinder at Reynolds number of 1000.\nWe first compute the POD modes and project the Navier-Stokes equations onto the\nlimited number of modes in a Galerkin approach to develop a conventional ROM\nand LES-inspired ROM for comparison. We then develop a hybrid model by\nintegrating the output of Galerkin projection ROM and long short-term memory\n(LSTM) RNN and term it as a physics-guided machine learning (PGML) model. The\nnovelty of this study is to introduce a hybrid model that integrates LES\ninspired ROM and RNN to achieve more accurate and reliable predictions of\nturbulent flows. The results demonstrate that PGML for higher temporal\ncoefficients outperforms the conventional and LES-inspired ROM."
    ],
    "b_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.19121",
    "c_title":[
      "Analysis on the mechanical jamming of particle flow using impeller-based\n  rheometer"
    ],
    "c_abstract":[
      "We simulated the cohesive particle flow in an impeller-based rheometer using\nDiscrete Element Method (DEM), and we focus on the dynamics of particles around\nthe constriction between the blade and its surrounding vessel wall. The results\nshow that mechanical jamming could transiently and intermittently occur in the\nconstriction, but it is limited in a narrow region and short duration. Larger\nstiffness of particles and lifting flow pattern are more prone to the\noccurrence of jamming. The scaling law used to speed up the DEM simulation by\nreducing particle stiffness may fail for particle flow passing through\nclearance. The mechanical jamming of particles is in low frequency with value\nless than 50 Hz and the duration of an individual jamming event is usually less\nthan 0.04 s. The existence of mechanical jamming is also illustrated by the\nexperiment, where the wear of particle surface is clearly observed with\nscratches and pits."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-985",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.17367",
    "b_title":[
      "Exploring the Properties of Light Diatomic Molecules in Strong Magnetic\n  Fields"
    ],
    "b_abstract":[
      "In this study, we develop and implement a specialized coupled-cluster (CC)\napproach tailored for accurately describing atoms and molecules in strong\nmagnetic fields. Using the open-source Ghent Quantum Chemistry Package\n(\\texttt{GQCP}) in conjunction with the Python-based Simulations of Chemistry\nFramework (\\texttt{PySCF}), we calculate potential energy curves, permanent and\ntransient dipole moments, as well as vibrational spectra for the diatomic\nmolecules H$_2$, HeH$^+$ and LiH under various magnetic field strengths\nadopting a fully non-perturbative treatment. The main computational\ndifficulties stem from the inclusion of the magnetic field in the Hamiltonian,\nin particular, from the presence of the angular momentum operator, which leads\nto a complication of the wave function and introduces a gauge-origin\ndependence. Addressing these challenges requires advanced modifications to\nexisting routines, which we achieve by implementing gauge-comprising atomic\norbitals (GIAOs) by using \\texttt{GQCP}, and the capabilities offered by\n\\texttt{PySCF}. This approach enhances the accuracy and reliability of the CC\ntheory, opening pathways for more comprehensive investigations in molecular\nquantum chemistry at strong magnetic fields."
    ],
    "b_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2503.01681",
    "c_title":[
      "Microcell CPT atomic clock using laser current-actuated power modulation\n  with 10$^{-12}$ range stability at 1 day"
    ],
    "c_abstract":[
      "We present a coherent-population trapping (CPT) microcell atomic clock using\nsymmetric auto-balanced Ramsey (SABR) spectroscopy. The pulsed SABR sequence is\napplied through direct current-based power modulation of the vertical-cavity\nsurface-emitting laser, eliminating the need for an external optical shutter\nand enabling compatibility with fully-integrated clocks. The sequence is\ncontrolled by a single FPGA-based digital electronics board. A key aspect of\nproper clock operation was the implementation of a real-time tracking of the\natomic signal detection window. The clock frequency dependence on laser power,\nmicrowave power, laser frequency, and timing of the detection window has been\nmeasured, obtaining sensitivity coefficients lower than those obtained with\nRamsey-CPT spectroscopy. The Allan deviation of the SABR-CPT clock, based on a\nmicrofabricated cell with low-permeation glass windows, is\n1.1~$\\times$~10$^{-9}$ at 1~s and averages down to the low 10$^{-12}$ range at\n1 day integration time. These results pave the way towards the development of\nRamsey-CPT chip-scale atomic clocks with enhanced timekeeping performances."
    ],
    "c_categories":[
      [
        "physics.atom-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-986",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.06308",
    "b_title":[
      "Adaptive multi-wave sampling for efficient chart validation"
    ],
    "b_abstract":[
      "Computable phenotypes are used to characterize patients and identify outcomes\nin studies conducted using healthcare claims and electronic health record data.\nChart review studies establish reference labels against which computable\nphenotypes are compared to understand their measurement characteristics, the\nquantity of interest, for instance the positive predictive value. We describe a\nmethod to adaptively evaluate a quantity of interest over sequential samples of\ncharts, with the goal to minimize the number of charts reviewed. With the help\nof a simultaneous confidence band, we stop the reviewing once the confidence\nband meets a pre-specified stopping threshold. The contribution of this article\nis threefold. First, we tested the use of an adaptive approach called Neyman's\nsampling of charts versus random or stratified random sampling. Second, we\npropose frequentist confidence bands and Bayesian credible intervals to\nsequentially evaluate the quantity of interest. Third, we propose a tool to\npredict the stopping time (defined as the number of charts reviewed) at which\nthe chart review would be complete. We observe that Bayesian credible intervals\nproved to be tighter than its frequentist confidence band counterparts.\nMoreover, we observe that simple random sampling is often performing similarly\nto Neyman's sampling."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.04924",
    "c_title":[
      "A Nonparametric Bayesian Model to Adjust for Monitoring Bias with an\n  Application to Identifying Environments Stressed by Climate Change"
    ],
    "c_abstract":[
      "We propose a new method to adjust for the bias that occurs when an individual\nmonitors a location and reports the status of an event. For example, a monitor\nmay visit a plant each week and report whether the plant is in flower or not.\nThe goal is to estimate the time the event occurred at that location. The\nproblem is that popular estimators often incur bias both because the event may\nnot coincide with the arrival of the monitor and because the monitor may report\nthe status in error. To correct for this bias, we propose a nonparametric\nBayesian model that uses monotonic splines to estimate the event time. We first\ndemonstrate the problem and our proposed solution using simulated data. We then\napply our method to a real-world example from phenology in which lilac are\nmonitored by citizen scientists in the northeastern United States, and the\ntiming of the flowering is used to study anthropogenic warming. Our analysis\nsuggests that common methods fail to account for monitoring bias and\nunderestimate the peak bloom date of the lilac by 48 days on average. In\naddition, after adjusting for monitoring bias, several locations had\nanomalously late bloom dates that did not appear anomalous before adjustment.\nOur findings underscore the importance of accounting for monitoring bias in\nevent-time estimation. By applying our nonparametric Bayesian model with\nmonotonic splines, we provide a more accurate approach to estimating bloom\ndates, revealing previously undetected anomalies and improving the reliability\nof citizen science data for environmental monitoring."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-987",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.04839",
    "b_title":[
      "Definitions and examples of algeebraic Morava K-theories"
    ],
    "b_abstract":[
      "Algebraic Morava K-theories are defined by Sechin,Vishik and others as\nquotients of algebraic cobordisms. On the other hand, the author had defined\nthem as some (two degrees) cohomology theories. In this paper, we compare these\ntheories."
    ],
    "b_categories":[
      [
        "math.AT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.14039",
    "c_title":[
      "Dold indices and symmetric powers"
    ],
    "c_abstract":[
      "Results of Macdonald and Dold from the 1960s and '70s expressing the\nLefschetz numbers of symmetric powers of a self-map of a compact ENR in terms\nof the Lefschetz numbers of iterates of the map are extended using the notion\nof a Lefschetz-polynomial functor. Configuration spaces and Borsuk-Ulam\nsymmetric products, as well as symmetric powers, are treated as examples of the\ngeneral method."
    ],
    "c_categories":[
      [
        "math.AT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-988",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.10876",
    "b_title":[
      "Teamwork makes the dream work: LLMs-Based Agents for GitHub README.MD\n  Summarization"
    ],
    "b_abstract":[
      "The proliferation of Large Language Models (LLMs) in recent years has\nrealized many applications in various domains. Being trained with a huge of\namount of data coming from various sources, LLMs can be deployed to solve\ndifferent tasks, including those in Software Engineering (SE). Though they have\nbeen widely adopted, the potential of using LLMs cooperatively has not been\nthoroughly investigated. In this paper, we proposed Metagente as a novel\napproach to amplify the synergy of various LLMs. Metagente is a Multi-Agent\nframework based on a series of LLMs to self-optimize the system through\nevaluation, feedback, and cooperation among specialized agents. Such a\nframework creates an environment where multiple agents iteratively refine and\noptimize prompts from various perspectives. The results of these explorations\nare then reviewed and aggregated by a teacher agent. To study its performance,\nwe evaluated Metagente with an SE task, i.e., summarization of README.MD files,\nand compared it with three well-established baselines, i.e., GitSum, LLaMA-2,\nand GPT-4o. The results show that our proposed approach works efficiently and\neffectively, consuming a small amount of data for fine-tuning but still getting\na high accuracy, thus substantially outperforming the baselines. The\nperformance gain compared to GitSum, the most relevant benchmark, ranges from\n27.63% to 60.43%. More importantly, compared to using only one LLM, Metagente\nboots up the accuracy to multiple folds."
    ],
    "b_categories":[
      [
        "cs.SE"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2501.17739",
    "c_title":[
      "Testing Research Software: An In-Depth Survey of Practices, Methods, and\n  Tools"
    ],
    "c_abstract":[
      "Context: Research software is essential for developing advanced tools and\nmodels to solve complex research problems and drive innovation across domains.\nTherefore, it is essential to ensure its correctness. Software testing plays a\nvital role in this task. However, testing research software is challenging due\nto the software's complexity and to the unique culture of the research software\ncommunity. Aims: Building on previous research, this study provides an in-depth\ninvestigation of testing practices in research software, focusing on test case\ndesign, challenges with expected outputs, use of quality metrics, execution\nmethods, tools, and desired tool features. Additionally, we explore whether\ndemographic factors influence testing processes. Method: We survey research\nsoftware developers to understand how they design test cases, handle output\nchallenges, use metrics, execute tests, and select tools. Results: Research\nsoftware testing varies widely. The primary challenges are test case design,\nevaluating test quality, and evaluating the correctness of test outputs.\nOverall, research software developers are not familiar with existing testing\ntools and have a need for new tools to support their specific needs.\nConclusion: Allocating human resources to testing and providing developers with\nknowledge about effective testing techniques are important steps toward\nimproving the testing process of research software. While many industrial\ntesting tools exist, they are inadequate for testing research software due to\nits complexity, specialized algorithms, continuous updates, and need for\nflexible, custom testing approaches. Access to a standard set of testing tools\nthat address these special characteristics will increase level of testing in\nresearch software development and reduce the overhead of distributing knowledge\nabout software testing."
    ],
    "c_categories":[
      [
        "cs.SE"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-989",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.18906",
    "b_title":[
      "The lifting problem for Galois representations"
    ],
    "b_abstract":[
      "We solve the lifting problem for Galois representations in every dimension\nand in every characteristic. That is, we determine all pairs $(n,k)$, where $n$\nis a positive integer and $k$ is a field of characteristic $p>0$, such that for\nevery field $F$, every continuous homomorphism $\\Gamma_F\\to \\mathrm{GL}_n(k)$\nlifts to $\\mathrm{GL}_n(W_2(k))$, where $\\Gamma_F$ is the absolute Galois group\nof $F$ and $W_2(k)$ is the ring of $p$-typical length $2$ Witt vectors of $k$."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2503.05296",
    "c_title":[
      "Strong $n$-conjectures over rings of integers"
    ],
    "c_abstract":[
      "We study diophantine equations of the form ${a_1 + \\ldots + a_n = 0}$ where\nthe $a_i$'s are assumed to be coprime and to satisfy certain subsum conditions.\nWe are interested in the limit superior of the qualities of the admissible\nsolutions of these equations, a question that in the case ${n = 3}$ is closely\nrelated to the famous $abc$-conjecture. In a previous article, we studied\nmultiple versions of this problem over the ring of rational integers,\nsummarising known results and proving stronger lower bounds. In this article we\nextend our work to the rings of the Gaussian integers and the Hurwitz\nquaternions, where a somewhat different picture emerges. In particular, we\nestablish much stronger lower bounds on qualities than for the rational\nintegers."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-990",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09248",
    "b_title":[
      "Sequential Covariance Fitting for InSAR Phase Linking"
    ],
    "b_abstract":[
      "Traditional Phase-Linking (PL) algorithms are known for their high cost,\nespecially with the huge volume of Synthetic Aperture Radar (SAR) images\ngenerated by Sentinel-1 SAR missions. Recently, a COvariance Fitting\nInterferometric Phase Linking (COFI-PL) approach has been proposed, which can\nbe seen as a generic framework for existing PL methods. Although this method is\nless computationally expensive than traditional PL approaches, COFI-PL exploits\nthe entire covariance matrix, which poses a challenge with the increasing time\nseries of SAR images. However, COFI-PL, like traditional PL approaches, cannot\naccommodate the efficient inclusion of newly acquired SAR images. This paper\novercomes this drawback by introducing a sequential integration of a block of\nnewly acquired SAR images. Specifically, we propose a method for effectively\naddressing optimization problems associated with phase-only complex vectors on\nthe torus based on the Majorization-Minimization framework."
    ],
    "b_categories":[
      [
        "stat.AP"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2501.18393",
    "c_title":[
      "Robust impact localisation on composite aerostructures using kernel\n  design and Bayesian fusion under environmental and operational uncertainties"
    ],
    "c_abstract":[
      "Impact localisation on composite aircraft structures remains a significant\nchallenge due to operational and environmental uncertainties, such as\nvariations in temperature, impact mass, and energy levels. This study proposes\na novel Gaussian Process Regression framework that leverages the order\ninvariance of time difference of arrival (TDOA) inputs to achieve probabilistic\nimpact localisation under such uncertainties. A composite kernel function,\ncombining radial basis function and cosine similarity kernels, is designed\nbased on wave propagation dynamics to enhance adaptability to diverse\nconditions. Additionally, a task covariance kernel is introduced to enable\nmultitask learning, facilitating the joint prediction of spatial coordinates\nwhile capturing interdependencies between outputs. To further improve\nrobustness and accuracy, Bayesian model averaging is employed to dynamically\nfuse kernel predictions, assigning adaptive weights that account for varying\nconditions. Extensive experimental validation on a composite plate, including\nscenarios with large-mass drop tower impacts and small-mass guided drop mass\nimpacts, demonstrates the proposed method's robustness and generalisability.\nNotably, the framework achieves accurate localisation without requiring\ncompensation strategies for variations in temperature or impact mass,\nhighlighting its suitability for real-world applications. The study also\nhighlights the critical role of sample standardisation for preprocessing TDOA\ninputs, demonstrating its superiority over feature standardisation by\npreserving TDOA order invariance and enhancing model compatibility. These\nadvancements establish the proposed method as a reliable and effective solution\nfor structural health monitoring in complex and uncertain operational\nenvironments."
    ],
    "c_categories":[
      [
        "stat.AP"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-991",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.14031",
    "b_title":[
      "Interacting galaxies in the IllustrisTNG simulations -- VIII:\n  Pericentric star formation rate enhancements are driven both by increased\n  fuelling and efficiency"
    ],
    "b_abstract":[
      "Using the TNG100-1 cosmological simulations, we explore how galaxy\nproperties, such as specific star formation rate ($\\rm sSFR=SFR\/M_*$), gas\nfraction ($\\rm f_{gas} \\,= \\, M_{\\rm H}\/M_{*}$), and star formation efficiency\n($\\rm SFE_{H} = SFR\/M_{H}$), change over the course of galaxy-galaxy\ninteractions. We identify 18,534 distinct encounters from the reconstructed\norbits of a sample of massive galaxies ($\\rm M_{*} > 10^{10} \\; \\rm M_{\\odot}$)\nwith companions within a stellar mass ratio of 0.1 to 10. Using these\nencounters, we study the variation of galaxy properties over time as they\napproach and move away from pericentric encounters over a redshift range of $0\n\\leq z < 1$. Following the closest pericentric encounters ($\\leq 50$ kpc) of a\nhost galaxy with its companion, we find that sSFR is enhanced by a factor of\n$1.6 \\pm 0.1$ on average within the central stellar half-mass radius\n(R\\textsubscript{1\/2}) compared to pre-encounter values. Our results show a\ntime delay between pericentre and maximum sSFR enhancement of $\\sim$0.1 Gyr\nwith a mean galaxy separation of 75 kpc. We similarly find that $\\rm f_{gas}$\nis enhanced by a factor of $1.2 \\pm 0.1$, and $\\rm SFE_{H}$ is enhanced by a\nfactor of $1.4 \\pm 0.1$ following the pericentre of an encounter within the\nsame timescale. Additionally, we find evidence of inflowing gas towards the\ncentre, measured by comparing the $\\rm f_{gas}$ and metallicity within the\ncentral R\\textsubscript{1\/2} to the galactic outskirts. We find that\napproximately 70 per cent of the peak sSFR enhancement can be attributed to the\nincrease in $\\rm SFE_{H}$, with the increase in $\\rm f_{gas}$ contributing the\nremaining 30 per cent."
    ],
    "b_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2502.09802",
    "c_title":[
      "Euclid: Finding strong gravitational lenses in the Early Release\n  Observations using convolutional neural networks"
    ],
    "c_abstract":[
      "The Early Release Observations (ERO) from Euclid have detected several new\ngalaxy-galaxy strong gravitational lenses, with the all-sky survey expected to\nfind 170,000 new systems, greatly enhancing studies of dark matter, dark\nenergy, and constraints on the cosmological parameters. As a first step, visual\ninspection of all galaxies in one of the ERO fields (Perseus) was carried out\nto identify candidate strong lensing systems and compared to the predictions\nfrom Convolutional Neural Networks (CNNs). However, the entire ERO data set is\ntoo large for expert visual inspection. In this paper, we therefore extend the\nCNN analysis to the whole ERO data set, using different CNN architectures and\nmethodologies. Using five CNN architectures, we identified 8,469 strong\ngravitational lens candidates from IE-band cutouts of 13 Euclid ERO fields,\nnarrowing them to 97 through visual inspection, including 14 grade A and 31\ngrade B candidates. We present the spectroscopic confirmation of a strong\ngravitational lensing candidate, EUCLJ081705.61+702348.8. The foreground\nlensing galaxy, an early-type system at redshift z = 0.335, and the background\nsource, a star-forming galaxy at redshift z = 1.475 with [O II] emission, are\nboth identified. Lens modeling using the Euclid strong lens modeling pipeline\nreveals two distinct arcs in a lensing configuration, with an Einstein radius\nof 1.18 \\pm 0.03 arcseconds, confirming the lensing nature of the system. These\nfindings highlight the importance of a broad CNN search to efficiently reduce\ncandidates, followed by visual inspection to eliminate false positives and\nachieve a high-purity sample of strong lenses in Euclid."
    ],
    "c_categories":[
      [
        "astro-ph.GA"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-992",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.12723",
    "b_title":[
      "myEye2Wheeler: A Two-Wheeler Indian Driver Real-World Eye-Tracking\n  Dataset"
    ],
    "b_abstract":[
      "This paper presents the myEye2Wheeler dataset, a unique resource of\nreal-world gaze behaviour of two-wheeler drivers navigating complex Indian\ntraffic. Most datasets are from four-wheeler drivers on well-planned roads and\nhomogeneous traffic. Our dataset offers a critical lens into the unique visual\nattention patterns and insights into the decision-making of Indian two-wheeler\ndrivers. The analysis demonstrates that existing saliency models, like\nTASED-Net, perform less effectively on the myEye-2Wheeler dataset compared to\nwhen applied on the European 4-wheeler eye tracking datasets (DR(Eye)VE),\nhighlighting the need for models specifically tailored to the traffic\nconditions. By introducing the dataset, we not only fill a significant gap in\ntwo-wheeler driver behaviour research in India but also emphasise the critical\nneed for developing context-specific saliency models. The larger aim is to\nimprove road safety for two-wheeler users and lane-planning to support a\ncost-effective mode of transport."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2503.02206",
    "c_title":[
      "Language-Guided Visual Perception Disentanglement for Image Quality\n  Assessment and Conditional Image Generation"
    ],
    "c_abstract":[
      "Contrastive vision-language models, such as CLIP, have demonstrated excellent\nzero-shot capability across semantic recognition tasks, mainly attributed to\nthe training on a large-scale I&1T (one Image with one Text) dataset. This kind\nof multimodal representations often blend semantic and perceptual elements,\nplacing a particular emphasis on semantics. However, this could be problematic\nfor popular tasks like image quality assessment (IQA) and conditional image\ngeneration (CIG), which typically need to have fine control on perceptual and\nsemantic features. Motivated by the above facts, this paper presents a new\nmultimodal disentangled representation learning framework, which leverages\ndisentangled text to guide image disentanglement. To this end, we first build\nan I&2T (one Image with a perceptual Text and a semantic Text) dataset, which\nconsists of disentangled perceptual and semantic text descriptions for an\nimage. Then, the disentangled text descriptions are utilized as supervisory\nsignals to disentangle pure perceptual representations from CLIP's original\n`coarse' feature space, dubbed DeCLIP. Finally, the decoupled feature\nrepresentations are used for both image quality assessment (technical quality\nand aesthetic quality) and conditional image generation. Extensive experiments\nand comparisons have demonstrated the advantages of the proposed method on the\ntwo popular tasks. The dataset, code, and model will be available."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-993",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.05907",
    "b_title":[
      "EvoAgent: Agent Autonomous Evolution with Continual World Model for\n  Long-Horizon Tasks"
    ],
    "b_abstract":[
      "Completing Long-Horizon (LH) tasks in open-ended worlds is an important yet\ndifficult problem for embodied agents. Existing approaches suffer from two key\nchallenges: (1) they heavily rely on experiences obtained from human-created\ndata or curricula, lacking the ability to continuously update multimodal\nexperiences, and (2) they may encounter catastrophic forgetting issues when\nfaced with new tasks, lacking the ability to continuously update world\nknowledge. To solve these challenges, this paper presents EvoAgent, an\nautonomous-evolving agent with a continual World Model (WM), which can\nautonomously complete various LH tasks across environments through\nself-planning, self-control, and self-reflection, without human intervention.\nOur proposed EvoAgent contains three modules, i.e., i) the memory-driven\nplanner which uses an LLM along with the WM and interaction memory, to convert\nLH tasks into executable sub-tasks; ii) the WM-guided action controller which\nleverages WM to generate low-level actions and incorporates a self-verification\nmechanism to update multimodal experiences; iii) the experience-inspired\nreflector which implements a two-stage curriculum learning algorithm to select\nexperiences for task-adaptive WM updates. Moreover, we develop a continual\nWorld Model for EvoAgent, which can continuously update the multimodal\nexperience pool and world knowledge through closed-loop dynamics. We conducted\nextensive experiments on Minecraft, compared with existing methods, EvoAgent\ncan achieve an average success rate improvement of 105% and reduce ineffective\nactions by more than 6x."
    ],
    "b_categories":[
      [
        "cs.RO"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.07595",
    "c_title":[
      "Distributed Coverage Control for Time-Varying Spatial Processes"
    ],
    "c_abstract":[
      "Multi-robot systems are essential for environmental monitoring, particularly\nfor tracking spatial phenomena like pollution, soil minerals, and water\nsalinity, and more. This study addresses the challenge of deploying a\nmulti-robot team for optimal coverage in environments where the density\ndistribution, describing areas of interest, is unknown and changes over time.\nWe propose a fully distributed control strategy that uses Gaussian Processes\n(GPs) to model the spatial field and balance the trade-off between learning the\nfield and optimally covering it. Unlike existing approaches, we address a more\nrealistic scenario by handling time-varying spatial fields, where the\nexploration-exploitation trade-off is dynamically adjusted over time. Each\nrobot operates locally, using only its own collected data and the information\nshared by the neighboring robots. To address the computational limits of GPs,\nthe algorithm efficiently manages the volume of data by selecting only the most\nrelevant samples for the process estimation. The performance of the proposed\nalgorithm is evaluated through several simulations and experiments,\nincorporating real-world data phenomena to validate its effectiveness."
    ],
    "c_categories":[
      [
        "cs.RO"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-994",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.08201",
    "b_title":[
      "Scale-Aware Pre-Training for Human-Centric Visual Perception: Enabling\n  Lightweight and Generalizable Models"
    ],
    "b_abstract":[
      "Human-centric visual perception (HVP) has recently achieved remarkable\nprogress due to advancements in large-scale self-supervised pretraining (SSP).\nHowever, existing HVP models face limitations in adapting to real-world\napplications, which require general visual patterns for downstream tasks while\nmaintaining computationally sustainable costs to ensure compatibility with edge\ndevices. These limitations primarily arise from two issues: 1) the pretraining\nobjectives focus solely on specific visual patterns, limiting the\ngeneralizability of the learned patterns for diverse downstream tasks; and 2)\nHVP models often exhibit excessively large model sizes, making them\nincompatible with real-world applications. To address these limitations, we\nintroduce Scale-Aware Image Pretraining (SAIP), a novel SSP framework enabling\nlightweight vision models to acquire general patterns for HVP. Specifically,\nSAIP incorporates three learning objectives based on the principle of\ncross-scale consistency: 1) Cross-scale Matching (CSM) which contrastively\nlearns image-level invariant patterns from multi-scale single-person images; 2)\nCross-scale Reconstruction (CSR) which learns pixel-level consistent visual\nstructures from multi-scale masked single-person images; and 3) Cross-scale\nSearch (CSS) which learns to capture diverse patterns from multi-scale\nmulti-person images. Three objectives complement one another, enabling\nlightweight models to learn multi-scale generalizable patterns essential for\nHVP downstream tasks.Extensive experiments conducted across 12 HVP datasets\ndemonstrate that SAIP exhibits remarkable generalization capabilities across 9\nhuman-centric vision tasks. Moreover, it achieves significant performance\nimprovements over existing methods, with gains of 3%-13% in single-person\ndiscrimination tasks, 1%-11% in dense prediction tasks, and 1%-6% in\nmulti-person visual understanding tasks."
    ],
    "b_categories":[
      [
        "cs.CV"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.12742",
    "c_title":[
      "3D Shape-to-Image Brownian Bridge Diffusion for Brain MRI Synthesis from\n  Cortical Surfaces"
    ],
    "c_abstract":[
      "Despite recent advances in medical image generation, existing methods\nstruggle to produce anatomically plausible 3D structures. In synthetic brain\nmagnetic resonance images (MRIs), characteristic fissures are often missing,\nand reconstructed cortical surfaces appear scattered rather than densely\nconvoluted. To address this issue, we introduce Cor2Vox, the first diffusion\nmodel-based method that translates continuous cortical shape priors to\nsynthetic brain MRIs. To achieve this, we leverage a Brownian bridge process\nwhich allows for direct structured mapping between shape contours and medical\nimages. Specifically, we adapt the concept of the Brownian bridge diffusion\nmodel to 3D and extend it to embrace various complementary shape\nrepresentations. Our experiments demonstrate significant improvements in the\ngeometric accuracy of reconstructed structures compared to previous voxel-based\napproaches. Moreover, Cor2Vox excels in image quality and diversity, yielding\nhigh variation in non-target structures like the skull. Finally, we highlight\nthe capability of our approach to simulate cortical atrophy at the sub-voxel\nlevel. Our code is available at https:\/\/github.com\/ai-med\/Cor2Vox."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-995",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2503.16204",
    "b_title":[
      "Resolution of a paradox: SDSS J1257+5428 can be explained as a\n  descendant of a cataclysmic variable with an evolved donor"
    ],
    "b_abstract":[
      "The existence of the binary system SDSS J1257+5428 has been described as\nparadoxical. Here we investigate under which conditions SDSS J1257+5428 could\nbe understood as a descendant of a cataclysmic variable with an evolved donor\nstar, which is a scenario that has never been explored in detail. We used the\nBSE code for pre-common-envelope (CE) evolution and the MESA code for post-CE\nevolution to run binary evolution simulations and searched for potential\nformation pathways for SDSS J1257+5428 that lead to its observed\ncharacteristics. For the post-CE evolution, we adopted a boosted version of the\nCARB model. We find that SDSS J1257+5428 can be explained as a\npost-cataclysmic-variable system if (i) the progenitor of the extremely\nlow-mass WD was initially a solar-type star that evolved into a subgiant before\nthe onset of mass transfer and underwent hydrogen shell flashes after the mass\ntransfer stopped, (ii) the massive WD was highly or entirely rejuvenated during\nthe cataclysmic variable evolution, and (iii) magnetic braking was strong\nenough to make the evolution convergent. In this case, the torques due to\nmagnetic braking need to be stronger than those provided by the CARB model by a\nfactor of ${\\sim100}$. We conclude that SDSS J1257+5428 can be reasonably well\nexplained as having originated from a cataclysmic variable that hosted an\nevolved donor star and should no longer be regarded as paradoxical. If our\nformation channel is correct, our findings provide further support that\nstronger magnetic braking acts on progenitors of (i) close detached WD\nbinaries, (ii) close detached millisecond pulsar with extremely low-mass WDs,\n(iii) AM CVn binaries, and (iv) ultra-compact X-ray binaries, in comparison to\nthe magnetic braking strength required to explain binaries hosting\nmain-sequence stars and single main-sequence stars."
    ],
    "b_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.12334",
    "c_title":[
      "Period Analysis of Eclipsing Cataclysmic Variable Stars"
    ],
    "c_abstract":[
      "We have performed a study of the orbital properties of seven eclipsing\ncataclysmic variable (CV) binary systems by analyzing photometric time series\nfrom the Transiting Exoplanet Survey Satellite (TESS). We employed Python code\nto determine the eclipse epochs and orbital periods for each system, and\nconstructed O-C diagrams from observed and predicted eclipse epochs. By\nanalyzing the O-C diagrams of our target CVs, we have constrained values for\nchanges in orbital period with time. Our targets include a sample of sources\nfrom each class of non-magnetic, eclipsing CVs: dwarf novae variables, Z Cam\ntype, and U Gem subclasses. We include in our study classical novae variables,\nnova-like variables (including the VY Scl and UX UMa subclasses), and recurrent\nnovae variable stars. We approached this project with goals of developing time\nseries analysis techniques for future undergraduate-level studies of eclipsing\nCVs, and how they may contribute to the understanding of their orbital\nevolution."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-996",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2502.09359",
    "b_title":[
      "Flipping operators and locally harmonic Maass forms"
    ],
    "b_abstract":[
      "In the theory of integral weight harmonic Maass forms of manageable growth,\ntwo key differential operators, the Bol operator and the shadow operator, play\na fundamental role. Harmonic Maass forms of manageable growth canonically split\ninto two parts, and each operator controls one of these parts. A third\noperator, called the flipping operator, exchanges the role of these two parts.\nMaass--Poincar\\'e series (of parabolic type) form a convenient basis of\nnegative weight harmonic Maass forms of manageable growth, and flipping has the\neffect of negating an index. Recently, there has been much interest in locally\nharmonic Maass forms defined by the first author, Kane, and Kohnen. These are\nlifts of Poincar\\'e series of hyperbolic type, and are intimately related to\nthe Shimura and Shintani lifts. In this note, we prove that a similar property\nholds for the flipping operator applied to these Poincar\\'e series."
    ],
    "b_categories":[
      [
        "math.NT"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.10530",
    "c_title":[
      "Smooth Numbers in Short Intervals"
    ],
    "c_abstract":[
      "Let \\( X \\geq y \\geq 2 \\), and let \\( u = \\frac{\\log X}{\\log y} \\). We say a\nnumber is \\textit{$y$-smooth} if all of its prime factors are less than or\nequal to \\( y \\). In this paper, we study the distribution of $y$-smooth\nnumbers in short intervals. In particular, for \\( y \\geq \\exp\\left( (\\log\nX)^{2\/3 + \\epsilon} \\right) \\), we show that the interval \\( [x, x+h] \\)\ncontains a $y$-smooth number for almost all \\( x \\in [X, 2X] \\), provided \\( h\n\\geq \\exp\\left( (1 + \\epsilon) \\left( \\frac{11}{8} u \\log u + 4 \\log \\log X\n\\right) \\right) \\), and \\( X \\) is sufficiently large depending on \\( \\epsilon\n\\). This result improves upon an earlier result by Matom\\\"aki. Additionally, we\nprovide the corresponding ``all intervals\" type result."
    ],
    "c_categories":[
      [
        "math.NT"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-997",
    "date":"",
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.04610",
    "b_title":[
      "Resilient Peer-to-peer Learning based on Adaptive Aggregation"
    ],
    "b_abstract":[
      "Collaborative learning in peer-to-peer networks offers the benefits of\ndistributed learning while mitigating the risks associated with single points\nof failure inherent in centralized servers. However, adversarial workers pose\npotential threats by attempting to inject malicious information into the\nnetwork. Thus, ensuring the resilience of peer-to-peer learning emerges as a\npivotal research objective. The challenge is exacerbated in the presence of\nnon-convex loss functions and non-iid data distributions. This paper introduces\na resilient aggregation technique tailored for such scenarios, aimed at\nfostering similarity among peers' learning processes. The aggregation weights\nare determined through an optimization procedure, and use the loss function\ncomputed using the neighbor's models and individual private data, thereby\naddressing concerns regarding data privacy in distributed machine learning.\nTheoretical analysis demonstrates convergence of parameters with non-convex\nloss functions and non-iid data distributions. Empirical evaluations across\nthree distinct machine learning tasks support the claims. The empirical\nfindings, which encompass a range of diverse attack models, also demonstrate\nimproved accuracy when compared to existing methodologies."
    ],
    "b_categories":[
      [
        "cs.LG"
      ]
    ],
    "b_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "c_id":"2502.11031",
    "c_title":[
      "A Critical Review of Predominant Bias in Neural Networks"
    ],
    "c_abstract":[
      "Bias issues of neural networks garner significant attention along with its\npromising advancement. Among various bias issues, mitigating two predominant\nbiases is crucial in advancing fair and trustworthy AI: (1) ensuring neural\nnetworks yields even performance across demographic groups, and (2) ensuring\nalgorithmic decision-making does not rely on protected attributes. However,\nupon the investigation of \\pc papers in the relevant literature, we find that\nthere exists a persistent, extensive but under-explored confusion regarding\nthese two types of biases. Furthermore, the confusion has already significantly\nhampered the clarity of the community and subsequent development of debiasing\nmethodologies. Thus, in this work, we aim to restore clarity by providing two\nmathematical definitions for these two predominant biases and leveraging these\ndefinitions to unify a comprehensive list of papers. Next, we highlight the\ncommon phenomena and the possible reasons for the existing confusion. To\nalleviate the confusion, we provide extensive experiments on synthetic, census,\nand image datasets, to validate the distinct nature of these biases,\ndistinguish their different real-world manifestations, and evaluate the\neffectiveness of a comprehensive list of bias assessment metrics in assessing\nthe mitigation of these biases. Further, we compare these two types of biases\nfrom multiple dimensions including the underlying causes, debiasing methods,\nevaluation protocol, prevalent datasets, and future directions. Last, we\nprovide several suggestions aiming to guide researchers engaged in bias-related\nwork to avoid confusion and further enhance clarity in the community."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      [
        "Computer Science, Electrical Engineering and Systems Science"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-998",
    "date":"",
    "fields":[
      "Physics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.08827",
    "b_title":[
      "CHEmical-shift selective Adiabatic Pulse (CHEAP): Fast and High\n  Resolution Downfield 3D 1H-MRSI at 7T"
    ],
    "b_abstract":[
      "The key molecules such as triphosphate (ATP), glutathione (GSH), and\nhomocarnosine (hCs) - central to metabolic processes in the human brain remain\nelusive or challenging to detect with upfield 1H-MRSI. Traditional 3D 1H-MRSI\nin vivo faces challenges, including a low signal-to-noise ratio and\nmagnetization transfer effects with water, leading to prolonged measurement\ntimes and reduced resolution. To address these limitations, we propose a\ndownfield 3D-MRSI method aimed at measuring downfield metabolites with enhanced\nspatial resolution, and speed acceptable for clinical practice at 7T. The\nCHEmical-shift selective Adiabatic Pulse (CHEAP) technique was integrated into\necho-planar spectroscopic imaging (EPSI) readout sequence for downfield\nmetabolite and water reference 3D-MRSI. Five healthy subjects and two glioma\npatients were scanned to test the feasibility. In this work, CHEAP-EPSI\ntechnique is shown to significantly enhance spatial the resolution to 0.37 ml\nwhile simultaneously reducing the scan time to 10.5 minutes. Its distinct\nadvantages include low specific absorption rate, effective suppression of water\nand lipid signals, and minimal baseline distortions, making it a valuable tool\nfor research or potentially diagnostic purposes. CHEAP-EPSI improves the\ndetection sensitivity of downfield metabolites like N-acetyl-aspartate (NAA+)\nand DF8.18 (ATP&GSH+), and offers new possibilities for the study of metabolism\nin healthy and diseased brain."
    ],
    "b_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "b_fields":[
      [
        "Physics"
      ]
    ],
    "c_id":"2501.07348",
    "c_title":[
      "Ultrasonic Medical Tissue Imaging Using Probabilistic Inversion:\n  Leveraging Variational Inference for Speed Reconstruction and Uncertainty\n  Quantification"
    ],
    "c_abstract":[
      "Full Waveform Inversion (FWI) is a promising technique for achieving\nhigh-resolution imaging in medical ultrasound. Traditional FWI methods suffer\nfrom issues related to computational efficiency, dependence on initial models,\nand the inability to quantify uncertainty. This study introduces the Stein\nVariational Gradient Descent (SVGD) algorithm into FWI, aiming to improve\ninversion performance and enhance uncertainty quantification. By deriving the\nposterior gradient, the study explores the integration of SVGD with FWI and\ndemonstrates its ability to approximate complex priors. In-silico experiments\nwith synthetic data and real-world breast tissue data highlight the advantages\nof the SVGD-based framework over conventional FWI. SVGD-based FWI improves\ninversion quality, provides more reliable uncertainty quantification, and\noffers a tighter bound for the prior distribution. These findings show that\nprobabilistic inversion is a promising tool for addressing the limitations of\ntraditional FWI methods in ultrasonic imaging of medical tissues."
    ],
    "c_categories":[
      [
        "physics.med-ph"
      ]
    ],
    "c_fields":[
      [
        "Physics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":"neg-d21-999",
    "date":"",
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"",
    "a_abstract":"",
    "explanation":"",
    "b_id":"2501.01923",
    "b_title":[
      "Thermostats without conjugate points"
    ],
    "b_abstract":[
      "We generalize Hopf's theorem to thermostats: the total thermostat curvature\nof a thermostat without conjugate points is non-positive, and vanishes only if\nthe thermostat curvature is identically zero. We further show that, if the\nthermostat curvature is zero, then the flow has no conjugate points, and the\nGreen bundles collapse almost everywhere. Given a thermostat without conjugate\npoints, we prove that the Green bundles are transversal everywhere if and only\nif it admits a dominated splitting. Finally, we provide an example showing that\nHopf's rigidity theorem on the 2-torus cannot be extended to thermostats. It is\nalso the first example of a thermostat with a dominated splitting which is not\nAnosov."
    ],
    "b_categories":[
      [
        "math.DS"
      ]
    ],
    "b_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "c_id":"2502.10969",
    "c_title":[
      "Moser's twist theorem revisited"
    ],
    "c_abstract":[
      "Inspired by the work of Katznelson and Ornstein, we present a short way to\nachieve the almost optimal regularity in Moser's twist theorem. Specifically,\nfor an integrable area-preserving twist map, the invariant circle with a given\nconstant type frequency $\\alpha$ persists under a small perturbation (dependent\non $\\alpha$) of class $C^{3+\\epsilon}$. This result was initially established\nindependently by Herman and R\\\"{u}ssmann in 1983. Our method differs\nessentially from their approaches."
    ],
    "c_categories":[
      [
        "math.DS"
      ]
    ],
    "c_fields":[
      [
        "Mathematics and Statistics"
      ]
    ],
    "y_true":false,
    "research_type":null
  },
  {
    "id":2411.01019,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"A lightweight Convolutional Neural Network based on U shape structure\n  and Attention Mechanism for Anterior Mediastinum Segmentation",
    "a_abstract":"To automatically detect Anterior Mediastinum Lesions (AMLs) in the Anterior\nMediastinum (AM), the primary requirement will be an automatic segmentation\nmodel specifically designed for the AM. The prevalence of AML is extremely low,\nmaking it challenging to conduct screening research similar to lung cancer\nscreening. Retrospectively reviewing chest CT scans over a specific period to\ninvestigate the prevalence of AML requires substantial time. Therefore,\ndeveloping an Artificial Intelligence (AI) model to find location of AM helps\nradiologist to enhance their ability to manage workloads and improve diagnostic\naccuracy for AMLs. In this paper, we introduce a U-shaped structure network to\nsegment AM. Two attention mechanisms were used for maintaining long-range\ndependencies and localization. In order to have the potential of Multi-Head\nSelf-Attention (MHSA) and a lightweight network, we designed a parallel MHSA\nnamed Wide-MHSA (W-MHSA). Maintaining long-range dependencies is crucial for\nsegmentation when we upsample feature maps. Therefore, we designed a Dilated\nDepth-Wise Parallel Path connection (DDWPP) for this purpose. In order to\ndesign a lightweight architecture, we introduced an expanding convolution block\nand combine it with the proposed W-MHSA for feature extraction in the encoder\npart of the proposed U-shaped network. The proposed network was trained on 2775\nAM cases, which obtained an average Dice Similarity Coefficient (DSC) of\n87.83%, mean Intersection over Union (IoU) of 79.16%, and Sensitivity of\n89.60%. Our proposed architecture exhibited superior segmentation performance\ncompared to the most advanced segmentation networks, such as Trans Unet,\nAttention Unet, Res Unet, and Res Unet++.",
    "explanation":"It's leveraging AI in another diffrent domain, namely medical science, to detect Anterior Mediastinum Lesions.",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Anterior mediastinal nodular lesion segmentation from chest computed tomography imaging using UNet based neural network with attention mechanisms"
    ],
    "b_abstract":[
      "Automated detection of anterior mediastinal nodular lesions (AMLs) has significance for clinical usage as it is challenging for radiologists to accurately identify AMLs from chest computed tomography (CT) imaging due to various factors, including poor resolution, variations in intensity and the similarity of the AMLs to other tissues. To assist radiologists in AML detection from chest CT imaging, a UNet-based computer-aided detection (CADe) system is proposed to segment AMLs from slice images of the chest CT scans. The proposed network adopts a modified UNet architecture. To guide the proposed network to selectively focus on AMLs and potentially disregard others in the image, different attention mechanisms are utilized in the proposed network, including the self-attention mechanism and the convolutional block attention module (CBAM). The proposed network was trained and evaluated on 180 chest CT scans which consist of 180 AMLs. 90 AMLs were identified as thymic cysts, and 90 AMLs were diagnosed as thymoma. The proposed network achieved an average dice similarity coefficient (DSC) of 93.23 with 5-fold cross-validation, for which the mean Intersection over Union (IoU), sensitivity and specificity were 90.29, 93.98 and 95.68 respectively. Our method demonstrated an improved segmentation performance over state-of-the-art segmentation networks, including UNet, ResUNet, TransUNet and UNet++. The proposed network employing attention mechanisms exhibited a promising result for segmenting AMLs from chest CT imaging and could be used to automate the AML detection process for achieving improved diagnostic reliability."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b6",
      "b1"
    ],
    "c_title":[
      "Screening for lung cancer: 2023 guideline update from the American Cancer Society",
      "Incidental Anterior Mediastinal Nodular Lesions on\u00a0Chest CT in Asymptomatic Subjects"
    ],
    "c_abstract":[
      "Abstract Lung cancer is the leading cause of mortality and person\u2010years life lost from among US men women. Early detection has been shown to be associated with reduced lung mortality. Our objective was update American Cancer Society (ACS) 2013 screening (LCS) guideline for adults at high risk cancer. The intended provide guidance health care providers their patients who are due a history smoking. ACS Guideline Development Group (GDG) utilized systematic review LCS literature commissioned Preventive Services Task Force 2021 recommendation update; second years since quitting smoking (YSQ); published 2021; two Intervention Surveillance Modeling Network\u2010validated models assess benefits harms screening; an epidemiologic modeling analysis examining effect YSQ aging on risk; updated benefit\u2010to\u2010radiation\u2010risk ratios follow\u2010up examinations. GDG also examined disease burden data National Institute\u2019s Surveillance, Epidemiology, End Results program. Formulation recommendations based quality evidence judgment (incorporating values preferences) about balance harms. judged that overall moderate sufficient support strong individuals meet eligibility criteria. in women aged 50\u201380 reduction deaths across range study designs, inferential supports older than 80 good health. recommends annual low\u2010dose computed tomography asymptomatic currently smoke or formerly smoked have \u226520 pack\u2010year ( , ). Before decision made initiate LCS, should engage shared decision\u2010making discussion qualified professional. For smoked, number not criterion begin stop screening. Individuals receive counseling quit connected cessation resources. comorbid conditions substantially limit expectancy screened. These considered by discussions LCS. If fully implemented, these likelihood significantly reducing death suffering United States.",
      "Objective: The aim of this study was to investigate the prevalence and characteristics of nodular lesions in the anterior mediastinum that had been found incidentally on screening chest computed tomography (CT) in asymptomatic subjects. Methods: We included 56,358 consecutive participants (mean age 52.4 \u00b1 10.5 years; male-female ratio 35,306:21,052) who underwent a baseline low-dose chest CT scan as part of a health checkup from 2006 through 2013. After the presence of anterior mediastinal nodular lesion had been confirmed, their CT findings, confirmatory diagnosis, and interval CT scan were reviewed. The standardized prevalence ratio for thymic epithelial tumor was calculated on the basis of the Republic of Korea cancer statistics for 2014. Results: Of the 56,358 participants, 413 (0.73%) had lesions (95% confidence interval: 0.66-0.80%); the prevalence increased with age (p <0.001) and a history of malignancy (p = 0.005). Of the lesions, 85.2% were smaller than 2 cm, 61.3% were round, and 80.2% had CT attenuation higher than 20 Hounsfield units. Among 51 proven cases, 39 lesions (76.9%) were benign and 12 (23.1%) were malignant. The standardized prevalence ratio for thymic epithelial tumor was 2.04 (95% confidence interval: 1.01-3.42). Of 11 resected thymic epithelial tumors, five were carcinomas, 10 were stage I or II, and all were completely resected without recurrence. Of the 237 unconfirmed cases with a follow-up CT scan, 82.2% were stable, 8.9% had increased, and the other 8.9% had decreased. Conclusions: The prevalence of incidental nodular lesion was 0.73%. Most lesions had CT features that were indistinguishable from thymic epithelial tumors, but a considerable portion of the lesions were suspected to be benign. Incidental thymic epithelial tumors were more prevalent than clinically detected tumors, were early-stage cancer, and showed favorable outcomes."
    ],
    "c_categories":[
      "q-bio.TO",
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.11084,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"BarcodeMamba: State Space Models for Biodiversity Analysis",
    "a_abstract":"DNA barcodes are crucial in biodiversity analysis for building automatic\nidentification systems that recognize known species and discover unseen\nspecies. Unlike human genome modeling, barcode-based invertebrate\nidentification poses challenges in the vast diversity of species and taxonomic\ncomplexity. Among Transformer-based foundation models, BarcodeBERT excelled in\nspecies-level identification of invertebrates, highlighting the effectiveness\nof self-supervised pretraining on barcode-specific datasets. Recently,\nstructured state space models (SSMs) have emerged, with a time complexity that\nscales sub-quadratically with the context length. SSMs provide an efficient\nparameterization of sequence modeling relative to attention-based\narchitectures. Given the success of Mamba and Mamba-2 in natural language, we\ndesigned BarcodeMamba, a performant and efficient foundation model for DNA\nbarcodes in biodiversity analysis. We conducted a comprehensive ablation study\non the impacts of self-supervised training and tokenization methods, and\ncompared both versions of Mamba layers in terms of expressiveness and their\ncapacity to identify \"unseen\" species held back from training. Our study shows\nthat BarcodeMamba has better performance than BarcodeBERT even when using only\n8.3% as many parameters, and improves accuracy to 99.2% on species-level\naccuracy in linear probing without fine-tuning for \"seen\" species. In our\nscaling study, BarcodeMamba with 63.6% of BarcodeBERT's parameters achieved\n70.2% genus-level accuracy in 1-nearest neighbor (1-NN) probing for unseen\nspecies. The code repository to reproduce our experiments is available at\nhttps:\/\/github.com\/bioscan-ml\/BarcodeMamba.",
    "explanation":"The paper talks about the use of BarcodeMamba for better scores in DNA barcode analysis of genomes.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Biological identifications through DNA barcodes"
    ],
    "b_abstract":[
      "Although much biological research depends upon species diagnoses, taxonomic expertise is collapsing.We are convinced that the sole prospect for a sustainable identification capability lies in construction of systems employ DNA sequences as taxon 'barcodes'.We establish mitochondrial gene cytochrome c oxidase I (COI) can serve core global bioidentification system animals.First, we demonstrate COI profiles, derived from low-density sampling higher categories, ordinarily assign newly analysed taxa to appropriate phylum or order.Second, species-level assignments be obtained by creating comprehensive profiles.A model profile, based analysis single individual each 200 closely allied lepidopterans, was 100% successful correctly identifying subsequent specimens.When fully developed, will provide reliable, cost-effective and accessible solution current problem identification.Its assembly also generate important new insights into diversification life rules molecular evolution."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "BarcodeBERT: Transformers for Biodiversity Analysis"
    ],
    "c_abstract":[
      "Understanding biodiversity is a global challenge, in which DNA barcodes - short snippets of that cluster by species play pivotal role. In particular, invertebrates, highly diverse and under-explored group, pose unique taxonomic complexities. We explore machine learning approaches, comparing supervised CNNs, fine-tuned foundation models, barcode-specific masking strategy across datasets varying complexity. While simpler tasks favor CNNs or transformers, challenging species-level identification demands paradigm shift towards self-supervised pretraining. propose BarcodeBERT, the first method for general analysis, leveraging 1.5 M invertebrate barcode reference library. This work highlights how dataset specifics coverage impact model selection, underscores role pretraining achieving high-accuracy barcode-based at genus level. Indeed, without fine-tuning step, BarcodeBERT pretrained on large outperforms DNABERT DNABERT-2 multiple downstream classification tasks. The code repository available https:\/\/github.com\/Kari-Genomics-Lab\/BarcodeBERT"
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.00609,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Tumor Location-weighted MRI-Report Contrastive Learning: A Framework for\n  Improving the Explainability of Pediatric Brain Tumor Diagnosis",
    "a_abstract":"Despite the promising performance of convolutional neural networks (CNNs) in\nbrain tumor diagnosis from magnetic resonance imaging (MRI), their integration\ninto the clinical workflow has been limited. That is mainly due to the fact\nthat the features contributing to a model's prediction are unclear to\nradiologists and hence, clinically irrelevant, i.e., lack of explainability. As\nthe invaluable sources of radiologists' knowledge and expertise, radiology\nreports can be integrated with MRI in a contrastive learning (CL) framework,\nenabling learning from image-report associations, to improve CNN\nexplainability. In this work, we train a multimodal CL architecture on 3D brain\nMRI scans and radiology reports to learn informative MRI representations.\nFurthermore, we integrate tumor location, salient to several brain tumor\nanalysis tasks, into this framework to improve its generalizability. We then\napply the learnt image representations to improve explainability and\nperformance of genetic marker classification of pediatric Low-grade Glioma, the\nmost prevalent brain tumor in children, as a downstream task. Our results\nindicate a Dice score of 31.1% between the model's attention maps and manual\ntumor segmentation (as an explainability measure) with test classification\nperformance of 87.7%, significantly outperforming the baselines. These\nenhancements can build trust in our model among radiologists, facilitating its\nintegration into clinical practices for more efficient tumor diagnosis.",
    "explanation":"The article presents a research involving the use of Computer Science methods to treat problems in Medicine. In this case, applying the use of Convolutional Neural Networks (CNN) for the recognition of pediatric tumors in medical images and Contrastive Learning (CL) to improve the explainability of the model.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Pediatric low-grade glioma: State-of-the-art and ongoing challenges"
    ],
    "b_abstract":[
      "Abstract The most common childhood central nervous system (CNS) tumor is pediatric low-grade glioma (pLGG), representing 30%\u201340% of all CNS tumors in children. Although there high associated morbidity, tumor-related mortality relatively rare. pLGG now conceptualized as a chronic disease, underscoring the importance functional outcomes and quality-of-life measures. A wealth data has emerged about these tumors, including better understanding their natural history molecular drivers, paving way for use targeted inhibitors. While treatments have heralded tremendous promise, challenges remain how to best optimize use, long-term toxicities with inhibitors unknown. International Pediatric Low-Grade Glioma Coalition (iPLGGc) global group physicians scientists expertise focused on addressing key issues. Here, iPLGGc provides an overview current state-of-the-art pLGG, epidemiology, histology, landscape, treatment paradigms, survival outcomes, imaging response, ongoing challenges. This paper also serves introduction 3 other manuscripts (1) preclinical models, (2) consensus framework conducting early-phase clinical trials (3) resistance, rebound, recurrence."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Improving Pediatric Low-Grade Neuroepithelial Tumors Molecular Subtype\n  Identification Using a Novel AUROC Loss Function for Convolutional Neural\n  Networks"
    ],
    "c_abstract":[
      "Pediatric Low-Grade Neuroepithelial Tumors (PLGNT) are the most common pediatric cancer type, accounting for 40% of brain tumors in children, and identifying PLGNT molecular subtype is crucial treatment planning. However, gold standard to determine biopsy, which can be impractical or dangerous patients. This research improves performance Convolutional Neural Networks (CNNs) classifying subtypes through MRI scans by introducing a loss function that specifically model's Area Under Receiver Operating Characteristic (ROC) Curve (AUROC), offering non-invasive diagnostic alternative. In this study, retrospective dataset 339 children with (143 BRAF fusion, 71 V600E mutation, 125 non-BRAF) was curated. We employed CNN model Monte Carlo random data splitting. The baseline trained using binary cross entropy (BCE), achieved an AUROC 86.11% differentiating fusion mutations, improved 87.71% our proposed (p-value 0.045). With multiclass classification, from 74.42% 76. 59% 0.0016)."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.00726,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading\n  with Cataract",
    "a_abstract":"Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a\ncommon complication of diabetes. As two different imaging tools for DR grading,\ncolor fundus photography (CFP) and infrared fundus photography (IFP) are\nhighly-correlated and complementary in clinical applications. To the best of\nour knowledge, this is the first study that explores a novel multi-modal deep\nlearning framework to fuse the information from CFP and IFP towards more\naccurate DR grading. Specifically, we construct a dual-stream architecture\nCross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus\nimage modalities. In particular, a meticulously engineered Cross-Fundus\nAttention (CFA) module is introduced to capture the correspondence between CFP\nand IFP images. Moreover, we adopt both the single-modality and multi-modality\nsupervisions to maximize the overall performance for DR grading. Extensive\nexperiments on a clinical dataset consisting of 1,713 pairs of multi-modal\nfundus images demonstrate the superiority of our proposed method. Our code will\nbe released for public access.",
    "explanation":"The work combines transformers with two distinct methods that evaluate the quality of retinopathy",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Relation Between Retinal Vasculature and Retinal Thickness in Macular Edema"
    ],
    "b_abstract":[
      "This study has investigated the relationship of retinal vasculature and thickness for Macular Edema (ME) subjects. Ninety sets Fluorescein Angiograph (FA) Optical Coherence Tomography (OCT) 54 participants were analyzed. Multivariate analysis using binary logistic regression model was used to association between vessel parameters thickness. The results reveal feature i.e. fractal dimension (FD) as most sensitive parameter changes in associated with ME. Thus, indicating a direct which is caused due neovascular causing exudates, leakages hemorrhages, applications alternate modality detection"
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    ],
    "c_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.05236,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Designing a Light-based Communication System with a Biomolecular\n  Receiver",
    "a_abstract":"Biological systems transduce signals from their surroundings in numerous\nways. This paper introduces a communication system using the light-gated ion\nchannel Channelrhodopsin-2 (ChR2), which causes an ion current to flow in\nresponse to light. Our design includes a ChR2-based receiver along with\nencoding, modulation techniques and detection. Analyzing the resulting\ncommunication system, we discuss the effect of different parameters on the\nperformance of the system. Finally, we discuss its potential design in the\ncontext of bio-engineering and light-based communication and show that the data\nrate scales up with the number of receptors, indicating that high-speed\ncommunication may be possible.",
    "explanation":"The paper is interdisciplinary because it aims to use channelrhodopsin-2 (ChR2), a biomolecule, as a receiver to design a light-based communication system, which is a work related to engineering.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Channelrhodopsin-2, a directly light-gated cation-selective membrane channel"
    ],
    "b_abstract":[
      "Microbial-type rhodopsins are found in archaea, prokaryotes, and eukaryotes. Some of them represent membrane ion transport proteins such as bacteriorhodopsin, a light-driven proton pump, or channelrhodopsin-1 (ChR1), recently identified light-gated channel from the green alga Chlamydomonas reinhardtii . ChR1 ChR2, related microbial-type rhodopsin C. , were shown to be involved generation photocurrents this alga. We demonstrate by functional expression, both oocytes Xenopus laevis mammalian cells, that ChR2 is directly light-switched cation-selective channel. This opens rapidly after absorption photon generate large permeability for monovalent divalent cations. desensitizes continuous light smaller steady-state conductance. Recovery desensitization accelerated extracellular H + negative potential, whereas closing decelerated intracellular expressed mainly under low-light conditions, suggesting involvement photoreception dark-adapted cells. The predicted seven-transmembrane \u03b1 helices characteristic G protein-coupled receptors but reflect different motif Finally, we may used depolarize small simply illumination."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2",
      "b0"
    ],
    "c_title":[
      "Shannon capacity of signal transduction for multiple independent receptors",
      "DESIGN AND IMPLEMENTATION OF VISIBLE LIGHT COMMUNICATION SYSTEM IN INDOOR ENVIRONMENT"
    ],
    "c_abstract":[
      "Cyclic adenosine monophosphate (cAMP) is considered a model system for signal transduction, the mechanism by which cells exchange chemical messages. Our previous work calculated Shannon capacity of single cAMP receptor; however, typical cell may have thousands receptors operating in parallel. In this paper, we calculate transduction with an arbitrary number independent, indistinguishable receptors. By leveraging prior results on feedback receptor, show (somewhat unexpectedly) that achieved IID input distribution, and n times receptor.",
      "Visible Light communication (VLC) using White Light Emitting Diode (LED) is a promising technology for next generation communication for short range, high speed wireless data transmission. In this paper inexpensive transmitter and receiver of VLC system is designed and its performance is evaluated. The effect of natural and artificial ambient light noise sources is also considered. Experimental results show that the data transmission distance achieved upto 0.45m.Performance analysis is done with respect to optical power, photo sensitivity of photodiode at the receiver and the increase in distance between the transmitter and receiver."
    ],
    "c_categories":[
      "cs.SY",
      "eess.SP"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.02815,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Artificial Intelligence-Enhanced Couinaud Segmentation for Precision\n  Liver Cancer Therapy",
    "a_abstract":"Precision therapy for liver cancer necessitates accurately delineating liver\nsub-regions to protect healthy tissue while targeting tumors, which is\nessential for reducing recurrence and improving survival rates. However, the\nsegmentation of hepatic segments, known as Couinaud segmentation, is\nchallenging due to indistinct sub-region boundaries and the need for extensive\nannotated datasets. This study introduces LiverFormer, a novel Couinaud\nsegmentation model that effectively integrates global context with low-level\nlocal features based on a 3D hybrid CNN-Transformer architecture. Additionally,\na registration-based data augmentation strategy is equipped to enhance the\nsegmentation performance with limited labeled data. Evaluated on CT images from\n123 patients, LiverFormer demonstrated high accuracy and strong concordance\nwith expert annotations across various metrics, allowing for enhanced treatment\nplanning for surgery and radiation therapy. It has great potential to reduces\ncomplications and minimizes potential damages to surrounding tissue, leading to\nimproved outcomes for patients undergoing complex liver cancer treatments.",
    "explanation":"The paper presents a tool that uses Convolutional Neural Networks (CNN) and Transformers, technologies from Computer Science, to improve the accuracy and efficiency of Couinaud segmentation in liver cancer treatment, a challenge in the field of Medicine.",
    "b_id":[
      "b36",
      "b33"
    ],
    "b_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "Automated segmentation of liver segment on portal venous phase MR images using a 3D convolutional neural network"
    ],
    "b_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train.",
      "We aim to develop and validate a three-dimensional convolutional neural network (3D-CNN) model for automatic liver segment segmentation on MRI images.This retrospective study evaluated an automated method using deep that was trained, validated, tested with 367, 157, 158 portal venous phase MR images, respectively. The Dice similarity coefficient (DSC), mean surface distance (MSD), Hausdorff (HD), volume ratio (RV) were used quantitatively measure the accuracy of segmentation. time consumed manual also compared. In addition, applied 100 consecutive cases from real clinical scenario qualitative evaluation indirect evaluation.In quantitative evaluation, achieved high DSC, MSD, HD RV (0.920, 3.34, 3.61 1.01, respectively). Compared segmentation, reduced 26 min 8 s. quality rated as good in 79% cases, moderate 15% poor 6%. 93.4% (99\/106) lesions could be assigned correct by only referring results segmentation.The proposed may serve effective tool anatomical region annotation images."
    ],
    "b_categories":[
      "cs.CV",
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Liver Anatomy: Portal (and Suprahepatic) or Biliary Segmentation"
    ],
    "c_abstract":[
      "In liver anatomy and surgery, is portal hepatic vein segmentation (French segmentation) to be preferred over arteriobiliary (Healey Schroy, North American segmentation)?Several embryological arguments an analysis of anatomical data from a personal collection 110 vasculobiliary casts were made.Embryological arguments: Portal branching appears first, secondly follows the distribution. Segment II (the left lateral sector) development right lobe. The umbilical enters portion middle lobe, forming segment IV on III left: this paramedian sector. So fissure (between lobes) transversally crosses classical which not unit. VI late secondary prominence VII, reaching anterior margin only in man. Anatomical must added segmentation; academic lobe sector, separates lobes. preferred: duplication branches first order occurs 23.5% cases, while first-order noted 50% livers, being much simpler.Portal seems more accurate."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.00561,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Automated Classification of Cell Shapes: A Comparative Evaluation of\n  Shape Descriptors",
    "a_abstract":"This study addresses the challenge of classifying cell shapes from noisy\ncontours, such as those obtained through cell instance segmentation of\nhistological images. We assess the performance of various features for shape\nclassification, including Elliptical Fourier Descriptors, curvature features,\nand lower dimensional representations. Using an annotated synthetic dataset of\nnoisy contours, we identify the most suitable shape descriptors and apply them\nto a set of real images for qualitative analysis. Our aim is to provide a\ncomprehensive evaluation of descriptors for classifying cell shapes, which can\nsupport cell type identification and tissue characterization-critical tasks in\nboth biological research and histopathological assessments.",
    "explanation":"This study addresses the challenge of classifying cell shapes from noisy contours, such as those obtained through cell instance segmentation of histological images.\n\nOur aim is to provide a comprehensive evaluation of descriptors for classifying cell shapes, which can support cell type identification and tissue characterization\u2014critical tasks in both biological research and histopathological assessments.\n",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "Retrieval and classification of shape-based objects using Fourier, generic Fourier, and wavelet-Fourier descriptors technique: A comparative study"
    ],
    "b_abstract":[
      "In this paper, we report retrieval and classification of shape-based objects employing three techniques-conventional Fourier descriptors (FD), generic Fourier descriptors (GFD) and wavelet-Fourier descriptors (WFD) techniques. All the three techniques have been applied to a database of seven different types of shapes. The centroid distance based shape signatures have been used for the derivation of descriptors. The Euclidean distance has been calculated as a similarity measure parameter for shape classification. For WFD technique, a Mexican-hat wavelet function was used. Classification results from all the three techniques were compared and it was observed that WFD performs better than FD and GFD technique. To study the effect of the noise on the retrieval and classification of shapes of different objects, additive and multiplicative noise of various variances were applied to the database. Precision and recall were also measured as parameters of performance metric."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "What is a cell type, really? The quest to categorize life's myriad forms."
    ],
    "c_abstract":[
      "The problem of cell type became clear to genome biologist Jason Buenrostro in 2013. He was studying a cell line derived from someone with cancer, trying to map out how the DNA was arranged in the nucleus. The cells should have been pretty much identical, he thought. But the more Buenrostro looked at the DNA, the more differences he found in how it was packaged1. \u201cI realized that there were probably hundreds of flavours,\u201d recalls Buenrostro, who was a graduate student at Stanford University in California at the time."
    ],
    "c_categories":[
      "q-bio.BM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.01144,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"LEARNER: Learning Granular Labels from Coarse Labels using Contrastive\n  Learning",
    "a_abstract":"A crucial question in active patient care is determining if a treatment is\nhaving the desired effect, especially when changes are subtle over short\nperiods. We propose using inter-patient data to train models that can learn to\ndetect these fine-grained changes within a single patient. Specifically, can a\nmodel trained on multi-patient scans predict subtle changes in an individual\npatient's scans? Recent years have seen increasing use of deep learning (DL) in\npredicting diseases using biomedical imaging, such as predicting COVID-19\nseverity using lung ultrasound (LUS) data. While extensive literature exists on\nsuccessful applications of DL systems when well-annotated large-scale datasets\nare available, it is quite difficult to collect a large corpus of personalized\ndatasets for an individual. In this work, we investigate the ability of recent\ncomputer vision models to learn fine-grained differences while being trained on\ndata showing larger differences. We evaluate on an in-house LUS dataset and a\npublic ADNI brain MRI dataset. We find that models pre-trained on clips from\nmultiple patients can better predict fine-grained differences in scans from a\nsingle patient by employing contrastive learning.",
    "explanation":"Recent years have seen increasing use of deep learning\n(DL) in predicting diseases using biomedical imaging, such as\npredicting COVID-19 severity using lung ultrasound (LUS)\ndata.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Investigating training-test data splitting strategies for automated segmentation and scoring of COVID-19 lung ultrasound images."
    ],
    "b_abstract":[
      "Ultrasound in point-of-care lung assessment is becoming increasingly relevant. This is further reinforced in the context of the COVID-19 pandemic, where rapid decisions on the lung state must be made for staging and monitoring purposes. The lung structural changes due to severe COVID-19 modify the way ultrasound propagates in the parenchyma. This is reflected by changes in the appearance of the lung ultrasound images. In abnormal lungs, vertical artifacts known as B-lines appear and can evolve into white lung patterns in the more severe cases. Currently, these artifacts are assessed by trained physicians, and the diagnosis is qualitative and operator dependent. In this article, an automatic segmentation method using a convolutional neural network is proposed to automatically stage the progression of the disease. 1863 B-mode images from 203 videos obtained from 14 asymptomatic individual,14 confirmed COVID-19 cases, and 4 suspected COVID-19 cases were used. Signs of lung damage, such as the presence and extent of B-lines and white lung areas, are manually segmented and scored from zero to three (most severe). These manually scored images are considered as ground truth. Different test-training strategies are evaluated in this study. The results shed light on the efficient approaches and common challenges associated with automatic segmentation methods."
    ],
    "b_categories":[
      "Lung Ultrasound"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "A Simple Framework for Contrastive Learning of Visual Representations"
    ],
    "c_abstract":[
      "This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed self-supervised algorithms without requiring specialized architectures or memory bank. In order to understand what enables the prediction tasks learn useful representations, we systematically study major components our framework. show that (1) composition data augmentations plays critical role in defining effective predictive tasks, (2) introducing learnable nonlinear transformation between representation and loss substantially improves quality learned (3) benefits from larger batch sizes more training steps compared supervised learning. By combining these findings, are able considerably outperform previous methods semi-supervised on ImageNet. A linear classifier trained representations by SimCLR achieves 76.5% top-1 accuracy, which is 7% relative improvement over state-of-the-art, matching performance ResNet-50. When fine-tuned only 1% labels, achieve 85.8% top-5 outperforming AlexNet with 100X fewer labels."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.00922,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Lung tumor segmentation in MRI mice scans using 3D nnU-Net with minimum\n  annotations",
    "a_abstract":"In drug discovery, accurate lung tumor segmentation is an important step for\nassessing tumor size and its progression using \\textit{in-vivo} imaging such as\nMRI. While deep learning models have been developed to automate this process,\nthe focus has predominantly been on human subjects, neglecting the pivotal role\nof animal models in pre-clinical drug development. In this work, we focus on\noptimizing lung tumor segmentation in mice. First, we demonstrate that the\nnnU-Net model outperforms the U-Net, U-Net3+, and DeepMeta models. Most\nimportantly, we achieve better results with nnU-Net 3D models than 2D models,\nindicating the importance of spatial context for segmentation tasks in MRI mice\nscans. This study demonstrates the importance of 3D input over 2D input images\nfor lung tumor segmentation in MRI scans. Finally, we outperform the prior\nstate-of-the-art approach that involves the combined segmentation of lungs and\ntumors within the lungs. Our work achieves comparable results using only lung\ntumor annotations requiring fewer annotations, saving time and annotation\nefforts. This work\n(https:\/\/anonymous.4open.science\/r\/lung-tumour-mice-mri-64BB) is an important\nstep in automating pre-clinical animal studies to quantify the efficacy of\nexperimental drugs, particularly in assessing tumor changes.",
    "explanation":"In this work, we focus on optimizing lung tumor segmen-\ntation in mice. First, we demonstrate that the nnU-Net model outper-\nforms the U-Net, U-Net3+, and DeepMeta models.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Deep learning model for automatic segmentation of lungs and pulmonary metastasis in small animal MR images"
    ],
    "b_abstract":[
      "Lungs are the most frequent site of metastases growth. The amount and size pulmonary acquired from MRI imaging data important criteria to assess efficacy new drugs in preclinical models. While efficient solutions both for MR downstream automatic segmentation have been proposed human patients, lung animal models remains challenging due physiological motion (respiratory cardiac movements), low protons this organ particular challenge precise metastases. As a consequence post-mortem analysis is currently required obtain information on metastatic volume. In work, we developed complete methodological pipeline automated lungs mice, consisting an sequence image acquisition deep learning method On one hand, optimized mouse with high contrast detection sensitivity. other hand DeepMeta, multiclass U-Net 3+ model automatically segment images. To if able provide accurate metastases, longitudinally imaged mice fast- slow-growing metastasis. Fifty-five balb\/c were injected two different derivatives renal carcinoma cells. Mice SG-bSSFP (self-gated balanced steady state free precession) at time points after injection cancer Both segmentations manually performed by experts. DeepMeta was trained perform based resulting ground truth annotations. Volumes as well number per measured separate test dataset Thanks SG method, 3D bSSFP images artifact-free, enabling serial follow-up Moreover, accurately soon they reached volume \u223c0.02mm3 . Thus distinguish groups terms slow versus fast patterns growth We shown that our methodology combining learning, enables processing whole thus viable alternative histology alone."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b12"
    ],
    "c_title":[
      "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "c_abstract":[
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.02695,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"An ADHD Diagnostic Interface Based on EEG Spectrograms and Deep Learning\n  Techniques",
    "a_abstract":"This paper introduces an innovative approach to\nAttention-deficit\/hyperactivity disorder (ADHD) diagnosis by employing deep\nlearning (DL) techniques on electroencephalography (EEG) signals. This method\naddresses the limitations of current behavior-based diagnostic methods, which\noften lead to misdiagnosis and gender bias. By utilizing a publicly available\nEEG dataset and converting the signals into spectrograms, a Resnet-18\nconvolutional neural network (CNN) architecture was used to extract features\nfor ADHD classification. The model achieved a high precision, recall, and an\noverall F1 score of 0.9. Feature extraction highlighted significant brain\nregions (frontopolar, parietal, and occipital lobes) associated with ADHD.\nThese insights guided the creation of a three-part digital diagnostic system,\nfacilitating cost-effective and accessible ADHD screening, especially in school\nenvironments. This system enables earlier and more accurate identification of\nstudents at risk for ADHD, providing timely support to enhance their\ndevelopmental outcomes. This study showcases the potential of integrating EEG\nanalysis with DL to enhance ADHD diagnostics, presenting a viable alternative\nto traditional methods.",
    "explanation":"his paper introduces an innovative approach to\nAttention-deficit\/hyperactivity disorder (ADHD) diagnosis by em-\nploying deep learning (DL) techniques on electroencephalography\n(EEG) signals.  By utilizing a publicly available EEG\ndataset and converting the signals into spectrograms, a Resnet-18\nconvolutional neural network (CNN) architecture was used to ex-\ntract features for ADHD classification. ",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "EEG data for ADHD \/ Control children"
    ],
    "b_abstract":[
      "Participants were 61 children with ADHD and 60 healthy controls (boys and girls, ages 7-12). The ADHD children were diagnosed by an experienced psychiatrist to DSM-IV criteria, and have taken Ritalin for up to 6 months. None of the children in the control group had a history of psychiatric disorders, epilepsy, or any report of high-risk behaviors. EEG recording was performed based on 10-20 standard by 19 channels (Fz, Cz, Pz, C3, T3, C4, T4, Fp1, Fp2, F3, F4, F7, F8, P3, P4, T5, T6, O1, O2) at 128 Hz sampling frequency. The A1 and A2 electrodes were the references located on earlobes. Since one of the deficits in ADHD children is visual attention, the EEG recording protocol was based on visual attention tasks. In the task, a set of pictures of cartoon characters was shown to the children and they were asked to count the characters. The number of characters in each image was randomly selected between 5 and 16, and the size of the pictures was large enough to be easily visible and countable by children. To have a continuous stimulus during the signal recording, each image was displayed immediately and uninterrupted after the child\u2019s response. Thus, the duration of EEG recording throughout this cognitive visual task was dependent on the child\u2019s performance (i.e. response speed)."
    ],
    "b_categories":[
      "Neurotherapeutics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Deep Residual Learning for Image Recognition"
    ],
    "c_abstract":[
      "Deeper neural networks are more difficult to train. We present a residual learning framework ease the training of that substantially deeper than those used previously. explicitly reformulate layers as functions with reference layer inputs, instead unreferenced functions. provide comprehensive empirical evidence showing these easier optimize, and can gain accuracy from considerably increased depth. On ImageNet dataset we evaluate nets depth up 152 - 8\u00d7 VGG [40] but still having lower complexity. An ensemble achieves 3.57% error on test set. This result won 1st place ILSVRC 2015 classification task. also analysis CIFAR-10 100 1000 layers. The representations is central importance for many visual recognition tasks. Solely due our extremely deep representations, obtain 28% relative improvement COCO object detection dataset. Deep foundations submissions & competitions1, where places tasks detection, localization, segmentation."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.03522,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Exploring the Potentials and Challenges of Using Large Language Models\n  for the Analysis of Transcriptional Regulation of Long Non-coding RNAs",
    "a_abstract":"Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.",
    "explanation":"Given the tremendous success of large language mod-\nels (LLMs) in capturing complex dependencies in sequential data, this study aims to systematically explore the potential and limitations of LLMs in the sequence analysis related to the transcriptional regulation of lncRNA genes. ",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Language Models are Few-Shot Learners"
    ],
    "b_abstract":[
      "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training a large corpus of text followed fine-tuning specific task. While typically task-agnostic in architecture, this method still requires task-specific datasets thousands or tens examples. By contrast, humans can generally perform new language task from only few examples simple instructions - something which current systems largely struggle to do. Here we show that scaling up models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art approaches. Specifically, train GPT-3, an autoregressive model 175 billion parameters, 10x more than any previous non-sparse model, test its performance the setting. For all tasks, GPT-3 is applied without gradient updates fine-tuning, demonstrations specified purely via interaction model. achieves strong datasets, including translation, question-answering, cloze as well several require on-the-fly reasoning domain adaptation, such unscrambling words, using novel word sentence, performing 3-digit arithmetic. At same time, also identify some where GPT-3's learning struggles, faces methodological issues related training web corpora. Finally, find generate samples news articles human evaluators have difficulty distinguishing written humans. We discuss broader societal impacts finding general."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b20"
    ],
    "c_title":[
      "Long non-coding RNAs: definitions, functions, challenges and recommendations"
    ],
    "c_abstract":[
      "Genes specifying long non-coding RNAs (lncRNAs) occupy a large fraction of the genomes of complex organisms. The term \u2018lncRNAs\u2019 encompasses RNA polymerase I (Pol I), Pol II and Pol III transcribed RNAs, and RNAs from processed introns. The various functions of lncRNAs and their many isoforms and interleaved relationships with other genes make lncRNA classification and annotation difficult. Most lncRNAs evolve more rapidly than protein-coding sequences, are cell type specific and regulate many aspects of cell differentiation and development and other physiological processes. Many lncRNAs associate with chromatin-modifying complexes, are transcribed from enhancers and nucleate phase separation of nuclear condensates and domains, indicating an intimate link between lncRNA expression and the spatial control of gene expression during development. lncRNAs also have important roles in the cytoplasm and beyond, including in the regulation of translation, metabolism and signalling. lncRNAs often have a modular structure and are rich in repeats, which are increasingly being shown to be relevant to their function. In this Consensus Statement, we address the definition and nomenclature of lncRNAs and their conservation, expression, phenotypic visibility, structure and functions. We also discuss research challenges and provide recommendations to advance the understanding of the roles of lncRNAs in development, cell biology and disease."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.17702,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Finding \"Good Views\" of Electrocardiogram Signals for Inferring\n  Abnormalities in Cardiac Condition",
    "a_abstract":"Electrocardiograms (ECGs) are an established technique to screen for abnormal\ncardiac signals. Recent work has established that it is possible to detect\narrhythmia directly from the ECG signal using deep learning algorithms. While a\nfew prior approaches with contrastive learning have been successful, the best\nway to define a positive sample remains an open question. In this project, we\ninvestigate several ways to define positive samples, and assess which approach\nyields the best performance in a downstream task of classifying arrhythmia. We\nexplore spatiotemporal invariances, generic augmentations, demographic\nsimilarities, cardiac rhythms, and wave attributes of ECG as potential ways to\nmatch positive samples. We then evaluate each strategy with downstream task\nperformance, and find that learned representations invariant to patient\nidentity are powerful in arrhythmia detection. We made our code available in:\nhttps:\/\/github.com\/mandiehyewon\/goodviews_ecg.git",
    "explanation":"Recent work has established that it is possible to de-\ntect arrhythmia directly from the ECG signal using deep learning algorithms. While a few prior approaches with contrastive learning have been successful,\nthe best way to define a positive sample remains an open question.",
    "b_id":[
      "b5",
      "b11"
    ],
    "b_title":[
      "Patient Contrastive Learning: a Performant, Expressive, and Practical Approach to ECG Modeling.",
      "CLOCS: Contrastive Learning of Cardiac Signals Across Space, Time, and Patients"
    ],
    "b_abstract":[
      "Supervised machine learning applications in health care are often limited due to a scarcity of labeled training data. To mitigate this effect small sample size, we introduce pre-training approach, Patient Contrastive Learning Representations (PCLR), which creates latent representations ECGs from large number unlabeled examples. The resulting expressive, performant, and practical across wide spectrum clinical tasks. We develop PCLR using system with over 3.2 million 12-lead ECGs, demonstrate substantial improvements multiple new tasks when there fewer than 5,000 labels.",
      "The healthcare industry generates troves of unlabelled physiological data. This data can be exploited via contrastive learning, a self-supervised pre-training method that encourages representations instances to similar one another. We propose family learning methods, CLOCS, across space, time, \\textit{and} patients show CLOCS consistently outperforms the state-of-the-art BYOL and SimCLR, when performing linear evaluation of, fine-tuning on, downstream tasks. also achieves strong generalization performance with only 25\\% labelled training Furthermore, our procedure naturally patient-specific used quantify patient-similarity."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Screening for cardiac contractile dysfunction using an artificial intelligence-enabled electrocardiogram"
    ],
    "c_abstract":[
      "Asymptomatic left ventricular dysfunction (ALVD) is present in 3-6% of the general population, is associated with reduced quality of life and longevity, and is treatable when found1-4. An inexpensive, noninvasive screening tool for ALVD in the doctor's office is not available. We tested the hypothesis that application of artificial intelligence (AI) to the electrocardiogram (ECG), a routine method of measuring the heart's electrical activity, could identify ALVD. Using paired 12-lead ECG and echocardiogram data, including the left ventricular ejection fraction (a measure of contractile function), from 44,959 patients at the Mayo Clinic, we trained a convolutional neural network to identify patients with ventricular dysfunction, defined as ejection fraction \u226435%, using the ECG data alone. When tested on an independent set of 52,870 patients, the network model yielded values for the area under the curve, sensitivity, specificity, and accuracy of 0.93, 86.3%, 85.7%, and 85.7%, respectively. In patients without ventricular dysfunction, those with a positive AI screen were at 4 times the risk (hazard ratio, 4.1; 95% confidence interval, 3.3 to 5.0) of developing future ventricular dysfunction compared with those with a negative screen. Application of AI to the ECG-a ubiquitous, low-cost test-permits the ECG to serve as a powerful screening tool in asymptomatic individuals to identify ALVD."
    ],
    "c_categories":[
      "Cardio"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":2412.20007,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Uncertainty Quantified Deep Learning and Regression Analysis Framework\n  for Image Segmentation of Skin Cancer Lesions",
    "a_abstract":"Deep learning models (DLMs) frequently achieve accurate segmentation and\nclassification of tumors from medical images. However, DLMs lacking feedback on\ntheir image segmentation mechanisms, such as Dice coefficients and confidence\nin their performance, face challenges when processing previously unseen images\nin real-world clinical settings. Uncertainty estimates to identify DLM\npredictions at the cellular or single-pixel level that require clinician review\ncan enhance trust. However, their deployment requires significant computational\nresources. This study reports two DLMs, one trained from scratch and another\nbased on transfer learning, with Monte Carlo dropout or Bayes-by-backprop\nuncertainty estimations to segment lesions from the publicly available The\nInternational Skin Imaging Collaboration-19 dermoscopy image database with\ncancerous lesions. A novel approach to compute pixel-by-pixel uncertainty\nestimations of DLM segmentation performance in multiple clinical regions from a\nsingle dermoscopy image with corresponding Dice scores is reported for the\nfirst time. Image-level uncertainty maps demonstrated correspondence between\nimperfect DLM segmentation and high uncertainty levels in specific skin tissue\nregions, with or without lesions. Four new linear regression models that can\npredict the Dice performance of DLM segmentation using constants and\nuncertainty measures, either individually or in combination from lesions,\ntissue structures, and non-tissue pixel regions critical for clinical diagnosis\nand prognostication in skin images (Spearman's correlation, p < 0.05), are\nreported for the first time for low-compute uncertainty estimation workflows.",
    "explanation":"Deep learning models (DLMs) frequently achieve\naccurate segmentation and classification of tumors from medical\nimages.  DLMs lacking feedback on their image seg-\nmentation mechanisms such as Dice coefficients and confidence in\ntheir performance face challenges processing previously unseen\nimages in real-world clinical settings. A novel\napproach to compute pixel-by-pixel uncertainty estimations of\nDLM segmentation performance in multiple clinical regions from\na single dermatoscopy image with corresponding Dice scores\nis reported for the first time. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"
    ],
    "b_abstract":[
      "Deep learning tools have gained tremendous attention in applied machine learning. However such for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about uncertainty, but usually come with prohibitive computational cost. this paper we develop new theoretical casting dropout training deep neural networks (NNs) as approximate inference Gaussian processes. A direct result of theory gives us uncertainty NNs -- extracting information from existing that has been thrown away so far. This mitigates the problem representing without sacrificing either complexity or test accuracy. We perform an extensive study properties dropout's Various network architectures non-linearities are assessed on tasks classification, using MNIST example. show considerable improvement predictive log-likelihood RMSE compared state-of-the-art methods, finish by reinforcement"
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions"
    ],
    "c_abstract":[
      "Training of neural networks for automated diagnosis pigmented skin lesions is hampered by the small size and lack diversity available datasets dermatoscopic images. We tackle this problem releasing HAM10000 (\"Human Against Machine with 10000 training images\") dataset. collected images from different populations acquired stored modalities. Given we had to apply acquisition cleaning methods developed semi-automatic workflows utilizing specifically trained networks. The final dataset consists 10015 which are released as a set academic machine learning purposes publicly through ISIC archive. This benchmark can be used comparisons human experts. Cases include representative collection all important diagnostic categories in realm lesions. More than 50% have been confirmed pathology, while ground truth rest cases was either follow-up, expert consensus, or confirmation in-vivo confocal microscopy."
    ],
    "c_categories":[
      "Data"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.05188,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"AGE2HIE: Transfer Learning from Brain Age to Predicting Neurocognitive\n  Outcome for Infant Brain Injury",
    "a_abstract":"Hypoxic-Ischemic Encephalopathy (HIE) affects 1 to 5 out of every 1,000\nnewborns, with 30% to 50% of cases resulting in adverse neurocognitive\noutcomes. However, these outcomes can only be reliably assessed as early as age\n2. Therefore, early and accurate prediction of HIE-related neurocognitive\noutcomes using deep learning models is critical for improving clinical\ndecision-making, guiding treatment decisions and assessing novel therapies.\nHowever, a major challenge in developing deep learning models for this purpose\nis the scarcity of large, annotated HIE datasets. We have assembled the first\nand largest public dataset, however it contains only 156 cases with 2-year\nneurocognitive outcome labels. In contrast, we have collected 8,859 normal\nbrain black Magnetic Resonance Imagings (MRIs) with 0-97 years of age that are\navailable for brain age estimation using deep learning models. In this paper,\nwe introduce AGE2HIE to transfer knowledge learned by deep learning models from\nhealthy controls brain MRIs to a diseased cohort, from structural to diffusion\nMRIs, from regression of continuous age estimation to prediction of the binary\nneurocognitive outcomes, and from lifespan age (0-97 years) to infant (0-2\nweeks). Compared to training from scratch, transfer learning from brain age\nestimation significantly improves not only the prediction accuracy (3% or 2%\nimprovement in same or multi-site), but also the model generalization across\ndifferent sites (5% improvement in cross-site validation).",
    "explanation":"Hypoxic-Ischemic Encephalopathy (HIE) affects 1 to 5 out of\nevery 1,000 newborns, with 30% to 50% of cases resulting in\nadverse neurocognitive outcomes. However, these outcomes\ncan only be reliably assessed as early as age 2. Therefore,\nearly and accurate prediction of HIE-related neurocognitive\noutcomes using deep learning models is critical for improv-\ning clinical decision-making, guiding treatment decisions and\nassessing novel therapies",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Limitations of conventional magnetic resonance imaging as a predictor of death or disability following neonatal hypoxic-ischemic encephalopathy in the late hypothermia trial"
    ],
    "b_abstract":[
      "Objective: To investigate if magnetic resonance imaging (MRI) is an accurate predictor for death or moderate-severe disability at 18-22 months of age among infants with neonatal encephalopathy in a trial of cooling initiated at 6-24 hours. Study design: Subgroup analysis of infants \u226536 weeks of gestation with moderate-severe neonatal encephalopathy randomized at 6-24 postnatal hours to hypothermia or usual care in a multicenter trial of late hypothermia. MRI scans were performed per each center's practice and interpreted by 2 central readers using the Eunice Kennedy Shriver National Institute of Child Health and Human Development injury score (6 levels, normal to hemispheric devastation). Neurodevelopmental outcomes were assessed at 18-22 months of age. Results: Of 168 enrollees, 128 had an interpretable MRI and were seen in follow-up (n = 119) or died (n = 9). MRI findings were predominantly acute injury and did not differ by cooling treatment. At 18-22 months, death or severe disability occurred in 20.3%. No infant had moderate disability. Agreement between central readers was moderate (weighted kappa 0.56, 95% CI 0.45-0.67). The adjusted odds of death or severe disability increased 3.7-fold (95% CI 1.8-7.9) for each increment of injury score. The area under the curve for severe MRI patterns to predict death or severe disability was 0.77 and the positive and negative predictive values were 36% and 100%, respectively. Conclusions: MRI injury scores were associated with neurodevelopmental outcome at 18-22 months among infants in the Late Hypothermia Trial. However, the results suggest caution when using qualitative interpretations of MRI images to provide prognostic information to families following perinatal hypoxia-ischemia."
    ],
    "b_categories":[
      "Pediatrics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "What is being transferred in transfer learning?"
    ],
    "c_abstract":[
      "One desired capability for machines is the ability to transfer their knowledge of one domain another where data (usually) scarce. Despite ample adaptation learning in various deep applications, we yet do not understand what enables a successful and which part network responsible that. In this paper, provide new tools analyses address these fundamental questions. Through series on transferring block-shuffled images, separate effect feature reuse from low-level statistics show that some benefit comes latter. We present when training pre-trained weights, model stays same basin loss landscape different instances such are similar space close parameter space."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.19345,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"3D Wasserstein generative adversarial network with dense U-Net based\n  discriminator for preclinical fMRI denoising",
    "a_abstract":"Functional magnetic resonance imaging (fMRI) is extensively used in clinical\nand preclinical settings to study brain function, however, fMRI data is\ninherently noisy due to physiological processes, hardware, and external noise.\nDenoising is one of the main preprocessing steps in any fMRI analysis pipeline.\nThis process is challenging in preclinical data in comparison to clinical data\ndue to variations in brain geometry, image resolution, and low signal-to-noise\nratios. In this paper, we propose a structure-preserved algorithm based on a 3D\nWasserstein generative adversarial network with a 3D dense U-net based\ndiscriminator called, 3D U-WGAN. We apply a 4D data configuration to\neffectively denoise temporal and spatial information in analyzing preclinical\nfMRI data. GAN-based denoising methods often utilize a discriminator to\nidentify significant differences between denoised and noise-free images,\nfocusing on global or local features. To refine the fMRI denoising model, our\nmethod employs a 3D dense U-Net discriminator to learn both global and local\ndistinctions. To tackle potential over-smoothing, we introduce an adversarial\nloss and enhance perceptual similarity by measuring feature space distances.\nExperiments illustrate that 3D U-WGAN significantly improves image quality in\nresting-state and task preclinical fMRI data, enhancing signal-to-noise ratio\nwithout introducing excessive structural changes in existing methods. The\nproposed method outperforms state-of-the-art methods when applied to simulated\nand real data in a fMRI analysis pipeline.",
    "explanation":"Denoising is one of the main preprocessing steps in any fMRI analysis pipeline. In this\npaper, we propose a structure-preserved algorithm based on a 3D Wasserstein\ngenerative adversarial network with a 3D dense U-net based discriminator called,\n3D U-WGAN. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "On the use of preclinical imaging to explore the principles of brain function in rodent models and their relevance for illnesses of the human mind"
    ],
    "b_abstract":[
      "Dear Editor, We recently published in Translational Psychiatry an article that examine the strategies for evaluating brain function at the wholebrain level [1]. In this review, we covered several methods, from functional MRI to functional ultrasound to calcium imaging. For each technique, we wrote a brief history of its development, the physical notion, some key applications, its potentials, and its limitations. We concluded that methods for imaging the rodent brain at the network level are growing and will advance our understanding of brain function. A commentary by Zhuo and colleagues further enhances the complexity of addressing the issue of \u201ctranslation\u201d from animal models to patients for the discipline of psychiatry [2]. They propose that the approaches employed to develop an animal model for a psychiatric disease need to be thoroughly scrutinized and, perhaps, revised. For example, most rodent models of mental diseases are to-date established using a simple pharmacological infusion [3] and\/or psychosocial stimulation [4]. The key concern posed, however, is how these manipulations change the brain\u2019s structure and function, and whether these models genuinely reflect the pathophysiology of human mental illnesses. Especially since it is difficult to evaluate whether one can speak of inverse inference from rodents to humans. This is a true and acceptable statement. However, this is exactly what preclinical imaging aims to deliver. By mapping the dynamic responses of brain networks in animal models and compare them, if possible, with those reported in clinical studies, we can obtain quantitative data and parameters to establish whether our models are effectively translational [5]. If these metrics demonstrate temporal and spatial similarity in network-level modifications as those observed in humans, we can pursue further inquiry utilizing more intrusive and more specific methods for brain recordings in animal models. Otherwise, we must have the confidence and the correctness to move forward and attempt other solutions. Two recent examples. In 2019 we established a causal association between activity of the noradrenergic nucleus locus coeruleus (LC) and the engagement of numerous large-scale brain networks in mice, in particular of the salience and amygdala networks [6]. In addition, we could link network-changes with direct markers of norepinephrine (NE) turnover and with the distribution of NE receptors over the entire brain. The hypothesis that specific brain networks dynamics are related to LC activity and to NE receptor density derives from stress-research and pharmacological studies in humans [7, 8]. However, since it is impossible to selectively stimulate LC in people, it has remained a hypothesis for more than a decade. Our preclinical work helped confirm this causal relationship and this has direct implications for interpreting the results of clinical imaging studies on stress and anxiety behavior. More recently, the Gozzi lab described how chronic local neuronal suppression via overexpression of a potassium channel or acute silencing via chemogenetics result in a paradoxical hyperconnectivity [9]; an intriguing finding often reported in humans after stroke [10] and in early stages of Alzheimer\u2019s disease [11], but never truly understood. Using in vivo electrophysiology, they showed local inhibition improves low frequency (0.1\u20134 Hz) oscillatory power via suppression of neuronal activity not phaselocked to slow rhythms, resulting in increased slow and \u03b4 band coherence between areas that display fMRI overconnectivity. These data present causal evidence that cortical inactivation can counterintuitively augment fMRI connectivity via greater, lesslocalized slow oscillatory processes. Once again, this could be only achieved by combining functional MRI and electrophysiology with neuromodulation in animal models. These and other examples give a peek of what the future of preclinical imaging might look like: a field of research capable of delivering causal explanations to the hypotheses presented by human neuroscience, neurology and psychiatry. Lastly, I would argue against statements like \u201cthe computational complexity of human brains is billions of times that of mouse brain\u201d. While this may be true from a numerical standpoint of mere neuronal counts, preclinical neuroimaging\u2019s objective should not be per se to map every single neuron in real time but of identifying the general neural and cellular principles governing the assembly of brain networks and its breakdown in brain disorders. The field is relatively new but is moving fast and has already produced some important insights. The future is challenging and will require time, devotion and an optimal synergy between engineering, chemistry, biology, and computer science. If the community will be patient and supportive enough, there will be further important discoveries in the future."
    ],
    "b_categories":[
      "Psychiatry"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "GAN\uff08Generative Adversarial Nets\uff09"
    ],
    "c_abstract":[
      "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: model G that captures the data distribution, and discriminative D estimates probability sample came from training rather than G. The procedure is to maximize of making mistake. This corresponds minimax two-player game. In space arbitrary functions D, unique solution exists, with recovering distribution equal \u00bd everywhere. case where are defined by multilayer perceptrons, entire system can be trained backpropagation. There no need any Markov chains or unrolled approximate inference networks during either generation samples. Experiments demonstrate potential through qualitative quantitative evaluation generated"
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.00688,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Mathematics and Statistics"
    ],
    "a_title":"Why do we regularise in every iteration for imaging inverse problems?",
    "a_abstract":"Regularisation is commonly used in iterative methods for solving imaging\ninverse problems. Many algorithms involve the evaluation of the proximal\noperator of the regularisation term in every iteration, leading to a\nsignificant computational overhead since such evaluation can be costly. In this\ncontext, the ProxSkip algorithm, recently proposed for federated learning\npurposes, emerges as an solution. It randomly skips regularisation steps,\nreducing the computational time of an iterative algorithm without affecting its\nconvergence. Here we explore for the first time the efficacy of ProxSkip to a\nvariety of imaging inverse problems and we also propose a novel PDHGSkip\nversion. Extensive numerical results highlight the potential of these methods\nto accelerate computations while maintaining high-quality reconstructions.",
    "explanation":"Regularisation is commonly used in iterative methods for solving imaging inverse problems. Here we explore for the first time the efficacy of ProxSkip to a variety of imaging inverse problems and we also propose a novel PDHGSkip version.",
    "b_id":[
      "b19"
    ],
    "b_title":[
      "Parameter-Free FISTA by Adaptive Restart and Backtracking"
    ],
    "b_abstract":[
      "We consider a combined restarting and adaptive backtracking strategy for the\npopular Fast Iterative Shrinking-Thresholding Algorithm frequently employed for\naccelerating the convergence speed of large-scale structured convex\noptimization problems. Several variants of FISTA enjoy a provable linear\nconvergence rate for the function values $F(x_n)$ of the form $\\mathcal{O}(\ne^{-K\\sqrt{\\mu\/L}~n})$ under the prior knowledge of problem conditioning, i.e.\nof the ratio between the (\\L ojasiewicz) parameter $\\mu$ determining the growth\nof the objective function and the Lipschitz constant $L$ of its smooth\ncomponent. These parameters are nonetheless hard to estimate in many practical\ncases. Recent works address the problem by estimating either parameter via\nsuitable adaptive strategies. In our work both parameters can be estimated at\nthe same time by means of an algorithmic restarting scheme where, at each\nrestart, a non-monotone estimation of $L$ is performed. For this scheme,\ntheoretical convergence results are proved, showing that a $\\mathcal{O}(\ne^{-K\\sqrt{\\mu\/L}n})$ convergence speed can still be achieved along with\nquantitative estimates of the conditioning. The resulting Free-FISTA algorithm\nis therefore parameter-free. Several numerical results are reported to confirm\nthe practical interest of its use in many exemplar problems."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Convex generalizations of total variation based on the structure tensor with applications to inverse problems"
    ],
    "c_abstract":[
      "We introduce a generic convex energy functional that is suitable for both grayscale and vector-valued images. Our functional is based on the eigenvalues of the structure tensor, therefore it penalizes image variation at every point by taking into account the information from its neighborhood. It generalizes several existing variational penalties, such as the Total Variation and vectorial extensions of it. By introducing the concept of patch-based Jacobian operator, we derive an equivalent formulation of the proposed regularizer that is based on the Schatten norm of this operator. Using this new formulation, we prove convexity and develop a dual definition for the proposed energy, which gives rise to an efficient and parallelizable minimization algorithm. Moreover, we establish a connection between the minimization of the proposed convex regularizer and a generic type of nonlinear anisotropic diffusion that is driven by a spatially regularized and adaptive diffusion tensor. Finally, we perform extensive experiments with image denoising and deblurring for grayscale and color images. The results show the effectiveness of the proposed approach as well as its improved performance compared to Total Variation and existing vectorial extensions of it."
    ],
    "c_categories":[
      "eess.IV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.00036,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Economics and Quantitative Finance"
    ],
    "a_title":"Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial\n  Market Dynamics",
    "a_abstract":"We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.",
    "explanation":"The paper proposes the use of a new method using diffusion model generative methodology to produce synthetic market scenarios.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "On the Distribution of the Two-Sample Cramer-von Mises Criterion"
    ],
    "b_abstract":[
      "The Cramer-von Mises $\\omega^2$ criterion for testing that a sample, $x_1, \\cdots, x_N$, has been drawn from specified continuous distribution $F(x)$ is \\begin{equation*}\\tag{1}\\omega^2 = \\int^\\infty_{-\\infty} \\lbrack F_N(x) - F(x)\\rbrack^2 dF(x),\\end{equation*} where $F_N(x)$ the empirical function of sample; is, $F_N(x) k\/N$ if exactly $k$ observations are less than or equal to $x(k 0, 1, N)$. If there second $y_1, y_M$, test hypothesis two samples come same (unspecified) can be based on analogue $N\\omega^2$, namely \\begin{equation*}\\tag{2} T NM\/(N + M)\\rbrack G_M(x)\\rbrack^2 dH_{N+M}(x),\\end{equation*} $G_M(x)$ sample and $H_{N+M}(x)$ together [that $(N M)H_{N+M}(x) NF_N(x) MG_M(x)\\rbrack$. limiting $N\\omega^2$ as $N \\rightarrow \\infty$ tabulated [2], it shown ([3], [4a], [7]) $T$ \\infty, M \\infty$, $N\/M \\lambda$, $\\lambda$ any finite positive constant. In this note we consider small values $N$ $M$ present tables permit use at some conventional significance levels $M$. seems surprisingly good approximation exact moderate sizes (corresponding feature [6]). accuracy better in case two-sample Kolmogorov-Smirnov statistic studied by Hodges [4]."
    ],
    "b_categories":[
      "q-fin.GN"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "b24"
    ],
    "c_title":[
      "Quant GANs: deep generation of financial time series"
    ],
    "c_abstract":[
      "Modeling financial time series by stochastic processes is a challenging task and a central area of research in financial mathematics. As an alternative, we introduce Quant GANs, a data-driven model which is inspired by the recent success of generative adversarial networks (GANs). Quant GANs consist of a generator and discriminator function, which utilize temporal convolutional networks (TCNs) and thereby achieve to capture long-range dependencies such as the presence of volatility clusters. The generator function is explicitly constructed such that the induced stochastic process allows a transition to its risk-neutral distribution. Our numerical results highlight that distributional properties for small and large lags are in an excellent agreement and dependence properties such as volatility clusters, leverage effects, and serial autocorrelations can be generated by the generator function of Quant GANs, demonstrably in high fidelity."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.0064,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Mathematics and Statistics"
    ],
    "a_title":"Adding Error Bars to Evals: A Statistical Approach to Language Model\n  Evaluations",
    "a_abstract":"Evaluations are critical for understanding the capabilities of large language\nmodels (LLMs). Fundamentally, evaluations are experiments; but the literature\non evaluations has largely ignored the literature from other sciences on\nexperiment analysis and planning. This article shows researchers with some\ntraining in statistics how to think about and analyze data from language model\nevaluations. Conceptualizing evaluation questions as having been drawn from an\nunseen super-population, we present formulas for analyzing evaluation data,\nmeasuring differences between two models, and planning an evaluation\nexperiment. We make a number of specific recommendations for running language\nmodel evaluations and reporting experiment results in a way that minimizes\nstatistical noise and maximizes informativeness.",
    "explanation":"This is an interdisciplinary work because it combines two different subjects: LLM and statistics. This suggests that we could also consider the error bars in the evaluations. ",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "Quantifying Variance in Evaluation Benchmarks"
    ],
    "b_abstract":[
      "Evaluation benchmarks are the cornerstone of measuring capabilities large language models (LLMs), as well driving progress in said capabilities. Originally designed to make claims about (or lack thereof) fully pretrained models, evaluation now also extensively used decide between various training choices. Despite this widespread usage, we rarely quantify variance our benchmarks, which dictates whether differences performance meaningful. Here, define and measure a range metrics geared towards including seed across initialisations, monotonicity during training. By studying number -- both openly available from scratch provide empirical estimates for variety metrics, with considerations recommendations practitioners. We evaluate utility tradeoffs continuous versus discrete measures explore options better understanding reducing variance. find that simple changes, such framing choice tasks (like MMLU) completion tasks, can often reduce smaller scale ($\\sim$7B) while more involved methods inspired human testing literature (such item analysis response theory) struggle meaningfully Overall, work provides insights into suggests LM-specific techniques variance, generally encourages practitioners carefully factor when comparing models."
    ],
    "b_categories":[
      "stat.ME"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "The Llama 3 Herd of Models"
    ],
    "c_abstract":[
      "Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.18784,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"MRI Breast tissue segmentation using nnU-Net for biomechanical modeling",
    "a_abstract":"Integrating 2D mammography with 3D magnetic resonance imaging (MRI) is\ncrucial for improving breast cancer diagnosis and treatment planning. However,\nthis integration is challenging due to differences in imaging modalities and\nthe need for precise tissue segmentation and alignment. This paper addresses\nthese challenges by enhancing biomechanical breast models in two main aspects:\nimproving tissue identification using nnU-Net segmentation models and\nevaluating finite element (FE) biomechanical solvers, specifically comparing\nNiftySim and FEBio. We performed a detailed six-class segmentation of breast\nMRI data using the nnU-Net architecture, achieving Dice Coefficients of 0.94\nfor fat, 0.88 for glandular tissue, and 0.87 for pectoral muscle. The overall\nforeground segmentation reached a mean Dice Coefficient of 0.83 through an\nensemble of 2D and 3D U-Net configurations, providing a solid foundation for 3D\nreconstruction and biomechanical modeling. The segmented data was then used to\ngenerate detailed 3D meshes and develop biomechanical models using NiftySim and\nFEBio, which simulate breast tissue's physical behaviors under compression. Our\nresults include a comparison between NiftySim and FEBio, providing insights\ninto the accuracy and reliability of these simulations in studying breast\ntissue responses under compression. The findings of this study have the\npotential to improve the integration of 2D and 3D imaging modalities, thereby\nenhancing diagnostic accuracy and treatment planning for breast cancer.",
    "explanation":"Integrating 2D mammography with 3D magnetic resonance\nimaging (MRI) is crucial for improving breast cancer diagnosis and treat-\nment planning. However, this integration is challenging due to differences\nin imaging modalities and the need for precise tissue segmentation and\nalignment. This paper addresses these challenges by enhancing biome-\nchanical breast models in two main aspects: improving tissue identifica-\ntion using nnU-Net segmentation models and evaluating finite element\n(FE) biomechanical solvers, specifically comparing NiftySim and FEBio.\u00a0",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "nnu-net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "b_abstract":[
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Multimodal Breast Parenchymal Patterns Correlation Using a Patient-Specific Biomechanical Model"
    ],
    "c_abstract":[
      "In this paper, we aim to produce a realistic 2-D projection of the breast parenchymal distribution from a 3-D breast magnetic resonance image (MRI). To evaluate the accuracy of our simulation, we compare our results with the local breast density (i.e., density map) obtained from the complementary full-field digital mammogram. To achieve this goal, we have developed a fully automatic framework, which registers MRI volumes to X-ray mammograms using a subject-specific biomechanical model of the breast. The optimization step modifies the position, orientation, and elastic parameters of the breast model to perform the alignment between the images. When the model reaches an optimal solution, the MRI glandular tissue is projected and compared with the one obtained from the corresponding mammograms. To reduce the loss of information during the ray-casting, we introduce a new approach that avoids resampling the MRI volume. In the results, we focus our efforts on evaluating the agreement of the distributions of glandular tissue, the degree of structural similarity, and the correlation between the real and synthetic density maps. Our approach obtained a high-structural agreement regardless the glandularity of the breast, whilst the similarity of the glandular tissue distributions and correlation between both images increase in denser breasts. Furthermore, the synthetic images show continuity with respect to large structures in the density maps."
    ],
    "c_categories":[
      "Imaging"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.00663,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Deep Learning for Longitudinal Gross Tumor Volume Segmentation in\n  MRI-Guided Adaptive Radiotherapy for Head and Neck Cancer",
    "a_abstract":"Accurate segmentation of gross tumor volume (GTV) is essential for effective\nMRI-guided adaptive radiotherapy (MRgART) in head and neck cancer. However,\nmanual segmentation of the GTV over the course of therapy is time-consuming and\nprone to interobserver variability. Deep learning (DL) has the potential to\novercome these challenges by automatically delineating GTVs. In this study, our\nteam, $\\textit{UW LAIR}$, tackled the challenges of both pre-radiotherapy\n(pre-RT) (Task 1) and mid-radiotherapy (mid-RT) (Task 2) tumor volume\nsegmentation. To this end, we developed a series of DL models for longitudinal\nGTV segmentation. The backbone of our models for both tasks was SegResNet with\ndeep supervision. For Task 1, we trained the model using a combined dataset of\npre-RT and mid-RT MRI data, which resulted in the improved aggregated Dice\nsimilarity coefficient (DSCagg) on an internal testing set compared to models\ntrained solely on pre-RT MRI data. In Task 2, we introduced mask-aware\nattention modules, enabling pre-RT GTV masks to influence intermediate features\nlearned from mid-RT data. This attention-based approach yielded slight\nimprovements over the baseline method, which concatenated mid-RT MRI with\npre-RT GTV masks as input. In the final testing phase, the ensemble of 10\npre-RT segmentation models achieved an average DSCagg of 0.794, with 0.745 for\nprimary GTV (GTVp) and 0.844 for metastatic lymph nodes (GTVn) in Task 1. For\nTask 2, the ensemble of 10 mid-RT segmentation models attained an average\nDSCagg of 0.733, with 0.607 for GTVp and 0.859 for GTVn, leading us to\n$\\textbf{achieve 1st place}$. In summary, we presented a collection of DL\nmodels that could facilitate GTV segmentation in MRgART, offering the potential\nto streamline radiation oncology workflows. Our code and model weights are\navailable at https:\/\/github.com\/xtie97\/HNTS-MRG24-UWLAIR.",
    "explanation":"In this study, our team, UW LAIR, tackled the challenges of both pre-radiotherapy\n(pre-RT) (Task 1) and mid-radiotherapy (mid-RT) (Task 2) tumor volume seg-\nmentation. To this end, we developed a series of DL models for longitudinal GTV\nsegmentation",
    "b_id":[
      "b4",
      "b2"
    ],
    "b_title":[
      "Deep Learning for Automatic Gross Tumor Volumes Contouring in Esophageal Cancer Based on Contrast-Enhanced Computed Tomography Images: A Multi-Institutional Study",
      "ConTEXTual Net: A Multimodal Vision-Language Model for Segmentation of Pneumothorax"
    ],
    "b_abstract":[
      "Purpose To develop and externally validate an automatic artificial intelligence (AI) tool for delineating gross tumor volume (GTV) in patients with esophageal squamous cell carcinoma (ESCC), which can assist in neo-adjuvant or radical radiation therapy treatment planning. Methods and Materials In this multi-institutional study, contrast-enhanced CT images from 580 eligible ESCC patients were retrospectively collected. The GTV contours delineated by 2 experts via consensus were used as ground truth. A 3-dimensional deep learning model was developed for GTV contouring in the training cohort and internally and externally validated in 3 validation cohorts. The AI tool was compared against 12 board-certified experts in 25 patients randomly selected from the external validation cohort to evaluate its assistance in improving contouring performance and reducing variation. Contouring performance was measured using dice similarity coefficient (DSC) and average surface distance. Additionally, our previously established radiomics model for predicting pathologic complete response was used to compare AI-generated and ground truth contours, to assess the potential of the AI contouring tool in radiomics analysis. Results The AI tool demonstrated good GTV contouring performance in multicenter validation cohorts, with median DSC values of 0.865, 0.876, and 0.866 and median average surface distance values of 0.939, 0.789, and 0.875 mm, respectively. Furthermore, the AI tool significantly improved contouring performance for half of 12 board-certified experts (DSC values, 0.794-0.835 vs 0.856-0.881, P = .003-0.048), reduced the intra- and interobserver variations by 37.4% and 55.2%, respectively, and saved contouring time by 77.6%. In the radiomics analysis, 88.7% of radiomic features from ground truth and AI-generated contours demonstrated stable reproducibility, and similar pathologic complete response prediction performance for these contours (P = .430) was observed. Conclusions Our AI contouring tool can improve GTV contouring performance and facilitate radiomics analysis in ESCC patients, which indicates its potential for GTV contouring during radiation therapy treatment planning and radiomics studies.",
      "Radiology narrative reports often describe characteristics of a patient's disease, including its location, size, and shape. Motivated by the recent success multimodal learning, we hypothesized that this descriptive text could guide medical image analysis algorithms. We proposed novel vision-language model, ConTEXTual Net, for task pneumothorax segmentation on chest radiographs. Net extracts language features from physician-generated free-form radiology using pre-trained model. then introduced cross-attention between intermediate embeddings an encoder-decoder convolutional neural network to enable guidance analysis. was trained CANDID-PTX dataset consisting 3196 positive cases with annotations 6 different physicians as well clinical reports. Using cross-validation, achieved Dice score 0.716\u00b10.016, which similar degree inter-reader variability (0.712\u00b10.044) computed subset data. It outperformed vision-only models (Swin UNETR: 0.670\u00b10.015, ResNet50 U-Net: 0.677\u00b10.015, GLoRIA: 0.686\u00b10.014, nnUNet 0.694\u00b10.016) competing model (LAVT: 0.706\u00b10.009). Ablation studies confirmed it information led performance gains. Additionally, show certain augmentation methods degraded Net's breaking image-text concordance. also evaluated effects activation functions in module, highlighting efficacy our chosen architectural design."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "MRI-Guided Adaptive Radiation Therapy"
    ],
    "c_abstract":[
      "Magnetic resonance imaging-guided radiation therapy (MRIgRT) has improved soft tissue contrast over computed tomography (CT) based image-guided RT. Superior visualization of the target and surrounding radiosensitive structures has the potential to improve oncological outcomes partly due to safer dose-escalation and adaptive planning. In this review, we highlight the workflow of adaptive MRIgRT planning, which includes simulation imaging, daily MRI, identifying isocenter shifts, contouring, plan optimization, quality control, and delivery. Increased utilization of MRIgRT will depend on addressing technical limitations of this technology, while addressing treatment efficacy, cost-effectiveness, and workflow training."
    ],
    "c_categories":[
      "Oncology"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.18602,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Evaluating and Improving the Effectiveness of Synthetic Chest X-Rays for\n  Medical Image Analysis",
    "a_abstract":"Purpose: To explore best-practice approaches for generating synthetic chest\nX-ray images and augmenting medical imaging datasets to optimize the\nperformance of deep learning models in downstream tasks like classification and\nsegmentation. Materials and Methods: We utilized a latent diffusion model to\ncondition the generation of synthetic chest X-rays on text prompts and\/or\nsegmentation masks. We explored methods like using a proxy model and using\nradiologist feedback to improve the quality of synthetic data. These synthetic\nimages were then generated from relevant disease information or geometrically\ntransformed segmentation masks and added to ground truth training set images\nfrom the CheXpert, CANDID-PTX, SIIM, and RSNA Pneumonia datasets to measure\nimprovements in classification and segmentation model performance on the test\nsets. F1 and Dice scores were used to evaluate classification and segmentation\nrespectively. One-tailed t-tests with Bonferroni correction assessed the\nstatistical significance of performance improvements with synthetic data.\nResults: Across all experiments, the synthetic data we generated resulted in a\nmaximum mean classification F1 score improvement of 0.150453 (CI:\n0.099108-0.201798; P=0.0031) compared to using only real data. For\nsegmentation, the maximum Dice score improvement was 0.14575 (CI:\n0.108267-0.183233; P=0.0064). Conclusion: Best practices for generating\nsynthetic chest X-ray images for downstream tasks include conditioning on\nsingle-disease labels or geometrically transformed segmentation masks, as well\nas potentially using proxy modeling for fine-tuning such generations.",
    "explanation":"We utilized a latent diffusion model to condition the generation of synthetic chest X-rays on text prompts and\/or segmentation masks",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Rsna pneumonia detection challenge"
    ],
    "b_abstract":[
      "In this competition, you\u2019re challenged to build an algorithm to detect a visual signal for pneumonia in medical images. Specifically, your algorithm needs to automatically locate lung opacities on chest radiographs. Here\u2019s the backstory and why solving this problem matters. Pneumonia accounts for over 15% of all deaths of children under 5 years old internationally. In 2015, 920,000 children under the age of 5 died from the disease. In the United States, pneumonia accounts for over 500,000 visits to emergency departments [1] and over 50,000 deaths in 2015 [2], keeping the ailment on the list of top 10 causes of death in the country. While common, accurately diagnosing pneumonia is a tall order. It requires review of a chest radiograph (CXR) by highly trained specialists and confirmation through clinical history, vital signs and laboratory exams. Pneumonia usually manifests as an area or areas of increased opacity [3] on CXR. However, the diagnosis of pneumonia on CXR is complicated because of a number of other conditions in the lungs such as fluid overload (pulmonary edema), bleeding, volume loss (atelectasis or collapse), lung cancer, or post-radiation or surgical changes. Outside of the lungs, fluid in the pleural space (pleural effusion) also appears as increased opacity on CXR. When available, comparison of CXRs of the patient taken at different time points and correlation with clinical symptoms and history are helpful in making the diagnosis. CXRs are the most commonly performed diagnostic imaging study. A number of factors such as positioning of the patient and depth of inspiration can alter the appearance of the CXR [4], complicating interpretation further. In addition, clinicians are faced with reading high volumes of images every shift. To improve the efficiency and reach of diagnostic services, the Radiological Society of North America (RSNA\u00ae) has reached out to Kaggle\u2019s machine learning community and collaborated with the US National Institutes of Health, The Society of Thoracic Radiology, and MD.ai to develop a rich dataset for this challenge. The RSNA is an international society of radiologists, medical physicists and other medical professionals with more than 54,000 members from 146 countries across the globe. They see the potential for ML to automate initial detection (imaging screening) of potential pneumonia cases in order to prioritize and expedite their review. Challenge participants may be invited to present their AI models and methodologies during an award ceremony at the RSNA Annual Meeting which will be held in Chicago, Illinois, USA, from November 25-30, 2018."
    ],
    "b_categories":[
      "Imaging"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b14",
      "b9"
    ],
    "c_title":[
      "Adding Conditional Control to Text-to-Image Diffusion Models",
      "Highresolution image synthesis with latent diffusion models"
    ],
    "c_abstract":[
      "We present ControlNet, a neural network architecture to add spatial conditioning controls large, pretrained text-to-image diffusion models. ControlNet locks the production-ready large models, and reuses their deep robust encoding layers with billions of images as strong backbone learn diverse set conditional controls. The is connected \"zero convolutions\" (zero-initialized convolution layers) that progressively grow parameters from zero ensure no harmful noise could affect finetuning. test various controls, e.g., edges, depth, segmentation, human pose, etc., Stable Diffusion, using single or multiple conditions, without prompts. show training ControlNets small (<50k) (>1m) datasets. Extensive results may facilitate wider applications control image",
      "By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.18902,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"MSEMG: Surface Electromyography Denoising with a Mamba-based Efficient\n  Network",
    "a_abstract":"Surface electromyography (sEMG) recordings can be contaminated by\nelectrocardiogram (ECG) signals when the monitored muscle is closed to the\nheart. Traditional signal-processing-based approaches, such as high-pass\nfiltering and template subtraction, have been used to remove ECG interference\nbut are often limited in their effectiveness. Recently, neural-network-based\nmethods have shown greater promise for sEMG denoising, but they still struggle\nto balance both efficiency and effectiveness. In this study, we introduce\nMSEMG, a novel system that integrates the Mamba State Space Model with a\nconvolutional neural network to serve as a lightweight sEMG denoising model. We\nevaluated MSEMG using sEMG data from the Non-Invasive Adaptive Prosthetics\ndatabase and ECG signals from the MIT-BIH Normal Sinus Rhythm Database. The\nresults show that MSEMG outperforms existing methods, generating higher-quality\nsEMG signals with fewer parameters. The source code for MSEMG is available at\nhttps:\/\/github.com\/tonyliu0910\/MSEMG.",
    "explanation":"Surface electromyography (sEMG) recordings can\nbe contaminated by electrocardiogram (ECG) signals when the\nmonitored muscle is closed to the heart. In this study, we introduce MSEMG, a novel\nsystem that integrates the Mamba state space model with a\nconvolutional neural network to serve as a lightweight sEMG\ndenoising mode",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "Biomechanics and motor control of human movement"
    ],
    "b_abstract":[
      "Preface to the Fourth Edition. 1 Biomechanics as an Interdiscipline. 1.0 Introduction. 1.1 Measurement, Description, Analysis, and Assessment. 1.2 its Relationship with Physiology Anatomy. 1.3 Scope of Textbook. 1.4 References. 2 Signal Processing. 2.0 2.1 Auto- Cross-Correlation Analyses. 2.2 Frequency Analysis. 2.3 Ensemble Averaging Repetitive Waveforms. 2.4 3 Kinematics. 3.0 Historical Development Complexity Problem. 3.1 Kinematic Conventions. 3.2 Direct Measurement Techniques. 3.3 Imaging 3.4 Processing Raw Data. 3.5 Calculation Other Variables. 3.6 Problems Based on 3.7 4 Anthropometry. 4.0 Anthropometry in Movement Biomechanics. 4.1 Density, Mass, Inertial Properties. 4.2 Experimental Measures. 4.3 Muscle 4.4 Anthropometric 4.5 5 Kinetics: Forces Moments Force. 5.0 Biomechanical Models. 5.1 Basic Link-Segment Equations-the Free-Body Diagram. 5.2 Force Transducers Plates. 5.3 Bone-on-Bone During Dynamic Conditions. 5.4 Kinetic 5.5 6 Mechanical Work, Energy, Power. 6.0 6.1 Efficiency. 6.2 Forms Energy Storage. 6.3 Internal External Work. 6.4 Power Balances at Joints Within Segments. 6.5 6.6 7 Three-Dimensional Kinematics Kinetics. 7.0 7.1 Axes Systems. 7.2 Marker Anatomical 7.3 Determination Segment Angular Velocities Accelerations. 7.4 Analysis Reaction Moments. 7.5 Suggested Further Reading. 7.6 8 Synthesis Human Movement-Forward Solutions. 8.0 8.1 Review Forward Solution 8.2 Mathematical Formulation. 8.3 System Energy. 8.4 Torques. 8.5 Designation Joints. 8.6 Illustrative Example. 8.7 Conclusions. 8.8 9 Mechanics. 9.0 9.1 Force-Length Characteristics Muscles. 9.2 Force-Velocity Characteristics. 9.3 Modeling. 9.4 10 Kinesiological Electromyography. 10.0 10.1 Electrophysiology Contraction. 10.2 Recording Electromyogram. 10.3 Electromyogram,. 10.4 between Electromyogram 10.5 11 Synergies. 11.0 11.1 The Support Moment Synergy. 11.2 Medial\/Lateral Anterior\/Posterior Balance Standing. 11.3 during Walking. 11.4 APPENDICES. A. Kinematic, Kinetic, Figure A.1 Walking Trial-Marker Locations Mass Frame Rate Information. Table Coordinate Data (cm). A.2( a ) Filtered Kinematics-Rib Cage Greater Trochanter (Hip). b Kinematics-Femoral Lateral Epicondyle (Knee) Head Fibula. c Kinematics-Lateral Malleolus (Ankle) Heel. d Kinematics-Fifth Metatarsal Toe. A.3( Linear Kinematics-Foot. Kinematics-Leg. Kinematics-Thigh. Kinematics-1\/2 HAT. A.4 Relative Joint Kinematics-Ankle, Knee, Hip. A.5( Force-Ankle Knee. Force-Hip. A.6 Potential, Total Energies-Foot, Leg, Thigh, and1\/2 A.7 Generation\/Absorption Transfer-Ankle, B. Units Definitions Related Electromyographical Measurements. B.1 Base SI Units. B.2 Derived Index."
    ],
    "b_categories":[
      "Biomechanics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"
    ],
    "c_abstract":[
      "Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution recurrent structured state space models (SSMs) have been developed to address Transformers' computational inefficiency long sequences, but they not performed well important modalities language. We identify that a key weakness is their inability perform content-based reasoning, make several improvements. First, simply letting SSM parameters be functions input addresses with discrete modalities, allowing model selectively propagate or forget information along sequence length dimension depending current token. Second, even though this change prevents use efficient convolutions, we design hardware-aware parallel algorithm mode. integrate these selective SSMs into simplified end-to-end neural network without MLP blocks (Mamba). Mamba enjoys fast inference (5$\\times$ higher throughput than Transformers) scaling length, performance improves real data up million-length sequences. As general backbone, achieves state-of-the-art across language, audio, genomics. On language modeling, our Mamba-3B outperforms Transformers same size matches twice size, both pretraining downstream evaluation."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.03551,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Enhancing Weakly Supervised Semantic Segmentation for Fibrosis via\n  Controllable Image Generation",
    "a_abstract":"Fibrotic Lung Disease (FLD) is a severe condition marked by lung stiffening\nand scarring, leading to respiratory decline. High-resolution computed\ntomography (HRCT) is critical for diagnosing and monitoring FLD; however,\nfibrosis appears as irregular, diffuse patterns with unclear boundaries,\nleading to high inter-observer variability and time-intensive manual\nannotation. To tackle this challenge, we propose DiffSeg, a novel weakly\nsupervised semantic segmentation (WSSS) method that uses image-level\nannotations to generate pixel-level fibrosis segmentation, reducing the need\nfor fine-grained manual labeling. Additionally, our DiffSeg incorporates a\ndiffusion-based generative model to synthesize HRCT images with different\nlevels of fibrosis from healthy slices, enabling the generation of the\nfibrosis-injected slices and their paired fibrosis location. Experiments\nindicate that our method significantly improves the accuracy of pseudo masks\ngenerated by existing WSSS methods, greatly reducing the complexity of manual\nlabeling and enhancing the consistency of the generated masks.",
    "explanation":"However, fibrosis appears\nas irregular, diffuse patterns with unclear boundaries, lead-\ning to high inter-observer variability and time-intensive man-\nual annotation. To tackle this challenge, we propose DiffSeg,\na novel weakly supervised semantic segmentation (WSSS)\nmethod that uses image-level annotations to generate pixel-\nlevel fibrosis segmentation, reducing the need for fine-grained\nmanual labeling. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Interobserver Variability in the CT Assessment of Honeycombing in the Lungs"
    ],
    "b_abstract":[
      "To quantify observer agreement and analyze causes of disagreement in identifying honeycombing at chest computed tomography (CT).The institutional review board approved this multiinstitutional HIPAA-compliant retrospective study, informed patient consent was not required. Five core study members scored 80 CT images with a five-point scale (5 = definitely yes to 1 no) establish reference standard for the identification honeycombing. Forty-three observers from various subspecialties geographic regions by using same scoring system. Weighted \u03ba values scores compared were analyzed investigate intergroup differences. Images divided into four groups allow analysis imaging features cases which there disagreement: on presence honeycombing, absence other (none preceding three applied).Agreement 43 moderate (Cohen weighted values: 0.40-0.58). There no significant differences among defined either subspecialty or region (Tukey-Kramer test, P .38 >.99). In 29% cases, These included mixed traction bronchiectasis, large cysts, superimposed pulmonary emphysema.Identification is subjective, largely caused conditions that mimic"
    ],
    "b_categories":[
      "Radiology"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "DuPL: Dual Student with Trustworthy Progressive Learning for Robust Weakly Supervised Semantic Segmentation"
    ],
    "c_abstract":[
      "Recently, One-stage Weakly Supervised Semantic Segmentation (WSSS) with image-level labels has gained increasing interest due to simplification over its cumbersome multi-stage counterpart. Limited by the inherent ambiguity of Class Activation Map (CAM), we observe that one-stage pipelines often encounter confirmation bias caused by incorrect CAM pseudo-labels, impairing their final segmentation performance. Although recent works discard many unreliable pseudo-labels to implicitly alleviate this issue, they fail to exploit sufficient supervision for their models. To this end, we propose a dual student framework with trustworthy progressive learning (DuPL). Specifically, we propose a dual student network with a discrepancy loss to yield diverse CAMs for each sub-net. The two sub-nets generate supervision for each other, mitigating the confirmation bias caused by learning their own incorrect pseudo-labels. In this process, we progressively introduce more trustworthy pseudo-labels to be involved in the supervision through dynamic threshold adjustment with an adaptive noise filtering strategy. Moreover, we believe that every pixel, even discarded from supervision due to its unreliability, is important for WSSS. Thus, we develop consistency regularization on these discarded regions, providing supervision of every pixel. Experiment results demonstrate the superiority of the proposed DuPL over the recent state-of-the-art alternatives on PASCAL VOC 2012 and MS COCO datasets."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.09469,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"An Explainable Attention Model for Cervical Precancer Risk\n  Classification using Colposcopic Images",
    "a_abstract":"Cervical cancer remains a major worldwide health issue, with early\nidentification and risk assessment playing critical roles in effective\npreventive interventions. This paper presents the Cervix-AID-Net model for\ncervical precancer risk classification. The study designs and evaluates the\nproposed Cervix-AID-Net model based on patients colposcopy images. The model\ncomprises a Convolutional Block Attention Module (CBAM) and convolutional\nlayers that extract interpretable and representative features of colposcopic\nimages to distinguish high-risk and low-risk cervical precancer. In addition,\nthe proposed Cervix-AID-Net model integrates four explainable techniques,\nnamely gradient class activation maps, Local Interpretable Model-agnostic\nExplanations, CartoonX, and pixel rate distortion explanation based on output\nfeature maps and input features. The evaluation using holdout and ten-fold\ncross-validation techniques yielded a classification accuracy of 99.33\\% and\n99.81\\%. The analysis revealed that CartoonX provides meticulous explanations\nfor the decision of the Cervix-AID-Net model due to its ability to provide the\nrelevant piece-wise smooth part of the image. The effect of Gaussian noise and\nblur on the input shows that the performance remains unchanged up to Gaussian\nnoise of 3\\% and blur of 10\\%, while the performance reduces thereafter. A\ncomparison study of the proposed model's performance compared to other deep\nlearning approaches highlights the Cervix-AID-Net model's potential as a\nsupplemental tool for increasing the effectiveness of cervical precancer risk\nassessment. The proposed method, which incorporates the CBAM and explainable\nartificial integration, has the potential to influence cervical cancer\nprevention and early detection, improving patient outcomes and lowering the\nworldwide burden of this preventable disease.",
    "explanation":"This paper presents the Cervix-AID-Net model for cervical precancer risk classification. The study designs and evaluates the proposed Cervix-\nAID-Net model based on patients colposcopy images. The model comprises a Convolutional Block\nAttention Module (CBAM) and convolutional layers that extract interpretable and representative\nfeatures of colposcopic images to distinguish high-risk and low-risk cervical precancer. ",
    "b_id":[
      "b36"
    ],
    "b_title":[
      "CBAM: Convolutional block attention module"
    ],
    "b_abstract":[
      "We propose Convolutional Block Attention Module (CBAM), a simple yet effective attention module for feed-forward convolutional neural networks. Given an intermediate feature map, our module sequentially infers attention maps along two separate dimensions, channel and spatial, then the attention maps are multiplied to the input feature map for adaptive feature refinement. Because CBAM is a lightweight and general module, it can be integrated into any CNN architectures seamlessly with negligible overheads and is end-to-end trainable along with base CNNs. We validate our CBAM through extensive experiments on ImageNet-1K, MS~COCO detection, and VOC~2007 detection datasets. Our experiments show consistent improvements in classification and detection performances with various models, demonstrating the wide applicability of CBAM. The code and models will be publicly available."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "The accuracy of colposcopic biopsy: Analyses from the placebo arm of the Gardasil clinical trials"
    ],
    "c_abstract":[
      "We evaluated the overall agreement between colposcopically directed biopsies and definitive excisional specimens within context of three clinical trials. A total 737 women aged 16-45 who had a cervical biopsy taken 6 months before their therapy were included. Per-protocol, colposcopists to also obtain representative immediately therapy. Using adjudicated histological diagnoses, initial same day correlated with surgically excised specimens. The therapy, diagnoses was 42% (weighted kappa = 0.34) (95% CI: 0.29-0.39). underestimation intraepithelial neoplasia grade 2\/3 or adenocarcinoma in situ (CIN2-3\/AIS) CIN3\/AIS 26 42%, respectively. When allowing for one degree variance correlation, 92% CIN2-3\/AIS. specimen 56% 0.41) 0.36-0.47), CIN2-3\/AIS 57%. There significant associations when patients stratified by age, number biopsies, lesion size, presence human papillomavirus (HPV)16\/18 region. Of 178 diagnostic endocervical curettages performed, 14 (7.9%) found any HPV disease. Colposcopic accuracy improved CIN2 grouped as single predictive measure high-grade Colposcopy functioned well allowed one-degree difference surgical histologic interpretations, done practice. Taking more than colposcopic could improve patient management."
    ],
    "c_categories":[
      "Clinical Trial"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.14752,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Comparative Analysis of nnUNet and MedNeXt for Head and Neck Tumor\n  Segmentation in MRI-guided Radiotherapy",
    "a_abstract":"Radiation therapy (RT) is essential in treating head and neck cancer (HNC),\nwith magnetic resonance imaging(MRI)-guided RT offering superior soft tissue\ncontrast and functional imaging. However, manual tumor segmentation is\ntime-consuming and complex, and therfore remains a challenge. In this study, we\npresent our solution as team TUMOR to the HNTS-MRG24 MICCAI Challenge which is\nfocused on automated segmentation of primary gross tumor volumes (GTVp) and\nmetastatic lymph node gross tumor volume (GTVn) in pre-RT and mid-RT MRI\nimages. We utilized the HNTS-MRG2024 dataset, which consists of 150 MRI scans\nfrom patients diagnosed with HNC, including original and registered pre-RT and\nmid-RT T2-weighted images with corresponding segmentation masks for GTVp and\nGTVn. We employed two state-of-the-art models in deep learning, nnUNet and\nMedNeXt. For Task 1, we pretrained models on pre-RT registered and mid-RT\nimages, followed by fine-tuning on original pre-RT images. For Task 2, we\ncombined registered pre-RT images, registered pre-RT segmentation masks, and\nmid-RT data as a multi-channel input for training. Our solution for Task 1\nachieved 1st place in the final test phase with an aggregated Dice Similarity\nCoefficient of 0.8254, and our solution for Task 2 ranked 8th with a score of\n0.7005. The proposed solution is publicly available at Github Repository.",
    "explanation":"Radiation therapy (RT) is essential in treating head and neck cancer\n(HNC), with magnetic resonance imaging(MRI)-guided RT offering superior soft tis-\nsue contrast and functional imaging. However, manual tumor segmentation is time-\nconsuming and complex, and therfore remains a challenge. In this study, we present\nour solution as team TUMOR to the HNTS-MRG24 MICCAI Challenge which is\nfocused on automated segmentation of primary gross tumor volumes (GTVp) and\nmetastatic lymph node gross tumor volume (GTVn) in pre-RT and mid-RT MRI im-\nages. We employed two state-of-the-art models in deep learning, nnUNet and MedNeXt.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "\u201cApr\u00e8s Mois, Le D\u00e9luge\u201d: Preparing for the Coming Data Flood in the MRI-Guided Radiotherapy Era"
    ],
    "b_abstract":[
      "Magnetic resonance imaging provides a sea of quantitative and semi-quantitative data. While radiation oncologists already navigate pool clinical (semantic) data, the tide will swell with advent hybrid MRI\/linear accelerator devices increasing interest in MRI-guided radiotherapy (MRIgRT), including adaptive MRIgRT. The variety MR sequences (of greater complexity than single parameter Hounsfield unit CT scanning routinely used radiotherapy), workflow fractionation, sheer quantity daily images acquired are challenges for scaling this technology. Biomedical informatics, which is science information biomedicine, can provide helpful insights looming transition. Funneling MRIgRT data into clinically meaningful streams requires committing to flow inter-institutional accessibility interoperability initiatives, standardizing dosimetry methods, streamlining linear workflow, MRI acquisition post-processing, current topic review attempt conceptually ford using informatics approaches as theoretical bridge."
    ],
    "b_categories":[
      "Oncology"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation",
      "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "c_abstract":[
      "There has been exploding interest in embracing Transformer-based architectures for medical image segmentation. However, the lack of large-scale annotated medical datasets make achieving performances equivalent to those in natural images challenging. Convolutional networks, in contrast, have higher inductive biases and consequently, are easily trainable to high performance. Recently, the ConvNeXt architecture attempted to modernize the standard ConvNet by mirroring Transformer blocks. In this work, we improve upon this to design a modernized and scalable convolutional architecture customized to challenges of data-scarce medical settings. We introduce MedNeXt, a Transformer-inspired large kernel segmentation network which introduces - 1) A fully ConvNeXt 3D Encoder-Decoder Network for medical image segmentation, 2) Residual ConvNeXt up and downsampling blocks to preserve semantic richness across scales, 3) A novel technique to iteratively increase kernel sizes by upsampling small kernel networks, to prevent performance saturation on limited medical data, 4) Compound scaling at multiple levels (depth, width, kernel size) of MedNeXt. This leads to state-of-the-art performance on 4 tasks on CT and MRI modalities and varying dataset sizes, representing a modernized deep architecture for medical image segmentation. Our code is made publicly available at: https:\/\/github.com\/MIC-DKFZ\/MedNeXt.",
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.06785,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"White-Box Diffusion Transformer for single-cell RNA-seq generation",
    "a_abstract":"As a powerful tool for characterizing cellular subpopulations and cellular\nheterogeneity, single cell RNA sequencing (scRNA-seq) technology offers\nadvantages of high throughput and multidimensional analysis. However, the\nprocess of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a hybrid model\nbased on Diffusion model and White-Box transformer that aims to generate\nsynthetic and biologically plausible scRNA-seq data. Diffusion model\nprogressively introduce noise into the data and then recover the original data\nthrough a denoising process, a forward and reverse process that is particularly\nsuitable for generating complex data distributions. White-Box transformer is a\ndeep learning architecture that emphasizes mathematical interpretability. By\nminimizing the encoding rate of the data and maximizing the sparsity of the\nrepresentation, it not only reduces the computational burden, but also provides\nclear insight into underlying structure. Our White-Box Diffusion Transformer\ncombines the generative capabilities of Diffusion model with the mathematical\ninterpretability of White-Box transformer. Through experiments using six\ndifferent single-cell RNA-Seq datasets, we visualize both generated and real\ndata using t-SNE dimensionality reduction technique, as well as quantify\nsimilarity between generated and real data using various metrics to demonstrate\ncomparable performance of White-Box Diffusion Transformer and Diffusion\nTransformer in generating scRNA-seq data alongside significant improvements in\ntraining efficiency and resource utilization. Our code is available at\nhttps:\/\/github.com\/lingximamo\/White-Box-Diffusion-Transformer",
    "explanation":"As a powerful tool for characterizing cellular subpopulations and cellular heterogeneity, single cell\nRNA sequencing (scRNA-seq) technology offers advantages of high throughput and multidimensional\nanalysis. However, the process of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a model based on Diffusion model\nand White-Box transformer that aims to generate synthetic and biologically plausible scRNA-seq\ndata.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "RNA-Seq: a revolutionary tool for transcriptomics"
    ],
    "b_abstract":[
      "RNA-Seq is a recently developed approach to transcriptome profiling that uses deep-sequencing technologies. Studies using this method have already altered our view of the extent and complexity of eukaryotic transcriptomes. RNA-Seq also provides a far more precise measurement of levels of transcripts and their isoforms than other methods. This article describes the RNA-Seq approach, the challenges associated with its application, and the advances made so far in characterizing several eukaryote transcriptomes."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "White-Box Transformers via Sparse Rate Reduction"
    ],
    "c_abstract":[
      "In this paper, we contend that the objective of representation learning is to compress and transform distribution data, say sets tokens, towards a mixture low-dimensional Gaussian distributions supported on incoherent subspaces. The quality final can be measured by unified function called sparse rate reduction. From perspective, popular deep networks such as transformers naturally viewed realizing iterative schemes optimize incrementally. Particularly, show standard transformer block derived from alternating optimization complementary parts objective: multi-head self-attention operator gradient descent step token minimizing their lossy coding rate, subsequent multi-layer perceptron attempting sparsify tokens. This leads family white-box transformer-like network architectures which are mathematically fully interpretable. Despite simplicity, experiments these indeed learn designed they representations large-scale real-world vision datasets ImageNet, achieve performance very close thoroughly engineered ViT."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.00868,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Mathematics and Statistics"
    ],
    "a_title":"Quantifying perturbation impacts for large language models",
    "a_abstract":"We consider the problem of quantifying how an input perturbation impacts the\noutputs of large language models (LLMs), a fundamental task for model\nreliability and post-hoc interpretability. A key obstacle in this domain is\ndisentangling the meaningful changes in model responses from the intrinsic\nstochasticity of LLM outputs. To overcome this, we introduce Distribution-Based\nPerturbation Analysis (DBPA), a framework that reformulates LLM perturbation\nanalysis as a frequentist hypothesis testing problem. DBPA constructs empirical\nnull and alternative output distributions within a low-dimensional semantic\nsimilarity space via Monte Carlo sampling. Comparisons of Monte Carlo estimates\nin the reduced dimensionality space enables tractable frequentist inference\nwithout relying on restrictive distributional assumptions. The framework is\nmodel-agnostic, supports the evaluation of arbitrary input perturbations on any\nblack-box LLM, yields interpretable p-values, supports multiple perturbation\ntesting via controlled error rates, and provides scalar effect sizes for any\nchosen similarity or distance metric. We demonstrate the effectiveness of DBPA\nin evaluating perturbation impacts, showing its versatility for perturbation\nanalysis.",
    "explanation":"\"We consider the problem of quantifying how an input perturbation impacts the outputs of large language models (LLMs), a fundamental task for model reliability and post-hoc interpretability.\"",
    "b_id":[
      "b22"
    ],
    "b_title":[
      "Context-Aware Testing: A New Paradigm for Model Testing with Large\n  Language Models"
    ],
    "b_abstract":[
      "The predominant de facto paradigm of testing ML models relies on either using\nonly held-out data to compute aggregate evaluation metrics or by assessing the\nperformance on different subgroups. However, such data-only testing methods\noperate under the restrictive assumption that the available empirical data is\nthe sole input for testing ML models, disregarding valuable contextual\ninformation that could guide model testing. In this paper, we challenge the\ngo-to approach of data-only testing and introduce context-aware testing (CAT)\nwhich uses context as an inductive bias to guide the search for meaningful\nmodel failures. We instantiate the first CAT system, SMART Testing, which\nemploys large language models to hypothesize relevant and likely failures,\nwhich are evaluated on data using a self-falsification mechanism. Through\nempirical evaluations in diverse settings, we show that SMART automatically\nidentifies more relevant and impactful failures than alternatives,\ndemonstrating the potential of CAT as a testing paradigm."
    ],
    "b_categories":[
      "stat.ME"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "How resilient are language models to text perturbations"
    ],
    "c_abstract":[
      "Large language models typically rely on highly curated datasets that lack common irregularities such as typos and contractions, resulting in a mismatch between their training environments and real-world applications. This study evaluates the resilience of four prominent models in five different NLP tasks when confronted with perturbed inputs. We investigate three categories of perturbations: character-level, word-level and miscellaneous perturbations. By comparing performance on original and altered datasets, our results reveal a significant sensitivity to input perturbations across all models, with varying degrees of vulnerability depending on both the specific task and the type of perturbation. In particular, the XLNet model consistently shows superior robustness, while tasks involving grammatical coherence are most adversely affected."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.01668,
    "date":null,
    "fields":[
      "Economics and Quantitative Finance",
      "Mathematics and Statistics"
    ],
    "a_title":"Linear Quadratic Mean Field Games with Quantile-Dependent Cost\n  Coefficients",
    "a_abstract":"This paper studies a class of linear quadratic mean field games where the\ncoefficients of quadratic cost functions depend on both the mean and the\nvariance of the population's state distribution through its quantile function.\nSuch a formulation allows for modelling agents that are sensitive to not only\nthe population average but also the population variance. The corresponding mean\nfield game equilibrium is identified, which involves solving two coupled\ndifferential equations: one is a Riccati equation and the other the variance\nevolution equation. Furthermore, the conditions for the existence and\nuniqueness of the mean field equilibrium are established. Finally, numerical\nresults are presented to illustrate the behavior of two coupled differential\nequations and the performance of the mean field game solution.",
    "explanation":"\"This paper studies a class of linear quadratic mean field games where the coefficients of quadratic cost functions depend on both the mean and the variance of the population\u2019s state distribution through its quantile function. \"\n\n\n",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Mean\u2010field games with differing beliefs for algorithmic trading"
    ],
    "b_abstract":[
      "Abstract Even when confronted with the same data, agents often disagree on a model of real world. Here, we address question how interacting heterogeneous agents, who what world follows, optimize their trading actions. The market has latent factors that drive prices, and account for permanent impact they have prices. This leads to large stochastic game, where each performance criteria are computed under different probability measure. We analyze mean\u2010field game (MFG) limit show Nash equilibrium is given by solution nonstandard vector\u2010valued forward\u2013backward differential equation. Under some mild assumptions, construct in terms expectations filtered states. Furthermore, prove MFG strategy forms an \u03b5\u2010Nash finite player game. Finally, present least square Monte Carlo based algorithm computing equilibria through simulations increasing disagreement may increase price volatility activity."
    ],
    "b_categories":[
      "q-fin.MF"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Linear-quadratic mean field games"
    ],
    "c_abstract":[
      "In this article, we provide a comprehensive study of the linear-quadratic mean field games via the adjoint equation approach; although the problem has been considered in the literature by Huang, Caines and Malhame (HCM, 2007a), their method is based on Dynamic Programming. It turns out that two methods are not equivalent, as far as giving sufficient condition for the existence of a solution is concerned. Due to the linearity of the adjoint equations, the optimal mean field term satisfies a linear forward-backward ordinary differential equation. For the one dimensional case, we show that the equilibrium strategy always exists uniquely. For dimension greater than one, by choosing a suitable norm and then applying the Banach Fixed Point Theorem, a sufficient condition, which is independent of the solution of the standard Riccati differential equation, for the unique existence of the equilibrium strategy is provided. As a by-product, we also establish a neat and instructive sufficient condition for the unique existence of the solution for a class of non-trivial nonsymmetric Riccati equations. Numerical examples of non-existence of the equilibrium strategy and the comparison of HCM's approach will also be provided."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":2411.00575,
    "date":null,
    "fields":[
      "Mathematics and Statistics"
    ],
    "a_title":"A Semi-Discrete Optimal Transport Scheme for the 3D Incompressible\n  Semi-Geostrophic Equations",
    "a_abstract":"We describe a mesh-free three-dimensional numerical scheme for solving the\nincompressible semi-geostrophic equations based on semi-discrete optimal\ntransport techniques. These results generalise previous two-dimensional\nimplementations. The optimal transport methods we adopt are known for their\nstructural preservation and energy conservation qualities and achieve an\nexcellent level of efficiency and numerical energy-conservation. We use this\nscheme to generate numerical simulations of an important cyclone benchmark\nproblem. To our knowledge, this is the first fully three-dimensional simulation\nof the semi-geostrophic equations, evidencing semi-discrete optimal transport\nas a novel, robust numerical tool for meteorological and oceanographic\nmodelling.",
    "explanation":"We describe a mesh-free three-dimensional numerical scheme for solving the in-\ncompressible semi-geostrophic equations based on semi-discrete optimal transport techniques.\nThese results generalise previous two-dimensional implementations.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Weak Existence for the Semigeostrophic Equations Formulated as a Coupled Monge--Amp\u00e8re\/Transport Problem"
    ],
    "b_abstract":[
      "Hoskins's semigeostrophic equations are reformulated as a coupled Monge--Amp\u00e8re\/ transport problem [B. J. Hoskins, Quart. Royal Met. Soc., 97 (1971), pp. 139--153]. Existence of global weak solutions is obtained for this formulation."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b22"
    ],
    "c_title":[
      "Vertical slice modelling of nonlinear Eady waves using a compatible finite element method"
    ],
    "c_abstract":[
      "A vertical slice model is developed for the Euler-Boussinesq equations with a\nconstant temperature gradient in the direction normal to the slice (the\nEady-Boussinesq model). The model is a solution of the full three-dimensional\nequations with no variation normal to the slice, which is an idealized problem\nused to study the formation and subsequent evolution of weather fronts. A\ncompatible finite element method is used to discretise the governing equations.\nTo extend the Charney-Phillips grid staggering in the compatible finite element\nframework, we use the same node locations for buoyancy as the vertical part of\nvelocity and apply a transport scheme for a partially continuous finite element\nspace. For the time discretisation, we solve the semi-implicit equations\ntogether with an explicit strong-stability-preserving Runge-Kutta scheme to all\nof the advection terms. The model reproduces several quasi-periodic lifecycles\nof fronts despite the presence of strong discontinuities. An asymptotic limit\nanalysis based on the semi-geostrophic theory shows that the model solutions\nare converging to a solution in cross-front geostrophic balance. The results\nare consistent with the previous results using finite difference methods,\nindicating that the compatible finite element method is performing as well as\nfinite difference methods for this test problem. We observe dissipation of\nkinetic energy of the cross-front velocity in the model due to the lack of\nresolution at the fronts, even though the energy loss is not likely to account\nfor the large gap on the strength of the fronts between the model result and\nthe semi-geostrophic limit solution."
    ],
    "c_categories":[
      "math.MP"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":2411.00578,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Federated Voxel Scene Graph for Intracranial Hemorrhage",
    "a_abstract":"Intracranial Hemorrhage is a potentially lethal condition whose manifestation\nis vastly diverse and shifts across clinical centers worldwide.\nDeep-learning-based solutions are starting to model complex relations between\nbrain structures, but still struggle to generalize. While gathering more\ndiverse data is the most natural approach, privacy regulations often limit the\nsharing of medical data. We propose the first application of Federated Scene\nGraph Generation. We show that our models can leverage the increased training\ndata diversity. For Scene Graph Generation, they can recall up to 20% more\nclinically relevant relations across datasets compared to models trained on a\nsingle centralized dataset. Learning structured data representation in a\nfederated setting can open the way to the development of new methods that can\nleverage this finer information to regularize across clients more effectively.",
    "explanation":"intracranial Hemorrhage is a potentially lethal condition whose manifestation is vastly diverse and shifts across\nclinical centers worldwide. Deep-learning-based solutions are starting to model complex relations between brain\nstructures, but still struggle to generalize.",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "American Heart Association\/American Stroke Association. 2022 guideline for the management of patients with spontaneous intracerebral hemorrhage: A guideline from the american heart association\/american stroke association"
    ],
    "b_abstract":[
      "Approximately 10% of the 795\u2009000 strokes per year in the United States are intracerebral hemorrhages (ICHs),1 defined by brain injury attributable to acute blood extravasation into the brain parenchyma from a ruptured cerebral blood vessel. The clinical impact of ICH appears disproportionately high among lower-resource populations both in the United States and internationally. In US-based studies, ICH incidence has been reported to be \u22481.6-fold greater among Black than White people2 and 1.6-fold greater among Mexican American than non-Hispanic White people.3 Internationally, ICH incidence is substantially higher in low- and middle-income versus high-income countries, both as a proportion of all strokes and in absolute incidence rates.4,5 Several additional features of ICH make it a greater public health threat than conveyed by incidence numbers alone. ICH is arguably the deadliest form of acute stroke, with early-term mortality about 30% to 40% and no or minimal trend toward improvement over more recent time epochs.6\u20139 Incidence of ICH increases sharply with age and is therefore expected to remain substantial as the population ages, even with counterbalancing public health improvements in blood pressure (BP) control.8 Another growing source of ICH is more widespread use of anticoagulants,10 a trend likely to counterbalance the reduced ICH risk associated with increasing prescription of direct oral anticoagulants (DOACs) relative to vitamin K antagonists (VKAs).11 ICH thus remains in need of novel treatments and improved application of established approaches for every aspect of the disease: primary and secondary prevention, acute inpatient care, and poststroke rehabilitation and recovery. This guideline seeks to synthesize data in the ICH field into practical recommendations for clinical practice."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "Voxel Scene Graph for Intracranial Hemorrhage"
    ],
    "c_abstract":[
      "Patients with Intracranial Hemorrhage (ICH) face a potentially life-threatening condition, and patient-centered individualized treatment remains challenging due to possible clinical complications. Deep-Learning-based methods can efficiently analyze the routinely acquired head CTs support decision-making. The majority of early work focuses on detection segmentation ICH, but do not model complex relations between ICH adjacent brain structures. In this work, we design tailored object method for which unite segmentation-grounded Scene Graph Generation (SGG) learn holistic representation cerebral scene. To best our knowledge, is first application SGG 3D voxel images. We evaluate two head-CT datasets demonstrate that recall up 74% clinically relevant relations. This lays foundation towards data. generated Graphs already provide insights clinician, are also valuable all downstream tasks as compact interpretable representation."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.00614,
    "date":null,
    "fields":[
      "Mathematics and Statistics",
      "Quantitative Biology"
    ],
    "a_title":"Fast and scalable Wasserstein-1 neural optimal transport solver for\n  single-cell perturbation prediction",
    "a_abstract":"Predicting single-cell perturbation responses requires mapping between two\nunpaired single-cell data distributions. Optimal transport (OT) theory provides\na principled framework for constructing such mappings by minimizing transport\ncost. Recently, Wasserstein-2 ($W_2$) neural optimal transport solvers\n(\\textit{e.g.}, CellOT) have been employed for this prediction task. However,\n$W_2$ OT relies on the general Kantorovich dual formulation, which involves\noptimizing over two conjugate functions, leading to a complex min-max\noptimization problem that converges slowly. To address these challenges, we\npropose a novel solver based on the Wasserstein-1 ($W_1$) dual formulation.\nUnlike $W_2$, the $W_1$ dual simplifies the optimization to a maximization\nproblem over a single 1-Lipschitz function, thus eliminating the need for\ntime-consuming min-max optimization. While solving the $W_1$ dual only reveals\nthe transport direction and does not directly provide a unique optimal\ntransport map, we incorporate an additional step using adversarial training to\ndetermine an appropriate transport step size, effectively recovering the\ntransport map. Our experiments demonstrate that the proposed $W_1$ neural\noptimal transport solver can mimic the $W_2$ OT solvers in finding a unique and\n``monotonic\" map on 2D datasets. Moreover, the $W_1$ OT solver achieves\nperformance on par with or surpasses $W_2$ OT solvers on real single-cell\nperturbation datasets. Furthermore, we show that $W_1$ OT solver achieves $25\n\\sim 45\\times$ speedup, scales better on high dimensional transportation task,\nand can be directly applied on single-cell RNA-seq dataset with highly variable\ngenes. Our implementation and experiments are open-sourced at\n\\url{https:\/\/github.com\/poseidonchan\/w1ot}.",
    "explanation":"Predicting single-cell perturbation responses requires mapping between two unpaired single-\ncell data distributions. Optimal transport (OT) theory provides a principled framework for constructing\nsuch mappings by minimizing transport cost.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Multimodal pooled Perturb-CITE-seq screens in patient models define mechanisms of cancer immune evasion"
    ],
    "b_abstract":[
      "Resistance to immune checkpoint inhibitors (ICIs) is a key challenge in cancer therapy. To elucidate underlying mechanisms, we developed Perturb-CITE-sequencing (Perturb-CITE-seq), enabling pooled clustered regularly interspaced short palindromic repeat (CRISPR)\u2013Cas9 perturbations with single-cell transcriptome and protein readouts. In patient-derived melanoma cells and autologous tumor-infiltrating lymphocyte (TIL) co-cultures, we profiled transcriptomes and 20\u2009proteins in ~218,000\u2009cells under ~750\u2009perturbations associated with cancer cell-intrinsic ICI resistance (ICR). We recover known mechanisms of resistance, including defects in the interferon-\u03b3 (IFN-\u03b3)\u2013JAK\/STAT and antigen-presentation pathways in RNA, protein and perturbation space, and new ones, including loss\/downregulation of CD58. Loss of CD58 conferred immune evasion in multiple co-culture models and was downregulated in tumors of melanoma patients with ICR. CD58 protein expression was not induced by IFN-\u03b3 signaling, and CD58 loss conferred immune evasion without compromising major histocompatibility complex (MHC) expression, suggesting that it acts orthogonally to known mechanisms of ICR. This work provides a framework for the deciphering of complex mechanisms by large-scale perturbation screens with multimodal, single-cell readouts, and discovers potentially clinically relevant mechanisms of immune evasion."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Causal identification of single-cell experimental perturbation effects with CINEMA-OT"
    ],
    "c_abstract":[
      "Abstract Recent advancements in single-cell technologies allow characterization of experimental perturbations at resolution. While methods have been developed to analyze such experiments, the application a strict causal framework has not yet explored for inference treatment effects level. Here we present causal-inference-based approach perturbation analysis, termed CINEMA-OT (causal independent effect module attribution + optimal transport). separates confounding sources variation from obtain an transport matching that reflects counterfactual cell pairs. These pairs represent responses permitting number novel analyses, as individual treatment-effect response clustering, and synergy analysis. We benchmark on array estimation tasks several simulated real datasets show it outperforms other analysis methods. Finally, perform two newly generated datasets: (1) rhinovirus cigarette-smoke-exposed airway organoids, (2) combinatorial cytokine stimulation immune cells. In these reveals potential mechanisms by which cigarette-smoke exposure dulls antiviral response, well logic governs chemokine secretion peripheral recruitment."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.00714,
    "date":null,
    "fields":[

    ],
    "a_title":"Self-reinforcing cascades: A spreading model for beliefs or products of\n  varying intensity or quality",
    "a_abstract":"Models of how things spread often assume that transmission mechanisms are\nfixed over time. However, social contagions--the spread of ideas, beliefs,\ninnovations--can lose or gain in momentum as they spread: ideas can get\nreinforced, beliefs strengthened, products refined. We study the impacts of\nsuch self-reinforcement mechanisms in cascade dynamics. We use different\nmathematical modeling techniques to capture the recursive, yet changing nature\nof the process. We find a critical regime with a range of power-law cascade\nsize distributions with varying scaling exponents. This regime clashes with\nclassic models, where criticality requires fine tuning at a precise critical\npoint. Self-reinforced cascades produce critical-like behavior over a wide\nrange of parameters, which may help explain the ubiquity of power-law\ndistributions in empirical social data.",
    "explanation":"Models of how things spread often assume that transmission mechanisms are fixed over time. However, social\ncontagions\u2013the spread of ideas, beliefs, innovations\u2013can lose or gain in momentum as they spread: ideas can get\nreinforced, beliefs strengthened, products refined. e use different mathematical modeling techniques to capture the recursive, yet changing\nnature of the process.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Universality, criticality and complexity of information propagation in social media"
    ],
    "b_abstract":[
      "Abstract Statistical laws of information avalanches in social media appear, at least according to existing empirical studies, not robust across systems. As a consequence, radically different processes may represent plausible driving mechanisms for propagation. Here, we analyze almost one billion time-stamped events collected from several online platforms \u2013 including Telegram, Twitter and Weibo over observation windows longer than ten years, show that the propagation is universal critical process. Universality arises identical macroscopic patterns platforms, irrespective details specific system hand. Critical behavior deduced power-law distributions, corresponding hyperscaling relations, characterizing size duration information. testing on our data indicates mixture simple complex contagion characterizes media. Data suggest complexity process correlated with semantic content propagated."
    ],
    "b_categories":[
      "Human Behaviors"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "Random graphs with arbitrary degree distributions and their applications"
    ],
    "c_abstract":[
      "Recent work on the structure of social networks and internet has focused attention graphs with distributions vertex degree that are significantly different from Poisson have been widely studied in past. In this paper we develop detail theory random arbitrary distributions. addition to simple undirected, unipartite graphs, examine properties directed bipartite graphs. Among other results, derive exact expressions for position phase transition at which a giant component first forms, mean size, size if there is one, number vertices certain distance away randomly chosen vertex, average vertex-vertex within graph. We apply our some real-world including world-wide web collaboration scientists Fortune 1000 company directors. demonstrate cases appropriate predict surprising accuracy behavior real world, while others measurable discrepancy between reality, perhaps indicating presence additional network not captured by"
    ],
    "c_categories":[
      "Modeling"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":2411.00749,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"PathoGen-X: A Cross-Modal Genomic Feature Trans-Align Network for\n  Enhanced Survival Prediction from Histopathology Images",
    "a_abstract":"Accurate survival prediction is essential for personalized cancer treatment.\nHowever, genomic data - often a more powerful predictor than pathology data -\nis costly and inaccessible. We present the cross-modal genomic feature\ntranslation and alignment network for enhanced survival prediction from\nhistopathology images (PathoGen-X). It is a deep learning framework that\nleverages both genomic and imaging data during training, relying solely on\nimaging data at testing. PathoGen-X employs transformer-based networks to align\nand translate image features into the genomic feature space, enhancing weaker\nimaging signals with stronger genomic signals. Unlike other methods, PathoGen-X\ntranslates and aligns features without projecting them to a shared latent space\nand requires fewer paired samples. Evaluated on TCGA-BRCA, TCGA-LUAD, and\nTCGA-GBM datasets, PathoGen-X demonstrates strong survival prediction\nperformance, emphasizing the potential of enriched imaging models for\naccessible cancer prognosis.",
    "explanation":"Accurate survival prediction is essential for personalized\ncancer treatment. . It is a\ndeep learning framework that leverages both genomic and\nimaging data during training, relying solely on imaging data\nat testing. ",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "A 2021 update on cancer image analytics with deep learning"
    ],
    "b_abstract":[
      "Deep learning (DL)-based interpretation of medical images has reached a critical juncture of expanding outside research projects into translational ones, and is ready to make its way to the clinics. Advances over the last decade in data availability, DL techniques, as well as computing capabilities have accelerated this journey. Through this journey, today we have a better understanding of the challenges to and pitfalls of wider adoption of DL into clinical care, which, according to us, should and will drive the advances in this field in the next few years. The most important among these challenges are the lack of an appropriately digitized environment within healthcare institutions, the lack of adequate open and representative datasets on which DL algorithms can be trained and tested, and the lack of robustness of widely used DL training algorithms to certain pervasive pathological characteristics of medical images and repositories. In this review, we provide an overview of the role of imaging in oncology, the different techniques that are shaping the way DL algorithms are being made ready for clinical use, and also the problems that DL techniques still need to address before DL can find a home in clinics. Finally, we also provide a summary of how DL can potentially drive the adoption of digital pathology, vendor neutral archives, and picture archival and communication systems. We caution that the respective researchers may find the coverage of their own fields to be at a high-level. This is so by design as this format is meant to only introduce those looking in from outside of deep learning and medical research, respectively, to gain an appreciation for the main concerns and limitations of these two fields instead of telling them something new about their own."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classification"
    ],
    "c_abstract":[
      "Multiple instance learning (MIL) is a powerful tool to solve the weakly supervised classification in whole slide image (WSI) based pathology diagnosis. However, current MIL methods are usually on independent and identical distribution hypothesis, thus neglect correlation among different instances. To address this problem, we proposed new framework, called correlated MIL, provided proof for convergence. Based devised Transformer (TransMIL), which explored both morphological spatial information. The TransMIL can effectively deal with unbalanced\/balanced binary\/multiple great visualization interpretability. We conducted various experiments three computational problems achieved better performance faster convergence compared state-of-the-art methods. test AUC binary tumor be up 93.09% over CAMELYON16 dataset. And cancer subtypes 96.03% 98.82% TCGA-NSCLC dataset TCGA-RCC dataset, respectively. Implementation available at: https:\/\/github.com\/szc19990412\/TransMIL."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.00758,
    "date":null,
    "fields":[
      "Physics",
      "Mathematics and Statistics"
    ],
    "a_title":"Inverse methods for freeform optical design",
    "a_abstract":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design, based on Hamilton's characteristic functions and\nconservation of luminous flux, and briefly explain the connection with the\nmathematical theory of optimal transport. We outline several iterative\nleast-squares solvers for our models and demonstrate their performance for a\nfew challenging problems.",
    "explanation":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design .We outline several iterative least-squares solvers for our models and demonstrate their\nperformance for a few challenging problems.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Introduction to Nonimaging Optics, second edition"
    ],
    "b_abstract":[
      "Introduction to Nonimaging Optics covers the theoretical foundations and design methods of nonimaging optics, as well as key concepts from related fields. This fully updated, revised, and expanded Second Edition: \u2022 Features a new and intuitive introduction with a basic description of the advantages of nonimaging optics \u2022 Adds new chapters on wavefronts for a prescribed output (irradiance or intensity), infinitesimal \u00e9tendue optics (generalization of the aplanatic optics), and K\u00f6hler optics and color mixing \u2022 Incorporates new material on the simultaneous multiple surface (SMS) design method in 3-D, integral invariants, and \u00e9tendue 2-D \u2022 Contains 21 chapters, 24 fully worked and several other examples, and 1,000+ illustrations, including photos of real devices \u2022 Addresses applications ranging from solar energy concentration to illumination engineering Introduction to Nonimaging Optics, Second Edition invites newcomers to explore the growing field of nonimaging optics, while providing seasoned veterans with an extensive reference book."
    ],
    "b_categories":[
      "physics.optics"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "Inverse methods for illumination optics"
    ],
    "c_abstract":[
      "\u2022 A submitted manuscript is the version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website. \u2022 The final author version and the galley proof are versions of the publication after peer review. \u2022 The final published version features the final layout of the paper including the volume, issue and page numbers."
    ],
    "c_categories":[
      "math.MP"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":2411.01291,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Deep Multi-contrast Cardiac MRI Reconstruction via vSHARP with Auxiliary\n  Refinement Network",
    "a_abstract":"Cardiac MRI (CMRI) is a cornerstone imaging modality that provides in-depth\ninsights into cardiac structure and function. Multi-contrast CMRI (MCCMRI),\nwhich acquires sequences with varying contrast weightings, significantly\nenhances diagnostic capabilities by capturing a wide range of cardiac tissue\ncharacteristics. However, MCCMRI is often constrained by lengthy acquisition\ntimes and susceptibility to motion artifacts. To mitigate these challenges,\naccelerated imaging techniques that use k-space undersampling via different\nsampling schemes at acceleration factors have been developed to shorten scan\ndurations. In this context, we propose a deep learning-based reconstruction\nmethod for 2D dynamic multi-contrast, multi-scheme, and multi-acceleration MRI.\nOur approach integrates the state-of-the-art vSHARP model, which utilizes\nhalf-quadratic variable splitting and ADMM optimization, with a Variational\nNetwork serving as an Auxiliary Refinement Network (ARN) to better adapt to the\ndiverse nature of MCCMRI data. Specifically, the subsampled k-space data is fed\ninto the ARN, which produces an initial prediction for the denoising step used\nby vSHARP. This, along with the subsampled k-space, is then used by vSHARP to\ngenerate high-quality 2D sequence predictions. Our method outperforms\ntraditional reconstruction techniques and other vSHARP-based models.",
    "explanation":"Cardiac MRI (CMRI) is a cornerstone imaging modality that\nprovides in-depth insights into cardiac structure and function.  Our approach integrates the state-of-the-art vSHARP model, which uti-\nlizes half-quadratic variable splitting and ADMM optimization, with a\nVariational Network serving as an Auxiliary Refinement Network (ARN)\nto better adapt to the diverse nature of MCCMRI data. ",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting\n  Universal Machine Learning for Accelerated Cardiac MRI"
    ],
    "b_abstract":[
      "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically gold-standard technique for diagnosing cardiac diseases, thanks to its ability provide diverse information with multiple modalities and anatomical views. Accelerated MRI is highly expected achieve time-efficient patient-friendly imaging, then advanced image reconstruction approaches are required recover high-quality, interpretable images from undersampled measurements. However, the lack of publicly available k-space dataset in terms both quantity diversity severely hindered substantial technological progress, particularly data-driven artificial intelligence. Here, we standardized, diverse, high-quality CMRxRecon2024 facilitate technical development, fair evaluation, clinical transfer approaches, towards promoting universal frameworks that enable fast robust reconstructions across different protocols practice. To best our knowledge, largest most dataset. It acquired 330 healthy volunteers, covering commonly used modalities, views, acquisition trajectories workflows. Besides, an open platform tutorials, benchmarks, data processing tools provided usage, method performance evaluation."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b19"
    ],
    "c_title":[
      "vSHARP: variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse-Problems"
    ],
    "c_abstract":[
      "Medical Imaging (MI) tasks, such as accelerated parallel Magnetic Resonance Imaging (MRI), often involve reconstructing an image from noisy or incomplete measurements. This amounts to solving ill-posed inverse problems, where a satisfactory closed-form analytical solution is not available. Traditional methods such as Compressed Sensing (CS) in MRI reconstruction can be time-consuming or prone to obtaining low-fidelity images. Recently, a plethora of Deep Learning (DL) approaches have demonstrated superior performance in inverse-problem solving, surpassing conventional methods. In this study, we propose vSHARP (variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse Problems), a novel DL-based method for solving ill-posed inverse problems arising in MI. vSHARP utilizes the Half-Quadratic Variable Splitting method and employs the Alternating Direction Method of Multipliers (ADMM) to unroll the optimization process. For data consistency, vSHARP unrolls a differentiable gradient descent process in the image domain, while a DL-based denoiser, such as a U-Net architecture, is applied to enhance image quality. vSHARP also employs a dilated-convolution DL-based model to predict the Lagrange multipliers for the ADMM initialization. We evaluate vSHARP on tasks of accelerated parallel MRI Reconstruction using two distinct datasets and on accelerated parallel dynamic MRI Reconstruction using another dataset. Our comparative analysis with state-of-the-art methods demonstrates the superior performance of vSHARP in these applications."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.01758,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Disentangled PET Lesion Segmentation",
    "a_abstract":"PET imaging is an invaluable tool in clinical settings as it captures the\nfunctional activity of both healthy anatomy and cancerous lesions. Developing\nautomatic lesion segmentation methods for PET images is crucial since manual\nlesion segmentation is laborious and prone to inter- and intra-observer\nvariability. We propose PET-Disentangler, a 3D disentanglement method that uses\na 3D UNet-like encoder-decoder architecture to disentangle disease and normal\nhealthy anatomical features with losses for segmentation, reconstruction, and\nhealthy component plausibility. A critic network is used to encourage the\nhealthy latent features to match the distribution of healthy samples and thus\nencourages these features to not contain any lesion-related features. Our\nquantitative results show that PET-Disentangler is less prone to incorrectly\ndeclaring healthy and high tracer uptake regions as cancerous lesions, since\nsuch uptake pattern would be assigned to the disentangled healthy component.",
    "explanation":"PET imaging is an invaluable tool in clinical settings as it\ncaptures the functional activity of both healthy anatomy and\ncancerous lesions. Developing automatic lesion segmentation\nmethods for PET images is crucial since manual lesion seg-\nmentation is laborious and prone to inter- and intra-observer\nvariability. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Multi-site quality and variability analysis of 3D FDG PET segmentations based on phantom and clinical image data"
    ],
    "b_abstract":[
      "Purpose: Radiomics utilizes a large number of image-derived features for quantifying tumor characteristics that can in turn be correlated with response and prognosis. Unfortunately, extraction and analysis of such image-based features is subject to measurement variability and bias. The challenge for radiomics is particularly acute in Positron Emission Tomography (PET) where limited resolution, a high noise component related to the limited stochastic nature of the raw data, and the wide variety of reconstruction options confound quantitative feature metrics. Extracted feature quality is also affected by tumor segmentation methods used to define regions over which to calculate features, making it challenging to produce consistent radiomics analysis results across multiple institutions that use different segmentation algorithms in their PET image analysis. Understanding each element contributing to these inconsistencies in quantitative image feature and metric generation is paramount for ultimate utilization of these methods in multi-institutional trials and clinical oncology decision making. Methods: To assess segmentation quality and consistency at the multi-institutional level, we conducted a study of seven institutional members of the National Cancer Institute Quantitative Imaging Network. For the study, members were asked to segment a common set of phantom PET scans acquired over a range of imaging conditions as well as a second set of head and neck cancer (HNC) PET scans. Segmentations were generated at each institution using their preferred approach. In addition, participants were asked to repeat segmentations with a time interval between initial and repeat segmentation. This procedure resulted in overall 806 phantom insert and 641 lesion segmentations. Subsequently, the volume was computed from the segmentations and compared to the corresponding reference volume by means of statistical analysis. Results: On the two test sets (phantom and HNC PET scans), the performance of the seven segmentation approaches was as follows. On the phantom test set, the mean relative volume errors ranged from 29.9 to 87.8% of the ground truth reference volumes, and the repeat difference for each institution ranged between -36.4 to 39.9%. On the HNC test set, the mean relative volume error ranged between -50.5 to 701.5%, and the repeat difference for each institution ranged between -37.7 to 31.5%. In addition, performance measures per phantom insert\/lesion size categories are given in the paper. On phantom data, regression analysis resulted in coefficient of variation (CV) components of 42.5% for scanners, 26.8% for institutional approaches, 21.1% for repeated segmentations, 14.3% for relative contrasts, 5.3% for count statistics (acquisition times), and 0.0% for repeated scans. Analysis showed that the CV components for approaches and repeated segmentations were significantly larger on the HNC test set with increases by 112.7% and 102.4%, respectively. Conclusion: Analysis results underline the importance of PET scanner reconstruction harmonization and imaging protocol standardization for quantification of lesion volumes. In addition, to enable a distributed multi-site analysis of FDG PET images, harmonization of analysis approaches and operator training in combination with highly automated segmentation methods seems to be advisable. Future work will focus on quantifying the impact of segmentation variation on radiomics system performance."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "A review on segmentation of positron emission tomography images"
    ],
    "c_abstract":[
      "Positron Emission Tomography (PET), a non-invasive functional imaging method at the molecular level, images the distribution of biologically targeted radiotracers with high sensitivity. PET imaging provides detailed quantitative information about many diseases and is often used to evaluate inflammation, infection, and cancer by detecting emitted photons from a radiotracer localized to abnormal cells. In order to differentiate abnormal tissue from surrounding areas in PET images, image segmentation methods play a vital role; therefore, accurate image segmentation is often necessary for proper disease detection, diagnosis, treatment planning, and follow-ups. In this review paper, we present state-of-the-art PET image segmentation methods, as well as the recent advances in image segmentation techniques. In order to make this manuscript self-contained, we also briefly explain the fundamentals of PET imaging, the challenges of diagnostic PET image analysis, and the effects of these challenges on the segmentation results."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.03389,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Neurons for Neutrons: A Transformer Model for Computation Load\n  Estimation on Domain-Decomposed Neutron Transport Problems",
    "a_abstract":"Domain decomposition is a technique used to reduce memory overhead on large\nneutron transport problems. Currently, the optimal load-balanced processor\nallocation for these domains is typically determined through small-scale\nsimulations of the problem, which can be time-consuming for researchers and\nmust be repeated anytime a problem input is changed. We propose a Transformer\nmodel with a unique 3D input embedding, and input representations designed for\ndomain-decomposed neutron transport problems, which can predict the subdomain\ncomputation loads generated by small-scale simulations. We demonstrate that\nsuch a model trained on domain-decomposed Small Modular Reactor (SMR)\nsimulations achieves 98.2% accuracy while being able to skip the small-scale\nsimulation step entirely. Tests of the model's robustness on variant fuel\nassemblies, other problem geometries, and changes in simulation parameters are\nalso discussed.",
    "explanation":"Currently, the optimal load-\nbalanced processor allocation for these domains is typically determined\nthrough small-scale simulations of the problem, which can be time-consuming\nfor researchers and must be repeated anytime a problem input is changed.\nWe propose a Transformer model with a unique 3D input embedding, and\ninput representations designed for domain-decomposed neutron transport\nproblems, which can predict the subdomain computation loads generated\nby small-scale simulations.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Attention Is All You Need"
    ],
    "b_abstract":[
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. best performing also connect the encoder and decoder through attention mechanism. We propose a new simple network architecture, Transformer, solely mechanisms, dispensing with recurrence convolutions entirely. Experiments two machine translation tasks show these to be superior quality while being more parallelizable requiring significantly less time train. Our model achieves 28.4 BLEU WMT 2014 English-to-German task, improving over existing results, including ensembles by 2 BLEU. On English-to-French our establishes single-model state-of-the-art score of 41.8 after training for 3.5 days eight GPUs, small fraction costs from literature. that Transformer generalizes well other applying it successfully English constituency parsing both large limited data."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Continuous-energy Monte Carlo neutron transport on GPUs in the Shift code"
    ],
    "c_abstract":[
      "A continuous-energy Monte Carlo neutron transport solver executing on GPUs has been developed within the Shift code. Several algorithmic approaches are considered, including both history-based and event-based implementations. Unlike in previous work involving multigroup Monte Carlo transport, it is demonstrated that event-based algorithms significantly outperform a history-based approach for continuous-energy transport as a result of increased device occupancy and reduced thread divergence. Numerical results are presented for detailed full-core models of a small modular reactor (SMR), including a model containing depleted fuel materials. These results demonstrate the substantial gains in performance that are possible with the latest-generation of GPUs. On the depleted SMR core configuration, an NVIDIA P100 GPU with 56 streaming multiprocessors provides performance equivalent to 90 CPU cores, and the latest V100 GPU with 80 multiprocessors offers the performance of more than 150 CPU cores."
    ],
    "c_categories":[
      "astro-ph.HE"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.04682,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"DNN-based 3D Cloud Retrieval for Variable Solar Illumination and\n  Multiview Spaceborne Imaging",
    "a_abstract":"Climate studies often rely on remotely sensed images to retrieve\ntwo-dimensional maps of cloud properties. To advance volumetric analysis, we\nfocus on recovering the three-dimensional (3D) heterogeneous extinction\ncoefficient field of shallow clouds using multiview remote sensing data.\nClimate research requires large-scale worldwide statistics. To enable scalable\ndata processing, previous deep neural networks (DNNs) can infer at spaceborne\nremote sensing downlink rates. However, prior methods are limited to a fixed\nsolar illumination direction. In this work, we introduce the first scalable\nDNN-based system for 3D cloud retrieval that accommodates varying camera poses\nand solar directions. By integrating multiview cloud intensity images with\ncamera poses and solar direction data, we achieve greater flexibility in\nrecovery. Training of the DNN is performed by a novel two-stage scheme to\naddress the high number of degrees of freedom in this problem. Our approach\nshows substantial improvements over previous state-of-the-art, particularly in\nhandling variations in the sun's zenith angle.",
    "explanation":"Climate studies often rely on remotely sensed im-\nages to retrieve two-dimensional maps of cloud properties. To\nadvance volumetric analysis, we focus on recovering the three-\ndimensional (3D) heterogeneous extinction coefficient field of\nshallow clouds using multiview remote sensing data. \n\n\nTo enable\nscalable data processing, previous deep neural networks (DNNs)\ncan infer at spaceborne remote sensing downlink rates. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Distributed Sky Imaging Radiometry and Tomography"
    ],
    "b_abstract":[
      "The composition of the atmosphere is significant to our ecosystem. Accordingly, there a need sense distributions atmospheric scatterers such as aerosols and cloud droplets. There growing interest in recovering these scattering fields three-dimensions (3D). Even so, current observations usually use expensive unscalable equipment. Moreover, analysis retrieves partial information (e.g., cloud-base altitudes, water droplet size at tops) based on simplified 1D models. To advance retrievals, we develop new computational imaging approach for sensing analyzing atmosphere, volumetrically. Our comprises ground-based network cameras. We deployed it conjunction with additional remote equipment, including Raman lidar sunphotometer, which provide initialization algorithms ground truth. camera scalable, low cost, enables 3D high spatial temporal resolution. describe how system calibrated absolute radiometric readouts light field. Consequently, recover volumetric field scatterers, using tomography. tomography process adapted relative prior art, run large-scale domains being in-situ within scatterer fields. empirically demonstrate feasibility clouds, data."
    ],
    "b_categories":[
      "astro-ph.EP"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "Variable Imaging Projection Cloud Scattering Tomography"
    ],
    "c_abstract":[
      "Scattering-based computed tomography (CT) recovers a heterogeneous volumetric scattering medium using images taken from multiple directions. It is nonlinear problem. Prior art mainly approached it by explicit physics-based optimization of image-fitting, being slow and difficult to scale. Scale particularly important when the objects constitute large cloud fields, where recovery for climate studies. Besides speed, imaging need be flexible, efficiently handle variable viewing geometries resolutions. These can caused perturbation in camera poses or fusion data different types observational sensors. There fast projection clouds (VIP-CT). We develop learning-based solution, deep-neural network (DNN) which trains on labeled dataset. The DNN parameters are oblivious domain scale, hence work with arbitrarily domains. VIP-CT offers much better quality than state art. inference speed flexibility make effectively real-time context spaceborne observations. paper first demonstrate CT real empirical directly DNN. may offer model solution problems other scientific Our code available online."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.03156,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Unleashing the power of novel conditional generative approaches for new\n  materials discovery",
    "a_abstract":"For a very long time, computational approaches to the design of new materials\nhave relied on an iterative process of finding a candidate material and\nmodeling its properties. AI has played a crucial role in this regard, helping\nto accelerate the discovery and optimization of crystal properties and\nstructures through advanced computational methodologies and data-driven\napproaches. To address the problem of new materials design and fasten the\nprocess of new materials search, we have applied latest generative approaches\nto the problem of crystal structure design, trying to solve the inverse\nproblem: by given properties generate a structure that satisfies them without\nutilizing supercomputer powers. In our work we propose two approaches: 1)\nconditional structure modification: optimization of the stability of an\narbitrary atomic configuration, using the energy difference between the most\nenergetically favorable structure and all its less stable polymorphs and 2)\nconditional structure generation. We used a representation for materials that\nincludes the following information: lattice, atom coordinates, atom types,\nchemical features, space group and formation energy of the structure. The loss\nfunction was optimized to take into account the periodic boundary conditions of\ncrystal structures. We have applied Diffusion models approach, Flow matching,\nusual Autoencoder (AE) and compared the results of the models and approaches.\nAs a metric for the study, physical PyMatGen matcher was employed: we compare\ntarget structure with generated one using default tolerances. So far, our\nmodifier and generator produce structures with needed properties with accuracy\n41% and 82% respectively. To prove the offered methodology efficiency,\ninference have been carried out, resulting in several potentially new\nstructures with formation energy below the AFLOW-derived convex hulls.",
    "explanation":"\" In our work we propose two approaches: 1) conditional structure modification: optimization of the stability of an arbitrary atomic configuration, using the energy difference between the most energetically favorable structure and all its less stable polymorphs and 2) conditional structure generation.\"",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Physics guided deep learning for generative design of crystal materials with symmetry constraints"
    ],
    "b_abstract":[
      "Abstract Discovering new materials is a challenging task in science crucial to the progress of human society. Conventional approaches based on experiments and simulations are labor-intensive or costly with success heavily depending experts\u2019 heuristic knowledge. Here, we propose deep learning Physics Guided Crystal Generative Model (PGCGM) for efficient crystal material design high structural diversity symmetry. Our model increases generation validity by more than 700% compared FTCP, one latest structure generators 45% our previous CubicGAN model. Density Functional Theory (DFT) calculations used validate generated structures 1869 out 2000 successfully optimized deposited into Carolina Materials Database www.carolinamatdb.org , which 39.6% have negative formation energy 5.3% energy-above-hull less 0.25 eV\/atom, indicating their thermodynamic stability potential synthesizability."
    ],
    "b_categories":[
      "physics.comp-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "High\u2010Throughput Discovery of Novel Cubic Crystal Materials Using Deep Generative Neural Networks"
    ],
    "c_abstract":[
      "Abstract High\u2010throughput screening has become one of the major strategies for discovery novel functional materials. However, its effectiveness is severely limited by lack sufficient and diverse materials in current repositories such as open quantum database (OQMD). Recent progress deep learning have enabled generative that learn implicit chemical rules creating hypothetical with new compositions structures. models difficulty generating structurally diverse, chemically valid, stable Here we propose CubicGAN, a adversarial network (GAN) based neural model large scale design cubic When trained on 375 749 ternary from OQMD database, authors show able to not only rediscover most currently known but also generate structure prototypes. A total 506 been verified phonon dispersion calculation. Considering importance wide applications solar panels, GAN provides promising approach significantly expand existing repositories, enabling via screening. The crystal structures discovered are freely accessible at www.carolinamatdb.org ."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.17907,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"A Multimodal Emotion Recognition System: Integrating Facial Expressions,\n  Body Movement, Speech, and Spoken Language",
    "a_abstract":"Traditional psychological evaluations rely heavily on human observation and\ninterpretation, which are prone to subjectivity, bias, fatigue, and\ninconsistency. To address these limitations, this work presents a multimodal\nemotion recognition system that provides a standardised, objective, and\ndata-driven tool to support evaluators, such as psychologists, psychiatrists,\nand clinicians. The system integrates recognition of facial expressions,\nspeech, spoken language, and body movement analysis to capture subtle emotional\ncues that are often overlooked in human evaluations. By combining these\nmodalities, the system provides more robust and comprehensive emotional state\nassessment, reducing the risk of mis- and overdiagnosis. Preliminary testing in\na simulated real-world condition demonstrates the system's potential to provide\nreliable emotional insights to improve the diagnostic accuracy. This work\nhighlights the promise of automated multimodal analysis as a valuable\ncomplement to traditional psychological evaluation practices, with applications\nin clinical and therapeutic settings.",
    "explanation":"Traditional psychological evaluations rely heavily\non human observation and interpretation, which are prone to\nsubjectivity, bias, fatigue, and inconsistency. To address these\nlimitations, this work presents a multimodal emotion recognition\nsystem that provides a standardised, objective, and data-driven\ntool to support evaluators, such as psychologists, psychiatrists,\nand clinicians.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Deep Facial Expression Recognition: A Survey"
    ],
    "b_abstract":[
      "With the transition of facial expression recognition (FER) from laboratory-controlled to challenging in-the-wild conditions and recent success deep learning techniques in various fields, neural networks have increasingly been leveraged learn discriminative representations for automatic FER. Recent FER systems generally focus on two important issues: overfitting caused by a lack sufficient training data expression-unrelated variations, such as illumination, head pose identity bias. In this paper, we provide comprehensive survey FER, including datasets algorithms that insights into these intrinsic problems. First, describe standard pipeline system with related background knowledge suggestions applicable implementations each stage. We then introduce available are widely used literature accepted selection evaluation principles datasets. For state art review existing novel strategies designed based both static images dynamic image sequences, discuss their advantages limitations. Competitive performances benchmarks also summarized section. extend our additional issues application scenarios. Finally, remaining challenges corresponding opportunities field well future directions design robust systems."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Recognizing and reducing cognitive bias in clinical and forensic neurology"
    ],
    "c_abstract":[
      "In medicine, cognitive errors form the basis of bias in clinical practice. Several types are common and pervasive, may lead to inaccurate diagnosis or treatment. Forensic neurology, even when aided by current technologies, still dependent on interpretations, therefore prone bias. This article discusses 4 biases that can clinician astray. They confirmation (selective gathering neglect contradictory evidence); base rate (ignoring misusing prevailing data); hindsight (oversimplification past causation); good old days (the tendency for patients misremember exaggerate their preinjury functioning). We briefly describe strategies adopted from field psychology could minimize While debiasing is not easy, reducing such requires awareness acknowledgment our susceptibility these distortions."
    ],
    "c_categories":[
      "Clinical Neurology"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.05055,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Integrating Large Language Models for Genetic Variant Classification",
    "a_abstract":"The classification of genetic variants, particularly Variants of Uncertain\nSignificance (VUS), poses a significant challenge in clinical genetics and\nprecision medicine. Large Language Models (LLMs) have emerged as transformative\ntools in this realm. These models can uncover intricate patterns and predictive\ninsights that traditional methods might miss, thus enhancing the predictive\naccuracy of genetic variant pathogenicity.\n  This study investigates the integration of state-of-the-art LLMs, including\nGPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for\nvariant classification. Our approach evaluates these integrated models using\nthe well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in\nclassification performance. The models were rigorously tested on a set of\nchallenging variants, demonstrating substantial improvements over existing\nstate-of-the-art tools, especially in handling ambiguous and clinically\nuncertain variants.\n  The results of this research underline the efficacy of combining multiple\nmodeling approaches to significantly refine the accuracy and reliability of\ngenetic variant classification systems. These findings support the deployment\nof these advanced computational models in clinical environments, where they can\nsignificantly enhance the diagnostic processes for genetic disorders,\nultimately pushing the boundaries of personalized medicine by offering more\ndetailed and actionable genetic insights.",
    "explanation":"This study investigates the integration of state-of-the-art LLMs,\nincluding GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for variant classification.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"
    ],
    "b_abstract":[
      "TensorFlow is an interface for expressing machine learning algorithms, and implementation executing such algorithms. A computation expressed using can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices as phones tablets up to large-scale distributed systems hundreds machines thousands computational GPU cards. The system flexible used express including training inference algorithms deep neural network models, it has been conducting research deploying into production across more than dozen areas computer science other fields, speech recognition, vision, robotics, information retrieval, natural language processing, geographic extraction, drug discovery. This paper describes the that we have built at Google. API reference were released open-source package under Apache 2.0 license in November, 2015 are available www.tensorflow.org."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Predicting Functional Effect of Human Missense Mutations Using PolyPhen\u20102"
    ],
    "c_abstract":[
      "Abstract PolyPhen\u20102 (Polymorphism Phenotyping v2), available as software and via a Web server, predicts the possible impact of amino acid substitutions on stability function human proteins using structural comparative evolutionary considerations. It performs functional annotation single\u2010nucleotide polymorphisms (SNPs), maps coding SNPs to gene transcripts, extracts protein sequence annotations attributes, builds conservation profiles. then estimates probability missense mutation being damaging based combination all these properties. features include high\u2010quality multiple alignment pipeline prediction method employing machine\u2010learning classification. The also integrates UCSC Genome Browser's genome MultiZ alignments vertebrate genomes with genome. is capable analyzing large volumes data produced by next\u2010generation sequencing projects, thanks built\u2010in support for high\u2010performance computing environments like Grid Engine Platform LSF. Curr. Protoc. Hum. Genet . 76:7.20.1\u20107.20.41. \u00a9 2013 John Wiley &amp; Sons, Inc."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.18156,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"scReader: Prompting Large Language Models to Interpret scRNA-seq Data",
    "a_abstract":"Large language models (LLMs) have demonstrated remarkable advancements,\nprimarily due to their capabilities in modeling the hidden relationships within\ntext sequences. This innovation presents a unique opportunity in the field of\nlife sciences, where vast collections of single-cell omics data from multiple\nspecies provide a foundation for training foundational models. However, the\nchallenge lies in the disparity of data scales across different species,\nhindering the development of a comprehensive model for interpreting genetic\ndata across diverse organisms. In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of LLMs with\ndomain-specific representation models for single-cell omics data\ninterpretation. We begin by focusing on genes as the fundamental unit of\nrepresentation. Gene representations are initialized using functional\ndescriptions, leveraging the strengths of mature language models such as\nLLaMA-2. By inputting single-cell gene-level expression data with prompts, we\neffectively model cellular representations based on the differential expression\nlevels of genes across various species and cell types. In the experiments, we\nconstructed developmental cells from humans and mice, specifically targeting\ncells that are challenging to annotate. We evaluated our methodology through\nbasic tasks such as cell annotation and visualization analysis. The results\ndemonstrate the efficacy of our approach compared to other methods using LLMs,\nhighlighting significant improvements in accuracy and interoperability. Our\nhybrid approach enhances the representation of single-cell data and offers a\nrobust framework for future research in cross-species genetic analysis.",
    "explanation":". In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of\nLLMs with domain-specific representation models for single-cell\nomics data interpretation.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Llamafactory: Unified efficient fine-tuning of 100+ language models"
    ],
    "b_abstract":[
      "Efficient fine-tuning is vital for adapting large language models (LLMs) to downstream tasks. However, it requires non-trivial efforts to implement these methods on different models. We present LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It provides a solution for flexibly customizing the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard. We empirically validate the efficiency and effectiveness of our framework on language modeling and text generation tasks."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "GeneCompass: Deciphering Universal Gene Regulatory Mechanisms with Knowledge-Informed Cross-Species Foundation Model"
    ],
    "c_abstract":[
      "Abstract Deciphering the universal gene regulatory mechanisms in diverse organisms holds great potential to advance our knowledge of fundamental life process and facilitate research on clinical applications. However, traditional paradigm primarily focuses individual model organisms, resulting limited collection integration complex features various cell types across species. Recent breakthroughs single-cell sequencing advancements deep learning techniques present an unprecedented opportunity tackle this challenge. In study, we developed GeneCompass, first knowledge-informed, cross-species foundation pre-trained extensive dataset over 120 million transcriptomes from human mouse. During pre-training, GeneCompass effectively integrates four biological prior enhance understanding a self-supervised manner. Fine-tuning towards multiple downstream tasks, outperforms competing state-of-the-art models tasks single species unlocks new realms investigation. Overall, marks milestone advancing accelerating discovery key fate regulators candidate targets for drug development."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.07871,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in\n  Alzheimer's Disease",
    "a_abstract":"The rapid advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have shown great potential in medical diagnostics, particularly\nin radiology, where datasets such as X-rays are paired with human-generated\ndiagnostic reports. However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer's disease, due\nto the lack of comprehensive diagnostic reports that can be utilized for model\nfine-tuning. This paper addresses this gap by generating synthetic diagnostic\nreports using GPT-4o-mini on structured data from the OASIS-4 dataset, which\ncomprises 663 patients. Using the synthetic reports as ground truth for\ntraining and validation, we then generated neurological reports directly from\nthe images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.\nOur proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,\nand METEOR score of 0.4163, revealing its potential in generating clinically\nrelevant and accurate diagnostic reports.",
    "explanation":"However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer\u2019s\ndisease, due to the lack of comprehensive diagnostic reports that\ncan be utilized for model fine-tuning. This paper addresses this\ngap by generating synthetic diagnostic reports using GPT-4o-mini\non structured data from the OASIS-4 dataset, which comprises\n663 patients",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "2016 Alzheimer's disease facts and figures"
    ],
    "b_abstract":[
      "This report describes the public health impact of Alzheimer's disease, including incidence and prevalence, mortality rates, costs care, overall on caregivers society. It also examines in detail financial families, annual to families difficult decisions must often make pay those costs. An estimated 5.4 million Americans have disease. By mid-century, number people living with disease United States is projected grow 13.8 million, fueled large part by aging baby boom generation. Today, someone country develops every 66 seconds. 2050, one new case expected develop 33 seconds, resulting nearly 1 cases per year. In 2013, official death certificates recorded 84,767 deaths from making it sixth leading cause fifth age \u2265 65 years. Between 2000 stroke, heart prostate cancer decreased 23%, 14%, 11%, respectively, whereas increased 71%. The actual which contributes likely much larger than certificates. 2016, an 700,000 years will die many them because complications caused 2015, more 15 family members other unpaid provided 18.1 billion hours care dementias, a contribution valued at $221 billion. Average per-person Medicare payments for services beneficiaries dementias are two half times as great all without these conditions, Medicaid 19 great. Total 2016 long-term hospice dementia be $236 may place substantial burden who take money out their retirement savings, cut back buying food, reduce own trips doctor. addition, incorrectly believe that pays nursing home types care. Such findings highlight need solutions prevent dementia-related jeopardizing security dementias."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Computer-aided diagnosis of Alzheimer\u2019s disease and neurocognitive disorders with multimodal Bi-Vision Transformer (BiViT)"
    ],
    "c_abstract":[
      "<jats:title>Abstract<\/jats:title><jats:p>Cognitive disorders affect various cognitive functions that can have a substantial impact on individual\u2019s daily life. Alzheimer\u2019s disease (AD) is one of such well-known cognitive disorders. Early detection and treatment of cognitive diseases using artificial intelligence can help contain them. However, the complex spatial relationships and long-range dependencies found in medical imaging data present challenges in achieving the objective. Moreover, for a few years, the application of transformers in imaging has emerged as a promising area of research. A reason can be transformer\u2019s impressive capabilities of tackling spatial relationships and long-range dependency challenges in two ways, i.e., (1) using their self-attention mechanism to generate comprehensive features, and (2) capture complex patterns by incorporating global context and long-range dependencies. In this work, a Bi-Vision Transformer (BiViT) architecture is proposed for classifying different stages of AD, and multiple types of cognitive disorders from 2-dimensional MRI imaging data. More specifically, the transformer is composed of two novel modules, namely Mutual Latent Fusion (MLF) and Parallel Coupled Encoding Strategy (PCES), for effective feature learning. Two different datasets have been used to evaluate the performance of proposed BiViT-based architecture. The first dataset contain several classes such as mild or moderate demented stages of the AD. The other dataset is composed of samples from patients with AD and different cognitive disorders such as mild, early, or moderate impairments. For comprehensive comparison, a multiple transfer learning algorithm and a deep autoencoder have been each trained on both datasets. The results show that the proposed BiViT-based model achieves an accuracy of 96.38% on the AD dataset. However, when applied to cognitive disease data, the accuracy slightly decreases below 96% which can be resulted due to smaller amount of data and imbalance in data distribution. Nevertheless, given the results, it can be hypothesized that the proposed algorithm can perform better if the imbalanced distribution and limited availability problems in data can be addressed.<\/jats:p>\n                <jats:p><jats:bold>Graphical abstract<\/jats:bold><\/jats:p>"
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.08073,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"LoRA-BERT: a Natural Language Processing Model for Robust and Accurate\n  Prediction of long non-coding RNAs",
    "a_abstract":"Long non-coding RNAs (lncRNAs) serve as crucial regulators in numerous\nbiological processes. Although they share sequence similarities with messenger\nRNAs (mRNAs), lncRNAs perform entirely different roles, providing new avenues\nfor biological research. The emergence of next-generation sequencing\ntechnologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify\nlong non-coding RNAs (lncRNAs). These advanced methods have significantly\nenhanced the efficiency of identifying lncRNAs. However, many of these methods\nare devoid of robustness and accuracy due to the extended length of the\nsequences involved. To tackle this issue, we have introduced a novel\npre-trained bidirectional encoder representation called LoRA-BERT. LoRA-BERT is\ndesigned to capture the importance of nucleotide-level information during\nsequence classification, leading to more robust and satisfactory outcomes. In a\ncomprehensive comparison with commonly used sequence prediction tools, we have\ndemonstrated that LoRA-BERT outperforms them in terms of accuracy and\nefficiency. Our results indicate that, when utilizing the transformer model,\nLoRA-BERT achieves state-of-the-art performance in predicting both lncRNAs and\nmRNAs for human and mouse species. Through the utilization of LoRA-BERT, we\nacquire valuable insights into the traits of lncRNAs and mRNAs, offering the\npotential to aid in the comprehension and detection of diseases linked to\nlncRNAs in humans.",
    "explanation":"The emergence of next-\ngeneration sequencing technologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify long non-coding\nRNAs (lncRNAs). ",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome"
    ],
    "b_abstract":[
      "Abstract Motivation Deciphering the language of non-coding DNA is one fundamental problems in genome research. Gene regulatory code highly complex due to existence polysemy and distant semantic relationship, which previous informatics methods often fail capture especially data-scarce scenarios. Results To address this challenge, we developed a novel pre-trained bidirectional encoder representation, named DNABERT, global transferrable understanding genomic sequences based on up downstream nucleotide contexts. We compared DNABERT most widely used programs for genome-wide elements prediction demonstrate its ease use, accuracy efficiency. show that single transformers model can simultaneously achieve state-of-the-art performance promoters, splice sites transcription factor binding sites, after easy fine-tuning using small task-specific labeled data. Further, enables direct visualization nucleotide-level importance relationship within input better interpretability accurate identification conserved sequence motifs functional genetic variant candidates. Finally, with human even be readily applied other organisms exceptional performance. anticipate fined tuned many analyses tasks. Availability implementation The source code, pretrained finetuned are available at GitHub (https:\/\/github.com\/jerryji1993\/DNABERT). Supplementary information data Bioinformatics online."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b20"
    ],
    "c_title":[
      "A primer on deep learning in genomics"
    ],
    "c_abstract":[
      "Deep learning methods are a class of machine learning techniques capable of identifying highly complex patterns in large datasets. Here, we provide a perspective and primer on deep learning applications for genome analysis. We discuss successful applications in the fields of regulatory genomics, variant calling and pathogenicity scores. We include general guidance for how to effectively use deep learning methods as well as a practical guide to tools and resources. This primer is accompanied by an interactive online tutorial."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.08664,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"UniMat: Unifying Materials Embeddings through Multi-modal Learning",
    "a_abstract":"Materials science datasets are inherently heterogeneous and are available in\ndifferent modalities such as characterization spectra, atomic structures,\nmicroscopic images, and text-based synthesis conditions. The advancements in\nmulti-modal learning, particularly in vision and language models, have opened\nnew avenues for integrating data in different forms. In this work, we evaluate\ncommon techniques in multi-modal learning (alignment and fusion) in unifying\nsome of the most important modalities in materials science: atomic structure,\nX-ray diffraction patterns (XRD), and composition. We show that structure graph\nmodality can be enhanced by aligning with XRD patterns. Additionally, we show\nthat aligning and fusing more experimentally accessible data formats, such as\nXRD patterns and compositions, can create more robust joint embeddings than\nindividual modalities across various tasks. This lays the groundwork for future\nstudies aiming to exploit the full potential of multi-modal data in materials\nscience, facilitating more informed decision-making in materials design and\ndiscovery.",
    "explanation":"n this work, we evaluate common techniques in multi-modal learning\n(alignment and fusion) in unifying some of the most important modalities in materials\nscience: atomic structure, X-ray diffraction patterns (XRD), and composition.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Comprehensive Inorganic Chemistry III (Third Edition)"
    ],
    "b_abstract":[
      "Comprehensive Inorganic Chemistry III, a ten-volume reference work, is intended to cover fundamental principles, recent discoveries, and significant applications of elements and their compounds. Authored by renowned experts in the field and edited by a world-class editorial board, each chapter provides a thorough and in-depth overview of the topic covered, featuring resources which will be useful to students, researchers, faculty as well as those in the industry. Comprehensive Inorganic Chemistry III focuses on main group chemistry, biological inorganic chemistry, solid state and materials chemistry, catalysis, and new developments in electrochemistry and photochemistry, as well as NMR and diffraction methods for studying inorganic compounds. The work expands on our 2013 work Comprehensive Inorganic Chemistry II while also adding new volumes on cutting-edge research areas and techniques for studying inorganic compounds. Researchers seeking background information on a specific problem involving the synthesis of inorganic compounds, as well as applications for numerous elements from the periodic table, and their compounds, will be able to rely on and refer to this authoritative scientific resource time and again."
    ],
    "b_categories":[
      "Material"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Multimodal Foundation Models for Material Property Prediction and Discovery"
    ],
    "c_abstract":[
      "Artificial intelligence is transforming computational materials science, improving the prediction of material properties, and accelerating the discovery of novel materials. Recently, publicly available material data repositories have grown rapidly. This growth encompasses not only more materials but also a greater variety and quantity of their associated properties. Existing machine learning efforts in materials science focus primarily on single-modality tasks, i.e. relationships between materials and a single physical property, thus not taking advantage of the rich and multimodal set of material properties. Here, we introduce Multimodal Learning for Materials (MultiMat), which enables self-supervised multi-modality training of foundation models for materials. We demonstrate our framework's potential using data from the Materials Project database on multiple axes: (i) MultiMat achieves state-of-the-art performance for challenging material property prediction tasks; (ii) MultiMat enables novel and accurate material discovery via latent space similarity, enabling screening for stable materials with desired properties; and (iii) MultiMat encodes interpretable emergent features that may provide novel scientific insights."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.0908,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Language Models for Music Medicine Generation",
    "a_abstract":"Music therapy has been shown in recent years to provide multiple health\nbenefits related to emotional wellness. In turn, maintaining a healthy\nemotional state has proven to be effective for patients undergoing treatment,\nsuch as Parkinson's patients or patients suffering from stress and anxiety. We\npropose fine-tuning MusicGen, a music-generating transformer model, to create\nshort musical clips that assist patients in transitioning from negative to\ndesired emotional states. Using low-rank decomposition fine-tuning on the\nMTG-Jamendo Dataset with emotion tags, we generate 30-second clips that adhere\nto the iso principle, guiding patients through intermediate states in the\nvalence-arousal circumplex. The generated music is evaluated using a music\nemotion recognition model to ensure alignment with intended emotions. By\nconcatenating these clips, we produce a 15-minute \"music medicine\" resembling a\nmusic therapy session. Our approach is the first model to leverage Language\nModels to generate music medicine. Ultimately, the output is intended to be\nused as a temporary relief between music therapy sessions with a\nboard-certified therapist.",
    "explanation":"We propose fine-tuning MusicGen, a music-generating\ntransformer model, to create short musical clips that assist\npatients in transitioning from negative to desired emotional\nstates",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Music Transformer: Generating Music with Long-Term Structure"
    ],
    "b_abstract":[
      "Music relies heavily on repetition to build structure and meaning. Self-reference occurs on multiple timescales, from motifs to phrases to reusing of entire sections of music, such as in pieces with ABA structure. The Transformer (Vaswani et al., 2017), a sequence model based on self-attention, has achieved compelling results in many generation tasks that require maintaining long-range coherence. This suggests that self-attention might also be well-suited to modeling music. In musical composition and performance, however, relative timing is critically important. Existing approaches for representing relative positional information in the Transformer modulate attention based on pairwise distance (Shaw et al., 2018). This is impractical for long sequences such as musical compositions since their memory complexity for intermediate relative information is quadratic in the sequence length. We propose an algorithm that reduces their intermediate memory requirement to linear in the sequence length. This enables us to demonstrate that a Transformer with our modified relative attention mechanism can generate minute-long compositions (thousands of steps, four times the length modeled in Oore et al., 2018) with compelling structure, generate continuations that coherently elaborate on a given motif, and in a seq2seq setup generate accompaniments conditioned on melodies. We evaluate the Transformer with our relative attention mechanism on two datasets, JSB Chorales and Piano-e-Competition, and obtain state-of-the-art results on the latter."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "On the use of AI for Generation of Functional Music to Improve Mental Health"
    ],
    "c_abstract":[
      "Increasingly music has been shown to have both physical and mental health benefits including improvements in cardiovascular health, a link reduction of cases dementia elderly populations, markers general well-being such as stress reduction. Here, we describe short case studies addressing (anxiety, stress-reduction) through AI-driven generation. Engaging active listening music-making activities (especially for at risk age groups) can be particularly beneficial, the practice therapy helpful range use across wide range. However, access prohibitive terms expertize, materials, cost. Furthermore existing functional outcomes (such targeted improvement suggested above) hindered by issues repetition subsequent over-familiarity with material. In this paper, machine learning approaches which create informed biophysiological measurement two studies, target emotional states opposing ends Cartesian affective space (a dimensional emotion points ranging from descriptors relaxation, fear). Galvanic skin response is used marker psychological arousal an estimate state control signal training algorithm. This algorithm creates non-linear time series musical features sound synthesis \u201con-the-fly\u201d, using perceptually feature similarity model. We find interaction between familiarity perceived response. also report on psychometric evaluation generated material, consider how these - similar techniques might useful generation tasks, example, nonlinear sound-tracking that found interactive media or video games."
    ],
    "c_categories":[
      "Mental Health"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.15211,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"LightLLM: A Versatile Large Language Model for Predictive Light Sensing",
    "a_abstract":"We propose LightLLM, a model that fine tunes pre-trained large language\nmodels (LLMs) for light-based sensing tasks. It integrates a sensor data\nencoder to extract key features, a contextual prompt to provide environmental\ninformation, and a fusion layer to combine these inputs into a unified\nrepresentation. This combined input is then processed by the pre-trained LLM,\nwhich remains frozen while being fine-tuned through the addition of\nlightweight, trainable components, allowing the model to adapt to new tasks\nwithout altering its original parameters. This approach enables flexible\nadaptation of LLM to specialized light sensing tasks with minimal computational\noverhead and retraining effort. We have implemented LightLLM for three light\nsensing tasks: light-based localization, outdoor solar forecasting, and indoor\nsolar estimation. Using real-world experimental datasets, we demonstrate that\nLightLLM significantly outperforms state-of-the-art methods, achieving 4.4x\nimprovement in localization accuracy and 3.4x improvement in indoor solar\nestimation when tested in previously unseen environments. We further\ndemonstrate that LightLLM outperforms ChatGPT-4 with direct prompting,\nhighlighting the advantages of LightLLM's specialized architecture for sensor\ndata fusion with textual prompts.",
    "explanation":"We propose LightLLM, a model that fine tunes pre-trained\nlarge language models (LLMs) for light-based sensing tasks.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Solar Cells for Indoor Applications: Progress and Development"
    ],
    "b_abstract":[
      "The Internet of things (IoT) has been rapidly growing in the past few years. IoT connects numerous devices, such as wireless sensors, actuators, and wearable to optimize monitor daily activities. Most these devices require power microwatt range operate indoors. To this end, a self-sustainable source, photovoltaic (PV) cell, which can harvest low-intensity indoor light, is appropriate. Recently, development highly efficient PV cells for applications attracted tremendous attention. Therefore, different types materials, inorganic, dye-sensitized, organic, perovskite have employed harvesting light energy. Although considerable efforts made by researchers develop low-cost, stable, applications, Extensive investigation necessary resolve some critical issues concerning cells, environmental stability, lifetime, large-area fabrication, mechanical flexibility, production cost. address issues, systematic review aspects will be useful research community. This study discusses current status based on previous reports. First, we provided relevant background information. Then, described sources, subsequently critically reviewed reports regarding solar active materials perovskite. Finally, placed an attempt provide insight into factors needed further improve feasibility technology applications."
    ],
    "b_categories":[
      "astro-ph.SR"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
    ],
    "c_abstract":[
      "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent models, BERT is designed to pre-train deep bidirectional representations unlabeled text by jointly conditioning on both left and right context in all layers. As result, the pre-trained can be fine-tuned with just one additional output layer create state-of-the-art models wide range of tasks, such as question answering inference, without substantial task-specific architecture modifications. conceptually simple empirically powerful. It obtains results eleven natural processing including pushing GLUE score 80.5% (7.7% point absolute improvement), MultiNLI accuracy 86.7% (4.6% SQuAD v1.1 Test F1 93.2 (1.5 improvement) v2.0 83.1 (5.1 improvement)."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.00129,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Scaling Particle Collision Data Analysis",
    "a_abstract":"For decades, researchers have developed task-specific models to address\nscientific challenges across diverse disciplines. Recently, large language\nmodels (LLMs) have shown enormous capabilities in handling general tasks;\nhowever, these models encounter difficulties in addressing real-world\nscientific problems, particularly in domains involving large-scale numerical\ndata analysis, such as experimental high energy physics. This limitation is\nprimarily due to BPE tokenization's inefficacy with numerical data. In this\npaper, we propose a task-agnostic architecture, BBT-Neutron, which employs a\nbinary tokenization method to facilitate pretraining on a mixture of textual\nand large-scale numerical experimental data. We demonstrate the application of\nBBT-Neutron to Jet Origin Identification (JoI), a critical categorization\nchallenge in high-energy physics that distinguishes jets originating from\nvarious quarks or gluons. Our results indicate that BBT-Neutron achieves\ncomparable performance to state-of-the-art task-specific JoI models.\nFurthermore, we examine the scaling behavior of BBT-Neutron's performance with\nincreasing data volume, suggesting the potential for BBT-Neutron to serve as a\nfoundational model for particle physics data analysis, with possible extensions\nto a broad spectrum of scientific computing applications for Big Science\nexperiments, industrial manufacturing and spacial computing. The project code\nis available at https:\/\/github.com\/supersymmetry-technologies\/bbt-neutron.",
    "explanation":"In this paper, we propose a task-agnostic architecture,\nBBT-Neutron, which employs a binary tokenization method to facilitate pre-\ntraining on a mixture of textual and large-scale numerical experimental data. We\ndemonstrate the application of BBT-Neutron to Jet Origin Identification (JoI),\na critical categorization challenge in high-energy physics that distinguishes jets\noriginating from various quarks or gluons",
    "b_id":[
      "b23"
    ],
    "b_title":[
      "DARWIN Series: Domain Specific Large Language Models for Natural Science"
    ],
    "b_abstract":[
      "Emerging tools bring forth fresh approaches to work, and the field of natural science is no different. In science, traditional manual, serial, labour-intensive work being augmented by automated, parallel, iterative processes driven artificial intelligence-based experimental automation more. To add new capabilities in enabling acceleration enrichment discovery process, we present DARWIN, a series tailored LLMs for mainly physics, chemistry, material science. This relies on open-source LLM, incorporating structured unstructured scientific knowledge from public datasets literature. We fine-tuned models using over 60,000 instruction data points, emphasizing factual correctness. During fine-tuning, introduce Scientific Instruction Generation (SIG) model, automating generation texts. eliminates need manual extraction or domain-specific graphs efficiently injects into model. also explore multi-task training strategies, revealing interconnections between tasks. DARWIN not only achieves state-of-the-art results various tasks but diminishes reliance closed-source AI models. Our research showcases ability LLM domain, with overarching goal fostering prosperity within broader community."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b29"
    ],
    "c_title":[
      "Study of Fermion pair production in e+e- collisions at 130-183 GeV"
    ],
    "c_abstract":[
      "The cross sections and forward-backward asymmetries of hadronic and leptonic\nevents produced in e+e- collisions at centre-of-mass energies of 130-183 GeV\nare presented. Results for ee, mumu, tautau, qq, bb and cc production show no\nsignificant deviation from the Standard Model predictions. This enable\nconstraints to be set upon physics beyond the Standard Model such as\nfour-fermion contact interactions, leptoquarks, Z' bosons and R-parity\nviolating squarks and sneutrinos. Limits on the energy scale Lambda of eeff\ncontact interactions are typically in the range from 2-10 TeV. Limits on\nR-parity violating sneutrinos reach masses of a few hundred GeV for large\nvalues of their Yukawa couplings."
    ],
    "c_categories":[
      "astro-ph.HE"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.19475,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Effective Fine-Tuning of Vision-Language Models for Accurate Galaxy\n  Morphology Analysis",
    "a_abstract":"Galaxy morphology analysis involves classifying galaxies by their shapes and\nstructures. For this task, directly training domain-specific models on large,\nannotated astronomical datasets is effective but costly. In contrast,\nfine-tuning vision foundation models on a smaller set of astronomical images is\nmore resource-efficient but generally results in lower accuracy. To harness the\nbenefits of both approaches and address their shortcomings, we propose\nGalaxAlign, a novel method that fine-tunes pre-trained foundation models to\nachieve high accuracy on astronomical tasks. Specifically, our method extends a\ncontrastive learning architecture to align three types of data in fine-tuning:\n(1) a set of schematic symbols representing galaxy shapes and structures, (2)\ntextual labels of these symbols, and (3) galaxy images. This way, GalaxAlign\nnot only eliminates the need for expensive pretraining but also enhances the\neffectiveness of fine-tuning. Extensive experiments on galaxy classification\nand similarity search demonstrate that our method effectively fine-tunes\ngeneral pre-trained models for astronomical tasks by incorporating\ndomain-specific multi-modal knowledge.",
    "explanation":"To harness the benefits of\nboth approaches and address their shortcomings, we pro-\npose GalaxAlign, a novel method that fine-tunes pre-trained\nfoundation models to achieve high accuracy on astronom-\nical tasks.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Radio galaxy zoo EMU: Towards a semantic radio galaxy morphology taxonomy"
    ],
    "b_abstract":[
      "ABSTRACT We present a novel natural language processing (NLP) approach to deriving plain English descriptors for science cases otherwise restricted by obfuscating technical terminology. address the limitations of common radio galaxy morphology classifications applying this approach. experimentally derive set semantic tags Radio Galaxy Zoo EMU (Evolutionary Map Universe) project and wider astronomical community. collect 8486 annotations morphology, from which we taxonomy tags. The are English. result is an extensible framework, more flexible, easily communicated, sensitive rare feature combinations, indescribable using current framework astronomy classifications."
    ],
    "b_categories":[
      "astro-ph.CO"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "ImageNet: A large-scale hierarchical image database"
    ],
    "c_abstract":[
      "The explosion of image data on the Internet has potential to foster more sophisticated and robust models algorithms index, retrieve, organize interact with images multimedia data. But exactly how such can be harnessed organized remains a critical problem. We introduce here new database called \"ImageNet\", large-scale ontology built upon backbone WordNet structure. ImageNet aims populate majority 80,000 synsets an average 500\u20131000 clean full resolution images. This will result in tens millions annotated by semantic hierarchy WordNet. paper offers detailed analysis its current state: 12 subtrees 5247 3.2 million total. show that is much larger scale diversity accurate than datasets. Constructing challenging task. describe collection scheme Amazon Mechanical Turk. Lastly, we illustrate usefulness through three simple applications object recognition, classification automatic clustering. hope scale, accuracy, hierarchical structure offer unparalleled opportunities researchers computer vision community beyond."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.17595,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Can artificial intelligence predict clinical trial outcomes?",
    "a_abstract":"The increasing complexity and cost of clinical trials, particularly in the\ncontext of oncology and advanced therapies, pose significant challenges for\ndrug development. This study evaluates the predictive capabilities of large\nlanguage models (LLMs) such as GPT-3.5, GPT-4, and HINT in determining clinical\ntrial outcomes. By leveraging a curated dataset of trials from\nClinicalTrials.gov, we compare the models' performance using metrics including\nbalanced accuracy, specificity, recall, and Matthews Correlation Coefficient\n(MCC). Results indicate that GPT-4o demonstrates robust performance in early\ntrial phases, achieving high recall but facing limitations in specificity.\nConversely, the HINT model excels in recognizing negative outcomes,\nparticularly in later trial phases, offering a balanced approach across diverse\nendpoints. Oncology trials, characterized by high complexity, remain\nchallenging for all models. Additionally, trial duration and disease categories\ninfluence predictive performance, with longer durations and complex diseases\nsuch as neoplasms reducing accuracy. This study highlights the complementary\nstrengths of LLMs and HINT, providing insights into optimizing predictive tools\nfor clinical trial design and risk management. Future advancements in LLMs are\nessential to address current gaps in handling negative outcomes and complex\ndomains.",
    "explanation":"This study evaluates the performance of large language models (LLMs) and the\nHINT model in predicting clinical trial outcomes, focusing on metrics includ-\ning Balanced Accuracy, Matthews Correlation Coefficient (MCC), Recall, and\nSpecificity",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Machine learning model to predict oncologic outcomes for drugs in randomized clinical trials"
    ],
    "b_abstract":[
      "Abstract Predicting oncologic outcome is challenging due to the diversity of cancer histologies and complex network underlying biological factors. In this study, we determine whether machine learning (ML) can extract meaningful associations between clinical trial, drug\u2010related biomarker molecular profile information. We analyzed therapeutic trials corresponding 1102 outcomes from 104 758 patients with advanced colorectal adenocarcinoma, pancreatic melanoma nonsmall\u2010cell lung cancer. For each intervention arm, a dataset following attributes was curated: line treatment, number cytotoxic chemotherapies, small\u2010molecule inhibitors, or monoclonal antibody agents, drug class, alteration status arm's population, type, probability sensitivity (PDS) (integrating genomic, transcriptomic proteomic biomarkers in population interest) outcome. A total 467 progression\u2010free survival (PFS) 369 overall (OS) data points were used as training sets build our ML (random forest) model. Cross\u2010validation for PFS OS, obtaining correlation coefficients ( r ) 0.82 0.70, respectively (outcome vs model's parameters). 156 110 OS test sets. The Spearman s predicted actual statistically significant (PFS: = 0.879, OS: 0.878, P &lt; .0001). better arm 81% N 59\/73, z 5.24, .0001) 71% (OS: 37\/52, 2.91, .004) randomized trials. success algorithm predict may be exploitable model optimize trial design pharmaceutical agents."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "Lint: Llm interaction network for clinical trial outcome prediction"
    ],
    "c_abstract":[
      "Clinical trial outcome prediction aims to predict the success probability of a clinical trial that reaches its desirable endpoint. Most of the effort focuses on developing machine learning models for making accurate predictions with diverse data sources, including clinical trial descriptions, drug molecules, and target disease conditions. Accurate trial outcome prediction helps trial planning and asset portfolio prioritization. Previous works have focused on small-molecule drugs; however, biologics are a quickly growing intervention type that lacks information that is traditionally known for drugs, like molecular properties. Additionally, traditional methods like graph neural networks are much more difficult to apply to biologics data which are a fast-growing type of drug. To address these points, we propose a Language Interaction Network (LINT), a novel method for trial outcome prediction using only free-text descriptions. We validate the effectiveness of LINT with thorough experiments across three trial phases. Specifically, LINT obtains 0.770, 0.740, and 0.748 ROC-AUC scores on phase I, II, and III, respectively, for clinical trials with biologic interventions."
    ],
    "c_categories":[
      "Clinical trials"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.15395,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"ChatBCI: A P300 Speller BCI Leveraging Large Language Models for\n  Improved Sentence Composition in Realistic Scenarios",
    "a_abstract":"P300 speller BCIs allow users to compose sentences by selecting target keys\non a GUI through the detection of P300 component in their EEG signals following\nvisual stimuli. Most P300 speller BCIs require users to spell words letter by\nletter, or the first few initial letters, resulting in high keystroke demands\nthat increase time, cognitive load, and fatigue. This highlights the need for\nmore efficient, user-friendly methods for faster sentence composition. In this\nwork, we introduce ChatBCI, a P300 speller BCI that leverages the zero-shot\nlearning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing\nkeystrokes and accelerating sentence composition. ChatBCI retrieves word\nsuggestions through remote queries to the GPT-3.5 API. A new GUI, displaying\nGPT-3.5 word suggestions as extra keys is designed. SWLDA is used for the P300\nclassification. Seven subjects completed two online spelling tasks: 1)\ncopy-spelling a self-composed sentence using ChatBCI, and 2) improvising a\nsentence using ChatBCI's word suggestions. Results demonstrate that in Task 1,\non average, ChatBCI outperforms letter-by-letter BCI spellers, reducing time\nand keystrokes by 62.14% and 53.22%, respectively, and increasing information\ntransfer rate by 198.96%. In Task 2, ChatBCI achieves 80.68% keystroke savings\nand a record 8.53 characters\/min for typing speed. Overall, ChatBCI, by\nemploying remote LLM queries, enhances sentence composition in realistic\nscenarios, significantly outperforming traditional spellers without requiring\nlocal model training or storage. ChatBCI's (multi-) word predictions, combined\nwith its new GUI, pave the way for developing next-generation speller BCIs that\nare efficient and effective for real-time communication, especially for users\nwith communication and motor disabilities.",
    "explanation":"In this work, we introduce ChatBCI, a P300 speller BCI that leverages the zero-\nshot learning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing keystrokes\nand accelerating sentence composition. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Brain\u2013Computer Interface Spellers: A Review"
    ],
    "b_abstract":[
      "A Brain\u2013Computer Interface (BCI) provides a novel non-muscular communication method via brain signals. BCI-speller can be considered as one of the first published BCI applications and has opened gate for many advances in field. Although BCI-spellers have been developed during last few decades, to our knowledge, no reviews described different spellers proposed studied this vital The presented speller systems are categorized according major paradigms: P300, steady-state visual evoked potential (SSVEP), motor imagery (MI). Different paradigms require specific electroencephalogram (EEG) signal features lead development appropriate Graphical User Interfaces (GUIs). purpose review is consolidate most successful since 2010, while mentioning some other older which were built explicitly spelling purposes. We aim assist researchers concerned individuals field by illustrating highlights presenting them review. It almost impossible carry out an objective comparison between spellers, each its variables, parameters, conditions. However, gathered information provided taxonomy about helpful, it could identify suitable first-hand users, well opportunities learning from previous studies researchers."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b17"
    ],
    "c_title":[
      "Language Model-Guided Classifier Adaptation for Brain-Computer Interfaces for Communication"
    ],
    "c_abstract":[
      "Brain-computer interfaces (BCIs), such as the P300 speller, can provide a means of communication for individuals with severe neuromuscular limitations. BCIs interpret electroencephalography (EEG) signals in order to translate embedded information about user's intent into executable commands control external devices. However, EEG are inherently noisy and nonstationary, posing challenge extended BCI use. Conventionally, classifier is trained via supervised learning an offline calibration session; once trained, deployed online use not updated. As statistics data change over time, performance static may decline It therefore desirable automatically adapt current without requiring recalibration. In existing semi-supervised approach, on labeled then updated using incoming unlabeled classifier-predicted labels. To reduce risk from incorrect predictions, threshold imposed exclude low-confidence label predictions expanded training set when retraining adaptive classifier. this work, we propose language model spelling error correction disambiguation correctness during learning. Results simulations multi-session speller user demonstrate that our language-guided approach significantly improves accuracy relative conventional threshold-based"
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.08063,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"MatPilot: an LLM-enabled AI Materials Scientist under the Framework of\n  Human-Machine Collaboration",
    "a_abstract":"The rapid evolution of artificial intelligence, particularly large language\nmodels, presents unprecedented opportunities for materials science research. We\nproposed and developed an AI materials scientist named MatPilot, which has\nshown encouraging abilities in the discovery of new materials. The core\nstrength of MatPilot is its natural language interactive human-machine\ncollaboration, which augments the research capabilities of human scientist\nteams through a multi-agent system. MatPilot integrates unique cognitive\nabilities, extensive accumulated experience, and ongoing curiosity of\nhuman-beings with the AI agents' capabilities of advanced abstraction, complex\nknowledge storage and high-dimensional information processing. It could\ngenerate scientific hypotheses and experimental schemes, and employ predictive\nmodels and optimization algorithms to drive an automated experimental platform\nfor experiments. It turns out that our system demonstrates capabilities for\nefficient validation, continuous learning, and iterative optimization.",
    "explanation":"proposed and\ndeveloped an AI materials scientist named MatPilot, which has shown encouraging\nabilities in the discovery of new materials. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "A Data-Science Approach to Predict the Heat Capacity of Nanoporous Materials"
    ],
    "b_abstract":[
      "The heat capacity of a material is a fundamental property of great practical importance. For example, in a carbon capture process, the heat required to regenerate a solid sorbent is directly related to the heat capacity of the material. However, for most materials suitable for carbon capture applications, the heat capacity is not known, and thus the standard procedure is to assume the same value for all materials. In this work, we developed a machine learning approach, trained on density functional theory simulations, to accurately predict the heat capacity of these materials, that is, zeolites, metal\u2013organic frameworks and covalent\u2013organic frameworks. The accuracy of our prediction is confirmed with experimental data. Finally, for a temperature swing adsorption process that captures carbon from the flue gas of a coal-fired power plant, we show that for some materials, the heat requirement is reduced by as much as a factor of two using the correct heat capacity. Heat capacity of nanoporous materials is important for processes such as carbon capture, as this can affect process design energy requirements. Here, a machine learning approach for heat capacity prediction, trained on density functional theory simulations, is presented and experimentally verified."
    ],
    "b_categories":[
      "cond-mat.mtrl-sci"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "A deep-learning approach to realizing functionality in nanoelectronic devices"
    ],
    "c_abstract":[
      "Many nanoscale devices require precise optimization to function. Tuning them to the desired operation regime becomes increasingly difficult and time-consuming when the number of terminals and couplings grows. Imperfections and device-to-device variations hinder optimization that uses physics-based models. Deep neural networks (DNNs) can model various complex physical phenomena but, so far, are mainly used as predictive tools. Here, we propose a generic deep-learning approach to efficiently optimize complex, multi-terminal nanoelectronic devices for desired functionality. We demonstrate our approach for realizing functionality in a disordered network of dopant atoms in silicon. We model the input\u2013output characteristics of the device with a DNN, and subsequently optimize control parameters in the DNN model through gradient descent to realize various classification tasks. When the corresponding control settings are applied to the physical device, the resulting functionality is as predicted by the DNN model. We expect our approach to contribute to fast, in situ optimization of complex (quantum) nanoelectronic devices."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.13126,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"A Knowledge-enhanced Pathology Vision-language Foundation Model for\n  Cancer Diagnosis",
    "a_abstract":"Deep learning has enabled the development of highly robust foundation models\nfor various pathological tasks across diverse diseases and patient cohorts.\nAmong these models, vision-language pre-training, which leverages large-scale\npaired data to align pathology image and text embedding spaces, and provides a\nnovel zero-shot paradigm for downstream tasks. However, existing models have\nbeen primarily data-driven and lack the incorporation of domain-specific\nknowledge, which limits their performance in cancer diagnosis, especially for\nrare tumor subtypes. To address this limitation, we establish a\nKnowledge-enhanced Pathology (KEEP) foundation model that harnesses disease\nknowledge to facilitate vision-language pre-training. Specifically, we first\nconstruct a disease knowledge graph (KG) that covers 11,454 human diseases with\n139,143 disease attributes, including synonyms, definitions, and hypernym\nrelations. We then systematically reorganize the millions of publicly available\nnoisy pathology image-text pairs, into 143K well-structured semantic groups\nlinked through the hierarchical relations of the disease KG. To derive more\nnuanced image and text representations, we propose a novel knowledge-enhanced\nvision-language pre-training approach that integrates disease knowledge into\nthe alignment within hierarchical semantic groups instead of unstructured\nimage-text pairs. Validated on 18 diverse benchmarks with more than 14,000\nwhole slide images (WSIs), KEEP achieves state-of-the-art performance in\nzero-shot cancer diagnostic tasks. Notably, for cancer detection, KEEP\ndemonstrates an average sensitivity of 89.8% at a specificity of 95.0% across 7\ncancer types. For cancer subtyping, KEEP achieves a median balanced accuracy of\n0.456 in subtyping 30 rare brain cancers, indicating strong generalizability\nfor diagnosing rare tumors.",
    "explanation":"However, existing models have been primarily data-driven and\nlack the incorporation of domain-specific knowledge, which limits their performance in cancer diagnosis,\nespecially for rare tumor subtypes. To address this limitation, we establish a KnowledgE-Enhanced\nPathology (KEEP) foundation model that harnesses disease knowledge to facilitate vision-language\npre-training.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Machine Learning-driven Histotype Diagnosis of Ovarian Carcinoma: Insights from the OCEAN AI Challenge"
    ],
    "b_abstract":[
      "Ovarian cancer poses a significant health burden as one of the deadliest malignancies affecting women globally. Histotype assignment of epithelial ovarian cancers can be challenging due to morphologic overlap, inter-observer variability, and the lack of ancillary diagnostic techniques in some areas of the world. Moreover, rare cancers can pose particular diagnostic difficulties because of a relative lack of familiarity with them, underscoring the necessity for robust diagnostic methodologies. The emergence of Artificial Intelligence (AI) has brought promising prospects to the realm of ovarian cancer diagnosis. While various studies have underscored AI's promise, its validation across multiple healthcare centers and hospitals has been limited. Inspired by innovations in medical imaging driven by public competitions, we initiated the Ovarian Cancer subtypE clAssification and outlier detectioN (OCEAN) challenge, the most extensive histopathology competition to date."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Viable and necrotic tumor assessment from whole slide images of osteosarcoma using machine-learning and deep-learning models"
    ],
    "c_abstract":[
      "Pathological estimation of tumor necrosis after chemotherapy is essential for patients with osteosarcoma. This study reports the first fully automated tool to assess viable and necrotic in osteosarcoma, employing advances histopathology digitization learning. We selected 40 digitized whole slide images representing heterogeneity osteosarcoma response. With goal labeling diverse regions tissue into tumor, non-tumor, we trained 13 machine-learning models top performing one (a Support Vector Machine) based on reported accuracy. also developed a deep-learning architecture it same data set. computed receiver-operator characteristic discrimination non-tumor from followed by conditional found our exceptionally well. then used identify interest image-tiles generated test images. The classification output visualized as tumor-prediction map, displaying extent image. Thus, lay foundation complete assessment pipeline original histology map generation. proposed can be adopted other types tumor."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.17717,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Comprehensive Methodology for Sample Augmentation in EEG Biomarker\n  Studies for Alzheimers Risk Classification",
    "a_abstract":"Background: Dementia, marked by cognitive decline, is a global health\nchallenge. Alzheimer's disease (AD), the leading type, accounts for ~70% of\ncases. Electroencephalography (EEG) measures show promise in identifying AD\nrisk, but obtaining large samples for reliable comparisons is challenging.\nObjective: This study integrates signal processing, harmonization, and\nstatistical techniques to enhance sample size and improve AD risk\nclassification reliability. Methods: We used advanced EEG preprocessing,\nfeature extraction, harmonization, and propensity score matching (PSM) to\nbalance healthy non-carriers (HC) and asymptomatic E280A mutation carriers\n(ACr). Data from four databases were harmonized to adjust site effects while\npreserving covariates like age and sex. PSM ratios (2:1, 5:1, 10:1) were\napplied to assess sample size impact on model performance. The final dataset\nunderwent machine learning analysis with decision trees and cross-validation\nfor robust results. Results: Balancing sample sizes via PSM significantly\nimproved classification accuracy, ranging from 0.92 to 0.96 across ratios. This\napproach enabled precise risk identification even with limited samples.\nConclusion: Integrating data processing, harmonization, and balancing\ntechniques improves AD risk classification accuracy, offering potential for\nother neurodegenerative diseases.",
    "explanation":"This study implements a\ncomprehensive methodology that integrates signal processing, data harmonization, and\nstatistical techniques to increase sample size and improve the reliability of Alzheimer's disease\nrisk classification models.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Neural biomarker diagnosis and prediction to mild cognitive impairment and Alzheimer\u2019s disease using EEG technology"
    ],
    "b_abstract":[
      "Background Electroencephalogram (EEG) has emerged as a non-invasive tool to detect the aberrant neuronal activity related to different stages of Alzheimer\u2019s disease (AD). However, the effectiveness of EEG in the precise diagnosis and assessment of AD and its preclinical stage, amnestic mild cognitive impairment (MCI), has yet to be fully elucidated. In this study, we aimed to identify key EEG biomarkers that are effective in distinguishing patients at the early stage of AD and monitoring the progression of AD. Methods A total of 890 participants, including 189 patients with MCI, 330 patients with AD, 125 patients with other dementias (frontotemporal dementia, dementia with Lewy bodies, and vascular cognitive impairment), and 246 healthy controls (HC) were enrolled. Biomarkers were extracted from resting-state EEG recordings for a three-level classification of HC, MCI, and AD. The optimal EEG biomarkers were then identified based on the classification performance. Random forest regression was used to train a series of models by combining participants\u2019 EEG biomarkers, demographic information (i.e., sex, age), CSF biomarkers, and APOE phenotype for assessing the disease progression and individual\u2019s cognitive function. Results The identified EEG biomarkers achieved over 70% accuracy in the three-level classification of HC, MCI, and AD. Among all six groups, the most prominent effects of AD-linked neurodegeneration on EEG metrics were localized at parieto-occipital regions. In the cross-validation predictive analyses, the optimal EEG features were more effective than the CSF + APOE biomarkers in predicting the age of onset and disease course, whereas the combination of EEG + CSF + APOE measures achieved the best performance for all targets of prediction. Conclusions Our study indicates that EEG can be used as a useful screening tool for the diagnosis and disease progression evaluation of MCI and AD."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Quantitative EEG analysis disease during resting and memory task in carriers and non-carriers of PS-1 E280A mutation of familial Alzheimer's"
    ],
    "c_abstract":[
      "Background: Alzheimer\u2019s disease is the most leading cause of dementia in world; mutation PS-1 E280A alters gene Presenilin-1 and causes an early onset familial disease. This has been found large kindred Antioquia, Colombia. The objective this study was to find differences revealed by electroencephalogram between healthy subjects asymptomatic carriers that can be used as clinical markers population. Methods: EEG recorded 15 non during resting a memory task using 64 channels amplifier. Two conditions were analyzed: encoding retrieval, process recording evocating information, respectively. Power spectrum calculated delta (0.5\u20134.0 Hz), theta (4.0\u20138. 0 alpha-1 (8.0\u201310.0 alpha-2 (10.0\u201313.0 beta (13.0\u201325.0 Hz) gamma (25.0\u201350 frequency bands for four regions interest. Changes evaluated different ANOVA analysis. Results: In condition significant decrease (p=0. 0001) increase frequencies (p=0.037) compare with controls. During significantly lower compared controls 008) comparing versus retrieval each group, there more synchronization carriers. Conclusion: Early changes observed recordings, it could use Also seems activate additional cortical order conserve successful cognitive functions before impairment ."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.16728,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Maximizing the Impact of Deep Learning on Subseasonal-to-Seasonal\n  Climate Forecasting: The Essential Role of Optimization",
    "a_abstract":"Weather and climate forecasting is vital for sectors such as agriculture and\ndisaster management. Although numerical weather prediction (NWP) systems have\nadvanced, forecasting at the subseasonal-to-seasonal (S2S) scale, spanning 2 to\n6 weeks, remains challenging due to the chaotic and sparse atmospheric signals\nat this interval. Even state-of-the-art deep learning models struggle to\noutperform simple climatology models in this domain. This paper identifies that\noptimization, instead of network structure, could be the root cause of this\nperformance gap, and then we develop a novel multi-stage optimization strategy\nto close the gap. Extensive empirical studies demonstrate that our multi-stage\noptimization approach significantly improves key skill metrics, PCC and TCC,\nwhile utilizing the same backbone structure, surpassing the state-of-the-art\nNWP systems (ECMWF-S2S) by over \\textbf{19-91\\%}. Our research contests the\nrecent study that direct forecasting outperforms rolling forecasting for S2S\ntasks. Through theoretical analysis, we propose that the underperformance of\nrolling forecasting may arise from the accumulation of Jacobian matrix products\nduring training. Our multi-stage framework can be viewed as a form of teacher\nforcing to address this issue. Code is available at\n\\url{https:\/\/anonymous.4open.science\/r\/Baguan-S2S-23E7\/}",
    "explanation":"Weather and climate forecasting is vital for sectors such\nas agriculture and disaster management. Although numeri-\ncal weather prediction (NWP) systems have advanced, fore-\ncasting at the subseasonal-to-seasonal (S2S) scale, span-\nning 2 to 6 weeks, remains challenging due to the chaotic\nand sparse atmospheric signals at this interval.",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "FuXi-S2S: An accurate machine learning model for global subseasonal forecasts"
    ],
    "b_abstract":[
      "Skillful subseasonal forecasts beyond 2 weeks are crucial for a wide range of applications across various sectors society. Recently, state-of-the-art machine learning based weather forecasting models have made significant advancements, outperforming the high-resolution forecast (HRES) from European Centre Medium-Range Weather Forecasts (ECMWF). However, full potential in has yet to be fully explored. In this study, we introduce FuXi Subseasonal-to-Seasonal (FuXi-S2S), model that provides global daily mean up 42 days, covering 5 upper-air atmospheric variables at 13 pressure levels and 11 surface variables. FuXi-S2S integrates an enhanced base with perturbation module flow-dependent perturbations hidden features, incorporates Perlin noise perturb initial conditions. The is developed using 72 years statistics ECMWF ERA5 reanalysis data. When compared (S2S) reforecasts, demonstrate superior deterministic ensemble total precipitation (TP), outgoing longwave radiation (OLR), geopotential 500 hPa (Z500). Although it shows slightly inferior performance predicting 2-meter temperature (T2M), clear advantages over land area. Regarding extreme forecasts, outperforms S2S globally TP. Furthermore, surpass reforecasts Madden Julian Oscillation (MJO), key source predictability. They extend skillful prediction MJO 30 days 36 days."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b21"
    ],
    "c_title":[
      "Analysis methods for numerical weather prediction"
    ],
    "c_abstract":[
      "Abstract Bayesian probabilistic arguments are used to derive idealized equations for finding the best analysis numerical weather prediction. These compared with those from other published methods in light of physical characteristics NWP problem; namely predetermined nature basis analysis, need approximation because large\u2010order systems, underdeterminacy problem when using observations alone, and availability prior relationships resolve underdeterminacy. Prior result (1) knowledge time evolution model (which together use a distribution constitutes four\u2010dimensional data assimilation); (2) that atmosphere varies slowly (leading balance relationships); (3) nonlinear coupling parameters scales atmosphere. Methods discussed include variational techniques, smoothing splines, Kriging, optimal interpolation, successive corrections, constrained initialization, Kalman\u2010Bucy filter, adjoint assimilation. They all shown relate hence each other. Opinions given on particular might be more appropriate. By comparison method some insight is gained into appropriate choices practical methods."
    ],
    "c_categories":[
      "physics.data-an"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.02466,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Weakly supervised deep learning model with size constraint for prostate\n  cancer detection in multiparametric MRI and generalization to unseen domains",
    "a_abstract":"Fully supervised deep models have shown promising performance for many\nmedical segmentation tasks. Still, the deployment of these tools in clinics is\nlimited by the very timeconsuming collection of manually expert-annotated data.\nMoreover, most of the state-ofthe-art models have been trained and validated on\nmoderately homogeneous datasets. It is known that deep learning methods are\noften greatly degraded by domain or label shifts and are yet to be built in\nsuch a way as to be robust to unseen data or label distributions. In the\nclinical setting, this problematic is particularly relevant as the deployment\ninstitutions may have different scanners or acquisition protocols than those\nfrom which the data has been collected to train the model. In this work, we\npropose to address these two challenges on the detection of clinically\nsignificant prostate cancer (csPCa) from bi-parametric MRI. We evaluate the\nmethod proposed by (Kervadec et al., 2018), which introduces a size constaint\nloss to produce fine semantic cancer lesions segmentations from weak circle\nscribbles annotations. Performance of the model is based on two public (PI-CAI\nand Prostate158) and one private databases. First, we show that the model\nachieves on-par performance with strong fully supervised baseline models, both\non in-distribution validation data and unseen test images. Second, we observe a\nperformance decrease for both fully supervised and weakly supervised models\nwhen tested on unseen data domains. This confirms the crucial need for\nefficient domain adaptation methods if deep learning models are aimed to be\ndeployed in a clinical environment. Finally, we show that ensemble predictions\nfrom multiple trainings increase generalization performance.",
    "explanation":"n this work, we propose to address these two challenges\non the detection of clinically significant prostate cancer (csPCa) from bi-parametric MRI.\nWe evaluate the method proposed by (Kervadec et al., 2018), which introduces a size con-\nstaint loss to produce fine semantic cancer lesions segmentations from weak circle scribbles\nannotations",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "A review of artificial intelligence in prostate cancer detection on imaging"
    ],
    "b_abstract":[
      "A multitude of studies have explored the role artificial intelligence (AI) in providing diagnostic support to radiologists, pathologists, and urologists prostate cancer detection, risk-stratification, management. This review provides a comprehensive overview relevant literature regarding use AI models (1) detecting on radiology images (magnetic resonance ultrasound imaging), (2) histopathology biopsy tissue, (3) assisting supporting tasks for detection (prostate gland segmentation, MRI-histopathology registration, MRI-ultrasound registration). We discuss both potential these assist clinical workflow diagnosis, as well current limitations including variability training data sets, algorithms, evaluation criteria. also ongoing challenges what is needed bridge gap between academic research commercial solutions that improve routine care."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "Automatic Prostate Cancer Detection On Multi-Parametric Mri With Hierarchical Weakly Supervised Learning"
    ],
    "c_abstract":[
      "Multi-parametric MRI (mp-MRI) is one of the most commonly used non-invasive methods for prostate cancer (PCa) diagnosis. In recent years, computer aided diagnosis (CAD) PCa on mp-MRI based deep learning techniques has gained much attention and shown promising progress. The key success to obtain a large amount high quality region annotation such that network can accurately learn variation lesions. order precisely annotate mp-MRI, pathological whole mount data patient normally required as reference, which often difficult in real world clinical situations. Therefore, we are motivated propose new method integrate different levels information available screening workflow through multitask hierarchical weakly supervised framework detection mp-MRI. Experimental results show our achieves segmentation results."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.02614,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Divergent Domains, Convergent Grading: Enhancing Generalization in\n  Diabetic Retinopathy Grading",
    "a_abstract":"Diabetic Retinopathy (DR) constitutes 5% of global blindness cases. While\nnumerous deep learning approaches have sought to enhance traditional DR grading\nmethods, they often falter when confronted with new out-of-distribution data\nthereby impeding their widespread application. In this study, we introduce a\nnovel deep learning method for achieving domain generalization (DG) in DR\ngrading and make the following contributions. First, we propose a new way of\ngenerating image-to-image diagnostically relevant fundus augmentations\nconditioned on the grade of the original fundus image. These augmentations are\ntailored to emulate the types of shifts in DR datasets thus increase the\nmodel's robustness. Second, we address the limitations of the standard\nclassification loss in DG for DR fundus datasets by proposing a new DG-specific\nloss, domain alignment loss; which ensures that the feature vectors from all\ndomains corresponding to the same class converge onto the same manifold for\nbetter domain generalization. Third, we tackle the coupled problem of data\nimbalance across DR domains and classes by proposing to employ Focal loss which\nseamlessly integrates with our new alignment loss. Fourth, due to inevitable\nobserver variability in DR diagnosis that induces label noise, we propose\nleveraging self-supervised pretraining. This approach ensures that our DG model\nremains robust against early susceptibility to label noise, even when only a\nlimited dataset of non-DR fundus images is available for pretraining. Our\nmethod demonstrates significant improvements over the strong Empirical Risk\nMinimization baseline and other recently proposed state-of-the-art DG methods\nfor DR grading. Code is available at https:\/\/github.com\/sharonchokuwa\/dg-adr.",
    "explanation":"In this study, we introduce a novel deep learning\nmethod for achieving domain generalization (DG) in DR\ngrading and make the following contributions.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Medical diffusion on a budget: textual inversion for medical image generation"
    ],
    "b_abstract":[
      "Diffusion-based models for text-to-image generation have gained immense popularity due to recent advancements in efficiency, accessibility, and quality. Although it is becoming increasingly feasible perform inference with these systems using consumer-grade GPUs, training them from scratch still requires access large datasets significant computational resources. In the case of medical image generation, availability large, publicly accessible that include text reports limited legal ethical concerns. While a diffusion model on private dataset may address this issue, not always institutions lacking necessary This work demonstrates pre-trained Stable Diffusion models, originally trained natural images, can be adapted various imaging modalities by embeddings textual inversion. study, we conducted experiments comprising only 100 samples three modalities. Embeddings were matter hours, while retaining diagnostic relevance generation. Experiments designed achieve several objectives. Firstly, fine-tuned processes inversion, revealing larger more examples are required. Secondly, validated our approach demonstrating 2\\% increase accuracy (AUC) detecting prostate cancer MRI, which challenging multi-modal modality, 0.78 0.80. Thirdly, performed simulations interpolating between healthy diseased states, combining multiple pathologies, inpainting show embedding flexibility control disease appearance. Finally, study small (less than 1 MB), facilitates easy sharing data reduced privacy"
    ],
    "b_categories":[
      "q-bio.OT"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "Deep Learning Techniques for Diabetic Retinopathy Classification: A Survey"
    ],
    "c_abstract":[
      "Diabetic Retinopathy (DR) is a degenerative disease that impacts the eyes and consequence of Diabetes mellitus, where high blood glucose levels induce lesions on eye retina.Diabetic regarded as leading cause blindness for diabetic patients, especially working-age population in developing nations.Treatment involves sustaining patient's current grade vision since irreversible.Early detection crucial order to sustain effectively.The main issue involved with DR manual diagnosis process very time, money, effort consuming an ophthalmologist's examination retinal fundus images.The latter also proves be more difficult, particularly early stages when features are less prominent images.Machine learning-based medical image analysis has proven competency assessing images, utilization deep learning algorithms aided (DR).This paper reviews analyzes state-of-the-art methods supervised, self-supervised, Vision Transformer setups, proposing classification detection.For instance, referable, non-referable, proliferative classifications reviewed summarized.Moreover, discusses available datasets used tasks such detection, classification, segmentation.The assesses research gaps area detection\/classification addresses various challenges need further study investigation."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.18767,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Multi-Task Learning for Integrated Automated Contouring and Voxel-Based\n  Dose Prediction in Radiotherapy",
    "a_abstract":"Deep learning-based automated contouring and treatment planning has been\nproven to improve the efficiency and accuracy of radiotherapy. However,\nconventional radiotherapy treatment planning process has the automated\ncontouring and treatment planning as separate tasks. Moreover in deep learning\n(DL), the contouring and dose prediction tasks for automated treatment planning\nare done independently. In this study, we applied the multi-task learning (MTL)\napproach in order to seamlessly integrate automated contouring and voxel-based\ndose prediction tasks, as MTL can leverage common information between the two\ntasks and be able able to increase the efficiency of the automated tasks. We\ndeveloped our MTL framework using the two datasets: in-house prostate cancer\ndataset and the publicly available head and neck cancer dataset, OpenKBP.\nCompared to the sequential DL contouring and treatment planning tasks, our\nproposed method using MTL improved the mean absolute difference of dose volume\nhistogram metrics of prostate and head and neck sites by 19.82% and 16.33%,\nrespectively. Our MTL model for automated contouring and dose prediction tasks\ndemonstrated enhanced dose prediction performance while maintaining or\nsometimes even improving the contouring accuracy. Compared to the baseline\nautomated contouring model with the dice score coefficients of 0.818 for\nprostate and 0.674 for head and neck datasets, our MTL approach achieved\naverage scores of 0.824 and 0.716 for these datasets, respectively. Our study\nhighlights the potential of the proposed automated contouring and planning\nusing MTL to support the development of efficient and accurate automated\ntreatment planning for radiotherapy.",
    "explanation":"Deep learning-based automated contouring and treatment planning has\nbeen proven to improve the efficiency and accuracy of radiotherapy.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "A Transformer-Embedded Multi-Task Model for Dose Distribution Prediction"
    ],
    "b_abstract":[
      "Radiation therapy is a fundamental cancer treatment in the clinic. However, to satisfy clinical requirements, radiologists have iteratively adjust radiotherapy plan based on experience, causing it extremely subjective and time-consuming obtain clinically acceptable plan. To this end, we introduce transformer-embedded multi-task dose prediction (TransMTDP) network automatically predict distribution radiotherapy. Specifically, achieve more stable accurate predictions, three highly correlated tasks are included our TransMTDP network, i.e. main task provide each pixel with fine-grained value, an auxiliary isodose lines produce coarse-grained ranges, gradient learn subtle information such as radiation patterns edges maps. The integrated through shared encoder, following learning strategy. strengthen connection of output layers for different tasks, further use two additional constraints, consistency loss loss, reinforce match between features generated by task. Additionally, considering many organs human body symmetrical maps present abundant global features, embed transformer into framework capture long-range dependencies Evaluated in-house rectum dataset public head neck dataset, method gains superior performance compared state-of-the-art ones. Code available at https:\/\/github.com\/luuuwen\/TransMTDP."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Clinical integration of machine learning for curative-intent radiation treatment of patients with prostate cancer"
    ],
    "c_abstract":[
      "Machine learning (ML) holds great promise for impacting healthcare delivery; however, to date most methods are tested in \u2018simulated\u2019 environments that cannot recapitulate factors influencing real-world clinical practice. We prospectively deployed and evaluated a random forest algorithm for therapeutic curative-intent radiation therapy (RT) treatment planning for prostate cancer in a blinded, head-to-head study with full integration into the clinical workflow. ML- and human-generated RT treatment plans were directly compared in a retrospective simulation with retesting (n\u2009=\u200950) and a prospective clinical deployment (n\u2009=\u200950) phase. Consistently throughout the study phases, treating physicians assessed ML- and human-generated RT treatment plans in a blinded manner following a priori defined standardized criteria and peer review processes, with the selected RT plan in the prospective phase delivered for patient treatment. Overall, 89% of ML-generated RT plans were considered clinically acceptable and 72% were selected over human-generated RT plans in head-to-head comparisons. RT planning using ML reduced the median time required for the entire RT planning process by 60.1% (118 to 47\u2009h). While ML RT plan acceptability remained stable between the simulation and deployment phases (92 versus 86%), the number of ML RT plans selected for treatment was significantly reduced (83 versus 61%, respectively). These findings highlight that retrospective or simulated evaluation of ML methods, even under expert blinded review, may not be representative of algorithm acceptance in a real-world clinical setting when patient care is at stake."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.10004,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"EyeDiff: text-to-image diffusion model improves rare eye disease\n  diagnosis",
    "a_abstract":"The rising prevalence of vision-threatening retinal diseases poses a\nsignificant burden on the global healthcare systems. Deep learning (DL) offers\na promising solution for automatic disease screening but demands substantial\ndata. Collecting and labeling large volumes of ophthalmic images across various\nmodalities encounters several real-world challenges, especially for rare\ndiseases. Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and\nevaluate its applicability in diagnosing common and rare diseases. EyeDiff is\ntrained on eight large-scale datasets using the advanced latent diffusion\nmodel, covering 14 ophthalmic image modalities and over 80 ocular diseases, and\nis adapted to ten multi-country external datasets. The generated images\naccurately capture essential lesional characteristics, achieving high alignment\nwith text prompts as evaluated by objective metrics and human experts.\nFurthermore, integrating generated images significantly enhances the accuracy\nof detecting minority classes and rare eye diseases, surpassing traditional\noversampling methods in addressing data imbalance. EyeDiff effectively tackles\nthe issue of data imbalance and insufficiency typically encountered in rare\ndiseases and addresses the challenges of collecting large-scale annotated\nimages, offering a transformative solution to enhance the development of\nexpert-level diseases diagnosis models in ophthalmic field.",
    "explanation":"Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and evaluate its\napplicability in diagnosing common and rare diseases.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Artificial Intelligence for Pediatric Ophthalmology"
    ],
    "b_abstract":[
      "PURPOSE OF REVIEW: Despite the impressive results of recent artificial\nintelligence (AI) applications to general ophthalmology, comparatively less\nprogress has been made toward solving problems in pediatric ophthalmology using\nsimilar techniques. This article discusses the unique needs of pediatric\nophthalmology patients and how AI techniques can address these challenges,\nsurveys recent applications of AI to pediatric ophthalmology, and discusses\nfuture directions in the field.\n  RECENT FINDINGS: The most significant advances involve the automated\ndetection of retinopathy of prematurity (ROP), yielding results that rival\nexperts. Machine learning (ML) has also been successfully applied to the\nclassification of pediatric cataracts, prediction of post-operative\ncomplications following cataract surgery, detection of strabismus and\nrefractive error, prediction of future high myopia, and diagnosis of reading\ndisability via eye tracking. In addition, ML techniques have been used for the\nstudy of visual development, vessel segmentation in pediatric fundus images,\nand ophthalmic image synthesis.\n  SUMMARY: AI applications could significantly benefit clinical care for\npediatric ophthalmology patients by optimizing disease detection and grading,\nbroadening access to care, furthering scientific discovery, and improving\nclinical efficiency. These methods need to match or surpass physician\nperformance in clinical trials before deployment with patients. Due to\nwidespread use of closed-access data sets and software implementations, it is\ndifficult to directly compare the performance of these approaches, and\nreproducibility is poor. Open-access data sets and software implementations\ncould alleviate these issues, and encourage further AI applications to\npediatric ophthalmology.\n  KEYWORDS: pediatric ophthalmology, machine learning, artificial intelligence,\ndeep learning"
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "Classification of Retinal Diseases in Optical Coherence Tomography Images Using Artificial Intelligence and Firefly Algorithm"
    ],
    "c_abstract":[
      "In recent years, the number of studies for automatic diagnosis biomedical diseases has increased. Many these have used Deep Learning, which gives extremely good results but requires a vast amount data and computing load. If processor is insufficient quality, this takes time places an excessive load on processor. On other hand, Machine Learning faster than does not much-needed load, it provide as high accuracy value Learning. Therefore, our goal to develop hybrid system that provides value, while requiring smaller less diagnose such retinal we chose study. For purpose, first, layer extraction was conducted through image preprocessing. Then, traditional feature extractors were combined with pre-trained extractors. To select best features, Firefly algorithm. end, multiple binary classifications instead multiclass classification classifiers. Two public datasets in The first dataset had mean 0.957, second 0.954."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.01375,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Mathematics and Statistics"
    ],
    "a_title":"Scaling Laws with Hidden Structure",
    "a_abstract":"Statistical learning in high-dimensional spaces is challenging without a\nstrong underlying data structure. Recent advances with foundational models\nsuggest that text and image data contain such hidden structures, which help\nmitigate the curse of dimensionality. Inspired by results from nonparametric\nstatistics, we hypothesize that this phenomenon can be partially explained in\nterms of decomposition of complex tasks into simpler subtasks. In this paper,\nwe present a controlled experimental framework to test whether neural networks\ncan indeed exploit such ``hidden factorial structures.'' We find that they do\nleverage these latent patterns to learn discrete distributions more\nefficiently, and derive scaling laws linking model sizes, hidden\nfactorizations, and accuracy. We also study the interplay between our\nstructural assumptions and the models' capacity for generalization.",
    "explanation":"The key references I chose in Task 3 combined the concepts of Neural Networks with Discrete Distribution Theory to support this IDR paper. In the abstract, the following lines describe the integration of those selected references:\n\"In this paper, we present a controlled experimental framework to test whether neural networks can indeed exploit such \u201chidden factorial structures.\u201d\n\"We find that they do leverage these latent patterns to learn discrete distributions more efficiently. \"\n\n",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Learning Parities with Neural Networks"
    ],
    "b_abstract":[
      "In recent years we see a rapidly growing line of research which shows learnability various models via common neural network algorithms. Yet, besides very few outliers, these results show that can be learned using linear methods. Namely, such learning neural-networks with gradient-descent is competitive classifier on top data-independent representation the examples. This leaves much to desired, as networks are far more successful than Furthermore, conceptual level, don't seem capture deepness deep networks. this paper make step towards showing leanability inherently non-linear. We under certain distributions, sparse parities learnable gradient decent depth-two network. On other hand, same cannot efficiently by"
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Testing conditional independence of discrete distributions"
    ],
    "c_abstract":[
      "We study the problem of testing *conditional independence* for discrete distributions. Specifically, given samples from a random variable (X, Y, Z) on domain [\u21131]\u00d7[\u21132] \u00d7 [n], we want to distinguish, with probability at least 2\/3, between case that X and Y are conditionally independent Z is \u0454-far, in \u21131-distance, every distribution has this property. Conditional independence concept central importance statistics important applications various scientific domains. As such, statistical task conditional been extensively studied forms within econometrics community nearly century. Perhaps surprisingly, not previously considered framework property particular no tester *sublinear* sample complexity known, even special domains binary."
    ],
    "c_categories":[
      "stat.CO"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":2412.00544,
    "date":null,
    "fields":[
      "Physics"
    ],
    "a_title":"RoBo6: Standardized MMT Light Curve Dataset for Rocket Body\n  Classification",
    "a_abstract":"Space debris presents a critical challenge for the sustainability of future\nspace missions, emphasizing the need for robust and standardized identification\nmethods. However, a comprehensive benchmark for rocket body classification\nremains absent. This paper addresses this gap by introducing the RoBo6 dataset\nfor rocket body classification based on light curves. The dataset, derived from\nthe Mini Mega Tortora database, includes light curves for six rocket body\nclasses: CZ-3B, Atlas 5 Centaur, Falcon 9, H-2A, Ariane 5, and Delta 4. With\n5,676 training and 1,404 test samples, it addresses data inconsistencies using\nresampling, normalization, and filtering techniques. Several machine learning\nmodels were evaluated, including CNN and transformer-based approaches, with\nAstroconformer reporting the best performance. The dataset establishes a common\nbenchmark for future comparisons and advancements in rocket body classification\ntasks.",
    "explanation":"The selected references in Task 3 were based from the following topics introduced in the abstract:\n\n\"Space debris presents a critical challenge for the sustainability of future space missions, emphasizing the need for robust and standardized identification methods.\"\n\"Several machine learning models were evaluated, including\nCNN and transformer-based approaches, with  Astroconformer reporting the best performance\"",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "Attention Is All You Need"
    ],
    "b_abstract":[
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. best performing also connect the encoder and decoder through attention mechanism. We propose a new simple network architecture, Transformer, solely mechanisms, dispensing with recurrence convolutions entirely. Experiments two machine translation tasks show these to be superior quality while being more parallelizable requiring significantly less time train. Our model achieves 28.4 BLEU WMT 2014 English-to-German task, improving over existing results, including ensembles by 2 BLEU. On English-to-French our establishes single-model state-of-the-art score of 41.8 after training for 3.5 days eight GPUs, small fraction costs from literature. that Transformer generalizes well other applying it successfully English constituency parsing both large limited data."
    ],
    "b_categories":[
      "cond-mat.dis-nn"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Space objects classification via lightcurve measurements: deep convolutional neural networks and model-based transfer learning"
    ],
    "c_abstract":[
      "Developing a detailed understanding of the Space Object (SO) population is a fundamental goal of Space Situational Awareness (SSA). The current SO catalog includes simplified characteristic for the observed space objects, mainly the solar radiation pressure and\/or drag ballistic coefficients. Such simplified description limits the dynamic propagation model used for predicting the state of motion of SO to models that assume cannon ball shapes and generic surface properties. The future SO catalog and SSA systems will have to be capable of building a detailed picture of SO characteristics. Traditional measurement sources for SO tracking, such as radar and optical, provide information on SO characteristics. These measurements have been shown to be sensitive to shape, attitude, angular velocity, and surface parameters. State-of-the-art in the literature has been advanced over the past decades and in recent years seen the development of multiple models, nonlinear state estimation, and full Bayesian inversion approaches for SO characterization. The key shortcoming of approaches in literature is their overall computational cost and the limited flexibility to deal with a larger and larger amount of data. In this paper, we present a data-driven method to classification of SO based on a deep learning approach that takes advantage of the representational power of deep neural networks. Here, we design, train and validate a Convolutional Neural Network (CNN) capable of learning to classify SOs from collected light-curve measurements. The proposed methodology relies a physically-based model capable of accurately representing SO reflected light as function of time, size shape and state of motion. The model generates thousands of light-curves per selected class of SO which are employ to train a deep CNN to learn the functional relationship between light curves and SO class. Additionally, a deep CNN is trained using real SO light curves to evaluate the performance on a real, but limited training set. CNNs are compared with more conventional machine learning techniques (bagged trees, support vector machines) and are shown to outperform such methods especially when trained on real data. The concept of model-based transfer learning is proposed as possible path forward to increase the accuracy and speedup the training process."
    ],
    "c_categories":[
      "astro-ph.HE"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.0484,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Mathematics and Statistics"
    ],
    "a_title":"Localized KBO with genetic dynamics for multi-modal optimization",
    "a_abstract":"In this paper, we introduce a novel approach to multi-modal optimization by\nenhancing the recently developed kinetic-based optimization (KBO) method with\ngenetic dynamics (GKBO). The proposed method targets objective functions with\nmultiple global minima, addressing a critical need in fields like engineering\ndesign, machine learning, and bioinformatics. By incorpo rating leader-follower\ndynamics and localized interactions, the algorithm efficiently navigates\nhigh-dimensional search spaces to detect multiple optimal solutions. After\nproviding a binary description, a mean-field approximation is derived, and\ndifferent numerical experiments are conducted to validate the results.",
    "explanation":"This IDR paper involves a combination of topics from different fields. In particular, I highlighted key references in Task 3 where topics in Genetics and the use of Data Structures and Algorithms come into play. Below are some sentences from the Abstract that reflect that:\n\n\"n this paper, we introduce a novel approach to multi-modal optimization by enhancing the recently developed kinetic-based optimization (KBO) method with genetic dynamics (GKBO)\"\n\" By incorporating leader-follower dynamics and localized interactions, the algorithm efficiently navigates high-dimensional search spaces to detect multiple optimal solution.\"",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Kinetic description and convergence analysis of genetic algorithms for global optimization"
    ],
    "b_abstract":[
      "Genetic Algorithms (GA) are a class of metaheuristic global optimization methods inspired by the process natural selection among individuals in population. Despite their widespread use, comprehensive theoretical analysis these remains challenging due to complexity heuristic mechanisms involved. In this work, relying on tools statistical physics, we take first step towards mathematical understanding GA showing how behavior for large number can be approximated through time-discrete kinetic model. This allows us prove convergence algorithm minimum under mild assumptions objective function popular choice mechanism. Furthermore, derive time-continuous model GA, represented Boltzmann-like partial differential equation, and establish relations with other mean-field dynamics optimization. Numerical experiments support validity proposed approximation investigate asymptotic configurations particle system different benchmark problems."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "Genetic Algorithms + Data Structures = Evolution Programs"
    ],
    "c_abstract":[
      "Genetic algorithms are founded upon the principle of evolution, i.e., survival of the fittest. Hence evolution programming techniques, based on genetic algorithms, are applicable to many hard optimization problems, such as optimization of functions with linear and nonlinear constraints, the traveling salesman problem, and problems of scheduling, partitioning, and control. The importance of these techniques is still growing, since evolution programs are parallel in nature, and parallelism is one of the most promising directions in computer science. The book is self-contained and the only prerequisite is basic undergraduate mathematics. This third edition has been substantially revised and extended by three new chapters and by additional appendices containing working material to cover recent developments and a change in the perception of evolutionary computation."
    ],
    "c_categories":[
      "cs.DS"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":2411.17342,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Automatic Skull Reconstruction by Deep Learnable Symmetry Enforcement",
    "a_abstract":"Every year, thousands of people suffer from skull damage and require\npersonalized implants to fill the cranial cavity. Unfortunately, the waiting\ntime for reconstruction surgery can extend to several weeks or even months,\nespecially in less developed countries. One factor contributing to the extended\nwaiting period is the intricate process of personalized implant modeling.\nCurrently, the preparation of these implants by experienced biomechanical\nexperts is both costly and time-consuming. Recent advances in artificial\nintelligence, especially in deep learning, offer promising potential for\nautomating the process. However, deep learning-based cranial reconstruction\nfaces several challenges: (i) the limited size of training datasets, (ii) the\nhigh resolution of the volumetric data, and (iii) significant data\nheterogeneity. In this work, we propose a novel approach to address these\nchallenges by enhancing the reconstruction through learnable symmetry\nenforcement. We demonstrate that it is possible to train a neural network\ndedicated to calculating skull symmetry, which can be utilized either as an\nadditional objective function during training or as a post-reconstruction\nobjective during the refinement step. We quantitatively evaluate the proposed\nmethod using open SkullBreak and SkullFix datasets, and qualitatively using\nreal clinical cases. The results indicate that the symmetry-preserving\nreconstruction network achieves considerably better outcomes compared to the\nbaseline (0.94\/0.94\/1.31 vs 0.84\/0.76\/2.43 in terms of DSC, bDSC, and HD95).\nMoreover, the results are comparable to the best-performing methods while\nrequiring significantly fewer computational resources (< 500 vs > 100,000 GPU\nhours). The proposed method is a considerable contribution to the field of\napplied artificial intelligence in medicine and is a step toward automatic\ncranial defect reconstruction in clinical practice.",
    "explanation":"This IDR paper is an applied research paper that focuses on combining Neural Networks to advance biomechanics. Below are some sentences in the abstract that reflect the references in Task 3:\n\n\"We demonstrate that it is possible to train a neural network dedicated to calculating skull symmetry,\"\n\n\"Every year, thousands of people suffer from skull damage and require personalized implants to fill the cranial cavity. Unfortunately, the waiting time for reconstruction surgery can extend to several weeks or even months, especially in less developed countries.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Reconstruction of cranial defect with patient-specific implants: Four different cost-effective techniques"
    ],
    "b_abstract":[
      "Cranial defects secondary to trauma, surgery or pathological causes, result in large cranial imperfection, which affects the appearance of patient as well results sinking flap syndrome. Rehabilitation such a defect can be done using prosthetic options like custom-made polymethyl methacrylate (PMMA) prosthesis surgical outer table calvarial graft segments. It is usually observed that conventional moulage impression defective site most difficult task. The accuracy affected by impression, cast and techniques fabricating wax pattern. Orthodox method mark tentative outline make site. However, this an arbitrary offers challenges accurate replication borders defect. Recently, medical imaging digital modeling dentistry have paved way for dental practice additive manufacturing replacing manual subtractive procedures. use computerized tomography scan obtain 3 D image replica with rapid prototyping has markedly improved at margin defect\/prosthesis interface, resulting better fit optimal contour lending itself esthetic outcome. more reliable implant prosthesis, requires minimum adjustment when on OT table. These case reports compare rehabilitation PMMA methods technique. seen expensive but gives"
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b35"
    ],
    "c_title":[
      "Deep learning-based framework for automatic cranial defect reconstruction and implant modeling"
    ],
    "c_abstract":[
      "This article presents a robust, fast, and fully automatic method for personalized cranial defect reconstruction implant modeling.We propose two-step deep learning-based using modified U-Net architecture to perform the reconstruction, dedicated iterative procedure improve geometry, followed by an generation of models ready 3-D printing. We cross-case augmentation based on imperfect image registration combining cases from different datasets. Additional ablation studies compare strategies other state-of-the-art methods.We evaluate three datasets introduced during AutoImplant 2021 challenge, organized jointly with MICCAI conference. quantitative evaluation Dice boundary coefficients, Hausdorff distance. The coefficient, 95th percentile distance averaged across all test sets, are 0.91, 0.94, 1.53 mm respectively. additional qualitative printing visualization in mixed reality confirm implant's usefulness.The proposes complete pipeline that enables one create model described is greatly extended version scored 1st place challenge tasks. freely release source code, which together open datasets, makes results reproducible. defects may enable manufacturing implants significantly shorter time, possibly allowing process directly given intervention. Moreover, we show usability further reduce surgery time."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.04747,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Equivariant Graph Attention Networks with Structural Motifs for\n  Predicting Cell Line-Specific Synergistic Drug Combinations",
    "a_abstract":"Cancer is the second leading cause of death, with chemotherapy as one of the\nprimary forms of treatment. As a result, researchers are turning to drug\ncombination therapy to decrease drug resistance and increase efficacy. Current\nmethods of drug combination screening, such as in vivo and in vitro, are\ninefficient due to stark time and monetary costs. In silico methods have become\nincreasingly important for screening drugs, but current methods are inaccurate\nand generalize poorly to unseen anticancer drugs. In this paper, I employ a\ngeometric deep-learning model utilizing a graph attention network that is\nequivariant to 3D rotations, translations, and reflections with structural\nmotifs. Additionally, the gene expression of cancer cell lines is utilized to\nclassify synergistic drug combinations specific to each cell line. I compared\nthe proposed geometric deep learning framework to current state-of-the-art\n(SOTA) methods, and the proposed model architecture achieved greater\nperformance on all 12 benchmark tasks performed on the DrugComb dataset.\nSpecifically, the proposed framework outperformed other SOTA methods by an\naccuracy difference greater than 28%. Based on these results, I believe that\nthe equivariant graph attention network's capability of learning geometric data\naccounts for the large performance improvements. The model's ability to\ngeneralize to foreign drugs is thought to be due to the structural motifs\nproviding a better representation of the molecule. Overall, I believe that the\nproposed equivariant geometric deep learning framework serves as an effective\ntool for virtually screening anticancer drug combinations for further\nvalidation in a wet lab environment. The code for this work is made available\nonline at: https:\/\/github.com\/WeToTheMoon\/EGAT_DrugSynergy.",
    "explanation":"From the key references cited in Task 3, below are some sentences that point to the significance of those references that show how this paper is an IDR.\n\n\"Additionally, the gene expression of cancer cell lines is utilized to classify synergistic drug combinations specificto each cell line. \"\n\"I compared the proposed geometric deep learning\nframework to current state-of-the-art (SOTA) methods\"\n\"Based on these results, I believe that the equivariant graph attention network\u2019s capability of learning geometric data accounts for the large performance improvements.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Trends in Phase II Trials for Cancer Therapies"
    ],
    "b_abstract":[
      "Background: Drug combinations are the standard of care in cancer treatment. Identifying effective drug has become more challenging because increasing number drugs. However, a substantial drugs stumble at Phase III clinical trials despite exhibiting favourable efficacy earlier Phase. Methods: We analysed recent II comprising 2165 response rates to uncover trends therapies and used null model non-interacting agents infer synergistic antagonistic combinations. compared our latest dataset with previous assess progress therapy. Results: Targeted reach higher when combination cytotoxic identify four 10 based on observed expected rates. demonstrate that targeted have not significantly increased Conclusions: conclude either we making or rate measured by tumour shrinkage is reliable surrogate endpoint for agents."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b16"
    ],
    "c_title":[
      "E(n) Equivariant Graph Neural Networks"
    ],
    "c_abstract":[
      "This paper introduces a new model to learn graph neural networks equivariant rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. addition, whereas methods are limited equivariance on 3 dimensional spaces, is easily scaled higher-dimensional spaces. We demonstrate the effectiveness of method dynamical systems modelling, representation learning autoencoders predicting molecular properties."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.11513,
    "date":null,
    "fields":[
      "Quantitative Biology"
    ],
    "a_title":"A Modular Open Source Framework for Genomic Variant Calling",
    "a_abstract":"Variant calling is a fundamental task in genomic research, essential for\ndetecting genetic variations such as single nucleotide polymorphisms (SNPs) and\ninsertions or deletions (indels). This paper presents an enhancement to\nDeepChem, a widely used open-source drug discovery framework, through the\nintegration of DeepVariant. In particular, we introduce a variant calling\npipeline that leverages DeepVariant's convolutional neural network (CNN)\narchitecture to improve the accuracy and reliability of variant detection. The\nimplemented pipeline includes stages for realignment of sequencing reads,\ncandidate variant detection, and pileup image generation, followed by variant\nclassification using a modified Inception v3 model. Our work adds a modular and\nextensible variant calling framework to the DeepChem framework and enables\nfuture work integrating DeepChem's drug discovery infrastructure more tightly\nwith bioinformatics pipelines.",
    "explanation":"Some sentences that point to the key references selected in Task 3 are specified below:\n\n\"Variant calling is a fundamental task in genomic research, essential for detecting genetic variations such as single nucleotide polymorphisms (SNPs) and insertions or deletions (indels).\"\n\n\"Our work adds a modular and extensible variant calling framework to the DeepChem framework and enables\nfuture work integrating DeepChem\u2019s drug discovery infrastructure more tightly with bioinformatics pipelines.\"",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "The Genome Analysis Toolkit: A MapReduce framework for analyzing next-generation DNA sequencing data"
    ],
    "b_abstract":[
      "Next-generation DNA sequencing (NGS) projects, such as the 1000 Genomes Project, are already revolutionizing our understanding of genetic variation among individuals. However, massive data sets generated by NGS\u2014the Genome pilot alone includes nearly five terabases\u2014make writing feature-rich, efficient, and robust analysis tools difficult for even computationally sophisticated Indeed, many professionals limited in scope ease with which they can answer scientific questions complexity accessing manipulating produced these machines. Here, we discuss Analysis Toolkit (GATK), a structured programming framework designed to development efficient next-generation sequencers using functional philosophy MapReduce. The GATK provides small but rich set access patterns that encompass majority tool needs. Separating specific calculations from common management infrastructure enables us optimize correctness, stability, CPU memory efficiency enable distributed shared parallelization. We highlight capabilities describing implementation application robust, scale-tolerant like coverage calculators single nucleotide polymorphism (SNP) calling. conclude developers analysts quickly easily write NGS tools, have been incorporated into large-scale projects Project Cancer Atlas."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b12"
    ],
    "c_title":[
      "Rethinking the Inception Architecture for Computer Vision"
    ],
    "c_abstract":[
      "Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety tasks. Since 2014 very deep convolutional started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend translate immediate quality tasks (as long as enough labeled data is provided training), efficiency low parameter count still enabling factors use cases such mobile big-data scenarios. Here we exploring ways scale up that aim utilizing added computation efficiently possible by suitably factorized convolutions aggressive regularization. We benchmark our methods on ILSVRC 2012 classification challenge validation set demonstrate over art: 21:2% top-1 5:6% top-5 error single frame evaluation using network with 5 billion multiply-adds per inference less than 25 million parameters. With an ensemble 4 models multi-crop evaluation, report 3:5% 17:3% 3:6% official test set."
    ],
    "c_categories":[
      "BioInformatics"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.00319,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Improving speaker verification robustness with synthetic emotional\n  utterances",
    "a_abstract":"A speaker verification (SV) system offers an authentication service designed\nto confirm whether a given speech sample originates from a specific speaker.\nThis technology has paved the way for various personalized applications that\ncater to individual preferences. A noteworthy challenge faced by SV systems is\ntheir ability to perform consistently across a range of emotional spectra. Most\nexisting models exhibit high error rates when dealing with emotional utterances\ncompared to neutral ones. Consequently, this phenomenon often leads to missing\nout on speech of interest. This issue primarily stems from the limited\navailability of labeled emotional speech data, impeding the development of\nrobust speaker representations that encompass diverse emotional states.\n  To address this concern, we propose a novel approach employing the CycleGAN\nframework to serve as a data augmentation method. This technique synthesizes\nemotional speech segments for each specific speaker while preserving the unique\nvocal identity. Our experimental findings underscore the effectiveness of\nincorporating synthetic emotional data into the training process. The models\ntrained using this augmented dataset consistently outperform the baseline\nmodels on the task of verifying speakers in emotional speech scenarios,\nreducing equal error rate by as much as 3.64% relative.",
    "explanation":"A speaker verification (SV) system offers an authentication ser-\nvice designed to confirm whether a given speech sample orig-\ninates from a specific speaker. To address this concern, we propose a novel\napproach employing the CycleGAN framework to serve as a\ndata augmentation method. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Human-Centric Interfaces for Ambient Intelligence"
    ],
    "b_abstract":[
      "To create truly effective human-centric ambient intelligence systems both engineering and computing methods are needed. This is the first book to bridge data processing and intelligent reasoning methods for the creation of human-centered ambient intelligence systems. Interdisciplinary in nature, the book covers topics such as multi-modal interfaces, human-computer interaction, smart environments and pervasive computing, addressing principles, paradigms, methods and applications. This book will be an ideal reference for university researchers, R&amp;D engineers, computer engineers, and graduate students working in signal, speech and video processing, multi-modal interfaces, human-computer interaction and applications of ambient intelligence."
    ],
    "b_categories":[
      "physics.app-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "Speaker Diarization with LSTM"
    ],
    "c_abstract":[
      "For many years, i-vector based audio embedding techniques were the dominant approach for speaker verification and diarization applications. However, mirroring rise of deep learning in various domains, neural network embeddings, also known as <i xmlns:mml=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" xmlns:xlink=\"http:\/\/www.w3.org\/1999\/xlink\">d-vectors<\/i> , have consistently demonstrated superior performance. In this paper, we build on success d-vector systems to develop a new diarization. Specifically, combine LSTM-based embeddings with recent work non-parametric clustering obtain state-of-the-art system. Our system is evaluated three standard public datasets, suggesting that offer significant advantages over traditional systems. We achieved 12.0% error rate NIST SRE 2000 CALLHOME, while our model trained out-of-domain data from voice search logs."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.00173,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Spatial Clustering of Molecular Localizations with Graph Neural Networks",
    "a_abstract":"Single-molecule localization microscopy generates point clouds corresponding\nto fluorophore localizations. Spatial cluster identification and analysis of\nthese point clouds are crucial for extracting insights about molecular\norganization. However, this task becomes challenging in the presence of\nlocalization noise, high point density, or complex biological structures. Here,\nwe introduce MIRO (Multimodal Integration through Relational Optimization), an\nalgorithm that uses recurrent graph neural networks to transform the point\nclouds in order to improve clustering efficiency when applying conventional\nclustering techniques. We show that MIRO supports simultaneous processing of\nclusters of different shapes and at multiple scales, demonstrating improved\nperformance across varied datasets. Our comprehensive evaluation demonstrates\nMIRO's transformative potential for single-molecule localization applications,\nshowcasing its capability to revolutionize cluster analysis and provide\naccurate, reliable details of molecular architecture. In addition, MIRO's\nrobust clustering capabilities hold promise for applications in various fields\nsuch as neuroscience, for the analysis of neural connectivity patterns, and\nenvironmental science, for studying spatial distributions of ecological data.",
    "explanation":"Single-molecule localization microscopy generates point clouds corresponding to\nfluorophore localizations.  Here, we introduce MIRO (Mul-\ntimodal Integration through Relational Optimization), an algorithm that uses\nrecurrent graph neural networks to transform the point clouds in order to improve\nclustering efficiency when applying conventional clustering techniques.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Turning single-molecule localization microscopy into a quantitative bioanalytical tool"
    ],
    "b_abstract":[
      "Single-molecule localization microscopy (SMLM) generates super-resolution images by serially detecting individual fluorescent molecules. The power of SMLM, however, goes beyond images: biologically relevant information can be extracted from the mathematical relationships between the positions of the fluorophores in space and time. Here we review the history of SMLM and how recent progress in methods for spatial point analysis has enabled quantitative measurement of SMLM data, providing insights into biomolecule patterning, clustering and oligomerization in biological systems."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b22"
    ],
    "c_title":[
      "A framework for evaluating the performance of SMLM cluster analysis algorithms"
    ],
    "c_abstract":[
      "This analysis compares the performance of seven algorithms for cluster analysis of single-molecule localization microscopy data. The results provide a framework for comparing these types of methods and point users to the best tools. Single-molecule localization microscopy (SMLM) generates data in the form of coordinates of localized fluorophores. Cluster analysis is an attractive route for extracting biologically meaningful information from such data and has been widely applied. Despite a range of cluster analysis algorithms, there exists no consensus framework for the evaluation of their performance. Here, we use a systematic approach based on two metrics to score the success of clustering algorithms in simulated conditions mimicking experimental data. We demonstrate the framework using seven diverse analysis algorithms: DBSCAN, ToMATo, KDE, FOCAL, CAML, ClusterViSu and SR-Tesseler. Given that the best performer depended on the underlying distribution of localizations, we demonstrate an analysis pipeline based on statistical similarity measures that enables the selection of the most appropriate algorithm, and the optimized analysis parameters for real SMLM data. We propose that these standard simulated conditions, metrics and analysis pipeline become the basis for future analysis algorithm development and evaluation."
    ],
    "c_categories":[
      "eess.IV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.1945,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Unsupervised Learning Approach to Anomaly Detection in Gravitational\n  Wave Data",
    "a_abstract":"Gravitational waves (GW), predicted by Einstein's General Theory of\nRelativity, provide a powerful probe of astrophysical phenomena and fundamental\nphysics. In this work, we propose an unsupervised anomaly detection method\nusing variational autoencoders (VAEs) to analyze GW time-series data. By\ntraining on noise-only data, the VAE accurately reconstructs noise inputs while\nfailing to reconstruct anomalies, such as GW signals, which results in\nmeasurable spikes in the reconstruction error. The method was applied to data\nfrom the LIGO H1 and L1 detectors. Evaluation on testing datasets containing\nboth noise and GW events demonstrated reliable detection, achieving an area\nunder the ROC curve (AUC) of 0.89. This study introduces VAEs as a robust,\nunsupervised approach for identifying anomalies in GW data, which offers a\nscalable framework for detecting known and potentially new phenomena in\nphysics.",
    "explanation":"Gravitational waves (GW), predicted by Einstein\u2019s General Theory of Relativity, provide a pow-\nerful probe of astrophysical phenomena and fundamental physics. In this work, we propose an\nunsupervised anomaly detection method using variational autoencoders (VAEs) to analyze GW\ntime-series data. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining"
    ],
    "b_abstract":[
      "It is our great pleasure to welcome you the 2017 ACM Conference on Knowledge Discovery and Data Mining -- KDD 2017. We hope that content professional networking opportunities at will help succeed professionally by enabling to: identify new technology trends; learn from contributed papers, presentations, posters; discover tools, processes practices; job opportunities; hire team members. The terms \"Data Science\", Mining\" \"Big Data\" have, in last few years, grown out of research labs gained presence media everyday conversations. also hear these social decision makers various level governments corporations. impact technologies felt almost every walk life. Importantly, current rapid progress data science facilitated timely sharing newly discovered developed representations algorithms between those working interested industrial deployment. hallmark conferences past they have been bridge theory practise, facilitator catalyst for this exchange. Researchers practitioners meet person interact a meaningful way over several days. conference program, with its three parallel tracks - Research Track, Applied Science Track Invited Speakers brings two groups together. Participants are freely attend any track, events common all tracks. year continues tradition strong tutorial workshop program leading edge issues mining during first days program. devoted technical describing both novel, important contributions, deployed, innovative solutions. Three keynote talks, Cynthia Dwork, Bin Yu, Ren\u00e9e J. Miller touch some hard, emerging before field mining. With growing industry around AI assistants, Panel together experts spawn discussions an exchanges ideas. outstanding lineup speakers their experiences expertise deploying continue hands-on which participants how use practical tools. In order broaden increase participation attendees who would greatly benefit but otherwise found it financially challenging attend, we reserved substantial budget travel grants. awarded record USD 145k student set aside 25k enable smaller startups attend. \"Meet Experts\" sessions, gives researchers unique opportunity form networks share perspectives others aspects science. serve as meeting ground researchers, practitioners, funding agencies investors create commercial products."
    ],
    "b_categories":[
      "physics.gen-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Auto-Encoding Variational Bayes"
    ],
    "c_abstract":[
      "How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.05237,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Pruning the Path to Optimal Care: Identifying Systematically Suboptimal\n  Medical Decision-Making with Inverse Reinforcement Learning",
    "a_abstract":"In aims to uncover insights into medical decision-making embedded within\nobservational data from clinical settings, we present a novel application of\nInverse Reinforcement Learning (IRL) that identifies suboptimal clinician\nactions based on the actions of their peers. This approach centers two stages\nof IRL with an intermediate step to prune trajectories displaying behavior that\ndeviates significantly from the consensus. This enables us to effectively\nidentify clinical priorities and values from ICU data containing both optimal\nand suboptimal clinician decisions. We observe that the benefits of removing\nsuboptimal actions vary by disease and differentially impact certain\ndemographic groups.",
    "explanation":"In aims to uncover insights into medical decision-making embedded within observational data from clinical settings,\nwe present a novel application of Inverse Reinforcement Learning (IRL) that identifies suboptimal clinician actions\nbased on the actions of their peers. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Factors Influencing Physicians' Clinical Decision-making at Upazila Health Complexes in Bangladesh"
    ],
    "b_abstract":[
      "Selecting the most appropriate treatment for each patient is key activity in patient-physician encounters and providing healthcare services. Achieving desirable clinical goals mostly depends on making right decision at time any setting. But little known about physicians' decision-making primary care setting Bangladesh. Therefore, this study explored factors that influence decisions prescribing medications, ordering pathologic tests, counseling patients, average length of visits a consultation session, referral patients to other physicians or hospitals by Upazila Health Complexes (UHCs) country. It also structure social networks their association with process.This was cross-sectional descriptive used data collected from 85 physicians. The respondents, who work UHCs Rajshahi Division, were selected purposively. analyzed statistics including frequency, percentage, one-way analysis variance, linear regression understand relationships among variables.The results reveal multiple visits, referring UHCs. Most prescribe drugs keeping mind purchasing capacity. Risk violence patients' relatives better management are two decisions. professional personal play an influential role process. found dedicate 16.17 minutes session. influenced various distance between residence workplace, level education, number colleagues whom they have regular contact can seek help.The yielded some novel insights complexity everyday tasks would be interest public health researchers policy makers."
    ],
    "b_categories":[
      "Healthcare"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Interactive Teaching Algorithms for Inverse Reinforcement Learning"
    ],
    "c_abstract":[
      "We study the problem of inverse reinforcement learning (IRL) with added twist that learner is assisted by a helpful teacher. More formally, we tackle following algorithmic question: How could teacher provide an informative sequence demonstrations to IRL speed up process? present interactive teaching framework where adaptively chooses next demonstration based on learner's current policy. In particular, design algorithms for two concrete settings: omniscient setting has full knowledge about dynamics and blackbox minimal knowledge. Then, sequential variant popular MCE-IRL prove convergence guarantees our algorithm in setting. Extensive experiments car driving simulator environment show progress can be speeded drastically as compared uninformative"
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":2412.09927,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Neural Vector Tomography for Reconstructing a Magnetization Vector Field",
    "a_abstract":"Discretized techniques for vector tomographic reconstructions are prone to\nproducing artifacts in the reconstructions. The quality of these\nreconstructions may further deteriorate as the amount of noise increases. In\nthis work, we instead model the underlying vector fields using smooth neural\nfields. Owing to the fact that the activation functions in the neural network\nmay be chosen to be smooth and the domain is no longer pixelated, the model\nresults in high-quality reconstructions, even under presence of noise. In the\ncase where we have underlying global continuous symmetry, we find that the\nneural network substantially improves the accuracy of the reconstruction over\nthe existing techniques.",
    "explanation":" In this work, we instead model the underlying\nvector fields using smooth neural fields",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Three-dimensional nanomagnetism"
    ],
    "b_abstract":[
      "Magnetic nanostructures are being developed for use in many aspects of our daily life, spanning areas such as data storage, sensing and biomedicine. Whereas patterned nanomagnets traditionally two-dimensional planar structures, recent work is expanding nanomagnetism into three dimensions; a move triggered by the advance unconventional synthesis methods discovery new magnetic effects. In three-dimensional more complex configurations become possible, with unprecedented properties. Here we review creation these structures their implications emergence physics, development instrumentation computational methods, exploitation numerous applications. Nanoscale devices play key role modern technologies but current applications involve only 2D like discs. authors progress fabrication understanding 3D nanostructures, enabling diverse functionalities."
    ],
    "b_categories":[
      "cond-mat.mes-hall"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "MagNet: machine learning enhanced three-dimensional magnetic reconstruction"
    ],
    "c_abstract":[
      "Three-dimensional (3D) magnetic reconstruction is vital to the study of novel materials for 3D spintronics. Vector field electron tomography (VFET) a major in house tool achieve that. However, conventional VFET exhibits significant artefacts due unavoidable presence missing wedges. In this article, we propose deep-learning enhanced method address issue. A textures library built by micromagnetic simulations. MagNet, an U-shaped convolutional neural network, trained and tested with dataset generated from library. We demonstrate that MagNet outperforms under wedge. Quality reconstructed induction fields significantly improved."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.19927,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Modeling Continuous Spatial-temporal Dynamics of Turbulent Flow with\n  Test-time Refinement",
    "a_abstract":"The precise simulation of turbulent flows holds immense significance across\nvarious scientific and engineering domains, including climate science,\nfreshwater science, and energy-efficient manufacturing. Within the realm of\nsimulating turbulent flows, large eddy simulation (LES) has emerged as a\nprevalent alternative to direct numerical simulation (DNS), offering\ncomputational efficiency. However, LES cannot accurately capture the full\nspectrum of turbulent transport scales and is present only at a lower spatial\nresolution. Reconstructing high-fidelity DNS data from the lower-resolution LES\ndata is essential for numerous applications, but it poses significant\nchallenges to existing super-resolution techniques, primarily due to the\ncomplex spatio-temporal nature of turbulent flows. This paper proposes a novel\nflow reconstruction approach that leverages physical knowledge to model flow\ndynamics. Different from traditional super-resolution techniques, the proposed\napproach uses LES data only in the testing phase through a degradation-based\nrefinement approach to enforce physical constraints and mitigate cumulative\nreconstruction errors over time. Furthermore, a feature sampling strategy is\ndeveloped to enable flow data reconstruction across different resolutions. The\nresults on two distinct sets of turbulent flow data indicate the effectiveness\nof the proposed method in reconstructing high-resolution DNS data, preserving\nthe inherent physical attributes of flow transport, and achieving DNS\nreconstruction at different resolutions.",
    "explanation":"his paper proposes a novel flow recon-\nstruction approach that leverages physical knowledge to\nmodel flow dynamics.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Model-free simulations of turbulent reactive flows"
    ],
    "b_abstract":[
      "A critical review of the modern computational methods for solving the transport equations of turbulent reacting single-phase flows is presented. Primary consideration is given to those methods which lead to \u2018model-free\u2019 simulations while some attention is devoted to \u2018turbulence modeling\u2019. Emphasis is placed upon the role of supercomputers and how their increased computational capacities may be exploited to allow better simulations of the physics of turbulent reactive flows. Comparisons between the commonly employed computational schemes for simulating these flows are given, with the advantages and the limitations associated with each scheme being highlighted. Examples are presented of recent applications of model-free simulations to a variety of unsteady reacting flows, with detailed discussions on the physical phenomena captured by such simulations. Due to the nature of this review, experimental contributions are mentioned only in the context of providing empirical evidence. References are made to other contributions which are not directly related to the computational efforts in order to provide a reasonably comprehensive bibliography for those interested in pursuing various topics in greater detail. Predictions of future accomplishments, as well as some suggestions for future work, are also given."
    ],
    "b_categories":[
      "physics.flu-dyn"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b40"
    ],
    "c_title":[
      "Physics guided neural networks for spatio-temporal superresolution of turbulent flows"
    ],
    "c_abstract":[
      "Direct numerical simulation (DNS) of turbulent flows is computationally expensive and cannot be applied to flows with large Reynolds numbers. Low-resolution large eddy simulation (LES) is a popular alternative, but it is unable to capture all of the scales of turbulent transport accurately. Reconstructing DNS from low-resolution LES is critical for large-scale simulation in many scientific and engineering disciplines, but it poses many challenges to existing super-resolution methods due to the complexity of turbulent flows and computational cost of generating frequent LES data. We propose a physics-guided neural network for reconstructing frequent DNS from sparse LES data by enhancing its spatial resolution and temporal frequency. Our proposed method consists of a partial differential equation (PDE)-based recurrent unit for capturing underlying temporal processes and a physics-guided super-resolution model that incorporates additional physical constraints. We demonstrate the effectiveness of both components in reconstructing the Taylor-Green Vortex using sparse LES data. Moreover, we show that the proposed recurrent unit can preserve the physical characteristics of turbulent flows by leveraging the physical relationships in the Navier-Stokes equation."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.10196,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"High-dimensional Statistics Applications to Batch Effects in\n  Metabolomics",
    "a_abstract":"Batch effects are inevitable in large-scale metabolomics. Prior to formal\ndata analysis, batch effect correction (BEC) is applied to prevent from\nobscuring biological variations, and batch effect evaluation (BEE) is used for\ncorrection assessment. However, existing BEE algorithms neglect covariances\nbetween the variables, and existing BEC algorithms might fail to adequately\ncorrect the covariances. Therefore, we resort to recent advancements in\nhigh-dimensional statistics, and respectively propose \"quality control-based\nsimultaneous tests (QC-ST)\" and \"covariance correction (CoCo)\". Validated by\nthe simulation data, QC-ST can simultaneously detect the statistical\nsignificance of QC samples' mean vectors and covariance matrices across\ndifferent batches, and has a satisfactory statistical performance in empirical\nsizes, empirical powers, and computational speed. Then, we apply four QC-based\nBEC algorithms to two large cohort datasets, and find that extreme gradient\nboost (XGBoost) performs best in relative standard deviation (RSD) and\ndispersion-ratio (D-ratio). After prepositive BEC, if QC-ST still suggests that\nbatch effects between some two batches are significant, CoCo should be\nimplemented. And after CoCo (if necessary), the four metrics (i.e., RSD,\nD-ratio, classification performance, and QC-ST) might be further improved. In\nsummary, under the guidance of QC-ST, we can develop a matching strategy to\nintegrate multiple BEC algorithms more rationally and flexibly, and minimize\nbatch effects for reliable biological conclusions.",
    "explanation":"Batch effects are inevitable in large-scale metabolomics. Prior to formal data analysis, batch effect correction (BEC) is applied to prevent from obscuring biological variations, and batch effect evaluation (BEE) is used for correction assessment.we apply four QC-based BEC algorithms to two large cohort datasets, and find that extreme gradient boost (XGBoost) performs best in relative standard deviation (RSD) and dispersion-ratio (D-ratio).",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Quality assurance procedures for mass spectrometry untargeted metabolomics. a review"
    ],
    "b_abstract":[
      "Untargeted metabolomics, as a global approach, has already proven its great potential and capabilities for the investigation of health and disease, as well as the wide applicability for other research areas. Although great progress has been made on the feasibility of metabolomics experiments, there are still some challenges that should be faced and that includes all sources of fluctuations and bias affecting every step involved in multiplatform untargeted metabolomics studies. The identification and reduction of the main sources of unwanted variation regarding the pre-analytical, analytical and post-analytical phase of metabolomics experiments is essential to ensure high data quality. Nowadays, there is still a lack of information regarding harmonized guidelines for quality assurance as those available for targeted analysis. In this review, sources of variations to be considered and minimized along with methodologies and strategies for monitoring and improvement the quality of the results are discussed. The given information is based on evidences from different groups among our own experiences and recommendations for each stage of the metabolomics workflow. The comprehensive overview with tools presented here might serve other researchers interested in monitoring, controlling and improving the reliability of their findings by implementation of good experimental quality practices in the untargeted metabolomics study."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b16"
    ],
    "c_title":[
      "XGBoost: A Scalable Tree Boosting System"
    ],
    "c_abstract":[
      "Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.00225,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Mathematics and Statistics"
    ],
    "a_title":"Meta-learning Loss Functions of Parametric Partial Differential\n  Equations Using Physics-Informed Neural Networks",
    "a_abstract":"This paper proposes a new way to learn Physics-Informed Neural Network loss\nfunctions using Generalized Additive Models. We apply our method by\nmeta-learning parametric partial differential equations, PDEs, on Burger's and\n2D Heat Equations. The goal is to learn a new loss function for each parametric\nPDE using meta-learning. The derived loss function replaces the traditional\ndata loss, allowing us to learn each parametric PDE more efficiently, improving\nthe meta-learner's performance and convergence.",
    "explanation":"This paper proposes a new way to learn Physics-Informed Neural Network loss functions using Generalized Additive Models.We apply our method by meta-learning parametric partial differential equations, PDEs, on Burger\u2019s and 2D Heat Equations.",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "The Burgers equation"
    ],
    "b_abstract":[
      "The Burgers equation is a simple equation to understand the main properties of the Navier-Stokes equations. In this one-dimensional equation the pressure is neglected but the effects of the nonlinear and viscous terms remain, hence as in the Navier-Stokes equations a Reynolds number can be defined. This number expresses the ratio between the advective and the viscous contribution in a flow. The present book deals with flows at high Reynolds numbers where the nonlinear terms play a fundamental role, and the physics is more complicated than that when the viscous term dominates. The simulation of the flow evolution then necessitates the use of accurate and robust numerical methods. In 3D turbulent flows, where the number of degrees of freedom is greater than in high Re laminar flows, to get solutions it is necessary to introduce some sort of closure to account for the impossibility to resolve the small scales. Before applying any new idea about numerical methods to 3D flows, the good sense suggests to find the simplest equation to test these ideas. This consideration explains why the Burgers equation was often used to check new numerical methods or closure for turbulent flows."
    ],
    "b_categories":[
      "math.AP"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b17"
    ],
    "c_title":[
      "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations"
    ],
    "c_abstract":[
      "We introduce physics-informed neural networks \u2013 neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge\u2013Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction\u2013diffusion systems, and the propagation of nonlinear shallow-water waves."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.05456,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Comparative Study of Probabilistic Atlas and Deep Learning Approaches\n  for Automatic Brain Tissue Segmentation from MRI Using N4 Bias Field\n  Correction and Anisotropic Diffusion Pre-processing Techniques",
    "a_abstract":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI)\nimages is vital for accurate diagnosis and further analysis in medical imaging.\nDespite advancements in segmentation techniques, a comprehensive comparison\nbetween traditional statistical methods and modern deep learning approaches\nusing pre-processing techniques like N4 Bias Field Correction and Anisotropic\nDiffusion remains underexplored. This study provides a comparative analysis of\nvarious segmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and\nLinkNet, enhanced with these pre-processing techniques to segment brain tissues\n(white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF)) on the\nInternet Brain Segmentation Repository (IBSR18) dataset. Our results\ndemonstrate that the 3D nnU-Net model outperforms others, achieving the highest\nmean Dice Coefficient score (0.937 +- 0.012), while the 2D nnU-Net model\nrecorded the lowest mean Hausdorff Distance (5.005 +- 0.343 mm) and the lowest\nmean Absolute Volumetric Difference (3.695 +- 2.931 mm) across five unseen test\nsamples. The findings highlight the superiority of nnU-Net models in brain\ntissue segmentation, particularly when combined with N4 Bias Field Correction\nand Anisotropic Diffusion pre-processing techniques. Our implemented code can\nbe accessed via GitHub.",
    "explanation":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI) images is vital for accurate diagnosis and further analysis in medical imaging. \n\nThis study provides a comparative analysis of various\nsegmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and LinkNet, enhanced with these preprocessing techniques to segment brain tissue",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "MRI segmentation of the human brain: challenges, methods, and applications"
    ],
    "b_abstract":[
      "Image segmentation is one of the most important tasks in medical image analysis and is often the first and the most critical step in many clinical applications. In brain MRI analysis, image segmentation is commonly used for measuring and visualizing the brain\u2019s anatomical structures, for analyzing brain changes, for delineating pathological regions, and for surgical planning and image-guided interventions. In the last few decades, various segmentation techniques of different accuracy and degree of complexity have been developed and reported in the literature. In this paper we review the most popular methods commonly used for brain MRI segmentation. We highlight differences between them and discuss their capabilities, advantages, and limitations. To address the complexity and challenges of the brain MRI segmentation problem, we first introduce the basic concepts of image segmentation. Then, we explain different MRI preprocessing steps including image registration, bias field correction, and removal of nonbrain tissue. Finally, after reviewing different brain MRI segmentation methods, we discuss the validation problem in brain MRI segmentation."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "U-net: Convolutional networks for biomedical image segmentation"
    ],
    "c_abstract":[
      "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.05213,
    "date":null,
    "fields":[
      "Mathematics and Statistics",
      "Quantitative Biology"
    ],
    "a_title":"A chemostat model with variable dilution rate due to biofilm growth",
    "a_abstract":"In many real life applications, a continuous culture bioreactor may cease to\nfunction properly due to bioclogging which is typically caused by the microbial\novergrowth. This is a problem that has been largely overlooked in the chemostat\nmodeling literature, despite the fact that a number of models explicitly\naccounted for biofilm development inside the bioreactor. In a typical chemostat\nmodel, the physical volume of the biofilm is considered negligible when\ncompared to the volume of the fluid. In this paper, we investigate the\ntheoretical consequences of removing such assumption. Specifically, we\nformulate a novel mathematical model of a chemostat where the increase of the\nbiofilm volume occurs at the expense of the fluid volume of the bioreactor, and\nas a result the corresponding dilution rate increases reciprocally. We show\nthat our model is well-posed and describes the bioreactor that can operate in\nthree distinct types of dynamic regimes: the washout equilibrium, the\ncoexistence equilibrium, or a transient towards the clogged state which is\nreached in finite time. We analyze the multiplicity and the stability of the\ncorresponding equilibria. In particular, we delineate the parameter\ncombinations for which the chemostat never clogs up and those for which it\nclogs up in finite time. We also derive criteria for microbial persistence and\nextinction. Finally, we present a numerical evidence that a multistable\ncoexistence in the chemostat with variable dilution rate is feasible.",
    "explanation":"Specifically, we formulate a novel mathematical model of a chemostat where the increase of the biofilm volume occurs at the expense of the fluid volume of the bioreactor, and as a result the corresponding dilution rate increases reciprocally.",
    "b_id":[
      "b1",
      "b8"
    ],
    "b_title":[
      "Microreactors gain wider use as alternative to batch production",
      "How flocculation can explain coexistence in the chemostat"
    ],
    "b_abstract":[
      "The microreactors are gaining wide use among the pharmaceuticals and chemical companies as an alternative to batch production. They not only offers a flexible approach to continuous processing, but promises to save much of the time and effort consumed while expanding the chemistries at commercial scale. Most of the ten global pharma and chemical companies have acquired the Cytos Lab System,, a microreactor product developed by Cellular Process Chemistry Systems GmbH (CPC). Microreactors are comprised of plates with distinct channels in the submillimeter range, providing high surface-to-volume ratio, ultra fast mixing and high degree of control at all levels of production.",
      "We study a chemostat model in which two microbial species grow on single resource. show that coexistence is possible when the would normally win exclusive competition aggregates flocs. Our mathematical analysis exploits fact flocculation fast compared to biological growth, common hypothesis floc models. A numerical shows validity of this approach large parameter range. indicate how our yields mechanistic justification for so-called density-dependent growth."
    ],
    "b_categories":[
      "q-bio.OT"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Effect of bioclogging in porous media on complex conductivity signatures"
    ],
    "c_abstract":[
      "Flow through sand columns inoculated with Pseudomonas aeruginosa were used to investigate the effect of bioclogging on complex conductivity and flow transport properties. Complex (0.1\u20131000 Hz), bulk hydraulic (K), volumetric rate (Q), dispersivity (D), microbial cell concentrations monitored over time. Environmental scanning electron microscope images sands obtained at end experiment. Bioclogging resulting from increases in concentration production exopolymeric substances (EPS) had a large impact imaginary ( \u03c3 \u2033), K, Q, D, porosity (\u03a6). Changes electrical properties developed three stages: an initial stage 1 no significant changes all measured parameters (Days 1\u20138), which we attribute reversible irreversible attachment cells sand. In 2a 9\u201316), caused by growth biomass either as microcolonies filling pore throats and\/or uniform covering surfaces resulted maximum decrease Q but only moderate \u2033. 2b 17\u201324), EPS increase biofilm thickness higher \u2033 compared 2a. 3 25\u201332), reached quasi steady state insignificant are observed parameters. The results this study suggest that can provide complimentary information assessment porous media."
    ],
    "c_categories":[
      "math.MP"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":2411.07031,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Economics and Quantitative Finance"
    ],
    "a_title":"Evaluating the Accuracy of Chatbots in Financial Literature",
    "a_abstract":"We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview\nversions), and Gemini Advanced, in providing references on financial literature\nand employing novel methodologies. Alongside the conventional binary approach\ncommonly used in the literature, we developed a nonbinary approach and a\nrecency measure to assess how hallucination rates vary with how recent a topic\nis. After analyzing 150 citations, ChatGPT-4o had a hallucination rate of 20.0%\n(95% CI, 13.6%-26.4%), while the o1-preview had a hallucination rate of 21.3%\n(95% CI, 14.8%-27.9%). In contrast, Gemini Advanced exhibited higher\nhallucination rates: 76.7% (95% CI, 69.9%-83.4%). While hallucination rates\nincreased for more recent topics, this trend was not statistically significant\nfor Gemini Advanced. These findings emphasize the importance of verifying\nchatbot-provided references, particularly in rapidly evolving fields.",
    "explanation":"We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview versions), and Gemini Advanced, in providing references on financial literature and employing novel methodologies.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "ChatGPT Hallucinates Non-existent Citations: Evidence from Economics"
    ],
    "b_abstract":[
      "In this study, we generate prompts derived from every topic within the Journal of Economic Literature to assess abilities both GPT-3.5 and GPT-4 versions ChatGPT large language model (LLM) write about economic concepts. demonstrates considerable competency in offering general summaries but also cites non-existent references. More than 30% citations provided by version do not exist rate is only slightly reduced for version. Additionally, our findings suggest that reliability decreases as become more specific. We provide quantitative evidence errors output demonstrate importance LLM verification. JEL Codes: B4; O33; I2"
    ],
    "b_categories":[
      "q-fin.ST"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Accuracy of Chatbots in Citing Journal Articles"
    ],
    "c_abstract":[
      "This cross-sectional study quantifies the journal article citation error rate of an artificial intelligence chatbot."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.06184,
    "date":null,
    "fields":[
      "Mathematics and Statistics",
      "Quantitative Biology"
    ],
    "a_title":"Alleviating Hyperparameter-Tuning Burden in SVM Classifiers for\n  Pulmonary Nodules Diagnosis with Multi-Task Bayesian Optimization",
    "a_abstract":"In the field of non-invasive medical imaging, radiomic features are utilized\nto measure tumor characteristics. However, these features can be affected by\nthe techniques used to discretize the images, ultimately impacting the accuracy\nof diagnosis. To investigate the influence of various image discretization\nmethods on diagnosis, it is common practice to evaluate multiple discretization\nstrategies individually. This approach often leads to redundant and\ntime-consuming tasks such as training predictive models and fine-tuning\nhyperparameters separately. This study examines the feasibility of employing\nmulti-task Bayesian optimization to accelerate the hyperparameters search for\nclassifying benign and malignant pulmonary nodules using RBF SVM. Our findings\nsuggest that multi-task Bayesian optimization significantly accelerates the\nsearch for hyperparameters in comparison to a single-task approach. To the best\nof our knowledge, this is the first investigation to utilize multi-task\nBayesian optimization in a critical medical context.",
    "explanation":"This study examines the feasibility of employing multi-task Bayesian optimization to accelerate the hyperparameters search for classifying benign and malignant pulmonary nodules using RBF SVM.",
    "b_id":[
      "b6",
      "b7"
    ],
    "b_title":[
      "Multi-Task Bayesian Optimization",
      "Taking the Human Out of the Loop: A Review of Bayesian Optimization"
    ],
    "b_abstract":[
      "Bayesian optimization has recently been proposed as a framework for automatically tuning the hyperparameters of machine learning models and shown to yield state-of-the-art performance with impressive ease efficiency. In this paper, we explore whether it is possible transfer knowledge gained from previous optimizations new tasks in order find optimal hyperparameter settings more efficiently. Our approach based on extending multi-task Gaussian processes optimization. We show that method significantly speeds up process when compared standard single-task approach. further propose straightforward extension our algorithm jointly minimize average error across multiple demonstrate how can be used greatly speed k-fold cross-validation. Lastly, an adaptation developed acquisition function, entropy search, cost-sensitive, setting. utility function by leveraging small dataset hyper-parameter large dataset. dynamically chooses which query most information per unit cost.",
      "Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing storage architectures. The construction such involves many distributed design choices. end products (e.g., recommendation medical analysis tools, real-time game engines, speech recognizers) thus involve tunable configuration parameters. These parameters often specified hard-coded into the by various developers or teams. If optimized jointly, these can result in significant improvements. Bayesian optimization is a powerful tool for joint choices that gaining great popularity recent years. It promises greater automation so as to increase both product quality human productivity. This review paper introduces optimization, highlights some its methodological aspects, showcases wide range applications."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "New Pathologic Classification of Lung Cancer: Relevance for Clinical Practice and Clinical Trials"
    ],
    "c_abstract":[
      "We summarize significant changes in pathologic classification of lung cancer resulting from the 2011 International Association for Study Lung Cancer\/American Thoracic Society\/European Respiratory Society (IASLC\/ATS\/ERS) adenocarcinoma classification. The was developed by an international core panel experts representing IASLC, ATS, and ERS with oncologists\/pulmonologists, pathologists, radiologists, molecular biologists, thoracic surgeons. Because 70% patients present advanced stages, a new approach to small biopsies cytology specific terminology criteria focused on need distinguishing squamous cell carcinoma testing EGFR mutations ALK rearrangement. Tumors previously classified as non-small-cell carcinoma, not otherwise specified, because lack clear or morphology should be further using limited immunohistochemical workup preserve tissue testing. terms \"bronchioloalveolar carcinoma\" \"mixed subtype adenocarcinoma\" have been discontinued. For resected adenocarcinomas, concepts situ minimally invasive define who, if they undergo complete resection, will 100% disease-free survival. Invasive adenocarcinomas are now predominant pattern after comprehensive histologic subtyping lepidic, acinar, papillary, solid patterns; micropapillary is added poor prognosis. Former mucinous bronchioloalveolar carcinomas called \"invasive adenocarcinoma.\" field rapidly evolving advances occurring frequent basis, particularly arena, this provides much needed standard diagnosis only patient care but also clinical trials TNM"
    ],
    "c_categories":[
      "q-bio.QM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.20675,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Improved ICNN-LSTM Model Classification Based on Attitude Sensor Data\n  for Hazardous State Assessment of Magnetic Adhesion Climbing Wall Robots",
    "a_abstract":"Magnetic adhesion tracked climbing robots are widely utilized in\nhigh-altitude inspection, welding, and cleaning tasks due to their ability to\nperform various operations against gravity on vertical or inclined walls.\nHowever, during operation, the robot may experience overturning torque caused\nby its own weight and load, which can lead to the detachment of magnetic plates\nand subsequently pose safety risks. This paper proposes an improved ICNN-LSTM\nnetwork classification method based on Micro-Electro-Mechanical Systems (MEMS)\nattitude sensor data for real-time monitoring and assessment of hazardous\nstates in magnetic adhesion tracked climbing robots. Firstly, a data\nacquisition strategy for attitude sensors capable of capturing minute\nvibrations is designed. Secondly, a feature extraction and classification model\ncombining an Improved Convolutional Neural Network (ICNN) with a Long\nShort-Term Memory (LSTM) network is proposed. Experimental validation\ndemonstrates that the proposed minute vibration sensing method achieves\nsignificant results, and the proposed classification model consistently\nexhibits high accuracy compared to other models. The research findings provide\neffective technical support for the safe operation of climbing robots",
    "explanation":"This paper proposes an improved ICNN-LSTM network classification method based on Micro-Electro-Mechanical Systems (MEMS) attitude sensor data for real-time monitoring and assessment of hazardous states in magnetic adhesion tracked climbing robots.",
    "b_id":[
      "b13"
    ],
    "b_title":[
      "Discriminative feature learning using a multiscale convolutional capsule network from attitude data for fault diagnosis of industrial robots"
    ],
    "b_abstract":[
      "Effective fault diagnosis is important to ensure the reliability, safety, and efficiency of industrial robots. This article proposes a simple yet effective data acquisition strategy based on transmission mechanism analysis, using only one attitude sensor mounted on an end effector or an output component to monitor the attitude of all transmission components. Unlike widely used vibration-monitoring signals, attitude signals can provide fault features reflecting spatial relationships. Using one attitude sensor facilitates the data collection, but weakens fault features and introduces strong background noise in attitude signals. To learn discriminative features from the attitude data collected by the attitude sensor, a multiscale convolutional capsule network (MCCN) is proposed. In MCCN, integrating low-level and high-level features in a convolutional neural network (CNN) as multiscale features is conductive to noise reduction and robust feature extraction, and a capsule network (CapsNet) is used to recognize the spatial relationships in attitude data. The extracted multiscale features in CNN and the spatial-relational features in CapsNet are fused for effective fault diagnosis of industrial robots. The performance of MCCN is evaluated by attaching a softmax-based classifier and integrating it into different transfer learning frameworks to diagnose faults in industrial robots under single and variable working conditions, respectively. Fault diagnosis experiments were conducted on a 6-axis series industrial robot and a parallel robot-driven 3D printer. The superiority of the proposed MCCN was demonstrated by comparing its performance with the other feature learning methods."
    ],
    "b_categories":[
      "eess.SP"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b21"
    ],
    "c_title":[
      "LSTM Based Bearing Fault Diagnosis of Electrical Machines using Motor Current Signal"
    ],
    "c_abstract":[
      "Rolling element bearings are one of the most critical components rotating machinery, with bearing faults amounting up to 50% in electrical machines. Therefore, fault diagnosis has attracted attention many researchers. Typically, is performed using vibration signals from machine. In addition, by deep learning algorithms on signals, detection accuracy close 100% can be achieved. However, measurement requires an additional sensor, which not present majority Nevertheless, alternative approach, stator current used for diagnosis. paper emphasizes current. The signal processing signature extraction that buried underneath noise signal. uses Paderborn University damaged dataset, contains data healthy, real inner raceway and outer different severity. For redundant frequencies filtered, then filtered eight features extracted time time-frequency domain wavelet packet decomposition (WPD). Then, these well known algorithm Long Short-Term Memory (LSTM), classification made. LSTM mostly speech recognition due its coherence, but this paper, ability also demonstrated 96%, outperforms perform method developed independent speed loading conditions."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.10403,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Mathematics and Statistics",
      "Quantitative Biology"
    ],
    "a_title":"On the Foundation Model for Cardiac MRI Reconstruction",
    "a_abstract":"In recent years, machine learning (ML) based reconstruction has been widely\ninvestigated and employed in cardiac magnetic resonance (CMR) imaging. ML-based\nreconstructions can deliver clinically acceptable image quality under\nsubstantially accelerated scans. ML-based reconstruction, however, also\nrequires substantial data and computational time to train the neural network,\nwhich is often optimized for a fixed acceleration rate or image contrast. In\npractice, imaging parameters are often tuned to best suit the diagnosis, which\nmay differ from the training data. This can result in degraded image quality,\nand multiple trained networks are needed to fulfill the clinical demands. In\nthis study, we propose a foundation model that uses adaptive unrolling,\nchannel-shifting, and Pattern and Contrast-Prompt-UNet (PCP-UNet) to tackle the\nproblem. In particular, the undersampled data goes through a different number\nof unrolled iterations according to its acceleration rate. Channel-shifting\nimproves reconstructed data quality. The PCP-UNet is equipped with an image\ncontrast and sampling pattern prompt. In vivo CMR experiments were performed\nusing mixed combinations of image contrasts, acceleration rates, and\n(under)sampling patterns. The proposed foundation model has significantly\nimproved image quality for a wide range of CMR protocols and outperforms the\nconventional ML-based method.",
    "explanation":"n this study, we propose\na foundation model that uses adaptive unrolling, channel-shifting, and\nPattern and Contrast-Prompt-UNet (PCP-UNet) to tackle the problem.\nIn particular, the undersampled data goes through a different number\nof unrolled iterations according to its acceleration rate. Channel-shifting\nimproves reconstructed data quality.",
    "b_id":[
      "b14",
      "b1"
    ],
    "b_title":[
      "Sparse MRI: The application of compressed sensing for rapid MR imaging",
      "MoDL: Model-Based Deep Learning Architecture for Inverse Problems"
    ],
    "b_abstract":[
      "Abstract The sparsity which is implicit in MR images exploited to significantly undersample k \u2010space. Some such as angiograms are already sparse the pixel representation; other, more complicated have a representation some transform domain\u2013for example, terms of spatial finite\u2010differences or their wavelet coefficients. According recently developed mathematical theory compressed\u2010sensing, with can be recovered from randomly undersampled \u2010space data, provided an appropriate nonlinear recovery scheme used. Intuitively, artifacts due random undersampling add noise\u2010like interference. In domain significant coefficients stand out above A thresholding recover coefficients, effectively recovering image itself. this article, practical incoherent schemes and analyzed by means aliasing Incoherence introduced pseudo\u2010random variable\u2010density phase\u2010encodes. reconstruction performed minimizing \u2113 1 norm transformed image, subject data fidelity constraints. Examples demonstrate improved resolution accelerated acquisition for multislice fast spin\u2010echo brain imaging 3D contrast enhanced angiography. Magn Reson Med, 2007. \u00a9 2007 Wiley\u2010Liss, Inc.",
      "We introduce a model-based image reconstruction framework with convolution neural network (CNN)-based regularization prior. The proposed formulation provides systematic approach for deriving deep architectures inverse problems the arbitrary structure. Since forward model is explicitly accounted for, smaller fewer parameters sufficient to capture information compared direct inversion approaches. Thus, reducing demand training data and time. we rely on end-to-end weight sharing across iterations, CNN weights are customized model, thus offering improved performance over approaches that pre-trained denoisers. Our experiments show decoupling of number iterations from complexity offered by this benefits, including lower data, reduced risk overfitting, implementations significantly memory footprint. propose enforce data-consistency using numerical optimization blocks, such as conjugate gradients algorithm within network. This offers faster convergence per iteration, methods proximal steps consistency. translates performance, primarily when available GPU restricts iterations."
    ],
    "b_categories":[
      "stat.CO",
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Cardiovascular Flow Measurement with Phase-Contrast MR Imaging: Basic Facts and Implementation"
    ],
    "c_abstract":[
      "Phase-contrast magnetic resonance (MR) imaging is a well-known but undervalued method of obtaining quantitative information on blood flow. Applications this technique in cardiovascular MR are expanding. According to the sequences available, phase-contrast measurement can be performed breath hold or during normal respiration. Prospective as well retrospective gating techniques used. Common errors include mismatched encoding velocity, deviation plane, inadequate temporal resolution, spatial accelerated flow and misregistration, phase offset errors. Flow measurements most precise if plane perpendicular vessel interest set through-plane The sequence should repeated at least once, with high velocity used initially. If peak has estimated, an adapted velocity. overall error comprises prescription that occur image analysis data. With imaging, reduced less than 10%, acceptable level for routine clinical use."
    ],
    "c_categories":[
      "q-bio.QM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.15202,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"A Comparison of Machine Learning Algorithms for Predicting Sea Surface\n  Temperature in the Great Barrier Reef Region",
    "a_abstract":"Predicting Sea Surface Temperature (SST) in the Great Barrier Reef (GBR)\nregion is crucial for the effective management of its fragile ecosystems. This\nstudy provides a rigorous comparative analysis of several machine learning\ntechniques to identify the most effective method for SST prediction in this\narea. We evaluate the performance of ridge regression, Least Absolute Shrinkage\nand Selection Operator (LASSO), Random Forest, and Extreme Gradient Boosting\n(XGBoost) algorithms. Our results reveal that while LASSO and ridge regression\nperform well, Random Forest and XGBoost significantly outperform them in terms\nof predictive accuracy, as evidenced by lower Mean Squared Error (MSE), Mean\nAbsolute Error (MAE), and Root Mean Squared Prediction Error (RMSPE).\nAdditionally, XGBoost demonstrated superior performance in minimizing Kullback-\nLeibler Divergence (KLD), indicating a closer alignment of predicted\nprobability distributions with actual observations. These findings highlight\nthe efficacy of using ensemble methods, particularly XGBoost, for predicting\nsea surface temperatures, making them valuable tools for climatological and\nenvironmental modeling.",
    "explanation":"This study provides a rigorous comparative\nanalysis of several machine learning techniques to identify the most effective method for SST\nprediction in this area. We evaluate the performance of ridge regression, Least Absolute Shrinkage\nand Selection Operator (LASSO), Random Forest, and Extreme Gradient Boosting (XGBoost)\nalgorithms. Our results reveal that while LASSO and ridge regression perform well, Random Forest\nand XGBoost significantly outperform them in terms of predictive accuracy, as evidenced by lower\nMean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Prediction\nError (RMSPE).",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "The Great Barrier Reef: an environmental history"
    ],
    "b_abstract":[
      "Reconstructing changes in the Great Barrier Reef 15 3 The natural context of 33 4 spread European settlement coastal Queensland 43 5 beche--de ... mer, pearl shell and trochus fisheries 55 6 Impacts on marine turtles 72 7 dugongs 95 8 whales, sharks fish 9 impacts coral collecting 10 guano rock phosphate mining 11 vi Contents 12 Other reefs 13 Changes island biota 14 Conclusion"
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Ilf-lstm: Enhanced loss function in lstm to predict the sea surface temperature"
    ],
    "c_abstract":[
      "Globe's primary issue is global warming, water temperatures have accompanied it as the sea surface temperature, and it is the primary attribute to balance the energy on the earth's surface. Sea surface temperature prediction is vital to climate forecast. Downwelling currents carry some of this heat to the ocean's bottom layers, which are also heating, covering far behind the increase in sea surface temperature. In deep learning models, the correct loss function will try to reduce the error and converge fast. The proposed improved loss function correctly estimates how close the predictions made by the long short-term memory match the observed values in the training data. This research considers location-specific sea surface temperature predictions using the improved loss function in the long short-term memory neural network at six different locations around India for daily, weekly, and monthly time horizons. Most existing research concentrated on periodic forecasts, but this paper focused on daily, weekly, and monthly predictions. The improved loss function\u2014long short-term memory, achieved 98.7% accuracy, and this improved loss function overcomes the limitations of the existing techniques and reduces the processing time to\u2009~\u20090.35 s. In this research, the sea surface temperature prediction using the improved loss function in the long short-term memory neural network gives better results than the standard prediction models and other existing techniques by considering the long-time dependencies and obtaining features from the spatial data."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.06741,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Methane projections from Canada's oil sands tailings using scientific\n  deep learning reveal significant underestimation",
    "a_abstract":"Bitumen extraction for the production of synthetic crude oil in Canada's\nAthabasca Oil Sands industry has recently come under spotlight for being a\nsignificant source of greenhouse gas emission. A major cause of concern is\nmethane, a greenhouse gas produced by the anaerobic biodegradation of\nhydrocarbons in oil sands residues, or tailings, stored in settle basins\ncommonly known as oil sands tailing ponds. In order to determine the methane\nemitting potential of these tailing ponds and have future methane projections,\nwe use real-time weather data, mechanistic models developed from laboratory\ncontrolled experiments, and industrial reports to train a physics constrained\nmachine learning model. Our trained model can successfully identify the\ndirections of active ponds and estimate their emission levels, which are\ngenerally hard to obtain due to data sampling restrictions. We found that each\nactive oil sands tailing pond could emit between 950 to 1500 tonnes of methane\nper year, whose environmental impact is equivalent to carbon dioxide emissions\nfrom at least 6000 gasoline powered vehicles. Although abandoned ponds are\noften presumed to have insignificant emissions, our findings indicate that\nthese ponds could become active over time and potentially emit up to 1000\ntonnes of methane each year. Taking an average over all datasets that was used\nin model training, we estimate that emissions around major oil sands regions\nwould need to be reduced by approximately 12% over a year, to reduce the\naverage methane concentrations to 2005 levels.",
    "explanation":"In order\nto determine the methane emitting potential of these tailing ponds and have future methane projections,\nwe use real-time weather data, mechanistic models developed from laboratory controlled experiments,\nand industrial reports to train a physics constrained machine learning model.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Learning Polynomials with Neural Networks"
    ],
    "b_abstract":[
      "We study the effectiveness of learning low degree polynomials using neural networks by gradient descent method. While have been shown to great expressive power, and has widely used in practice for networks, few theoretical guarantees are known such methods. In particular, it is well that can get stuck at local minima, even simple classes target functions. this paper, we present several positive results support networks. focus on twolayer where bottom layer a set non-linear hidden nodes, top node linear function, similar Barron (1993). First show randomly initialized network with sufficiently many units, generic algorithm learns any polynomial, assuming initialize weights randomly. Secondly, if use complex-valued (the function still be real), then under suitable conditions, there no robust minima: always escape minimum performing random perturbation. This property does not hold real-valued weights. Thirdly, discuss whether sparse learned small size dependent sparsity function."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b20"
    ],
    "c_title":[
      "Physics-informed machine learning"
    ],
    "c_abstract":[
      "Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems."
    ],
    "c_categories":[
      "physics.chem-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.18259,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Transfer Learning for Deep Learning-based Prediction of Lattice Thermal\n  Conductivity",
    "a_abstract":"Machine learning promises to accelerate the material discovery by enabling\nhigh-throughput prediction of desirable macro-properties from atomic-level\ndescriptors or structures. However, the limited data available about precise\nvalues of these properties have been a barrier, leading to predictive models\nwith limited precision or the ability to generalize. This is particularly true\nof lattice thermal conductivity (LTC): existing datasets of precise (ab initio,\nDFT-based) computed values are limited to a few dozen materials with little\nvariability. Based on such datasets, we study the impact of transfer learning\non both the precision and generalizability of a deep learning model\n(ParAIsite). We start from an existing model (MEGNet~\\cite{Chen2019}) and show\nthat improvements are obtained by fine-tuning a pre-trained version on\ndifferent tasks. Interestingly, we also show that a much greater improvement is\nobtained when first fine-tuning it on a large datasets of low-quality\napproximations of LTC (based on the AGL model) and then applying a second phase\nof fine-tuning with our high-quality, smaller-scale datasets. The promising\nresults obtained pave the way not only towards a greater ability to explore\nlarge databases in search of low thermal conductivity materials but also to\nmethods enabling increasingly precise predictions in areas where quality data\nare rare.",
    "explanation":"Machine learning promises to accelerate the material discovery by enabling high-throughput pre-\ndiction of desirable macro-properties from atomic-level descriptors or structures.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Physics-informed machine learning"
    ],
    "b_abstract":[
      "Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Quantifying the performance of machine learning models in materials discovery"
    ],
    "c_abstract":[
      "The predictive capabilities of machine learning (ML) models used in materials discovery are typically measured using simple statistics such as the root-mean-square error (RMSE) or coefficient determination ($r^2$) between ML-predicted property values and their known values. A tempting assumption is that with low should be effective at guiding discovery, conversely, high give poor performance. However, we observe no clear connection exists a \"static\" quantity averaged across an entire training set, RMSE, ML model's ability to dynamically guide iterative (and often extrapolative) novel targeted properties. In this work, simulate sequential (SL)-guided process demonstrate decoupling traditional model metrics performance discoveries. We show depends strongly on (1) target range within distribution (e.g., whether 1st 10th decile material desired); (2) incorporation uncertainty estimates SL acquisition function; (3) scientist interested one many targets; (4) how iterations allowed. To overcome limitations static robustly capture performance, recommend Discovery Yield ($DY$), measure high-performing were discovered during SL, Probability ($DP$), likelihood discovering any point process."
    ],
    "c_categories":[
      "cond-mat.mtrl-sci"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.18253,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Multimodal Integration of Longitudinal Noninvasive Diagnostics for\n  Survival Prediction in Immunotherapy Using Deep Learning",
    "a_abstract":"Purpose: Analyzing noninvasive longitudinal and multimodal data using\nartificial intelligence could potentially transform immunotherapy for cancer\npatients, paving the way towards precision medicine. Methods: In this study, we\nintegrated pre- and on-treatment blood measurements, prescribed medications and\nCT-based volumes of organs from a large pan-cancer cohort of 694 patients\ntreated with immunotherapy to predict short and long-term overall survival. By\nleveraging a combination of recent developments, different variants of our\nextended multimodal transformer-based simple temporal attention (MMTSimTA)\nnetwork were trained end-to-end to predict mortality at three, six, nine and\ntwelve months. These models were also compared to baseline methods\nincorporating intermediate and late fusion based integration methods. Results:\nThe strongest prognostic performance was demonstrated using the extended\ntransformer-based multimodal model with area under the curves (AUCs) of $0.84\n\\pm $0.04, $0.83 \\pm $0.02, $0.82 \\pm $0.02, $0.81 \\pm $0.03 for 3-, 6-, 9-,\nand 12-month survival prediction, respectively. Conclusion: Our findings\nsuggest that analyzing integrated early treatment data has potential for\npredicting survival of immunotherapy patients. Integrating complementary\nnoninvasive modalities into a jointly trained model, using our extended\ntransformer-based architecture, demonstrated an improved multimodal prognostic\nperformance, especially in short term survival prediction.",
    "explanation":"In this study, we integrated pre- and on-treatment blood\nmeasurements, prescribed medications and CT-based volumes of organs from a large\npan-cancer cohort of 694 patients treated with immunotherapy to predict short and long-term\noverall survival. By leveraging a combination of recent developments, different variants of our\nextended multimodal transformer-based simple temporal attention (MMTSimTA) network were\ntrained end-to-end to predict mortality at three, six, nine and twelve months.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Multimodal data fusion for cancer biomarker discovery with deep learning"
    ],
    "b_abstract":[
      "Technological advances have made it possible to study a patient from multiple angles with high-dimensional, high-throughput multiscale biomedical data. In oncology, massive amounts of data are being generated, ranging from molecular, histopathology, radiology to clinical records. The introduction of deep learning has greatly advanced the analysis of biomedical data. However, most approaches focus on single data modalities, leading to slow progress in methods to integrate complementary data types. Development of effective multimodal fusion approaches is becoming increasingly important as a single modality might not be consistent and sufficient to capture the heterogeneity of complex diseases to tailor medical care and improve personalized medicine. Many initiatives now focus on integrating these disparate modalities to unravel the biological processes involved in multifactorial diseases such as cancer. However, many obstacles remain, including lack of usable data as well as methods for clinical validation and interpretation. Here, we cover these current challenges and reflect on opportunities through deep learning to tackle data sparsity and scarcity, multimodal interpretability and standardization of datasets."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Artificial intelligence for predictive biomarker discovery in immuno-oncology: a systematic review"
    ],
    "c_abstract":[
      "Background: The widespread use of immune checkpoint inhibitors (ICIs) has revolutionised treatment of multiple cancer types. However, selecting patients who may benefit from ICI remains challenging. Artificial intelligence (AI) approaches allow exploitation of high-dimension oncological data in research and development of precision immuno-oncology. Materials and methods: We conducted a systematic literature review of peer-reviewed original articles studying the ICI efficacy prediction in cancer patients across five data modalities: genomics (including genomics, transcriptomics, and epigenomics), radiomics, digital pathology (pathomics), and real-world and multimodality data. Results: A total of 90 studies were included in this systematic review, with 80% published in 2021-2022. Among them, 37 studies included genomic, 20 radiomic, 8 pathomic, 20 real-world, and 5 multimodal data. Standard machine learning (ML) methods were used in 72% of studies, deep learning (DL) methods in 22%, and both in 6%. The most frequently studied cancer type was non-small-cell lung cancer (36%), followed by melanoma (16%), while 25% included pan-cancer studies. No prospective study design incorporated AI-based methodologies from the outset; rather, all implemented AI as a post hoc analysis. Novel biomarkers for ICI in radiomics and pathomics were identified using AI approaches, and molecular biomarkers have expanded past genomics into transcriptomics and epigenomics. Finally, complex algorithms and new types of AI-based markers, such as meta-biomarkers, are emerging by integrating multimodal\/multi-omics data. Conclusion: AI-based methods have expanded the horizon for biomarker discovery, demonstrating the power of integrating multimodal data from existing datasets to discover new meta-biomarkers. While most of the included studies showed promise for AI-based prediction of benefit from immunotherapy, none provided high-level evidence for immediate practice change. A priori planned prospective trial designs are needed to cover all lifecycle steps of these software biomarkers, from development and validation to integration into clinical practice."
    ],
    "c_categories":[
      "Immunotherapy"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.17617,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"An Ensemble Approach for Brain Tumor Segmentation and Synthesis",
    "a_abstract":"The integration of machine learning in magnetic resonance imaging (MRI),\nspecifically in neuroimaging, is proving to be incredibly effective, leading to\nbetter diagnostic accuracy, accelerated image analysis, and data-driven\ninsights, which can potentially transform patient care. Deep learning models\nutilize multiple layers of processing to capture intricate details of complex\ndata, which can then be used on a variety of tasks, including brain tumor\nclassification, segmentation, image synthesis, and registration. Previous\nresearch demonstrates high accuracy in tumor segmentation using various model\narchitectures, including nn-UNet and Swin-UNet. U-Mamba, which uses state space\nmodeling, also achieves high accuracy in medical image segmentation. To\nleverage these models, we propose a deep learning framework that ensembles\nthese state-of-the-art architectures to achieve accurate segmentation and\nproduce finely synthesized images.",
    "explanation":"The integration of machine learning in magnetic resonance\nimaging (MRI), specifically in neuroimaging, is proving to be incred-\nibly effective, leading to better diagnostic accuracy, accelerated image\nanalysis, and data-driven insights, which can potentially transform pa-\ntient care.",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "ALL-Net: Anatomical information lesion-wise loss function integrated into neural network for multiple sclerosis lesion segmentation"
    ],
    "b_abstract":[
      "Accurate detection and segmentation of multiple sclerosis (MS) brain lesions on magnetic resonance images are important for disease diagnosis treatment. This is a challenging task as vary greatly in size, shape, location, image contrast. The objective our study was to develop an algorithm based deep convolutional neural network integrated with anatomic information lesion-wise loss function (ALL-Net) fast accurate automated MS lesions. Distance transformation mapping used construct module that encoded lesion-specific anatomical information. To overcome the lesion size imbalance during training improve small lesions, developed which individual were modeled spheres equal size. On ISBI-2015 longitudinal challenge dataset (19 subjects total), ALL-Net achieved overall score 93.32 amongst top performing methods. larger Cornell (176 significantly improved both voxel-wise metrics (Dice improvement 3.9% 35.3% p-values ranging from p < 0.01 0.0001, AUC precision-recall curve 2.1% 29.8%) (lesion-wise F1 12.6% 29.8% all ROC 1.4% 20.0%) compared leading publicly available tools."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "Deep learning-Based 3D inpainting of brain MR images"
    ],
    "c_abstract":[
      "Abstract The detailed anatomical information of the brain provided by 3D magnetic resonance imaging (MRI) enables various neuroscience research. However, due to long scan time for MR images, 2D images are mainly obtained in clinical environments. purpose this study is generate from a sparsely sampled using an inpainting deep neural network that has U-net-like structure and DenseNet sub-blocks. To train network, not only fidelity loss but also perceptual based on VGG were considered. Various methods used assess overall similarity between inpainted original data. In addition, morphological analyzes performed investigate whether data produced local features similar diagnostic ability was evaluated investigating pattern changes disease groups. Brain anatomy details efficiently recovered proposed network. voxel-based analysis gray matter volume cortical thickness, differences observed small clusters. method will be useful utilizing advanced neuroimaging techniques with MRI"
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.00252,
    "date":null,
    "fields":[

    ],
    "a_title":"Localization Phenomena in Large-Scale Networked Systems: Implications\n  for Fragility",
    "a_abstract":"We study phenomena where some eigenvectors of a graph Laplacian are largely\nconfined in small subsets of the graph. These localization phenomena are\nsimilar to those generally termed Anderson Localization in the Physics\nliterature, and are related to the complexity of the structure of large graphs\nin still unexplored ways. Using spectral perturbation theory and\npseudo-spectrum analysis, we explain how the presence of localized eigenvectors\ngives rise to fragilities (low robustness margins) to unmodeled node or link\ndynamics. Our analysis is demonstrated by examples of networks with relatively\nlow complexity, but with features that appear to induce eigenvector\nlocalization. The implications of this newly-discovered fragility phenomenon\nare briefly discussed.",
    "explanation":"The choices in Task 3 where represent the interdisciplinary topics utilized in this research paper summarized in the Abstract. Below are a few sentences from the Abstract that reflect that:\n\n\"Localization in the Physics literature, and are related to the complexity of the structure of large graphs in still unexplored ways.\"\n\"Using spectral perturbation theory and pseudospectrum analysis, we explain how the presence of localized eigenvectors gives rise to fragilities (low robustness margins) to unmodeled node or link dynamics.\"",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Analytic perturbation theory for matrices and operators"
    ],
    "b_abstract":[
      "Perturbation theory is the study of the behavior of mathematical objects under the influence of perturbations. It is not a well-defined mathematical topic with specific objects and methods, but rather a method of investigation. In this book, perturbation theory will be developed for linear operators. First, inter-est focuses on the properties of spectral objects, such as eigenvalues, eigenprojections, eigenvectors and Jordan vectors, under perturbation of the underlying operator. This study encompasses some difficult problems. On the one hand, variations of the spectral objects need to be calculated quantitatively. The spectral objects are assumed known for the unperturbed operator, the determination (or at least the approximation) of the spectral objects for the perturbed operator is at issue. This is the starting point for the perturbation theory of L. RAYLEIGH [1] (see also R. COURANT and D. HTT.BEBT [1, p. 296 sqq]). On the other hand, the spectral objects often undergo abrupt qualitative changes, even in the case of small perturbations. These changes cause significant complications. Usually, the behavior of the spectral objects depends strongly on the assumptions about the nature of the perturbation. For example, one can assume continuity, differ-entiability, smoothness (i.e. arbitrary differentiability) or analyticity. In the following discussion, only the case of analytic (holomorphic) perturbations will be investigated, even if this strong restriction is applied, the problems remain difficult enough. On the one hand, solving problems of perturbation theory is of conceptual interest. The study of intrinsic spectral properties of a linear operator undergoing perturbation leads to deeper insights and understanding of the structure of the operator. It also leads to the development of new tools for further investigations. On the other hand, applications (inside and outside of mathematics) lead to new questions in perturbation theory. One of the first calculations of perturbation theory was given by L. Rayleigh, who determined the eigenfrequencies and eigenmodes of an oscillating string, fixed at x = 0 and x = n, whose elasticity modulus is constant and whose mass density Q(X) has only a small deviation from a constant value for all x, 0 ^ x 5S n. (That is, the density o(x) is of the form Q(X) = p0 + ea(x), where a(x) is a given function and where e is a small perturbation parameter.) Actually, as this example indicates, the starting point for the development of per-turbation theory was the study of perturbations of spectral objects (eigenvalues and eigenvectors) for concrete classes of operators, for example, Fredholm integral operators or Sturm-Liouville differential operators (for example, see L. LIECHTENSTEIN [1])."
    ],
    "b_categories":[
      "Analytic Perturbation Theory "
    ],
    "b_fields":[

    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Localization and landscape functions for graph laplacians"
    ],
    "c_abstract":[
      "We discuss explicit landscape functions for quantum graphs. By a 'landscape function' Upsilon(x) we mean a function that controls the localization properties of normalized eigenfunctions psi(x) through a pointwise inequality of the form |psi(x)| le Upsilon(x). The ideal Upsilon is a function that a) responds to the potential energy V(x) and to the structure of the graph in some formulaic way; b) is small in examples where eigenfunctions are suppressed by the tunneling effect, and c) relatively large in regions where eigenfunctions may - or may not - be concentrated, as observed in specific examples. It turns out that the connectedness of a graph can present a barrier to the existence of universal landscape functions in the high-energy r\u00e9gime, as we show with simple examples. We therefore apply different methods in different r\u00e9gimes determined by the values of the potential energy V(x) and the eigenvalue parameter E."
    ],
    "c_categories":[
      "Anderson Localization"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":2411.06513,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"PRISM: Privacy-preserving Inter-Site MRI Harmonization via Disentangled\n  Representation Learning",
    "a_abstract":"Multi-site MRI studies often suffer from site-specific variations arising\nfrom differences in methodology, hardware, and acquisition protocols, thereby\ncompromising accuracy and reliability in clinical AI\/ML tasks. We present PRISM\n(Privacy-preserving Inter-Site MRI Harmonization), a novel Deep Learning\nframework for harmonizing structural brain MRI across multiple sites while\npreserving data privacy. PRISM employs a dual-branch autoencoder with\ncontrastive learning and variational inference to disentangle anatomical\nfeatures from style and site-specific variations, enabling unpaired image\ntranslation without traveling subjects or multiple MRI modalities. Our modular\ndesign allows harmonization to any target site and seamless integration of new\nsites without the need for retraining or fine-tuning. Using multi-site\nstructural MRI data, we demonstrate PRISM's effectiveness in downstream tasks\nsuch as brain tissue segmentation and validate its harmonization performance\nthrough multiple experiments. Our framework addresses key challenges in medical\nAI\/ML, including data privacy, distribution shifts, model generalizability and\ninterpretability. Code is available at https:\/\/github.com\/saranggalada\/PRISM",
    "explanation":"From the selected references in Task 3, the following sentences from the abstract reflect the interdisciplinary topics of this research paper, combining the field of medicine  (MRI Scans) with machine learning (AI\/ML tasks):\n\n\"Multi-site MRI studies often suffer from site-specific variations arising from differences in methodology, hardware,\nand acquisition protocols, thereby compromising accuracy\nand reliability in clinical AI\/ML tasks. \"\n\n\"We present PRISM (Privacy-preserving Inter-Site MRI Harmonization), a novel Deep Learning framework for harmonizing structural brain MRI across multiple sites while preserving data privacy.\"",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Advances and Open Problems in Federated Learning"
    ],
    "b_abstract":[
      "The term Federated Learning was coined as recently 2016 to describe a machine learning setting where multiple entities collaborate in solving problem, under the coordination of central server or service provider. Each client\u2019s raw data is stored locally and not exchanged transferred; instead, focused updates intended for immediate aggregation are used achieve objective. Since then, topic has gathered much interest across many different disciplines realization that these interdisciplinary problems likely requires just but techniques from distributed optimization, cryptography, security, differential privacy, fairness, compressed sensing, systems, information theory, statistics, more. This monograph contributions leading experts disciplines, who latest state-of-the art their perspective. These have been carefully curated into comprehensive treatment enables reader understand work done get pointers effort required solve before can become reality practical systems. Researchers working area systems will find this an enlightening read may inspire them on challenging issues outlined. up speed quickly easily what increasingly important topic: Learning."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "The future of digital health with federated learning"
    ],
    "c_abstract":[
      "Abstract Data-driven machine learning (ML) has emerged as a promising approach for building accurate and robust statistical models from medical data, which is collected in huge volumes by modern healthcare systems. Existing data not fully exploited ML primarily because it sits silos privacy concerns restrict access to this data. However, without sufficient will be prevented reaching its full potential and, ultimately, making the transition research clinical practice. This paper considers key factors contributing issue, explores how federated (FL) may provide solution future of digital health highlights challenges considerations that need addressed."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.16464,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Economics and Quantitative Finance"
    ],
    "a_title":"Generating social networks with static and dynamic utility-maximization\n  approaches",
    "a_abstract":"In this paper, we introduce a conceptual framework that model human social\nnetworks as an undirected dot-product graph of independent individuals. Their\nrelationships are only determined by a cost-benefit analysis, i.e. by\nmaximizing an objective function at the scale of the individual or of the whole\nnetwork. On this framework, we build a new artificial network generator in two\nversions. The first fits within the tradition of artificial network generators\nby being able to generate similar networks from empirical data. The second\nrelaxes the computational efficiency constraint and implements the same\nmicro-based decision algorithm, but in agent-based simulations with time and\nfully independent agents. This latter version enables social scientists to\nperform an in-depth analysis of the consequences of behavioral constraints\naffecting individuals on the network they form. This point is illustrated by a\ncase study of imperfect information.",
    "explanation":"The two key references selected in Task 3 reflect what makes this paper an IDR. The sentences copied from the abstract that relate to the references are shown below, combining economics and computational engineering.\n\n\"Their relationships are only determined by a cost-benefit analysis...\"\n\n\"The second relaxes the computational efficiency constraint\nand implements the same micro-based decision algorithm, but in agent-based simulations with time and fully independent agents.\"",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Meeting Strangers and Friends of Friends: How Random Are Social Networks?"
    ],
    "b_abstract":[
      "We present a dynamic model of network formation where nodes find other with whom to form links in two ways: some are found uniformly at random, while others by searching locally through the current structure (e.g., meeting friends friends). This combination processes results spectrum features exhibited large social networks, including presence more high- and low-degree than when formed independently having low distances between network, high clustering on local level. fit data from six networks impute relative ratio random network-based meetings link formation, which turns out vary dramatically across applications. show that as random\/network-based varies, resulting degree distributions can be ordered sense stochastic dominance, allows us infer how process affects average utility network. (JEL D85, Z13)"
    ],
    "b_categories":[
      "q-fin.EC"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "An agent-based spatial urban social network generator: A case study of beijing, china"
    ],
    "c_abstract":[
      "This paper proposes an agent-based spatial social network model, which combines a utility function and heuristic algorithms, to formulate friendships of agents in a given synthetic population comprising individuals and households, as well as their attributes and locations. In order to better and explicitly represent the real social networks, the model attempts to generate both close and somewhat close social networks by linking agents with either close or somewhat close friendships, fitting both distributions of network degree and transitivity, which are two basic characteristics of a network. Here, a utility function, which incorporates the similarity between agents in individual attributes (e.g., sex), as well as the spatial closeness of their residential locations and workplaces, is developed to judge whether a friendship between a pair of agents can be built. Furthermore, the social network model is developed as a key component of an agent-and Geographic Information System (GIS)-based virtual city creator that is a set of synthesis methods used to generate spatially disaggregate urban data. Finally, Beijing, China is used as a case study. Both close and somewhat close social networks are generated with the target and generated distributions well matched, and the generated networks are further analysed from a geographical perspective."
    ],
    "c_categories":[
      "cs.CE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":2411.1726,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"MiceBoneChallenge: Micro-CT public dataset and six solutions for\n  automatic growth plate detection in micro-CT mice bone scans",
    "a_abstract":"Detecting and quantifying bone changes in micro-CT scans of rodents is a\ncommon task in preclinical drug development studies. However, this task is\nmanual, time-consuming and subject to inter- and intra-observer variability. In\n2024, Anonymous Company organized an internal challenge to develop models for\nautomatic bone quantification. We prepared and annotated a high-quality dataset\nof 3D $\\mu$CT bone scans from $83$ mice. The challenge attracted over $80$ AI\nscientists from around the globe who formed $23$ teams. The participants were\ntasked with developing a solution to identify the plane where the bone growth\nhappens, which is essential for fully automatic segmentation of trabecular\nbone. As a result, six computer vision solutions were developed that can\naccurately identify the location of the growth plate plane. The solutions\nachieved the mean absolute error of $1.91\\pm0.87$ planes from the ground truth\non the test set, an accuracy level acceptable for practical use by a\nradiologist. The annotated 3D scans dataset along with the six solutions and\nsource code, is being made public, providing researchers with opportunities to\ndevelop and benchmark their own approaches. The code, trained models, and the\ndata will be shared.",
    "explanation":"This IDR combines various fields like computer science (Computer Vision and AI) and physical medicine (CT Scans) introduced in the abstract. The selected key references from Task 3 are described with a few sentences from the abstract shown below:\n\n\"We prepared and annotated a high-quality dataset of 3D \u03bcCT bone scans from 83 mice. \"\n\n\"As a result, six computer vision solutions were developed that can accurately identify the location of the growth plate plane. \"",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Differentiation of distal ureteral stones and pelvic phleboliths using a convolutional neural network"
    ],
    "b_abstract":[
      "Abstract The objectives were to develop and validate a Convolutional Neural Network (CNN) using local features for differentiating distal ureteral stones from pelvic phleboliths, compare the CNN method with semi-quantitative radiologists\u2019 assessments evaluate whether assessment of calcification its surroundings is sufficient discriminating phleboliths in non-contrast-enhanced CT (NECT). We retrospectively included 341 consecutive patients acute renal colic stone on NECT showing either stone, phlebolith or both. A 2.5-dimensional (2.5D-CNN) model was used, where perpendicular axial, coronal sagittal images through each used as input data CNN. trained 384 calcifications, evaluated an unseen dataset 50 phleboliths. compared by seven radiologists who reviewed 5 \u00d7 cm image stack surrounding calcification, cut-off values based attenuation volume calcifications. differentiated sensitivity, specificity accuracy 94%, 90% 92% AUC 0.95. This similar majority vote 93% significantly higher ( p = 0.03) than mean radiologist 86%. 49%. In conclusion, features. However, more are needed reach optimal discrimination."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b27"
    ],
    "c_title":[
      "Micro-CT data of early physiological cancellous bone formation in the lumbar spine of female C57BL\/6 mice"
    ],
    "c_abstract":[
      "Micro-CT provides critical data for musculoskeletal research, yielding three-dimensional datasets containing distributions of mineral density. Using high-resolution scans, we quantified changes in the fine architecture of bone in the spine of young mice. This data is made available as a reference to physiological cancellous bone growth. The scans (n\u2009=\u200919) depict the extensive structural changes typical for female C57BL\/6 mice pups, aged 1-, 3-, 7-, 10- and 14-days post-partum, as they attain the\u00a0mature geometry. We reveal the micro-morphology down to individual\u00a0trabeculae in the spine that follow phases of mineral-tissue rearrangement in the growing lumbar vertebra on a micrometer length scale. Phantom data is provided to facilitate mineral density calibration. Conventional histomorphometry matched with our micro-CT data on selected samples confirms the validity and accuracy of our 3D scans. The data may thus serve as a reference for modeling normal bone growth and can be used to benchmark other experiments assessing the effects of biomaterials, tissue growth, healing, and regeneration. Measurement(s) bone growth \u2022 bone mineralization involved in bone maturation Technology Type(s) micro-computed tomography Factor Type(s) age Sample Characteristic - Organism Mus musculus Sample Characteristic - Environment biological_process Machine-accessible metadata file describing the reported data: https:\/\/doi.org\/10.6084\/m9.figshare.14062073"
    ],
    "c_categories":[
      "physics.med-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.14846,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy\n  with Pre-training, Data Augmentation and Dual Flow UNet",
    "a_abstract":"Head and neck tumors and metastatic lymph nodes are crucial for treatment\nplanning and prognostic analysis. Accurate segmentation and quantitative\nanalysis of these structures require pixel-level annotation, making automated\nsegmentation techniques essential for the diagnosis and treatment of head and\nneck cancer. In this study, we investigated the effects of multiple strategies\non the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT)\nimages. For the segmentation of pre-RT images, we utilized: 1) a fully\nsupervised learning approach, and 2) the same approach enhanced with\npre-trained weights and the MixUp data augmentation technique. For mid-RT\nimages, we introduced a novel computational-friendly network architecture that\nfeatures separate encoders for mid-RT images and registered pre-RT images with\ntheir labels. The mid-RT encoder branch integrates information from pre-RT\nimages and labels progressively during the forward propagation. We selected the\nhighest-performing model from each fold and used their predictions to create an\nensemble average for inference. In the final test, our models achieved a\nsegmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on\naggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at\nhttps:\/\/github.com\/WltyBY\/HNTS-MRG2024_train_code.",
    "explanation":"In this IDR, mainly two topics from the two the two different fields of medical physics and artificial intelligence are being described. The use of MRI scans falls under the Medical Physics category and utilizing computer vision falls under AI. \n\nHere are a few sentences from the abstract that reflect the integration of this interdisciplinary ideas:\n\n\" In this study, we investigated the effects of multiple strategies on the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT) images.\"\n\"For mid-RT images, we introduced a novel computational-friendly network architecture that features separate encoders for mid-RT images and registered pre-RT images with their labels.\"",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Evaluation of the Impact of Magnetic Resonance Imaging (MRI) on Gross Tumor Volume (GTV) Definition for Radiation Treatment Planning (RTP) of Inoperable High Grade Gliomas (HGGs)"
    ],
    "b_abstract":[
      "Aim and Background . Inoperable high-grade gliomas (HGGs) comprise a specific group of brain tumors portending very poor prognosis. In the absence surgical management, radiation therapy (RT) offers primary local treatment modality for inoperable HGGs. Optimal target definition planning (RTP) HGGs is difficult task given diffusely infiltrative nature disease. this context, detailed multimodality imaging information may add to accuracy in We evaluated impact Magnetic Resonance Imaging (MRI) on Gross Tumor Volume (GTV) RTP study. Materials Methods Twenty-five patients with clinical diagnosis HGG were included GTV was based Computed Tomography- (CT-) simulation images only or both CT-simulation MR images, comparative assessment performed investigate incorporation MRI into Results Median volume acquired by using use CT 65.3 (39.6 - 94.3) cc 76.1 (46.8-108.9) cc, respectively. Incorporation has resulted median increase 12.61% (6%-19%) defined only, which statistically significant (p &lt; 0.05). Conclusion improve have implications dose escalation\/intensification strategies despite need further supporting evidence."
    ],
    "b_categories":[
      "physics.med-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation"
    ],
    "c_abstract":[
      "Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able process 2D images while data used in clinical practice consists of 3D volumes. In this work we propose an approach segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end MRI volumes depicting prostate, learns predict for whole volume at once. We introduce novel objective function, that optimise during training, Dice coefficient. way can deal with situations where there strong imbalance between number foreground background voxels. To cope limited annotated available augment applying random non-linear transformations histogram matching. show our experimental evaluation achieves good performances challenging test requiring fraction processing time needed by other previous methods."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.16995,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Mathematics and Statistics"
    ],
    "a_title":"Leveraging Neural Networks to Optimize Heliostat Field Aiming Strategies\n  in Concentrating Solar Power Tower Plants",
    "a_abstract":"Concentrating Solar Power Tower (CSPT) plants rely on heliostat fields to\nfocus sunlight onto a central receiver. Although simple aiming strategies, such\nas directing all heliostats to the receivers equator, can maximize energy\ncollection, they often result in uneven flux distributions that lead to\nhotspots, thermal stresses, and reduced receiver lifetimes. This paper presents\na novel, data-driven approach that integrates constraint learning, neural\nnetwork-based surrogates, and mathematical optimization to overcome these\nchallenges. The methodology learns complex heliostat-to-receiver flux\ninteractions from simulation data, constructing a surrogate model that is\nembedded into a tractable optimization framework. By maximizing a tailored\nquality score that balances energy collection and flux uniformity, the approach\nyields smoothly distributed flux profiles and mitigates excessive thermal\npeaks. An iterative refinement process, guided by the trust region and\nprogressive data sampling, ensures the surrogate model improves the obtained\nsolution by exploring new spaces during the iterations. Results from a real\nCSPT case study demonstrate that the proposed approach surpasses conventional\nheuristic methods, offering flatter flux distributions and safer thermal\nconditions without a substantial loss in overall energy capture.",
    "explanation":"The two fields described in the references chosen in Task 3 were AI and Mathematics. This IDR talks a lot about mathematical optimization and control to overcome certain challenges as well as leverages AI and machine learning (neural networks).\n\nSentences from the abstract:\n\"This paper presents a novel, data-driven approach that integrates constraint learning, neural network-based surrogates, and mathematical optimization to overcome these challenges.\"\n",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Multi-objective performance optimization & thermodynamic analysis of solar powered supercritical co2 power cycles using machine learning methods & genetic algorithm"
    ],
    "b_abstract":[
      "The present study is focused on multi-objective performance optimization & thermodynamic analysis from the perspectives of energy and exergy for Recompression, Partial Cooling & Main Compression Intercooling supercritical CO2 (sCO2) Brayton cycles for concentrated solar power (CSP) applications using machine learning algorithms. The novelty of this work lies in the integration of artificial neural networks (ANN) and genetic algorithms (GA) for optimizing the performance of advanced sCO2 power cycles considering climatic variation, which has significant implications for both the scientific community and engineering applications in the renewable energy sector. The methodology employed includes thermodynamic analysis based on energy, exergy & environmental factors including system performance optimization. The system is modelled for net power production of 15 MW thermal output utilizing equations for the energy and exergy balance for each component. Subsequently, thermodynamic model extracted dataset used for prediction & evaluation of Random Forest, XGBoost, KNN, AdaBoost, ANN and LightGBM algorithm. Finally, considering climate conditions, multi-objective optimization is carried out for the CSP integrated sCO2 Power cycle for optimal power output, exergy destruction, thermal and exergetic efficiency. Genetic algorithm and TOPSIS (technique for order of preference by similarity to ideal solution), multi-objective decision-making tool, were used to determine the optimum operating conditions. The major findings of this work reveal significant improvements in the performance of the advanced sCO2 cycle by 1.68 % and 7.87 % compared to conventional recompression and partial cooling cycle, respectively. This research could advance renewable energy technologies, particularly concentrated solar power, by improving power cycle designs to increase system efficiency and economic feasibility. Optimized advanced supercritical CO2 power cycles in concentrated solar power plants might increase renewable energy use and energy generation infrastructure, potentially opening new research avenues."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "A method for real-time optimal heliostat aiming strategy generation via deep learning"
    ],
    "c_abstract":[
      "Optimal aiming strategies are essential for efficient solar power tower technology operation. However, the high calculation complexity makes it difficult for existing optimization methods to solve the optimization problem in real-time directly. This work proposes a real-time optimal heliostat aiming strategy generation method via deep learning. First, a two-stage learning scheme where the neural network models are trained by genetic algorithm (GA) benchmark solutions to produce an optimal aiming strategy is presented. Then, an end-to-end model without needing GA solutions for training is developed and discussed. Furthermore, a robust end-to-end training method using randomly sampled flux maps is also proposed. The proposed models demonstrated comparable performance as GA with two orders of magnitude less computation time through case studies. Among the proposed models, the end-to-end model shows significantly better generalization ability than the pure data-driven two-stage model on the test set. A robust end-to-end model with data enhancement has better robustness on unseen flux maps."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.12897,
    "date":null,
    "fields":[

    ],
    "a_title":"Tree Species Classification using Machine Learning and 3D Tomographic\n  SAR -- a case study in Northern Europe",
    "a_abstract":"Tree species classification plays an important role in nature conservation,\nforest inventories, forest management, and the protection of endangered\nspecies. Over the past four decades, remote sensing technologies have been\nextensively utilized for tree species classification, with Synthetic Aperture\nRadar (SAR) emerging as a key technique. In this study, we employed TomoSense,\na 3D tomographic dataset, which utilizes a stack of single-look complex (SLC)\nimages, a byproduct of SAR, captured at different incidence angles to generate\na three-dimensional representation of the terrain. Our research focuses on\nevaluating multiple tabular machine-learning models using the height\ninformation derived from the tomographic image intensities to classify eight\ndistinct tree species. The SLC data and tomographic imagery were analyzed\nacross different polarimetric configurations and geosplit configurations. We\ninvestigated the impact of these variations on classification accuracy,\ncomparing the performance of various tabular machine-learning models and\noptimizing them using Bayesian optimization. Additionally, we incorporated a\nproxy for actual tree height using point cloud data from Light Detection and\nRanging (LiDAR) to provide height statistics associated with the model's\npredictions. This comparison offers insights into the reliability of\ntomographic data in predicting tree species classification based on height.",
    "explanation":"Some sentences that describe the integration of interdisciplinary fields based on the selected references in Task 3:\n\n\"Over the past four decades, remote sensing technologies have been extensively utilized for tree species classification, with Synthetic Aperture Radar (SAR) emerging as a key technique. \"\n\"Tree species classification plays an important role in nature conservation, forest inventories, forest management, and the protection of endangered species.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Mapping Tree Species Using Advanced Remote Sensing Technologies: A State-of-the-Art Review and Perspective"
    ],
    "b_abstract":[
      "Timely and accurate information on tree species (TS) is crucial for developing strategies sustainable management conservation of artificial natural forests. Over the last four decades, advances in remote sensing technologies have made TS classification possible. Since many studies topic been conducted their comprehensive results novel findings published literature, it necessary to conduct an updated review status, trends, potentials, challenges recommend future directions. The will provide overview various optical light detection ranging (LiDAR) sensors; present assess current techniques\/methods for, a general trend method development in, classification; identify limitations In this review, several concluding remarks were made. They include following: (1) A large group using high-resolution satellite, airborne multi-\/hyperspectral imagery, LiDAR data. (2) \u201cmultiple\u201d was observed. (3) Machine learning methods including deep models demonstrated be significant improving accuracy. (4) Recently, unmanned aerial vehicle- (UAV-) based sensors caught interest researchers practitioners topic-related research applications. addition, three directions recommended, refining categories methods, data fusion algorithms or processing chains, exploring new spectral unmixing automatically extract map from satellite hyperspectral"
    ],
    "b_categories":[
      "Remote Sensing Technologies"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Morphological transformation and spatial-logical aggregation for tree species classification using hyperspectral imagery"
    ],
    "c_abstract":[
      "Hyperspectral image (HSI) consists of abundant spectral and spatial characteristics, which contribute to a more accurate identification of materials and land covers. However, most existing methods of hyperspectral image analysis primarily focus on spectral knowledge or coarse-grained spatial information while neglecting the fine-grained morphological structures. In the classification task of complex objects, spatial morphological differences can help to search for the boundary of fine-grained classes, e.g., forestry tree species. Focusing on subtle traits extraction, a spatial-logical aggregation network (SLA-NET) is proposed with morphological transformation for tree species classification. The morphological operators are effectively embedded with the trainable structuring elements, which contributes to distinctive morphological representations. We evaluate the classification performance of the proposed method on two tree species datasets, and the results demonstrate that the proposed SLA-NET significantly outperforms the other state-of-the-art classifiers."
    ],
    "c_categories":[
      "Evolutionary Biology"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.07018,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Data-Driven Gradient Optimization for Field Emission Management in a\n  Superconducting Radio-Frequency Linac",
    "a_abstract":"Field emission can cause significant problems in superconducting\nradio-frequency linear accelerators (linacs). When cavity gradients are pushed\nhigher, radiation levels within the linacs may rise exponentially, causing\ndegradation of many nearby systems. This research aims to utilize machine\nlearning with uncertainty quantification to predict radiation levels at\nmultiple locations throughout the linacs and ultimately optimize cavity\ngradients to reduce field emission induced radiation while maintaining the\ntotal linac energy gain necessary for the experimental physics program. The\noptimized solutions show over 40% reductions for both neutron and gamma\nradiation from the standard operational settings.",
    "explanation":"The field emission is one of the most detrimental problems in superconducting radio-frequency linear accelerators (linacs). The research aims to utilize machine learning with uncertainty quantification to predict radiation levels at multiple locations throughout the linacs.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Field Emission in Superconducting Accelerators: Instrumented Measurements for Its Understanding and Mitigation"
    ],
    "b_abstract":[
      "Several new accelerator projects are adopting superconducting RF (SRF) technology. When accelerating SRF cavities maintain high RF gradients, field emission, the emission of electrons from cavity walls, can occur and may impact operational cavity gradient, radiological environment via activated components, and reliability. In this talk, we will discuss instrumented measurements of field emission from the two 1.1 GeV superconducting continuous wave (CW) linacs in CEBAF. The goal is to improve the understanding of field emission sources originating from cryomodule production, installation and operation. Such basic knowledge is needed in guiding field emission control, mitigation, and reduction toward high gradient and reliable operation of superconducting accelerators."
    ],
    "b_categories":[
      "physics.acc-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "Accelerating cavity fault prediction using deep learning at Jefferson laboratory"
    ],
    "c_abstract":[
      "Abstract Accelerating cavities are an integral part of the continuous electron beam accelerator facility (CEBAF) at Jefferson Laboratory. When any over 400 in CEBAF experiences a fault, it disrupts delivery to experimental user halls. In this study, we propose use deep learning model predict slowly developing cavity faults. By utilizing pre-fault signals, train long short-term memory-convolutional neural network binary classifier distinguish between radio-frequency (RF) signals during normal operation and RF indicative impending We optimize by adjusting fault confidence threshold implementing multiple consecutive window criterion identify events, ensuring low false positive rate. Results obtained from analysis real dataset collected accelerating simulating deployed scenario demonstrate model\u2019s ability with 99.99% accuracy correctly 80% Notably, these achievements were achieved context highly imbalanced dataset, predictions made several hundred milliseconds before onset fault. Anticipating faults enables preemptive measures improve operational efficiency preventing or mitigating their occurrence."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.19844,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Musical composition and 2D cellular automata based on music intervals",
    "a_abstract":"This study is a theoretical approach for exploring the applicability of a 2D\ncellular automaton based on melodic and harmonic intervals in random arrays of\nmusical notes. The aim of this study was to explore alternatives uses for a\ncellular automaton in the musical context for better understanding the musical\ncreativity. We used the complex systems and humanities approaches as a\nframework for capturing the essence of creating music based on rules of music\ntheory. Findings suggested that such rules matter for generating large-scale\npatterns of organized notes. Therefore, our formulation provides a novel\napproach for understanding and replicating aspects of the musical creativity.",
    "explanation":"The study is a theorical approach for exploring thge applicability of a D cellular automaton based on moelodic and harmonic intervals in random arrays of musical notes.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "A New Kind of Science"
    ],
    "b_abstract":[
      "3R3. A New Kind of Science. - S Wolfram (Wolfram Res Inc, 100 Trade Center Dr, Champaign IL 61820-7237). Media, Champaign, IL. 2002. 1197 pp. ISBN 1-57955-008-8. $44.95. Reviewed by M Gad-el-Hak (Eng Build, Rm 303, Virginia Commonwealth Univ, 601 W Main St, PO Box 843015, Richmond, VA 23284-3015). Reviewing Science is like stepping in a minefield. The danger lies going against the deluge praise, proving relevance to this audience, and arguing proposed new science that allegedly set replace science, as we know it. Those issues will be addressed turn, but first brief background. Stephen considered many have been child prodigy: journal paper particle physics at age 15; stint Oxford; PhD from Caltech 20; youngest recipient MacArthur Prize; faculty positions Caltech, Princeton, Illinois; significant contributions cellular automata complexity theory; developer popular software Mathematica; successful entrepreneur, becoming multi-millionaire 30. Running his company via e-mail videoconference, spent last 10 years virtual seclusion, relentlessly, tirelessly, secretly, nocturnally working on an idea possessed him: generating simple computations, algorithms only few lines. book, targeting both scientists non-scientists, partially about using rules generate complex patterns. In task, author has succeeded beyond reproach not showing can done brilliantly beautifully, also explaining it lucidly enough for all understand, appreciate, savor. opinion several reviewers, including one, aspect book tour de force clarity, elegance, simplicity. problem huge leap takes since nature computer-generated patterns look or behave similarly natural man-made things around us\u2014a snow flake, turbulent flow, lung, mollusk shell, traffic jam, outbreak starfish coral reef, entire universe\u2014therefore must way works. Nature runs its course same computer program. That essence science: yield secrets universe, solve our long-standing problems, provide theory everything. More flight fancy later. Deluge: was widely anticipated before actual publication. Published May 14, 2002, quickly became Amazon.com bestseller promptly reviewed scientific press. Heavyweights former included York Times, Chicago Tribune, Newsweek, Time, Daily Telegraph, Le Monde, Frankfurter Allgemeine Zeitung, Economist. Except last, press went gaga over touting author's claim stand existing head. Economist (p 79, June 1, 2002) more subdued even provocatively titling review \"The Emperor's Theory.\" press, reviews were somewhat less glorious skeptical. Physics Today 55, July 2002), Leo Kadanoff's once pointed, subtle polite, concluding he cannot support view any \"new kind science\" displayed Wolfram's book. Newsweek 59, 27, quoted famed physicist Freeman Dyson: \"There's tradition approaching senility come up with grand, improbable theories. unusual he's doing 40s.\" Kadanoff Dyson express minority opinion, however, majority reviewers being excited reason every human mystery currently depressed stock market, free will, quantum field theory, entropy. For present reviewer, lurks high particularly so months behind who already anointed Isaac Newton 21st century. Relevance: As aims replacing readers Applied Mechanics Reviews stake matter. Mechanics\u2014classical most part occasionally quantum\u2014is underlying branch upon which almost applied mechanics based. mathematics here often form partial differential equations, where space time are indefinitely divisible continuum. example, most, all, fluid flows described well-known, well-posed Navier\u2013Stokes equations. those first-principles equations solved agreement experiment reproach. It problem, such frustrated scores him. search simpler alternative is, therefore, quite alluring. mechanics, when they solved, powerful predictive tool explain mechanical world us well help design machines. When analytical solutions unattainable, discretized brute numerical integration used. But possible some situations, example realistic high-Reynolds-number other multi-scale problems required computational memory speed overwhelm today's supercomputers. impenetrable certain degree empiricism introduced relatively faster computations then proceed. Heuristic turbulence modeling compromise. Despite limitations, traditional works exceedingly well, mechanicians happily practice their craft. Readers should, care passionately if laws supplanted science. Argument: Cellular late 1940s John von Neumann Stanislaw Ulam, although claims independently discovered three decades discrete dynamical systems whose behavior completely specified terms repetitive local relation. continuum represented uniform one-, two-, three-dimensional grid, each cell containing single bit data, 0 red, white, blue, etc, bits states. advances steps. state cell, location, computed step algorithm priori defined close neighbors. Simple programs could, fact, result researched one-dimensional arranged line. data updated based value two nearest cells. methodically studied identified total 256 different rules. Space\u2013time diagrams generated show four distinct patterns: dull uniformity; periodic time-dependence; fractal behavior; truly non-repetitive says broken than 300 fix \"errors\" Darwin, Newton, great ones corrected all. proposes radical notion development world, uncover fundamental universe. pattern-generating capabilities supplant difficult-to-solve yet-to-be-found just because resemble does mean work way. Furthermore, believed represent reality used make predictions agree observations. This Galileo's paradigm underpinning modern explanatory power authority stem ability verifiable predictions; otherwise mere post-hoc speculation. exactly what is. games speculation possibly compete horsepower F=ma E=mc2.Wolfram's boasting, throughout 1200 pages, minimum excessive. He writes, \"I vastly I ever thought possible, fact now touches area besides.\" writes ideas originating him, credits belong elsewhere. Alan Turing conceptualized simplest universal computer, machine. Thinking universe vast digital brainchild Edward Fredkin. use machine environment physical detailed Tommaso Toffoli Norman Margolus. Other Per Bak, Charles Bennett, Hans Meinhardt percolate properly credited. Writing person, relegating notes 350 pages grudgingly dismissively mentioning names, restricting list references own publications, dispel important shortcoming. took approach bypassing peer process. self-published acting author, editor, publisher. opening paragraph mostly favorable Time's (May 20, worth reflecting on: \"Cranks occupational hazard scientist eventually faces. Fortunately, these characters usually easy spot. If someone grand overturns centuries knowledge\u2014especially spans unrelated fields biology economics\u2014the odds good she crank. publishes standard journals general readers, watch out. And issued rather conventional publisher, case pretty much airtight.\" extravagant cold fusion\u2014a` la Stanley Pons Martin Fleischman\u2014and deserve proportionally vigilant scrutiny. validated nor subjected process rest mortals expected do. contrast old anti-Newtonian model predict anything. emperor no clothes. offense play brick build edifice call Bottom Line: fun reading pictures, bad recommendation. inspiration, read Newton's Principia Mathematica, Latin. solving Newtonian framework still best bet, one's better books mechanics."
    ],
    "b_categories":[
      "cs.FL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "The structure of musical harmony as an ordered phase of sound: A statistical mechanics approach to music theory"
    ],
    "c_abstract":[
      "Music, while allowing nearly unlimited creative expression, almost always conforms to a set of rigid rules at fundamental level. The description and study these rules, the ordered structures that arise from them, is basis field music theory. Here, I present theoretical formalism aims explain why basic patterns emerge in music, using same statistical mechanics framework describes emergent order across phase transitions physical systems. first apply mean approximation demonstrate occur this model disordered sound discrete sets pitches, including 12-fold octave division used Western music. Beyond model, use numerical simulation uncover musical harmony. These results provide new lens through which view discover ideas explore."
    ],
    "c_categories":[
      "cs.NA"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.06414,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Psycho Gundam: Electroencephalography based real-time robotic control\n  system with deep learning",
    "a_abstract":"The Psycho Frame, a sophisticated system primarily used in Universal Century\n(U.C.) series mobile suits for NEWTYPE pilots, has evolved as an integral\ncomponent in harnessing the latent potential of mental energy. Its ability to\namplify and resonate with the pilot's psyche enables real-time mental control,\ncreating unique applications such as psychomagnetic fields and sensory-based\nweaponry. This paper presents the development of a novel robotic control system\ninspired by the Psycho Frame, combining electroencephalography (EEG) and deep\nlearning for real-time control of robotic systems. By capturing and\ninterpreting brainwave data through EEG, the system extends human cognitive\ncommands to robotic actions, reflecting the seamless synchronization of thought\nand machine, much like the Psyco Frame's integration with a Newtype pilot's\nmental faculties. This research demonstrates how modern AI techniques can\nexpand the limits of human-machine interaction, potentially transcending\ntraditional input methods and enabling a deeper, more intuitive control of\ncomplex robotic systems.",
    "explanation":"This paper presents the development of a novel robotic control system inspired by the Psycho Frame, combining electroencephalograhy and deep learning for real-time control of robotic systems.",
    "b_id":[
      "b1",
      "b9"
    ],
    "b_title":[
      "An EEG-based brain-computer interface for real-time multi-task robotic control",
      "QEEGNet: Quantum Machine Learning for Enhanced Electroencephalography\n  Encoding"
    ],
    "b_abstract":[
      "The Brain Computer Interface (BCI) is the communication between human brain and computer. Electroencephalogram (EEG) one of biomedical signals which can be obtained by attaching electrodes to scalp. Some EEG related applications developed help disabled people, such as based wheelchair or robotic arm. A hybrid BCI real-time control system proposed a multi-tasks robot. In this system, sliding window online data segmentation strategy segment training data, enable learn dynamic features when subject's state transfer from rest task execution state. achieve ensure continuity executing actions. addition, Common Spatial Pattern (CSP) better extract spatial these continuous actions that multiple commands are accurately classified. experiment, three subjects' collected, trained tested performance reliability system. records robot's spending time, moving distance, number objects pushing down. Experimental results given show feasibility Compared remote controller, similar performance. Thus, able robot in environment used develop robot-aided arm methods on neurological rehabilitation principles for stroke injury patients.",
      "Electroencephalography (EEG) is a critical tool in neuroscience and clinical practice for monitoring analyzing brain activity. Traditional neural network models, such as EEGNet, have achieved considerable success decoding EEG signals but often struggle with the complexity high dimensionality of data. Recent advances quantum computing present new opportunities to enhance machine learning models through (QML) techniques. In this paper, we introduce Quantum-EEGNet (QEEGNet), novel hybrid that integrates classical EEGNet architecture improve encoding analysis, forward-looking approach, acknowledging results might not always surpass traditional methods it shows its potential. QEEGNet incorporates layers within network, allowing capture more intricate patterns data potentially offering computational advantages. We evaluate on benchmark dataset, BCI Competition IV 2a, demonstrating consistently outperforms most subjects other robustness noise. Our highlight significant potential quantum-enhanced networks suggesting directions both research practical applications field."
    ],
    "b_categories":[
      "cs.LG",
      "cs.RO"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Braincomputer interfaces for communication and control"
    ],
    "c_abstract":[
      "For many years people have speculated that electroencephalographic activity or other electrophysiological measures of brain function might provide a new non-muscular channel for sending messages and commands to the external world \u2013 a brain\u2013computer interface (BCI). Over the past 15 years, productive BCI research programs have arisen. Encouraged by new understanding of brain function, by the advent of powerful low-cost computer equipment, and by growing recognition of the needs and potentials of people with disabilities, these programs concentrate on developing new augmentative communication and control technology for those with severe neuromuscular disorders, such as amyotrophic lateral sclerosis, brainstem stroke, and spinal cord injury. The immediate goal is to provide these users, who may be completely paralyzed, or \u2018locked in\u2019, with basic communication capabilities so that they can express their wishes to caregivers or even operate word processing programs or neuroprostheses. Present-day BCIs determine the intent of the user from a variety of different electrophysiological signals. These signals include slow cortical potentials, P300 potentials, and mu or beta rhythms recorded from the scalp, and cortical neuronal activity recorded by implanted electrodes. They are translated in real-time into commands that operate a computer display or other device. Successful operation requires that the user encode commands in these signals and that the BCI derive the commands from the signals. Thus, the user and the BCI system need to adapt to each other both initially and continually so as to ensure stable performance. Current BCIs have maximum information transfer rates up to 10\u201325 bits\/min. This limited capacity can be valuable for people whose severe disabilities prevent them from using conventional augmentative communication methods. At the same time, many possible applications of BCI technology, such as neuroprosthesis control, may require higher information transfer rates. Future progress will depend on: recognition that BCI research and development is an interdisciplinary problem, involving neurobiology, psychology, engineering, mathematics, and computer science; identification of those signals, whether evoked potentials, spontaneous rhythms, or neuronal firing rates, that users are best able to control independent of activity in conventional motor output pathways; development of training methods for helping users to gain and maintain that control; delineation of the best algorithms for translating these signals into device commands; attention to the identification and elimination of artifacts such as electromyographic and electro-oculographic activity; adoption of precise and objective procedures for evaluating BCI performance; recognition of the need for long-term as well as short-term assessment of BCI performance; identification of appropriate BCI applications and appropriate matching of applications and users; and attention to factors that affect user acceptance of augmentative technology, including ease of use, cosmesis, and provision of those communication and control capacities that are most important to the user. Development of BCI technology will also benefit from greater emphasis on peer-reviewed research publications and avoidance of the hyperbolic and often misleading media attention that tends to generate unrealistic expectations in the public and skepticism in other researchers. With adequate recognition and effective engagement of all these issues, BCI systems could eventually provide an important new communication and control option for those with motor disabilities and might also give those without disabilities a supplementary control channel or a control channel useful in special circumstances."
    ],
    "c_categories":[
      "Neurophysiology"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.07453,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Research on fault diagnosis of nuclear power first-second circuit based\n  on hierarchical multi-granularity classification network",
    "a_abstract":"The safe and reliable operation of complex electromechanical systems in\nnuclear power plants is crucial for the safe production of nuclear power plants\nand their nuclear power unit. Therefore, accurate and timely fault diagnosis of\nnuclear power systems is of great significance for ensuring the safe and\nreliable operation of nuclear power plants. The existing fault diagnosis\nmethods mainly target a single device or subsystem, making it difficult to\nanalyze the inherent connections and mutual effects between different types of\nfaults at the entire unit level. This article uses the AP1000 full-scale\nsimulator to simulate the important mechanical component failures of some key\nsystems in the primary and secondary circuits of nuclear power units, and\nconstructs a fault dataset. Meanwhile, a hierarchical multi granularity\nclassification fault diagnosis model based on the EfficientNet large model is\nproposed, aiming to achieve hierarchical classification of nuclear power\nfaults. The results indicate that the proposed fault diagnosis model can\neffectively classify faults in different circuits and system components of\nnuclear power units into hierarchical categories. However, the fault dataset in\nthis study was obtained from a simulator, which may introduce additional\ninformation due to parameter redundancy, thereby affecting the diagnostic\nperformance of the model.",
    "explanation":"The existing fault diagnosis methods of power plants mainly target a single device or subsystem, making it difficult to analyze the inherent connections and mutual effects between different types of faults at the entire unit level. The use of EfficientNet for classify faults in different circuits through a simulator.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Review of Research on Condition Assessment of Nuclear Power Plant Equipment Based on Data-Driven"
    ],
    "b_abstract":[
      "The condition assessment of the entire life cycle of nuclear power equipment has a significant impact on improving the safety and economy of nuclear power plants. In the past, operation and maintenance of systems, equipment, and structures of domestic nuclear power plants, mostly relied on the alarm mechanism of equipments, the simple threshold judgments of parameters, or the empirical judgments of engineers. With the implementation of online monitoring system in nuclear power plants, a large number of equipment operation data have been accumulated, and the use of data-driven technology to assess the health of equipment has become the focus of attention in the industry. In this paper, the current situation of the online monitoring system of nuclear power equipment was introduced and the common malfunction of nuclear power equipment was analyzed. The condition assessment of nuclear power equipment were categorized into three major problems (i.e., anomaly detection, life prediction, and fault diagnosis), the situation of research and application were summarized respectively, and the application potential of deep learning technology in this field was emphasized. Based on this, the challenges and possible solutions to the condition assessment of nuclear power plant equipment were further analyzed."
    ],
    "b_categories":[
      "nucl-th"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"
    ],
    "c_abstract":[
      "Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth\/width\/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. \nTo go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 \/ 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at this https URL."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.04775,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Learning dynamical systems from data: Gradient-based dictionary\n  optimization",
    "a_abstract":"The Koopman operator plays a crucial role in analyzing the global behavior of\ndynamical systems. Existing data-driven methods for approximating the Koopman\noperator or discovering the governing equations of the underlying system\ntypically require a fixed set of basis functions, also called dictionary. The\noptimal choice of basis functions is highly problem-dependent and often\nrequires domain knowledge. We present a novel gradient descent-based\noptimization framework for learning suitable and interpretable basis functions\nfrom data and show how it can be used in combination with EDMD, SINDy, and\nPDE-FIND. We illustrate the efficacy of the proposed approach with the aid of\nvarious benchmark problems such as the Ornstein-Uhlenbeck process, Chua's\ncircuit, a nonlinear heat equation, as well as protein-folding data.",
    "explanation":"The optimal choice of basis functions for approximation the Koopman operator is highly problem-dependent and often requires domain knowledge. The paper presents a gradient descent-based optimization framework for learning suitable and interpretable basis function from data.",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "A Data\u2013Driven Approximation of the Koopman Operator: Extending Dynamic Mode Decomposition"
    ],
    "b_abstract":[
      "The Koopman operator is a linear but infinite dimensional operator that\ngoverns the evolution of scalar observables defined on the state space of an\nautonomous dynamical system, and is a powerful tool for the analysis and\ndecomposition of nonlinear dynamical systems. In this manuscript, we present a\ndata driven method for approximating the leading eigenvalues, eigenfunctions,\nand modes of the Koopman operator. The method requires a data set of snapshot\npairs and a dictionary of scalar observables, but does not require explicit\ngoverning equations or interaction with a \"black box\" integrator. We will show\nthat this approach is, in effect, an extension of Dynamic Mode Decomposition\n(DMD), which has been used to approximate the Koopman eigenvalues and modes.\nFurthermore, if the data provided to the method are generated by a Markov\nprocess instead of a deterministic dynamical system, the algorithm approximates\nthe eigenfunctions of the Kolmogorov backward equation, which could be\nconsidered as the \"stochastic Koopman operator\" [1]. Finally, four illustrative\nexamples are presented: two that highlight the quantitative performance of the\nmethod when presented with either deterministic or stochastic data, and two\nthat show potential applications of the Koopman eigenfunctions."
    ],
    "b_categories":[
      "Mathematical Analysis"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b21",
      "b14"
    ],
    "c_title":[
      "Towards Scalable Koopman Operator Learning: Convergence Rates and A Distributed Learning Algorithm",
      "VAMPnets for deep learning of molecular kinetics"
    ],
    "c_abstract":[
      "We propose an alternating optimization algorithm to the nonconvex Koopman operator learning problem for nonlinear dynamic systems. show that proposed will converge a critical point with rate O(1\/T) and $O\\left( {\\frac{1}{{\\log T}}} \\right)$ constant diminishing rates, respectively, under some mild conditions. To cope high dimensional dynamical systems, we present first-ever distributed algorithm. has same convergence properties as centralized learning, in absence of optimal tracker, so long basis functions satisfy set state-based decomposition Numerical experiments are provided complement our theoretical results.",
      "Abstract There is an increasing demand for computing the relevant structures, equilibria, and long-timescale kinetics of biomolecular processes, such as protein-drug binding, from high-throughput molecular dynamics simulations. Current methods employ transformation simulated coordinates into structural features, dimension reduction, clustering dimension-reduced data, estimation a Markov state model or related interconversion rates between structures. This handcrafted approach demands substantial amount modeling expertise, poor decisions at any step will lead to large errors. Here we variational processes (VAMP) develop deep learning framework using neural networks, dubbed VAMPnets. A VAMPnet encodes entire mapping states, thus combining whole data processing pipeline in single end-to-end framework. Our method performs equally better than state-of-the-art provides easily interpretable few-state kinetic models."
    ],
    "c_categories":[
      "cs.LG",
      "eess.SP"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.17971,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Graph Neural Network for Cerebral Blood Flow Prediction With Clinical\n  Datasets",
    "a_abstract":"Accurate prediction of cerebral blood flow is essential for the diagnosis and\ntreatment of cerebrovascular diseases. Traditional computational methods,\nhowever, often incur significant computational costs, limiting their\npracticality in real-time clinical applications. This paper proposes a graph\nneural network (GNN) to predict blood flow and pressure in previously unseen\ncerebral vascular network structures that were not included in training data.\nThe GNN was developed using clinical datasets from patients with stenosis,\nfeaturing complex and abnormal vascular geometries. Additionally, the GNN model\nwas trained on data incorporating a wide range of inflow conditions, vessel\ntopologies, and network connectivities to enhance its generalization\ncapability. The approach achieved Pearson's correlation coefficients of 0.727\nfor pressure and 0.824 for flow rate, with sufficient training data. These\nfindings demonstrate the potential of the GNN for real-time cerebrovascular\ndiagnostics, particularly in handling intricate and pathological vascular\nnetworks.",
    "explanation":"This paper proposes a graph neural network (GNN) to predict blood flow and pressure in previously unseen cerebral vascular network structures that were not included in training data.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Multiscale modeling and simulation of brain blood flow"
    ],
    "b_abstract":[
      "The aim of this work is to present an overview recent advances in multi-scale modeling brain blood flow. In particular, we some approaches that enable the silico study and multi-physics phenomena cerebral vasculature. We discuss formulation continuum atomistic approaches, a consistent framework for their concurrent coupling, list challenges one needs overcome achieving seamless scalable integration heterogeneous numerical solvers. effectiveness proposed demonstrated realistic case involving thrombus formation process taking place on wall patient-specific aneurysm. This highlights ability algorithms resolve important biophysical processes span several spatial temporal scales, potentially yielding new insight into key aspects flow health disease. Finally, open questions emerging topics future research."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Learning Reduced-Order Models for Cardiovascular Simulations with Graph Neural Networks"
    ],
    "c_abstract":[
      "Reduced-order models based on physics are a popular choice in cardiovascular modeling due to their efficiency, but they may experience loss in accuracy when working with anatomies that contain numerous junctions or pathological conditions. We develop one-dimensional reduced-order models that simulate blood flow dynamics using a graph neural network trained on three-dimensional hemodynamic simulation data. Given the initial condition of the system, the network iteratively predicts the pressure and flow rate at the vessel centerline nodes. Our numerical results demonstrate the accuracy and generalizability of our method in physiological geometries comprising a variety of anatomies and boundary conditions. Our findings demonstrate that our approach can achieve errors below 3% for pressure and flow rate, provided there is adequate training data. As a result, our method exhibits superior performance compared to physics-based one-dimensional models while maintaining high efficiency at inference time."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.18141,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Predicting Water Quality using Quantum Machine Learning: The Case of the\n  Umgeni Catchment (U20A) Study Region",
    "a_abstract":"In this study, we consider a real-world application of QML techniques to\nstudy water quality in the U20A region in Durban, South Africa. Specifically,\nwe applied the quantum support vector classifier (QSVC) and quantum neural\nnetwork (QNN), and we showed that the QSVC is easier to implement and yields a\nhigher accuracy. The QSVC models were applied for three kernels: Linear,\npolynomial, and radial basis function (RBF), and it was shown that the\npolynomial and RBF kernels had exactly the same performance. The QNN model was\napplied using different optimizers, learning rates, noise on the circuit\ncomponents, and weight initializations were considered, but the QNN\npersistently ran into the dead neuron problem. Thus, the QNN was compared only\nby accraucy and loss, and it was shown that with the Adam optimizer, the model\nhas the best performance, however, still less than the QSVC.",
    "explanation":"In this study, we consider a real-world application of QML techniques to study water quality in the U20A region in Durban, South Africa.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "Quantum machine learning in chemistry and materials"
    ],
    "b_abstract":[
      "Within the past few years, we have witnessed the rising of quantum machine learning (QML) models which infer electronic properties of molecules and materials, rather than solving approximations to the electronic Schr\u00f6dinger equation. The increasing availability of large quantum mechanics reference datasets has enabled these developments. We review the basic theories and key ingredients of popular QML models such as choice of regressor, data of varying trustworthiness, the role of the representation, and the effect of training set selection. Throughout we emphasize the indispensable role of learning curves when it comes to the comparative assessment of different QML models."
    ],
    "b_categories":[
      "cs.ET"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b26"
    ],
    "c_title":[
      "Durban's water wars, sewage spills, fish kills and blue flag beaches. Durban's Climate Gamble"
    ],
    "c_abstract":[
      "Water is one of the primary barometers of climate change: A rise in sea-levels, flooding, and extreme storms combined with general water stress and more severe and frequent droughts will escalate crises in municipal infrastructure, requiring continual upgrades for water purification, stormwater drainage, and sewage treatment, all of which will dramatically raise the price of water at the retail level. In South Africa, the dry western side will be most adversely affected by droughts (threatening the production of rooibos tea and Cape wines). According to the Academy of Science in South Africa (ASSAf), Durban is also at great risk and will experience higher temperatures and heat stress, volatile rainfall, up to 160 million cubic metres less water each year by 2100, a sea-level rise of up to a metre by 2100 across Durban\u2019s 100 km of developed coastline, lower biodiversity, higher disease levels (especially malaria and cholera), declining agricultural output (a one degree Celsius rise leaves the surrounding region unreliable for the staple maize production), and other economic stresses (ASSAf 2011: 27). Tourism, one of Durban\u2019s main economic engines, will be irreparably harmed. Swimmers and surfers think of Durban\u2019s beachfront as one of the world\u2019s finest in any urban context. After apartheid-era rules that prohibited black people from using the best beaches were lifted at the end of the 1980s, the area stretching from the Blue Lagoon\u2019s Umgeni River to South Beach\u2019s uShaka Marine World\u2013including the immensely popular North Beach area near the main restaurant strip\u2013represented one of South Africa\u2019s most impressive, open and democratic public spaces."
    ],
    "c_categories":[
      "cond-mat.mtrl-sci"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.16349,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Machine learning for cerebral blood vessels' malformations",
    "a_abstract":"Cerebral aneurysms and arteriovenous malformations are life-threatening\nhemodynamic pathologies of the brain. While surgical intervention is often\nessential to prevent fatal outcomes, it carries significant risks both during\nthe procedure and in the postoperative period, making the management of these\nconditions highly challenging. Parameters of cerebral blood flow, routinely\nmonitored during medical interventions, could potentially be utilized in\nmachine learning-assisted protocols for risk assessment and therapeutic\nprognosis. To this end, we developed a linear oscillatory model of blood\nvelocity and pressure for clinical data acquired from neurosurgical operations.\nUsing the method of Sparse Identification of Nonlinear Dynamics (SINDy), the\nparameters of our model can be reconstructed online within milliseconds from a\nshort time series of the hemodynamic variables. The identified parameter values\nenable automated classification of the blood-flow pathologies by means of\nlogistic regression, achieving an accuracy of 73 %. Our results demonstrate the\npotential of this model for both diagnostic and prognostic applications,\nproviding a robust and interpretable framework for assessing cerebral blood\nvessel conditions.",
    "explanation":"Parameters of cerebral blood flow, routinely monitored during medical interventions or with modern noninvasive high-resolution imaging methods, could potentially be utilized in machine learning-assisted protocols for risk assessment and therapeutic prognosis.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Cerebral aneurysms. New Engl. J. Medicine"
    ],
    "b_abstract":[
      "Saccular intracranial aneurysms cause substantial morbidity and mortality. Recently, major changes have occurred in the way we think about and treat this disease. This review discusses the percutaneous endovascular treatment of intracranial aneurysms as compared with surgical intervention. The technological advances and supporting research contributing to this important change in practice patterns are reviewed."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "Data-driven science and engineering: machine learning, dynamical systems, and control"
    ],
    "c_abstract":[
      "\"Data-driven science and engineering: machine learning, dynamical systems, control.\" Contemporary Physics, 60(4), p. 320"
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.19,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"A Unified Platform for At-Home Post-Stroke Rehabilitation Enabled by\n  Wearable Technologies and Artificial Intelligence",
    "a_abstract":"At-home rehabilitation for post-stroke patients presents significant\nchallenges, as continuous, personalized care is often limited outside clinical\nsettings. Additionally, the absence of comprehensive solutions addressing\ndiverse rehabilitation needs in home environments complicates recovery efforts.\nHere, we introduce a smart home platform that integrates wearable sensors,\nambient monitoring, and large language model (LLM)-powered assistance to\nprovide seamless health monitoring and intelligent support. The system\nleverages machine learning enabled plantar pressure arrays for motor recovery\nassessment (94% classification accuracy), a wearable eye-tracking module for\ncognitive evaluation, and ambient sensors for precise smart home control (100%\noperational success, <1 s latency). Additionally, the LLM-powered agent,\nAuto-Care, offers real-time interventions, such as health reminders and\nenvironmental adjustments, enhancing user satisfaction by 29%. This work\nestablishes a fully integrated platform for long-term, personalized\nrehabilitation, offering new possibilities for managing chronic conditions and\nsupporting aging populations.",
    "explanation":"Here, we present a multimodal smart home platform designed for continuous, at-home rehabilitation of post-stroke patients, integrating wearable sensing, ambient monitoring, and adaptive automation.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Addressing disparities in the global epidemiology of stroke"
    ],
    "b_abstract":[
      "Stroke is the second leading cause of death and the third leading cause of disability worldwide. Though the burden of stroke worldwide seems to have declined in the past three decades, much of this effect reflects decreases in high-income countries (HICs). By contrast, the burden of stroke has grown rapidly in low-income and middle-income countries (LMICs), where epidemiological, socioeconomic and demographic shifts have increased the incidence of stroke and other non-communicable diseases. Furthermore, even in HICs, disparities in stroke epidemiology exist along racial, ethnic, socioeconomic and geographical lines. In this Review, we highlight the under-acknowledged disparities in the burden of stroke. We emphasize the shifting global landscape of stroke risk factors, critical gaps in stroke service delivery, and the need for a more granular analysis of the burden of stroke within and between LMICs and HICs to guide context-appropriate capacity-building. Finally, we review strategies for addressing key inequalities in stroke epidemiology, including improvements in epidemiological surveillance and context-specific research efforts in under-resourced regions, development of the global workforce of stroke care providers, expansion of access to preventive and treatment services through mobile and telehealth platforms, and scaling up of evidence-based strategies and policies that target local, national, regional and global stroke disparities."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "Artificial intelligence applications in stroke"
    ],
    "c_abstract":[
      "Management of stroke highly depends on information from imaging studies. Noncontrast computed tomography (CT) and magnetic resonance imaging (MRI) can both be used to distinguish between ischemic and hemorrhagic stroke, which is difficult based on clinical features. Hypodensity on CT and DWI hyperintensity on MRI identifies irreversibly damaged tissue, although the sensitivity of MRI is higher in the acute setting. Angiographic and perfusion imaging sequences can identify a large vessel occlusion and, along with perfusion imaging, can select patients for endovascular therapy. The FLAIR-DWI mismatch yields information about patients with unknown time of onset (including wake-up strokes). Stroke imaging also gives insight into prognosis, with current methods aiming to give a picture of the short-term consequences of successful reperfusion or continued large vessel occlusion. One important caveat about stroke imaging is that it must be done quickly, as faster treatment leads to better outcomes.1 However, most steps in the stroke imaging triage pathway require the presence of human radiologists and neurologists, and this is often the time-limiting step. The expertise required for these tasks may not be available at all sites or at all times. Therefore, there is interest in automated methods for stroke imaging evaluation. Artificial intelligence (AI) is a broad term reflecting the use of computers to perform tasks that humans may find difficult, often in ways that are hard to pinpoint. For example, although humans find high-level computation difficult, calculator technology is not considered AI because we know how to break this down into discrete steps and feel we understand it. However, facial recognition is a task that humans perform well, but an algorithm to identify faces is usually considered AI since we cannot articulate precisely how this is done. Machine learning (ML) is a subset of AI in which algorithms learn from the data itself without explicit programming. ML methods reflect a broad range of statistical techniques ranging from linear regression to more complex methods such as support vector machines and decision trees. ML methods can be further broken into supervised and unsupervised learning, which differ from one another in that the former requires access to gold standard labels although the latter attempts to find the answers implicitly in the data itself. While ML methods have grown more popular over recent years, the advent of a specific supervised ML method based on architectures resembling human neural networks over the past decade has led to a quantum leap in performance.2 This method, called deep learning (DL) because of many multiple internal layers, can be considered a transformative technology. Compared with previous methods that required humans to identify image features, a deep neural network trained on a dataset with known outputs can learn the best features for organizing the data. In this review, we will discuss ML methods applied to stroke imaging with an emphasis on DL applications. We refer to Figure for a graphical overview of the applications discussed in this review."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.1057,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Normative Modeling for AD Diagnosis and Biomarker Identification",
    "a_abstract":"In this paper, we introduce a novel normative modeling approach that\nincorporates focal loss and adversarial autoencoders (FAAE) for Alzheimer's\nDisease (AD) diagnosis and biomarker identification. Our method is an\nend-to-end approach that embeds an adversarial focal loss discriminator within\nthe autoencoder structure, specifically designed to effectively target and\ncapture more complex and challenging cases. We first use the enhanced\nautoencoder to create a normative model based on data from healthy control (HC)\nindividuals. We then apply this model to estimate total and regional\nneuroanatomical deviation in AD patients. Through extensive experiments on the\nOASIS-3 and ADNI datasets, our approach significantly outperforms previous\nstate-of-the-art methods. This advancement not only streamlines the detection\nprocess but also provides a greater insight into the biomarker potential for\nAD. Our code can be found at \\url{https:\/\/github.com\/soz223\/FAAE}.",
    "explanation":"In this paper, we introduce a novel normative modeling ap proach that incorporates focal loss and adversarial autoencoders (FAAE) for Alzheimer\u2019s Disease (AD) diagnosis and biomarker identification",
    "b_id":[
      "b13"
    ],
    "b_title":[
      "Using deep autoencoders to identify abnormal brain structural patterns in neuropsychiatric disorders: A large\u2010scale multi\u2010sample study"
    ],
    "b_abstract":[
      "Machine learning is becoming an increasingly popular approach for investigating spatially distributed and subtle neuroanatomical alterations in brain\u2010based disorders. However, some machine learning models have been criticized for requiring a large number of cases in each experimental group, and for resembling a \u201cblack box\u201d that provides little or no insight into the nature of the data. In this article, we propose an alternative conceptual and practical approach for investigating brain\u2010based disorders which aim to overcome these limitations. We used an artificial neural network known as \u201cdeep autoencoder\u201d to create a normative model using structural magnetic resonance imaging data from 1,113 healthy people. We then used this model to estimate total and regional neuroanatomical deviation in individual patients with schizophrenia and autism spectrum disorder using two independent data sets (n =\u2009263). We report that the model was able to generate different values of total neuroanatomical deviation for each disease under investigation relative to their control group (p <\u2009.005). Furthermore, the model revealed distinct patterns of neuroanatomical deviations for the two diseases, consistent with the existing neuroimaging literature. We conclude that the deep autoencoder provides a flexible and promising framework for assessing total and regional neuroanatomical deviations in neuropsychiatric populations."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "Using normative modelling to detect disease progression in mild cognitive impairment and Alzheimer\u2019s disease in a cross-sectional multi-cohort study"
    ],
    "c_abstract":[
      "Normative modelling is an emerging method for quantifying how individuals deviate from the healthy populational pattern. Several machine learning models have been implemented to develop normative models to investigate brain disorders, including regression, support vector machines and Gaussian process models. With the advance of deep learning technology, the use of deep neural networks has also been proposed. In this study, we assessed normative models based on deep autoencoders using structural neuroimaging data from patients with Alzheimer\u2019s disease (n\u2009=\u2009206) and mild cognitive impairment (n\u2009=\u2009354). We first trained the autoencoder on an independent dataset (UK Biobank dataset) with 11,034 healthy controls. Then, we estimated how each patient deviated from this norm and established which brain regions were associated to this deviation. Finally, we compared the performance of our normative model against traditional classifiers. As expected, we found that patients exhibited deviations according to the severity of their clinical condition. The model identified medial temporal regions, including the hippocampus, and the ventricular system as critical regions for the calculation of the deviation score. Overall, the normative model had comparable cross-cohort generalizability to traditional classifiers. To promote open science, we are making all scripts and the trained models available to the wider research community."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.14474,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Attention-guided Spectrogram Sequence Modeling with CNNs for Music Genre\n  Classification",
    "a_abstract":"Music genre classification is a critical component of music recommendation\nsystems, generation algorithms, and cultural analytics. In this work, we\npresent an innovative model for classifying music genres using attention-based\ntemporal signature modeling. By processing spectrogram sequences through\nConvolutional Neural Networks (CNNs) and multi-head attention layers, our\napproach captures the most temporally significant moments within each piece,\ncrafting a unique \"signature\" for genre identification. This temporal focus not\nonly enhances classification accuracy but also reveals insights into\ngenre-specific characteristics that can be intuitively mapped to listener\nperceptions. Our findings offer potential applications in personalized music\nrecommendation systems by highlighting cross-genre similarities and\ndistinctiveness, aligning closely with human musical intuition. This work\nbridges the gap between technical classification tasks and the nuanced, human\nexperience of genre.",
    "explanation":"In this work, we present an innovative model for classifying music genres using attention based temporal signature modeling. By processing spectrogram sequences through Convolutional Neural Networks (CNNs) and multi-head attention layers, our approach captures the most temporally significant moments within each piece, crafting a unique \u201dsignature\u201d for genre identification",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Convolutional recurrent neural networks for music classification"
    ],
    "b_abstract":[
      "We introduce a convolutional recurrent neural network (CRNN) for music tagging. CRNNs take advantage of networks (CNNs) local feature extraction and temporal summarisation the extracted features. compare CRNN with three CNN structures that have been used tagging while controlling number parameters respect to their performance training time per sample. Overall, we found show strong parameter time, indicating effectiveness its hybrid structure in summarisation."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "A deep representation for invariance and music classification"
    ],
    "c_abstract":[
      "Representations in the auditory cortex might be based on mechanisms similar to visual ventral stream; modules for building invariance transformations and multiple layers compositionality selectivity. In this paper we propose use of such computational extracting invariant discriminative audio representations. Building a theory hierarchical architectures, novel, mid-level representation acoustical signals, using empirical distributions projections set templates their transformations. Under assumption that, by construction, dictionary is composed from classes, samples orbit variance-inducing signal (such as shift scale), resulting signature theoretically guaranteed unique, stable deformations. Modules projection pooling can then constitute deep networks, learning composite We present main theoretical aspects framework unsupervised representations, empirically evaluated music genre classification."
    ],
    "c_categories":[
      "physics.class-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.14975,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Exploring Foundation Models Fine-Tuning for Cytology Classification",
    "a_abstract":"Cytology slides are essential tools in diagnosing and staging cancer, but\ntheir analysis is time-consuming and costly. Foundation models have shown great\npotential to assist in these tasks. In this paper, we explore how existing\nfoundation models can be applied to cytological classification. More\nparticularly, we focus on low-rank adaptation, a parameter-efficient\nfine-tuning method suited to few-shot learning. We evaluated five foundation\nmodels across four cytological classification datasets. Our results demonstrate\nthat fine-tuning the pre-trained backbones with LoRA significantly improves\nmodel performance compared to fine-tuning only the classifier head, achieving\nstate-of-the-art results on both simple and complex classification tasks while\nrequiring fewer data samples.",
    "explanation":"In this paper, we explore how existing foundation models can be applied to cytological classification",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "HiCervix: An Extensive Hierarchical Dataset and Benchmark for Cervical Cytology Classification"
    ],
    "b_abstract":[
      "Cervical cytology is a critical screening strategy for early detection of pre-cancerous and cancerous cervical lesions. The challenge lies in accurately classifying various cell types. Existing automated methods are primarily trained on databases covering narrow range coarse-grained types, which fail to provide comprehensive detailed performance analysis that represents real-world cytopathology conditions. To overcome these limitations, we introduce HiCervix, the most extensive, multi-center dataset currently available public. HiCervix includes 40,229 cells from 4,496 whole slide images, categorized into 29 annotated classes. These classes organized within three-level hierarchical tree capture fine-grained subtype information. exploit semantic correlation inherent this tree, propose HierSwin, vision transformer-based classification network. HierSwin serves as benchmark feature learning both coarse-level fine-level cancer tasks. In our experiments, demonstrated remarkable performance, achieving 92.08% accuracy 82.93% averaged across all three levels. When compared board-certified cytopathologists, achieved high (0.8293 versus 0.7359 accuracy), highlighting its potential clinical applications. This newly released dataset, along with method, poised make substantial impact advancement deep algorithms rapid greatly improve prevention patient outcomes settings."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b17"
    ],
    "c_title":[
      "LoRA: Low-Rank Adaptation of Large Language Models"
    ],
    "c_abstract":[
      "An important paradigm of natural language processing consists large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances fine-tuned each with is prohibitively expensive. We propose Low-Rank Adaptation, LoRA, freezes the pre-trained weights injects trainable rank decomposition matrices into layer Transformer architecture, greatly reducing number parameters for downstream tasks. Compared Adam, LoRA can reduce by 10,000 times GPU memory requirement 3 times. performs on-par better than fine-tuning in quality RoBERTa, DeBERTa, GPT-2, GPT-3, despite having fewer a higher training throughput, and, unlike adapters, no additional inference latency. also provide empirical investigation rank-deficiency adaptation, sheds light efficacy LoRA. release package that facilitates integration PyTorch models our implementations checkpoints GPT-2 at https:\/\/github.com\/microsoft\/LoRA."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.15331,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"GeoScatt-GNN: A Geometric Scattering Transform-Based Graph Neural\n  Network Model for Ames Mutagenicity Prediction",
    "a_abstract":"This paper tackles the pressing challenge of mutagenicity prediction by\nintroducing three ground-breaking approaches. First, it showcases the superior\nperformance of 2D scattering coefficients extracted from molecular images,\ncompared to traditional molecular descriptors. Second, it presents a hybrid\napproach that combines geometric graph scattering (GGS), Graph Isomorphism\nNetworks (GIN), and machine learning models, achieving strong results in\nmutagenicity prediction. Third, it introduces a novel graph neural network\narchitecture, MOLG3-SAGE, which integrates GGS node features into a fully\nconnected graph structure, delivering outstanding predictive accuracy.\nExperimental results on the ZINC dataset demonstrate significant improvements,\nemphasizing the effectiveness of blending 2D and geometric scattering\ntechniques with graph neural networks. This study illustrates the potential of\nGNNs and GGS for mutagenicity prediction, with broad implications for drug\ndiscovery and chemical safety assessment.",
    "explanation":"This study illustrates the potential of GNNs and GGS for mutagenicity prediction, with broad implications for drug discovery and chemical safety assessment",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Improvement of quantitative structure\u2013activity relationship (QSAR) tools for predicting Ames mutagenicity: outcomes of the Ames\/QSAR International Challenge Project"
    ],
    "b_abstract":[
      "The International Conference on Harmonization (ICH) M7 guideline allows the use of in silico approaches for predicting Ames mutagenicity initial assessment impurities pharmaceuticals. This is first international that addresses quantitative structure\u2013activity relationship (QSAR) models lieu actual toxicological studies human health assessment. Therefore, QSAR now require higher predictive power identifying mutagenic chemicals. To increase models, larger experimental datasets from reliable sources are required. Division Genetics and Mutagenesis, National Institute Health Sciences (DGM\/NIHS) Japan recently established a unique proprietary database containing 12140 new chemicals have not been previously used developing models. DGM\/NIHS provided this to vendors validate improve their tools. Ames\/QSAR Challenge Project was initiated 2014 with 12 testing 17 tools against these compounds three phases. We present final results. All were considerably improved by participation project. Most achieved >50% sensitivity (positive prediction among all positives) (accuracy) as high 80%, almost equivalent inter-laboratory reproducibility tests. further tools, accumulation additional test data required well re-evaluation some previous Indeed, Ames-positive or Ames-negative may incorrectly classified because methodological weakness, resulting false-positive false-negative predictions These incorrect hamper source noise development It thus essential establish large benchmark consisting only well-validated results build more accurate"
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Mutagenpred-gcnns: a graph convolutional neural network-based classification model for mutagenicity prediction with data-driven molecular fingerprints"
    ],
    "c_abstract":[
      "An important task in the early stage of drug discovery is the identification of mutagenic compounds. Mutagenicity prediction models that can interpret relationships between toxicological endpoints and compound structures are especially favorable. In this research, we used an advanced graph convolutional neural network (GCNN) architecture to identify the molecular representation and develop predictive models based on these representations. The predictive model based on features extracted by GCNNs can not only predict the mutagenicity of compounds but also identify the structure alerts in compounds. In fivefold cross-validation and external validation, the highest area under the curve was 0.8782 and 0.8382, respectively; the highest accuracy (Q) was 80.98% and 76.63%, respectively; the highest sensitivity was 83.27% and 78.92%, respectively; and the highest specificity was 78.83% and 76.32%, respectively. Additionally, our model also identified some toxicophores, such as aromatic nitro, three-membered heterocycles, quinones, and nitrogen and sulfur mustard. These results indicate that GCNNs could learn the features of mutagens effectively. In summary, we developed a mutagenicity classification model with high predictive performance and interpretability based on a data-driven molecular representation trained through GCNNs."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.03341,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Interpretable Embeddings for Segmentation-Free Single-Cell Analysis in\n  Multiplex Imaging",
    "a_abstract":"Multiplex Imaging (MI) enables the simultaneous visualization of multiple\nbiological markers in separate imaging channels at subcellular resolution,\nproviding valuable insights into cell-type heterogeneity and spatial\norganization. However, current computational pipelines rely on cell\nsegmentation algorithms, which require laborious fine-tuning and can introduce\ndownstream errors due to inaccurate single-cell representations. We propose a\nsegmentation-free deep learning approach that leverages grouped convolutions to\nlearn interpretable embedded features from each imaging channel, enabling\nrobust cell-type identification without manual feature selection. Validated on\nan Imaging Mass Cytometry dataset of 1.8 million cells from neuroblastoma\npatients, our method enables the accurate identification of known cell types,\nshowcasing its scalability and suitability for high-dimensional MI data.",
    "explanation":"Validated on an Imaging Mass Cytometry dataset of 1.8 million cells from neuroblastoma patients.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Highly multiplexed imaging of tumor tissues with subcellular resolution by mass cytometry"
    ],
    "b_abstract":[
      "Mass cytometry enables high-dimensional, single-cell analysis of cell type and state. In mass cytometry, rare earth metals are used as reporters on antibodies. Analysis of metal abundances using the mass cytometer allows determination of marker expression in individual cells. Mass cytometry has previously been applied only to cell suspensions. To gain spatial information, we have coupled immunohistochemical and immunocytochemical methods with high-resolution laser ablation to CyTOF mass cytometry. This approach enables the simultaneous imaging of 32 proteins and protein modifications at subcellular resolution; with the availability of additional isotopes, measurement of over 100 markers will be possible. We applied imaging mass cytometry to human breast cancer samples, allowing delineation of cell subpopulations and cell-cell interactions and highlighting tumor heterogeneity. Imaging mass cytometry complements existing imaging approaches. It will enable basic studies of tissue heterogeneity and function and support the transition of medicine toward individualized molecularly targeted diagnosis and therapies."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "A ConvNet for the 2020s"
    ],
    "c_abstract":[
      "The \"Roaring 20s\" of visual recognition began with the introduction Vision Transformers (ViTs), which quickly superseded ConvNets as state-of-the-art image classification model. A vanilla ViT, on other hand, faces difficulties when applied to general computer vision tasks such object detection and semantic segmentation. It is hierarchical (e.g., Swin Transformers) that reintroduced several ConvNet priors, making practically viable a generic backbone demonstrating remarkable performance wide variety tasks. However, effectiveness hybrid approaches still largely credited intrinsic superiority Transformers, rather than inherent inductive biases convolutions. In this work, we reexamine design spaces test limits what pure can achieve. We gradually \"modernize\" standard ResNet toward Transformer, discover key components contribute difference along way. outcome exploration family models dubbed ConvNeXt. Constructed entirely from modules, ConvNeXts compete favorably in terms accuracy scalability, achieving 87.8% ImageNet top-1 outperforming COCO ADE20K segmentation, while maintaining simplicity efficiency ConvNets."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.11399,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Quantization of Climate Change Impacts on Renewable Energy Generation\n  Capacity: A Super-Resolution Recurrent Diffusion Model",
    "a_abstract":"Driven by global climate change and the ongoing energy transition, the\ncoupling between power supply capabilities and meteorological factors has\nbecome increasingly significant. Over the long term, accurately quantifying the\npower generation capacity of renewable energy under the influence of climate\nchange is essential for the development of sustainable power systems. However,\ndue to interdisciplinary differences in data requirements, climate data often\nlacks the necessary hourly resolution to capture the short-term variability and\nuncertainties of renewable energy resources. To address this limitation, a\nsuper-resolution recurrent diffusion model (SRDM) has been developed to enhance\nthe temporal resolution of climate data and model the short-term uncertainty.\nThe SRDM incorporates a pre-trained decoder and a denoising network, that\ngenerates long-term, high-resolution climate data through a recurrent coupling\nmechanism. The high-resolution climate data is then converted into power value\nusing the mechanism model, enabling the simulation of wind and photovoltaic\n(PV) power generation capacity on future long-term scales. Case studies were\nconducted in the Ejina region of Inner Mongolia, China, using fifth-generation\nreanalysis (ERA5) and coupled model intercomparison project (CMIP6) data under\ntwo climate pathways: SSP126 and SSP585. The results demonstrate that the SRDM\noutperforms existing generative models in generating super-resolution climate\ndata. For the Ejina region, under a high-emission pathway, the annual\nutilization hours of wind power are projected to decrease by 2.82 hours\/year,\nwhile those for PV power are projected to decrease by 0.26 hours\/year.\nFurthermore, the research highlights the estimation biases introduced when\nlow-resolution climate data is used for power conversion.",
    "explanation":"CLimate data often lacks the necessary hourly resolution to capture the shot-term variability and uncertainties of renewable energy resources. TO address this limitation, a super-resolution recurrent diffusiion model (SRDM) has been developed toenhance the temporal resolution of climate data and model the short-term uncertainty.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "Forecasting the inevitable: A review on the impacts of climate change on renewable energy resources"
    ],
    "b_abstract":[
      "Understanding the relationship and quantifying impacts of climate change on energy production is key to meeting our objectives achieving a sustainable future. Here we review current state art methodologies forecast future climate, potential changes in renewable main findings regarding role renewables decarbonisation supply. Most studies used model power equations estimate output. The largest variation estimated was for long-term scenarios, with non-significant variations reported short-term. highest variability found wind followed by hydro, both long-term, overall low solar any period. Additionally, efforts point investments as one pillars reducing fossil fuel dependency. Current knowledge gaps about uncertainty modelling results combined effects resources. Future should focus increasing resolution models improving input data, well assess entire electricity system not concentrate single source, which will aid defining strategies."
    ],
    "b_categories":[
      "Physical Geography"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "High-Resolution Image Synthesis with Latent Diffusion Models"
    ],
    "c_abstract":[
      "By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on data and beyond. Additionally, their formulation allows for guiding mechanism to control generation without retraining. However, since these typically operate directly in pixel space, optimization powerful DMs often consumes hundreds GPU days inference is expensive due evaluations. To enable DM training limited computational resources while retaining quality flexibility, we apply them latent space pretrained autoencoders. In contrast previous work, such representation first time reach near-optimal point between complexity reduction detail preservation, greatly boosting visual fidelity. introducing cross-attention layers model architecture, turn flexible generators general conditioning inputs as text or bounding boxes high-resolution becomes possible convolutional manner. Our (LDMs) new state art scores inpainting class-conditional highly competitive performance various tasks, including unconditional generation, text-to-image synthesis, super-resolution, significantly reducing requirements compared pixel-based DMs."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.18649,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"FITS: Ensuring Safe and Effective Touchscreen Use in Moving Vehicles",
    "a_abstract":"Touch interfaces are replacing physical buttons, dials, and switches in the\nnew generation of cars, aircraft, and vessels. However, vehicle vibrations and\naccelerations perturb finger movements and cause erroneous touchscreen inputs\nby users. Furthermore, unlike physical buttons, touchscreens cannot be operated\nby touch alone and always require users' visual focus. Hence, despite their\nnumerous benefits, touchscreens are not inherently suited for use in vehicles,\nwhich results in an increased risk of accidents. In a recently awarded research\nproject titled \"Right Touch Right Time: Future In-vehicle Touchscreens (FITS)\",\nwe aim to address these problems by developing novel in-vehicle touchscreens\nthat actively predict and correct perturbed finger movements and simulate\nphysical touch interactions with artificial tactile feedback.",
    "explanation":"The paper address the tactile feedback problems by developing novel in-vehicle touchscreens that actively predict and correct perturbed finger movements and simulate physical touch interactions with artificial tactile feedback.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "A Review of Surface Haptics: Enabling Tactile Effects on Touch Surfaces"
    ],
    "b_abstract":[
      "In this article, we review the current technology underlying surface haptics that converts passive touch surfaces to active ones (machine haptics), our perception of tactile stimuli displayed through (human their potential applications (human-machine interaction), and finally, challenges ahead us in making them available commercial systems. This article primarily covers interactions human fingers or hands with surface-haptics displays by focusing on three most popular actuation methods: vibrotactile, electrostatic, ultrasonic."
    ],
    "b_categories":[
      "cs.HC"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Biophysical properties of the human finger for touch comprehension: influences of ageing and gender"
    ],
    "c_abstract":[
      "The human finger plays an extremely important role in tactile perception, but little is known about how age and gender affect its biophysical properties their perception. We combined studies on contact characteristics, mechanical surface topography to understand effects the finger. values obtained regarding characteristics (i.e. adhesive force) were significantly higher for women than men. As Young's modulus E), a significant positive correlation with was observed found be women. A between arithmetic mean of roughness However, inverse effect highlighted have never been reported previously literature. These results open new perspectives understanding weakening perception across ages it differs men"
    ],
    "c_categories":[
      "Biodynamic"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.0656,
    "date":null,
    "fields":[
      "Physics"
    ],
    "a_title":"ElectricityEmissions.jl: A Framework for the Comparison of Carbon\n  Intensity Signals",
    "a_abstract":"An increasing number of individuals, companies and organizations are\ninterested in computing and minimizing the carbon emissions associated with\ntheir real-time electricity consumption. To achieve this, they require a carbon\nsignal, i.e. a metric that defines the real-time carbon intensity of their\nelectricity supply. Unfortunately, in a grid with multiple generation sources\nand multiple consumers, there is no unambiguous way to trace electricity from\nsource to sink. This makes it hard to define an appropriate signal, leading to\na raging discussion about how to best quantify the carbon footprint of\nelectricity.\n  This paper seeks to inform the discussion about which carbon signal is better\nor more suitable for two important use cases, namely carbon-informed load\nshifting and carbon accounting. We do this by developing a new software package\nElectricityEmissions$.$jl, that computes several established and newly proposed\ncarbon emission metrics for standard electric grid test cases. We also\ndemonstrate how the package can be used to investigate the effects of using\nthese metrics to guide load shifting. Our results affirm previous research,\nwhich showed that the choice of carbon emission metric has significant impact\non shifting results and associated carbon emission reductions. In addition, we\ndemonstrate the impact of load shifting on both the consumers that perform the\nshifting and consumers that do not. Disconcertingly, we observe that shifting\naccording to common metrics such as average carbon emissions can reduce the\namount of emissions allocated to data center, but cause an increase in the\ntotal emissions of the system.",
    "explanation":"The paper proposes a software package that computes several established and newly proposed carbon emission metrics for standard electric grid test cases.",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Tracing Power With Circuit Theory"
    ],
    "b_abstract":[
      "Power tracing is the task of disaggregating power injection a generator (or load) into sum constituent components that can unambiguously be attributed to loads (generators) and losses. Applications range broad spectrum of: transmission services pricing, loss allocation in distribution networks, fixed-cost allocation, modelling bilateral transactions, financial storage rights. This paper develops an analytical approach leveraging elementary circuit laws. The method rigorous from system-theoretic vantage point, it yields unambiguous results are consistent with constitutive principles describe steady-state behaviour networks. Moreover, implemented limited computational burden, applies networks arbitrary topologies, preserves coupling between activeand reactive-power injections. Numerical experiments indicate given solved power-flow solution, disaggregations computed for test system 2383 buses, 327 generators, 2056 4.34 s on personal computer, hence establishing scalability. Furthermore, applications demonstrated case studies focused quantifying impact distributed generation extracting nodal contributions respectively."
    ],
    "b_categories":[
      "Digital Circuits"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Carbon-Aware Optimal Power Flow"
    ],
    "c_abstract":[
      "To facilitate effective decarbonization of the electric power sector, this paper introduces generic Carbon-aware Optimal Power Flow (C-OPF) method for system decision-making that considers demand-side carbon accounting and emission management. Built upon classic optimal flow (OPF) model, C-OPF incorporates equations constraints, as well carbon-related objectives, to jointly optimize flow. In particular, establishes invertibility matrix proposes modeling linearization techniques address issues undetermined directions bilinear terms in model. Additionally, two novel models, together with schemes, energy storage systems are developed integrated into Numerical simulations demonstrate characteristics effectiveness method, comparison OPF solutions."
    ],
    "c_categories":[
      "physics.soc-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.05443,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Mathematics and Statistics"
    ],
    "a_title":"ClusterGraph: a new tool for visualization and compression of\n  multidimensional data",
    "a_abstract":"Understanding the global organization of complicated and high dimensional\ndata is of primary interest for many branches of applied sciences. It is\ntypically achieved by applying dimensionality reduction techniques mapping the\nconsidered data into lower dimensional space. This family of methods, while\npreserving local structures and features, often misses the global structure of\nthe dataset. Clustering techniques are another class of methods operating on\nthe data in the ambient space. They group together points that are similar\naccording to a fixed similarity criteria, however unlike dimensionality\nreduction techniques, they do not provide information about the global\norganization of the data. Leveraging ideas from Topological Data Analysis, in\nthis paper we provide an additional layer on the output of any clustering\nalgorithm. Such data structure, ClusterGraph, provides information about the\nglobal layout of clusters, obtained from the considered clustering algorithm.\nAppropriate measures are provided to assess the quality and usefulness of the\nobtained representation. Subsequently the ClusterGraph, possibly with an\nappropriate structure--preserving simplification, can be visualized and used in\nsynergy with state of the art exploratory data analysis techniques.",
    "explanation":"Understanding the global organization of complicated and high dimensional data is of primary interest for many branches of applied sciences. It is typically\nachieved by applying dimensionality reduction techniques mapping the considered data into lower dimensional space.\nThe paper proposes ClusterGraph, obtained through clustering algorithm, to be use in synergy with state of the art exploratory data analysis techniques.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Topological Methods for the Analysis of High Dimensional Data Sets and 3D Object Recognition. The Eurographics Association"
    ],
    "b_abstract":[
      "We present a computational method for extracting simple descriptions of high dimensional data sets in the form of simplicial complexes. Our method, called Mapper, is based on the idea of partial clustering of the data guided by a set of functions defined on the data. The proposed method is not dependent on any particular clustering algorithm, i.e. any clustering algorithm may be used with Mapper. We implement this method and present a few sample applications in which simple descriptions of the data present important information about its structure."
    ],
    "b_categories":[
      "cs.DC"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "A Global Geometric Framework for Nonlinear Dimensionality Reduction"
    ],
    "c_abstract":[
      "Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem dimensionality reduction: finding meaningful low-dimensional structures hidden in their observations. The brain confronts same everyday perception, extracting from its sensory inputs\u201430,000 auditory nerve fibers 106 optic fibers\u2014a manageably small number perceptually relevant features. Here we describe an approach to solving reduction problems that uses easily measured local metric information learn underlying geometry a data set. Unlike classical techniques principal component analysis (PCA) and multidimensional scaling (MDS), our is capable discovering nonlinear degrees freedom underlie complex natural observations, handwriting images face under different viewing conditions. In contrast previous algorithms for reduction, ours efficiently computes globally optimal solution, and, important class manifolds, guaranteed converge asymptotically true structure."
    ],
    "c_categories":[
      "math.ST"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.04992,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Which bits went where? Past and future transfer entropy decomposition\n  with the information bottleneck",
    "a_abstract":"Whether the system under study is a shoal of fish, a collection of neurons,\nor a set of interacting atmospheric and oceanic processes, transfer entropy\nmeasures the flow of information between time series and can detect possible\ncausal relationships. Much like mutual information, transfer entropy is\ngenerally reported as a single value summarizing an amount of shared variation,\nyet a more fine-grained accounting might illuminate much about the processes\nunder study. Here we propose to decompose transfer entropy and localize the\nbits of variation on both sides of information flow: that of the originating\nprocess's past and that of the receiving process's future. We employ the\ninformation bottleneck (IB) to compress the time series and identify the\ntransferred entropy. We apply our method to decompose the transfer entropy in\nseveral synthetic recurrent processes and an experimental mouse dataset of\nconcurrent behavioral and neural activity. Our approach highlights the nuanced\ndynamics within information flow, laying a foundation for future explorations\ninto the intricate interplay of temporal processes in complex systems.",
    "explanation":"Much like mutual information, transfer entropy is generally reported as a single\nvalue summarizing an amount of shared variation, yet a more fine-grained accounting might illuminate much about the processes under study. The paper propose to decompose transfer entropy and localize the bits of variation on both sides of information flow.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Transfer Entropy Bottleneck: Learning Sequence to Sequence Information Transfer"
    ],
    "b_abstract":[
      "When presented with a data stream of two statistically dependent variables, predicting the future one variables (the target stream) can benefit from information about both its history and other variable source stream). For example, fluctuations in temperature at weather station be predicted using temperatures barometric readings. However, challenge when modelling such is that it easy for neural network to rely on greatest joint correlations within stream, which may ignore crucial but small transfer stream. As well, there are often situations where have previously been modelled independently would useful use model inform new model. Here, we develop an bottleneck approach conditional learning streams data. Our method, call Transfer Entropy Bottleneck (TEB), allows learn bottlenecks directed transferred variable, while quantifying this such, TEB provides order make predictions them."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Symbolic Transfer Entropy"
    ],
    "c_abstract":[
      "We propose to estimate transfer entropy using a technique of symbolization. demonstrate numerically that symbolic is robust and computationally fast method quantify the dominating direction information flow between time series from structurally identical nonidentical coupled systems. Analyzing multiday, multichannel electroencephalographic recordings 15 epilepsy patients our approach allowed us reliably identify hemisphere containing epileptic focus without observing actual seizure activity."
    ],
    "c_categories":[
      "physics.data-an"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.06447,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Multi-Parameter Molecular MRI Quantification using Physics-Informed\n  Self-Supervised Learning",
    "a_abstract":"Biophysical model fitting plays a key role in obtaining quantitative\nparameters from physiological signals and images. However, the model complexity\nfor molecular magnetic resonance imaging (MRI) often translates into excessive\ncomputation time, which makes clinical use impractical. Here, we present a\ngeneric computational approach for solving the parameter extraction inverse\nproblem posed by ordinary differential equation (ODE) modeling coupled with\nexperimental measurement of the system dynamics. This is achieved by\nformulating a numerical ODE solver to function as a step-wise analytical one,\nthereby making it compatible with automatic differentiation-based optimization.\nThis enables efficient gradient-based model fitting, and provides a new\napproach to parameter quantification based on self-supervised learning from a\nsingle data observation. The neural-network-based train-by-fit pipeline was\nused to quantify semisolid magnetization transfer (MT) and chemical exchange\nsaturation transfer (CEST) amide proton exchange parameters in the human brain,\nin an in-vivo molecular MRI study (n=4). The entire pipeline of the first whole\nbrain quantification was completed in 18.3$\\pm$8.3 minutes, which is an\norder-of-magnitude faster than comparable alternatives. Reusing the\nsingle-subject-trained network for inference in new subjects took 1.0$\\pm$0.2\ns, to provide results in agreement with literature values and scan-specific fit\nresults (Pearson's r>0.98, p<0.0001).",
    "explanation":"The model complexity for molecular magnetic resonance imaging (MRI) often translates into excessive computation time, which makes clinical use impractical. Here, we present a generic computational approach for solving the parameter extraction inverse problem posed by ordinary differential equation (ODE) modeling coupled with experimental measurement of the system dynamics. This is achieved by formulating a numerical ODE solver to function as a step-wise analytical one, thereby making it compatible with automatic differentiation-based optimization. This enables efficient gradient-based model fitting, and provides a new approach to parameter quantification based on self-supervised learning from a single data observation.",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "A deep learning approach for magnetization transfer contrast MR fingerprinting and chemical exchange saturation transfer imaging"
    ],
    "b_abstract":[
      "Semisolid magnetization transfer contrast (MTC) and chemical exchange saturation (CEST) MRI based on MT phenomenon have shown potential to evaluate brain development, neurological, psychiatric, neurodegenerative diseases. However, a qualitative ratio (MTR) metric commonly used in conventional MTC imaging is limited the assessment of quantitative semisolid macromolecular proton rates concentrations. In addition, CEST signals measured by MTR asymmetry analysis are unavoidably contaminated upfield nuclear Overhauser enhancement (NOE) mobile macromolecules. To address these issues, we developed an MTC-MR fingerprinting (MTC-MRF) technique quantify tissue parameters, which further allows estimation accurate at certain frequency offset. A pseudorandomized RF scheme was generate unique signal evolutions for different tissues supervised deep neural network designed extract properties from MTC-MRF signals. Through detailed Bloch equation-based digital phantom vivo studies, demonstrated that can characteristics with high accuracy computational efficiency, compared equation fitting approach, provide baseline reference NOE imaging. For validation, images were synthesized using parameters estimated deep-learning method experimentally acquired as standard. The proposed framework 3D MTC, CEST, human within clinically acceptable scan time."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Magnetic resonance fingerprinting"
    ],
    "c_abstract":[
      "Magnetic Resonance Fingerprinting (MRF) is a new approach to quantitative magnetic resonance imaging that allows simultaneous measurement of multiple tissue properties in a single, time-efficient acquisition. The ability to reproducibly and quantitatively measure tissue properties could enable more objective tissue diagnosis, comparisons of scans acquired at different locations and time points, longitudinal follow-up of individual patients and development of imaging biomarkers. This review provides a general overview of MRF technology, current preclinical and clinical applications and potential future directions. MRF has been initially evaluated in brain, prostate, liver, cardiac, musculoskeletal imaging, and measurement of perfusion and microvascular properties through MR vascular fingerprinting."
    ],
    "c_categories":[
      "nucl-th"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.10822,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"A Data-Efficient Sequential Learning Framework for Melt Pool Defect\n  Classification in Laser Powder Bed Fusion",
    "a_abstract":"Ensuring the quality and reliability of Metal Additive Manufacturing (MAM)\ncomponents is crucial, especially in the Laser Powder Bed Fusion (L-PBF)\nprocess, where melt pool defects such as keyhole, balling, and lack of fusion\ncan significantly compromise structural integrity. This study presents SL-RF+\n(Sequentially Learned Random Forest with Enhanced Sampling), a novel Sequential\nLearning (SL) framework for melt pool defect classification designed to\nmaximize data efficiency and model accuracy in data-scarce environments. SL-RF+\nutilizes RF classifier combined with Least Confidence Sampling (LCS) and Sobol\nsequence-based synthetic sampling to iteratively select the most informative\nsamples to learn from, thereby refining the model's decision boundaries with\nminimal labeled data. Results show that SL-RF+ outperformed traditional machine\nlearning models across key performance metrics, including accuracy, precision,\nrecall, and F1 score, demonstrating significant robustness in identifying melt\npool defects with limited data. This framework efficiently captures complex\ndefect patterns by focusing on high-uncertainty regions in the process\nparameter space, ultimately achieving superior classification performance\nwithout the need for extensive labeled datasets. While this study utilizes\npre-existing experimental data, SL-RF+ shows strong potential for real-world\napplications in pure sequential learning settings, where data is acquired and\nlabeled incrementally, mitigating the high costs and time constraints of sample\nacquisition.",
    "explanation":"Ensuring the quality and reliability of Metal Additive Manufacturing (MAM) components is crucial, especially in the Laser Powder Bed Fusion (L-PBF) process, where melt pool defects such as keyhole, balling, and lack of fusion can significantly compromise structural integrity. This study presents SL-RF+ (Sequentially Learned Random Forest with Enhanced Sampling), a novel Sequential Learning (SL) framework for melt pool defect classification designed to maximize data efficiency and model accuracy in data-scarce environments.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Additive manufacturing and sustainability: an exploratory study of the advantages and challenges"
    ],
    "b_abstract":[
      "The emergence of advanced manufacturing technologies, coupled with consumer demands for more customised products and services, are causing shifts in the scale distribution manufacturing. In this paper, consideration is given to role one such process technology: additive consequences adopting novel production technology on industrial sustainability not well understood exploratory study draws publically available data provide insights into impacts sustainability. Benefits found exist across product material life cycles through redesign, improvements input processing, make-to-order component manufacturing, closing loop. As an immature technology, there substantial challenges these benefits being realised at each stage cycle. This paper summarises advantages challenges, discusses implications terms sources innovation, business models, configuration value chains."
    ],
    "b_categories":[
      "cond-mat.mtrl-sci"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Machine learning in additive manufacturing: State-of-the-art and perspectives"
    ],
    "c_abstract":[
      "Additive manufacturing (AM) has emerged as a disruptive digital manufacturing technology. However, its broad adoption in industry is still hindered by high entry barriers of design for additive manufacturing (DfAM), limited materials library, various processing defects, and inconsistent product quality. In recent years, machine learning (ML) has gained increasing attention in AM due to its unprecedented performance in data tasks such as classification, regression and clustering. This article provides a comprehensive review on the state-of-the-art of ML applications in a variety of AM domains. In the DfAM, ML can be leveraged to output new high-performance metamaterials and optimized topological designs. In AM processing, contemporary ML algorithms can help to optimize process parameters, and conduct examination of powder spreading and in-process defect monitoring. On the production of AM, ML is able to assist practitioners in pre-manufacturing planning, and product quality assessment and control. Moreover, there has been an increasing concern about data security in AM as data breaches could occur with the aid of ML techniques. Lastly, it concludes with a section summarizing the main findings from the literature and providing perspectives on some selected interesting applications of ML in research and development of AM."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.04323,
    "date":null,
    "fields":[
      "Physics",
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Efficient Symmetry-Aware Materials Generation via Hierarchical\n  Generative Flow Networks",
    "a_abstract":"Discovering new solid-state materials requires rapidly exploring the vast\nspace of crystal structures and locating stable regions. Generating stable\nmaterials with desired properties and compositions is extremely difficult as we\nsearch for very small isolated pockets in the exponentially many possibilities,\nconsidering elements from the periodic table and their 3D arrangements in\ncrystal lattices. Materials discovery necessitates both optimized solution\nstructures and diversity in the generated material structures. Existing methods\nstruggle to explore large material spaces and generate diverse samples with\ndesired properties and requirements. We propose the Symmetry-aware Hierarchical\nArchitecture for Flow-based Traversal (SHAFT), a novel generative model\nemploying a hierarchical exploration strategy to efficiently exploit the\nsymmetry of the materials space to generate crystal structures given desired\nproperties. In particular, our model decomposes the exponentially large\nmaterials space into a hierarchy of subspaces consisting of symmetric space\ngroups, lattice parameters, and atoms. We demonstrate that SHAFT significantly\noutperforms state-of-the-art iterative generative methods, such as Generative\nFlow Networks (GFlowNets) and Crystal Diffusion Variational AutoEncoders\n(CDVAE), in crystal structure generation tasks, achieving higher validity,\ndiversity, and stability of generated structures optimized for target\nproperties and requirements.",
    "explanation":"Materials discovery necessitates both optimized solution structures and diversity in the generated material structures. We propose the Symmetry-aware\nHierarchical Architecture for Flow-based Traversal (SHAFT),a novel generative model employing a hierarchical exploration strategy to efficiently exploit the symmetry of the materials space to generate crystal structures given desired properties.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation"
    ],
    "b_abstract":[
      "This paper is about the problem of learning a stochastic policy for generating an object (like molecular graph) from sequence actions, such that probability proportional to given positive reward object. Whereas standard return maximization tends converge single return-maximizing sequence, there are cases where we would like sample diverse set high-return solutions. These arise, example, in black-box function optimization when few rounds possible, each with large batches queries, should be diverse, e.g., design new molecules. One can also see this as approximately converting energy generative distribution. While MCMC methods achieve that, they expensive and generally only perform local exploration. Instead, training amortizes cost search during yields fast generation. Using insights Temporal Difference learning, propose GFlowNet, based on view process flow network, making it possible handle tricky case different trajectories yield same final state, many ways sequentially add atoms generate some graph. We cast convert consistency equations into objective, akin casting Bellman methods. prove any global minimum proposed objectives which samples desired distribution, demonstrate improved performance diversity GFlowNet simple domain modes function, molecule synthesis task."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals"
    ],
    "c_abstract":[
      "Graph networks are a new machine learning (ML) paradigm that supports both relational reasoning and combinatorial generalization. Here, we develop universal MatErials Network (MEGNet) models for accurate property prediction in molecules crystals. We demonstrate the MEGNet outperform prior ML such as SchNet 11 out of 13 properties QM9 molecule data set. Similarly, show trained on \u223c60 000 crystals Materials Project substantially formation energies, band gaps, elastic moduli crystals, achieving better than density functional theory accuracy over much larger present two strategies to address limitations common materials science chemistry. First, physically intuitive approach unify four separate molecular internal energy at 0 K room temperature, enthalpy, Gibbs free into single model by incorporating pressure, entropy global state inputs. Second, learned element embeddings encode periodic chemical trends can be transfer-learned from set (formation energies) improve with smaller amounts (band gaps moduli)."
    ],
    "c_categories":[
      "cond-mat.mtrl-sci"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.2062,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Construction and optimization of health behavior prediction model for   the elderly in smart elderly care",
    "a_abstract":"With the intensification of global aging, health management of the elderly has become a focus of social attention. This study designs and implements a smart elderly care service model to address issues such as data diversity, health status complexity, long-term dependence and data loss, sudden changes in behavior, and data privacy in the prediction of health behaviors of the elderly. The model achieves accurate prediction and dynamic management of health behaviors of the elderly through modules such as multimodal data fusion, data loss processing, nonlinear prediction, emergency detection, and privacy protection. In the experimental design, based on multi-source data sets and market research results, the model demonstrates excellent performance in health behavior prediction, emergency detection, and personalized services. The experimental results show that the model can effectively improve the accuracy and robustness of health behavior prediction and meet the actual application needs in the field of smart elderly care. In the future, with the integration of more data and further optimization of technology, the model will provide more powerful technical support for smart elderly care services.",
    "explanation":"This study designs and implements a smart elderly care service model to\naddress issues such as data diversity, health status complexity, long-term dependence and data loss, sudden changes in behavior, and data privacy in the prediction of health behaviors of the elderly. The model achieves accurate prediction and dynamic management of health behaviors of the elderly through modules such as multimodal data fusion, data loss processing, nonlinear prediction, emergency detection, and privacy protection.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Artificial intelligence in elderly healthcare: A scoping review"
    ],
    "b_abstract":[
      "The ageing population has led to a surge in the adoption of artificial intelligence (AI) technologies in elderly healthcare worldwide. However, in the advancement of AI technologies, there is currently a lack of clarity about the types and roles of AI technologies in elderly healthcare. This scoping review aimed to provide a comprehensive overview of AI technologies in elderly healthcare by exploring the types of AI technologies employed, and identifying their roles in elderly healthcare based on existing studies. A total of 10 databases were searched for this review, from January 1 2000 to July 31 2022. Based on the inclusion criteria, 105 studies were included. The AI devices utilized in elderly healthcare were summarised as robots, exoskeleton devices, intelligent homes, AI-enabled health smart applications and wearables, voice-activated devices, and virtual reality. Five roles of AI technologies were identified: rehabilitation therapists, emotional supporters, social facilitators, supervisors, and cognitive promoters. Results showed that the impact of AI technologies on elderly healthcare is promising and that AI technologies are capable of satisfying the unmet care needs of older adults and demonstrating great potential in its further development in this area. More well-designed randomised controlled trials are needed in the future to validate the roles of AI technologies in elderly healthcare."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Digital health platforms for the elderly? Key adoption and usage barriers and ways to address them"
    ],
    "c_abstract":[
      "Digital healthcare platforms (DHPs) represent a relatively new phenomenon that could provide valuable complement to physical primary care \u2013 for example, by reducing costs, improving access healthcare, and allowing patient monitoring. However, such are mainly used today the younger generations, which creates \"digital divide\" between elderly. This article aims identify: i) perceived key barriers inhibit adoption usage of DHPs elderly, ii) what DHP providers can do facilitate increased The draws on qualitative interviews with elderly complementary process data from major Swedish DHP. We find perceives two initial DHPs: negative attitudes technology anxiety one barrier affecting both lack trust. analysis also identifies multiple development suggestions improvement better accommodate needs including application tailored education activities. an integrated framework outlining ways address them. In so doing, we contribute literature mHealth in healthcare."
    ],
    "c_categories":[
      "Healthcare"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.16896,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Enhancing Fluorescence Lifetime Parameter Estimation Accuracy with\n  Differential Transformer Based Deep Learning Model Incorporating Pixelwise\n  Instrument Response Function",
    "a_abstract":"Fluorescence Lifetime Imaging (FLI) is a critical molecular imaging modality\nthat provides unique information about the tissue microenvironment, which is\ninvaluable for biomedical applications. FLI operates by acquiring and analyzing\nphoton time-of-arrival histograms to extract quantitative parameters associated\nwith temporal fluorescence decay. These histograms are influenced by the\nintrinsic properties of the fluorophore, instrument parameters, time-of-flight\ndistributions associated with pixel-wise variations in the topographic and\noptical characteristics of the sample. Recent advancements in Deep Learning\n(DL) have enabled improved fluorescence lifetime parameter estimation. However,\nexisting models are primarily designed for planar surface samples, limiting\ntheir applicability in translational scenarios involving complex surface\nprofiles, such as \\textit{in-vivo} whole-animal or imaged guided surgical\napplications. To address this limitation, we present MFliNet (Macroscopic FLI\nNetwork), a novel DL architecture that integrates the Instrument Response\nFunction (IRF) as an additional input alongside experimental photon\ntime-of-arrival histograms. Leveraging the capabilities of a Differential\nTransformer encoder-decoder architecture, MFliNet effectively focuses on\ncritical input features, such as variations in photon time-of-arrival\ndistributions. We evaluate MFliNet using rigorously designed tissue-mimicking\nphantoms and preclinical in-vivo cancer xenograft models. Our results\ndemonstrate the model's robustness and suitability for complex macroscopic FLI\napplications, offering new opportunities for advanced biomedical imaging in\ndiverse and challenging settings.",
    "explanation":"Recent advancements in Deep Learning (DL) have enabled improved fluorescence lifetime parameter estimation",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Characterization of fluorescence lifetime of organic fluorophores for molecular imaging in the shortwave infrared window"
    ],
    "b_abstract":[
      "SignificanceFluorescence lifetime imaging in the shortwave infrared (SWIR) is expected to enable high-resolution multiplexed molecular highly scattering tissue.AimTo characterize brightness and fluorescence of commercially available organic SWIR fluorophores benchmark them against tail emission conventional NIR-excited probes.ApproachCharacterization was performed through our established time-domain mesoscopic tomography system integrated around a time-correlated single-photon counting-single-photon avalanche diode array. Brightness were measured for NIR probes >1000 nm. Simultaneous probe then assess their potential studies.ResultsThe outperformed while mean lifetimes extremely short. The phantom study demonstrated feasibility multiplexing window with both probes.ConclusionsLong-tail Fluorescence readily detectable window, where showed shorter compared probes. We demonstrate which paves way vivo studies intact tissues at improved resolution."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b27"
    ],
    "c_title":[
      "Fast fit-free analysis of fluorescence lifetime imaging via deep learning"
    ],
    "c_abstract":[
      "Fluorescence lifetime imaging (FLI) provides unique quantitative information in biomedical and molecular biology studies but relies on complex data-fitting techniques to derive the quantities of interest. Herein, we propose a fit-free approach FLI image formation that is based deep learning (DL) quantify fluorescence decays simultaneously over whole at fast speeds. We report neural network (DNN) architecture, named (FLI-Net) designed trained for different classes experiments, including visible near-infrared (NIR) microscopy (FLIM) NIR gated macroscopy (MFLI). FLI-Net outputs quantitatively spatially resolved lifetime-based parameters are typically employed field. validate utility framework by performing microscopic preclinical across spectra, as well 2 main data acquisition technologies. These results demonstrate suited accurately lifetimes cells and, real time, intact animals without any parameter settings. Hence, paves way reproducible unprecedented speeds, improved dissemination impact many important applications ranging from fundamental discoveries cellular clinical translation."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.16961,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Glo-In-One-v2: Holistic Identification of Glomerular Cells, Tissues, and\n  Lesions in Human and Mouse Histopathology",
    "a_abstract":"Segmenting glomerular intraglomerular tissue and lesions traditionally\ndepends on detailed morphological evaluations by expert nephropathologists, a\nlabor-intensive process susceptible to interobserver variability. Our group\npreviously developed the Glo-In-One toolkit for integrated detection and\nsegmentation of glomeruli. In this study, we leverage the Glo-In-One toolkit to\nversion 2 with fine-grained segmentation capabilities, curating 14 distinct\nlabels for tissue regions, cells, and lesions across a dataset of 23,529\nannotated glomeruli across human and mouse histopathology data. To our\nknowledge, this dataset is among the largest of its kind to date.In this study,\nwe present a single dynamic head deep learning architecture designed to segment\n14 classes within partially labeled images of human and mouse pathology data.\nOur model was trained using a training set derived from 368 annotated kidney\nwhole-slide images (WSIs) to identify 5 key intraglomerular tissues covering\nBowman's capsule, glomerular tuft, mesangium, mesangial cells, and podocytes.\nAdditionally, the network segments 9 glomerular lesion classes including\nadhesion, capsular drop, global sclerosis, hyalinosis, mesangial lysis,\nmicroaneurysm, nodular sclerosis, mesangial expansion, and segmental sclerosis.\nThe glomerulus segmentation model achieved a decent performance compared with\nbaselines, and achieved a 76.5 % average Dice Similarity Coefficient (DSC).\nAdditional, transfer learning from rodent to human for glomerular lesion\nsegmentation model has enhanced the average segmentation accuracy across\ndifferent types of lesions by more than 3 %, as measured by Dice scores. The\nGlo-In-One-v2 model and trained weight have been made publicly available at\nhttps: \/\/github.com\/hrlblab\/Glo-In-One_v2.",
    "explanation":"In this study, we present a single dynamic head deep learning architecture designed to segment 14 classes within partially labeled images of human and mouse pathology data",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Pathology image analysis using segmentation deep learning algorithms"
    ],
    "b_abstract":[
      "With the rapid development of image scanning techniques and visualization software, whole slide imaging (WSI) is becoming a routine diagnostic method. Accelerating clinical diagnosis from pathology images and automating image analysis efficiently and accurately remain significant challenges. Recently, deep learning algorithms have shown great promise in pathology image analysis, such as in tumor region identification, metastasis detection, and patient prognosis. Many machine learning algorithms, including convolutional neural networks, have been proposed to automatically segment pathology images. Among these algorithms, segmentation deep learning algorithms such as fully convolutional networks stand out for their accuracy, computational efficiency, and generalizability. Thus, deep learning\u2013based pathology image segmentation has become an important tool in WSI analysis. In this review, the pathology image segmentation process using deep learning algorithms is described in detail. The goals are to provide quick guidance for implementing deep learning into pathology image analysis and to provide some potential ways of further improving segmentation performance. Although there have been previous reviews on using machine learning methods in digital pathology image analysis, this is the first in-depth review of the applications of deep learning algorithms for segmentation in WSI analysis."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "Comparative gene expression profiles of intestinal transporters in mice, rats and humans"
    ],
    "c_abstract":[
      "We have studied gene expression profiles of intestinal transporters in model animals and humans. Total RNA was isolated from duodenum and the mRNA expression was measured using Affymetrix GeneChip oligonucleotide arrays. Detected genes from the intestine of mice, rats, and humans were about 60% of 22,690 sequences, 40% of 8739, and 47% of 12,559, respectively. A total of 86 genes involving transporters expressed in mice, 50 genes in rats, and 61 genes in humans were detected. Mice exhibited abundant mRNA expressions for peptide transporter HPT1, amino acid transporters CSNU3, CT1 and ASC1, nucleoside transporter CNT2, organic cation transporter SFXN1, organic anion transporter NBC3, glucose transporter SGLT1, and fatty acid transporters FABP1 and FABP2. Rats showed high expression profiles of peptide transporter PEPT1, amino acid transporters CSNU1 and 4F2HC, nucleoside transporter CNT2, organic cation transporter OCT5, organic anion transporter SDCT1, glucose transporter GLUT2 and GLUT5, and folate carrier FOLT. In humans, the highly expressed genes were peptide transporter HPT1, amino acid transporters LAT3, 4F2HC and PROT, nucleoside transporter CNT2, organic cation transporter OCTN2, organic anion transporters NADC1, NBC1 and SBC2, glucose transporters SGLT1 and GLUT5, multidrug resistance-associated protein RHO12, fatty acid transporters FABP1 and FABP2, and phosphate carrier PHC. Overall these data reveal diverse transcriptomic profiles for intestinal transporters among these species. Therefore, this transcriptional data may lead to more effective use of the laboratory animals as a model for oral drug development."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.02083,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "a_title":"Implementing An Artificial Quantum Perceptron",
    "a_abstract":"A Perceptron is a fundamental building block of a neural network. The\nflexibility and scalability of perceptron make it ubiquitous in building\nintelligent systems. Studies have shown the efficacy of a single neuron in\nmaking intelligent decisions. Here, we examined and compared two perceptrons\nwith distinct mechanisms, and developed a quantum version of one of those\nperceptrons. As a part of this modeling, we implemented the quantum circuit for\nan artificial perception, generated a dataset, and simulated the training.\nThrough these experiments, we show that there is an exponential growth\nadvantage and test different qubit versions. Our findings show that this\nquantum model of an individual perceptron can be used as a pattern classifier.\nFor the second type of model, we provide an understanding to design and\nsimulate a spike-dependent quantum perceptron. Our code is available at\n\\url{https:\/\/github.com\/ashutosh1919\/quantum-perceptron}",
    "explanation":"Studies have shown the efficacy of a single neuron in making intelligent decisions. Here, we examined and compared two perceptrons with distinct mechanisms, and developed a quantum version of one of those perceptrons",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Learning internal representations by back-propagating errors"
    ],
    "b_abstract":[
      "We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal \u2018hidden\u2019 units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "Quantum algorithms for supervised and unsupervised machine learning"
    ],
    "c_abstract":[
      "Machine-learning tasks frequently involve problems of manipulating and classifying large numbers vectors in high-dimensional spaces. Classical algorithms for solving such typically take time polynomial the number dimension space. Quantum computers are good at tensor product This paper provides supervised unsupervised quantum machine learning cluster assignment finding. can logarithmic both their dimension, an exponential speed-up over classical algorithms."
    ],
    "c_categories":[
      "Quantum Physics"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":2411.0675,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"SynStitch: a Self-Supervised Learning Network for Ultrasound Image\n  Stitching Using Synthetic Training Pairs and Indirect Supervision",
    "a_abstract":"Ultrasound (US) image stitching can expand the field-of-view (FOV) by\ncombining multiple US images from varied probe positions. However, registering\nUS images with only partially overlapping anatomical contents is a challenging\ntask. In this work, we introduce SynStitch, a self-supervised framework\ndesigned for 2DUS stitching. SynStitch consists of a synthetic stitching pair\ngeneration module (SSPGM) and an image stitching module (ISM). SSPGM utilizes a\npatch-conditioned ControlNet to generate realistic 2DUS stitching pairs with\nknown affine matrix from a single input image. ISM then utilizes this synthetic\npaired data to learn 2DUS stitching in a supervised manner. Our framework was\nevaluated against multiple leading methods on a kidney ultrasound dataset,\ndemonstrating superior 2DUS stitching performance through both qualitative and\nquantitative analyses. The code will be made public upon acceptance of the\npaper.",
    "explanation":"Ultrasound (US) image stitching can expand the field-of view (FOV) by combining multiple US images from varied probe positions [...] In this work, we introduce SynStitch, a self-supervised framework designed for 2DUS stitching",
    "b_id":[
      "b3",
      "b21"
    ],
    "b_title":[
      "3-D ultrasound imaging: a review",
      "Generative AI for Medical Imaging: extending the MONAI Framework"
    ],
    "b_abstract":[
      "The development of 3-D ultrasound imaging is a way to address the disadvantages conventional imaging. In this article authors review approaches that have been attempted in such as B-mode, color Doppler, and power Doppler systems. Acquisition, reconstruction, rendering techniques for are discussed, well applications limitations.",
      "Recent advances in generative AI have brought incredible breakthroughs several areas, including medical imaging. These models tremendous potential not only to help safely share data via synthetic datasets but also perform an array of diverse applications, such as anomaly detection, image-to-image translation, denoising, and MRI reconstruction. However, due the complexity these models, their implementation reproducibility can be difficult. This hinder progress, act a use barrier, dissuade comparison new methods with existing works. In this study, we present MONAI Generative Models, freely available open-source platform that allows researchers developers easily train, evaluate, deploy related applications. Our reproduces state-of-art studies standardised way involving different architectures (such diffusion autoregressive transformers, GANs), provides pre-trained for community. We implemented generalisable fashion, illustrating results extended 2D or 3D scenarios, images modalities (like CT, MRI, X-Ray data) from anatomical areas. Finally, adopt modular extensible approach, ensuring long-term maintainability extension current applications future features."
    ],
    "b_categories":[
      "cs.CV",
      "eess.IV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Symmetric diffeomorphic image registration with crosscorrelation: evaluating automated labeling of elderly and neurodegenerative brain"
    ],
    "c_abstract":[
      "One of the most challenging problems in modern neuroimaging is detailed characterization of neurodegeneration. Quantifying spatial and longitudinal atrophy patterns is an important component of this process. These spatiotemporal signals will aid in discriminating between related diseases, such as frontotemporal dementia (FTD) and Alzheimer's disease (AD), which manifest themselves in the same at-risk population. Here, we develop a novel symmetric image normalization method (SyN) for maximizing the cross-correlation within the space of diffeomorphic maps and provide the Euler-Lagrange equations necessary for this optimization. We then turn to a careful evaluation of our method. Our evaluation uses gold standard, human cortical segmentation to contrast SyN's performance with a related elastic method and with the standard ITK implementation of Thirion's Demons algorithm. The new method compares favorably with both approaches, in particular when the distance between the template brain and the target brain is large. We then report the correlation of volumes gained by algorithmic cortical labelings of FTD and control subjects with those gained by the manual rater. This comparison shows that, of the three methods tested, SyN's volume measurements are the most strongly correlated with volume measurements gained by expert labeling. This study indicates that SyN, with cross-correlation, is a reliable method for normalizing and making anatomical measurements in volumetric MRI of patients and at-risk elderly individuals."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2411.1742,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Cross-modal Medical Image Generation Based on Pyramid Convolutional\n  Attention Network",
    "a_abstract":"The integration of multimodal medical imaging can provide complementary and\ncomprehensive information for the diagnosis of Alzheimer's disease (AD).\nHowever, in clinical practice, since positron emission tomography (PET) is\noften missing, multimodal images might be incomplete. To address this problem,\nwe propose a method that can efficiently utilize structural magnetic resonance\nimaging (sMRI) image information to generate high-quality PET images. Our\ngeneration model efficiently utilizes pyramid convolution combined with channel\nattention mechanism to extract multi-scale local features in sMRI, and injects\nglobal correlation information into these features using self-attention\nmechanism to ensure the restoration of the generated PET image on local texture\nand global structure. Additionally, we introduce additional loss functions to\nguide the generation model in producing higher-quality PET images. Through\nexperiments conducted on publicly available ADNI databases, the generated\nimages outperform previous research methods in various performance indicators\n(average absolute error: 0.0194, peak signal-to-noise ratio: 29.65, structural\nsimilarity: 0.9486) and are close to real images. In promoting AD diagnosis,\nthe generated images combined with their corresponding sMRI also showed\nexcellent performance in AD diagnosis tasks (classification accuracy: 94.21 %),\nand outperformed previous research methods of the same type. The experimental\nresults demonstrate that our method outperforms other competing methods in\nquantitative metrics, qualitative visualization, and evaluation criteria.",
    "explanation":"Our generation model efficiently utilizes pyramid convolution combined with channel attention mechanism to extract multi-scale local features in sMRI, and injects global correlation information into these features using self-attention mechanism to ensure the restoration of the generated PET image on local texture and global structure",
    "b_id":[
      "b3",
      "b17"
    ],
    "b_title":[
      "Deep learning-based classification of healthy aging controls, mild cognitive impairment and alzheimer's disease using fusion of mri-pet imaging",
      "Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"
    ],
    "b_abstract":[
      "Automated detection of dementia stage using multimodal imaging modalities will be helpful for improving the clinical diagnosis. In this study, we develop the Inception-ResNet wrapper model in differentiating the healthy controls (HC), mild cognitive impairment (MCI), and Alzheimer\u2019s disease (AD) using conjoint magnetic resonance imaging (MRI) and positron emission tomography (PET) scans. We use T1-weighted MR and PET images of individuals aged between 42 and 95 years, including HC, MCI and AD patients. We first perform 3D tissue segmentation of MR images after skull striping. The atlas-based segmented MR image tissue is fused with PET image. Then we transform PET images from RGB to HSI color space and apply fusion of MRI with PET images using two-dimensional Fourier and discrete wavelet transform (DWT) and then reconstruct the MR-PET fused image using inverse Fourier and DWT methods. After the fusion of MRI and PET imaging modalities, we used 60 % training, 20 % for validation and the remaining 20 % as a test set using various convolutional neural networks. We found the proposed model as the best classifier with an accuracy of 95.5 %, 94.1 % and 95.9 % in classifying HC vs MCI, MCI vs AD and AD vs HC respectively when compared to the existing methods. We conclude that the proposed deep learning model has potential in automated classification of healthy and dementia stages using combined MRI and PET modalities with good performance.",
      "Image-to-image translation is a class of vision and graphics problems where the goal to learn mapping between an input image output using training set aligned pairs. However, for many tasks, paired data will not be available. We present approach learning translate from source domain X target Y in absence examples. Our G : \u2192 such that distribution images G(X) indistinguishable adversarial loss. Because this highly under-constrained, we couple it with inverse F introduce cycle consistency loss push F(G(X)) \u2248 (and vice versa). Qualitative results are presented on several tasks does exist, including collection style transfer, object transfiguration, season photo enhancement, etc. Quantitative comparisons against prior methods demonstrate superiority our approach."
    ],
    "b_categories":[
      "cs.CV",
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b19"
    ],
    "c_title":[
      "Bidirectional Mapping of Brain MRI and PET With 3D Reversible GAN for the Diagnosis of Alzheimer\u2019s Disease"
    ],
    "c_abstract":[
      "<jats:p>Combining multi-modality data for brain disease diagnosis such as Alzheimer\u2019s disease (AD) commonly leads to improved performance than those using a single modality. However, it is still challenging to train a multi-modality model since it is difficult in clinical practice to obtain complete data that includes all modality data. Generally speaking, it is difficult to obtain both magnetic resonance images (MRI) and positron emission tomography (PET) images of a single patient. PET is expensive and requires the injection of radioactive substances into the patient\u2019s body, while MR images are cheaper, safer, and more widely used in practice. Discarding samples without PET data is a common method in previous studies, but the reduction in the number of samples will result in a decrease in model performance. To take advantage of multi-modal complementary information, we first adopt the Reversible Generative Adversarial Network (RevGAN) model to reconstruct the missing data. After that, a 3D convolutional neural network (CNN) classification model with multi-modality input was proposed to perform AD diagnosis. We have evaluated our method on the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database, and compared the performance of the proposed method with those using state-of-the-art methods. The experimental results show that the structural and functional information of brain tissue can be mapped well and that the image synthesized by our method is close to the real image. In addition, the use of synthetic data is beneficial for the diagnosis and prediction of Alzheimer\u2019s disease, demonstrating the effectiveness of the proposed framework.<\/jats:p>"
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":2412.16425,
    "date":null,
    "fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Quantitative Biology"
    ],
    "a_title":"Patherea: Cell Detection and Classification for the 2020s",
    "a_abstract":"This paper presents a Patherea, a framework for point-based cell detection\nand classification that provides a complete solution for developing and\nevaluating state-of-the-art approaches. We introduce a large-scale dataset\ncollected to directly replicate a clinical workflow for Ki-67 proliferation\nindex estimation and use it to develop an efficient point-based approach that\ndirectly predicts point-based predictions, without the need for intermediate\nrepresentations. The proposed approach effectively utilizes point proposal\ncandidates with the hybrid Hungarian matching strategy and a flexible\narchitecture that enables the usage of various backbones and (pre)training\nstrategies. We report state-of-the-art results on existing public datasets -\nLizard, BRCA-M2C, BCData, and the newly proposed Patherea dataset. We show that\nthe performance on existing public datasets is saturated and that the newly\nproposed Patherea dataset represents a significantly harder challenge for the\nrecently proposed approaches. We also demonstrate the effectiveness of recently\nproposed pathology foundational models that our proposed approach can natively\nutilize and benefit from. We also revisit the evaluation protocol that is used\nin the broader field of cell detection and classification and identify the\nerroneous calculation of performance metrics. Patherea provides a benchmarking\nutility that addresses the identified issues and enables a fair comparison of\ndifferent approaches. The dataset and the code will be publicly released upon\nacceptance.",
    "explanation":"This paper presents a Patherea, a framework for point-based cell detection and classification that provides a complete solution for developing and evaluating state-of-the-art approaches.",
    "b_id":[
      "b40"
    ],
    "b_title":[
      "Whole Slide Imaging Versus Microscopy for Primary Diagnosis in Surgical Pathology: A Multicenter Blinded Randomized Noninferiority Study of 1992 Cases (Pivotal Study)"
    ],
    "b_abstract":[
      "Most prior studies of primary diagnosis in surgical pathology using whole slide imaging (WSI) versus microscopy have focused on specific organ systems or included relatively few cases. The objective this study was to demonstrate that WSI is noninferior for pathology. A blinded randomized noninferiority conducted across the entire range cases (biopsies and resections, including hematoxylin eosin, immunohistochemistry, special stains) from 4 institutions original sign-out (baseline diagnosis) as reference standard. Cases were scanned, converted randomized. Sixteen pathologists interpreted by WSI, followed a wash-out period \u22654 weeks, after which read same observers other modality. Major discordances identified an adjudication panel, differences between major discordance rates both (against standard) calculated. total 1992 included, resulting 15,925 reads. rate with standard 4.9% 4.6% microscopy. difference 0.4% (95% confidence interval, -0.30% 1.01%). highest endocrine (1.8%), neoplastic kidney (1.5%), urinary bladder (1.3%), gynecologic (1.2%). Detailed analysis these revealed no instances where interpretation consistently inaccurate compared multiple observers. We conclude pathology, biopsies resections stained immunohistochemistry stains. This conclusion valid wide variety specimen types."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    ],
    "c_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  }
]