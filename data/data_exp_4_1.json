[
  {
    "id":"2411.01019",
    "a_title":"A lightweight Convolutional Neural Network based on U shape structure\n  and Attention Mechanism for Anterior Mediastinum Segmentation",
    "a_abstract":"To automatically detect Anterior Mediastinum Lesions (AMLs) in the Anterior\nMediastinum (AM), the primary requirement will be an automatic segmentation\nmodel specifically designed for the AM. The prevalence of AML is extremely low,\nmaking it challenging to conduct screening research similar to lung cancer\nscreening. Retrospectively reviewing chest CT scans over a specific period to\ninvestigate the prevalence of AML requires substantial time. Therefore,\ndeveloping an Artificial Intelligence (AI) model to find location of AM helps\nradiologist to enhance their ability to manage workloads and improve diagnostic\naccuracy for AMLs. In this paper, we introduce a U-shaped structure network to\nsegment AM. Two attention mechanisms were used for maintaining long-range\ndependencies and localization. In order to have the potential of Multi-Head\nSelf-Attention (MHSA) and a lightweight network, we designed a parallel MHSA\nnamed Wide-MHSA (W-MHSA). Maintaining long-range dependencies is crucial for\nsegmentation when we upsample feature maps. Therefore, we designed a Dilated\nDepth-Wise Parallel Path connection (DDWPP) for this purpose. In order to\ndesign a lightweight architecture, we introduced an expanding convolution block\nand combine it with the proposed W-MHSA for feature extraction in the encoder\npart of the proposed U-shaped network. The proposed network was trained on 2775\nAM cases, which obtained an average Dice Similarity Coefficient (DSC) of\n87.83%, mean Intersection over Union (IoU) of 79.16%, and Sensitivity of\n89.60%. Our proposed architecture exhibited superior segmentation performance\ncompared to the most advanced segmentation networks, such as Trans Unet,\nAttention Unet, Res Unet, and Res Unet++.",
    "explanation":"It's leveraging AI in another diffrent domain, namely medical science, to detect Anterior Mediastinum Lesions.",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Anterior mediastinal nodular lesion segmentation from chest computed tomography imaging using UNet based neural network with attention mechanisms"
    ],
    "b_abstract":[
      "Automated detection of anterior mediastinal nodular lesions (AMLs) has significance for clinical usage as it is challenging for radiologists to accurately identify AMLs from chest computed tomography (CT) imaging due to various factors, including poor resolution, variations in intensity and the similarity of the AMLs to other tissues. To assist radiologists in AML detection from chest CT imaging, a UNet-based computer-aided detection (CADe) system is proposed to segment AMLs from slice images of the chest CT scans. The proposed network adopts a modified UNet architecture. To guide the proposed network to selectively focus on AMLs and potentially disregard others in the image, different attention mechanisms are utilized in the proposed network, including the self-attention mechanism and the convolutional block attention module (CBAM). The proposed network was trained and evaluated on 180 chest CT scans which consist of 180 AMLs. 90 AMLs were identified as thymic cysts, and 90 AMLs were diagnosed as thymoma. The proposed network achieved an average dice similarity coefficient (DSC) of 93.23 with 5-fold cross-validation, for which the mean Intersection over Union (IoU), sensitivity and specificity were 90.29, 93.98 and 95.68 respectively. Our method demonstrated an improved segmentation performance over state-of-the-art segmentation networks, including UNet, ResUNet, TransUNet and UNet++. The proposed network employing attention mechanisms exhibited a promising result for segmenting AMLs from chest CT imaging and could be used to automate the AML detection process for achieving improved diagnostic reliability."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b6",
      "b1"
    ],
    "c_title":[
      "Screening for lung cancer: 2023 guideline update from the American Cancer Society",
      "Incidental Anterior Mediastinal Nodular Lesions on\u00a0Chest CT in Asymptomatic Subjects"
    ],
    "c_abstract":[
      "Abstract Lung cancer is the leading cause of mortality and person\u2010years life lost from among US men women. Early detection has been shown to be associated with reduced lung mortality. Our objective was update American Cancer Society (ACS) 2013 screening (LCS) guideline for adults at high risk cancer. The intended provide guidance health care providers their patients who are due a history smoking. ACS Guideline Development Group (GDG) utilized systematic review LCS literature commissioned Preventive Services Task Force 2021 recommendation update; second years since quitting smoking (YSQ); published 2021; two Intervention Surveillance Modeling Network\u2010validated models assess benefits harms screening; an epidemiologic modeling analysis examining effect YSQ aging on risk; updated benefit\u2010to\u2010radiation\u2010risk ratios follow\u2010up examinations. GDG also examined disease burden data National Institute\u2019s Surveillance, Epidemiology, End Results program. Formulation recommendations based quality evidence judgment (incorporating values preferences) about balance harms. judged that overall moderate sufficient support strong individuals meet eligibility criteria. in women aged 50\u201380 reduction deaths across range study designs, inferential supports older than 80 good health. recommends annual low\u2010dose computed tomography asymptomatic currently smoke or formerly smoked have \u226520 pack\u2010year ( , ). Before decision made initiate LCS, should engage shared decision\u2010making discussion qualified professional. For smoked, number not criterion begin stop screening. Individuals receive counseling quit connected cessation resources. comorbid conditions substantially limit expectancy screened. These considered by discussions LCS. If fully implemented, these likelihood significantly reducing death suffering United States.",
      "Objective: The aim of this study was to investigate the prevalence and characteristics of nodular lesions in the anterior mediastinum that had been found incidentally on screening chest computed tomography (CT) in asymptomatic subjects. Methods: We included 56,358 consecutive participants (mean age 52.4 \u00b1 10.5 years; male-female ratio 35,306:21,052) who underwent a baseline low-dose chest CT scan as part of a health checkup from 2006 through 2013. After the presence of anterior mediastinal nodular lesion had been confirmed, their CT findings, confirmatory diagnosis, and interval CT scan were reviewed. The standardized prevalence ratio for thymic epithelial tumor was calculated on the basis of the Republic of Korea cancer statistics for 2014. Results: Of the 56,358 participants, 413 (0.73%) had lesions (95% confidence interval: 0.66-0.80%); the prevalence increased with age (p <0.001) and a history of malignancy (p = 0.005). Of the lesions, 85.2% were smaller than 2 cm, 61.3% were round, and 80.2% had CT attenuation higher than 20 Hounsfield units. Among 51 proven cases, 39 lesions (76.9%) were benign and 12 (23.1%) were malignant. The standardized prevalence ratio for thymic epithelial tumor was 2.04 (95% confidence interval: 1.01-3.42). Of 11 resected thymic epithelial tumors, five were carcinomas, 10 were stage I or II, and all were completely resected without recurrence. Of the 237 unconfirmed cases with a follow-up CT scan, 82.2% were stable, 8.9% had increased, and the other 8.9% had decreased. Conclusions: The prevalence of incidental nodular lesion was 0.73%. Most lesions had CT features that were indistinguishable from thymic epithelial tumors, but a considerable portion of the lesions were suspected to be benign. Incidental thymic epithelial tumors were more prevalent than clinically detected tumors, were early-stage cancer, and showed favorable outcomes."
    ],
    "c_categories":[
      "q-bio.TO",
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.11084",
    "a_title":"BarcodeMamba: State Space Models for Biodiversity Analysis",
    "a_abstract":"DNA barcodes are crucial in biodiversity analysis for building automatic\nidentification systems that recognize known species and discover unseen\nspecies. Unlike human genome modeling, barcode-based invertebrate\nidentification poses challenges in the vast diversity of species and taxonomic\ncomplexity. Among Transformer-based foundation models, BarcodeBERT excelled in\nspecies-level identification of invertebrates, highlighting the effectiveness\nof self-supervised pretraining on barcode-specific datasets. Recently,\nstructured state space models (SSMs) have emerged, with a time complexity that\nscales sub-quadratically with the context length. SSMs provide an efficient\nparameterization of sequence modeling relative to attention-based\narchitectures. Given the success of Mamba and Mamba-2 in natural language, we\ndesigned BarcodeMamba, a performant and efficient foundation model for DNA\nbarcodes in biodiversity analysis. We conducted a comprehensive ablation study\non the impacts of self-supervised training and tokenization methods, and\ncompared both versions of Mamba layers in terms of expressiveness and their\ncapacity to identify \"unseen\" species held back from training. Our study shows\nthat BarcodeMamba has better performance than BarcodeBERT even when using only\n8.3% as many parameters, and improves accuracy to 99.2% on species-level\naccuracy in linear probing without fine-tuning for \"seen\" species. In our\nscaling study, BarcodeMamba with 63.6% of BarcodeBERT's parameters achieved\n70.2% genus-level accuracy in 1-nearest neighbor (1-NN) probing for unseen\nspecies. The code repository to reproduce our experiments is available at\nhttps:\/\/github.com\/bioscan-ml\/BarcodeMamba.",
    "explanation":"The paper talks about the use of BarcodeMamba for better scores in DNA barcode analysis of genomes.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Biological identifications through DNA barcodes"
    ],
    "b_abstract":[
      "Although much biological research depends upon species diagnoses, taxonomic expertise is collapsing.We are convinced that the sole prospect for a sustainable identification capability lies in construction of systems employ DNA sequences as taxon 'barcodes'.We establish mitochondrial gene cytochrome c oxidase I (COI) can serve core global bioidentification system animals.First, we demonstrate COI profiles, derived from low-density sampling higher categories, ordinarily assign newly analysed taxa to appropriate phylum or order.Second, species-level assignments be obtained by creating comprehensive profiles.A model profile, based analysis single individual each 200 closely allied lepidopterans, was 100% successful correctly identifying subsequent specimens.When fully developed, will provide reliable, cost-effective and accessible solution current problem identification.Its assembly also generate important new insights into diversification life rules molecular evolution."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "BarcodeBERT: Transformers for Biodiversity Analysis"
    ],
    "c_abstract":[
      "Understanding biodiversity is a global challenge, in which DNA barcodes - short snippets of that cluster by species play pivotal role. In particular, invertebrates, highly diverse and under-explored group, pose unique taxonomic complexities. We explore machine learning approaches, comparing supervised CNNs, fine-tuned foundation models, barcode-specific masking strategy across datasets varying complexity. While simpler tasks favor CNNs or transformers, challenging species-level identification demands paradigm shift towards self-supervised pretraining. propose BarcodeBERT, the first method for general analysis, leveraging 1.5 M invertebrate barcode reference library. This work highlights how dataset specifics coverage impact model selection, underscores role pretraining achieving high-accuracy barcode-based at genus level. Indeed, without fine-tuning step, BarcodeBERT pretrained on large outperforms DNABERT DNABERT-2 multiple downstream classification tasks. The code repository available https:\/\/github.com\/Kari-Genomics-Lab\/BarcodeBERT"
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00609",
    "a_title":"Tumor Location-weighted MRI-Report Contrastive Learning: A Framework for\n  Improving the Explainability of Pediatric Brain Tumor Diagnosis",
    "a_abstract":"Despite the promising performance of convolutional neural networks (CNNs) in\nbrain tumor diagnosis from magnetic resonance imaging (MRI), their integration\ninto the clinical workflow has been limited. That is mainly due to the fact\nthat the features contributing to a model's prediction are unclear to\nradiologists and hence, clinically irrelevant, i.e., lack of explainability. As\nthe invaluable sources of radiologists' knowledge and expertise, radiology\nreports can be integrated with MRI in a contrastive learning (CL) framework,\nenabling learning from image-report associations, to improve CNN\nexplainability. In this work, we train a multimodal CL architecture on 3D brain\nMRI scans and radiology reports to learn informative MRI representations.\nFurthermore, we integrate tumor location, salient to several brain tumor\nanalysis tasks, into this framework to improve its generalizability. We then\napply the learnt image representations to improve explainability and\nperformance of genetic marker classification of pediatric Low-grade Glioma, the\nmost prevalent brain tumor in children, as a downstream task. Our results\nindicate a Dice score of 31.1% between the model's attention maps and manual\ntumor segmentation (as an explainability measure) with test classification\nperformance of 87.7%, significantly outperforming the baselines. These\nenhancements can build trust in our model among radiologists, facilitating its\nintegration into clinical practices for more efficient tumor diagnosis.",
    "explanation":"The article presents a research involving the use of Computer Science methods to treat problems in Medicine. In this case, applying the use of Convolutional Neural Networks (CNN) for the recognition of pediatric tumors in medical images and Contrastive Learning (CL) to improve the explainability of the model.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Pediatric low-grade glioma: State-of-the-art and ongoing challenges"
    ],
    "b_abstract":[
      "Abstract The most common childhood central nervous system (CNS) tumor is pediatric low-grade glioma (pLGG), representing 30%\u201340% of all CNS tumors in children. Although there high associated morbidity, tumor-related mortality relatively rare. pLGG now conceptualized as a chronic disease, underscoring the importance functional outcomes and quality-of-life measures. A wealth data has emerged about these tumors, including better understanding their natural history molecular drivers, paving way for use targeted inhibitors. While treatments have heralded tremendous promise, challenges remain how to best optimize use, long-term toxicities with inhibitors unknown. International Pediatric Low-Grade Glioma Coalition (iPLGGc) global group physicians scientists expertise focused on addressing key issues. Here, iPLGGc provides an overview current state-of-the-art pLGG, epidemiology, histology, landscape, treatment paradigms, survival outcomes, imaging response, ongoing challenges. This paper also serves introduction 3 other manuscripts (1) preclinical models, (2) consensus framework conducting early-phase clinical trials (3) resistance, rebound, recurrence."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Improving Pediatric Low-Grade Neuroepithelial Tumors Molecular Subtype\n  Identification Using a Novel AUROC Loss Function for Convolutional Neural\n  Networks"
    ],
    "c_abstract":[
      "Pediatric Low-Grade Neuroepithelial Tumors (PLGNT) are the most common pediatric cancer type, accounting for 40% of brain tumors in children, and identifying PLGNT molecular subtype is crucial treatment planning. However, gold standard to determine biopsy, which can be impractical or dangerous patients. This research improves performance Convolutional Neural Networks (CNNs) classifying subtypes through MRI scans by introducing a loss function that specifically model's Area Under Receiver Operating Characteristic (ROC) Curve (AUROC), offering non-invasive diagnostic alternative. In this study, retrospective dataset 339 children with (143 BRAF fusion, 71 V600E mutation, 125 non-BRAF) was curated. We employed CNN model Monte Carlo random data splitting. The baseline trained using binary cross entropy (BCE), achieved an AUROC 86.11% differentiating fusion mutations, improved 87.71% our proposed (p-value 0.045). With multiclass classification, from 74.42% 76. 59% 0.0016)."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00726",
    "a_title":"Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading\n  with Cataract",
    "a_abstract":"Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a\ncommon complication of diabetes. As two different imaging tools for DR grading,\ncolor fundus photography (CFP) and infrared fundus photography (IFP) are\nhighly-correlated and complementary in clinical applications. To the best of\nour knowledge, this is the first study that explores a novel multi-modal deep\nlearning framework to fuse the information from CFP and IFP towards more\naccurate DR grading. Specifically, we construct a dual-stream architecture\nCross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus\nimage modalities. In particular, a meticulously engineered Cross-Fundus\nAttention (CFA) module is introduced to capture the correspondence between CFP\nand IFP images. Moreover, we adopt both the single-modality and multi-modality\nsupervisions to maximize the overall performance for DR grading. Extensive\nexperiments on a clinical dataset consisting of 1,713 pairs of multi-modal\nfundus images demonstrate the superiority of our proposed method. Our code will\nbe released for public access.",
    "explanation":"The work combines transformers with two distinct methods that evaluate the quality of retinopathy",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Relation Between Retinal Vasculature and Retinal Thickness in Macular Edema"
    ],
    "b_abstract":[
      "This study has investigated the relationship of retinal vasculature and thickness for Macular Edema (ME) subjects. Ninety sets Fluorescein Angiograph (FA) Optical Coherence Tomography (OCT) 54 participants were analyzed. Multivariate analysis using binary logistic regression model was used to association between vessel parameters thickness. The results reveal feature i.e. fractal dimension (FD) as most sensitive parameter changes in associated with ME. Thus, indicating a direct which is caused due neovascular causing exudates, leakages hemorrhages, applications alternate modality detection"
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    ],
    "c_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05236",
    "a_title":"Designing a Light-based Communication System with a Biomolecular\n  Receiver",
    "a_abstract":"Biological systems transduce signals from their surroundings in numerous\nways. This paper introduces a communication system using the light-gated ion\nchannel Channelrhodopsin-2 (ChR2), which causes an ion current to flow in\nresponse to light. Our design includes a ChR2-based receiver along with\nencoding, modulation techniques and detection. Analyzing the resulting\ncommunication system, we discuss the effect of different parameters on the\nperformance of the system. Finally, we discuss its potential design in the\ncontext of bio-engineering and light-based communication and show that the data\nrate scales up with the number of receptors, indicating that high-speed\ncommunication may be possible.",
    "explanation":"The paper is interdisciplinary because it aims to use channelrhodopsin-2 (ChR2), a biomolecule, as a receiver to design a light-based communication system, which is a work related to engineering.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Channelrhodopsin-2, a directly light-gated cation-selective membrane channel"
    ],
    "b_abstract":[
      "Microbial-type rhodopsins are found in archaea, prokaryotes, and eukaryotes. Some of them represent membrane ion transport proteins such as bacteriorhodopsin, a light-driven proton pump, or channelrhodopsin-1 (ChR1), recently identified light-gated channel from the green alga Chlamydomonas reinhardtii . ChR1 ChR2, related microbial-type rhodopsin C. , were shown to be involved generation photocurrents this alga. We demonstrate by functional expression, both oocytes Xenopus laevis mammalian cells, that ChR2 is directly light-switched cation-selective channel. This opens rapidly after absorption photon generate large permeability for monovalent divalent cations. desensitizes continuous light smaller steady-state conductance. Recovery desensitization accelerated extracellular H + negative potential, whereas closing decelerated intracellular expressed mainly under low-light conditions, suggesting involvement photoreception dark-adapted cells. The predicted seven-transmembrane \u03b1 helices characteristic G protein-coupled receptors but reflect different motif Finally, we may used depolarize small simply illumination."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2",
      "b0"
    ],
    "c_title":[
      "Shannon capacity of signal transduction for multiple independent receptors",
      "DESIGN AND IMPLEMENTATION OF VISIBLE LIGHT COMMUNICATION SYSTEM IN INDOOR ENVIRONMENT"
    ],
    "c_abstract":[
      "Cyclic adenosine monophosphate (cAMP) is considered a model system for signal transduction, the mechanism by which cells exchange chemical messages. Our previous work calculated Shannon capacity of single cAMP receptor; however, typical cell may have thousands receptors operating in parallel. In this paper, we calculate transduction with an arbitrary number independent, indistinguishable receptors. By leveraging prior results on feedback receptor, show (somewhat unexpectedly) that achieved IID input distribution, and n times receptor.",
      "Visible Light communication (VLC) using White Light Emitting Diode (LED) is a promising technology for next generation communication for short range, high speed wireless data transmission. In this paper inexpensive transmitter and receiver of VLC system is designed and its performance is evaluated. The effect of natural and artificial ambient light noise sources is also considered. Experimental results show that the data transmission distance achieved upto 0.45m.Performance analysis is done with respect to optical power, photo sensitivity of photodiode at the receiver and the increase in distance between the transmitter and receiver."
    ],
    "c_categories":[
      "cs.SY",
      "eess.SP"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.02815",
    "a_title":"Artificial Intelligence-Enhanced Couinaud Segmentation for Precision\n  Liver Cancer Therapy",
    "a_abstract":"Precision therapy for liver cancer necessitates accurately delineating liver\nsub-regions to protect healthy tissue while targeting tumors, which is\nessential for reducing recurrence and improving survival rates. However, the\nsegmentation of hepatic segments, known as Couinaud segmentation, is\nchallenging due to indistinct sub-region boundaries and the need for extensive\nannotated datasets. This study introduces LiverFormer, a novel Couinaud\nsegmentation model that effectively integrates global context with low-level\nlocal features based on a 3D hybrid CNN-Transformer architecture. Additionally,\na registration-based data augmentation strategy is equipped to enhance the\nsegmentation performance with limited labeled data. Evaluated on CT images from\n123 patients, LiverFormer demonstrated high accuracy and strong concordance\nwith expert annotations across various metrics, allowing for enhanced treatment\nplanning for surgery and radiation therapy. It has great potential to reduces\ncomplications and minimizes potential damages to surrounding tissue, leading to\nimproved outcomes for patients undergoing complex liver cancer treatments.",
    "explanation":"The paper presents a tool that uses Convolutional Neural Networks (CNN) and Transformers, technologies from Computer Science, to improve the accuracy and efficiency of Couinaud segmentation in liver cancer treatment, a challenge in the field of Medicine.",
    "b_id":[
      "b36",
      "b33"
    ],
    "b_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "Automated segmentation of liver segment on portal venous phase MR images using a 3D convolutional neural network"
    ],
    "b_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train.",
      "We aim to develop and validate a three-dimensional convolutional neural network (3D-CNN) model for automatic liver segment segmentation on MRI images.This retrospective study evaluated an automated method using deep that was trained, validated, tested with 367, 157, 158 portal venous phase MR images, respectively. The Dice similarity coefficient (DSC), mean surface distance (MSD), Hausdorff (HD), volume ratio (RV) were used quantitatively measure the accuracy of segmentation. time consumed manual also compared. In addition, applied 100 consecutive cases from real clinical scenario qualitative evaluation indirect evaluation.In quantitative evaluation, achieved high DSC, MSD, HD RV (0.920, 3.34, 3.61 1.01, respectively). Compared segmentation, reduced 26 min 8 s. quality rated as good in 79% cases, moderate 15% poor 6%. 93.4% (99\/106) lesions could be assigned correct by only referring results segmentation.The proposed may serve effective tool anatomical region annotation images."
    ],
    "b_categories":[
      "cs.CV",
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Liver Anatomy: Portal (and Suprahepatic) or Biliary Segmentation"
    ],
    "c_abstract":[
      "In liver anatomy and surgery, is portal hepatic vein segmentation (French segmentation) to be preferred over arteriobiliary (Healey Schroy, North American segmentation)?Several embryological arguments an analysis of anatomical data from a personal collection 110 vasculobiliary casts were made.Embryological arguments: Portal branching appears first, secondly follows the distribution. Segment II (the left lateral sector) development right lobe. The umbilical enters portion middle lobe, forming segment IV on III left: this paramedian sector. So fissure (between lobes) transversally crosses classical which not unit. VI late secondary prominence VII, reaching anterior margin only in man. Anatomical must added segmentation; academic lobe sector, separates lobes. preferred: duplication branches first order occurs 23.5% cases, while first-order noted 50% livers, being much simpler.Portal seems more accurate."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00561",
    "a_title":"Automated Classification of Cell Shapes: A Comparative Evaluation of\n  Shape Descriptors",
    "a_abstract":"This study addresses the challenge of classifying cell shapes from noisy\ncontours, such as those obtained through cell instance segmentation of\nhistological images. We assess the performance of various features for shape\nclassification, including Elliptical Fourier Descriptors, curvature features,\nand lower dimensional representations. Using an annotated synthetic dataset of\nnoisy contours, we identify the most suitable shape descriptors and apply them\nto a set of real images for qualitative analysis. Our aim is to provide a\ncomprehensive evaluation of descriptors for classifying cell shapes, which can\nsupport cell type identification and tissue characterization-critical tasks in\nboth biological research and histopathological assessments.",
    "explanation":"This study addresses the challenge of classifying cell shapes from noisy contours, such as those obtained through cell instance segmentation of histological images.\n\nOur aim is to provide a comprehensive evaluation of descriptors for classifying cell shapes, which can support cell type identification and tissue characterization\u2014critical tasks in both biological research and histopathological assessments.\n",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "Retrieval and classification of shape-based objects using Fourier, generic Fourier, and wavelet-Fourier descriptors technique: A comparative study"
    ],
    "b_abstract":[
      "In this paper, we report retrieval and classification of shape-based objects employing three techniques-conventional Fourier descriptors (FD), generic Fourier descriptors (GFD) and wavelet-Fourier descriptors (WFD) techniques. All the three techniques have been applied to a database of seven different types of shapes. The centroid distance based shape signatures have been used for the derivation of descriptors. The Euclidean distance has been calculated as a similarity measure parameter for shape classification. For WFD technique, a Mexican-hat wavelet function was used. Classification results from all the three techniques were compared and it was observed that WFD performs better than FD and GFD technique. To study the effect of the noise on the retrieval and classification of shapes of different objects, additive and multiplicative noise of various variances were applied to the database. Precision and recall were also measured as parameters of performance metric."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "What is a cell type, really? The quest to categorize life's myriad forms."
    ],
    "c_abstract":[
      "The problem of cell type became clear to genome biologist Jason Buenrostro in 2013. He was studying a cell line derived from someone with cancer, trying to map out how the DNA was arranged in the nucleus. The cells should have been pretty much identical, he thought. But the more Buenrostro looked at the DNA, the more differences he found in how it was packaged1. \u201cI realized that there were probably hundreds of flavours,\u201d recalls Buenrostro, who was a graduate student at Stanford University in California at the time."
    ],
    "c_categories":[
      "q-bio.BM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01144",
    "a_title":"LEARNER: Learning Granular Labels from Coarse Labels using Contrastive\n  Learning",
    "a_abstract":"A crucial question in active patient care is determining if a treatment is\nhaving the desired effect, especially when changes are subtle over short\nperiods. We propose using inter-patient data to train models that can learn to\ndetect these fine-grained changes within a single patient. Specifically, can a\nmodel trained on multi-patient scans predict subtle changes in an individual\npatient's scans? Recent years have seen increasing use of deep learning (DL) in\npredicting diseases using biomedical imaging, such as predicting COVID-19\nseverity using lung ultrasound (LUS) data. While extensive literature exists on\nsuccessful applications of DL systems when well-annotated large-scale datasets\nare available, it is quite difficult to collect a large corpus of personalized\ndatasets for an individual. In this work, we investigate the ability of recent\ncomputer vision models to learn fine-grained differences while being trained on\ndata showing larger differences. We evaluate on an in-house LUS dataset and a\npublic ADNI brain MRI dataset. We find that models pre-trained on clips from\nmultiple patients can better predict fine-grained differences in scans from a\nsingle patient by employing contrastive learning.",
    "explanation":"Recent years have seen increasing use of deep learning\n(DL) in predicting diseases using biomedical imaging, such as\npredicting COVID-19 severity using lung ultrasound (LUS)\ndata.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Investigating training-test data splitting strategies for automated segmentation and scoring of COVID-19 lung ultrasound images."
    ],
    "b_abstract":[
      "Ultrasound in point-of-care lung assessment is becoming increasingly relevant. This is further reinforced in the context of the COVID-19 pandemic, where rapid decisions on the lung state must be made for staging and monitoring purposes. The lung structural changes due to severe COVID-19 modify the way ultrasound propagates in the parenchyma. This is reflected by changes in the appearance of the lung ultrasound images. In abnormal lungs, vertical artifacts known as B-lines appear and can evolve into white lung patterns in the more severe cases. Currently, these artifacts are assessed by trained physicians, and the diagnosis is qualitative and operator dependent. In this article, an automatic segmentation method using a convolutional neural network is proposed to automatically stage the progression of the disease. 1863 B-mode images from 203 videos obtained from 14 asymptomatic individual,14 confirmed COVID-19 cases, and 4 suspected COVID-19 cases were used. Signs of lung damage, such as the presence and extent of B-lines and white lung areas, are manually segmented and scored from zero to three (most severe). These manually scored images are considered as ground truth. Different test-training strategies are evaluated in this study. The results shed light on the efficient approaches and common challenges associated with automatic segmentation methods."
    ],
    "b_categories":[
      "Lung Ultrasound"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "A Simple Framework for Contrastive Learning of Visual Representations"
    ],
    "c_abstract":[
      "This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed self-supervised algorithms without requiring specialized architectures or memory bank. In order to understand what enables the prediction tasks learn useful representations, we systematically study major components our framework. show that (1) composition data augmentations plays critical role in defining effective predictive tasks, (2) introducing learnable nonlinear transformation between representation and loss substantially improves quality learned (3) benefits from larger batch sizes more training steps compared supervised learning. By combining these findings, are able considerably outperform previous methods semi-supervised on ImageNet. A linear classifier trained representations by SimCLR achieves 76.5% top-1 accuracy, which is 7% relative improvement over state-of-the-art, matching performance ResNet-50. When fine-tuned only 1% labels, achieve 85.8% top-5 outperforming AlexNet with 100X fewer labels."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00922",
    "a_title":"Lung tumor segmentation in MRI mice scans using 3D nnU-Net with minimum\n  annotations",
    "a_abstract":"In drug discovery, accurate lung tumor segmentation is an important step for\nassessing tumor size and its progression using \\textit{in-vivo} imaging such as\nMRI. While deep learning models have been developed to automate this process,\nthe focus has predominantly been on human subjects, neglecting the pivotal role\nof animal models in pre-clinical drug development. In this work, we focus on\noptimizing lung tumor segmentation in mice. First, we demonstrate that the\nnnU-Net model outperforms the U-Net, U-Net3+, and DeepMeta models. Most\nimportantly, we achieve better results with nnU-Net 3D models than 2D models,\nindicating the importance of spatial context for segmentation tasks in MRI mice\nscans. This study demonstrates the importance of 3D input over 2D input images\nfor lung tumor segmentation in MRI scans. Finally, we outperform the prior\nstate-of-the-art approach that involves the combined segmentation of lungs and\ntumors within the lungs. Our work achieves comparable results using only lung\ntumor annotations requiring fewer annotations, saving time and annotation\nefforts. This work\n(https:\/\/anonymous.4open.science\/r\/lung-tumour-mice-mri-64BB) is an important\nstep in automating pre-clinical animal studies to quantify the efficacy of\nexperimental drugs, particularly in assessing tumor changes.",
    "explanation":"In this work, we focus on optimizing lung tumor segmen-\ntation in mice. First, we demonstrate that the nnU-Net model outper-\nforms the U-Net, U-Net3+, and DeepMeta models.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Deep learning model for automatic segmentation of lungs and pulmonary metastasis in small animal MR images"
    ],
    "b_abstract":[
      "Lungs are the most frequent site of metastases growth. The amount and size pulmonary acquired from MRI imaging data important criteria to assess efficacy new drugs in preclinical models. While efficient solutions both for MR downstream automatic segmentation have been proposed human patients, lung animal models remains challenging due physiological motion (respiratory cardiac movements), low protons this organ particular challenge precise metastases. As a consequence post-mortem analysis is currently required obtain information on metastatic volume. In work, we developed complete methodological pipeline automated lungs mice, consisting an sequence image acquisition deep learning method On one hand, optimized mouse with high contrast detection sensitivity. other hand DeepMeta, multiclass U-Net 3+ model automatically segment images. To if able provide accurate metastases, longitudinally imaged mice fast- slow-growing metastasis. Fifty-five balb\/c were injected two different derivatives renal carcinoma cells. Mice SG-bSSFP (self-gated balanced steady state free precession) at time points after injection cancer Both segmentations manually performed by experts. DeepMeta was trained perform based resulting ground truth annotations. Volumes as well number per measured separate test dataset Thanks SG method, 3D bSSFP images artifact-free, enabling serial follow-up Moreover, accurately soon they reached volume \u223c0.02mm3 . Thus distinguish groups terms slow versus fast patterns growth We shown that our methodology combining learning, enables processing whole thus viable alternative histology alone."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b12"
    ],
    "c_title":[
      "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "c_abstract":[
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.02695",
    "a_title":"An ADHD Diagnostic Interface Based on EEG Spectrograms and Deep Learning\n  Techniques",
    "a_abstract":"This paper introduces an innovative approach to\nAttention-deficit\/hyperactivity disorder (ADHD) diagnosis by employing deep\nlearning (DL) techniques on electroencephalography (EEG) signals. This method\naddresses the limitations of current behavior-based diagnostic methods, which\noften lead to misdiagnosis and gender bias. By utilizing a publicly available\nEEG dataset and converting the signals into spectrograms, a Resnet-18\nconvolutional neural network (CNN) architecture was used to extract features\nfor ADHD classification. The model achieved a high precision, recall, and an\noverall F1 score of 0.9. Feature extraction highlighted significant brain\nregions (frontopolar, parietal, and occipital lobes) associated with ADHD.\nThese insights guided the creation of a three-part digital diagnostic system,\nfacilitating cost-effective and accessible ADHD screening, especially in school\nenvironments. This system enables earlier and more accurate identification of\nstudents at risk for ADHD, providing timely support to enhance their\ndevelopmental outcomes. This study showcases the potential of integrating EEG\nanalysis with DL to enhance ADHD diagnostics, presenting a viable alternative\nto traditional methods.",
    "explanation":"his paper introduces an innovative approach to\nAttention-deficit\/hyperactivity disorder (ADHD) diagnosis by em-\nploying deep learning (DL) techniques on electroencephalography\n(EEG) signals.  By utilizing a publicly available EEG\ndataset and converting the signals into spectrograms, a Resnet-18\nconvolutional neural network (CNN) architecture was used to ex-\ntract features for ADHD classification. ",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "EEG data for ADHD \/ Control children"
    ],
    "b_abstract":[
      "Participants were 61 children with ADHD and 60 healthy controls (boys and girls, ages 7-12). The ADHD children were diagnosed by an experienced psychiatrist to DSM-IV criteria, and have taken Ritalin for up to 6 months. None of the children in the control group had a history of psychiatric disorders, epilepsy, or any report of high-risk behaviors. EEG recording was performed based on 10-20 standard by 19 channels (Fz, Cz, Pz, C3, T3, C4, T4, Fp1, Fp2, F3, F4, F7, F8, P3, P4, T5, T6, O1, O2) at 128 Hz sampling frequency. The A1 and A2 electrodes were the references located on earlobes. Since one of the deficits in ADHD children is visual attention, the EEG recording protocol was based on visual attention tasks. In the task, a set of pictures of cartoon characters was shown to the children and they were asked to count the characters. The number of characters in each image was randomly selected between 5 and 16, and the size of the pictures was large enough to be easily visible and countable by children. To have a continuous stimulus during the signal recording, each image was displayed immediately and uninterrupted after the child\u2019s response. Thus, the duration of EEG recording throughout this cognitive visual task was dependent on the child\u2019s performance (i.e. response speed)."
    ],
    "b_categories":[
      "Neurotherapeutics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Deep Residual Learning for Image Recognition"
    ],
    "c_abstract":[
      "Deeper neural networks are more difficult to train. We present a residual learning framework ease the training of that substantially deeper than those used previously. explicitly reformulate layers as functions with reference layer inputs, instead unreferenced functions. provide comprehensive empirical evidence showing these easier optimize, and can gain accuracy from considerably increased depth. On ImageNet dataset we evaluate nets depth up 152 - 8\u00d7 VGG [40] but still having lower complexity. An ensemble achieves 3.57% error on test set. This result won 1st place ILSVRC 2015 classification task. also analysis CIFAR-10 100 1000 layers. The representations is central importance for many visual recognition tasks. Solely due our extremely deep representations, obtain 28% relative improvement COCO object detection dataset. Deep foundations submissions & competitions1, where places tasks detection, localization, segmentation."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03522",
    "a_title":"Exploring the Potentials and Challenges of Using Large Language Models\n  for the Analysis of Transcriptional Regulation of Long Non-coding RNAs",
    "a_abstract":"Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.",
    "explanation":"Given the tremendous success of large language mod-\nels (LLMs) in capturing complex dependencies in sequential data, this study aims to systematically explore the potential and limitations of LLMs in the sequence analysis related to the transcriptional regulation of lncRNA genes. ",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Language Models are Few-Shot Learners"
    ],
    "b_abstract":[
      "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training a large corpus of text followed fine-tuning specific task. While typically task-agnostic in architecture, this method still requires task-specific datasets thousands or tens examples. By contrast, humans can generally perform new language task from only few examples simple instructions - something which current systems largely struggle to do. Here we show that scaling up models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art approaches. Specifically, train GPT-3, an autoregressive model 175 billion parameters, 10x more than any previous non-sparse model, test its performance the setting. For all tasks, GPT-3 is applied without gradient updates fine-tuning, demonstrations specified purely via interaction model. achieves strong datasets, including translation, question-answering, cloze as well several require on-the-fly reasoning domain adaptation, such unscrambling words, using novel word sentence, performing 3-digit arithmetic. At same time, also identify some where GPT-3's learning struggles, faces methodological issues related training web corpora. Finally, find generate samples news articles human evaluators have difficulty distinguishing written humans. We discuss broader societal impacts finding general."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b20"
    ],
    "c_title":[
      "Long non-coding RNAs: definitions, functions, challenges and recommendations"
    ],
    "c_abstract":[
      "Genes specifying long non-coding RNAs (lncRNAs) occupy a large fraction of the genomes of complex organisms. The term \u2018lncRNAs\u2019 encompasses RNA polymerase I (Pol I), Pol II and Pol III transcribed RNAs, and RNAs from processed introns. The various functions of lncRNAs and their many isoforms and interleaved relationships with other genes make lncRNA classification and annotation difficult. Most lncRNAs evolve more rapidly than protein-coding sequences, are cell type specific and regulate many aspects of cell differentiation and development and other physiological processes. Many lncRNAs associate with chromatin-modifying complexes, are transcribed from enhancers and nucleate phase separation of nuclear condensates and domains, indicating an intimate link between lncRNA expression and the spatial control of gene expression during development. lncRNAs also have important roles in the cytoplasm and beyond, including in the regulation of translation, metabolism and signalling. lncRNAs often have a modular structure and are rich in repeats, which are increasingly being shown to be relevant to their function. In this Consensus Statement, we address the definition and nomenclature of lncRNAs and their conservation, expression, phenotypic visibility, structure and functions. We also discuss research challenges and provide recommendations to advance the understanding of the roles of lncRNAs in development, cell biology and disease."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17702",
    "a_title":"Finding \"Good Views\" of Electrocardiogram Signals for Inferring\n  Abnormalities in Cardiac Condition",
    "a_abstract":"Electrocardiograms (ECGs) are an established technique to screen for abnormal\ncardiac signals. Recent work has established that it is possible to detect\narrhythmia directly from the ECG signal using deep learning algorithms. While a\nfew prior approaches with contrastive learning have been successful, the best\nway to define a positive sample remains an open question. In this project, we\ninvestigate several ways to define positive samples, and assess which approach\nyields the best performance in a downstream task of classifying arrhythmia. We\nexplore spatiotemporal invariances, generic augmentations, demographic\nsimilarities, cardiac rhythms, and wave attributes of ECG as potential ways to\nmatch positive samples. We then evaluate each strategy with downstream task\nperformance, and find that learned representations invariant to patient\nidentity are powerful in arrhythmia detection. We made our code available in:\nhttps:\/\/github.com\/mandiehyewon\/goodviews_ecg.git",
    "explanation":"Recent work has established that it is possible to de-\ntect arrhythmia directly from the ECG signal using deep learning algorithms. While a few prior approaches with contrastive learning have been successful,\nthe best way to define a positive sample remains an open question.",
    "b_id":[
      "b5",
      "b11"
    ],
    "b_title":[
      "Patient Contrastive Learning: a Performant, Expressive, and Practical Approach to ECG Modeling.",
      "CLOCS: Contrastive Learning of Cardiac Signals Across Space, Time, and Patients"
    ],
    "b_abstract":[
      "Supervised machine learning applications in health care are often limited due to a scarcity of labeled training data. To mitigate this effect small sample size, we introduce pre-training approach, Patient Contrastive Learning Representations (PCLR), which creates latent representations ECGs from large number unlabeled examples. The resulting expressive, performant, and practical across wide spectrum clinical tasks. We develop PCLR using system with over 3.2 million 12-lead ECGs, demonstrate substantial improvements multiple new tasks when there fewer than 5,000 labels.",
      "The healthcare industry generates troves of unlabelled physiological data. This data can be exploited via contrastive learning, a self-supervised pre-training method that encourages representations instances to similar one another. We propose family learning methods, CLOCS, across space, time, \\textit{and} patients show CLOCS consistently outperforms the state-of-the-art BYOL and SimCLR, when performing linear evaluation of, fine-tuning on, downstream tasks. also achieves strong generalization performance with only 25\\% labelled training Furthermore, our procedure naturally patient-specific used quantify patient-similarity."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Screening for cardiac contractile dysfunction using an artificial intelligence-enabled electrocardiogram"
    ],
    "c_abstract":[
      "Asymptomatic left ventricular dysfunction (ALVD) is present in 3-6% of the general population, is associated with reduced quality of life and longevity, and is treatable when found1-4. An inexpensive, noninvasive screening tool for ALVD in the doctor's office is not available. We tested the hypothesis that application of artificial intelligence (AI) to the electrocardiogram (ECG), a routine method of measuring the heart's electrical activity, could identify ALVD. Using paired 12-lead ECG and echocardiogram data, including the left ventricular ejection fraction (a measure of contractile function), from 44,959 patients at the Mayo Clinic, we trained a convolutional neural network to identify patients with ventricular dysfunction, defined as ejection fraction \u226435%, using the ECG data alone. When tested on an independent set of 52,870 patients, the network model yielded values for the area under the curve, sensitivity, specificity, and accuracy of 0.93, 86.3%, 85.7%, and 85.7%, respectively. In patients without ventricular dysfunction, those with a positive AI screen were at 4 times the risk (hazard ratio, 4.1; 95% confidence interval, 3.3 to 5.0) of developing future ventricular dysfunction compared with those with a negative screen. Application of AI to the ECG-a ubiquitous, low-cost test-permits the ECG to serve as a powerful screening tool in asymptomatic individuals to identify ALVD."
    ],
    "c_categories":[
      "Cardio"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2412.20007",
    "a_title":"Uncertainty Quantified Deep Learning and Regression Analysis Framework\n  for Image Segmentation of Skin Cancer Lesions",
    "a_abstract":"Deep learning models (DLMs) frequently achieve accurate segmentation and\nclassification of tumors from medical images. However, DLMs lacking feedback on\ntheir image segmentation mechanisms, such as Dice coefficients and confidence\nin their performance, face challenges when processing previously unseen images\nin real-world clinical settings. Uncertainty estimates to identify DLM\npredictions at the cellular or single-pixel level that require clinician review\ncan enhance trust. However, their deployment requires significant computational\nresources. This study reports two DLMs, one trained from scratch and another\nbased on transfer learning, with Monte Carlo dropout or Bayes-by-backprop\nuncertainty estimations to segment lesions from the publicly available The\nInternational Skin Imaging Collaboration-19 dermoscopy image database with\ncancerous lesions. A novel approach to compute pixel-by-pixel uncertainty\nestimations of DLM segmentation performance in multiple clinical regions from a\nsingle dermoscopy image with corresponding Dice scores is reported for the\nfirst time. Image-level uncertainty maps demonstrated correspondence between\nimperfect DLM segmentation and high uncertainty levels in specific skin tissue\nregions, with or without lesions. Four new linear regression models that can\npredict the Dice performance of DLM segmentation using constants and\nuncertainty measures, either individually or in combination from lesions,\ntissue structures, and non-tissue pixel regions critical for clinical diagnosis\nand prognostication in skin images (Spearman's correlation, p < 0.05), are\nreported for the first time for low-compute uncertainty estimation workflows.",
    "explanation":"Deep learning models (DLMs) frequently achieve\naccurate segmentation and classification of tumors from medical\nimages.  DLMs lacking feedback on their image seg-\nmentation mechanisms such as Dice coefficients and confidence in\ntheir performance face challenges processing previously unseen\nimages in real-world clinical settings. A novel\napproach to compute pixel-by-pixel uncertainty estimations of\nDLM segmentation performance in multiple clinical regions from\na single dermatoscopy image with corresponding Dice scores\nis reported for the first time. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"
    ],
    "b_abstract":[
      "Deep learning tools have gained tremendous attention in applied machine learning. However such for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about uncertainty, but usually come with prohibitive computational cost. this paper we develop new theoretical casting dropout training deep neural networks (NNs) as approximate inference Gaussian processes. A direct result of theory gives us uncertainty NNs -- extracting information from existing that has been thrown away so far. This mitigates the problem representing without sacrificing either complexity or test accuracy. We perform an extensive study properties dropout's Various network architectures non-linearities are assessed on tasks classification, using MNIST example. show considerable improvement predictive log-likelihood RMSE compared state-of-the-art methods, finish by reinforcement"
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions"
    ],
    "c_abstract":[
      "Training of neural networks for automated diagnosis pigmented skin lesions is hampered by the small size and lack diversity available datasets dermatoscopic images. We tackle this problem releasing HAM10000 (\"Human Against Machine with 10000 training images\") dataset. collected images from different populations acquired stored modalities. Given we had to apply acquisition cleaning methods developed semi-automatic workflows utilizing specifically trained networks. The final dataset consists 10015 which are released as a set academic machine learning purposes publicly through ISIC archive. This benchmark can be used comparisons human experts. Cases include representative collection all important diagnostic categories in realm lesions. More than 50% have been confirmed pathology, while ground truth rest cases was either follow-up, expert consensus, or confirmation in-vivo confocal microscopy."
    ],
    "c_categories":[
      "Data"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05188",
    "a_title":"AGE2HIE: Transfer Learning from Brain Age to Predicting Neurocognitive\n  Outcome for Infant Brain Injury",
    "a_abstract":"Hypoxic-Ischemic Encephalopathy (HIE) affects 1 to 5 out of every 1,000\nnewborns, with 30% to 50% of cases resulting in adverse neurocognitive\noutcomes. However, these outcomes can only be reliably assessed as early as age\n2. Therefore, early and accurate prediction of HIE-related neurocognitive\noutcomes using deep learning models is critical for improving clinical\ndecision-making, guiding treatment decisions and assessing novel therapies.\nHowever, a major challenge in developing deep learning models for this purpose\nis the scarcity of large, annotated HIE datasets. We have assembled the first\nand largest public dataset, however it contains only 156 cases with 2-year\nneurocognitive outcome labels. In contrast, we have collected 8,859 normal\nbrain black Magnetic Resonance Imagings (MRIs) with 0-97 years of age that are\navailable for brain age estimation using deep learning models. In this paper,\nwe introduce AGE2HIE to transfer knowledge learned by deep learning models from\nhealthy controls brain MRIs to a diseased cohort, from structural to diffusion\nMRIs, from regression of continuous age estimation to prediction of the binary\nneurocognitive outcomes, and from lifespan age (0-97 years) to infant (0-2\nweeks). Compared to training from scratch, transfer learning from brain age\nestimation significantly improves not only the prediction accuracy (3% or 2%\nimprovement in same or multi-site), but also the model generalization across\ndifferent sites (5% improvement in cross-site validation).",
    "explanation":"Hypoxic-Ischemic Encephalopathy (HIE) affects 1 to 5 out of\nevery 1,000 newborns, with 30% to 50% of cases resulting in\nadverse neurocognitive outcomes. However, these outcomes\ncan only be reliably assessed as early as age 2. Therefore,\nearly and accurate prediction of HIE-related neurocognitive\noutcomes using deep learning models is critical for improv-\ning clinical decision-making, guiding treatment decisions and\nassessing novel therapies",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Limitations of conventional magnetic resonance imaging as a predictor of death or disability following neonatal hypoxic-ischemic encephalopathy in the late hypothermia trial"
    ],
    "b_abstract":[
      "Objective: To investigate if magnetic resonance imaging (MRI) is an accurate predictor for death or moderate-severe disability at 18-22 months of age among infants with neonatal encephalopathy in a trial of cooling initiated at 6-24 hours. Study design: Subgroup analysis of infants \u226536 weeks of gestation with moderate-severe neonatal encephalopathy randomized at 6-24 postnatal hours to hypothermia or usual care in a multicenter trial of late hypothermia. MRI scans were performed per each center's practice and interpreted by 2 central readers using the Eunice Kennedy Shriver National Institute of Child Health and Human Development injury score (6 levels, normal to hemispheric devastation). Neurodevelopmental outcomes were assessed at 18-22 months of age. Results: Of 168 enrollees, 128 had an interpretable MRI and were seen in follow-up (n = 119) or died (n = 9). MRI findings were predominantly acute injury and did not differ by cooling treatment. At 18-22 months, death or severe disability occurred in 20.3%. No infant had moderate disability. Agreement between central readers was moderate (weighted kappa 0.56, 95% CI 0.45-0.67). The adjusted odds of death or severe disability increased 3.7-fold (95% CI 1.8-7.9) for each increment of injury score. The area under the curve for severe MRI patterns to predict death or severe disability was 0.77 and the positive and negative predictive values were 36% and 100%, respectively. Conclusions: MRI injury scores were associated with neurodevelopmental outcome at 18-22 months among infants in the Late Hypothermia Trial. However, the results suggest caution when using qualitative interpretations of MRI images to provide prognostic information to families following perinatal hypoxia-ischemia."
    ],
    "b_categories":[
      "Pediatrics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "What is being transferred in transfer learning?"
    ],
    "c_abstract":[
      "One desired capability for machines is the ability to transfer their knowledge of one domain another where data (usually) scarce. Despite ample adaptation learning in various deep applications, we yet do not understand what enables a successful and which part network responsible that. In this paper, provide new tools analyses address these fundamental questions. Through series on transferring block-shuffled images, separate effect feature reuse from low-level statistics show that some benefit comes latter. We present when training pre-trained weights, model stays same basin loss landscape different instances such are similar space close parameter space."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19345",
    "a_title":"3D Wasserstein generative adversarial network with dense U-Net based\n  discriminator for preclinical fMRI denoising",
    "a_abstract":"Functional magnetic resonance imaging (fMRI) is extensively used in clinical\nand preclinical settings to study brain function, however, fMRI data is\ninherently noisy due to physiological processes, hardware, and external noise.\nDenoising is one of the main preprocessing steps in any fMRI analysis pipeline.\nThis process is challenging in preclinical data in comparison to clinical data\ndue to variations in brain geometry, image resolution, and low signal-to-noise\nratios. In this paper, we propose a structure-preserved algorithm based on a 3D\nWasserstein generative adversarial network with a 3D dense U-net based\ndiscriminator called, 3D U-WGAN. We apply a 4D data configuration to\neffectively denoise temporal and spatial information in analyzing preclinical\nfMRI data. GAN-based denoising methods often utilize a discriminator to\nidentify significant differences between denoised and noise-free images,\nfocusing on global or local features. To refine the fMRI denoising model, our\nmethod employs a 3D dense U-Net discriminator to learn both global and local\ndistinctions. To tackle potential over-smoothing, we introduce an adversarial\nloss and enhance perceptual similarity by measuring feature space distances.\nExperiments illustrate that 3D U-WGAN significantly improves image quality in\nresting-state and task preclinical fMRI data, enhancing signal-to-noise ratio\nwithout introducing excessive structural changes in existing methods. The\nproposed method outperforms state-of-the-art methods when applied to simulated\nand real data in a fMRI analysis pipeline.",
    "explanation":"Denoising is one of the main preprocessing steps in any fMRI analysis pipeline. In this\npaper, we propose a structure-preserved algorithm based on a 3D Wasserstein\ngenerative adversarial network with a 3D dense U-net based discriminator called,\n3D U-WGAN. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "On the use of preclinical imaging to explore the principles of brain function in rodent models and their relevance for illnesses of the human mind"
    ],
    "b_abstract":[
      "Dear Editor, We recently published in Translational Psychiatry an article that examine the strategies for evaluating brain function at the wholebrain level [1]. In this review, we covered several methods, from functional MRI to functional ultrasound to calcium imaging. For each technique, we wrote a brief history of its development, the physical notion, some key applications, its potentials, and its limitations. We concluded that methods for imaging the rodent brain at the network level are growing and will advance our understanding of brain function. A commentary by Zhuo and colleagues further enhances the complexity of addressing the issue of \u201ctranslation\u201d from animal models to patients for the discipline of psychiatry [2]. They propose that the approaches employed to develop an animal model for a psychiatric disease need to be thoroughly scrutinized and, perhaps, revised. For example, most rodent models of mental diseases are to-date established using a simple pharmacological infusion [3] and\/or psychosocial stimulation [4]. The key concern posed, however, is how these manipulations change the brain\u2019s structure and function, and whether these models genuinely reflect the pathophysiology of human mental illnesses. Especially since it is difficult to evaluate whether one can speak of inverse inference from rodents to humans. This is a true and acceptable statement. However, this is exactly what preclinical imaging aims to deliver. By mapping the dynamic responses of brain networks in animal models and compare them, if possible, with those reported in clinical studies, we can obtain quantitative data and parameters to establish whether our models are effectively translational [5]. If these metrics demonstrate temporal and spatial similarity in network-level modifications as those observed in humans, we can pursue further inquiry utilizing more intrusive and more specific methods for brain recordings in animal models. Otherwise, we must have the confidence and the correctness to move forward and attempt other solutions. Two recent examples. In 2019 we established a causal association between activity of the noradrenergic nucleus locus coeruleus (LC) and the engagement of numerous large-scale brain networks in mice, in particular of the salience and amygdala networks [6]. In addition, we could link network-changes with direct markers of norepinephrine (NE) turnover and with the distribution of NE receptors over the entire brain. The hypothesis that specific brain networks dynamics are related to LC activity and to NE receptor density derives from stress-research and pharmacological studies in humans [7, 8]. However, since it is impossible to selectively stimulate LC in people, it has remained a hypothesis for more than a decade. Our preclinical work helped confirm this causal relationship and this has direct implications for interpreting the results of clinical imaging studies on stress and anxiety behavior. More recently, the Gozzi lab described how chronic local neuronal suppression via overexpression of a potassium channel or acute silencing via chemogenetics result in a paradoxical hyperconnectivity [9]; an intriguing finding often reported in humans after stroke [10] and in early stages of Alzheimer\u2019s disease [11], but never truly understood. Using in vivo electrophysiology, they showed local inhibition improves low frequency (0.1\u20134 Hz) oscillatory power via suppression of neuronal activity not phaselocked to slow rhythms, resulting in increased slow and \u03b4 band coherence between areas that display fMRI overconnectivity. These data present causal evidence that cortical inactivation can counterintuitively augment fMRI connectivity via greater, lesslocalized slow oscillatory processes. Once again, this could be only achieved by combining functional MRI and electrophysiology with neuromodulation in animal models. These and other examples give a peek of what the future of preclinical imaging might look like: a field of research capable of delivering causal explanations to the hypotheses presented by human neuroscience, neurology and psychiatry. Lastly, I would argue against statements like \u201cthe computational complexity of human brains is billions of times that of mouse brain\u201d. While this may be true from a numerical standpoint of mere neuronal counts, preclinical neuroimaging\u2019s objective should not be per se to map every single neuron in real time but of identifying the general neural and cellular principles governing the assembly of brain networks and its breakdown in brain disorders. The field is relatively new but is moving fast and has already produced some important insights. The future is challenging and will require time, devotion and an optimal synergy between engineering, chemistry, biology, and computer science. If the community will be patient and supportive enough, there will be further important discoveries in the future."
    ],
    "b_categories":[
      "Psychiatry"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "GAN\uff08Generative Adversarial Nets\uff09"
    ],
    "c_abstract":[
      "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: model G that captures the data distribution, and discriminative D estimates probability sample came from training rather than G. The procedure is to maximize of making mistake. This corresponds minimax two-player game. In space arbitrary functions D, unique solution exists, with recovering distribution equal \u00bd everywhere. case where are defined by multilayer perceptrons, entire system can be trained backpropagation. There no need any Markov chains or unrolled approximate inference networks during either generation samples. Experiments demonstrate potential through qualitative quantitative evaluation generated"
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00688",
    "a_title":"Why do we regularise in every iteration for imaging inverse problems?",
    "a_abstract":"Regularisation is commonly used in iterative methods for solving imaging\ninverse problems. Many algorithms involve the evaluation of the proximal\noperator of the regularisation term in every iteration, leading to a\nsignificant computational overhead since such evaluation can be costly. In this\ncontext, the ProxSkip algorithm, recently proposed for federated learning\npurposes, emerges as an solution. It randomly skips regularisation steps,\nreducing the computational time of an iterative algorithm without affecting its\nconvergence. Here we explore for the first time the efficacy of ProxSkip to a\nvariety of imaging inverse problems and we also propose a novel PDHGSkip\nversion. Extensive numerical results highlight the potential of these methods\nto accelerate computations while maintaining high-quality reconstructions.",
    "explanation":"Regularisation is commonly used in iterative methods for solving imaging inverse problems. Here we explore for the first time the efficacy of ProxSkip to a variety of imaging inverse problems and we also propose a novel PDHGSkip version.",
    "b_id":[
      "b19"
    ],
    "b_title":[
      "Parameter-Free FISTA by Adaptive Restart and Backtracking"
    ],
    "b_abstract":[
      "We consider a combined restarting and adaptive backtracking strategy for the\npopular Fast Iterative Shrinking-Thresholding Algorithm frequently employed for\naccelerating the convergence speed of large-scale structured convex\noptimization problems. Several variants of FISTA enjoy a provable linear\nconvergence rate for the function values $F(x_n)$ of the form $\\mathcal{O}(\ne^{-K\\sqrt{\\mu\/L}~n})$ under the prior knowledge of problem conditioning, i.e.\nof the ratio between the (\\L ojasiewicz) parameter $\\mu$ determining the growth\nof the objective function and the Lipschitz constant $L$ of its smooth\ncomponent. These parameters are nonetheless hard to estimate in many practical\ncases. Recent works address the problem by estimating either parameter via\nsuitable adaptive strategies. In our work both parameters can be estimated at\nthe same time by means of an algorithmic restarting scheme where, at each\nrestart, a non-monotone estimation of $L$ is performed. For this scheme,\ntheoretical convergence results are proved, showing that a $\\mathcal{O}(\ne^{-K\\sqrt{\\mu\/L}n})$ convergence speed can still be achieved along with\nquantitative estimates of the conditioning. The resulting Free-FISTA algorithm\nis therefore parameter-free. Several numerical results are reported to confirm\nthe practical interest of its use in many exemplar problems."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Convex generalizations of total variation based on the structure tensor with applications to inverse problems"
    ],
    "c_abstract":[
      "We introduce a generic convex energy functional that is suitable for both grayscale and vector-valued images. Our functional is based on the eigenvalues of the structure tensor, therefore it penalizes image variation at every point by taking into account the information from its neighborhood. It generalizes several existing variational penalties, such as the Total Variation and vectorial extensions of it. By introducing the concept of patch-based Jacobian operator, we derive an equivalent formulation of the proposed regularizer that is based on the Schatten norm of this operator. Using this new formulation, we prove convexity and develop a dual definition for the proposed energy, which gives rise to an efficient and parallelizable minimization algorithm. Moreover, we establish a connection between the minimization of the proposed convex regularizer and a generic type of nonlinear anisotropic diffusion that is driven by a spatially regularized and adaptive diffusion tensor. Finally, we perform extensive experiments with image denoising and deblurring for grayscale and color images. The results show the effectiveness of the proposed approach as well as its improved performance compared to Total Variation and existing vectorial extensions of it."
    ],
    "c_categories":[
      "eess.IV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00036",
    "a_title":"Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial\n  Market Dynamics",
    "a_abstract":"We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.",
    "explanation":"The paper proposes the use of a new method using diffusion model generative methodology to produce synthetic market scenarios.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "On the Distribution of the Two-Sample Cramer-von Mises Criterion"
    ],
    "b_abstract":[
      "The Cramer-von Mises $\\omega^2$ criterion for testing that a sample, $x_1, \\cdots, x_N$, has been drawn from specified continuous distribution $F(x)$ is \\begin{equation*}\\tag{1}\\omega^2 = \\int^\\infty_{-\\infty} \\lbrack F_N(x) - F(x)\\rbrack^2 dF(x),\\end{equation*} where $F_N(x)$ the empirical function of sample; is, $F_N(x) k\/N$ if exactly $k$ observations are less than or equal to $x(k 0, 1, N)$. If there second $y_1, y_M$, test hypothesis two samples come same (unspecified) can be based on analogue $N\\omega^2$, namely \\begin{equation*}\\tag{2} T NM\/(N + M)\\rbrack G_M(x)\\rbrack^2 dH_{N+M}(x),\\end{equation*} $G_M(x)$ sample and $H_{N+M}(x)$ together [that $(N M)H_{N+M}(x) NF_N(x) MG_M(x)\\rbrack$. limiting $N\\omega^2$ as $N \\rightarrow \\infty$ tabulated [2], it shown ([3], [4a], [7]) $T$ \\infty, M \\infty$, $N\/M \\lambda$, $\\lambda$ any finite positive constant. In this note we consider small values $N$ $M$ present tables permit use at some conventional significance levels $M$. seems surprisingly good approximation exact moderate sizes (corresponding feature [6]). accuracy better in case two-sample Kolmogorov-Smirnov statistic studied by Hodges [4]."
    ],
    "b_categories":[
      "q-fin.GN"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "b24"
    ],
    "c_title":[
      "Quant GANs: deep generation of financial time series"
    ],
    "c_abstract":[
      "Modeling financial time series by stochastic processes is a challenging task and a central area of research in financial mathematics. As an alternative, we introduce Quant GANs, a data-driven model which is inspired by the recent success of generative adversarial networks (GANs). Quant GANs consist of a generator and discriminator function, which utilize temporal convolutional networks (TCNs) and thereby achieve to capture long-range dependencies such as the presence of volatility clusters. The generator function is explicitly constructed such that the induced stochastic process allows a transition to its risk-neutral distribution. Our numerical results highlight that distributional properties for small and large lags are in an excellent agreement and dependence properties such as volatility clusters, leverage effects, and serial autocorrelations can be generated by the generator function of Quant GANs, demonstrably in high fidelity."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00640",
    "a_title":"Adding Error Bars to Evals: A Statistical Approach to Language Model\n  Evaluations",
    "a_abstract":"Evaluations are critical for understanding the capabilities of large language\nmodels (LLMs). Fundamentally, evaluations are experiments; but the literature\non evaluations has largely ignored the literature from other sciences on\nexperiment analysis and planning. This article shows researchers with some\ntraining in statistics how to think about and analyze data from language model\nevaluations. Conceptualizing evaluation questions as having been drawn from an\nunseen super-population, we present formulas for analyzing evaluation data,\nmeasuring differences between two models, and planning an evaluation\nexperiment. We make a number of specific recommendations for running language\nmodel evaluations and reporting experiment results in a way that minimizes\nstatistical noise and maximizes informativeness.",
    "explanation":"This is an interdisciplinary work because it combines two different subjects: LLM and statistics. This suggests that we could also consider the error bars in the evaluations. ",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "Quantifying Variance in Evaluation Benchmarks"
    ],
    "b_abstract":[
      "Evaluation benchmarks are the cornerstone of measuring capabilities large language models (LLMs), as well driving progress in said capabilities. Originally designed to make claims about (or lack thereof) fully pretrained models, evaluation now also extensively used decide between various training choices. Despite this widespread usage, we rarely quantify variance our benchmarks, which dictates whether differences performance meaningful. Here, define and measure a range metrics geared towards including seed across initialisations, monotonicity during training. By studying number -- both openly available from scratch provide empirical estimates for variety metrics, with considerations recommendations practitioners. We evaluate utility tradeoffs continuous versus discrete measures explore options better understanding reducing variance. find that simple changes, such framing choice tasks (like MMLU) completion tasks, can often reduce smaller scale ($\\sim$7B) while more involved methods inspired human testing literature (such item analysis response theory) struggle meaningfully Overall, work provides insights into suggests LM-specific techniques variance, generally encourages practitioners carefully factor when comparing models."
    ],
    "b_categories":[
      "stat.ME"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "The Llama 3 Herd of Models"
    ],
    "c_abstract":[
      "Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18784",
    "a_title":"MRI Breast tissue segmentation using nnU-Net for biomechanical modeling",
    "a_abstract":"Integrating 2D mammography with 3D magnetic resonance imaging (MRI) is\ncrucial for improving breast cancer diagnosis and treatment planning. However,\nthis integration is challenging due to differences in imaging modalities and\nthe need for precise tissue segmentation and alignment. This paper addresses\nthese challenges by enhancing biomechanical breast models in two main aspects:\nimproving tissue identification using nnU-Net segmentation models and\nevaluating finite element (FE) biomechanical solvers, specifically comparing\nNiftySim and FEBio. We performed a detailed six-class segmentation of breast\nMRI data using the nnU-Net architecture, achieving Dice Coefficients of 0.94\nfor fat, 0.88 for glandular tissue, and 0.87 for pectoral muscle. The overall\nforeground segmentation reached a mean Dice Coefficient of 0.83 through an\nensemble of 2D and 3D U-Net configurations, providing a solid foundation for 3D\nreconstruction and biomechanical modeling. The segmented data was then used to\ngenerate detailed 3D meshes and develop biomechanical models using NiftySim and\nFEBio, which simulate breast tissue's physical behaviors under compression. Our\nresults include a comparison between NiftySim and FEBio, providing insights\ninto the accuracy and reliability of these simulations in studying breast\ntissue responses under compression. The findings of this study have the\npotential to improve the integration of 2D and 3D imaging modalities, thereby\nenhancing diagnostic accuracy and treatment planning for breast cancer.",
    "explanation":"Integrating 2D mammography with 3D magnetic resonance\nimaging (MRI) is crucial for improving breast cancer diagnosis and treat-\nment planning. However, this integration is challenging due to differences\nin imaging modalities and the need for precise tissue segmentation and\nalignment. This paper addresses these challenges by enhancing biome-\nchanical breast models in two main aspects: improving tissue identifica-\ntion using nnU-Net segmentation models and evaluating finite element\n(FE) biomechanical solvers, specifically comparing NiftySim and FEBio.\u00a0",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "nnu-net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "b_abstract":[
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Multimodal Breast Parenchymal Patterns Correlation Using a Patient-Specific Biomechanical Model"
    ],
    "c_abstract":[
      "In this paper, we aim to produce a realistic 2-D projection of the breast parenchymal distribution from a 3-D breast magnetic resonance image (MRI). To evaluate the accuracy of our simulation, we compare our results with the local breast density (i.e., density map) obtained from the complementary full-field digital mammogram. To achieve this goal, we have developed a fully automatic framework, which registers MRI volumes to X-ray mammograms using a subject-specific biomechanical model of the breast. The optimization step modifies the position, orientation, and elastic parameters of the breast model to perform the alignment between the images. When the model reaches an optimal solution, the MRI glandular tissue is projected and compared with the one obtained from the corresponding mammograms. To reduce the loss of information during the ray-casting, we introduce a new approach that avoids resampling the MRI volume. In the results, we focus our efforts on evaluating the agreement of the distributions of glandular tissue, the degree of structural similarity, and the correlation between the real and synthetic density maps. Our approach obtained a high-structural agreement regardless the glandularity of the breast, whilst the similarity of the glandular tissue distributions and correlation between both images increase in denser breasts. Furthermore, the synthetic images show continuity with respect to large structures in the density maps."
    ],
    "c_categories":[
      "Imaging"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00663",
    "a_title":"Deep Learning for Longitudinal Gross Tumor Volume Segmentation in\n  MRI-Guided Adaptive Radiotherapy for Head and Neck Cancer",
    "a_abstract":"Accurate segmentation of gross tumor volume (GTV) is essential for effective\nMRI-guided adaptive radiotherapy (MRgART) in head and neck cancer. However,\nmanual segmentation of the GTV over the course of therapy is time-consuming and\nprone to interobserver variability. Deep learning (DL) has the potential to\novercome these challenges by automatically delineating GTVs. In this study, our\nteam, $\\textit{UW LAIR}$, tackled the challenges of both pre-radiotherapy\n(pre-RT) (Task 1) and mid-radiotherapy (mid-RT) (Task 2) tumor volume\nsegmentation. To this end, we developed a series of DL models for longitudinal\nGTV segmentation. The backbone of our models for both tasks was SegResNet with\ndeep supervision. For Task 1, we trained the model using a combined dataset of\npre-RT and mid-RT MRI data, which resulted in the improved aggregated Dice\nsimilarity coefficient (DSCagg) on an internal testing set compared to models\ntrained solely on pre-RT MRI data. In Task 2, we introduced mask-aware\nattention modules, enabling pre-RT GTV masks to influence intermediate features\nlearned from mid-RT data. This attention-based approach yielded slight\nimprovements over the baseline method, which concatenated mid-RT MRI with\npre-RT GTV masks as input. In the final testing phase, the ensemble of 10\npre-RT segmentation models achieved an average DSCagg of 0.794, with 0.745 for\nprimary GTV (GTVp) and 0.844 for metastatic lymph nodes (GTVn) in Task 1. For\nTask 2, the ensemble of 10 mid-RT segmentation models attained an average\nDSCagg of 0.733, with 0.607 for GTVp and 0.859 for GTVn, leading us to\n$\\textbf{achieve 1st place}$. In summary, we presented a collection of DL\nmodels that could facilitate GTV segmentation in MRgART, offering the potential\nto streamline radiation oncology workflows. Our code and model weights are\navailable at https:\/\/github.com\/xtie97\/HNTS-MRG24-UWLAIR.",
    "explanation":"In this study, our team, UW LAIR, tackled the challenges of both pre-radiotherapy\n(pre-RT) (Task 1) and mid-radiotherapy (mid-RT) (Task 2) tumor volume seg-\nmentation. To this end, we developed a series of DL models for longitudinal GTV\nsegmentation",
    "b_id":[
      "b4",
      "b2"
    ],
    "b_title":[
      "Deep Learning for Automatic Gross Tumor Volumes Contouring in Esophageal Cancer Based on Contrast-Enhanced Computed Tomography Images: A Multi-Institutional Study",
      "ConTEXTual Net: A Multimodal Vision-Language Model for Segmentation of Pneumothorax"
    ],
    "b_abstract":[
      "Purpose To develop and externally validate an automatic artificial intelligence (AI) tool for delineating gross tumor volume (GTV) in patients with esophageal squamous cell carcinoma (ESCC), which can assist in neo-adjuvant or radical radiation therapy treatment planning. Methods and Materials In this multi-institutional study, contrast-enhanced CT images from 580 eligible ESCC patients were retrospectively collected. The GTV contours delineated by 2 experts via consensus were used as ground truth. A 3-dimensional deep learning model was developed for GTV contouring in the training cohort and internally and externally validated in 3 validation cohorts. The AI tool was compared against 12 board-certified experts in 25 patients randomly selected from the external validation cohort to evaluate its assistance in improving contouring performance and reducing variation. Contouring performance was measured using dice similarity coefficient (DSC) and average surface distance. Additionally, our previously established radiomics model for predicting pathologic complete response was used to compare AI-generated and ground truth contours, to assess the potential of the AI contouring tool in radiomics analysis. Results The AI tool demonstrated good GTV contouring performance in multicenter validation cohorts, with median DSC values of 0.865, 0.876, and 0.866 and median average surface distance values of 0.939, 0.789, and 0.875 mm, respectively. Furthermore, the AI tool significantly improved contouring performance for half of 12 board-certified experts (DSC values, 0.794-0.835 vs 0.856-0.881, P = .003-0.048), reduced the intra- and interobserver variations by 37.4% and 55.2%, respectively, and saved contouring time by 77.6%. In the radiomics analysis, 88.7% of radiomic features from ground truth and AI-generated contours demonstrated stable reproducibility, and similar pathologic complete response prediction performance for these contours (P = .430) was observed. Conclusions Our AI contouring tool can improve GTV contouring performance and facilitate radiomics analysis in ESCC patients, which indicates its potential for GTV contouring during radiation therapy treatment planning and radiomics studies.",
      "Radiology narrative reports often describe characteristics of a patient's disease, including its location, size, and shape. Motivated by the recent success multimodal learning, we hypothesized that this descriptive text could guide medical image analysis algorithms. We proposed novel vision-language model, ConTEXTual Net, for task pneumothorax segmentation on chest radiographs. Net extracts language features from physician-generated free-form radiology using pre-trained model. then introduced cross-attention between intermediate embeddings an encoder-decoder convolutional neural network to enable guidance analysis. was trained CANDID-PTX dataset consisting 3196 positive cases with annotations 6 different physicians as well clinical reports. Using cross-validation, achieved Dice score 0.716\u00b10.016, which similar degree inter-reader variability (0.712\u00b10.044) computed subset data. It outperformed vision-only models (Swin UNETR: 0.670\u00b10.015, ResNet50 U-Net: 0.677\u00b10.015, GLoRIA: 0.686\u00b10.014, nnUNet 0.694\u00b10.016) competing model (LAVT: 0.706\u00b10.009). Ablation studies confirmed it information led performance gains. Additionally, show certain augmentation methods degraded Net's breaking image-text concordance. also evaluated effects activation functions in module, highlighting efficacy our chosen architectural design."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "MRI-Guided Adaptive Radiation Therapy"
    ],
    "c_abstract":[
      "Magnetic resonance imaging-guided radiation therapy (MRIgRT) has improved soft tissue contrast over computed tomography (CT) based image-guided RT. Superior visualization of the target and surrounding radiosensitive structures has the potential to improve oncological outcomes partly due to safer dose-escalation and adaptive planning. In this review, we highlight the workflow of adaptive MRIgRT planning, which includes simulation imaging, daily MRI, identifying isocenter shifts, contouring, plan optimization, quality control, and delivery. Increased utilization of MRIgRT will depend on addressing technical limitations of this technology, while addressing treatment efficacy, cost-effectiveness, and workflow training."
    ],
    "c_categories":[
      "Oncology"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18602",
    "a_title":"Evaluating and Improving the Effectiveness of Synthetic Chest X-Rays for\n  Medical Image Analysis",
    "a_abstract":"Purpose: To explore best-practice approaches for generating synthetic chest\nX-ray images and augmenting medical imaging datasets to optimize the\nperformance of deep learning models in downstream tasks like classification and\nsegmentation. Materials and Methods: We utilized a latent diffusion model to\ncondition the generation of synthetic chest X-rays on text prompts and\/or\nsegmentation masks. We explored methods like using a proxy model and using\nradiologist feedback to improve the quality of synthetic data. These synthetic\nimages were then generated from relevant disease information or geometrically\ntransformed segmentation masks and added to ground truth training set images\nfrom the CheXpert, CANDID-PTX, SIIM, and RSNA Pneumonia datasets to measure\nimprovements in classification and segmentation model performance on the test\nsets. F1 and Dice scores were used to evaluate classification and segmentation\nrespectively. One-tailed t-tests with Bonferroni correction assessed the\nstatistical significance of performance improvements with synthetic data.\nResults: Across all experiments, the synthetic data we generated resulted in a\nmaximum mean classification F1 score improvement of 0.150453 (CI:\n0.099108-0.201798; P=0.0031) compared to using only real data. For\nsegmentation, the maximum Dice score improvement was 0.14575 (CI:\n0.108267-0.183233; P=0.0064). Conclusion: Best practices for generating\nsynthetic chest X-ray images for downstream tasks include conditioning on\nsingle-disease labels or geometrically transformed segmentation masks, as well\nas potentially using proxy modeling for fine-tuning such generations.",
    "explanation":"We utilized a latent diffusion model to condition the generation of synthetic chest X-rays on text prompts and\/or segmentation masks",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Rsna pneumonia detection challenge"
    ],
    "b_abstract":[
      "In this competition, you\u2019re challenged to build an algorithm to detect a visual signal for pneumonia in medical images. Specifically, your algorithm needs to automatically locate lung opacities on chest radiographs. Here\u2019s the backstory and why solving this problem matters. Pneumonia accounts for over 15% of all deaths of children under 5 years old internationally. In 2015, 920,000 children under the age of 5 died from the disease. In the United States, pneumonia accounts for over 500,000 visits to emergency departments [1] and over 50,000 deaths in 2015 [2], keeping the ailment on the list of top 10 causes of death in the country. While common, accurately diagnosing pneumonia is a tall order. It requires review of a chest radiograph (CXR) by highly trained specialists and confirmation through clinical history, vital signs and laboratory exams. Pneumonia usually manifests as an area or areas of increased opacity [3] on CXR. However, the diagnosis of pneumonia on CXR is complicated because of a number of other conditions in the lungs such as fluid overload (pulmonary edema), bleeding, volume loss (atelectasis or collapse), lung cancer, or post-radiation or surgical changes. Outside of the lungs, fluid in the pleural space (pleural effusion) also appears as increased opacity on CXR. When available, comparison of CXRs of the patient taken at different time points and correlation with clinical symptoms and history are helpful in making the diagnosis. CXRs are the most commonly performed diagnostic imaging study. A number of factors such as positioning of the patient and depth of inspiration can alter the appearance of the CXR [4], complicating interpretation further. In addition, clinicians are faced with reading high volumes of images every shift. To improve the efficiency and reach of diagnostic services, the Radiological Society of North America (RSNA\u00ae) has reached out to Kaggle\u2019s machine learning community and collaborated with the US National Institutes of Health, The Society of Thoracic Radiology, and MD.ai to develop a rich dataset for this challenge. The RSNA is an international society of radiologists, medical physicists and other medical professionals with more than 54,000 members from 146 countries across the globe. They see the potential for ML to automate initial detection (imaging screening) of potential pneumonia cases in order to prioritize and expedite their review. Challenge participants may be invited to present their AI models and methodologies during an award ceremony at the RSNA Annual Meeting which will be held in Chicago, Illinois, USA, from November 25-30, 2018."
    ],
    "b_categories":[
      "Imaging"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b14",
      "b9"
    ],
    "c_title":[
      "Adding Conditional Control to Text-to-Image Diffusion Models",
      "Highresolution image synthesis with latent diffusion models"
    ],
    "c_abstract":[
      "We present ControlNet, a neural network architecture to add spatial conditioning controls large, pretrained text-to-image diffusion models. ControlNet locks the production-ready large models, and reuses their deep robust encoding layers with billions of images as strong backbone learn diverse set conditional controls. The is connected \"zero convolutions\" (zero-initialized convolution layers) that progressively grow parameters from zero ensure no harmful noise could affect finetuning. test various controls, e.g., edges, depth, segmentation, human pose, etc., Stable Diffusion, using single or multiple conditions, without prompts. show training ControlNets small (<50k) (>1m) datasets. Extensive results may facilitate wider applications control image",
      "By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18902",
    "a_title":"MSEMG: Surface Electromyography Denoising with a Mamba-based Efficient\n  Network",
    "a_abstract":"Surface electromyography (sEMG) recordings can be contaminated by\nelectrocardiogram (ECG) signals when the monitored muscle is closed to the\nheart. Traditional signal-processing-based approaches, such as high-pass\nfiltering and template subtraction, have been used to remove ECG interference\nbut are often limited in their effectiveness. Recently, neural-network-based\nmethods have shown greater promise for sEMG denoising, but they still struggle\nto balance both efficiency and effectiveness. In this study, we introduce\nMSEMG, a novel system that integrates the Mamba State Space Model with a\nconvolutional neural network to serve as a lightweight sEMG denoising model. We\nevaluated MSEMG using sEMG data from the Non-Invasive Adaptive Prosthetics\ndatabase and ECG signals from the MIT-BIH Normal Sinus Rhythm Database. The\nresults show that MSEMG outperforms existing methods, generating higher-quality\nsEMG signals with fewer parameters. The source code for MSEMG is available at\nhttps:\/\/github.com\/tonyliu0910\/MSEMG.",
    "explanation":"Surface electromyography (sEMG) recordings can\nbe contaminated by electrocardiogram (ECG) signals when the\nmonitored muscle is closed to the heart. In this study, we introduce MSEMG, a novel\nsystem that integrates the Mamba state space model with a\nconvolutional neural network to serve as a lightweight sEMG\ndenoising mode",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "Biomechanics and motor control of human movement"
    ],
    "b_abstract":[
      "Preface to the Fourth Edition. 1 Biomechanics as an Interdiscipline. 1.0 Introduction. 1.1 Measurement, Description, Analysis, and Assessment. 1.2 its Relationship with Physiology Anatomy. 1.3 Scope of Textbook. 1.4 References. 2 Signal Processing. 2.0 2.1 Auto- Cross-Correlation Analyses. 2.2 Frequency Analysis. 2.3 Ensemble Averaging Repetitive Waveforms. 2.4 3 Kinematics. 3.0 Historical Development Complexity Problem. 3.1 Kinematic Conventions. 3.2 Direct Measurement Techniques. 3.3 Imaging 3.4 Processing Raw Data. 3.5 Calculation Other Variables. 3.6 Problems Based on 3.7 4 Anthropometry. 4.0 Anthropometry in Movement Biomechanics. 4.1 Density, Mass, Inertial Properties. 4.2 Experimental Measures. 4.3 Muscle 4.4 Anthropometric 4.5 5 Kinetics: Forces Moments Force. 5.0 Biomechanical Models. 5.1 Basic Link-Segment Equations-the Free-Body Diagram. 5.2 Force Transducers Plates. 5.3 Bone-on-Bone During Dynamic Conditions. 5.4 Kinetic 5.5 6 Mechanical Work, Energy, Power. 6.0 6.1 Efficiency. 6.2 Forms Energy Storage. 6.3 Internal External Work. 6.4 Power Balances at Joints Within Segments. 6.5 6.6 7 Three-Dimensional Kinematics Kinetics. 7.0 7.1 Axes Systems. 7.2 Marker Anatomical 7.3 Determination Segment Angular Velocities Accelerations. 7.4 Analysis Reaction Moments. 7.5 Suggested Further Reading. 7.6 8 Synthesis Human Movement-Forward Solutions. 8.0 8.1 Review Forward Solution 8.2 Mathematical Formulation. 8.3 System Energy. 8.4 Torques. 8.5 Designation Joints. 8.6 Illustrative Example. 8.7 Conclusions. 8.8 9 Mechanics. 9.0 9.1 Force-Length Characteristics Muscles. 9.2 Force-Velocity Characteristics. 9.3 Modeling. 9.4 10 Kinesiological Electromyography. 10.0 10.1 Electrophysiology Contraction. 10.2 Recording Electromyogram. 10.3 Electromyogram,. 10.4 between Electromyogram 10.5 11 Synergies. 11.0 11.1 The Support Moment Synergy. 11.2 Medial\/Lateral Anterior\/Posterior Balance Standing. 11.3 during Walking. 11.4 APPENDICES. A. Kinematic, Kinetic, Figure A.1 Walking Trial-Marker Locations Mass Frame Rate Information. Table Coordinate Data (cm). A.2( a ) Filtered Kinematics-Rib Cage Greater Trochanter (Hip). b Kinematics-Femoral Lateral Epicondyle (Knee) Head Fibula. c Kinematics-Lateral Malleolus (Ankle) Heel. d Kinematics-Fifth Metatarsal Toe. A.3( Linear Kinematics-Foot. Kinematics-Leg. Kinematics-Thigh. Kinematics-1\/2 HAT. A.4 Relative Joint Kinematics-Ankle, Knee, Hip. A.5( Force-Ankle Knee. Force-Hip. A.6 Potential, Total Energies-Foot, Leg, Thigh, and1\/2 A.7 Generation\/Absorption Transfer-Ankle, B. Units Definitions Related Electromyographical Measurements. B.1 Base SI Units. B.2 Derived Index."
    ],
    "b_categories":[
      "Biomechanics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"
    ],
    "c_abstract":[
      "Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution recurrent structured state space models (SSMs) have been developed to address Transformers' computational inefficiency long sequences, but they not performed well important modalities language. We identify that a key weakness is their inability perform content-based reasoning, make several improvements. First, simply letting SSM parameters be functions input addresses with discrete modalities, allowing model selectively propagate or forget information along sequence length dimension depending current token. Second, even though this change prevents use efficient convolutions, we design hardware-aware parallel algorithm mode. integrate these selective SSMs into simplified end-to-end neural network without MLP blocks (Mamba). Mamba enjoys fast inference (5$\\times$ higher throughput than Transformers) scaling length, performance improves real data up million-length sequences. As general backbone, achieves state-of-the-art across language, audio, genomics. On language modeling, our Mamba-3B outperforms Transformers same size matches twice size, both pretraining downstream evaluation."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03551",
    "a_title":"Enhancing Weakly Supervised Semantic Segmentation for Fibrosis via\n  Controllable Image Generation",
    "a_abstract":"Fibrotic Lung Disease (FLD) is a severe condition marked by lung stiffening\nand scarring, leading to respiratory decline. High-resolution computed\ntomography (HRCT) is critical for diagnosing and monitoring FLD; however,\nfibrosis appears as irregular, diffuse patterns with unclear boundaries,\nleading to high inter-observer variability and time-intensive manual\nannotation. To tackle this challenge, we propose DiffSeg, a novel weakly\nsupervised semantic segmentation (WSSS) method that uses image-level\nannotations to generate pixel-level fibrosis segmentation, reducing the need\nfor fine-grained manual labeling. Additionally, our DiffSeg incorporates a\ndiffusion-based generative model to synthesize HRCT images with different\nlevels of fibrosis from healthy slices, enabling the generation of the\nfibrosis-injected slices and their paired fibrosis location. Experiments\nindicate that our method significantly improves the accuracy of pseudo masks\ngenerated by existing WSSS methods, greatly reducing the complexity of manual\nlabeling and enhancing the consistency of the generated masks.",
    "explanation":"However, fibrosis appears\nas irregular, diffuse patterns with unclear boundaries, lead-\ning to high inter-observer variability and time-intensive man-\nual annotation. To tackle this challenge, we propose DiffSeg,\na novel weakly supervised semantic segmentation (WSSS)\nmethod that uses image-level annotations to generate pixel-\nlevel fibrosis segmentation, reducing the need for fine-grained\nmanual labeling. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Interobserver Variability in the CT Assessment of Honeycombing in the Lungs"
    ],
    "b_abstract":[
      "To quantify observer agreement and analyze causes of disagreement in identifying honeycombing at chest computed tomography (CT).The institutional review board approved this multiinstitutional HIPAA-compliant retrospective study, informed patient consent was not required. Five core study members scored 80 CT images with a five-point scale (5 = definitely yes to 1 no) establish reference standard for the identification honeycombing. Forty-three observers from various subspecialties geographic regions by using same scoring system. Weighted \u03ba values scores compared were analyzed investigate intergroup differences. Images divided into four groups allow analysis imaging features cases which there disagreement: on presence honeycombing, absence other (none preceding three applied).Agreement 43 moderate (Cohen weighted values: 0.40-0.58). There no significant differences among defined either subspecialty or region (Tukey-Kramer test, P .38 >.99). In 29% cases, These included mixed traction bronchiectasis, large cysts, superimposed pulmonary emphysema.Identification is subjective, largely caused conditions that mimic"
    ],
    "b_categories":[
      "Radiology"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "DuPL: Dual Student with Trustworthy Progressive Learning for Robust Weakly Supervised Semantic Segmentation"
    ],
    "c_abstract":[
      "Recently, One-stage Weakly Supervised Semantic Segmentation (WSSS) with image-level labels has gained increasing interest due to simplification over its cumbersome multi-stage counterpart. Limited by the inherent ambiguity of Class Activation Map (CAM), we observe that one-stage pipelines often encounter confirmation bias caused by incorrect CAM pseudo-labels, impairing their final segmentation performance. Although recent works discard many unreliable pseudo-labels to implicitly alleviate this issue, they fail to exploit sufficient supervision for their models. To this end, we propose a dual student framework with trustworthy progressive learning (DuPL). Specifically, we propose a dual student network with a discrepancy loss to yield diverse CAMs for each sub-net. The two sub-nets generate supervision for each other, mitigating the confirmation bias caused by learning their own incorrect pseudo-labels. In this process, we progressively introduce more trustworthy pseudo-labels to be involved in the supervision through dynamic threshold adjustment with an adaptive noise filtering strategy. Moreover, we believe that every pixel, even discarded from supervision due to its unreliability, is important for WSSS. Thus, we develop consistency regularization on these discarded regions, providing supervision of every pixel. Experiment results demonstrate the superiority of the proposed DuPL over the recent state-of-the-art alternatives on PASCAL VOC 2012 and MS COCO datasets."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.09469",
    "a_title":"An Explainable Attention Model for Cervical Precancer Risk\n  Classification using Colposcopic Images",
    "a_abstract":"Cervical cancer remains a major worldwide health issue, with early\nidentification and risk assessment playing critical roles in effective\npreventive interventions. This paper presents the Cervix-AID-Net model for\ncervical precancer risk classification. The study designs and evaluates the\nproposed Cervix-AID-Net model based on patients colposcopy images. The model\ncomprises a Convolutional Block Attention Module (CBAM) and convolutional\nlayers that extract interpretable and representative features of colposcopic\nimages to distinguish high-risk and low-risk cervical precancer. In addition,\nthe proposed Cervix-AID-Net model integrates four explainable techniques,\nnamely gradient class activation maps, Local Interpretable Model-agnostic\nExplanations, CartoonX, and pixel rate distortion explanation based on output\nfeature maps and input features. The evaluation using holdout and ten-fold\ncross-validation techniques yielded a classification accuracy of 99.33\\% and\n99.81\\%. The analysis revealed that CartoonX provides meticulous explanations\nfor the decision of the Cervix-AID-Net model due to its ability to provide the\nrelevant piece-wise smooth part of the image. The effect of Gaussian noise and\nblur on the input shows that the performance remains unchanged up to Gaussian\nnoise of 3\\% and blur of 10\\%, while the performance reduces thereafter. A\ncomparison study of the proposed model's performance compared to other deep\nlearning approaches highlights the Cervix-AID-Net model's potential as a\nsupplemental tool for increasing the effectiveness of cervical precancer risk\nassessment. The proposed method, which incorporates the CBAM and explainable\nartificial integration, has the potential to influence cervical cancer\nprevention and early detection, improving patient outcomes and lowering the\nworldwide burden of this preventable disease.",
    "explanation":"This paper presents the Cervix-AID-Net model for cervical precancer risk classification. The study designs and evaluates the proposed Cervix-\nAID-Net model based on patients colposcopy images. The model comprises a Convolutional Block\nAttention Module (CBAM) and convolutional layers that extract interpretable and representative\nfeatures of colposcopic images to distinguish high-risk and low-risk cervical precancer. ",
    "b_id":[
      "b36"
    ],
    "b_title":[
      "CBAM: Convolutional block attention module"
    ],
    "b_abstract":[
      "We propose Convolutional Block Attention Module (CBAM), a simple yet effective attention module for feed-forward convolutional neural networks. Given an intermediate feature map, our module sequentially infers attention maps along two separate dimensions, channel and spatial, then the attention maps are multiplied to the input feature map for adaptive feature refinement. Because CBAM is a lightweight and general module, it can be integrated into any CNN architectures seamlessly with negligible overheads and is end-to-end trainable along with base CNNs. We validate our CBAM through extensive experiments on ImageNet-1K, MS~COCO detection, and VOC~2007 detection datasets. Our experiments show consistent improvements in classification and detection performances with various models, demonstrating the wide applicability of CBAM. The code and models will be publicly available."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "The accuracy of colposcopic biopsy: Analyses from the placebo arm of the Gardasil clinical trials"
    ],
    "c_abstract":[
      "We evaluated the overall agreement between colposcopically directed biopsies and definitive excisional specimens within context of three clinical trials. A total 737 women aged 16-45 who had a cervical biopsy taken 6 months before their therapy were included. Per-protocol, colposcopists to also obtain representative immediately therapy. Using adjudicated histological diagnoses, initial same day correlated with surgically excised specimens. The therapy, diagnoses was 42% (weighted kappa = 0.34) (95% CI: 0.29-0.39). underestimation intraepithelial neoplasia grade 2\/3 or adenocarcinoma in situ (CIN2-3\/AIS) CIN3\/AIS 26 42%, respectively. When allowing for one degree variance correlation, 92% CIN2-3\/AIS. specimen 56% 0.41) 0.36-0.47), CIN2-3\/AIS 57%. There significant associations when patients stratified by age, number biopsies, lesion size, presence human papillomavirus (HPV)16\/18 region. Of 178 diagnostic endocervical curettages performed, 14 (7.9%) found any HPV disease. Colposcopic accuracy improved CIN2 grouped as single predictive measure high-grade Colposcopy functioned well allowed one-degree difference surgical histologic interpretations, done practice. Taking more than colposcopic could improve patient management."
    ],
    "c_categories":[
      "Clinical Trial"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.14752",
    "a_title":"Comparative Analysis of nnUNet and MedNeXt for Head and Neck Tumor\n  Segmentation in MRI-guided Radiotherapy",
    "a_abstract":"Radiation therapy (RT) is essential in treating head and neck cancer (HNC),\nwith magnetic resonance imaging(MRI)-guided RT offering superior soft tissue\ncontrast and functional imaging. However, manual tumor segmentation is\ntime-consuming and complex, and therfore remains a challenge. In this study, we\npresent our solution as team TUMOR to the HNTS-MRG24 MICCAI Challenge which is\nfocused on automated segmentation of primary gross tumor volumes (GTVp) and\nmetastatic lymph node gross tumor volume (GTVn) in pre-RT and mid-RT MRI\nimages. We utilized the HNTS-MRG2024 dataset, which consists of 150 MRI scans\nfrom patients diagnosed with HNC, including original and registered pre-RT and\nmid-RT T2-weighted images with corresponding segmentation masks for GTVp and\nGTVn. We employed two state-of-the-art models in deep learning, nnUNet and\nMedNeXt. For Task 1, we pretrained models on pre-RT registered and mid-RT\nimages, followed by fine-tuning on original pre-RT images. For Task 2, we\ncombined registered pre-RT images, registered pre-RT segmentation masks, and\nmid-RT data as a multi-channel input for training. Our solution for Task 1\nachieved 1st place in the final test phase with an aggregated Dice Similarity\nCoefficient of 0.8254, and our solution for Task 2 ranked 8th with a score of\n0.7005. The proposed solution is publicly available at Github Repository.",
    "explanation":"Radiation therapy (RT) is essential in treating head and neck cancer\n(HNC), with magnetic resonance imaging(MRI)-guided RT offering superior soft tis-\nsue contrast and functional imaging. However, manual tumor segmentation is time-\nconsuming and complex, and therfore remains a challenge. In this study, we present\nour solution as team TUMOR to the HNTS-MRG24 MICCAI Challenge which is\nfocused on automated segmentation of primary gross tumor volumes (GTVp) and\nmetastatic lymph node gross tumor volume (GTVn) in pre-RT and mid-RT MRI im-\nages. We employed two state-of-the-art models in deep learning, nnUNet and MedNeXt.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "\u201cApr\u00e8s Mois, Le D\u00e9luge\u201d: Preparing for the Coming Data Flood in the MRI-Guided Radiotherapy Era"
    ],
    "b_abstract":[
      "Magnetic resonance imaging provides a sea of quantitative and semi-quantitative data. While radiation oncologists already navigate pool clinical (semantic) data, the tide will swell with advent hybrid MRI\/linear accelerator devices increasing interest in MRI-guided radiotherapy (MRIgRT), including adaptive MRIgRT. The variety MR sequences (of greater complexity than single parameter Hounsfield unit CT scanning routinely used radiotherapy), workflow fractionation, sheer quantity daily images acquired are challenges for scaling this technology. Biomedical informatics, which is science information biomedicine, can provide helpful insights looming transition. Funneling MRIgRT data into clinically meaningful streams requires committing to flow inter-institutional accessibility interoperability initiatives, standardizing dosimetry methods, streamlining linear workflow, MRI acquisition post-processing, current topic review attempt conceptually ford using informatics approaches as theoretical bridge."
    ],
    "b_categories":[
      "Oncology"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation",
      "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "c_abstract":[
      "There has been exploding interest in embracing Transformer-based architectures for medical image segmentation. However, the lack of large-scale annotated medical datasets make achieving performances equivalent to those in natural images challenging. Convolutional networks, in contrast, have higher inductive biases and consequently, are easily trainable to high performance. Recently, the ConvNeXt architecture attempted to modernize the standard ConvNet by mirroring Transformer blocks. In this work, we improve upon this to design a modernized and scalable convolutional architecture customized to challenges of data-scarce medical settings. We introduce MedNeXt, a Transformer-inspired large kernel segmentation network which introduces - 1) A fully ConvNeXt 3D Encoder-Decoder Network for medical image segmentation, 2) Residual ConvNeXt up and downsampling blocks to preserve semantic richness across scales, 3) A novel technique to iteratively increase kernel sizes by upsampling small kernel networks, to prevent performance saturation on limited medical data, 4) Compound scaling at multiple levels (depth, width, kernel size) of MedNeXt. This leads to state-of-the-art performance on 4 tasks on CT and MRI modalities and varying dataset sizes, representing a modernized deep architecture for medical image segmentation. Our code is made publicly available at: https:\/\/github.com\/MIC-DKFZ\/MedNeXt.",
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06785",
    "a_title":"White-Box Diffusion Transformer for single-cell RNA-seq generation",
    "a_abstract":"As a powerful tool for characterizing cellular subpopulations and cellular\nheterogeneity, single cell RNA sequencing (scRNA-seq) technology offers\nadvantages of high throughput and multidimensional analysis. However, the\nprocess of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a hybrid model\nbased on Diffusion model and White-Box transformer that aims to generate\nsynthetic and biologically plausible scRNA-seq data. Diffusion model\nprogressively introduce noise into the data and then recover the original data\nthrough a denoising process, a forward and reverse process that is particularly\nsuitable for generating complex data distributions. White-Box transformer is a\ndeep learning architecture that emphasizes mathematical interpretability. By\nminimizing the encoding rate of the data and maximizing the sparsity of the\nrepresentation, it not only reduces the computational burden, but also provides\nclear insight into underlying structure. Our White-Box Diffusion Transformer\ncombines the generative capabilities of Diffusion model with the mathematical\ninterpretability of White-Box transformer. Through experiments using six\ndifferent single-cell RNA-Seq datasets, we visualize both generated and real\ndata using t-SNE dimensionality reduction technique, as well as quantify\nsimilarity between generated and real data using various metrics to demonstrate\ncomparable performance of White-Box Diffusion Transformer and Diffusion\nTransformer in generating scRNA-seq data alongside significant improvements in\ntraining efficiency and resource utilization. Our code is available at\nhttps:\/\/github.com\/lingximamo\/White-Box-Diffusion-Transformer",
    "explanation":"As a powerful tool for characterizing cellular subpopulations and cellular heterogeneity, single cell\nRNA sequencing (scRNA-seq) technology offers advantages of high throughput and multidimensional\nanalysis. However, the process of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a model based on Diffusion model\nand White-Box transformer that aims to generate synthetic and biologically plausible scRNA-seq\ndata.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "RNA-Seq: a revolutionary tool for transcriptomics"
    ],
    "b_abstract":[
      "RNA-Seq is a recently developed approach to transcriptome profiling that uses deep-sequencing technologies. Studies using this method have already altered our view of the extent and complexity of eukaryotic transcriptomes. RNA-Seq also provides a far more precise measurement of levels of transcripts and their isoforms than other methods. This article describes the RNA-Seq approach, the challenges associated with its application, and the advances made so far in characterizing several eukaryote transcriptomes."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "White-Box Transformers via Sparse Rate Reduction"
    ],
    "c_abstract":[
      "In this paper, we contend that the objective of representation learning is to compress and transform distribution data, say sets tokens, towards a mixture low-dimensional Gaussian distributions supported on incoherent subspaces. The quality final can be measured by unified function called sparse rate reduction. From perspective, popular deep networks such as transformers naturally viewed realizing iterative schemes optimize incrementally. Particularly, show standard transformer block derived from alternating optimization complementary parts objective: multi-head self-attention operator gradient descent step token minimizing their lossy coding rate, subsequent multi-layer perceptron attempting sparsify tokens. This leads family white-box transformer-like network architectures which are mathematically fully interpretable. Despite simplicity, experiments these indeed learn designed they representations large-scale real-world vision datasets ImageNet, achieve performance very close thoroughly engineered ViT."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00868",
    "a_title":"Quantifying perturbation impacts for large language models",
    "a_abstract":"We consider the problem of quantifying how an input perturbation impacts the\noutputs of large language models (LLMs), a fundamental task for model\nreliability and post-hoc interpretability. A key obstacle in this domain is\ndisentangling the meaningful changes in model responses from the intrinsic\nstochasticity of LLM outputs. To overcome this, we introduce Distribution-Based\nPerturbation Analysis (DBPA), a framework that reformulates LLM perturbation\nanalysis as a frequentist hypothesis testing problem. DBPA constructs empirical\nnull and alternative output distributions within a low-dimensional semantic\nsimilarity space via Monte Carlo sampling. Comparisons of Monte Carlo estimates\nin the reduced dimensionality space enables tractable frequentist inference\nwithout relying on restrictive distributional assumptions. The framework is\nmodel-agnostic, supports the evaluation of arbitrary input perturbations on any\nblack-box LLM, yields interpretable p-values, supports multiple perturbation\ntesting via controlled error rates, and provides scalar effect sizes for any\nchosen similarity or distance metric. We demonstrate the effectiveness of DBPA\nin evaluating perturbation impacts, showing its versatility for perturbation\nanalysis.",
    "explanation":"\"We consider the problem of quantifying how an input perturbation impacts the outputs of large language models (LLMs), a fundamental task for model reliability and post-hoc interpretability.\"",
    "b_id":[
      "b22"
    ],
    "b_title":[
      "Context-Aware Testing: A New Paradigm for Model Testing with Large\n  Language Models"
    ],
    "b_abstract":[
      "The predominant de facto paradigm of testing ML models relies on either using\nonly held-out data to compute aggregate evaluation metrics or by assessing the\nperformance on different subgroups. However, such data-only testing methods\noperate under the restrictive assumption that the available empirical data is\nthe sole input for testing ML models, disregarding valuable contextual\ninformation that could guide model testing. In this paper, we challenge the\ngo-to approach of data-only testing and introduce context-aware testing (CAT)\nwhich uses context as an inductive bias to guide the search for meaningful\nmodel failures. We instantiate the first CAT system, SMART Testing, which\nemploys large language models to hypothesize relevant and likely failures,\nwhich are evaluated on data using a self-falsification mechanism. Through\nempirical evaluations in diverse settings, we show that SMART automatically\nidentifies more relevant and impactful failures than alternatives,\ndemonstrating the potential of CAT as a testing paradigm."
    ],
    "b_categories":[
      "stat.ME"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "How resilient are language models to text perturbations"
    ],
    "c_abstract":[
      "Large language models typically rely on highly curated datasets that lack common irregularities such as typos and contractions, resulting in a mismatch between their training environments and real-world applications. This study evaluates the resilience of four prominent models in five different NLP tasks when confronted with perturbed inputs. We investigate three categories of perturbations: character-level, word-level and miscellaneous perturbations. By comparing performance on original and altered datasets, our results reveal a significant sensitivity to input perturbations across all models, with varying degrees of vulnerability depending on both the specific task and the type of perturbation. In particular, the XLNet model consistently shows superior robustness, while tasks involving grammatical coherence are most adversely affected."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01668",
    "a_title":"Linear Quadratic Mean Field Games with Quantile-Dependent Cost\n  Coefficients",
    "a_abstract":"This paper studies a class of linear quadratic mean field games where the\ncoefficients of quadratic cost functions depend on both the mean and the\nvariance of the population's state distribution through its quantile function.\nSuch a formulation allows for modelling agents that are sensitive to not only\nthe population average but also the population variance. The corresponding mean\nfield game equilibrium is identified, which involves solving two coupled\ndifferential equations: one is a Riccati equation and the other the variance\nevolution equation. Furthermore, the conditions for the existence and\nuniqueness of the mean field equilibrium are established. Finally, numerical\nresults are presented to illustrate the behavior of two coupled differential\nequations and the performance of the mean field game solution.",
    "explanation":"\"This paper studies a class of linear quadratic mean field games where the coefficients of quadratic cost functions depend on both the mean and the variance of the population\u2019s state distribution through its quantile function. \"\n\n\n",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Mean\u2010field games with differing beliefs for algorithmic trading"
    ],
    "b_abstract":[
      "Abstract Even when confronted with the same data, agents often disagree on a model of real world. Here, we address question how interacting heterogeneous agents, who what world follows, optimize their trading actions. The market has latent factors that drive prices, and account for permanent impact they have prices. This leads to large stochastic game, where each performance criteria are computed under different probability measure. We analyze mean\u2010field game (MFG) limit show Nash equilibrium is given by solution nonstandard vector\u2010valued forward\u2013backward differential equation. Under some mild assumptions, construct in terms expectations filtered states. Furthermore, prove MFG strategy forms an \u03b5\u2010Nash finite player game. Finally, present least square Monte Carlo based algorithm computing equilibria through simulations increasing disagreement may increase price volatility activity."
    ],
    "b_categories":[
      "q-fin.MF"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Linear-quadratic mean field games"
    ],
    "c_abstract":[
      "In this article, we provide a comprehensive study of the linear-quadratic mean field games via the adjoint equation approach; although the problem has been considered in the literature by Huang, Caines and Malhame (HCM, 2007a), their method is based on Dynamic Programming. It turns out that two methods are not equivalent, as far as giving sufficient condition for the existence of a solution is concerned. Due to the linearity of the adjoint equations, the optimal mean field term satisfies a linear forward-backward ordinary differential equation. For the one dimensional case, we show that the equilibrium strategy always exists uniquely. For dimension greater than one, by choosing a suitable norm and then applying the Banach Fixed Point Theorem, a sufficient condition, which is independent of the solution of the standard Riccati differential equation, for the unique existence of the equilibrium strategy is provided. As a by-product, we also establish a neat and instructive sufficient condition for the unique existence of the solution for a class of non-trivial nonsymmetric Riccati equations. Numerical examples of non-existence of the equilibrium strategy and the comparison of HCM's approach will also be provided."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.00575",
    "a_title":"A Semi-Discrete Optimal Transport Scheme for the 3D Incompressible\n  Semi-Geostrophic Equations",
    "a_abstract":"We describe a mesh-free three-dimensional numerical scheme for solving the\nincompressible semi-geostrophic equations based on semi-discrete optimal\ntransport techniques. These results generalise previous two-dimensional\nimplementations. The optimal transport methods we adopt are known for their\nstructural preservation and energy conservation qualities and achieve an\nexcellent level of efficiency and numerical energy-conservation. We use this\nscheme to generate numerical simulations of an important cyclone benchmark\nproblem. To our knowledge, this is the first fully three-dimensional simulation\nof the semi-geostrophic equations, evidencing semi-discrete optimal transport\nas a novel, robust numerical tool for meteorological and oceanographic\nmodelling.",
    "explanation":"We describe a mesh-free three-dimensional numerical scheme for solving the in-\ncompressible semi-geostrophic equations based on semi-discrete optimal transport techniques.\nThese results generalise previous two-dimensional implementations.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Weak Existence for the Semigeostrophic Equations Formulated as a Coupled Monge--Amp\u00e8re\/Transport Problem"
    ],
    "b_abstract":[
      "Hoskins's semigeostrophic equations are reformulated as a coupled Monge--Amp\u00e8re\/ transport problem [B. J. Hoskins, Quart. Royal Met. Soc., 97 (1971), pp. 139--153]. Existence of global weak solutions is obtained for this formulation."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b22"
    ],
    "c_title":[
      "Vertical slice modelling of nonlinear Eady waves using a compatible finite element method"
    ],
    "c_abstract":[
      "A vertical slice model is developed for the Euler-Boussinesq equations with a\nconstant temperature gradient in the direction normal to the slice (the\nEady-Boussinesq model). The model is a solution of the full three-dimensional\nequations with no variation normal to the slice, which is an idealized problem\nused to study the formation and subsequent evolution of weather fronts. A\ncompatible finite element method is used to discretise the governing equations.\nTo extend the Charney-Phillips grid staggering in the compatible finite element\nframework, we use the same node locations for buoyancy as the vertical part of\nvelocity and apply a transport scheme for a partially continuous finite element\nspace. For the time discretisation, we solve the semi-implicit equations\ntogether with an explicit strong-stability-preserving Runge-Kutta scheme to all\nof the advection terms. The model reproduces several quasi-periodic lifecycles\nof fronts despite the presence of strong discontinuities. An asymptotic limit\nanalysis based on the semi-geostrophic theory shows that the model solutions\nare converging to a solution in cross-front geostrophic balance. The results\nare consistent with the previous results using finite difference methods,\nindicating that the compatible finite element method is performing as well as\nfinite difference methods for this test problem. We observe dissipation of\nkinetic energy of the cross-front velocity in the model due to the lack of\nresolution at the fronts, even though the energy loss is not likely to account\nfor the large gap on the strength of the fronts between the model result and\nthe semi-geostrophic limit solution."
    ],
    "c_categories":[
      "math.MP"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.00578",
    "a_title":"Federated Voxel Scene Graph for Intracranial Hemorrhage",
    "a_abstract":"Intracranial Hemorrhage is a potentially lethal condition whose manifestation\nis vastly diverse and shifts across clinical centers worldwide.\nDeep-learning-based solutions are starting to model complex relations between\nbrain structures, but still struggle to generalize. While gathering more\ndiverse data is the most natural approach, privacy regulations often limit the\nsharing of medical data. We propose the first application of Federated Scene\nGraph Generation. We show that our models can leverage the increased training\ndata diversity. For Scene Graph Generation, they can recall up to 20% more\nclinically relevant relations across datasets compared to models trained on a\nsingle centralized dataset. Learning structured data representation in a\nfederated setting can open the way to the development of new methods that can\nleverage this finer information to regularize across clients more effectively.",
    "explanation":"intracranial Hemorrhage is a potentially lethal condition whose manifestation is vastly diverse and shifts across\nclinical centers worldwide. Deep-learning-based solutions are starting to model complex relations between brain\nstructures, but still struggle to generalize.",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "American Heart Association\/American Stroke Association. 2022 guideline for the management of patients with spontaneous intracerebral hemorrhage: A guideline from the american heart association\/american stroke association"
    ],
    "b_abstract":[
      "Approximately 10% of the 795\u2009000 strokes per year in the United States are intracerebral hemorrhages (ICHs),1 defined by brain injury attributable to acute blood extravasation into the brain parenchyma from a ruptured cerebral blood vessel. The clinical impact of ICH appears disproportionately high among lower-resource populations both in the United States and internationally. In US-based studies, ICH incidence has been reported to be \u22481.6-fold greater among Black than White people2 and 1.6-fold greater among Mexican American than non-Hispanic White people.3 Internationally, ICH incidence is substantially higher in low- and middle-income versus high-income countries, both as a proportion of all strokes and in absolute incidence rates.4,5 Several additional features of ICH make it a greater public health threat than conveyed by incidence numbers alone. ICH is arguably the deadliest form of acute stroke, with early-term mortality about 30% to 40% and no or minimal trend toward improvement over more recent time epochs.6\u20139 Incidence of ICH increases sharply with age and is therefore expected to remain substantial as the population ages, even with counterbalancing public health improvements in blood pressure (BP) control.8 Another growing source of ICH is more widespread use of anticoagulants,10 a trend likely to counterbalance the reduced ICH risk associated with increasing prescription of direct oral anticoagulants (DOACs) relative to vitamin K antagonists (VKAs).11 ICH thus remains in need of novel treatments and improved application of established approaches for every aspect of the disease: primary and secondary prevention, acute inpatient care, and poststroke rehabilitation and recovery. This guideline seeks to synthesize data in the ICH field into practical recommendations for clinical practice."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "Voxel Scene Graph for Intracranial Hemorrhage"
    ],
    "c_abstract":[
      "Patients with Intracranial Hemorrhage (ICH) face a potentially life-threatening condition, and patient-centered individualized treatment remains challenging due to possible clinical complications. Deep-Learning-based methods can efficiently analyze the routinely acquired head CTs support decision-making. The majority of early work focuses on detection segmentation ICH, but do not model complex relations between ICH adjacent brain structures. In this work, we design tailored object method for which unite segmentation-grounded Scene Graph Generation (SGG) learn holistic representation cerebral scene. To best our knowledge, is first application SGG 3D voxel images. We evaluate two head-CT datasets demonstrate that recall up 74% clinically relevant relations. This lays foundation towards data. generated Graphs already provide insights clinician, are also valuable all downstream tasks as compact interpretable representation."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00614",
    "a_title":"Fast and scalable Wasserstein-1 neural optimal transport solver for\n  single-cell perturbation prediction",
    "a_abstract":"Predicting single-cell perturbation responses requires mapping between two\nunpaired single-cell data distributions. Optimal transport (OT) theory provides\na principled framework for constructing such mappings by minimizing transport\ncost. Recently, Wasserstein-2 ($W_2$) neural optimal transport solvers\n(\\textit{e.g.}, CellOT) have been employed for this prediction task. However,\n$W_2$ OT relies on the general Kantorovich dual formulation, which involves\noptimizing over two conjugate functions, leading to a complex min-max\noptimization problem that converges slowly. To address these challenges, we\npropose a novel solver based on the Wasserstein-1 ($W_1$) dual formulation.\nUnlike $W_2$, the $W_1$ dual simplifies the optimization to a maximization\nproblem over a single 1-Lipschitz function, thus eliminating the need for\ntime-consuming min-max optimization. While solving the $W_1$ dual only reveals\nthe transport direction and does not directly provide a unique optimal\ntransport map, we incorporate an additional step using adversarial training to\ndetermine an appropriate transport step size, effectively recovering the\ntransport map. Our experiments demonstrate that the proposed $W_1$ neural\noptimal transport solver can mimic the $W_2$ OT solvers in finding a unique and\n``monotonic\" map on 2D datasets. Moreover, the $W_1$ OT solver achieves\nperformance on par with or surpasses $W_2$ OT solvers on real single-cell\nperturbation datasets. Furthermore, we show that $W_1$ OT solver achieves $25\n\\sim 45\\times$ speedup, scales better on high dimensional transportation task,\nand can be directly applied on single-cell RNA-seq dataset with highly variable\ngenes. Our implementation and experiments are open-sourced at\n\\url{https:\/\/github.com\/poseidonchan\/w1ot}.",
    "explanation":"Predicting single-cell perturbation responses requires mapping between two unpaired single-\ncell data distributions. Optimal transport (OT) theory provides a principled framework for constructing\nsuch mappings by minimizing transport cost.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Multimodal pooled Perturb-CITE-seq screens in patient models define mechanisms of cancer immune evasion"
    ],
    "b_abstract":[
      "Resistance to immune checkpoint inhibitors (ICIs) is a key challenge in cancer therapy. To elucidate underlying mechanisms, we developed Perturb-CITE-sequencing (Perturb-CITE-seq), enabling pooled clustered regularly interspaced short palindromic repeat (CRISPR)\u2013Cas9 perturbations with single-cell transcriptome and protein readouts. In patient-derived melanoma cells and autologous tumor-infiltrating lymphocyte (TIL) co-cultures, we profiled transcriptomes and 20\u2009proteins in ~218,000\u2009cells under ~750\u2009perturbations associated with cancer cell-intrinsic ICI resistance (ICR). We recover known mechanisms of resistance, including defects in the interferon-\u03b3 (IFN-\u03b3)\u2013JAK\/STAT and antigen-presentation pathways in RNA, protein and perturbation space, and new ones, including loss\/downregulation of CD58. Loss of CD58 conferred immune evasion in multiple co-culture models and was downregulated in tumors of melanoma patients with ICR. CD58 protein expression was not induced by IFN-\u03b3 signaling, and CD58 loss conferred immune evasion without compromising major histocompatibility complex (MHC) expression, suggesting that it acts orthogonally to known mechanisms of ICR. This work provides a framework for the deciphering of complex mechanisms by large-scale perturbation screens with multimodal, single-cell readouts, and discovers potentially clinically relevant mechanisms of immune evasion."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Causal identification of single-cell experimental perturbation effects with CINEMA-OT"
    ],
    "c_abstract":[
      "Abstract Recent advancements in single-cell technologies allow characterization of experimental perturbations at resolution. While methods have been developed to analyze such experiments, the application a strict causal framework has not yet explored for inference treatment effects level. Here we present causal-inference-based approach perturbation analysis, termed CINEMA-OT (causal independent effect module attribution + optimal transport). separates confounding sources variation from obtain an transport matching that reflects counterfactual cell pairs. These pairs represent responses permitting number novel analyses, as individual treatment-effect response clustering, and synergy analysis. We benchmark on array estimation tasks several simulated real datasets show it outperforms other analysis methods. Finally, perform two newly generated datasets: (1) rhinovirus cigarette-smoke-exposed airway organoids, (2) combinatorial cytokine stimulation immune cells. In these reveals potential mechanisms by which cigarette-smoke exposure dulls antiviral response, well logic governs chemokine secretion peripheral recruitment."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00714",
    "a_title":"Self-reinforcing cascades: A spreading model for beliefs or products of\n  varying intensity or quality",
    "a_abstract":"Models of how things spread often assume that transmission mechanisms are\nfixed over time. However, social contagions--the spread of ideas, beliefs,\ninnovations--can lose or gain in momentum as they spread: ideas can get\nreinforced, beliefs strengthened, products refined. We study the impacts of\nsuch self-reinforcement mechanisms in cascade dynamics. We use different\nmathematical modeling techniques to capture the recursive, yet changing nature\nof the process. We find a critical regime with a range of power-law cascade\nsize distributions with varying scaling exponents. This regime clashes with\nclassic models, where criticality requires fine tuning at a precise critical\npoint. Self-reinforced cascades produce critical-like behavior over a wide\nrange of parameters, which may help explain the ubiquity of power-law\ndistributions in empirical social data.",
    "explanation":"Models of how things spread often assume that transmission mechanisms are fixed over time. However, social\ncontagions\u2013the spread of ideas, beliefs, innovations\u2013can lose or gain in momentum as they spread: ideas can get\nreinforced, beliefs strengthened, products refined. e use different mathematical modeling techniques to capture the recursive, yet changing\nnature of the process.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Universality, criticality and complexity of information propagation in social media"
    ],
    "b_abstract":[
      "Abstract Statistical laws of information avalanches in social media appear, at least according to existing empirical studies, not robust across systems. As a consequence, radically different processes may represent plausible driving mechanisms for propagation. Here, we analyze almost one billion time-stamped events collected from several online platforms \u2013 including Telegram, Twitter and Weibo over observation windows longer than ten years, show that the propagation is universal critical process. Universality arises identical macroscopic patterns platforms, irrespective details specific system hand. Critical behavior deduced power-law distributions, corresponding hyperscaling relations, characterizing size duration information. testing on our data indicates mixture simple complex contagion characterizes media. Data suggest complexity process correlated with semantic content propagated."
    ],
    "b_categories":[
      "Human Behaviors"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "Random graphs with arbitrary degree distributions and their applications"
    ],
    "c_abstract":[
      "Recent work on the structure of social networks and internet has focused attention graphs with distributions vertex degree that are significantly different from Poisson have been widely studied in past. In this paper we develop detail theory random arbitrary distributions. addition to simple undirected, unipartite graphs, examine properties directed bipartite graphs. Among other results, derive exact expressions for position phase transition at which a giant component first forms, mean size, size if there is one, number vertices certain distance away randomly chosen vertex, average vertex-vertex within graph. We apply our some real-world including world-wide web collaboration scientists Fortune 1000 company directors. demonstrate cases appropriate predict surprising accuracy behavior real world, while others measurable discrepancy between reality, perhaps indicating presence additional network not captured by"
    ],
    "c_categories":[
      "Modeling"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.00749",
    "a_title":"PathoGen-X: A Cross-Modal Genomic Feature Trans-Align Network for\n  Enhanced Survival Prediction from Histopathology Images",
    "a_abstract":"Accurate survival prediction is essential for personalized cancer treatment.\nHowever, genomic data - often a more powerful predictor than pathology data -\nis costly and inaccessible. We present the cross-modal genomic feature\ntranslation and alignment network for enhanced survival prediction from\nhistopathology images (PathoGen-X). It is a deep learning framework that\nleverages both genomic and imaging data during training, relying solely on\nimaging data at testing. PathoGen-X employs transformer-based networks to align\nand translate image features into the genomic feature space, enhancing weaker\nimaging signals with stronger genomic signals. Unlike other methods, PathoGen-X\ntranslates and aligns features without projecting them to a shared latent space\nand requires fewer paired samples. Evaluated on TCGA-BRCA, TCGA-LUAD, and\nTCGA-GBM datasets, PathoGen-X demonstrates strong survival prediction\nperformance, emphasizing the potential of enriched imaging models for\naccessible cancer prognosis.",
    "explanation":"Accurate survival prediction is essential for personalized\ncancer treatment. . It is a\ndeep learning framework that leverages both genomic and\nimaging data during training, relying solely on imaging data\nat testing. ",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "A 2021 update on cancer image analytics with deep learning"
    ],
    "b_abstract":[
      "Deep learning (DL)-based interpretation of medical images has reached a critical juncture of expanding outside research projects into translational ones, and is ready to make its way to the clinics. Advances over the last decade in data availability, DL techniques, as well as computing capabilities have accelerated this journey. Through this journey, today we have a better understanding of the challenges to and pitfalls of wider adoption of DL into clinical care, which, according to us, should and will drive the advances in this field in the next few years. The most important among these challenges are the lack of an appropriately digitized environment within healthcare institutions, the lack of adequate open and representative datasets on which DL algorithms can be trained and tested, and the lack of robustness of widely used DL training algorithms to certain pervasive pathological characteristics of medical images and repositories. In this review, we provide an overview of the role of imaging in oncology, the different techniques that are shaping the way DL algorithms are being made ready for clinical use, and also the problems that DL techniques still need to address before DL can find a home in clinics. Finally, we also provide a summary of how DL can potentially drive the adoption of digital pathology, vendor neutral archives, and picture archival and communication systems. We caution that the respective researchers may find the coverage of their own fields to be at a high-level. This is so by design as this format is meant to only introduce those looking in from outside of deep learning and medical research, respectively, to gain an appreciation for the main concerns and limitations of these two fields instead of telling them something new about their own."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classification"
    ],
    "c_abstract":[
      "Multiple instance learning (MIL) is a powerful tool to solve the weakly supervised classification in whole slide image (WSI) based pathology diagnosis. However, current MIL methods are usually on independent and identical distribution hypothesis, thus neglect correlation among different instances. To address this problem, we proposed new framework, called correlated MIL, provided proof for convergence. Based devised Transformer (TransMIL), which explored both morphological spatial information. The TransMIL can effectively deal with unbalanced\/balanced binary\/multiple great visualization interpretability. We conducted various experiments three computational problems achieved better performance faster convergence compared state-of-the-art methods. test AUC binary tumor be up 93.09% over CAMELYON16 dataset. And cancer subtypes 96.03% 98.82% TCGA-NSCLC dataset TCGA-RCC dataset, respectively. Implementation available at: https:\/\/github.com\/szc19990412\/TransMIL."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00758",
    "a_title":"Inverse methods for freeform optical design",
    "a_abstract":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design, based on Hamilton's characteristic functions and\nconservation of luminous flux, and briefly explain the connection with the\nmathematical theory of optimal transport. We outline several iterative\nleast-squares solvers for our models and demonstrate their performance for a\nfew challenging problems.",
    "explanation":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design .We outline several iterative least-squares solvers for our models and demonstrate their\nperformance for a few challenging problems.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Introduction to Nonimaging Optics, second edition"
    ],
    "b_abstract":[
      "Introduction to Nonimaging Optics covers the theoretical foundations and design methods of nonimaging optics, as well as key concepts from related fields. This fully updated, revised, and expanded Second Edition: \u2022 Features a new and intuitive introduction with a basic description of the advantages of nonimaging optics \u2022 Adds new chapters on wavefronts for a prescribed output (irradiance or intensity), infinitesimal \u00e9tendue optics (generalization of the aplanatic optics), and K\u00f6hler optics and color mixing \u2022 Incorporates new material on the simultaneous multiple surface (SMS) design method in 3-D, integral invariants, and \u00e9tendue 2-D \u2022 Contains 21 chapters, 24 fully worked and several other examples, and 1,000+ illustrations, including photos of real devices \u2022 Addresses applications ranging from solar energy concentration to illumination engineering Introduction to Nonimaging Optics, Second Edition invites newcomers to explore the growing field of nonimaging optics, while providing seasoned veterans with an extensive reference book."
    ],
    "b_categories":[
      "physics.optics"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "Inverse methods for illumination optics"
    ],
    "c_abstract":[
      "\u2022 A submitted manuscript is the version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website. \u2022 The final author version and the galley proof are versions of the publication after peer review. \u2022 The final published version features the final layout of the paper including the volume, issue and page numbers."
    ],
    "c_categories":[
      "math.MP"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.01291",
    "a_title":"Deep Multi-contrast Cardiac MRI Reconstruction via vSHARP with Auxiliary\n  Refinement Network",
    "a_abstract":"Cardiac MRI (CMRI) is a cornerstone imaging modality that provides in-depth\ninsights into cardiac structure and function. Multi-contrast CMRI (MCCMRI),\nwhich acquires sequences with varying contrast weightings, significantly\nenhances diagnostic capabilities by capturing a wide range of cardiac tissue\ncharacteristics. However, MCCMRI is often constrained by lengthy acquisition\ntimes and susceptibility to motion artifacts. To mitigate these challenges,\naccelerated imaging techniques that use k-space undersampling via different\nsampling schemes at acceleration factors have been developed to shorten scan\ndurations. In this context, we propose a deep learning-based reconstruction\nmethod for 2D dynamic multi-contrast, multi-scheme, and multi-acceleration MRI.\nOur approach integrates the state-of-the-art vSHARP model, which utilizes\nhalf-quadratic variable splitting and ADMM optimization, with a Variational\nNetwork serving as an Auxiliary Refinement Network (ARN) to better adapt to the\ndiverse nature of MCCMRI data. Specifically, the subsampled k-space data is fed\ninto the ARN, which produces an initial prediction for the denoising step used\nby vSHARP. This, along with the subsampled k-space, is then used by vSHARP to\ngenerate high-quality 2D sequence predictions. Our method outperforms\ntraditional reconstruction techniques and other vSHARP-based models.",
    "explanation":"Cardiac MRI (CMRI) is a cornerstone imaging modality that\nprovides in-depth insights into cardiac structure and function.  Our approach integrates the state-of-the-art vSHARP model, which uti-\nlizes half-quadratic variable splitting and ADMM optimization, with a\nVariational Network serving as an Auxiliary Refinement Network (ARN)\nto better adapt to the diverse nature of MCCMRI data. ",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting\n  Universal Machine Learning for Accelerated Cardiac MRI"
    ],
    "b_abstract":[
      "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically gold-standard technique for diagnosing cardiac diseases, thanks to its ability provide diverse information with multiple modalities and anatomical views. Accelerated MRI is highly expected achieve time-efficient patient-friendly imaging, then advanced image reconstruction approaches are required recover high-quality, interpretable images from undersampled measurements. However, the lack of publicly available k-space dataset in terms both quantity diversity severely hindered substantial technological progress, particularly data-driven artificial intelligence. Here, we standardized, diverse, high-quality CMRxRecon2024 facilitate technical development, fair evaluation, clinical transfer approaches, towards promoting universal frameworks that enable fast robust reconstructions across different protocols practice. To best our knowledge, largest most dataset. It acquired 330 healthy volunteers, covering commonly used modalities, views, acquisition trajectories workflows. Besides, an open platform tutorials, benchmarks, data processing tools provided usage, method performance evaluation."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b19"
    ],
    "c_title":[
      "vSHARP: variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse-Problems"
    ],
    "c_abstract":[
      "Medical Imaging (MI) tasks, such as accelerated parallel Magnetic Resonance Imaging (MRI), often involve reconstructing an image from noisy or incomplete measurements. This amounts to solving ill-posed inverse problems, where a satisfactory closed-form analytical solution is not available. Traditional methods such as Compressed Sensing (CS) in MRI reconstruction can be time-consuming or prone to obtaining low-fidelity images. Recently, a plethora of Deep Learning (DL) approaches have demonstrated superior performance in inverse-problem solving, surpassing conventional methods. In this study, we propose vSHARP (variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse Problems), a novel DL-based method for solving ill-posed inverse problems arising in MI. vSHARP utilizes the Half-Quadratic Variable Splitting method and employs the Alternating Direction Method of Multipliers (ADMM) to unroll the optimization process. For data consistency, vSHARP unrolls a differentiable gradient descent process in the image domain, while a DL-based denoiser, such as a U-Net architecture, is applied to enhance image quality. vSHARP also employs a dilated-convolution DL-based model to predict the Lagrange multipliers for the ADMM initialization. We evaluate vSHARP on tasks of accelerated parallel MRI Reconstruction using two distinct datasets and on accelerated parallel dynamic MRI Reconstruction using another dataset. Our comparative analysis with state-of-the-art methods demonstrates the superior performance of vSHARP in these applications."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01758",
    "a_title":"Disentangled PET Lesion Segmentation",
    "a_abstract":"PET imaging is an invaluable tool in clinical settings as it captures the\nfunctional activity of both healthy anatomy and cancerous lesions. Developing\nautomatic lesion segmentation methods for PET images is crucial since manual\nlesion segmentation is laborious and prone to inter- and intra-observer\nvariability. We propose PET-Disentangler, a 3D disentanglement method that uses\na 3D UNet-like encoder-decoder architecture to disentangle disease and normal\nhealthy anatomical features with losses for segmentation, reconstruction, and\nhealthy component plausibility. A critic network is used to encourage the\nhealthy latent features to match the distribution of healthy samples and thus\nencourages these features to not contain any lesion-related features. Our\nquantitative results show that PET-Disentangler is less prone to incorrectly\ndeclaring healthy and high tracer uptake regions as cancerous lesions, since\nsuch uptake pattern would be assigned to the disentangled healthy component.",
    "explanation":"PET imaging is an invaluable tool in clinical settings as it\ncaptures the functional activity of both healthy anatomy and\ncancerous lesions. Developing automatic lesion segmentation\nmethods for PET images is crucial since manual lesion seg-\nmentation is laborious and prone to inter- and intra-observer\nvariability. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Multi-site quality and variability analysis of 3D FDG PET segmentations based on phantom and clinical image data"
    ],
    "b_abstract":[
      "Purpose: Radiomics utilizes a large number of image-derived features for quantifying tumor characteristics that can in turn be correlated with response and prognosis. Unfortunately, extraction and analysis of such image-based features is subject to measurement variability and bias. The challenge for radiomics is particularly acute in Positron Emission Tomography (PET) where limited resolution, a high noise component related to the limited stochastic nature of the raw data, and the wide variety of reconstruction options confound quantitative feature metrics. Extracted feature quality is also affected by tumor segmentation methods used to define regions over which to calculate features, making it challenging to produce consistent radiomics analysis results across multiple institutions that use different segmentation algorithms in their PET image analysis. Understanding each element contributing to these inconsistencies in quantitative image feature and metric generation is paramount for ultimate utilization of these methods in multi-institutional trials and clinical oncology decision making. Methods: To assess segmentation quality and consistency at the multi-institutional level, we conducted a study of seven institutional members of the National Cancer Institute Quantitative Imaging Network. For the study, members were asked to segment a common set of phantom PET scans acquired over a range of imaging conditions as well as a second set of head and neck cancer (HNC) PET scans. Segmentations were generated at each institution using their preferred approach. In addition, participants were asked to repeat segmentations with a time interval between initial and repeat segmentation. This procedure resulted in overall 806 phantom insert and 641 lesion segmentations. Subsequently, the volume was computed from the segmentations and compared to the corresponding reference volume by means of statistical analysis. Results: On the two test sets (phantom and HNC PET scans), the performance of the seven segmentation approaches was as follows. On the phantom test set, the mean relative volume errors ranged from 29.9 to 87.8% of the ground truth reference volumes, and the repeat difference for each institution ranged between -36.4 to 39.9%. On the HNC test set, the mean relative volume error ranged between -50.5 to 701.5%, and the repeat difference for each institution ranged between -37.7 to 31.5%. In addition, performance measures per phantom insert\/lesion size categories are given in the paper. On phantom data, regression analysis resulted in coefficient of variation (CV) components of 42.5% for scanners, 26.8% for institutional approaches, 21.1% for repeated segmentations, 14.3% for relative contrasts, 5.3% for count statistics (acquisition times), and 0.0% for repeated scans. Analysis showed that the CV components for approaches and repeated segmentations were significantly larger on the HNC test set with increases by 112.7% and 102.4%, respectively. Conclusion: Analysis results underline the importance of PET scanner reconstruction harmonization and imaging protocol standardization for quantification of lesion volumes. In addition, to enable a distributed multi-site analysis of FDG PET images, harmonization of analysis approaches and operator training in combination with highly automated segmentation methods seems to be advisable. Future work will focus on quantifying the impact of segmentation variation on radiomics system performance."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "A review on segmentation of positron emission tomography images"
    ],
    "c_abstract":[
      "Positron Emission Tomography (PET), a non-invasive functional imaging method at the molecular level, images the distribution of biologically targeted radiotracers with high sensitivity. PET imaging provides detailed quantitative information about many diseases and is often used to evaluate inflammation, infection, and cancer by detecting emitted photons from a radiotracer localized to abnormal cells. In order to differentiate abnormal tissue from surrounding areas in PET images, image segmentation methods play a vital role; therefore, accurate image segmentation is often necessary for proper disease detection, diagnosis, treatment planning, and follow-ups. In this review paper, we present state-of-the-art PET image segmentation methods, as well as the recent advances in image segmentation techniques. In order to make this manuscript self-contained, we also briefly explain the fundamentals of PET imaging, the challenges of diagnostic PET image analysis, and the effects of these challenges on the segmentation results."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03389",
    "a_title":"Neurons for Neutrons: A Transformer Model for Computation Load\n  Estimation on Domain-Decomposed Neutron Transport Problems",
    "a_abstract":"Domain decomposition is a technique used to reduce memory overhead on large\nneutron transport problems. Currently, the optimal load-balanced processor\nallocation for these domains is typically determined through small-scale\nsimulations of the problem, which can be time-consuming for researchers and\nmust be repeated anytime a problem input is changed. We propose a Transformer\nmodel with a unique 3D input embedding, and input representations designed for\ndomain-decomposed neutron transport problems, which can predict the subdomain\ncomputation loads generated by small-scale simulations. We demonstrate that\nsuch a model trained on domain-decomposed Small Modular Reactor (SMR)\nsimulations achieves 98.2% accuracy while being able to skip the small-scale\nsimulation step entirely. Tests of the model's robustness on variant fuel\nassemblies, other problem geometries, and changes in simulation parameters are\nalso discussed.",
    "explanation":"Currently, the optimal load-\nbalanced processor allocation for these domains is typically determined\nthrough small-scale simulations of the problem, which can be time-consuming\nfor researchers and must be repeated anytime a problem input is changed.\nWe propose a Transformer model with a unique 3D input embedding, and\ninput representations designed for domain-decomposed neutron transport\nproblems, which can predict the subdomain computation loads generated\nby small-scale simulations.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Attention Is All You Need"
    ],
    "b_abstract":[
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. best performing also connect the encoder and decoder through attention mechanism. We propose a new simple network architecture, Transformer, solely mechanisms, dispensing with recurrence convolutions entirely. Experiments two machine translation tasks show these to be superior quality while being more parallelizable requiring significantly less time train. Our model achieves 28.4 BLEU WMT 2014 English-to-German task, improving over existing results, including ensembles by 2 BLEU. On English-to-French our establishes single-model state-of-the-art score of 41.8 after training for 3.5 days eight GPUs, small fraction costs from literature. that Transformer generalizes well other applying it successfully English constituency parsing both large limited data."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Continuous-energy Monte Carlo neutron transport on GPUs in the Shift code"
    ],
    "c_abstract":[
      "A continuous-energy Monte Carlo neutron transport solver executing on GPUs has been developed within the Shift code. Several algorithmic approaches are considered, including both history-based and event-based implementations. Unlike in previous work involving multigroup Monte Carlo transport, it is demonstrated that event-based algorithms significantly outperform a history-based approach for continuous-energy transport as a result of increased device occupancy and reduced thread divergence. Numerical results are presented for detailed full-core models of a small modular reactor (SMR), including a model containing depleted fuel materials. These results demonstrate the substantial gains in performance that are possible with the latest-generation of GPUs. On the depleted SMR core configuration, an NVIDIA P100 GPU with 56 streaming multiprocessors provides performance equivalent to 90 CPU cores, and the latest V100 GPU with 80 multiprocessors offers the performance of more than 150 CPU cores."
    ],
    "c_categories":[
      "astro-ph.HE"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04682",
    "a_title":"DNN-based 3D Cloud Retrieval for Variable Solar Illumination and\n  Multiview Spaceborne Imaging",
    "a_abstract":"Climate studies often rely on remotely sensed images to retrieve\ntwo-dimensional maps of cloud properties. To advance volumetric analysis, we\nfocus on recovering the three-dimensional (3D) heterogeneous extinction\ncoefficient field of shallow clouds using multiview remote sensing data.\nClimate research requires large-scale worldwide statistics. To enable scalable\ndata processing, previous deep neural networks (DNNs) can infer at spaceborne\nremote sensing downlink rates. However, prior methods are limited to a fixed\nsolar illumination direction. In this work, we introduce the first scalable\nDNN-based system for 3D cloud retrieval that accommodates varying camera poses\nand solar directions. By integrating multiview cloud intensity images with\ncamera poses and solar direction data, we achieve greater flexibility in\nrecovery. Training of the DNN is performed by a novel two-stage scheme to\naddress the high number of degrees of freedom in this problem. Our approach\nshows substantial improvements over previous state-of-the-art, particularly in\nhandling variations in the sun's zenith angle.",
    "explanation":"Climate studies often rely on remotely sensed im-\nages to retrieve two-dimensional maps of cloud properties. To\nadvance volumetric analysis, we focus on recovering the three-\ndimensional (3D) heterogeneous extinction coefficient field of\nshallow clouds using multiview remote sensing data. \n\n\nTo enable\nscalable data processing, previous deep neural networks (DNNs)\ncan infer at spaceborne remote sensing downlink rates. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Distributed Sky Imaging Radiometry and Tomography"
    ],
    "b_abstract":[
      "The composition of the atmosphere is significant to our ecosystem. Accordingly, there a need sense distributions atmospheric scatterers such as aerosols and cloud droplets. There growing interest in recovering these scattering fields three-dimensions (3D). Even so, current observations usually use expensive unscalable equipment. Moreover, analysis retrieves partial information (e.g., cloud-base altitudes, water droplet size at tops) based on simplified 1D models. To advance retrievals, we develop new computational imaging approach for sensing analyzing atmosphere, volumetrically. Our comprises ground-based network cameras. We deployed it conjunction with additional remote equipment, including Raman lidar sunphotometer, which provide initialization algorithms ground truth. camera scalable, low cost, enables 3D high spatial temporal resolution. describe how system calibrated absolute radiometric readouts light field. Consequently, recover volumetric field scatterers, using tomography. tomography process adapted relative prior art, run large-scale domains being in-situ within scatterer fields. empirically demonstrate feasibility clouds, data."
    ],
    "b_categories":[
      "astro-ph.EP"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "Variable Imaging Projection Cloud Scattering Tomography"
    ],
    "c_abstract":[
      "Scattering-based computed tomography (CT) recovers a heterogeneous volumetric scattering medium using images taken from multiple directions. It is nonlinear problem. Prior art mainly approached it by explicit physics-based optimization of image-fitting, being slow and difficult to scale. Scale particularly important when the objects constitute large cloud fields, where recovery for climate studies. Besides speed, imaging need be flexible, efficiently handle variable viewing geometries resolutions. These can caused perturbation in camera poses or fusion data different types observational sensors. There fast projection clouds (VIP-CT). We develop learning-based solution, deep-neural network (DNN) which trains on labeled dataset. The DNN parameters are oblivious domain scale, hence work with arbitrarily domains. VIP-CT offers much better quality than state art. inference speed flexibility make effectively real-time context spaceborne observations. paper first demonstrate CT real empirical directly DNN. may offer model solution problems other scientific Our code available online."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03156",
    "a_title":"Unleashing the power of novel conditional generative approaches for new\n  materials discovery",
    "a_abstract":"For a very long time, computational approaches to the design of new materials\nhave relied on an iterative process of finding a candidate material and\nmodeling its properties. AI has played a crucial role in this regard, helping\nto accelerate the discovery and optimization of crystal properties and\nstructures through advanced computational methodologies and data-driven\napproaches. To address the problem of new materials design and fasten the\nprocess of new materials search, we have applied latest generative approaches\nto the problem of crystal structure design, trying to solve the inverse\nproblem: by given properties generate a structure that satisfies them without\nutilizing supercomputer powers. In our work we propose two approaches: 1)\nconditional structure modification: optimization of the stability of an\narbitrary atomic configuration, using the energy difference between the most\nenergetically favorable structure and all its less stable polymorphs and 2)\nconditional structure generation. We used a representation for materials that\nincludes the following information: lattice, atom coordinates, atom types,\nchemical features, space group and formation energy of the structure. The loss\nfunction was optimized to take into account the periodic boundary conditions of\ncrystal structures. We have applied Diffusion models approach, Flow matching,\nusual Autoencoder (AE) and compared the results of the models and approaches.\nAs a metric for the study, physical PyMatGen matcher was employed: we compare\ntarget structure with generated one using default tolerances. So far, our\nmodifier and generator produce structures with needed properties with accuracy\n41% and 82% respectively. To prove the offered methodology efficiency,\ninference have been carried out, resulting in several potentially new\nstructures with formation energy below the AFLOW-derived convex hulls.",
    "explanation":"\" In our work we propose two approaches: 1) conditional structure modification: optimization of the stability of an arbitrary atomic configuration, using the energy difference between the most energetically favorable structure and all its less stable polymorphs and 2) conditional structure generation.\"",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Physics guided deep learning for generative design of crystal materials with symmetry constraints"
    ],
    "b_abstract":[
      "Abstract Discovering new materials is a challenging task in science crucial to the progress of human society. Conventional approaches based on experiments and simulations are labor-intensive or costly with success heavily depending experts\u2019 heuristic knowledge. Here, we propose deep learning Physics Guided Crystal Generative Model (PGCGM) for efficient crystal material design high structural diversity symmetry. Our model increases generation validity by more than 700% compared FTCP, one latest structure generators 45% our previous CubicGAN model. Density Functional Theory (DFT) calculations used validate generated structures 1869 out 2000 successfully optimized deposited into Carolina Materials Database www.carolinamatdb.org , which 39.6% have negative formation energy 5.3% energy-above-hull less 0.25 eV\/atom, indicating their thermodynamic stability potential synthesizability."
    ],
    "b_categories":[
      "physics.comp-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "High\u2010Throughput Discovery of Novel Cubic Crystal Materials Using Deep Generative Neural Networks"
    ],
    "c_abstract":[
      "Abstract High\u2010throughput screening has become one of the major strategies for discovery novel functional materials. However, its effectiveness is severely limited by lack sufficient and diverse materials in current repositories such as open quantum database (OQMD). Recent progress deep learning have enabled generative that learn implicit chemical rules creating hypothetical with new compositions structures. models difficulty generating structurally diverse, chemically valid, stable Here we propose CubicGAN, a adversarial network (GAN) based neural model large scale design cubic When trained on 375 749 ternary from OQMD database, authors show able to not only rediscover most currently known but also generate structure prototypes. A total 506 been verified phonon dispersion calculation. Considering importance wide applications solar panels, GAN provides promising approach significantly expand existing repositories, enabling via screening. The crystal structures discovered are freely accessible at www.carolinamatdb.org ."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.17907",
    "a_title":"A Multimodal Emotion Recognition System: Integrating Facial Expressions,\n  Body Movement, Speech, and Spoken Language",
    "a_abstract":"Traditional psychological evaluations rely heavily on human observation and\ninterpretation, which are prone to subjectivity, bias, fatigue, and\ninconsistency. To address these limitations, this work presents a multimodal\nemotion recognition system that provides a standardised, objective, and\ndata-driven tool to support evaluators, such as psychologists, psychiatrists,\nand clinicians. The system integrates recognition of facial expressions,\nspeech, spoken language, and body movement analysis to capture subtle emotional\ncues that are often overlooked in human evaluations. By combining these\nmodalities, the system provides more robust and comprehensive emotional state\nassessment, reducing the risk of mis- and overdiagnosis. Preliminary testing in\na simulated real-world condition demonstrates the system's potential to provide\nreliable emotional insights to improve the diagnostic accuracy. This work\nhighlights the promise of automated multimodal analysis as a valuable\ncomplement to traditional psychological evaluation practices, with applications\nin clinical and therapeutic settings.",
    "explanation":"Traditional psychological evaluations rely heavily\non human observation and interpretation, which are prone to\nsubjectivity, bias, fatigue, and inconsistency. To address these\nlimitations, this work presents a multimodal emotion recognition\nsystem that provides a standardised, objective, and data-driven\ntool to support evaluators, such as psychologists, psychiatrists,\nand clinicians.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Deep Facial Expression Recognition: A Survey"
    ],
    "b_abstract":[
      "With the transition of facial expression recognition (FER) from laboratory-controlled to challenging in-the-wild conditions and recent success deep learning techniques in various fields, neural networks have increasingly been leveraged learn discriminative representations for automatic FER. Recent FER systems generally focus on two important issues: overfitting caused by a lack sufficient training data expression-unrelated variations, such as illumination, head pose identity bias. In this paper, we provide comprehensive survey FER, including datasets algorithms that insights into these intrinsic problems. First, describe standard pipeline system with related background knowledge suggestions applicable implementations each stage. We then introduce available are widely used literature accepted selection evaluation principles datasets. For state art review existing novel strategies designed based both static images dynamic image sequences, discuss their advantages limitations. Competitive performances benchmarks also summarized section. extend our additional issues application scenarios. Finally, remaining challenges corresponding opportunities field well future directions design robust systems."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Recognizing and reducing cognitive bias in clinical and forensic neurology"
    ],
    "c_abstract":[
      "In medicine, cognitive errors form the basis of bias in clinical practice. Several types are common and pervasive, may lead to inaccurate diagnosis or treatment. Forensic neurology, even when aided by current technologies, still dependent on interpretations, therefore prone bias. This article discusses 4 biases that can clinician astray. They confirmation (selective gathering neglect contradictory evidence); base rate (ignoring misusing prevailing data); hindsight (oversimplification past causation); good old days (the tendency for patients misremember exaggerate their preinjury functioning). We briefly describe strategies adopted from field psychology could minimize While debiasing is not easy, reducing such requires awareness acknowledgment our susceptibility these distortions."
    ],
    "c_categories":[
      "Clinical Neurology"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05055",
    "a_title":"Integrating Large Language Models for Genetic Variant Classification",
    "a_abstract":"The classification of genetic variants, particularly Variants of Uncertain\nSignificance (VUS), poses a significant challenge in clinical genetics and\nprecision medicine. Large Language Models (LLMs) have emerged as transformative\ntools in this realm. These models can uncover intricate patterns and predictive\ninsights that traditional methods might miss, thus enhancing the predictive\naccuracy of genetic variant pathogenicity.\n  This study investigates the integration of state-of-the-art LLMs, including\nGPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for\nvariant classification. Our approach evaluates these integrated models using\nthe well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in\nclassification performance. The models were rigorously tested on a set of\nchallenging variants, demonstrating substantial improvements over existing\nstate-of-the-art tools, especially in handling ambiguous and clinically\nuncertain variants.\n  The results of this research underline the efficacy of combining multiple\nmodeling approaches to significantly refine the accuracy and reliability of\ngenetic variant classification systems. These findings support the deployment\nof these advanced computational models in clinical environments, where they can\nsignificantly enhance the diagnostic processes for genetic disorders,\nultimately pushing the boundaries of personalized medicine by offering more\ndetailed and actionable genetic insights.",
    "explanation":"This study investigates the integration of state-of-the-art LLMs,\nincluding GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for variant classification.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"
    ],
    "b_abstract":[
      "TensorFlow is an interface for expressing machine learning algorithms, and implementation executing such algorithms. A computation expressed using can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices as phones tablets up to large-scale distributed systems hundreds machines thousands computational GPU cards. The system flexible used express including training inference algorithms deep neural network models, it has been conducting research deploying into production across more than dozen areas computer science other fields, speech recognition, vision, robotics, information retrieval, natural language processing, geographic extraction, drug discovery. This paper describes the that we have built at Google. API reference were released open-source package under Apache 2.0 license in November, 2015 are available www.tensorflow.org."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Predicting Functional Effect of Human Missense Mutations Using PolyPhen\u20102"
    ],
    "c_abstract":[
      "Abstract PolyPhen\u20102 (Polymorphism Phenotyping v2), available as software and via a Web server, predicts the possible impact of amino acid substitutions on stability function human proteins using structural comparative evolutionary considerations. It performs functional annotation single\u2010nucleotide polymorphisms (SNPs), maps coding SNPs to gene transcripts, extracts protein sequence annotations attributes, builds conservation profiles. then estimates probability missense mutation being damaging based combination all these properties. features include high\u2010quality multiple alignment pipeline prediction method employing machine\u2010learning classification. The also integrates UCSC Genome Browser's genome MultiZ alignments vertebrate genomes with genome. is capable analyzing large volumes data produced by next\u2010generation sequencing projects, thanks built\u2010in support for high\u2010performance computing environments like Grid Engine Platform LSF. Curr. Protoc. Hum. Genet . 76:7.20.1\u20107.20.41. \u00a9 2013 John Wiley &amp; Sons, Inc."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.18156",
    "a_title":"scReader: Prompting Large Language Models to Interpret scRNA-seq Data",
    "a_abstract":"Large language models (LLMs) have demonstrated remarkable advancements,\nprimarily due to their capabilities in modeling the hidden relationships within\ntext sequences. This innovation presents a unique opportunity in the field of\nlife sciences, where vast collections of single-cell omics data from multiple\nspecies provide a foundation for training foundational models. However, the\nchallenge lies in the disparity of data scales across different species,\nhindering the development of a comprehensive model for interpreting genetic\ndata across diverse organisms. In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of LLMs with\ndomain-specific representation models for single-cell omics data\ninterpretation. We begin by focusing on genes as the fundamental unit of\nrepresentation. Gene representations are initialized using functional\ndescriptions, leveraging the strengths of mature language models such as\nLLaMA-2. By inputting single-cell gene-level expression data with prompts, we\neffectively model cellular representations based on the differential expression\nlevels of genes across various species and cell types. In the experiments, we\nconstructed developmental cells from humans and mice, specifically targeting\ncells that are challenging to annotate. We evaluated our methodology through\nbasic tasks such as cell annotation and visualization analysis. The results\ndemonstrate the efficacy of our approach compared to other methods using LLMs,\nhighlighting significant improvements in accuracy and interoperability. Our\nhybrid approach enhances the representation of single-cell data and offers a\nrobust framework for future research in cross-species genetic analysis.",
    "explanation":". In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of\nLLMs with domain-specific representation models for single-cell\nomics data interpretation.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Llamafactory: Unified efficient fine-tuning of 100+ language models"
    ],
    "b_abstract":[
      "Efficient fine-tuning is vital for adapting large language models (LLMs) to downstream tasks. However, it requires non-trivial efforts to implement these methods on different models. We present LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It provides a solution for flexibly customizing the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard. We empirically validate the efficiency and effectiveness of our framework on language modeling and text generation tasks."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "GeneCompass: Deciphering Universal Gene Regulatory Mechanisms with Knowledge-Informed Cross-Species Foundation Model"
    ],
    "c_abstract":[
      "Abstract Deciphering the universal gene regulatory mechanisms in diverse organisms holds great potential to advance our knowledge of fundamental life process and facilitate research on clinical applications. However, traditional paradigm primarily focuses individual model organisms, resulting limited collection integration complex features various cell types across species. Recent breakthroughs single-cell sequencing advancements deep learning techniques present an unprecedented opportunity tackle this challenge. In study, we developed GeneCompass, first knowledge-informed, cross-species foundation pre-trained extensive dataset over 120 million transcriptomes from human mouse. During pre-training, GeneCompass effectively integrates four biological prior enhance understanding a self-supervised manner. Fine-tuning towards multiple downstream tasks, outperforms competing state-of-the-art models tasks single species unlocks new realms investigation. Overall, marks milestone advancing accelerating discovery key fate regulators candidate targets for drug development."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.07871",
    "a_title":"Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in\n  Alzheimer's Disease",
    "a_abstract":"The rapid advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have shown great potential in medical diagnostics, particularly\nin radiology, where datasets such as X-rays are paired with human-generated\ndiagnostic reports. However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer's disease, due\nto the lack of comprehensive diagnostic reports that can be utilized for model\nfine-tuning. This paper addresses this gap by generating synthetic diagnostic\nreports using GPT-4o-mini on structured data from the OASIS-4 dataset, which\ncomprises 663 patients. Using the synthetic reports as ground truth for\ntraining and validation, we then generated neurological reports directly from\nthe images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.\nOur proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,\nand METEOR score of 0.4163, revealing its potential in generating clinically\nrelevant and accurate diagnostic reports.",
    "explanation":"However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer\u2019s\ndisease, due to the lack of comprehensive diagnostic reports that\ncan be utilized for model fine-tuning. This paper addresses this\ngap by generating synthetic diagnostic reports using GPT-4o-mini\non structured data from the OASIS-4 dataset, which comprises\n663 patients",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "2016 Alzheimer's disease facts and figures"
    ],
    "b_abstract":[
      "This report describes the public health impact of Alzheimer's disease, including incidence and prevalence, mortality rates, costs care, overall on caregivers society. It also examines in detail financial families, annual to families difficult decisions must often make pay those costs. An estimated 5.4 million Americans have disease. By mid-century, number people living with disease United States is projected grow 13.8 million, fueled large part by aging baby boom generation. Today, someone country develops every 66 seconds. 2050, one new case expected develop 33 seconds, resulting nearly 1 cases per year. In 2013, official death certificates recorded 84,767 deaths from making it sixth leading cause fifth age \u2265 65 years. Between 2000 stroke, heart prostate cancer decreased 23%, 14%, 11%, respectively, whereas increased 71%. The actual which contributes likely much larger than certificates. 2016, an 700,000 years will die many them because complications caused 2015, more 15 family members other unpaid provided 18.1 billion hours care dementias, a contribution valued at $221 billion. Average per-person Medicare payments for services beneficiaries dementias are two half times as great all without these conditions, Medicaid 19 great. Total 2016 long-term hospice dementia be $236 may place substantial burden who take money out their retirement savings, cut back buying food, reduce own trips doctor. addition, incorrectly believe that pays nursing home types care. Such findings highlight need solutions prevent dementia-related jeopardizing security dementias."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Computer-aided diagnosis of Alzheimer\u2019s disease and neurocognitive disorders with multimodal Bi-Vision Transformer (BiViT)"
    ],
    "c_abstract":[
      "<jats:title>Abstract<\/jats:title><jats:p>Cognitive disorders affect various cognitive functions that can have a substantial impact on individual\u2019s daily life. Alzheimer\u2019s disease (AD) is one of such well-known cognitive disorders. Early detection and treatment of cognitive diseases using artificial intelligence can help contain them. However, the complex spatial relationships and long-range dependencies found in medical imaging data present challenges in achieving the objective. Moreover, for a few years, the application of transformers in imaging has emerged as a promising area of research. A reason can be transformer\u2019s impressive capabilities of tackling spatial relationships and long-range dependency challenges in two ways, i.e., (1) using their self-attention mechanism to generate comprehensive features, and (2) capture complex patterns by incorporating global context and long-range dependencies. In this work, a Bi-Vision Transformer (BiViT) architecture is proposed for classifying different stages of AD, and multiple types of cognitive disorders from 2-dimensional MRI imaging data. More specifically, the transformer is composed of two novel modules, namely Mutual Latent Fusion (MLF) and Parallel Coupled Encoding Strategy (PCES), for effective feature learning. Two different datasets have been used to evaluate the performance of proposed BiViT-based architecture. The first dataset contain several classes such as mild or moderate demented stages of the AD. The other dataset is composed of samples from patients with AD and different cognitive disorders such as mild, early, or moderate impairments. For comprehensive comparison, a multiple transfer learning algorithm and a deep autoencoder have been each trained on both datasets. The results show that the proposed BiViT-based model achieves an accuracy of 96.38% on the AD dataset. However, when applied to cognitive disease data, the accuracy slightly decreases below 96% which can be resulted due to smaller amount of data and imbalance in data distribution. Nevertheless, given the results, it can be hypothesized that the proposed algorithm can perform better if the imbalanced distribution and limited availability problems in data can be addressed.<\/jats:p>\n                <jats:p><jats:bold>Graphical abstract<\/jats:bold><\/jats:p>"
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.08073",
    "a_title":"LoRA-BERT: a Natural Language Processing Model for Robust and Accurate\n  Prediction of long non-coding RNAs",
    "a_abstract":"Long non-coding RNAs (lncRNAs) serve as crucial regulators in numerous\nbiological processes. Although they share sequence similarities with messenger\nRNAs (mRNAs), lncRNAs perform entirely different roles, providing new avenues\nfor biological research. The emergence of next-generation sequencing\ntechnologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify\nlong non-coding RNAs (lncRNAs). These advanced methods have significantly\nenhanced the efficiency of identifying lncRNAs. However, many of these methods\nare devoid of robustness and accuracy due to the extended length of the\nsequences involved. To tackle this issue, we have introduced a novel\npre-trained bidirectional encoder representation called LoRA-BERT. LoRA-BERT is\ndesigned to capture the importance of nucleotide-level information during\nsequence classification, leading to more robust and satisfactory outcomes. In a\ncomprehensive comparison with commonly used sequence prediction tools, we have\ndemonstrated that LoRA-BERT outperforms them in terms of accuracy and\nefficiency. Our results indicate that, when utilizing the transformer model,\nLoRA-BERT achieves state-of-the-art performance in predicting both lncRNAs and\nmRNAs for human and mouse species. Through the utilization of LoRA-BERT, we\nacquire valuable insights into the traits of lncRNAs and mRNAs, offering the\npotential to aid in the comprehension and detection of diseases linked to\nlncRNAs in humans.",
    "explanation":"The emergence of next-\ngeneration sequencing technologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify long non-coding\nRNAs (lncRNAs). ",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome"
    ],
    "b_abstract":[
      "Abstract Motivation Deciphering the language of non-coding DNA is one fundamental problems in genome research. Gene regulatory code highly complex due to existence polysemy and distant semantic relationship, which previous informatics methods often fail capture especially data-scarce scenarios. Results To address this challenge, we developed a novel pre-trained bidirectional encoder representation, named DNABERT, global transferrable understanding genomic sequences based on up downstream nucleotide contexts. We compared DNABERT most widely used programs for genome-wide elements prediction demonstrate its ease use, accuracy efficiency. show that single transformers model can simultaneously achieve state-of-the-art performance promoters, splice sites transcription factor binding sites, after easy fine-tuning using small task-specific labeled data. Further, enables direct visualization nucleotide-level importance relationship within input better interpretability accurate identification conserved sequence motifs functional genetic variant candidates. Finally, with human even be readily applied other organisms exceptional performance. anticipate fined tuned many analyses tasks. Availability implementation The source code, pretrained finetuned are available at GitHub (https:\/\/github.com\/jerryji1993\/DNABERT). Supplementary information data Bioinformatics online."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b20"
    ],
    "c_title":[
      "A primer on deep learning in genomics"
    ],
    "c_abstract":[
      "Deep learning methods are a class of machine learning techniques capable of identifying highly complex patterns in large datasets. Here, we provide a perspective and primer on deep learning applications for genome analysis. We discuss successful applications in the fields of regulatory genomics, variant calling and pathogenicity scores. We include general guidance for how to effectively use deep learning methods as well as a practical guide to tools and resources. This primer is accompanied by an interactive online tutorial."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.08664",
    "a_title":"UniMat: Unifying Materials Embeddings through Multi-modal Learning",
    "a_abstract":"Materials science datasets are inherently heterogeneous and are available in\ndifferent modalities such as characterization spectra, atomic structures,\nmicroscopic images, and text-based synthesis conditions. The advancements in\nmulti-modal learning, particularly in vision and language models, have opened\nnew avenues for integrating data in different forms. In this work, we evaluate\ncommon techniques in multi-modal learning (alignment and fusion) in unifying\nsome of the most important modalities in materials science: atomic structure,\nX-ray diffraction patterns (XRD), and composition. We show that structure graph\nmodality can be enhanced by aligning with XRD patterns. Additionally, we show\nthat aligning and fusing more experimentally accessible data formats, such as\nXRD patterns and compositions, can create more robust joint embeddings than\nindividual modalities across various tasks. This lays the groundwork for future\nstudies aiming to exploit the full potential of multi-modal data in materials\nscience, facilitating more informed decision-making in materials design and\ndiscovery.",
    "explanation":"n this work, we evaluate common techniques in multi-modal learning\n(alignment and fusion) in unifying some of the most important modalities in materials\nscience: atomic structure, X-ray diffraction patterns (XRD), and composition.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Comprehensive Inorganic Chemistry III (Third Edition)"
    ],
    "b_abstract":[
      "Comprehensive Inorganic Chemistry III, a ten-volume reference work, is intended to cover fundamental principles, recent discoveries, and significant applications of elements and their compounds. Authored by renowned experts in the field and edited by a world-class editorial board, each chapter provides a thorough and in-depth overview of the topic covered, featuring resources which will be useful to students, researchers, faculty as well as those in the industry. Comprehensive Inorganic Chemistry III focuses on main group chemistry, biological inorganic chemistry, solid state and materials chemistry, catalysis, and new developments in electrochemistry and photochemistry, as well as NMR and diffraction methods for studying inorganic compounds. The work expands on our 2013 work Comprehensive Inorganic Chemistry II while also adding new volumes on cutting-edge research areas and techniques for studying inorganic compounds. Researchers seeking background information on a specific problem involving the synthesis of inorganic compounds, as well as applications for numerous elements from the periodic table, and their compounds, will be able to rely on and refer to this authoritative scientific resource time and again."
    ],
    "b_categories":[
      "Material"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Multimodal Foundation Models for Material Property Prediction and Discovery"
    ],
    "c_abstract":[
      "Artificial intelligence is transforming computational materials science, improving the prediction of material properties, and accelerating the discovery of novel materials. Recently, publicly available material data repositories have grown rapidly. This growth encompasses not only more materials but also a greater variety and quantity of their associated properties. Existing machine learning efforts in materials science focus primarily on single-modality tasks, i.e. relationships between materials and a single physical property, thus not taking advantage of the rich and multimodal set of material properties. Here, we introduce Multimodal Learning for Materials (MultiMat), which enables self-supervised multi-modality training of foundation models for materials. We demonstrate our framework's potential using data from the Materials Project database on multiple axes: (i) MultiMat achieves state-of-the-art performance for challenging material property prediction tasks; (ii) MultiMat enables novel and accurate material discovery via latent space similarity, enabling screening for stable materials with desired properties; and (iii) MultiMat encodes interpretable emergent features that may provide novel scientific insights."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.09080",
    "a_title":"Language Models for Music Medicine Generation",
    "a_abstract":"Music therapy has been shown in recent years to provide multiple health\nbenefits related to emotional wellness. In turn, maintaining a healthy\nemotional state has proven to be effective for patients undergoing treatment,\nsuch as Parkinson's patients or patients suffering from stress and anxiety. We\npropose fine-tuning MusicGen, a music-generating transformer model, to create\nshort musical clips that assist patients in transitioning from negative to\ndesired emotional states. Using low-rank decomposition fine-tuning on the\nMTG-Jamendo Dataset with emotion tags, we generate 30-second clips that adhere\nto the iso principle, guiding patients through intermediate states in the\nvalence-arousal circumplex. The generated music is evaluated using a music\nemotion recognition model to ensure alignment with intended emotions. By\nconcatenating these clips, we produce a 15-minute \"music medicine\" resembling a\nmusic therapy session. Our approach is the first model to leverage Language\nModels to generate music medicine. Ultimately, the output is intended to be\nused as a temporary relief between music therapy sessions with a\nboard-certified therapist.",
    "explanation":"We propose fine-tuning MusicGen, a music-generating\ntransformer model, to create short musical clips that assist\npatients in transitioning from negative to desired emotional\nstates",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Music Transformer: Generating Music with Long-Term Structure"
    ],
    "b_abstract":[
      "Music relies heavily on repetition to build structure and meaning. Self-reference occurs on multiple timescales, from motifs to phrases to reusing of entire sections of music, such as in pieces with ABA structure. The Transformer (Vaswani et al., 2017), a sequence model based on self-attention, has achieved compelling results in many generation tasks that require maintaining long-range coherence. This suggests that self-attention might also be well-suited to modeling music. In musical composition and performance, however, relative timing is critically important. Existing approaches for representing relative positional information in the Transformer modulate attention based on pairwise distance (Shaw et al., 2018). This is impractical for long sequences such as musical compositions since their memory complexity for intermediate relative information is quadratic in the sequence length. We propose an algorithm that reduces their intermediate memory requirement to linear in the sequence length. This enables us to demonstrate that a Transformer with our modified relative attention mechanism can generate minute-long compositions (thousands of steps, four times the length modeled in Oore et al., 2018) with compelling structure, generate continuations that coherently elaborate on a given motif, and in a seq2seq setup generate accompaniments conditioned on melodies. We evaluate the Transformer with our relative attention mechanism on two datasets, JSB Chorales and Piano-e-Competition, and obtain state-of-the-art results on the latter."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "On the use of AI for Generation of Functional Music to Improve Mental Health"
    ],
    "c_abstract":[
      "Increasingly music has been shown to have both physical and mental health benefits including improvements in cardiovascular health, a link reduction of cases dementia elderly populations, markers general well-being such as stress reduction. Here, we describe short case studies addressing (anxiety, stress-reduction) through AI-driven generation. Engaging active listening music-making activities (especially for at risk age groups) can be particularly beneficial, the practice therapy helpful range use across wide range. However, access prohibitive terms expertize, materials, cost. Furthermore existing functional outcomes (such targeted improvement suggested above) hindered by issues repetition subsequent over-familiarity with material. In this paper, machine learning approaches which create informed biophysiological measurement two studies, target emotional states opposing ends Cartesian affective space (a dimensional emotion points ranging from descriptors relaxation, fear). Galvanic skin response is used marker psychological arousal an estimate state control signal training algorithm. This algorithm creates non-linear time series musical features sound synthesis \u201con-the-fly\u201d, using perceptually feature similarity model. We find interaction between familiarity perceived response. also report on psychometric evaluation generated material, consider how these - similar techniques might useful generation tasks, example, nonlinear sound-tracking that found interactive media or video games."
    ],
    "c_categories":[
      "Mental Health"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.15211",
    "a_title":"LightLLM: A Versatile Large Language Model for Predictive Light Sensing",
    "a_abstract":"We propose LightLLM, a model that fine tunes pre-trained large language\nmodels (LLMs) for light-based sensing tasks. It integrates a sensor data\nencoder to extract key features, a contextual prompt to provide environmental\ninformation, and a fusion layer to combine these inputs into a unified\nrepresentation. This combined input is then processed by the pre-trained LLM,\nwhich remains frozen while being fine-tuned through the addition of\nlightweight, trainable components, allowing the model to adapt to new tasks\nwithout altering its original parameters. This approach enables flexible\nadaptation of LLM to specialized light sensing tasks with minimal computational\noverhead and retraining effort. We have implemented LightLLM for three light\nsensing tasks: light-based localization, outdoor solar forecasting, and indoor\nsolar estimation. Using real-world experimental datasets, we demonstrate that\nLightLLM significantly outperforms state-of-the-art methods, achieving 4.4x\nimprovement in localization accuracy and 3.4x improvement in indoor solar\nestimation when tested in previously unseen environments. We further\ndemonstrate that LightLLM outperforms ChatGPT-4 with direct prompting,\nhighlighting the advantages of LightLLM's specialized architecture for sensor\ndata fusion with textual prompts.",
    "explanation":"We propose LightLLM, a model that fine tunes pre-trained\nlarge language models (LLMs) for light-based sensing tasks.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Solar Cells for Indoor Applications: Progress and Development"
    ],
    "b_abstract":[
      "The Internet of things (IoT) has been rapidly growing in the past few years. IoT connects numerous devices, such as wireless sensors, actuators, and wearable to optimize monitor daily activities. Most these devices require power microwatt range operate indoors. To this end, a self-sustainable source, photovoltaic (PV) cell, which can harvest low-intensity indoor light, is appropriate. Recently, development highly efficient PV cells for applications attracted tremendous attention. Therefore, different types materials, inorganic, dye-sensitized, organic, perovskite have employed harvesting light energy. Although considerable efforts made by researchers develop low-cost, stable, applications, Extensive investigation necessary resolve some critical issues concerning cells, environmental stability, lifetime, large-area fabrication, mechanical flexibility, production cost. address issues, systematic review aspects will be useful research community. This study discusses current status based on previous reports. First, we provided relevant background information. Then, described sources, subsequently critically reviewed reports regarding solar active materials perovskite. Finally, placed an attempt provide insight into factors needed further improve feasibility technology applications."
    ],
    "b_categories":[
      "astro-ph.SR"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
    ],
    "c_abstract":[
      "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent models, BERT is designed to pre-train deep bidirectional representations unlabeled text by jointly conditioning on both left and right context in all layers. As result, the pre-trained can be fine-tuned with just one additional output layer create state-of-the-art models wide range of tasks, such as question answering inference, without substantial task-specific architecture modifications. conceptually simple empirically powerful. It obtains results eleven natural processing including pushing GLUE score 80.5% (7.7% point absolute improvement), MultiNLI accuracy 86.7% (4.6% SQuAD v1.1 Test F1 93.2 (1.5 improvement) v2.0 83.1 (5.1 improvement)."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00129",
    "a_title":"Scaling Particle Collision Data Analysis",
    "a_abstract":"For decades, researchers have developed task-specific models to address\nscientific challenges across diverse disciplines. Recently, large language\nmodels (LLMs) have shown enormous capabilities in handling general tasks;\nhowever, these models encounter difficulties in addressing real-world\nscientific problems, particularly in domains involving large-scale numerical\ndata analysis, such as experimental high energy physics. This limitation is\nprimarily due to BPE tokenization's inefficacy with numerical data. In this\npaper, we propose a task-agnostic architecture, BBT-Neutron, which employs a\nbinary tokenization method to facilitate pretraining on a mixture of textual\nand large-scale numerical experimental data. We demonstrate the application of\nBBT-Neutron to Jet Origin Identification (JoI), a critical categorization\nchallenge in high-energy physics that distinguishes jets originating from\nvarious quarks or gluons. Our results indicate that BBT-Neutron achieves\ncomparable performance to state-of-the-art task-specific JoI models.\nFurthermore, we examine the scaling behavior of BBT-Neutron's performance with\nincreasing data volume, suggesting the potential for BBT-Neutron to serve as a\nfoundational model for particle physics data analysis, with possible extensions\nto a broad spectrum of scientific computing applications for Big Science\nexperiments, industrial manufacturing and spacial computing. The project code\nis available at https:\/\/github.com\/supersymmetry-technologies\/bbt-neutron.",
    "explanation":"In this paper, we propose a task-agnostic architecture,\nBBT-Neutron, which employs a binary tokenization method to facilitate pre-\ntraining on a mixture of textual and large-scale numerical experimental data. We\ndemonstrate the application of BBT-Neutron to Jet Origin Identification (JoI),\na critical categorization challenge in high-energy physics that distinguishes jets\noriginating from various quarks or gluons",
    "b_id":[
      "b23"
    ],
    "b_title":[
      "DARWIN Series: Domain Specific Large Language Models for Natural Science"
    ],
    "b_abstract":[
      "Emerging tools bring forth fresh approaches to work, and the field of natural science is no different. In science, traditional manual, serial, labour-intensive work being augmented by automated, parallel, iterative processes driven artificial intelligence-based experimental automation more. To add new capabilities in enabling acceleration enrichment discovery process, we present DARWIN, a series tailored LLMs for mainly physics, chemistry, material science. This relies on open-source LLM, incorporating structured unstructured scientific knowledge from public datasets literature. We fine-tuned models using over 60,000 instruction data points, emphasizing factual correctness. During fine-tuning, introduce Scientific Instruction Generation (SIG) model, automating generation texts. eliminates need manual extraction or domain-specific graphs efficiently injects into model. also explore multi-task training strategies, revealing interconnections between tasks. DARWIN not only achieves state-of-the-art results various tasks but diminishes reliance closed-source AI models. Our research showcases ability LLM domain, with overarching goal fostering prosperity within broader community."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b29"
    ],
    "c_title":[
      "Study of Fermion pair production in e+e- collisions at 130-183 GeV"
    ],
    "c_abstract":[
      "The cross sections and forward-backward asymmetries of hadronic and leptonic\nevents produced in e+e- collisions at centre-of-mass energies of 130-183 GeV\nare presented. Results for ee, mumu, tautau, qq, bb and cc production show no\nsignificant deviation from the Standard Model predictions. This enable\nconstraints to be set upon physics beyond the Standard Model such as\nfour-fermion contact interactions, leptoquarks, Z' bosons and R-parity\nviolating squarks and sneutrinos. Limits on the energy scale Lambda of eeff\ncontact interactions are typically in the range from 2-10 TeV. Limits on\nR-parity violating sneutrinos reach masses of a few hundred GeV for large\nvalues of their Yukawa couplings."
    ],
    "c_categories":[
      "astro-ph.HE"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19475",
    "a_title":"Effective Fine-Tuning of Vision-Language Models for Accurate Galaxy\n  Morphology Analysis",
    "a_abstract":"Galaxy morphology analysis involves classifying galaxies by their shapes and\nstructures. For this task, directly training domain-specific models on large,\nannotated astronomical datasets is effective but costly. In contrast,\nfine-tuning vision foundation models on a smaller set of astronomical images is\nmore resource-efficient but generally results in lower accuracy. To harness the\nbenefits of both approaches and address their shortcomings, we propose\nGalaxAlign, a novel method that fine-tunes pre-trained foundation models to\nachieve high accuracy on astronomical tasks. Specifically, our method extends a\ncontrastive learning architecture to align three types of data in fine-tuning:\n(1) a set of schematic symbols representing galaxy shapes and structures, (2)\ntextual labels of these symbols, and (3) galaxy images. This way, GalaxAlign\nnot only eliminates the need for expensive pretraining but also enhances the\neffectiveness of fine-tuning. Extensive experiments on galaxy classification\nand similarity search demonstrate that our method effectively fine-tunes\ngeneral pre-trained models for astronomical tasks by incorporating\ndomain-specific multi-modal knowledge.",
    "explanation":"To harness the benefits of\nboth approaches and address their shortcomings, we pro-\npose GalaxAlign, a novel method that fine-tunes pre-trained\nfoundation models to achieve high accuracy on astronom-\nical tasks.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Radio galaxy zoo EMU: Towards a semantic radio galaxy morphology taxonomy"
    ],
    "b_abstract":[
      "ABSTRACT We present a novel natural language processing (NLP) approach to deriving plain English descriptors for science cases otherwise restricted by obfuscating technical terminology. address the limitations of common radio galaxy morphology classifications applying this approach. experimentally derive set semantic tags Radio Galaxy Zoo EMU (Evolutionary Map Universe) project and wider astronomical community. collect 8486 annotations morphology, from which we taxonomy tags. The are English. result is an extensible framework, more flexible, easily communicated, sensitive rare feature combinations, indescribable using current framework astronomy classifications."
    ],
    "b_categories":[
      "astro-ph.CO"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "ImageNet: A large-scale hierarchical image database"
    ],
    "c_abstract":[
      "The explosion of image data on the Internet has potential to foster more sophisticated and robust models algorithms index, retrieve, organize interact with images multimedia data. But exactly how such can be harnessed organized remains a critical problem. We introduce here new database called \"ImageNet\", large-scale ontology built upon backbone WordNet structure. ImageNet aims populate majority 80,000 synsets an average 500\u20131000 clean full resolution images. This will result in tens millions annotated by semantic hierarchy WordNet. paper offers detailed analysis its current state: 12 subtrees 5247 3.2 million total. show that is much larger scale diversity accurate than datasets. Constructing challenging task. describe collection scheme Amazon Mechanical Turk. Lastly, we illustrate usefulness through three simple applications object recognition, classification automatic clustering. hope scale, accuracy, hierarchical structure offer unparalleled opportunities researchers computer vision community beyond."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17595",
    "a_title":"Can artificial intelligence predict clinical trial outcomes?",
    "a_abstract":"The increasing complexity and cost of clinical trials, particularly in the\ncontext of oncology and advanced therapies, pose significant challenges for\ndrug development. This study evaluates the predictive capabilities of large\nlanguage models (LLMs) such as GPT-3.5, GPT-4, and HINT in determining clinical\ntrial outcomes. By leveraging a curated dataset of trials from\nClinicalTrials.gov, we compare the models' performance using metrics including\nbalanced accuracy, specificity, recall, and Matthews Correlation Coefficient\n(MCC). Results indicate that GPT-4o demonstrates robust performance in early\ntrial phases, achieving high recall but facing limitations in specificity.\nConversely, the HINT model excels in recognizing negative outcomes,\nparticularly in later trial phases, offering a balanced approach across diverse\nendpoints. Oncology trials, characterized by high complexity, remain\nchallenging for all models. Additionally, trial duration and disease categories\ninfluence predictive performance, with longer durations and complex diseases\nsuch as neoplasms reducing accuracy. This study highlights the complementary\nstrengths of LLMs and HINT, providing insights into optimizing predictive tools\nfor clinical trial design and risk management. Future advancements in LLMs are\nessential to address current gaps in handling negative outcomes and complex\ndomains.",
    "explanation":"This study evaluates the performance of large language models (LLMs) and the\nHINT model in predicting clinical trial outcomes, focusing on metrics includ-\ning Balanced Accuracy, Matthews Correlation Coefficient (MCC), Recall, and\nSpecificity",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Machine learning model to predict oncologic outcomes for drugs in randomized clinical trials"
    ],
    "b_abstract":[
      "Abstract Predicting oncologic outcome is challenging due to the diversity of cancer histologies and complex network underlying biological factors. In this study, we determine whether machine learning (ML) can extract meaningful associations between clinical trial, drug\u2010related biomarker molecular profile information. We analyzed therapeutic trials corresponding 1102 outcomes from 104 758 patients with advanced colorectal adenocarcinoma, pancreatic melanoma nonsmall\u2010cell lung cancer. For each intervention arm, a dataset following attributes was curated: line treatment, number cytotoxic chemotherapies, small\u2010molecule inhibitors, or monoclonal antibody agents, drug class, alteration status arm's population, type, probability sensitivity (PDS) (integrating genomic, transcriptomic proteomic biomarkers in population interest) outcome. A total 467 progression\u2010free survival (PFS) 369 overall (OS) data points were used as training sets build our ML (random forest) model. Cross\u2010validation for PFS OS, obtaining correlation coefficients ( r ) 0.82 0.70, respectively (outcome vs model's parameters). 156 110 OS test sets. The Spearman s predicted actual statistically significant (PFS: = 0.879, OS: 0.878, P &lt; .0001). better arm 81% N 59\/73, z 5.24, .0001) 71% (OS: 37\/52, 2.91, .004) randomized trials. success algorithm predict may be exploitable model optimize trial design pharmaceutical agents."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "Lint: Llm interaction network for clinical trial outcome prediction"
    ],
    "c_abstract":[
      "Clinical trial outcome prediction aims to predict the success probability of a clinical trial that reaches its desirable endpoint. Most of the effort focuses on developing machine learning models for making accurate predictions with diverse data sources, including clinical trial descriptions, drug molecules, and target disease conditions. Accurate trial outcome prediction helps trial planning and asset portfolio prioritization. Previous works have focused on small-molecule drugs; however, biologics are a quickly growing intervention type that lacks information that is traditionally known for drugs, like molecular properties. Additionally, traditional methods like graph neural networks are much more difficult to apply to biologics data which are a fast-growing type of drug. To address these points, we propose a Language Interaction Network (LINT), a novel method for trial outcome prediction using only free-text descriptions. We validate the effectiveness of LINT with thorough experiments across three trial phases. Specifically, LINT obtains 0.770, 0.740, and 0.748 ROC-AUC scores on phase I, II, and III, respectively, for clinical trials with biologic interventions."
    ],
    "c_categories":[
      "Clinical trials"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.15395",
    "a_title":"ChatBCI: A P300 Speller BCI Leveraging Large Language Models for\n  Improved Sentence Composition in Realistic Scenarios",
    "a_abstract":"P300 speller BCIs allow users to compose sentences by selecting target keys\non a GUI through the detection of P300 component in their EEG signals following\nvisual stimuli. Most P300 speller BCIs require users to spell words letter by\nletter, or the first few initial letters, resulting in high keystroke demands\nthat increase time, cognitive load, and fatigue. This highlights the need for\nmore efficient, user-friendly methods for faster sentence composition. In this\nwork, we introduce ChatBCI, a P300 speller BCI that leverages the zero-shot\nlearning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing\nkeystrokes and accelerating sentence composition. ChatBCI retrieves word\nsuggestions through remote queries to the GPT-3.5 API. A new GUI, displaying\nGPT-3.5 word suggestions as extra keys is designed. SWLDA is used for the P300\nclassification. Seven subjects completed two online spelling tasks: 1)\ncopy-spelling a self-composed sentence using ChatBCI, and 2) improvising a\nsentence using ChatBCI's word suggestions. Results demonstrate that in Task 1,\non average, ChatBCI outperforms letter-by-letter BCI spellers, reducing time\nand keystrokes by 62.14% and 53.22%, respectively, and increasing information\ntransfer rate by 198.96%. In Task 2, ChatBCI achieves 80.68% keystroke savings\nand a record 8.53 characters\/min for typing speed. Overall, ChatBCI, by\nemploying remote LLM queries, enhances sentence composition in realistic\nscenarios, significantly outperforming traditional spellers without requiring\nlocal model training or storage. ChatBCI's (multi-) word predictions, combined\nwith its new GUI, pave the way for developing next-generation speller BCIs that\nare efficient and effective for real-time communication, especially for users\nwith communication and motor disabilities.",
    "explanation":"In this work, we introduce ChatBCI, a P300 speller BCI that leverages the zero-\nshot learning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing keystrokes\nand accelerating sentence composition. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Brain\u2013Computer Interface Spellers: A Review"
    ],
    "b_abstract":[
      "A Brain\u2013Computer Interface (BCI) provides a novel non-muscular communication method via brain signals. BCI-speller can be considered as one of the first published BCI applications and has opened gate for many advances in field. Although BCI-spellers have been developed during last few decades, to our knowledge, no reviews described different spellers proposed studied this vital The presented speller systems are categorized according major paradigms: P300, steady-state visual evoked potential (SSVEP), motor imagery (MI). Different paradigms require specific electroencephalogram (EEG) signal features lead development appropriate Graphical User Interfaces (GUIs). purpose review is consolidate most successful since 2010, while mentioning some other older which were built explicitly spelling purposes. We aim assist researchers concerned individuals field by illustrating highlights presenting them review. It almost impossible carry out an objective comparison between spellers, each its variables, parameters, conditions. However, gathered information provided taxonomy about helpful, it could identify suitable first-hand users, well opportunities learning from previous studies researchers."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b17"
    ],
    "c_title":[
      "Language Model-Guided Classifier Adaptation for Brain-Computer Interfaces for Communication"
    ],
    "c_abstract":[
      "Brain-computer interfaces (BCIs), such as the P300 speller, can provide a means of communication for individuals with severe neuromuscular limitations. BCIs interpret electroencephalography (EEG) signals in order to translate embedded information about user's intent into executable commands control external devices. However, EEG are inherently noisy and nonstationary, posing challenge extended BCI use. Conventionally, classifier is trained via supervised learning an offline calibration session; once trained, deployed online use not updated. As statistics data change over time, performance static may decline It therefore desirable automatically adapt current without requiring recalibration. In existing semi-supervised approach, on labeled then updated using incoming unlabeled classifier-predicted labels. To reduce risk from incorrect predictions, threshold imposed exclude low-confidence label predictions expanded training set when retraining adaptive classifier. this work, we propose language model spelling error correction disambiguation correctness during learning. Results simulations multi-session speller user demonstrate that our language-guided approach significantly improves accuracy relative conventional threshold-based"
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.08063",
    "a_title":"MatPilot: an LLM-enabled AI Materials Scientist under the Framework of\n  Human-Machine Collaboration",
    "a_abstract":"The rapid evolution of artificial intelligence, particularly large language\nmodels, presents unprecedented opportunities for materials science research. We\nproposed and developed an AI materials scientist named MatPilot, which has\nshown encouraging abilities in the discovery of new materials. The core\nstrength of MatPilot is its natural language interactive human-machine\ncollaboration, which augments the research capabilities of human scientist\nteams through a multi-agent system. MatPilot integrates unique cognitive\nabilities, extensive accumulated experience, and ongoing curiosity of\nhuman-beings with the AI agents' capabilities of advanced abstraction, complex\nknowledge storage and high-dimensional information processing. It could\ngenerate scientific hypotheses and experimental schemes, and employ predictive\nmodels and optimization algorithms to drive an automated experimental platform\nfor experiments. It turns out that our system demonstrates capabilities for\nefficient validation, continuous learning, and iterative optimization.",
    "explanation":"proposed and\ndeveloped an AI materials scientist named MatPilot, which has shown encouraging\nabilities in the discovery of new materials. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "A Data-Science Approach to Predict the Heat Capacity of Nanoporous Materials"
    ],
    "b_abstract":[
      "The heat capacity of a material is a fundamental property of great practical importance. For example, in a carbon capture process, the heat required to regenerate a solid sorbent is directly related to the heat capacity of the material. However, for most materials suitable for carbon capture applications, the heat capacity is not known, and thus the standard procedure is to assume the same value for all materials. In this work, we developed a machine learning approach, trained on density functional theory simulations, to accurately predict the heat capacity of these materials, that is, zeolites, metal\u2013organic frameworks and covalent\u2013organic frameworks. The accuracy of our prediction is confirmed with experimental data. Finally, for a temperature swing adsorption process that captures carbon from the flue gas of a coal-fired power plant, we show that for some materials, the heat requirement is reduced by as much as a factor of two using the correct heat capacity. Heat capacity of nanoporous materials is important for processes such as carbon capture, as this can affect process design energy requirements. Here, a machine learning approach for heat capacity prediction, trained on density functional theory simulations, is presented and experimentally verified."
    ],
    "b_categories":[
      "cond-mat.mtrl-sci"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "A deep-learning approach to realizing functionality in nanoelectronic devices"
    ],
    "c_abstract":[
      "Many nanoscale devices require precise optimization to function. Tuning them to the desired operation regime becomes increasingly difficult and time-consuming when the number of terminals and couplings grows. Imperfections and device-to-device variations hinder optimization that uses physics-based models. Deep neural networks (DNNs) can model various complex physical phenomena but, so far, are mainly used as predictive tools. Here, we propose a generic deep-learning approach to efficiently optimize complex, multi-terminal nanoelectronic devices for desired functionality. We demonstrate our approach for realizing functionality in a disordered network of dopant atoms in silicon. We model the input\u2013output characteristics of the device with a DNN, and subsequently optimize control parameters in the DNN model through gradient descent to realize various classification tasks. When the corresponding control settings are applied to the physical device, the resulting functionality is as predicted by the DNN model. We expect our approach to contribute to fast, in situ optimization of complex (quantum) nanoelectronic devices."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.13126",
    "a_title":"A Knowledge-enhanced Pathology Vision-language Foundation Model for\n  Cancer Diagnosis",
    "a_abstract":"Deep learning has enabled the development of highly robust foundation models\nfor various pathological tasks across diverse diseases and patient cohorts.\nAmong these models, vision-language pre-training, which leverages large-scale\npaired data to align pathology image and text embedding spaces, and provides a\nnovel zero-shot paradigm for downstream tasks. However, existing models have\nbeen primarily data-driven and lack the incorporation of domain-specific\nknowledge, which limits their performance in cancer diagnosis, especially for\nrare tumor subtypes. To address this limitation, we establish a\nKnowledge-enhanced Pathology (KEEP) foundation model that harnesses disease\nknowledge to facilitate vision-language pre-training. Specifically, we first\nconstruct a disease knowledge graph (KG) that covers 11,454 human diseases with\n139,143 disease attributes, including synonyms, definitions, and hypernym\nrelations. We then systematically reorganize the millions of publicly available\nnoisy pathology image-text pairs, into 143K well-structured semantic groups\nlinked through the hierarchical relations of the disease KG. To derive more\nnuanced image and text representations, we propose a novel knowledge-enhanced\nvision-language pre-training approach that integrates disease knowledge into\nthe alignment within hierarchical semantic groups instead of unstructured\nimage-text pairs. Validated on 18 diverse benchmarks with more than 14,000\nwhole slide images (WSIs), KEEP achieves state-of-the-art performance in\nzero-shot cancer diagnostic tasks. Notably, for cancer detection, KEEP\ndemonstrates an average sensitivity of 89.8% at a specificity of 95.0% across 7\ncancer types. For cancer subtyping, KEEP achieves a median balanced accuracy of\n0.456 in subtyping 30 rare brain cancers, indicating strong generalizability\nfor diagnosing rare tumors.",
    "explanation":"However, existing models have been primarily data-driven and\nlack the incorporation of domain-specific knowledge, which limits their performance in cancer diagnosis,\nespecially for rare tumor subtypes. To address this limitation, we establish a KnowledgE-Enhanced\nPathology (KEEP) foundation model that harnesses disease knowledge to facilitate vision-language\npre-training.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Machine Learning-driven Histotype Diagnosis of Ovarian Carcinoma: Insights from the OCEAN AI Challenge"
    ],
    "b_abstract":[
      "Ovarian cancer poses a significant health burden as one of the deadliest malignancies affecting women globally. Histotype assignment of epithelial ovarian cancers can be challenging due to morphologic overlap, inter-observer variability, and the lack of ancillary diagnostic techniques in some areas of the world. Moreover, rare cancers can pose particular diagnostic difficulties because of a relative lack of familiarity with them, underscoring the necessity for robust diagnostic methodologies. The emergence of Artificial Intelligence (AI) has brought promising prospects to the realm of ovarian cancer diagnosis. While various studies have underscored AI's promise, its validation across multiple healthcare centers and hospitals has been limited. Inspired by innovations in medical imaging driven by public competitions, we initiated the Ovarian Cancer subtypE clAssification and outlier detectioN (OCEAN) challenge, the most extensive histopathology competition to date."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Viable and necrotic tumor assessment from whole slide images of osteosarcoma using machine-learning and deep-learning models"
    ],
    "c_abstract":[
      "Pathological estimation of tumor necrosis after chemotherapy is essential for patients with osteosarcoma. This study reports the first fully automated tool to assess viable and necrotic in osteosarcoma, employing advances histopathology digitization learning. We selected 40 digitized whole slide images representing heterogeneity osteosarcoma response. With goal labeling diverse regions tissue into tumor, non-tumor, we trained 13 machine-learning models top performing one (a Support Vector Machine) based on reported accuracy. also developed a deep-learning architecture it same data set. computed receiver-operator characteristic discrimination non-tumor from followed by conditional found our exceptionally well. then used identify interest image-tiles generated test images. The classification output visualized as tumor-prediction map, displaying extent image. Thus, lay foundation complete assessment pipeline original histology map generation. proposed can be adopted other types tumor."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17717",
    "a_title":"Comprehensive Methodology for Sample Augmentation in EEG Biomarker\n  Studies for Alzheimers Risk Classification",
    "a_abstract":"Background: Dementia, marked by cognitive decline, is a global health\nchallenge. Alzheimer's disease (AD), the leading type, accounts for ~70% of\ncases. Electroencephalography (EEG) measures show promise in identifying AD\nrisk, but obtaining large samples for reliable comparisons is challenging.\nObjective: This study integrates signal processing, harmonization, and\nstatistical techniques to enhance sample size and improve AD risk\nclassification reliability. Methods: We used advanced EEG preprocessing,\nfeature extraction, harmonization, and propensity score matching (PSM) to\nbalance healthy non-carriers (HC) and asymptomatic E280A mutation carriers\n(ACr). Data from four databases were harmonized to adjust site effects while\npreserving covariates like age and sex. PSM ratios (2:1, 5:1, 10:1) were\napplied to assess sample size impact on model performance. The final dataset\nunderwent machine learning analysis with decision trees and cross-validation\nfor robust results. Results: Balancing sample sizes via PSM significantly\nimproved classification accuracy, ranging from 0.92 to 0.96 across ratios. This\napproach enabled precise risk identification even with limited samples.\nConclusion: Integrating data processing, harmonization, and balancing\ntechniques improves AD risk classification accuracy, offering potential for\nother neurodegenerative diseases.",
    "explanation":"This study implements a\ncomprehensive methodology that integrates signal processing, data harmonization, and\nstatistical techniques to increase sample size and improve the reliability of Alzheimer's disease\nrisk classification models.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Neural biomarker diagnosis and prediction to mild cognitive impairment and Alzheimer\u2019s disease using EEG technology"
    ],
    "b_abstract":[
      "Background Electroencephalogram (EEG) has emerged as a non-invasive tool to detect the aberrant neuronal activity related to different stages of Alzheimer\u2019s disease (AD). However, the effectiveness of EEG in the precise diagnosis and assessment of AD and its preclinical stage, amnestic mild cognitive impairment (MCI), has yet to be fully elucidated. In this study, we aimed to identify key EEG biomarkers that are effective in distinguishing patients at the early stage of AD and monitoring the progression of AD. Methods A total of 890 participants, including 189 patients with MCI, 330 patients with AD, 125 patients with other dementias (frontotemporal dementia, dementia with Lewy bodies, and vascular cognitive impairment), and 246 healthy controls (HC) were enrolled. Biomarkers were extracted from resting-state EEG recordings for a three-level classification of HC, MCI, and AD. The optimal EEG biomarkers were then identified based on the classification performance. Random forest regression was used to train a series of models by combining participants\u2019 EEG biomarkers, demographic information (i.e., sex, age), CSF biomarkers, and APOE phenotype for assessing the disease progression and individual\u2019s cognitive function. Results The identified EEG biomarkers achieved over 70% accuracy in the three-level classification of HC, MCI, and AD. Among all six groups, the most prominent effects of AD-linked neurodegeneration on EEG metrics were localized at parieto-occipital regions. In the cross-validation predictive analyses, the optimal EEG features were more effective than the CSF + APOE biomarkers in predicting the age of onset and disease course, whereas the combination of EEG + CSF + APOE measures achieved the best performance for all targets of prediction. Conclusions Our study indicates that EEG can be used as a useful screening tool for the diagnosis and disease progression evaluation of MCI and AD."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Quantitative EEG analysis disease during resting and memory task in carriers and non-carriers of PS-1 E280A mutation of familial Alzheimer's"
    ],
    "c_abstract":[
      "Background: Alzheimer\u2019s disease is the most leading cause of dementia in world; mutation PS-1 E280A alters gene Presenilin-1 and causes an early onset familial disease. This has been found large kindred Antioquia, Colombia. The objective this study was to find differences revealed by electroencephalogram between healthy subjects asymptomatic carriers that can be used as clinical markers population. Methods: EEG recorded 15 non during resting a memory task using 64 channels amplifier. Two conditions were analyzed: encoding retrieval, process recording evocating information, respectively. Power spectrum calculated delta (0.5\u20134.0 Hz), theta (4.0\u20138. 0 alpha-1 (8.0\u201310.0 alpha-2 (10.0\u201313.0 beta (13.0\u201325.0 Hz) gamma (25.0\u201350 frequency bands for four regions interest. Changes evaluated different ANOVA analysis. Results: In condition significant decrease (p=0. 0001) increase frequencies (p=0.037) compare with controls. During significantly lower compared controls 008) comparing versus retrieval each group, there more synchronization carriers. Conclusion: Early changes observed recordings, it could use Also seems activate additional cortical order conserve successful cognitive functions before impairment ."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.16728",
    "a_title":"Maximizing the Impact of Deep Learning on Subseasonal-to-Seasonal\n  Climate Forecasting: The Essential Role of Optimization",
    "a_abstract":"Weather and climate forecasting is vital for sectors such as agriculture and\ndisaster management. Although numerical weather prediction (NWP) systems have\nadvanced, forecasting at the subseasonal-to-seasonal (S2S) scale, spanning 2 to\n6 weeks, remains challenging due to the chaotic and sparse atmospheric signals\nat this interval. Even state-of-the-art deep learning models struggle to\noutperform simple climatology models in this domain. This paper identifies that\noptimization, instead of network structure, could be the root cause of this\nperformance gap, and then we develop a novel multi-stage optimization strategy\nto close the gap. Extensive empirical studies demonstrate that our multi-stage\noptimization approach significantly improves key skill metrics, PCC and TCC,\nwhile utilizing the same backbone structure, surpassing the state-of-the-art\nNWP systems (ECMWF-S2S) by over \\textbf{19-91\\%}. Our research contests the\nrecent study that direct forecasting outperforms rolling forecasting for S2S\ntasks. Through theoretical analysis, we propose that the underperformance of\nrolling forecasting may arise from the accumulation of Jacobian matrix products\nduring training. Our multi-stage framework can be viewed as a form of teacher\nforcing to address this issue. Code is available at\n\\url{https:\/\/anonymous.4open.science\/r\/Baguan-S2S-23E7\/}",
    "explanation":"Weather and climate forecasting is vital for sectors such\nas agriculture and disaster management. Although numeri-\ncal weather prediction (NWP) systems have advanced, fore-\ncasting at the subseasonal-to-seasonal (S2S) scale, span-\nning 2 to 6 weeks, remains challenging due to the chaotic\nand sparse atmospheric signals at this interval.",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "FuXi-S2S: An accurate machine learning model for global subseasonal forecasts"
    ],
    "b_abstract":[
      "Skillful subseasonal forecasts beyond 2 weeks are crucial for a wide range of applications across various sectors society. Recently, state-of-the-art machine learning based weather forecasting models have made significant advancements, outperforming the high-resolution forecast (HRES) from European Centre Medium-Range Weather Forecasts (ECMWF). However, full potential in has yet to be fully explored. In this study, we introduce FuXi Subseasonal-to-Seasonal (FuXi-S2S), model that provides global daily mean up 42 days, covering 5 upper-air atmospheric variables at 13 pressure levels and 11 surface variables. FuXi-S2S integrates an enhanced base with perturbation module flow-dependent perturbations hidden features, incorporates Perlin noise perturb initial conditions. The is developed using 72 years statistics ECMWF ERA5 reanalysis data. When compared (S2S) reforecasts, demonstrate superior deterministic ensemble total precipitation (TP), outgoing longwave radiation (OLR), geopotential 500 hPa (Z500). Although it shows slightly inferior performance predicting 2-meter temperature (T2M), clear advantages over land area. Regarding extreme forecasts, outperforms S2S globally TP. Furthermore, surpass reforecasts Madden Julian Oscillation (MJO), key source predictability. They extend skillful prediction MJO 30 days 36 days."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b21"
    ],
    "c_title":[
      "Analysis methods for numerical weather prediction"
    ],
    "c_abstract":[
      "Abstract Bayesian probabilistic arguments are used to derive idealized equations for finding the best analysis numerical weather prediction. These compared with those from other published methods in light of physical characteristics NWP problem; namely predetermined nature basis analysis, need approximation because large\u2010order systems, underdeterminacy problem when using observations alone, and availability prior relationships resolve underdeterminacy. Prior result (1) knowledge time evolution model (which together use a distribution constitutes four\u2010dimensional data assimilation); (2) that atmosphere varies slowly (leading balance relationships); (3) nonlinear coupling parameters scales atmosphere. Methods discussed include variational techniques, smoothing splines, Kriging, optimal interpolation, successive corrections, constrained initialization, Kalman\u2010Bucy filter, adjoint assimilation. They all shown relate hence each other. Opinions given on particular might be more appropriate. By comparison method some insight is gained into appropriate choices practical methods."
    ],
    "c_categories":[
      "physics.data-an"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.02466",
    "a_title":"Weakly supervised deep learning model with size constraint for prostate\n  cancer detection in multiparametric MRI and generalization to unseen domains",
    "a_abstract":"Fully supervised deep models have shown promising performance for many\nmedical segmentation tasks. Still, the deployment of these tools in clinics is\nlimited by the very timeconsuming collection of manually expert-annotated data.\nMoreover, most of the state-ofthe-art models have been trained and validated on\nmoderately homogeneous datasets. It is known that deep learning methods are\noften greatly degraded by domain or label shifts and are yet to be built in\nsuch a way as to be robust to unseen data or label distributions. In the\nclinical setting, this problematic is particularly relevant as the deployment\ninstitutions may have different scanners or acquisition protocols than those\nfrom which the data has been collected to train the model. In this work, we\npropose to address these two challenges on the detection of clinically\nsignificant prostate cancer (csPCa) from bi-parametric MRI. We evaluate the\nmethod proposed by (Kervadec et al., 2018), which introduces a size constaint\nloss to produce fine semantic cancer lesions segmentations from weak circle\nscribbles annotations. Performance of the model is based on two public (PI-CAI\nand Prostate158) and one private databases. First, we show that the model\nachieves on-par performance with strong fully supervised baseline models, both\non in-distribution validation data and unseen test images. Second, we observe a\nperformance decrease for both fully supervised and weakly supervised models\nwhen tested on unseen data domains. This confirms the crucial need for\nefficient domain adaptation methods if deep learning models are aimed to be\ndeployed in a clinical environment. Finally, we show that ensemble predictions\nfrom multiple trainings increase generalization performance.",
    "explanation":"n this work, we propose to address these two challenges\non the detection of clinically significant prostate cancer (csPCa) from bi-parametric MRI.\nWe evaluate the method proposed by (Kervadec et al., 2018), which introduces a size con-\nstaint loss to produce fine semantic cancer lesions segmentations from weak circle scribbles\nannotations",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "A review of artificial intelligence in prostate cancer detection on imaging"
    ],
    "b_abstract":[
      "A multitude of studies have explored the role artificial intelligence (AI) in providing diagnostic support to radiologists, pathologists, and urologists prostate cancer detection, risk-stratification, management. This review provides a comprehensive overview relevant literature regarding use AI models (1) detecting on radiology images (magnetic resonance ultrasound imaging), (2) histopathology biopsy tissue, (3) assisting supporting tasks for detection (prostate gland segmentation, MRI-histopathology registration, MRI-ultrasound registration). We discuss both potential these assist clinical workflow diagnosis, as well current limitations including variability training data sets, algorithms, evaluation criteria. also ongoing challenges what is needed bridge gap between academic research commercial solutions that improve routine care."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "Automatic Prostate Cancer Detection On Multi-Parametric Mri With Hierarchical Weakly Supervised Learning"
    ],
    "c_abstract":[
      "Multi-parametric MRI (mp-MRI) is one of the most commonly used non-invasive methods for prostate cancer (PCa) diagnosis. In recent years, computer aided diagnosis (CAD) PCa on mp-MRI based deep learning techniques has gained much attention and shown promising progress. The key success to obtain a large amount high quality region annotation such that network can accurately learn variation lesions. order precisely annotate mp-MRI, pathological whole mount data patient normally required as reference, which often difficult in real world clinical situations. Therefore, we are motivated propose new method integrate different levels information available screening workflow through multitask hierarchical weakly supervised framework detection mp-MRI. Experimental results show our achieves segmentation results."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.02614",
    "a_title":"Divergent Domains, Convergent Grading: Enhancing Generalization in\n  Diabetic Retinopathy Grading",
    "a_abstract":"Diabetic Retinopathy (DR) constitutes 5% of global blindness cases. While\nnumerous deep learning approaches have sought to enhance traditional DR grading\nmethods, they often falter when confronted with new out-of-distribution data\nthereby impeding their widespread application. In this study, we introduce a\nnovel deep learning method for achieving domain generalization (DG) in DR\ngrading and make the following contributions. First, we propose a new way of\ngenerating image-to-image diagnostically relevant fundus augmentations\nconditioned on the grade of the original fundus image. These augmentations are\ntailored to emulate the types of shifts in DR datasets thus increase the\nmodel's robustness. Second, we address the limitations of the standard\nclassification loss in DG for DR fundus datasets by proposing a new DG-specific\nloss, domain alignment loss; which ensures that the feature vectors from all\ndomains corresponding to the same class converge onto the same manifold for\nbetter domain generalization. Third, we tackle the coupled problem of data\nimbalance across DR domains and classes by proposing to employ Focal loss which\nseamlessly integrates with our new alignment loss. Fourth, due to inevitable\nobserver variability in DR diagnosis that induces label noise, we propose\nleveraging self-supervised pretraining. This approach ensures that our DG model\nremains robust against early susceptibility to label noise, even when only a\nlimited dataset of non-DR fundus images is available for pretraining. Our\nmethod demonstrates significant improvements over the strong Empirical Risk\nMinimization baseline and other recently proposed state-of-the-art DG methods\nfor DR grading. Code is available at https:\/\/github.com\/sharonchokuwa\/dg-adr.",
    "explanation":"In this study, we introduce a novel deep learning\nmethod for achieving domain generalization (DG) in DR\ngrading and make the following contributions.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Medical diffusion on a budget: textual inversion for medical image generation"
    ],
    "b_abstract":[
      "Diffusion-based models for text-to-image generation have gained immense popularity due to recent advancements in efficiency, accessibility, and quality. Although it is becoming increasingly feasible perform inference with these systems using consumer-grade GPUs, training them from scratch still requires access large datasets significant computational resources. In the case of medical image generation, availability large, publicly accessible that include text reports limited legal ethical concerns. While a diffusion model on private dataset may address this issue, not always institutions lacking necessary This work demonstrates pre-trained Stable Diffusion models, originally trained natural images, can be adapted various imaging modalities by embeddings textual inversion. study, we conducted experiments comprising only 100 samples three modalities. Embeddings were matter hours, while retaining diagnostic relevance generation. Experiments designed achieve several objectives. Firstly, fine-tuned processes inversion, revealing larger more examples are required. Secondly, validated our approach demonstrating 2\\% increase accuracy (AUC) detecting prostate cancer MRI, which challenging multi-modal modality, 0.78 0.80. Thirdly, performed simulations interpolating between healthy diseased states, combining multiple pathologies, inpainting show embedding flexibility control disease appearance. Finally, study small (less than 1 MB), facilitates easy sharing data reduced privacy"
    ],
    "b_categories":[
      "q-bio.OT"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "Deep Learning Techniques for Diabetic Retinopathy Classification: A Survey"
    ],
    "c_abstract":[
      "Diabetic Retinopathy (DR) is a degenerative disease that impacts the eyes and consequence of Diabetes mellitus, where high blood glucose levels induce lesions on eye retina.Diabetic regarded as leading cause blindness for diabetic patients, especially working-age population in developing nations.Treatment involves sustaining patient's current grade vision since irreversible.Early detection crucial order to sustain effectively.The main issue involved with DR manual diagnosis process very time, money, effort consuming an ophthalmologist's examination retinal fundus images.The latter also proves be more difficult, particularly early stages when features are less prominent images.Machine learning-based medical image analysis has proven competency assessing images, utilization deep learning algorithms aided (DR).This paper reviews analyzes state-of-the-art methods supervised, self-supervised, Vision Transformer setups, proposing classification detection.For instance, referable, non-referable, proliferative classifications reviewed summarized.Moreover, discusses available datasets used tasks such detection, classification, segmentation.The assesses research gaps area detection\/classification addresses various challenges need further study investigation."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18767",
    "a_title":"Multi-Task Learning for Integrated Automated Contouring and Voxel-Based\n  Dose Prediction in Radiotherapy",
    "a_abstract":"Deep learning-based automated contouring and treatment planning has been\nproven to improve the efficiency and accuracy of radiotherapy. However,\nconventional radiotherapy treatment planning process has the automated\ncontouring and treatment planning as separate tasks. Moreover in deep learning\n(DL), the contouring and dose prediction tasks for automated treatment planning\nare done independently. In this study, we applied the multi-task learning (MTL)\napproach in order to seamlessly integrate automated contouring and voxel-based\ndose prediction tasks, as MTL can leverage common information between the two\ntasks and be able able to increase the efficiency of the automated tasks. We\ndeveloped our MTL framework using the two datasets: in-house prostate cancer\ndataset and the publicly available head and neck cancer dataset, OpenKBP.\nCompared to the sequential DL contouring and treatment planning tasks, our\nproposed method using MTL improved the mean absolute difference of dose volume\nhistogram metrics of prostate and head and neck sites by 19.82% and 16.33%,\nrespectively. Our MTL model for automated contouring and dose prediction tasks\ndemonstrated enhanced dose prediction performance while maintaining or\nsometimes even improving the contouring accuracy. Compared to the baseline\nautomated contouring model with the dice score coefficients of 0.818 for\nprostate and 0.674 for head and neck datasets, our MTL approach achieved\naverage scores of 0.824 and 0.716 for these datasets, respectively. Our study\nhighlights the potential of the proposed automated contouring and planning\nusing MTL to support the development of efficient and accurate automated\ntreatment planning for radiotherapy.",
    "explanation":"Deep learning-based automated contouring and treatment planning has\nbeen proven to improve the efficiency and accuracy of radiotherapy.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "A Transformer-Embedded Multi-Task Model for Dose Distribution Prediction"
    ],
    "b_abstract":[
      "Radiation therapy is a fundamental cancer treatment in the clinic. However, to satisfy clinical requirements, radiologists have iteratively adjust radiotherapy plan based on experience, causing it extremely subjective and time-consuming obtain clinically acceptable plan. To this end, we introduce transformer-embedded multi-task dose prediction (TransMTDP) network automatically predict distribution radiotherapy. Specifically, achieve more stable accurate predictions, three highly correlated tasks are included our TransMTDP network, i.e. main task provide each pixel with fine-grained value, an auxiliary isodose lines produce coarse-grained ranges, gradient learn subtle information such as radiation patterns edges maps. The integrated through shared encoder, following learning strategy. strengthen connection of output layers for different tasks, further use two additional constraints, consistency loss loss, reinforce match between features generated by task. Additionally, considering many organs human body symmetrical maps present abundant global features, embed transformer into framework capture long-range dependencies Evaluated in-house rectum dataset public head neck dataset, method gains superior performance compared state-of-the-art ones. Code available at https:\/\/github.com\/luuuwen\/TransMTDP."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Clinical integration of machine learning for curative-intent radiation treatment of patients with prostate cancer"
    ],
    "c_abstract":[
      "Machine learning (ML) holds great promise for impacting healthcare delivery; however, to date most methods are tested in \u2018simulated\u2019 environments that cannot recapitulate factors influencing real-world clinical practice. We prospectively deployed and evaluated a random forest algorithm for therapeutic curative-intent radiation therapy (RT) treatment planning for prostate cancer in a blinded, head-to-head study with full integration into the clinical workflow. ML- and human-generated RT treatment plans were directly compared in a retrospective simulation with retesting (n\u2009=\u200950) and a prospective clinical deployment (n\u2009=\u200950) phase. Consistently throughout the study phases, treating physicians assessed ML- and human-generated RT treatment plans in a blinded manner following a priori defined standardized criteria and peer review processes, with the selected RT plan in the prospective phase delivered for patient treatment. Overall, 89% of ML-generated RT plans were considered clinically acceptable and 72% were selected over human-generated RT plans in head-to-head comparisons. RT planning using ML reduced the median time required for the entire RT planning process by 60.1% (118 to 47\u2009h). While ML RT plan acceptability remained stable between the simulation and deployment phases (92 versus 86%), the number of ML RT plans selected for treatment was significantly reduced (83 versus 61%, respectively). These findings highlight that retrospective or simulated evaluation of ML methods, even under expert blinded review, may not be representative of algorithm acceptance in a real-world clinical setting when patient care is at stake."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.10004",
    "a_title":"EyeDiff: text-to-image diffusion model improves rare eye disease\n  diagnosis",
    "a_abstract":"The rising prevalence of vision-threatening retinal diseases poses a\nsignificant burden on the global healthcare systems. Deep learning (DL) offers\na promising solution for automatic disease screening but demands substantial\ndata. Collecting and labeling large volumes of ophthalmic images across various\nmodalities encounters several real-world challenges, especially for rare\ndiseases. Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and\nevaluate its applicability in diagnosing common and rare diseases. EyeDiff is\ntrained on eight large-scale datasets using the advanced latent diffusion\nmodel, covering 14 ophthalmic image modalities and over 80 ocular diseases, and\nis adapted to ten multi-country external datasets. The generated images\naccurately capture essential lesional characteristics, achieving high alignment\nwith text prompts as evaluated by objective metrics and human experts.\nFurthermore, integrating generated images significantly enhances the accuracy\nof detecting minority classes and rare eye diseases, surpassing traditional\noversampling methods in addressing data imbalance. EyeDiff effectively tackles\nthe issue of data imbalance and insufficiency typically encountered in rare\ndiseases and addresses the challenges of collecting large-scale annotated\nimages, offering a transformative solution to enhance the development of\nexpert-level diseases diagnosis models in ophthalmic field.",
    "explanation":"Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and evaluate its\napplicability in diagnosing common and rare diseases.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Artificial Intelligence for Pediatric Ophthalmology"
    ],
    "b_abstract":[
      "PURPOSE OF REVIEW: Despite the impressive results of recent artificial\nintelligence (AI) applications to general ophthalmology, comparatively less\nprogress has been made toward solving problems in pediatric ophthalmology using\nsimilar techniques. This article discusses the unique needs of pediatric\nophthalmology patients and how AI techniques can address these challenges,\nsurveys recent applications of AI to pediatric ophthalmology, and discusses\nfuture directions in the field.\n  RECENT FINDINGS: The most significant advances involve the automated\ndetection of retinopathy of prematurity (ROP), yielding results that rival\nexperts. Machine learning (ML) has also been successfully applied to the\nclassification of pediatric cataracts, prediction of post-operative\ncomplications following cataract surgery, detection of strabismus and\nrefractive error, prediction of future high myopia, and diagnosis of reading\ndisability via eye tracking. In addition, ML techniques have been used for the\nstudy of visual development, vessel segmentation in pediatric fundus images,\nand ophthalmic image synthesis.\n  SUMMARY: AI applications could significantly benefit clinical care for\npediatric ophthalmology patients by optimizing disease detection and grading,\nbroadening access to care, furthering scientific discovery, and improving\nclinical efficiency. These methods need to match or surpass physician\nperformance in clinical trials before deployment with patients. Due to\nwidespread use of closed-access data sets and software implementations, it is\ndifficult to directly compare the performance of these approaches, and\nreproducibility is poor. Open-access data sets and software implementations\ncould alleviate these issues, and encourage further AI applications to\npediatric ophthalmology.\n  KEYWORDS: pediatric ophthalmology, machine learning, artificial intelligence,\ndeep learning"
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "Classification of Retinal Diseases in Optical Coherence Tomography Images Using Artificial Intelligence and Firefly Algorithm"
    ],
    "c_abstract":[
      "In recent years, the number of studies for automatic diagnosis biomedical diseases has increased. Many these have used Deep Learning, which gives extremely good results but requires a vast amount data and computing load. If processor is insufficient quality, this takes time places an excessive load on processor. On other hand, Machine Learning faster than does not much-needed load, it provide as high accuracy value Learning. Therefore, our goal to develop hybrid system that provides value, while requiring smaller less diagnose such retinal we chose study. For purpose, first, layer extraction was conducted through image preprocessing. Then, traditional feature extractors were combined with pre-trained extractors. To select best features, Firefly algorithm. end, multiple binary classifications instead multiclass classification classifiers. Two public datasets in The first dataset had mean 0.957, second 0.954."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01375",
    "a_title":"Scaling Laws with Hidden Structure",
    "a_abstract":"Statistical learning in high-dimensional spaces is challenging without a\nstrong underlying data structure. Recent advances with foundational models\nsuggest that text and image data contain such hidden structures, which help\nmitigate the curse of dimensionality. Inspired by results from nonparametric\nstatistics, we hypothesize that this phenomenon can be partially explained in\nterms of decomposition of complex tasks into simpler subtasks. In this paper,\nwe present a controlled experimental framework to test whether neural networks\ncan indeed exploit such ``hidden factorial structures.'' We find that they do\nleverage these latent patterns to learn discrete distributions more\nefficiently, and derive scaling laws linking model sizes, hidden\nfactorizations, and accuracy. We also study the interplay between our\nstructural assumptions and the models' capacity for generalization.",
    "explanation":"The key references I chose in Task 3 combined the concepts of Neural Networks with Discrete Distribution Theory to support this IDR paper. In the abstract, the following lines describe the integration of those selected references:\n\"In this paper, we present a controlled experimental framework to test whether neural networks can indeed exploit such \u201chidden factorial structures.\u201d\n\"We find that they do leverage these latent patterns to learn discrete distributions more efficiently. \"\n\n",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Learning Parities with Neural Networks"
    ],
    "b_abstract":[
      "In recent years we see a rapidly growing line of research which shows learnability various models via common neural network algorithms. Yet, besides very few outliers, these results show that can be learned using linear methods. Namely, such learning neural-networks with gradient-descent is competitive classifier on top data-independent representation the examples. This leaves much to desired, as networks are far more successful than Furthermore, conceptual level, don't seem capture deepness deep networks. this paper make step towards showing leanability inherently non-linear. We under certain distributions, sparse parities learnable gradient decent depth-two network. On other hand, same cannot efficiently by"
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Testing conditional independence of discrete distributions"
    ],
    "c_abstract":[
      "We study the problem of testing *conditional independence* for discrete distributions. Specifically, given samples from a random variable (X, Y, Z) on domain [\u21131]\u00d7[\u21132] \u00d7 [n], we want to distinguish, with probability at least 2\/3, between case that X and Y are conditionally independent Z is \u0454-far, in \u21131-distance, every distribution has this property. Conditional independence concept central importance statistics important applications various scientific domains. As such, statistical task conditional been extensively studied forms within econometrics community nearly century. Perhaps surprisingly, not previously considered framework property particular no tester *sublinear* sample complexity known, even special domains binary."
    ],
    "c_categories":[
      "stat.CO"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2412.00544",
    "a_title":"RoBo6: Standardized MMT Light Curve Dataset for Rocket Body\n  Classification",
    "a_abstract":"Space debris presents a critical challenge for the sustainability of future\nspace missions, emphasizing the need for robust and standardized identification\nmethods. However, a comprehensive benchmark for rocket body classification\nremains absent. This paper addresses this gap by introducing the RoBo6 dataset\nfor rocket body classification based on light curves. The dataset, derived from\nthe Mini Mega Tortora database, includes light curves for six rocket body\nclasses: CZ-3B, Atlas 5 Centaur, Falcon 9, H-2A, Ariane 5, and Delta 4. With\n5,676 training and 1,404 test samples, it addresses data inconsistencies using\nresampling, normalization, and filtering techniques. Several machine learning\nmodels were evaluated, including CNN and transformer-based approaches, with\nAstroconformer reporting the best performance. The dataset establishes a common\nbenchmark for future comparisons and advancements in rocket body classification\ntasks.",
    "explanation":"The selected references in Task 3 were based from the following topics introduced in the abstract:\n\n\"Space debris presents a critical challenge for the sustainability of future space missions, emphasizing the need for robust and standardized identification methods.\"\n\"Several machine learning models were evaluated, including\nCNN and transformer-based approaches, with  Astroconformer reporting the best performance\"",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "Attention Is All You Need"
    ],
    "b_abstract":[
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. best performing also connect the encoder and decoder through attention mechanism. We propose a new simple network architecture, Transformer, solely mechanisms, dispensing with recurrence convolutions entirely. Experiments two machine translation tasks show these to be superior quality while being more parallelizable requiring significantly less time train. Our model achieves 28.4 BLEU WMT 2014 English-to-German task, improving over existing results, including ensembles by 2 BLEU. On English-to-French our establishes single-model state-of-the-art score of 41.8 after training for 3.5 days eight GPUs, small fraction costs from literature. that Transformer generalizes well other applying it successfully English constituency parsing both large limited data."
    ],
    "b_categories":[
      "cond-mat.dis-nn"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Space objects classification via lightcurve measurements: deep convolutional neural networks and model-based transfer learning"
    ],
    "c_abstract":[
      "Developing a detailed understanding of the Space Object (SO) population is a fundamental goal of Space Situational Awareness (SSA). The current SO catalog includes simplified characteristic for the observed space objects, mainly the solar radiation pressure and\/or drag ballistic coefficients. Such simplified description limits the dynamic propagation model used for predicting the state of motion of SO to models that assume cannon ball shapes and generic surface properties. The future SO catalog and SSA systems will have to be capable of building a detailed picture of SO characteristics. Traditional measurement sources for SO tracking, such as radar and optical, provide information on SO characteristics. These measurements have been shown to be sensitive to shape, attitude, angular velocity, and surface parameters. State-of-the-art in the literature has been advanced over the past decades and in recent years seen the development of multiple models, nonlinear state estimation, and full Bayesian inversion approaches for SO characterization. The key shortcoming of approaches in literature is their overall computational cost and the limited flexibility to deal with a larger and larger amount of data. In this paper, we present a data-driven method to classification of SO based on a deep learning approach that takes advantage of the representational power of deep neural networks. Here, we design, train and validate a Convolutional Neural Network (CNN) capable of learning to classify SOs from collected light-curve measurements. The proposed methodology relies a physically-based model capable of accurately representing SO reflected light as function of time, size shape and state of motion. The model generates thousands of light-curves per selected class of SO which are employ to train a deep CNN to learn the functional relationship between light curves and SO class. Additionally, a deep CNN is trained using real SO light curves to evaluate the performance on a real, but limited training set. CNNs are compared with more conventional machine learning techniques (bagged trees, support vector machines) and are shown to outperform such methods especially when trained on real data. The concept of model-based transfer learning is proposed as possible path forward to increase the accuracy and speedup the training process."
    ],
    "c_categories":[
      "astro-ph.HE"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04840",
    "a_title":"Localized KBO with genetic dynamics for multi-modal optimization",
    "a_abstract":"In this paper, we introduce a novel approach to multi-modal optimization by\nenhancing the recently developed kinetic-based optimization (KBO) method with\ngenetic dynamics (GKBO). The proposed method targets objective functions with\nmultiple global minima, addressing a critical need in fields like engineering\ndesign, machine learning, and bioinformatics. By incorpo rating leader-follower\ndynamics and localized interactions, the algorithm efficiently navigates\nhigh-dimensional search spaces to detect multiple optimal solutions. After\nproviding a binary description, a mean-field approximation is derived, and\ndifferent numerical experiments are conducted to validate the results.",
    "explanation":"This IDR paper involves a combination of topics from different fields. In particular, I highlighted key references in Task 3 where topics in Genetics and the use of Data Structures and Algorithms come into play. Below are some sentences from the Abstract that reflect that:\n\n\"n this paper, we introduce a novel approach to multi-modal optimization by enhancing the recently developed kinetic-based optimization (KBO) method with genetic dynamics (GKBO)\"\n\" By incorporating leader-follower dynamics and localized interactions, the algorithm efficiently navigates high-dimensional search spaces to detect multiple optimal solution.\"",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Kinetic description and convergence analysis of genetic algorithms for global optimization"
    ],
    "b_abstract":[
      "Genetic Algorithms (GA) are a class of metaheuristic global optimization methods inspired by the process natural selection among individuals in population. Despite their widespread use, comprehensive theoretical analysis these remains challenging due to complexity heuristic mechanisms involved. In this work, relying on tools statistical physics, we take first step towards mathematical understanding GA showing how behavior for large number can be approximated through time-discrete kinetic model. This allows us prove convergence algorithm minimum under mild assumptions objective function popular choice mechanism. Furthermore, derive time-continuous model GA, represented Boltzmann-like partial differential equation, and establish relations with other mean-field dynamics optimization. Numerical experiments support validity proposed approximation investigate asymptotic configurations particle system different benchmark problems."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "Genetic Algorithms + Data Structures = Evolution Programs"
    ],
    "c_abstract":[
      "Genetic algorithms are founded upon the principle of evolution, i.e., survival of the fittest. Hence evolution programming techniques, based on genetic algorithms, are applicable to many hard optimization problems, such as optimization of functions with linear and nonlinear constraints, the traveling salesman problem, and problems of scheduling, partitioning, and control. The importance of these techniques is still growing, since evolution programs are parallel in nature, and parallelism is one of the most promising directions in computer science. The book is self-contained and the only prerequisite is basic undergraduate mathematics. This third edition has been substantially revised and extended by three new chapters and by additional appendices containing working material to cover recent developments and a change in the perception of evolutionary computation."
    ],
    "c_categories":[
      "cs.DS"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.17342",
    "a_title":"Automatic Skull Reconstruction by Deep Learnable Symmetry Enforcement",
    "a_abstract":"Every year, thousands of people suffer from skull damage and require\npersonalized implants to fill the cranial cavity. Unfortunately, the waiting\ntime for reconstruction surgery can extend to several weeks or even months,\nespecially in less developed countries. One factor contributing to the extended\nwaiting period is the intricate process of personalized implant modeling.\nCurrently, the preparation of these implants by experienced biomechanical\nexperts is both costly and time-consuming. Recent advances in artificial\nintelligence, especially in deep learning, offer promising potential for\nautomating the process. However, deep learning-based cranial reconstruction\nfaces several challenges: (i) the limited size of training datasets, (ii) the\nhigh resolution of the volumetric data, and (iii) significant data\nheterogeneity. In this work, we propose a novel approach to address these\nchallenges by enhancing the reconstruction through learnable symmetry\nenforcement. We demonstrate that it is possible to train a neural network\ndedicated to calculating skull symmetry, which can be utilized either as an\nadditional objective function during training or as a post-reconstruction\nobjective during the refinement step. We quantitatively evaluate the proposed\nmethod using open SkullBreak and SkullFix datasets, and qualitatively using\nreal clinical cases. The results indicate that the symmetry-preserving\nreconstruction network achieves considerably better outcomes compared to the\nbaseline (0.94\/0.94\/1.31 vs 0.84\/0.76\/2.43 in terms of DSC, bDSC, and HD95).\nMoreover, the results are comparable to the best-performing methods while\nrequiring significantly fewer computational resources (< 500 vs > 100,000 GPU\nhours). The proposed method is a considerable contribution to the field of\napplied artificial intelligence in medicine and is a step toward automatic\ncranial defect reconstruction in clinical practice.",
    "explanation":"This IDR paper is an applied research paper that focuses on combining Neural Networks to advance biomechanics. Below are some sentences in the abstract that reflect the references in Task 3:\n\n\"We demonstrate that it is possible to train a neural network dedicated to calculating skull symmetry,\"\n\n\"Every year, thousands of people suffer from skull damage and require personalized implants to fill the cranial cavity. Unfortunately, the waiting time for reconstruction surgery can extend to several weeks or even months, especially in less developed countries.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Reconstruction of cranial defect with patient-specific implants: Four different cost-effective techniques"
    ],
    "b_abstract":[
      "Cranial defects secondary to trauma, surgery or pathological causes, result in large cranial imperfection, which affects the appearance of patient as well results sinking flap syndrome. Rehabilitation such a defect can be done using prosthetic options like custom-made polymethyl methacrylate (PMMA) prosthesis surgical outer table calvarial graft segments. It is usually observed that conventional moulage impression defective site most difficult task. The accuracy affected by impression, cast and techniques fabricating wax pattern. Orthodox method mark tentative outline make site. However, this an arbitrary offers challenges accurate replication borders defect. Recently, medical imaging digital modeling dentistry have paved way for dental practice additive manufacturing replacing manual subtractive procedures. use computerized tomography scan obtain 3 D image replica with rapid prototyping has markedly improved at margin defect\/prosthesis interface, resulting better fit optimal contour lending itself esthetic outcome. more reliable implant prosthesis, requires minimum adjustment when on OT table. These case reports compare rehabilitation PMMA methods technique. seen expensive but gives"
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b35"
    ],
    "c_title":[
      "Deep learning-based framework for automatic cranial defect reconstruction and implant modeling"
    ],
    "c_abstract":[
      "This article presents a robust, fast, and fully automatic method for personalized cranial defect reconstruction implant modeling.We propose two-step deep learning-based using modified U-Net architecture to perform the reconstruction, dedicated iterative procedure improve geometry, followed by an generation of models ready 3-D printing. We cross-case augmentation based on imperfect image registration combining cases from different datasets. Additional ablation studies compare strategies other state-of-the-art methods.We evaluate three datasets introduced during AutoImplant 2021 challenge, organized jointly with MICCAI conference. quantitative evaluation Dice boundary coefficients, Hausdorff distance. The coefficient, 95th percentile distance averaged across all test sets, are 0.91, 0.94, 1.53 mm respectively. additional qualitative printing visualization in mixed reality confirm implant's usefulness.The proposes complete pipeline that enables one create model described is greatly extended version scored 1st place challenge tasks. freely release source code, which together open datasets, makes results reproducible. defects may enable manufacturing implants significantly shorter time, possibly allowing process directly given intervention. Moreover, we show usability further reduce surgery time."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04747",
    "a_title":"Equivariant Graph Attention Networks with Structural Motifs for\n  Predicting Cell Line-Specific Synergistic Drug Combinations",
    "a_abstract":"Cancer is the second leading cause of death, with chemotherapy as one of the\nprimary forms of treatment. As a result, researchers are turning to drug\ncombination therapy to decrease drug resistance and increase efficacy. Current\nmethods of drug combination screening, such as in vivo and in vitro, are\ninefficient due to stark time and monetary costs. In silico methods have become\nincreasingly important for screening drugs, but current methods are inaccurate\nand generalize poorly to unseen anticancer drugs. In this paper, I employ a\ngeometric deep-learning model utilizing a graph attention network that is\nequivariant to 3D rotations, translations, and reflections with structural\nmotifs. Additionally, the gene expression of cancer cell lines is utilized to\nclassify synergistic drug combinations specific to each cell line. I compared\nthe proposed geometric deep learning framework to current state-of-the-art\n(SOTA) methods, and the proposed model architecture achieved greater\nperformance on all 12 benchmark tasks performed on the DrugComb dataset.\nSpecifically, the proposed framework outperformed other SOTA methods by an\naccuracy difference greater than 28%. Based on these results, I believe that\nthe equivariant graph attention network's capability of learning geometric data\naccounts for the large performance improvements. The model's ability to\ngeneralize to foreign drugs is thought to be due to the structural motifs\nproviding a better representation of the molecule. Overall, I believe that the\nproposed equivariant geometric deep learning framework serves as an effective\ntool for virtually screening anticancer drug combinations for further\nvalidation in a wet lab environment. The code for this work is made available\nonline at: https:\/\/github.com\/WeToTheMoon\/EGAT_DrugSynergy.",
    "explanation":"From the key references cited in Task 3, below are some sentences that point to the significance of those references that show how this paper is an IDR.\n\n\"Additionally, the gene expression of cancer cell lines is utilized to classify synergistic drug combinations specificto each cell line. \"\n\"I compared the proposed geometric deep learning\nframework to current state-of-the-art (SOTA) methods\"\n\"Based on these results, I believe that the equivariant graph attention network\u2019s capability of learning geometric data accounts for the large performance improvements.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Trends in Phase II Trials for Cancer Therapies"
    ],
    "b_abstract":[
      "Background: Drug combinations are the standard of care in cancer treatment. Identifying effective drug has become more challenging because increasing number drugs. However, a substantial drugs stumble at Phase III clinical trials despite exhibiting favourable efficacy earlier Phase. Methods: We analysed recent II comprising 2165 response rates to uncover trends therapies and used null model non-interacting agents infer synergistic antagonistic combinations. compared our latest dataset with previous assess progress therapy. Results: Targeted reach higher when combination cytotoxic identify four 10 based on observed expected rates. demonstrate that targeted have not significantly increased Conclusions: conclude either we making or rate measured by tumour shrinkage is reliable surrogate endpoint for agents."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b16"
    ],
    "c_title":[
      "E(n) Equivariant Graph Neural Networks"
    ],
    "c_abstract":[
      "This paper introduces a new model to learn graph neural networks equivariant rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. addition, whereas methods are limited equivariance on 3 dimensional spaces, is easily scaled higher-dimensional spaces. We demonstrate the effectiveness of method dynamical systems modelling, representation learning autoencoders predicting molecular properties."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.11513",
    "a_title":"A Modular Open Source Framework for Genomic Variant Calling",
    "a_abstract":"Variant calling is a fundamental task in genomic research, essential for\ndetecting genetic variations such as single nucleotide polymorphisms (SNPs) and\ninsertions or deletions (indels). This paper presents an enhancement to\nDeepChem, a widely used open-source drug discovery framework, through the\nintegration of DeepVariant. In particular, we introduce a variant calling\npipeline that leverages DeepVariant's convolutional neural network (CNN)\narchitecture to improve the accuracy and reliability of variant detection. The\nimplemented pipeline includes stages for realignment of sequencing reads,\ncandidate variant detection, and pileup image generation, followed by variant\nclassification using a modified Inception v3 model. Our work adds a modular and\nextensible variant calling framework to the DeepChem framework and enables\nfuture work integrating DeepChem's drug discovery infrastructure more tightly\nwith bioinformatics pipelines.",
    "explanation":"Some sentences that point to the key references selected in Task 3 are specified below:\n\n\"Variant calling is a fundamental task in genomic research, essential for detecting genetic variations such as single nucleotide polymorphisms (SNPs) and insertions or deletions (indels).\"\n\n\"Our work adds a modular and extensible variant calling framework to the DeepChem framework and enables\nfuture work integrating DeepChem\u2019s drug discovery infrastructure more tightly with bioinformatics pipelines.\"",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "The Genome Analysis Toolkit: A MapReduce framework for analyzing next-generation DNA sequencing data"
    ],
    "b_abstract":[
      "Next-generation DNA sequencing (NGS) projects, such as the 1000 Genomes Project, are already revolutionizing our understanding of genetic variation among individuals. However, massive data sets generated by NGS\u2014the Genome pilot alone includes nearly five terabases\u2014make writing feature-rich, efficient, and robust analysis tools difficult for even computationally sophisticated Indeed, many professionals limited in scope ease with which they can answer scientific questions complexity accessing manipulating produced these machines. Here, we discuss Analysis Toolkit (GATK), a structured programming framework designed to development efficient next-generation sequencers using functional philosophy MapReduce. The GATK provides small but rich set access patterns that encompass majority tool needs. Separating specific calculations from common management infrastructure enables us optimize correctness, stability, CPU memory efficiency enable distributed shared parallelization. We highlight capabilities describing implementation application robust, scale-tolerant like coverage calculators single nucleotide polymorphism (SNP) calling. conclude developers analysts quickly easily write NGS tools, have been incorporated into large-scale projects Project Cancer Atlas."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b12"
    ],
    "c_title":[
      "Rethinking the Inception Architecture for Computer Vision"
    ],
    "c_abstract":[
      "Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety tasks. Since 2014 very deep convolutional started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend translate immediate quality tasks (as long as enough labeled data is provided training), efficiency low parameter count still enabling factors use cases such mobile big-data scenarios. Here we exploring ways scale up that aim utilizing added computation efficiently possible by suitably factorized convolutions aggressive regularization. We benchmark our methods on ILSVRC 2012 classification challenge validation set demonstrate over art: 21:2% top-1 5:6% top-5 error single frame evaluation using network with 5 billion multiply-adds per inference less than 25 million parameters. With an ensemble 4 models multi-crop evaluation, report 3:5% 17:3% 3:6% official test set."
    ],
    "c_categories":[
      "BioInformatics"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00319",
    "a_title":"Improving speaker verification robustness with synthetic emotional\n  utterances",
    "a_abstract":"A speaker verification (SV) system offers an authentication service designed\nto confirm whether a given speech sample originates from a specific speaker.\nThis technology has paved the way for various personalized applications that\ncater to individual preferences. A noteworthy challenge faced by SV systems is\ntheir ability to perform consistently across a range of emotional spectra. Most\nexisting models exhibit high error rates when dealing with emotional utterances\ncompared to neutral ones. Consequently, this phenomenon often leads to missing\nout on speech of interest. This issue primarily stems from the limited\navailability of labeled emotional speech data, impeding the development of\nrobust speaker representations that encompass diverse emotional states.\n  To address this concern, we propose a novel approach employing the CycleGAN\nframework to serve as a data augmentation method. This technique synthesizes\nemotional speech segments for each specific speaker while preserving the unique\nvocal identity. Our experimental findings underscore the effectiveness of\nincorporating synthetic emotional data into the training process. The models\ntrained using this augmented dataset consistently outperform the baseline\nmodels on the task of verifying speakers in emotional speech scenarios,\nreducing equal error rate by as much as 3.64% relative.",
    "explanation":"A speaker verification (SV) system offers an authentication ser-\nvice designed to confirm whether a given speech sample orig-\ninates from a specific speaker. To address this concern, we propose a novel\napproach employing the CycleGAN framework to serve as a\ndata augmentation method. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Human-Centric Interfaces for Ambient Intelligence"
    ],
    "b_abstract":[
      "To create truly effective human-centric ambient intelligence systems both engineering and computing methods are needed. This is the first book to bridge data processing and intelligent reasoning methods for the creation of human-centered ambient intelligence systems. Interdisciplinary in nature, the book covers topics such as multi-modal interfaces, human-computer interaction, smart environments and pervasive computing, addressing principles, paradigms, methods and applications. This book will be an ideal reference for university researchers, R&amp;D engineers, computer engineers, and graduate students working in signal, speech and video processing, multi-modal interfaces, human-computer interaction and applications of ambient intelligence."
    ],
    "b_categories":[
      "physics.app-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "Speaker Diarization with LSTM"
    ],
    "c_abstract":[
      "For many years, i-vector based audio embedding techniques were the dominant approach for speaker verification and diarization applications. However, mirroring rise of deep learning in various domains, neural network embeddings, also known as <i xmlns:mml=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" xmlns:xlink=\"http:\/\/www.w3.org\/1999\/xlink\">d-vectors<\/i> , have consistently demonstrated superior performance. In this paper, we build on success d-vector systems to develop a new diarization. Specifically, combine LSTM-based embeddings with recent work non-parametric clustering obtain state-of-the-art system. Our system is evaluated three standard public datasets, suggesting that offer significant advantages over traditional systems. We achieved 12.0% error rate NIST SRE 2000 CALLHOME, while our model trained out-of-domain data from voice search logs."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00173",
    "a_title":"Spatial Clustering of Molecular Localizations with Graph Neural Networks",
    "a_abstract":"Single-molecule localization microscopy generates point clouds corresponding\nto fluorophore localizations. Spatial cluster identification and analysis of\nthese point clouds are crucial for extracting insights about molecular\norganization. However, this task becomes challenging in the presence of\nlocalization noise, high point density, or complex biological structures. Here,\nwe introduce MIRO (Multimodal Integration through Relational Optimization), an\nalgorithm that uses recurrent graph neural networks to transform the point\nclouds in order to improve clustering efficiency when applying conventional\nclustering techniques. We show that MIRO supports simultaneous processing of\nclusters of different shapes and at multiple scales, demonstrating improved\nperformance across varied datasets. Our comprehensive evaluation demonstrates\nMIRO's transformative potential for single-molecule localization applications,\nshowcasing its capability to revolutionize cluster analysis and provide\naccurate, reliable details of molecular architecture. In addition, MIRO's\nrobust clustering capabilities hold promise for applications in various fields\nsuch as neuroscience, for the analysis of neural connectivity patterns, and\nenvironmental science, for studying spatial distributions of ecological data.",
    "explanation":"Single-molecule localization microscopy generates point clouds corresponding to\nfluorophore localizations.  Here, we introduce MIRO (Mul-\ntimodal Integration through Relational Optimization), an algorithm that uses\nrecurrent graph neural networks to transform the point clouds in order to improve\nclustering efficiency when applying conventional clustering techniques.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Turning single-molecule localization microscopy into a quantitative bioanalytical tool"
    ],
    "b_abstract":[
      "Single-molecule localization microscopy (SMLM) generates super-resolution images by serially detecting individual fluorescent molecules. The power of SMLM, however, goes beyond images: biologically relevant information can be extracted from the mathematical relationships between the positions of the fluorophores in space and time. Here we review the history of SMLM and how recent progress in methods for spatial point analysis has enabled quantitative measurement of SMLM data, providing insights into biomolecule patterning, clustering and oligomerization in biological systems."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b22"
    ],
    "c_title":[
      "A framework for evaluating the performance of SMLM cluster analysis algorithms"
    ],
    "c_abstract":[
      "This analysis compares the performance of seven algorithms for cluster analysis of single-molecule localization microscopy data. The results provide a framework for comparing these types of methods and point users to the best tools. Single-molecule localization microscopy (SMLM) generates data in the form of coordinates of localized fluorophores. Cluster analysis is an attractive route for extracting biologically meaningful information from such data and has been widely applied. Despite a range of cluster analysis algorithms, there exists no consensus framework for the evaluation of their performance. Here, we use a systematic approach based on two metrics to score the success of clustering algorithms in simulated conditions mimicking experimental data. We demonstrate the framework using seven diverse analysis algorithms: DBSCAN, ToMATo, KDE, FOCAL, CAML, ClusterViSu and SR-Tesseler. Given that the best performer depended on the underlying distribution of localizations, we demonstrate an analysis pipeline based on statistical similarity measures that enables the selection of the most appropriate algorithm, and the optimized analysis parameters for real SMLM data. We propose that these standard simulated conditions, metrics and analysis pipeline become the basis for future analysis algorithm development and evaluation."
    ],
    "c_categories":[
      "eess.IV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19450",
    "a_title":"Unsupervised Learning Approach to Anomaly Detection in Gravitational\n  Wave Data",
    "a_abstract":"Gravitational waves (GW), predicted by Einstein's General Theory of\nRelativity, provide a powerful probe of astrophysical phenomena and fundamental\nphysics. In this work, we propose an unsupervised anomaly detection method\nusing variational autoencoders (VAEs) to analyze GW time-series data. By\ntraining on noise-only data, the VAE accurately reconstructs noise inputs while\nfailing to reconstruct anomalies, such as GW signals, which results in\nmeasurable spikes in the reconstruction error. The method was applied to data\nfrom the LIGO H1 and L1 detectors. Evaluation on testing datasets containing\nboth noise and GW events demonstrated reliable detection, achieving an area\nunder the ROC curve (AUC) of 0.89. This study introduces VAEs as a robust,\nunsupervised approach for identifying anomalies in GW data, which offers a\nscalable framework for detecting known and potentially new phenomena in\nphysics.",
    "explanation":"Gravitational waves (GW), predicted by Einstein\u2019s General Theory of Relativity, provide a pow-\nerful probe of astrophysical phenomena and fundamental physics. In this work, we propose an\nunsupervised anomaly detection method using variational autoencoders (VAEs) to analyze GW\ntime-series data. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining"
    ],
    "b_abstract":[
      "It is our great pleasure to welcome you the 2017 ACM Conference on Knowledge Discovery and Data Mining -- KDD 2017. We hope that content professional networking opportunities at will help succeed professionally by enabling to: identify new technology trends; learn from contributed papers, presentations, posters; discover tools, processes practices; job opportunities; hire team members. The terms \"Data Science\", Mining\" \"Big Data\" have, in last few years, grown out of research labs gained presence media everyday conversations. also hear these social decision makers various level governments corporations. impact technologies felt almost every walk life. Importantly, current rapid progress data science facilitated timely sharing newly discovered developed representations algorithms between those working interested industrial deployment. hallmark conferences past they have been bridge theory practise, facilitator catalyst for this exchange. Researchers practitioners meet person interact a meaningful way over several days. conference program, with its three parallel tracks - Research Track, Applied Science Track Invited Speakers brings two groups together. Participants are freely attend any track, events common all tracks. year continues tradition strong tutorial workshop program leading edge issues mining during first days program. devoted technical describing both novel, important contributions, deployed, innovative solutions. Three keynote talks, Cynthia Dwork, Bin Yu, Ren\u00e9e J. Miller touch some hard, emerging before field mining. With growing industry around AI assistants, Panel together experts spawn discussions an exchanges ideas. outstanding lineup speakers their experiences expertise deploying continue hands-on which participants how use practical tools. In order broaden increase participation attendees who would greatly benefit but otherwise found it financially challenging attend, we reserved substantial budget travel grants. awarded record USD 145k student set aside 25k enable smaller startups attend. \"Meet Experts\" sessions, gives researchers unique opportunity form networks share perspectives others aspects science. serve as meeting ground researchers, practitioners, funding agencies investors create commercial products."
    ],
    "b_categories":[
      "physics.gen-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Auto-Encoding Variational Bayes"
    ],
    "c_abstract":[
      "How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05237",
    "a_title":"Pruning the Path to Optimal Care: Identifying Systematically Suboptimal\n  Medical Decision-Making with Inverse Reinforcement Learning",
    "a_abstract":"In aims to uncover insights into medical decision-making embedded within\nobservational data from clinical settings, we present a novel application of\nInverse Reinforcement Learning (IRL) that identifies suboptimal clinician\nactions based on the actions of their peers. This approach centers two stages\nof IRL with an intermediate step to prune trajectories displaying behavior that\ndeviates significantly from the consensus. This enables us to effectively\nidentify clinical priorities and values from ICU data containing both optimal\nand suboptimal clinician decisions. We observe that the benefits of removing\nsuboptimal actions vary by disease and differentially impact certain\ndemographic groups.",
    "explanation":"In aims to uncover insights into medical decision-making embedded within observational data from clinical settings,\nwe present a novel application of Inverse Reinforcement Learning (IRL) that identifies suboptimal clinician actions\nbased on the actions of their peers. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Factors Influencing Physicians' Clinical Decision-making at Upazila Health Complexes in Bangladesh"
    ],
    "b_abstract":[
      "Selecting the most appropriate treatment for each patient is key activity in patient-physician encounters and providing healthcare services. Achieving desirable clinical goals mostly depends on making right decision at time any setting. But little known about physicians' decision-making primary care setting Bangladesh. Therefore, this study explored factors that influence decisions prescribing medications, ordering pathologic tests, counseling patients, average length of visits a consultation session, referral patients to other physicians or hospitals by Upazila Health Complexes (UHCs) country. It also structure social networks their association with process.This was cross-sectional descriptive used data collected from 85 physicians. The respondents, who work UHCs Rajshahi Division, were selected purposively. analyzed statistics including frequency, percentage, one-way analysis variance, linear regression understand relationships among variables.The results reveal multiple visits, referring UHCs. Most prescribe drugs keeping mind purchasing capacity. Risk violence patients' relatives better management are two decisions. professional personal play an influential role process. found dedicate 16.17 minutes session. influenced various distance between residence workplace, level education, number colleagues whom they have regular contact can seek help.The yielded some novel insights complexity everyday tasks would be interest public health researchers policy makers."
    ],
    "b_categories":[
      "Healthcare"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Interactive Teaching Algorithms for Inverse Reinforcement Learning"
    ],
    "c_abstract":[
      "We study the problem of inverse reinforcement learning (IRL) with added twist that learner is assisted by a helpful teacher. More formally, we tackle following algorithmic question: How could teacher provide an informative sequence demonstrations to IRL speed up process? present interactive teaching framework where adaptively chooses next demonstration based on learner's current policy. In particular, design algorithms for two concrete settings: omniscient setting has full knowledge about dynamics and blackbox minimal knowledge. Then, sequential variant popular MCE-IRL prove convergence guarantees our algorithm in setting. Extensive experiments car driving simulator environment show progress can be speeded drastically as compared uninformative"
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2412.09927",
    "a_title":"Neural Vector Tomography for Reconstructing a Magnetization Vector Field",
    "a_abstract":"Discretized techniques for vector tomographic reconstructions are prone to\nproducing artifacts in the reconstructions. The quality of these\nreconstructions may further deteriorate as the amount of noise increases. In\nthis work, we instead model the underlying vector fields using smooth neural\nfields. Owing to the fact that the activation functions in the neural network\nmay be chosen to be smooth and the domain is no longer pixelated, the model\nresults in high-quality reconstructions, even under presence of noise. In the\ncase where we have underlying global continuous symmetry, we find that the\nneural network substantially improves the accuracy of the reconstruction over\nthe existing techniques.",
    "explanation":" In this work, we instead model the underlying\nvector fields using smooth neural fields",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Three-dimensional nanomagnetism"
    ],
    "b_abstract":[
      "Magnetic nanostructures are being developed for use in many aspects of our daily life, spanning areas such as data storage, sensing and biomedicine. Whereas patterned nanomagnets traditionally two-dimensional planar structures, recent work is expanding nanomagnetism into three dimensions; a move triggered by the advance unconventional synthesis methods discovery new magnetic effects. In three-dimensional more complex configurations become possible, with unprecedented properties. Here we review creation these structures their implications emergence physics, development instrumentation computational methods, exploitation numerous applications. Nanoscale devices play key role modern technologies but current applications involve only 2D like discs. authors progress fabrication understanding 3D nanostructures, enabling diverse functionalities."
    ],
    "b_categories":[
      "cond-mat.mes-hall"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "MagNet: machine learning enhanced three-dimensional magnetic reconstruction"
    ],
    "c_abstract":[
      "Three-dimensional (3D) magnetic reconstruction is vital to the study of novel materials for 3D spintronics. Vector field electron tomography (VFET) a major in house tool achieve that. However, conventional VFET exhibits significant artefacts due unavoidable presence missing wedges. In this article, we propose deep-learning enhanced method address issue. A textures library built by micromagnetic simulations. MagNet, an U-shaped convolutional neural network, trained and tested with dataset generated from library. We demonstrate that MagNet outperforms under wedge. Quality reconstructed induction fields significantly improved."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.19927",
    "a_title":"Modeling Continuous Spatial-temporal Dynamics of Turbulent Flow with\n  Test-time Refinement",
    "a_abstract":"The precise simulation of turbulent flows holds immense significance across\nvarious scientific and engineering domains, including climate science,\nfreshwater science, and energy-efficient manufacturing. Within the realm of\nsimulating turbulent flows, large eddy simulation (LES) has emerged as a\nprevalent alternative to direct numerical simulation (DNS), offering\ncomputational efficiency. However, LES cannot accurately capture the full\nspectrum of turbulent transport scales and is present only at a lower spatial\nresolution. Reconstructing high-fidelity DNS data from the lower-resolution LES\ndata is essential for numerous applications, but it poses significant\nchallenges to existing super-resolution techniques, primarily due to the\ncomplex spatio-temporal nature of turbulent flows. This paper proposes a novel\nflow reconstruction approach that leverages physical knowledge to model flow\ndynamics. Different from traditional super-resolution techniques, the proposed\napproach uses LES data only in the testing phase through a degradation-based\nrefinement approach to enforce physical constraints and mitigate cumulative\nreconstruction errors over time. Furthermore, a feature sampling strategy is\ndeveloped to enable flow data reconstruction across different resolutions. The\nresults on two distinct sets of turbulent flow data indicate the effectiveness\nof the proposed method in reconstructing high-resolution DNS data, preserving\nthe inherent physical attributes of flow transport, and achieving DNS\nreconstruction at different resolutions.",
    "explanation":"his paper proposes a novel flow recon-\nstruction approach that leverages physical knowledge to\nmodel flow dynamics.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Model-free simulations of turbulent reactive flows"
    ],
    "b_abstract":[
      "A critical review of the modern computational methods for solving the transport equations of turbulent reacting single-phase flows is presented. Primary consideration is given to those methods which lead to \u2018model-free\u2019 simulations while some attention is devoted to \u2018turbulence modeling\u2019. Emphasis is placed upon the role of supercomputers and how their increased computational capacities may be exploited to allow better simulations of the physics of turbulent reactive flows. Comparisons between the commonly employed computational schemes for simulating these flows are given, with the advantages and the limitations associated with each scheme being highlighted. Examples are presented of recent applications of model-free simulations to a variety of unsteady reacting flows, with detailed discussions on the physical phenomena captured by such simulations. Due to the nature of this review, experimental contributions are mentioned only in the context of providing empirical evidence. References are made to other contributions which are not directly related to the computational efforts in order to provide a reasonably comprehensive bibliography for those interested in pursuing various topics in greater detail. Predictions of future accomplishments, as well as some suggestions for future work, are also given."
    ],
    "b_categories":[
      "physics.flu-dyn"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b40"
    ],
    "c_title":[
      "Physics guided neural networks for spatio-temporal superresolution of turbulent flows"
    ],
    "c_abstract":[
      "Direct numerical simulation (DNS) of turbulent flows is computationally expensive and cannot be applied to flows with large Reynolds numbers. Low-resolution large eddy simulation (LES) is a popular alternative, but it is unable to capture all of the scales of turbulent transport accurately. Reconstructing DNS from low-resolution LES is critical for large-scale simulation in many scientific and engineering disciplines, but it poses many challenges to existing super-resolution methods due to the complexity of turbulent flows and computational cost of generating frequent LES data. We propose a physics-guided neural network for reconstructing frequent DNS from sparse LES data by enhancing its spatial resolution and temporal frequency. Our proposed method consists of a partial differential equation (PDE)-based recurrent unit for capturing underlying temporal processes and a physics-guided super-resolution model that incorporates additional physical constraints. We demonstrate the effectiveness of both components in reconstructing the Taylor-Green Vortex using sparse LES data. Moreover, we show that the proposed recurrent unit can preserve the physical characteristics of turbulent flows by leveraging the physical relationships in the Navier-Stokes equation."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.10196",
    "a_title":"High-dimensional Statistics Applications to Batch Effects in\n  Metabolomics",
    "a_abstract":"Batch effects are inevitable in large-scale metabolomics. Prior to formal\ndata analysis, batch effect correction (BEC) is applied to prevent from\nobscuring biological variations, and batch effect evaluation (BEE) is used for\ncorrection assessment. However, existing BEE algorithms neglect covariances\nbetween the variables, and existing BEC algorithms might fail to adequately\ncorrect the covariances. Therefore, we resort to recent advancements in\nhigh-dimensional statistics, and respectively propose \"quality control-based\nsimultaneous tests (QC-ST)\" and \"covariance correction (CoCo)\". Validated by\nthe simulation data, QC-ST can simultaneously detect the statistical\nsignificance of QC samples' mean vectors and covariance matrices across\ndifferent batches, and has a satisfactory statistical performance in empirical\nsizes, empirical powers, and computational speed. Then, we apply four QC-based\nBEC algorithms to two large cohort datasets, and find that extreme gradient\nboost (XGBoost) performs best in relative standard deviation (RSD) and\ndispersion-ratio (D-ratio). After prepositive BEC, if QC-ST still suggests that\nbatch effects between some two batches are significant, CoCo should be\nimplemented. And after CoCo (if necessary), the four metrics (i.e., RSD,\nD-ratio, classification performance, and QC-ST) might be further improved. In\nsummary, under the guidance of QC-ST, we can develop a matching strategy to\nintegrate multiple BEC algorithms more rationally and flexibly, and minimize\nbatch effects for reliable biological conclusions.",
    "explanation":"Batch effects are inevitable in large-scale metabolomics. Prior to formal data analysis, batch effect correction (BEC) is applied to prevent from obscuring biological variations, and batch effect evaluation (BEE) is used for correction assessment.we apply four QC-based BEC algorithms to two large cohort datasets, and find that extreme gradient boost (XGBoost) performs best in relative standard deviation (RSD) and dispersion-ratio (D-ratio).",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Quality assurance procedures for mass spectrometry untargeted metabolomics. a review"
    ],
    "b_abstract":[
      "Untargeted metabolomics, as a global approach, has already proven its great potential and capabilities for the investigation of health and disease, as well as the wide applicability for other research areas. Although great progress has been made on the feasibility of metabolomics experiments, there are still some challenges that should be faced and that includes all sources of fluctuations and bias affecting every step involved in multiplatform untargeted metabolomics studies. The identification and reduction of the main sources of unwanted variation regarding the pre-analytical, analytical and post-analytical phase of metabolomics experiments is essential to ensure high data quality. Nowadays, there is still a lack of information regarding harmonized guidelines for quality assurance as those available for targeted analysis. In this review, sources of variations to be considered and minimized along with methodologies and strategies for monitoring and improvement the quality of the results are discussed. The given information is based on evidences from different groups among our own experiences and recommendations for each stage of the metabolomics workflow. The comprehensive overview with tools presented here might serve other researchers interested in monitoring, controlling and improving the reliability of their findings by implementation of good experimental quality practices in the untargeted metabolomics study."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b16"
    ],
    "c_title":[
      "XGBoost: A Scalable Tree Boosting System"
    ],
    "c_abstract":[
      "Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00225",
    "a_title":"Meta-learning Loss Functions of Parametric Partial Differential\n  Equations Using Physics-Informed Neural Networks",
    "a_abstract":"This paper proposes a new way to learn Physics-Informed Neural Network loss\nfunctions using Generalized Additive Models. We apply our method by\nmeta-learning parametric partial differential equations, PDEs, on Burger's and\n2D Heat Equations. The goal is to learn a new loss function for each parametric\nPDE using meta-learning. The derived loss function replaces the traditional\ndata loss, allowing us to learn each parametric PDE more efficiently, improving\nthe meta-learner's performance and convergence.",
    "explanation":"This paper proposes a new way to learn Physics-Informed Neural Network loss functions using Generalized Additive Models.We apply our method by meta-learning parametric partial differential equations, PDEs, on Burger\u2019s and 2D Heat Equations.",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "The Burgers equation"
    ],
    "b_abstract":[
      "The Burgers equation is a simple equation to understand the main properties of the Navier-Stokes equations. In this one-dimensional equation the pressure is neglected but the effects of the nonlinear and viscous terms remain, hence as in the Navier-Stokes equations a Reynolds number can be defined. This number expresses the ratio between the advective and the viscous contribution in a flow. The present book deals with flows at high Reynolds numbers where the nonlinear terms play a fundamental role, and the physics is more complicated than that when the viscous term dominates. The simulation of the flow evolution then necessitates the use of accurate and robust numerical methods. In 3D turbulent flows, where the number of degrees of freedom is greater than in high Re laminar flows, to get solutions it is necessary to introduce some sort of closure to account for the impossibility to resolve the small scales. Before applying any new idea about numerical methods to 3D flows, the good sense suggests to find the simplest equation to test these ideas. This consideration explains why the Burgers equation was often used to check new numerical methods or closure for turbulent flows."
    ],
    "b_categories":[
      "math.AP"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b17"
    ],
    "c_title":[
      "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations"
    ],
    "c_abstract":[
      "We introduce physics-informed neural networks \u2013 neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge\u2013Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction\u2013diffusion systems, and the propagation of nonlinear shallow-water waves."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05456",
    "a_title":"Comparative Study of Probabilistic Atlas and Deep Learning Approaches\n  for Automatic Brain Tissue Segmentation from MRI Using N4 Bias Field\n  Correction and Anisotropic Diffusion Pre-processing Techniques",
    "a_abstract":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI)\nimages is vital for accurate diagnosis and further analysis in medical imaging.\nDespite advancements in segmentation techniques, a comprehensive comparison\nbetween traditional statistical methods and modern deep learning approaches\nusing pre-processing techniques like N4 Bias Field Correction and Anisotropic\nDiffusion remains underexplored. This study provides a comparative analysis of\nvarious segmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and\nLinkNet, enhanced with these pre-processing techniques to segment brain tissues\n(white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF)) on the\nInternet Brain Segmentation Repository (IBSR18) dataset. Our results\ndemonstrate that the 3D nnU-Net model outperforms others, achieving the highest\nmean Dice Coefficient score (0.937 +- 0.012), while the 2D nnU-Net model\nrecorded the lowest mean Hausdorff Distance (5.005 +- 0.343 mm) and the lowest\nmean Absolute Volumetric Difference (3.695 +- 2.931 mm) across five unseen test\nsamples. The findings highlight the superiority of nnU-Net models in brain\ntissue segmentation, particularly when combined with N4 Bias Field Correction\nand Anisotropic Diffusion pre-processing techniques. Our implemented code can\nbe accessed via GitHub.",
    "explanation":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI) images is vital for accurate diagnosis and further analysis in medical imaging. \n\nThis study provides a comparative analysis of various\nsegmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and LinkNet, enhanced with these preprocessing techniques to segment brain tissue",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "MRI segmentation of the human brain: challenges, methods, and applications"
    ],
    "b_abstract":[
      "Image segmentation is one of the most important tasks in medical image analysis and is often the first and the most critical step in many clinical applications. In brain MRI analysis, image segmentation is commonly used for measuring and visualizing the brain\u2019s anatomical structures, for analyzing brain changes, for delineating pathological regions, and for surgical planning and image-guided interventions. In the last few decades, various segmentation techniques of different accuracy and degree of complexity have been developed and reported in the literature. In this paper we review the most popular methods commonly used for brain MRI segmentation. We highlight differences between them and discuss their capabilities, advantages, and limitations. To address the complexity and challenges of the brain MRI segmentation problem, we first introduce the basic concepts of image segmentation. Then, we explain different MRI preprocessing steps including image registration, bias field correction, and removal of nonbrain tissue. Finally, after reviewing different brain MRI segmentation methods, we discuss the validation problem in brain MRI segmentation."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "U-net: Convolutional networks for biomedical image segmentation"
    ],
    "c_abstract":[
      "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05213",
    "a_title":"A chemostat model with variable dilution rate due to biofilm growth",
    "a_abstract":"In many real life applications, a continuous culture bioreactor may cease to\nfunction properly due to bioclogging which is typically caused by the microbial\novergrowth. This is a problem that has been largely overlooked in the chemostat\nmodeling literature, despite the fact that a number of models explicitly\naccounted for biofilm development inside the bioreactor. In a typical chemostat\nmodel, the physical volume of the biofilm is considered negligible when\ncompared to the volume of the fluid. In this paper, we investigate the\ntheoretical consequences of removing such assumption. Specifically, we\nformulate a novel mathematical model of a chemostat where the increase of the\nbiofilm volume occurs at the expense of the fluid volume of the bioreactor, and\nas a result the corresponding dilution rate increases reciprocally. We show\nthat our model is well-posed and describes the bioreactor that can operate in\nthree distinct types of dynamic regimes: the washout equilibrium, the\ncoexistence equilibrium, or a transient towards the clogged state which is\nreached in finite time. We analyze the multiplicity and the stability of the\ncorresponding equilibria. In particular, we delineate the parameter\ncombinations for which the chemostat never clogs up and those for which it\nclogs up in finite time. We also derive criteria for microbial persistence and\nextinction. Finally, we present a numerical evidence that a multistable\ncoexistence in the chemostat with variable dilution rate is feasible.",
    "explanation":"Specifically, we formulate a novel mathematical model of a chemostat where the increase of the biofilm volume occurs at the expense of the fluid volume of the bioreactor, and as a result the corresponding dilution rate increases reciprocally.",
    "b_id":[
      "b1",
      "b8"
    ],
    "b_title":[
      "Microreactors gain wider use as alternative to batch production",
      "How flocculation can explain coexistence in the chemostat"
    ],
    "b_abstract":[
      "The microreactors are gaining wide use among the pharmaceuticals and chemical companies as an alternative to batch production. They not only offers a flexible approach to continuous processing, but promises to save much of the time and effort consumed while expanding the chemistries at commercial scale. Most of the ten global pharma and chemical companies have acquired the Cytos Lab System,, a microreactor product developed by Cellular Process Chemistry Systems GmbH (CPC). Microreactors are comprised of plates with distinct channels in the submillimeter range, providing high surface-to-volume ratio, ultra fast mixing and high degree of control at all levels of production.",
      "We study a chemostat model in which two microbial species grow on single resource. show that coexistence is possible when the would normally win exclusive competition aggregates flocs. Our mathematical analysis exploits fact flocculation fast compared to biological growth, common hypothesis floc models. A numerical shows validity of this approach large parameter range. indicate how our yields mechanistic justification for so-called density-dependent growth."
    ],
    "b_categories":[
      "q-bio.OT"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Effect of bioclogging in porous media on complex conductivity signatures"
    ],
    "c_abstract":[
      "Flow through sand columns inoculated with Pseudomonas aeruginosa were used to investigate the effect of bioclogging on complex conductivity and flow transport properties. Complex (0.1\u20131000 Hz), bulk hydraulic (K), volumetric rate (Q), dispersivity (D), microbial cell concentrations monitored over time. Environmental scanning electron microscope images sands obtained at end experiment. Bioclogging resulting from increases in concentration production exopolymeric substances (EPS) had a large impact imaginary ( \u03c3 \u2033), K, Q, D, porosity (\u03a6). Changes electrical properties developed three stages: an initial stage 1 no significant changes all measured parameters (Days 1\u20138), which we attribute reversible irreversible attachment cells sand. In 2a 9\u201316), caused by growth biomass either as microcolonies filling pore throats and\/or uniform covering surfaces resulted maximum decrease Q but only moderate \u2033. 2b 17\u201324), EPS increase biofilm thickness higher \u2033 compared 2a. 3 25\u201332), reached quasi steady state insignificant are observed parameters. The results this study suggest that can provide complimentary information assessment porous media."
    ],
    "c_categories":[
      "math.MP"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.07031",
    "a_title":"Evaluating the Accuracy of Chatbots in Financial Literature",
    "a_abstract":"We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview\nversions), and Gemini Advanced, in providing references on financial literature\nand employing novel methodologies. Alongside the conventional binary approach\ncommonly used in the literature, we developed a nonbinary approach and a\nrecency measure to assess how hallucination rates vary with how recent a topic\nis. After analyzing 150 citations, ChatGPT-4o had a hallucination rate of 20.0%\n(95% CI, 13.6%-26.4%), while the o1-preview had a hallucination rate of 21.3%\n(95% CI, 14.8%-27.9%). In contrast, Gemini Advanced exhibited higher\nhallucination rates: 76.7% (95% CI, 69.9%-83.4%). While hallucination rates\nincreased for more recent topics, this trend was not statistically significant\nfor Gemini Advanced. These findings emphasize the importance of verifying\nchatbot-provided references, particularly in rapidly evolving fields.",
    "explanation":"We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview versions), and Gemini Advanced, in providing references on financial literature and employing novel methodologies.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "ChatGPT Hallucinates Non-existent Citations: Evidence from Economics"
    ],
    "b_abstract":[
      "In this study, we generate prompts derived from every topic within the Journal of Economic Literature to assess abilities both GPT-3.5 and GPT-4 versions ChatGPT large language model (LLM) write about economic concepts. demonstrates considerable competency in offering general summaries but also cites non-existent references. More than 30% citations provided by version do not exist rate is only slightly reduced for version. Additionally, our findings suggest that reliability decreases as become more specific. We provide quantitative evidence errors output demonstrate importance LLM verification. JEL Codes: B4; O33; I2"
    ],
    "b_categories":[
      "q-fin.ST"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Accuracy of Chatbots in Citing Journal Articles"
    ],
    "c_abstract":[
      "This cross-sectional study quantifies the journal article citation error rate of an artificial intelligence chatbot."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06184",
    "a_title":"Alleviating Hyperparameter-Tuning Burden in SVM Classifiers for\n  Pulmonary Nodules Diagnosis with Multi-Task Bayesian Optimization",
    "a_abstract":"In the field of non-invasive medical imaging, radiomic features are utilized\nto measure tumor characteristics. However, these features can be affected by\nthe techniques used to discretize the images, ultimately impacting the accuracy\nof diagnosis. To investigate the influence of various image discretization\nmethods on diagnosis, it is common practice to evaluate multiple discretization\nstrategies individually. This approach often leads to redundant and\ntime-consuming tasks such as training predictive models and fine-tuning\nhyperparameters separately. This study examines the feasibility of employing\nmulti-task Bayesian optimization to accelerate the hyperparameters search for\nclassifying benign and malignant pulmonary nodules using RBF SVM. Our findings\nsuggest that multi-task Bayesian optimization significantly accelerates the\nsearch for hyperparameters in comparison to a single-task approach. To the best\nof our knowledge, this is the first investigation to utilize multi-task\nBayesian optimization in a critical medical context.",
    "explanation":"This study examines the feasibility of employing multi-task Bayesian optimization to accelerate the hyperparameters search for classifying benign and malignant pulmonary nodules using RBF SVM.",
    "b_id":[
      "b6",
      "b7"
    ],
    "b_title":[
      "Multi-Task Bayesian Optimization",
      "Taking the Human Out of the Loop: A Review of Bayesian Optimization"
    ],
    "b_abstract":[
      "Bayesian optimization has recently been proposed as a framework for automatically tuning the hyperparameters of machine learning models and shown to yield state-of-the-art performance with impressive ease efficiency. In this paper, we explore whether it is possible transfer knowledge gained from previous optimizations new tasks in order find optimal hyperparameter settings more efficiently. Our approach based on extending multi-task Gaussian processes optimization. We show that method significantly speeds up process when compared standard single-task approach. further propose straightforward extension our algorithm jointly minimize average error across multiple demonstrate how can be used greatly speed k-fold cross-validation. Lastly, an adaptation developed acquisition function, entropy search, cost-sensitive, setting. utility function by leveraging small dataset hyper-parameter large dataset. dynamically chooses which query most information per unit cost.",
      "Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing storage architectures. The construction such involves many distributed design choices. end products (e.g., recommendation medical analysis tools, real-time game engines, speech recognizers) thus involve tunable configuration parameters. These parameters often specified hard-coded into the by various developers or teams. If optimized jointly, these can result in significant improvements. Bayesian optimization is a powerful tool for joint choices that gaining great popularity recent years. It promises greater automation so as to increase both product quality human productivity. This review paper introduces optimization, highlights some its methodological aspects, showcases wide range applications."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "New Pathologic Classification of Lung Cancer: Relevance for Clinical Practice and Clinical Trials"
    ],
    "c_abstract":[
      "We summarize significant changes in pathologic classification of lung cancer resulting from the 2011 International Association for Study Lung Cancer\/American Thoracic Society\/European Respiratory Society (IASLC\/ATS\/ERS) adenocarcinoma classification. The was developed by an international core panel experts representing IASLC, ATS, and ERS with oncologists\/pulmonologists, pathologists, radiologists, molecular biologists, thoracic surgeons. Because 70% patients present advanced stages, a new approach to small biopsies cytology specific terminology criteria focused on need distinguishing squamous cell carcinoma testing EGFR mutations ALK rearrangement. Tumors previously classified as non-small-cell carcinoma, not otherwise specified, because lack clear or morphology should be further using limited immunohistochemical workup preserve tissue testing. terms \"bronchioloalveolar carcinoma\" \"mixed subtype adenocarcinoma\" have been discontinued. For resected adenocarcinomas, concepts situ minimally invasive define who, if they undergo complete resection, will 100% disease-free survival. Invasive adenocarcinomas are now predominant pattern after comprehensive histologic subtyping lepidic, acinar, papillary, solid patterns; micropapillary is added poor prognosis. Former mucinous bronchioloalveolar carcinomas called \"invasive adenocarcinoma.\" field rapidly evolving advances occurring frequent basis, particularly arena, this provides much needed standard diagnosis only patient care but also clinical trials TNM"
    ],
    "c_categories":[
      "q-bio.QM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.20675",
    "a_title":"Improved ICNN-LSTM Model Classification Based on Attitude Sensor Data\n  for Hazardous State Assessment of Magnetic Adhesion Climbing Wall Robots",
    "a_abstract":"Magnetic adhesion tracked climbing robots are widely utilized in\nhigh-altitude inspection, welding, and cleaning tasks due to their ability to\nperform various operations against gravity on vertical or inclined walls.\nHowever, during operation, the robot may experience overturning torque caused\nby its own weight and load, which can lead to the detachment of magnetic plates\nand subsequently pose safety risks. This paper proposes an improved ICNN-LSTM\nnetwork classification method based on Micro-Electro-Mechanical Systems (MEMS)\nattitude sensor data for real-time monitoring and assessment of hazardous\nstates in magnetic adhesion tracked climbing robots. Firstly, a data\nacquisition strategy for attitude sensors capable of capturing minute\nvibrations is designed. Secondly, a feature extraction and classification model\ncombining an Improved Convolutional Neural Network (ICNN) with a Long\nShort-Term Memory (LSTM) network is proposed. Experimental validation\ndemonstrates that the proposed minute vibration sensing method achieves\nsignificant results, and the proposed classification model consistently\nexhibits high accuracy compared to other models. The research findings provide\neffective technical support for the safe operation of climbing robots",
    "explanation":"This paper proposes an improved ICNN-LSTM network classification method based on Micro-Electro-Mechanical Systems (MEMS) attitude sensor data for real-time monitoring and assessment of hazardous states in magnetic adhesion tracked climbing robots.",
    "b_id":[
      "b13"
    ],
    "b_title":[
      "Discriminative feature learning using a multiscale convolutional capsule network from attitude data for fault diagnosis of industrial robots"
    ],
    "b_abstract":[
      "Effective fault diagnosis is important to ensure the reliability, safety, and efficiency of industrial robots. This article proposes a simple yet effective data acquisition strategy based on transmission mechanism analysis, using only one attitude sensor mounted on an end effector or an output component to monitor the attitude of all transmission components. Unlike widely used vibration-monitoring signals, attitude signals can provide fault features reflecting spatial relationships. Using one attitude sensor facilitates the data collection, but weakens fault features and introduces strong background noise in attitude signals. To learn discriminative features from the attitude data collected by the attitude sensor, a multiscale convolutional capsule network (MCCN) is proposed. In MCCN, integrating low-level and high-level features in a convolutional neural network (CNN) as multiscale features is conductive to noise reduction and robust feature extraction, and a capsule network (CapsNet) is used to recognize the spatial relationships in attitude data. The extracted multiscale features in CNN and the spatial-relational features in CapsNet are fused for effective fault diagnosis of industrial robots. The performance of MCCN is evaluated by attaching a softmax-based classifier and integrating it into different transfer learning frameworks to diagnose faults in industrial robots under single and variable working conditions, respectively. Fault diagnosis experiments were conducted on a 6-axis series industrial robot and a parallel robot-driven 3D printer. The superiority of the proposed MCCN was demonstrated by comparing its performance with the other feature learning methods."
    ],
    "b_categories":[
      "eess.SP"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b21"
    ],
    "c_title":[
      "LSTM Based Bearing Fault Diagnosis of Electrical Machines using Motor Current Signal"
    ],
    "c_abstract":[
      "Rolling element bearings are one of the most critical components rotating machinery, with bearing faults amounting up to 50% in electrical machines. Therefore, fault diagnosis has attracted attention many researchers. Typically, is performed using vibration signals from machine. In addition, by deep learning algorithms on signals, detection accuracy close 100% can be achieved. However, measurement requires an additional sensor, which not present majority Nevertheless, alternative approach, stator current used for diagnosis. paper emphasizes current. The signal processing signature extraction that buried underneath noise signal. uses Paderborn University damaged dataset, contains data healthy, real inner raceway and outer different severity. For redundant frequencies filtered, then filtered eight features extracted time time-frequency domain wavelet packet decomposition (WPD). Then, these well known algorithm Long Short-Term Memory (LSTM), classification made. LSTM mostly speech recognition due its coherence, but this paper, ability also demonstrated 96%, outperforms perform method developed independent speed loading conditions."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.10403",
    "a_title":"On the Foundation Model for Cardiac MRI Reconstruction",
    "a_abstract":"In recent years, machine learning (ML) based reconstruction has been widely\ninvestigated and employed in cardiac magnetic resonance (CMR) imaging. ML-based\nreconstructions can deliver clinically acceptable image quality under\nsubstantially accelerated scans. ML-based reconstruction, however, also\nrequires substantial data and computational time to train the neural network,\nwhich is often optimized for a fixed acceleration rate or image contrast. In\npractice, imaging parameters are often tuned to best suit the diagnosis, which\nmay differ from the training data. This can result in degraded image quality,\nand multiple trained networks are needed to fulfill the clinical demands. In\nthis study, we propose a foundation model that uses adaptive unrolling,\nchannel-shifting, and Pattern and Contrast-Prompt-UNet (PCP-UNet) to tackle the\nproblem. In particular, the undersampled data goes through a different number\nof unrolled iterations according to its acceleration rate. Channel-shifting\nimproves reconstructed data quality. The PCP-UNet is equipped with an image\ncontrast and sampling pattern prompt. In vivo CMR experiments were performed\nusing mixed combinations of image contrasts, acceleration rates, and\n(under)sampling patterns. The proposed foundation model has significantly\nimproved image quality for a wide range of CMR protocols and outperforms the\nconventional ML-based method.",
    "explanation":"n this study, we propose\na foundation model that uses adaptive unrolling, channel-shifting, and\nPattern and Contrast-Prompt-UNet (PCP-UNet) to tackle the problem.\nIn particular, the undersampled data goes through a different number\nof unrolled iterations according to its acceleration rate. Channel-shifting\nimproves reconstructed data quality.",
    "b_id":[
      "b14",
      "b1"
    ],
    "b_title":[
      "Sparse MRI: The application of compressed sensing for rapid MR imaging",
      "MoDL: Model-Based Deep Learning Architecture for Inverse Problems"
    ],
    "b_abstract":[
      "Abstract The sparsity which is implicit in MR images exploited to significantly undersample k \u2010space. Some such as angiograms are already sparse the pixel representation; other, more complicated have a representation some transform domain\u2013for example, terms of spatial finite\u2010differences or their wavelet coefficients. According recently developed mathematical theory compressed\u2010sensing, with can be recovered from randomly undersampled \u2010space data, provided an appropriate nonlinear recovery scheme used. Intuitively, artifacts due random undersampling add noise\u2010like interference. In domain significant coefficients stand out above A thresholding recover coefficients, effectively recovering image itself. this article, practical incoherent schemes and analyzed by means aliasing Incoherence introduced pseudo\u2010random variable\u2010density phase\u2010encodes. reconstruction performed minimizing \u2113 1 norm transformed image, subject data fidelity constraints. Examples demonstrate improved resolution accelerated acquisition for multislice fast spin\u2010echo brain imaging 3D contrast enhanced angiography. Magn Reson Med, 2007. \u00a9 2007 Wiley\u2010Liss, Inc.",
      "We introduce a model-based image reconstruction framework with convolution neural network (CNN)-based regularization prior. The proposed formulation provides systematic approach for deriving deep architectures inverse problems the arbitrary structure. Since forward model is explicitly accounted for, smaller fewer parameters sufficient to capture information compared direct inversion approaches. Thus, reducing demand training data and time. we rely on end-to-end weight sharing across iterations, CNN weights are customized model, thus offering improved performance over approaches that pre-trained denoisers. Our experiments show decoupling of number iterations from complexity offered by this benefits, including lower data, reduced risk overfitting, implementations significantly memory footprint. propose enforce data-consistency using numerical optimization blocks, such as conjugate gradients algorithm within network. This offers faster convergence per iteration, methods proximal steps consistency. translates performance, primarily when available GPU restricts iterations."
    ],
    "b_categories":[
      "cs.LG",
      "stat.CO"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Cardiovascular Flow Measurement with Phase-Contrast MR Imaging: Basic Facts and Implementation"
    ],
    "c_abstract":[
      "Phase-contrast magnetic resonance (MR) imaging is a well-known but undervalued method of obtaining quantitative information on blood flow. Applications this technique in cardiovascular MR are expanding. According to the sequences available, phase-contrast measurement can be performed breath hold or during normal respiration. Prospective as well retrospective gating techniques used. Common errors include mismatched encoding velocity, deviation plane, inadequate temporal resolution, spatial accelerated flow and misregistration, phase offset errors. Flow measurements most precise if plane perpendicular vessel interest set through-plane The sequence should repeated at least once, with high velocity used initially. If peak has estimated, an adapted velocity. overall error comprises prescription that occur image analysis data. With imaging, reduced less than 10%, acceptable level for routine clinical use."
    ],
    "c_categories":[
      "q-bio.QM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.15202",
    "a_title":"A Comparison of Machine Learning Algorithms for Predicting Sea Surface\n  Temperature in the Great Barrier Reef Region",
    "a_abstract":"Predicting Sea Surface Temperature (SST) in the Great Barrier Reef (GBR)\nregion is crucial for the effective management of its fragile ecosystems. This\nstudy provides a rigorous comparative analysis of several machine learning\ntechniques to identify the most effective method for SST prediction in this\narea. We evaluate the performance of ridge regression, Least Absolute Shrinkage\nand Selection Operator (LASSO), Random Forest, and Extreme Gradient Boosting\n(XGBoost) algorithms. Our results reveal that while LASSO and ridge regression\nperform well, Random Forest and XGBoost significantly outperform them in terms\nof predictive accuracy, as evidenced by lower Mean Squared Error (MSE), Mean\nAbsolute Error (MAE), and Root Mean Squared Prediction Error (RMSPE).\nAdditionally, XGBoost demonstrated superior performance in minimizing Kullback-\nLeibler Divergence (KLD), indicating a closer alignment of predicted\nprobability distributions with actual observations. These findings highlight\nthe efficacy of using ensemble methods, particularly XGBoost, for predicting\nsea surface temperatures, making them valuable tools for climatological and\nenvironmental modeling.",
    "explanation":"This study provides a rigorous comparative\nanalysis of several machine learning techniques to identify the most effective method for SST\nprediction in this area. We evaluate the performance of ridge regression, Least Absolute Shrinkage\nand Selection Operator (LASSO), Random Forest, and Extreme Gradient Boosting (XGBoost)\nalgorithms. Our results reveal that while LASSO and ridge regression perform well, Random Forest\nand XGBoost significantly outperform them in terms of predictive accuracy, as evidenced by lower\nMean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Prediction\nError (RMSPE).",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "The Great Barrier Reef: an environmental history"
    ],
    "b_abstract":[
      "Reconstructing changes in the Great Barrier Reef 15 3 The natural context of 33 4 spread European settlement coastal Queensland 43 5 beche--de ... mer, pearl shell and trochus fisheries 55 6 Impacts on marine turtles 72 7 dugongs 95 8 whales, sharks fish 9 impacts coral collecting 10 guano rock phosphate mining 11 vi Contents 12 Other reefs 13 Changes island biota 14 Conclusion"
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Ilf-lstm: Enhanced loss function in lstm to predict the sea surface temperature"
    ],
    "c_abstract":[
      "Globe's primary issue is global warming, water temperatures have accompanied it as the sea surface temperature, and it is the primary attribute to balance the energy on the earth's surface. Sea surface temperature prediction is vital to climate forecast. Downwelling currents carry some of this heat to the ocean's bottom layers, which are also heating, covering far behind the increase in sea surface temperature. In deep learning models, the correct loss function will try to reduce the error and converge fast. The proposed improved loss function correctly estimates how close the predictions made by the long short-term memory match the observed values in the training data. This research considers location-specific sea surface temperature predictions using the improved loss function in the long short-term memory neural network at six different locations around India for daily, weekly, and monthly time horizons. Most existing research concentrated on periodic forecasts, but this paper focused on daily, weekly, and monthly predictions. The improved loss function\u2014long short-term memory, achieved 98.7% accuracy, and this improved loss function overcomes the limitations of the existing techniques and reduces the processing time to\u2009~\u20090.35 s. In this research, the sea surface temperature prediction using the improved loss function in the long short-term memory neural network gives better results than the standard prediction models and other existing techniques by considering the long-time dependencies and obtaining features from the spatial data."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06741",
    "a_title":"Methane projections from Canada's oil sands tailings using scientific\n  deep learning reveal significant underestimation",
    "a_abstract":"Bitumen extraction for the production of synthetic crude oil in Canada's\nAthabasca Oil Sands industry has recently come under spotlight for being a\nsignificant source of greenhouse gas emission. A major cause of concern is\nmethane, a greenhouse gas produced by the anaerobic biodegradation of\nhydrocarbons in oil sands residues, or tailings, stored in settle basins\ncommonly known as oil sands tailing ponds. In order to determine the methane\nemitting potential of these tailing ponds and have future methane projections,\nwe use real-time weather data, mechanistic models developed from laboratory\ncontrolled experiments, and industrial reports to train a physics constrained\nmachine learning model. Our trained model can successfully identify the\ndirections of active ponds and estimate their emission levels, which are\ngenerally hard to obtain due to data sampling restrictions. We found that each\nactive oil sands tailing pond could emit between 950 to 1500 tonnes of methane\nper year, whose environmental impact is equivalent to carbon dioxide emissions\nfrom at least 6000 gasoline powered vehicles. Although abandoned ponds are\noften presumed to have insignificant emissions, our findings indicate that\nthese ponds could become active over time and potentially emit up to 1000\ntonnes of methane each year. Taking an average over all datasets that was used\nin model training, we estimate that emissions around major oil sands regions\nwould need to be reduced by approximately 12% over a year, to reduce the\naverage methane concentrations to 2005 levels.",
    "explanation":"In order\nto determine the methane emitting potential of these tailing ponds and have future methane projections,\nwe use real-time weather data, mechanistic models developed from laboratory controlled experiments,\nand industrial reports to train a physics constrained machine learning model.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Learning Polynomials with Neural Networks"
    ],
    "b_abstract":[
      "We study the effectiveness of learning low degree polynomials using neural networks by gradient descent method. While have been shown to great expressive power, and has widely used in practice for networks, few theoretical guarantees are known such methods. In particular, it is well that can get stuck at local minima, even simple classes target functions. this paper, we present several positive results support networks. focus on twolayer where bottom layer a set non-linear hidden nodes, top node linear function, similar Barron (1993). First show randomly initialized network with sufficiently many units, generic algorithm learns any polynomial, assuming initialize weights randomly. Secondly, if use complex-valued (the function still be real), then under suitable conditions, there no robust minima: always escape minimum performing random perturbation. This property does not hold real-valued weights. Thirdly, discuss whether sparse learned small size dependent sparsity function."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b20"
    ],
    "c_title":[
      "Physics-informed machine learning"
    ],
    "c_abstract":[
      "Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems."
    ],
    "c_categories":[
      "physics.chem-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18259",
    "a_title":"Transfer Learning for Deep Learning-based Prediction of Lattice Thermal\n  Conductivity",
    "a_abstract":"Machine learning promises to accelerate the material discovery by enabling\nhigh-throughput prediction of desirable macro-properties from atomic-level\ndescriptors or structures. However, the limited data available about precise\nvalues of these properties have been a barrier, leading to predictive models\nwith limited precision or the ability to generalize. This is particularly true\nof lattice thermal conductivity (LTC): existing datasets of precise (ab initio,\nDFT-based) computed values are limited to a few dozen materials with little\nvariability. Based on such datasets, we study the impact of transfer learning\non both the precision and generalizability of a deep learning model\n(ParAIsite). We start from an existing model (MEGNet~\\cite{Chen2019}) and show\nthat improvements are obtained by fine-tuning a pre-trained version on\ndifferent tasks. Interestingly, we also show that a much greater improvement is\nobtained when first fine-tuning it on a large datasets of low-quality\napproximations of LTC (based on the AGL model) and then applying a second phase\nof fine-tuning with our high-quality, smaller-scale datasets. The promising\nresults obtained pave the way not only towards a greater ability to explore\nlarge databases in search of low thermal conductivity materials but also to\nmethods enabling increasingly precise predictions in areas where quality data\nare rare.",
    "explanation":"Machine learning promises to accelerate the material discovery by enabling high-throughput pre-\ndiction of desirable macro-properties from atomic-level descriptors or structures.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Physics-informed machine learning"
    ],
    "b_abstract":[
      "Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Quantifying the performance of machine learning models in materials discovery"
    ],
    "c_abstract":[
      "The predictive capabilities of machine learning (ML) models used in materials discovery are typically measured using simple statistics such as the root-mean-square error (RMSE) or coefficient determination ($r^2$) between ML-predicted property values and their known values. A tempting assumption is that with low should be effective at guiding discovery, conversely, high give poor performance. However, we observe no clear connection exists a \"static\" quantity averaged across an entire training set, RMSE, ML model's ability to dynamically guide iterative (and often extrapolative) novel targeted properties. In this work, simulate sequential (SL)-guided process demonstrate decoupling traditional model metrics performance discoveries. We show depends strongly on (1) target range within distribution (e.g., whether 1st 10th decile material desired); (2) incorporation uncertainty estimates SL acquisition function; (3) scientist interested one many targets; (4) how iterations allowed. To overcome limitations static robustly capture performance, recommend Discovery Yield ($DY$), measure high-performing were discovered during SL, Probability ($DP$), likelihood discovering any point process."
    ],
    "c_categories":[
      "cond-mat.mtrl-sci"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18253",
    "a_title":"Multimodal Integration of Longitudinal Noninvasive Diagnostics for\n  Survival Prediction in Immunotherapy Using Deep Learning",
    "a_abstract":"Purpose: Analyzing noninvasive longitudinal and multimodal data using\nartificial intelligence could potentially transform immunotherapy for cancer\npatients, paving the way towards precision medicine. Methods: In this study, we\nintegrated pre- and on-treatment blood measurements, prescribed medications and\nCT-based volumes of organs from a large pan-cancer cohort of 694 patients\ntreated with immunotherapy to predict short and long-term overall survival. By\nleveraging a combination of recent developments, different variants of our\nextended multimodal transformer-based simple temporal attention (MMTSimTA)\nnetwork were trained end-to-end to predict mortality at three, six, nine and\ntwelve months. These models were also compared to baseline methods\nincorporating intermediate and late fusion based integration methods. Results:\nThe strongest prognostic performance was demonstrated using the extended\ntransformer-based multimodal model with area under the curves (AUCs) of $0.84\n\\pm $0.04, $0.83 \\pm $0.02, $0.82 \\pm $0.02, $0.81 \\pm $0.03 for 3-, 6-, 9-,\nand 12-month survival prediction, respectively. Conclusion: Our findings\nsuggest that analyzing integrated early treatment data has potential for\npredicting survival of immunotherapy patients. Integrating complementary\nnoninvasive modalities into a jointly trained model, using our extended\ntransformer-based architecture, demonstrated an improved multimodal prognostic\nperformance, especially in short term survival prediction.",
    "explanation":"In this study, we integrated pre- and on-treatment blood\nmeasurements, prescribed medications and CT-based volumes of organs from a large\npan-cancer cohort of 694 patients treated with immunotherapy to predict short and long-term\noverall survival. By leveraging a combination of recent developments, different variants of our\nextended multimodal transformer-based simple temporal attention (MMTSimTA) network were\ntrained end-to-end to predict mortality at three, six, nine and twelve months.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Multimodal data fusion for cancer biomarker discovery with deep learning"
    ],
    "b_abstract":[
      "Technological advances have made it possible to study a patient from multiple angles with high-dimensional, high-throughput multiscale biomedical data. In oncology, massive amounts of data are being generated, ranging from molecular, histopathology, radiology to clinical records. The introduction of deep learning has greatly advanced the analysis of biomedical data. However, most approaches focus on single data modalities, leading to slow progress in methods to integrate complementary data types. Development of effective multimodal fusion approaches is becoming increasingly important as a single modality might not be consistent and sufficient to capture the heterogeneity of complex diseases to tailor medical care and improve personalized medicine. Many initiatives now focus on integrating these disparate modalities to unravel the biological processes involved in multifactorial diseases such as cancer. However, many obstacles remain, including lack of usable data as well as methods for clinical validation and interpretation. Here, we cover these current challenges and reflect on opportunities through deep learning to tackle data sparsity and scarcity, multimodal interpretability and standardization of datasets."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Artificial intelligence for predictive biomarker discovery in immuno-oncology: a systematic review"
    ],
    "c_abstract":[
      "Background: The widespread use of immune checkpoint inhibitors (ICIs) has revolutionised treatment of multiple cancer types. However, selecting patients who may benefit from ICI remains challenging. Artificial intelligence (AI) approaches allow exploitation of high-dimension oncological data in research and development of precision immuno-oncology. Materials and methods: We conducted a systematic literature review of peer-reviewed original articles studying the ICI efficacy prediction in cancer patients across five data modalities: genomics (including genomics, transcriptomics, and epigenomics), radiomics, digital pathology (pathomics), and real-world and multimodality data. Results: A total of 90 studies were included in this systematic review, with 80% published in 2021-2022. Among them, 37 studies included genomic, 20 radiomic, 8 pathomic, 20 real-world, and 5 multimodal data. Standard machine learning (ML) methods were used in 72% of studies, deep learning (DL) methods in 22%, and both in 6%. The most frequently studied cancer type was non-small-cell lung cancer (36%), followed by melanoma (16%), while 25% included pan-cancer studies. No prospective study design incorporated AI-based methodologies from the outset; rather, all implemented AI as a post hoc analysis. Novel biomarkers for ICI in radiomics and pathomics were identified using AI approaches, and molecular biomarkers have expanded past genomics into transcriptomics and epigenomics. Finally, complex algorithms and new types of AI-based markers, such as meta-biomarkers, are emerging by integrating multimodal\/multi-omics data. Conclusion: AI-based methods have expanded the horizon for biomarker discovery, demonstrating the power of integrating multimodal data from existing datasets to discover new meta-biomarkers. While most of the included studies showed promise for AI-based prediction of benefit from immunotherapy, none provided high-level evidence for immediate practice change. A priori planned prospective trial designs are needed to cover all lifecycle steps of these software biomarkers, from development and validation to integration into clinical practice."
    ],
    "c_categories":[
      "Immunotherapy"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17617",
    "a_title":"An Ensemble Approach for Brain Tumor Segmentation and Synthesis",
    "a_abstract":"The integration of machine learning in magnetic resonance imaging (MRI),\nspecifically in neuroimaging, is proving to be incredibly effective, leading to\nbetter diagnostic accuracy, accelerated image analysis, and data-driven\ninsights, which can potentially transform patient care. Deep learning models\nutilize multiple layers of processing to capture intricate details of complex\ndata, which can then be used on a variety of tasks, including brain tumor\nclassification, segmentation, image synthesis, and registration. Previous\nresearch demonstrates high accuracy in tumor segmentation using various model\narchitectures, including nn-UNet and Swin-UNet. U-Mamba, which uses state space\nmodeling, also achieves high accuracy in medical image segmentation. To\nleverage these models, we propose a deep learning framework that ensembles\nthese state-of-the-art architectures to achieve accurate segmentation and\nproduce finely synthesized images.",
    "explanation":"The integration of machine learning in magnetic resonance\nimaging (MRI), specifically in neuroimaging, is proving to be incred-\nibly effective, leading to better diagnostic accuracy, accelerated image\nanalysis, and data-driven insights, which can potentially transform pa-\ntient care.",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "ALL-Net: Anatomical information lesion-wise loss function integrated into neural network for multiple sclerosis lesion segmentation"
    ],
    "b_abstract":[
      "Accurate detection and segmentation of multiple sclerosis (MS) brain lesions on magnetic resonance images are important for disease diagnosis treatment. This is a challenging task as vary greatly in size, shape, location, image contrast. The objective our study was to develop an algorithm based deep convolutional neural network integrated with anatomic information lesion-wise loss function (ALL-Net) fast accurate automated MS lesions. Distance transformation mapping used construct module that encoded lesion-specific anatomical information. To overcome the lesion size imbalance during training improve small lesions, developed which individual were modeled spheres equal size. On ISBI-2015 longitudinal challenge dataset (19 subjects total), ALL-Net achieved overall score 93.32 amongst top performing methods. larger Cornell (176 significantly improved both voxel-wise metrics (Dice improvement 3.9% 35.3% p-values ranging from p < 0.01 0.0001, AUC precision-recall curve 2.1% 29.8%) (lesion-wise F1 12.6% 29.8% all ROC 1.4% 20.0%) compared leading publicly available tools."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "Deep learning-Based 3D inpainting of brain MR images"
    ],
    "c_abstract":[
      "Abstract The detailed anatomical information of the brain provided by 3D magnetic resonance imaging (MRI) enables various neuroscience research. However, due to long scan time for MR images, 2D images are mainly obtained in clinical environments. purpose this study is generate from a sparsely sampled using an inpainting deep neural network that has U-net-like structure and DenseNet sub-blocks. To train network, not only fidelity loss but also perceptual based on VGG were considered. Various methods used assess overall similarity between inpainted original data. In addition, morphological analyzes performed investigate whether data produced local features similar diagnostic ability was evaluated investigating pattern changes disease groups. Brain anatomy details efficiently recovered proposed network. voxel-based analysis gray matter volume cortical thickness, differences observed small clusters. method will be useful utilizing advanced neuroimaging techniques with MRI"
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00252",
    "a_title":"Localization Phenomena in Large-Scale Networked Systems: Implications\n  for Fragility",
    "a_abstract":"We study phenomena where some eigenvectors of a graph Laplacian are largely\nconfined in small subsets of the graph. These localization phenomena are\nsimilar to those generally termed Anderson Localization in the Physics\nliterature, and are related to the complexity of the structure of large graphs\nin still unexplored ways. Using spectral perturbation theory and\npseudo-spectrum analysis, we explain how the presence of localized eigenvectors\ngives rise to fragilities (low robustness margins) to unmodeled node or link\ndynamics. Our analysis is demonstrated by examples of networks with relatively\nlow complexity, but with features that appear to induce eigenvector\nlocalization. The implications of this newly-discovered fragility phenomenon\nare briefly discussed.",
    "explanation":"The choices in Task 3 where represent the interdisciplinary topics utilized in this research paper summarized in the Abstract. Below are a few sentences from the Abstract that reflect that:\n\n\"Localization in the Physics literature, and are related to the complexity of the structure of large graphs in still unexplored ways.\"\n\"Using spectral perturbation theory and pseudospectrum analysis, we explain how the presence of localized eigenvectors gives rise to fragilities (low robustness margins) to unmodeled node or link dynamics.\"",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Analytic perturbation theory for matrices and operators"
    ],
    "b_abstract":[
      "Perturbation theory is the study of the behavior of mathematical objects under the influence of perturbations. It is not a well-defined mathematical topic with specific objects and methods, but rather a method of investigation. In this book, perturbation theory will be developed for linear operators. First, inter-est focuses on the properties of spectral objects, such as eigenvalues, eigenprojections, eigenvectors and Jordan vectors, under perturbation of the underlying operator. This study encompasses some difficult problems. On the one hand, variations of the spectral objects need to be calculated quantitatively. The spectral objects are assumed known for the unperturbed operator, the determination (or at least the approximation) of the spectral objects for the perturbed operator is at issue. This is the starting point for the perturbation theory of L. RAYLEIGH [1] (see also R. COURANT and D. HTT.BEBT [1, p. 296 sqq]). On the other hand, the spectral objects often undergo abrupt qualitative changes, even in the case of small perturbations. These changes cause significant complications. Usually, the behavior of the spectral objects depends strongly on the assumptions about the nature of the perturbation. For example, one can assume continuity, differ-entiability, smoothness (i.e. arbitrary differentiability) or analyticity. In the following discussion, only the case of analytic (holomorphic) perturbations will be investigated, even if this strong restriction is applied, the problems remain difficult enough. On the one hand, solving problems of perturbation theory is of conceptual interest. The study of intrinsic spectral properties of a linear operator undergoing perturbation leads to deeper insights and understanding of the structure of the operator. It also leads to the development of new tools for further investigations. On the other hand, applications (inside and outside of mathematics) lead to new questions in perturbation theory. One of the first calculations of perturbation theory was given by L. Rayleigh, who determined the eigenfrequencies and eigenmodes of an oscillating string, fixed at x = 0 and x = n, whose elasticity modulus is constant and whose mass density Q(X) has only a small deviation from a constant value for all x, 0 ^ x 5S n. (That is, the density o(x) is of the form Q(X) = p0 + ea(x), where a(x) is a given function and where e is a small perturbation parameter.) Actually, as this example indicates, the starting point for the development of per-turbation theory was the study of perturbations of spectral objects (eigenvalues and eigenvectors) for concrete classes of operators, for example, Fredholm integral operators or Sturm-Liouville differential operators (for example, see L. LIECHTENSTEIN [1])."
    ],
    "b_categories":[
      "Analytic Perturbation Theory "
    ],
    "b_fields":[

    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Localization and landscape functions for graph laplacians"
    ],
    "c_abstract":[
      "We discuss explicit landscape functions for quantum graphs. By a 'landscape function' Upsilon(x) we mean a function that controls the localization properties of normalized eigenfunctions psi(x) through a pointwise inequality of the form |psi(x)| le Upsilon(x). The ideal Upsilon is a function that a) responds to the potential energy V(x) and to the structure of the graph in some formulaic way; b) is small in examples where eigenfunctions are suppressed by the tunneling effect, and c) relatively large in regions where eigenfunctions may - or may not - be concentrated, as observed in specific examples. It turns out that the connectedness of a graph can present a barrier to the existence of universal landscape functions in the high-energy r\u00e9gime, as we show with simple examples. We therefore apply different methods in different r\u00e9gimes determined by the values of the potential energy V(x) and the eigenvalue parameter E."
    ],
    "c_categories":[
      "Anderson Localization"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.06513",
    "a_title":"PRISM: Privacy-preserving Inter-Site MRI Harmonization via Disentangled\n  Representation Learning",
    "a_abstract":"Multi-site MRI studies often suffer from site-specific variations arising\nfrom differences in methodology, hardware, and acquisition protocols, thereby\ncompromising accuracy and reliability in clinical AI\/ML tasks. We present PRISM\n(Privacy-preserving Inter-Site MRI Harmonization), a novel Deep Learning\nframework for harmonizing structural brain MRI across multiple sites while\npreserving data privacy. PRISM employs a dual-branch autoencoder with\ncontrastive learning and variational inference to disentangle anatomical\nfeatures from style and site-specific variations, enabling unpaired image\ntranslation without traveling subjects or multiple MRI modalities. Our modular\ndesign allows harmonization to any target site and seamless integration of new\nsites without the need for retraining or fine-tuning. Using multi-site\nstructural MRI data, we demonstrate PRISM's effectiveness in downstream tasks\nsuch as brain tissue segmentation and validate its harmonization performance\nthrough multiple experiments. Our framework addresses key challenges in medical\nAI\/ML, including data privacy, distribution shifts, model generalizability and\ninterpretability. Code is available at https:\/\/github.com\/saranggalada\/PRISM",
    "explanation":"From the selected references in Task 3, the following sentences from the abstract reflect the interdisciplinary topics of this research paper, combining the field of medicine  (MRI Scans) with machine learning (AI\/ML tasks):\n\n\"Multi-site MRI studies often suffer from site-specific variations arising from differences in methodology, hardware,\nand acquisition protocols, thereby compromising accuracy\nand reliability in clinical AI\/ML tasks. \"\n\n\"We present PRISM (Privacy-preserving Inter-Site MRI Harmonization), a novel Deep Learning framework for harmonizing structural brain MRI across multiple sites while preserving data privacy.\"",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Advances and Open Problems in Federated Learning"
    ],
    "b_abstract":[
      "The term Federated Learning was coined as recently 2016 to describe a machine learning setting where multiple entities collaborate in solving problem, under the coordination of central server or service provider. Each client\u2019s raw data is stored locally and not exchanged transferred; instead, focused updates intended for immediate aggregation are used achieve objective. Since then, topic has gathered much interest across many different disciplines realization that these interdisciplinary problems likely requires just but techniques from distributed optimization, cryptography, security, differential privacy, fairness, compressed sensing, systems, information theory, statistics, more. This monograph contributions leading experts disciplines, who latest state-of-the art their perspective. These have been carefully curated into comprehensive treatment enables reader understand work done get pointers effort required solve before can become reality practical systems. Researchers working area systems will find this an enlightening read may inspire them on challenging issues outlined. up speed quickly easily what increasingly important topic: Learning."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "The future of digital health with federated learning"
    ],
    "c_abstract":[
      "Abstract Data-driven machine learning (ML) has emerged as a promising approach for building accurate and robust statistical models from medical data, which is collected in huge volumes by modern healthcare systems. Existing data not fully exploited ML primarily because it sits silos privacy concerns restrict access to this data. However, without sufficient will be prevented reaching its full potential and, ultimately, making the transition research clinical practice. This paper considers key factors contributing issue, explores how federated (FL) may provide solution future of digital health highlights challenges considerations that need addressed."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.16464",
    "a_title":"Generating social networks with static and dynamic utility-maximization\n  approaches",
    "a_abstract":"In this paper, we introduce a conceptual framework that model human social\nnetworks as an undirected dot-product graph of independent individuals. Their\nrelationships are only determined by a cost-benefit analysis, i.e. by\nmaximizing an objective function at the scale of the individual or of the whole\nnetwork. On this framework, we build a new artificial network generator in two\nversions. The first fits within the tradition of artificial network generators\nby being able to generate similar networks from empirical data. The second\nrelaxes the computational efficiency constraint and implements the same\nmicro-based decision algorithm, but in agent-based simulations with time and\nfully independent agents. This latter version enables social scientists to\nperform an in-depth analysis of the consequences of behavioral constraints\naffecting individuals on the network they form. This point is illustrated by a\ncase study of imperfect information.",
    "explanation":"The two key references selected in Task 3 reflect what makes this paper an IDR. The sentences copied from the abstract that relate to the references are shown below, combining economics and computational engineering.\n\n\"Their relationships are only determined by a cost-benefit analysis...\"\n\n\"The second relaxes the computational efficiency constraint\nand implements the same micro-based decision algorithm, but in agent-based simulations with time and fully independent agents.\"",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Meeting Strangers and Friends of Friends: How Random Are Social Networks?"
    ],
    "b_abstract":[
      "We present a dynamic model of network formation where nodes find other with whom to form links in two ways: some are found uniformly at random, while others by searching locally through the current structure (e.g., meeting friends friends). This combination processes results spectrum features exhibited large social networks, including presence more high- and low-degree than when formed independently having low distances between network, high clustering on local level. fit data from six networks impute relative ratio random network-based meetings link formation, which turns out vary dramatically across applications. show that as random\/network-based varies, resulting degree distributions can be ordered sense stochastic dominance, allows us infer how process affects average utility network. (JEL D85, Z13)"
    ],
    "b_categories":[
      "q-fin.EC"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "An agent-based spatial urban social network generator: A case study of beijing, china"
    ],
    "c_abstract":[
      "This paper proposes an agent-based spatial social network model, which combines a utility function and heuristic algorithms, to formulate friendships of agents in a given synthetic population comprising individuals and households, as well as their attributes and locations. In order to better and explicitly represent the real social networks, the model attempts to generate both close and somewhat close social networks by linking agents with either close or somewhat close friendships, fitting both distributions of network degree and transitivity, which are two basic characteristics of a network. Here, a utility function, which incorporates the similarity between agents in individual attributes (e.g., sex), as well as the spatial closeness of their residential locations and workplaces, is developed to judge whether a friendship between a pair of agents can be built. Furthermore, the social network model is developed as a key component of an agent-and Geographic Information System (GIS)-based virtual city creator that is a set of synthesis methods used to generate spatially disaggregate urban data. Finally, Beijing, China is used as a case study. Both close and somewhat close social networks are generated with the target and generated distributions well matched, and the generated networks are further analysed from a geographical perspective."
    ],
    "c_categories":[
      "cs.CE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.17260",
    "a_title":"MiceBoneChallenge: Micro-CT public dataset and six solutions for\n  automatic growth plate detection in micro-CT mice bone scans",
    "a_abstract":"Detecting and quantifying bone changes in micro-CT scans of rodents is a\ncommon task in preclinical drug development studies. However, this task is\nmanual, time-consuming and subject to inter- and intra-observer variability. In\n2024, Anonymous Company organized an internal challenge to develop models for\nautomatic bone quantification. We prepared and annotated a high-quality dataset\nof 3D $\\mu$CT bone scans from $83$ mice. The challenge attracted over $80$ AI\nscientists from around the globe who formed $23$ teams. The participants were\ntasked with developing a solution to identify the plane where the bone growth\nhappens, which is essential for fully automatic segmentation of trabecular\nbone. As a result, six computer vision solutions were developed that can\naccurately identify the location of the growth plate plane. The solutions\nachieved the mean absolute error of $1.91\\pm0.87$ planes from the ground truth\non the test set, an accuracy level acceptable for practical use by a\nradiologist. The annotated 3D scans dataset along with the six solutions and\nsource code, is being made public, providing researchers with opportunities to\ndevelop and benchmark their own approaches. The code, trained models, and the\ndata will be shared.",
    "explanation":"This IDR combines various fields like computer science (Computer Vision and AI) and physical medicine (CT Scans) introduced in the abstract. The selected key references from Task 3 are described with a few sentences from the abstract shown below:\n\n\"We prepared and annotated a high-quality dataset of 3D \u03bcCT bone scans from 83 mice. \"\n\n\"As a result, six computer vision solutions were developed that can accurately identify the location of the growth plate plane. \"",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Differentiation of distal ureteral stones and pelvic phleboliths using a convolutional neural network"
    ],
    "b_abstract":[
      "Abstract The objectives were to develop and validate a Convolutional Neural Network (CNN) using local features for differentiating distal ureteral stones from pelvic phleboliths, compare the CNN method with semi-quantitative radiologists\u2019 assessments evaluate whether assessment of calcification its surroundings is sufficient discriminating phleboliths in non-contrast-enhanced CT (NECT). We retrospectively included 341 consecutive patients acute renal colic stone on NECT showing either stone, phlebolith or both. A 2.5-dimensional (2.5D-CNN) model was used, where perpendicular axial, coronal sagittal images through each used as input data CNN. trained 384 calcifications, evaluated an unseen dataset 50 phleboliths. compared by seven radiologists who reviewed 5 \u00d7 cm image stack surrounding calcification, cut-off values based attenuation volume calcifications. differentiated sensitivity, specificity accuracy 94%, 90% 92% AUC 0.95. This similar majority vote 93% significantly higher ( p = 0.03) than mean radiologist 86%. 49%. In conclusion, features. However, more are needed reach optimal discrimination."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b27"
    ],
    "c_title":[
      "Micro-CT data of early physiological cancellous bone formation in the lumbar spine of female C57BL\/6 mice"
    ],
    "c_abstract":[
      "Micro-CT provides critical data for musculoskeletal research, yielding three-dimensional datasets containing distributions of mineral density. Using high-resolution scans, we quantified changes in the fine architecture of bone in the spine of young mice. This data is made available as a reference to physiological cancellous bone growth. The scans (n\u2009=\u200919) depict the extensive structural changes typical for female C57BL\/6 mice pups, aged 1-, 3-, 7-, 10- and 14-days post-partum, as they attain the\u00a0mature geometry. We reveal the micro-morphology down to individual\u00a0trabeculae in the spine that follow phases of mineral-tissue rearrangement in the growing lumbar vertebra on a micrometer length scale. Phantom data is provided to facilitate mineral density calibration. Conventional histomorphometry matched with our micro-CT data on selected samples confirms the validity and accuracy of our 3D scans. The data may thus serve as a reference for modeling normal bone growth and can be used to benchmark other experiments assessing the effects of biomaterials, tissue growth, healing, and regeneration. Measurement(s) bone growth \u2022 bone mineralization involved in bone maturation Technology Type(s) micro-computed tomography Factor Type(s) age Sample Characteristic - Organism Mus musculus Sample Characteristic - Environment biological_process Machine-accessible metadata file describing the reported data: https:\/\/doi.org\/10.6084\/m9.figshare.14062073"
    ],
    "c_categories":[
      "physics.med-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.14846",
    "a_title":"Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy\n  with Pre-training, Data Augmentation and Dual Flow UNet",
    "a_abstract":"Head and neck tumors and metastatic lymph nodes are crucial for treatment\nplanning and prognostic analysis. Accurate segmentation and quantitative\nanalysis of these structures require pixel-level annotation, making automated\nsegmentation techniques essential for the diagnosis and treatment of head and\nneck cancer. In this study, we investigated the effects of multiple strategies\non the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT)\nimages. For the segmentation of pre-RT images, we utilized: 1) a fully\nsupervised learning approach, and 2) the same approach enhanced with\npre-trained weights and the MixUp data augmentation technique. For mid-RT\nimages, we introduced a novel computational-friendly network architecture that\nfeatures separate encoders for mid-RT images and registered pre-RT images with\ntheir labels. The mid-RT encoder branch integrates information from pre-RT\nimages and labels progressively during the forward propagation. We selected the\nhighest-performing model from each fold and used their predictions to create an\nensemble average for inference. In the final test, our models achieved a\nsegmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on\naggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at\nhttps:\/\/github.com\/WltyBY\/HNTS-MRG2024_train_code.",
    "explanation":"In this IDR, mainly two topics from the two the two different fields of medical physics and artificial intelligence are being described. The use of MRI scans falls under the Medical Physics category and utilizing computer vision falls under AI. \n\nHere are a few sentences from the abstract that reflect the integration of this interdisciplinary ideas:\n\n\" In this study, we investigated the effects of multiple strategies on the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT) images.\"\n\"For mid-RT images, we introduced a novel computational-friendly network architecture that features separate encoders for mid-RT images and registered pre-RT images with their labels.\"",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Evaluation of the Impact of Magnetic Resonance Imaging (MRI) on Gross Tumor Volume (GTV) Definition for Radiation Treatment Planning (RTP) of Inoperable High Grade Gliomas (HGGs)"
    ],
    "b_abstract":[
      "Aim and Background . Inoperable high-grade gliomas (HGGs) comprise a specific group of brain tumors portending very poor prognosis. In the absence surgical management, radiation therapy (RT) offers primary local treatment modality for inoperable HGGs. Optimal target definition planning (RTP) HGGs is difficult task given diffusely infiltrative nature disease. this context, detailed multimodality imaging information may add to accuracy in We evaluated impact Magnetic Resonance Imaging (MRI) on Gross Tumor Volume (GTV) RTP study. Materials Methods Twenty-five patients with clinical diagnosis HGG were included GTV was based Computed Tomography- (CT-) simulation images only or both CT-simulation MR images, comparative assessment performed investigate incorporation MRI into Results Median volume acquired by using use CT 65.3 (39.6 - 94.3) cc 76.1 (46.8-108.9) cc, respectively. Incorporation has resulted median increase 12.61% (6%-19%) defined only, which statistically significant (p &lt; 0.05). Conclusion improve have implications dose escalation\/intensification strategies despite need further supporting evidence."
    ],
    "b_categories":[
      "physics.med-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation"
    ],
    "c_abstract":[
      "Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able process 2D images while data used in clinical practice consists of 3D volumes. In this work we propose an approach segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end MRI volumes depicting prostate, learns predict for whole volume at once. We introduce novel objective function, that optimise during training, Dice coefficient. way can deal with situations where there strong imbalance between number foreground background voxels. To cope limited annotated available augment applying random non-linear transformations histogram matching. show our experimental evaluation achieves good performances challenging test requiring fraction processing time needed by other previous methods."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.16995",
    "a_title":"Leveraging Neural Networks to Optimize Heliostat Field Aiming Strategies\n  in Concentrating Solar Power Tower Plants",
    "a_abstract":"Concentrating Solar Power Tower (CSPT) plants rely on heliostat fields to\nfocus sunlight onto a central receiver. Although simple aiming strategies, such\nas directing all heliostats to the receivers equator, can maximize energy\ncollection, they often result in uneven flux distributions that lead to\nhotspots, thermal stresses, and reduced receiver lifetimes. This paper presents\na novel, data-driven approach that integrates constraint learning, neural\nnetwork-based surrogates, and mathematical optimization to overcome these\nchallenges. The methodology learns complex heliostat-to-receiver flux\ninteractions from simulation data, constructing a surrogate model that is\nembedded into a tractable optimization framework. By maximizing a tailored\nquality score that balances energy collection and flux uniformity, the approach\nyields smoothly distributed flux profiles and mitigates excessive thermal\npeaks. An iterative refinement process, guided by the trust region and\nprogressive data sampling, ensures the surrogate model improves the obtained\nsolution by exploring new spaces during the iterations. Results from a real\nCSPT case study demonstrate that the proposed approach surpasses conventional\nheuristic methods, offering flatter flux distributions and safer thermal\nconditions without a substantial loss in overall energy capture.",
    "explanation":"The two fields described in the references chosen in Task 3 were AI and Mathematics. This IDR talks a lot about mathematical optimization and control to overcome certain challenges as well as leverages AI and machine learning (neural networks).\n\nSentences from the abstract:\n\"This paper presents a novel, data-driven approach that integrates constraint learning, neural network-based surrogates, and mathematical optimization to overcome these challenges.\"\n",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Multi-objective performance optimization & thermodynamic analysis of solar powered supercritical co2 power cycles using machine learning methods & genetic algorithm"
    ],
    "b_abstract":[
      "The present study is focused on multi-objective performance optimization & thermodynamic analysis from the perspectives of energy and exergy for Recompression, Partial Cooling & Main Compression Intercooling supercritical CO2 (sCO2) Brayton cycles for concentrated solar power (CSP) applications using machine learning algorithms. The novelty of this work lies in the integration of artificial neural networks (ANN) and genetic algorithms (GA) for optimizing the performance of advanced sCO2 power cycles considering climatic variation, which has significant implications for both the scientific community and engineering applications in the renewable energy sector. The methodology employed includes thermodynamic analysis based on energy, exergy & environmental factors including system performance optimization. The system is modelled for net power production of 15 MW thermal output utilizing equations for the energy and exergy balance for each component. Subsequently, thermodynamic model extracted dataset used for prediction & evaluation of Random Forest, XGBoost, KNN, AdaBoost, ANN and LightGBM algorithm. Finally, considering climate conditions, multi-objective optimization is carried out for the CSP integrated sCO2 Power cycle for optimal power output, exergy destruction, thermal and exergetic efficiency. Genetic algorithm and TOPSIS (technique for order of preference by similarity to ideal solution), multi-objective decision-making tool, were used to determine the optimum operating conditions. The major findings of this work reveal significant improvements in the performance of the advanced sCO2 cycle by 1.68 % and 7.87 % compared to conventional recompression and partial cooling cycle, respectively. This research could advance renewable energy technologies, particularly concentrated solar power, by improving power cycle designs to increase system efficiency and economic feasibility. Optimized advanced supercritical CO2 power cycles in concentrated solar power plants might increase renewable energy use and energy generation infrastructure, potentially opening new research avenues."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "A method for real-time optimal heliostat aiming strategy generation via deep learning"
    ],
    "c_abstract":[
      "Optimal aiming strategies are essential for efficient solar power tower technology operation. However, the high calculation complexity makes it difficult for existing optimization methods to solve the optimization problem in real-time directly. This work proposes a real-time optimal heliostat aiming strategy generation method via deep learning. First, a two-stage learning scheme where the neural network models are trained by genetic algorithm (GA) benchmark solutions to produce an optimal aiming strategy is presented. Then, an end-to-end model without needing GA solutions for training is developed and discussed. Furthermore, a robust end-to-end training method using randomly sampled flux maps is also proposed. The proposed models demonstrated comparable performance as GA with two orders of magnitude less computation time through case studies. Among the proposed models, the end-to-end model shows significantly better generalization ability than the pure data-driven two-stage model on the test set. A robust end-to-end model with data enhancement has better robustness on unseen flux maps."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.12897",
    "a_title":"Tree Species Classification using Machine Learning and 3D Tomographic\n  SAR -- a case study in Northern Europe",
    "a_abstract":"Tree species classification plays an important role in nature conservation,\nforest inventories, forest management, and the protection of endangered\nspecies. Over the past four decades, remote sensing technologies have been\nextensively utilized for tree species classification, with Synthetic Aperture\nRadar (SAR) emerging as a key technique. In this study, we employed TomoSense,\na 3D tomographic dataset, which utilizes a stack of single-look complex (SLC)\nimages, a byproduct of SAR, captured at different incidence angles to generate\na three-dimensional representation of the terrain. Our research focuses on\nevaluating multiple tabular machine-learning models using the height\ninformation derived from the tomographic image intensities to classify eight\ndistinct tree species. The SLC data and tomographic imagery were analyzed\nacross different polarimetric configurations and geosplit configurations. We\ninvestigated the impact of these variations on classification accuracy,\ncomparing the performance of various tabular machine-learning models and\noptimizing them using Bayesian optimization. Additionally, we incorporated a\nproxy for actual tree height using point cloud data from Light Detection and\nRanging (LiDAR) to provide height statistics associated with the model's\npredictions. This comparison offers insights into the reliability of\ntomographic data in predicting tree species classification based on height.",
    "explanation":"Some sentences that describe the integration of interdisciplinary fields based on the selected references in Task 3:\n\n\"Over the past four decades, remote sensing technologies have been extensively utilized for tree species classification, with Synthetic Aperture Radar (SAR) emerging as a key technique. \"\n\"Tree species classification plays an important role in nature conservation, forest inventories, forest management, and the protection of endangered species.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Mapping Tree Species Using Advanced Remote Sensing Technologies: A State-of-the-Art Review and Perspective"
    ],
    "b_abstract":[
      "Timely and accurate information on tree species (TS) is crucial for developing strategies sustainable management conservation of artificial natural forests. Over the last four decades, advances in remote sensing technologies have made TS classification possible. Since many studies topic been conducted their comprehensive results novel findings published literature, it necessary to conduct an updated review status, trends, potentials, challenges recommend future directions. The will provide overview various optical light detection ranging (LiDAR) sensors; present assess current techniques\/methods for, a general trend method development in, classification; identify limitations In this review, several concluding remarks were made. They include following: (1) A large group using high-resolution satellite, airborne multi-\/hyperspectral imagery, LiDAR data. (2) \u201cmultiple\u201d was observed. (3) Machine learning methods including deep models demonstrated be significant improving accuracy. (4) Recently, unmanned aerial vehicle- (UAV-) based sensors caught interest researchers practitioners topic-related research applications. addition, three directions recommended, refining categories methods, data fusion algorithms or processing chains, exploring new spectral unmixing automatically extract map from satellite hyperspectral"
    ],
    "b_categories":[
      "Remote Sensing Technologies"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Morphological transformation and spatial-logical aggregation for tree species classification using hyperspectral imagery"
    ],
    "c_abstract":[
      "Hyperspectral image (HSI) consists of abundant spectral and spatial characteristics, which contribute to a more accurate identification of materials and land covers. However, most existing methods of hyperspectral image analysis primarily focus on spectral knowledge or coarse-grained spatial information while neglecting the fine-grained morphological structures. In the classification task of complex objects, spatial morphological differences can help to search for the boundary of fine-grained classes, e.g., forestry tree species. Focusing on subtle traits extraction, a spatial-logical aggregation network (SLA-NET) is proposed with morphological transformation for tree species classification. The morphological operators are effectively embedded with the trainable structuring elements, which contributes to distinctive morphological representations. We evaluate the classification performance of the proposed method on two tree species datasets, and the results demonstrate that the proposed SLA-NET significantly outperforms the other state-of-the-art classifiers."
    ],
    "c_categories":[
      "Evolutionary Biology"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.07018",
    "a_title":"Data-Driven Gradient Optimization for Field Emission Management in a\n  Superconducting Radio-Frequency Linac",
    "a_abstract":"Field emission can cause significant problems in superconducting\nradio-frequency linear accelerators (linacs). When cavity gradients are pushed\nhigher, radiation levels within the linacs may rise exponentially, causing\ndegradation of many nearby systems. This research aims to utilize machine\nlearning with uncertainty quantification to predict radiation levels at\nmultiple locations throughout the linacs and ultimately optimize cavity\ngradients to reduce field emission induced radiation while maintaining the\ntotal linac energy gain necessary for the experimental physics program. The\noptimized solutions show over 40% reductions for both neutron and gamma\nradiation from the standard operational settings.",
    "explanation":"The field emission is one of the most detrimental problems in superconducting radio-frequency linear accelerators (linacs). The research aims to utilize machine learning with uncertainty quantification to predict radiation levels at multiple locations throughout the linacs.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Field Emission in Superconducting Accelerators: Instrumented Measurements for Its Understanding and Mitigation"
    ],
    "b_abstract":[
      "Several new accelerator projects are adopting superconducting RF (SRF) technology. When accelerating SRF cavities maintain high RF gradients, field emission, the emission of electrons from cavity walls, can occur and may impact operational cavity gradient, radiological environment via activated components, and reliability. In this talk, we will discuss instrumented measurements of field emission from the two 1.1 GeV superconducting continuous wave (CW) linacs in CEBAF. The goal is to improve the understanding of field emission sources originating from cryomodule production, installation and operation. Such basic knowledge is needed in guiding field emission control, mitigation, and reduction toward high gradient and reliable operation of superconducting accelerators."
    ],
    "b_categories":[
      "physics.acc-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "Accelerating cavity fault prediction using deep learning at Jefferson laboratory"
    ],
    "c_abstract":[
      "Abstract Accelerating cavities are an integral part of the continuous electron beam accelerator facility (CEBAF) at Jefferson Laboratory. When any over 400 in CEBAF experiences a fault, it disrupts delivery to experimental user halls. In this study, we propose use deep learning model predict slowly developing cavity faults. By utilizing pre-fault signals, train long short-term memory-convolutional neural network binary classifier distinguish between radio-frequency (RF) signals during normal operation and RF indicative impending We optimize by adjusting fault confidence threshold implementing multiple consecutive window criterion identify events, ensuring low false positive rate. Results obtained from analysis real dataset collected accelerating simulating deployed scenario demonstrate model\u2019s ability with 99.99% accuracy correctly 80% Notably, these achievements were achieved context highly imbalanced dataset, predictions made several hundred milliseconds before onset fault. Anticipating faults enables preemptive measures improve operational efficiency preventing or mitigating their occurrence."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19844",
    "a_title":"Musical composition and 2D cellular automata based on music intervals",
    "a_abstract":"This study is a theoretical approach for exploring the applicability of a 2D\ncellular automaton based on melodic and harmonic intervals in random arrays of\nmusical notes. The aim of this study was to explore alternatives uses for a\ncellular automaton in the musical context for better understanding the musical\ncreativity. We used the complex systems and humanities approaches as a\nframework for capturing the essence of creating music based on rules of music\ntheory. Findings suggested that such rules matter for generating large-scale\npatterns of organized notes. Therefore, our formulation provides a novel\napproach for understanding and replicating aspects of the musical creativity.",
    "explanation":"The study is a theorical approach for exploring thge applicability of a D cellular automaton based on moelodic and harmonic intervals in random arrays of musical notes.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "A New Kind of Science"
    ],
    "b_abstract":[
      "3R3. A New Kind of Science. - S Wolfram (Wolfram Res Inc, 100 Trade Center Dr, Champaign IL 61820-7237). Media, Champaign, IL. 2002. 1197 pp. ISBN 1-57955-008-8. $44.95. Reviewed by M Gad-el-Hak (Eng Build, Rm 303, Virginia Commonwealth Univ, 601 W Main St, PO Box 843015, Richmond, VA 23284-3015). Reviewing Science is like stepping in a minefield. The danger lies going against the deluge praise, proving relevance to this audience, and arguing proposed new science that allegedly set replace science, as we know it. Those issues will be addressed turn, but first brief background. Stephen considered many have been child prodigy: journal paper particle physics at age 15; stint Oxford; PhD from Caltech 20; youngest recipient MacArthur Prize; faculty positions Caltech, Princeton, Illinois; significant contributions cellular automata complexity theory; developer popular software Mathematica; successful entrepreneur, becoming multi-millionaire 30. Running his company via e-mail videoconference, spent last 10 years virtual seclusion, relentlessly, tirelessly, secretly, nocturnally working on an idea possessed him: generating simple computations, algorithms only few lines. book, targeting both scientists non-scientists, partially about using rules generate complex patterns. In task, author has succeeded beyond reproach not showing can done brilliantly beautifully, also explaining it lucidly enough for all understand, appreciate, savor. opinion several reviewers, including one, aspect book tour de force clarity, elegance, simplicity. problem huge leap takes since nature computer-generated patterns look or behave similarly natural man-made things around us\u2014a snow flake, turbulent flow, lung, mollusk shell, traffic jam, outbreak starfish coral reef, entire universe\u2014therefore must way works. Nature runs its course same computer program. That essence science: yield secrets universe, solve our long-standing problems, provide theory everything. More flight fancy later. Deluge: was widely anticipated before actual publication. Published May 14, 2002, quickly became Amazon.com bestseller promptly reviewed scientific press. Heavyweights former included York Times, Chicago Tribune, Newsweek, Time, Daily Telegraph, Le Monde, Frankfurter Allgemeine Zeitung, Economist. Except last, press went gaga over touting author's claim stand existing head. Economist (p 79, June 1, 2002) more subdued even provocatively titling review \"The Emperor's Theory.\" press, reviews were somewhat less glorious skeptical. Physics Today 55, July 2002), Leo Kadanoff's once pointed, subtle polite, concluding he cannot support view any \"new kind science\" displayed Wolfram's book. Newsweek 59, 27, quoted famed physicist Freeman Dyson: \"There's tradition approaching senility come up with grand, improbable theories. unusual he's doing 40s.\" Kadanoff Dyson express minority opinion, however, majority reviewers being excited reason every human mystery currently depressed stock market, free will, quantum field theory, entropy. For present reviewer, lurks high particularly so months behind who already anointed Isaac Newton 21st century. Relevance: As aims replacing readers Applied Mechanics Reviews stake matter. Mechanics\u2014classical most part occasionally quantum\u2014is underlying branch upon which almost applied mechanics based. mathematics here often form partial differential equations, where space time are indefinitely divisible continuum. example, most, all, fluid flows described well-known, well-posed Navier\u2013Stokes equations. those first-principles equations solved agreement experiment reproach. It problem, such frustrated scores him. search simpler alternative is, therefore, quite alluring. mechanics, when they solved, powerful predictive tool explain mechanical world us well help design machines. When analytical solutions unattainable, discretized brute numerical integration used. But possible some situations, example realistic high-Reynolds-number other multi-scale problems required computational memory speed overwhelm today's supercomputers. impenetrable certain degree empiricism introduced relatively faster computations then proceed. Heuristic turbulence modeling compromise. Despite limitations, traditional works exceedingly well, mechanicians happily practice their craft. Readers should, care passionately if laws supplanted science. Argument: Cellular late 1940s John von Neumann Stanislaw Ulam, although claims independently discovered three decades discrete dynamical systems whose behavior completely specified terms repetitive local relation. continuum represented uniform one-, two-, three-dimensional grid, each cell containing single bit data, 0 red, white, blue, etc, bits states. advances steps. state cell, location, computed step algorithm priori defined close neighbors. Simple programs could, fact, result researched one-dimensional arranged line. data updated based value two nearest cells. methodically studied identified total 256 different rules. Space\u2013time diagrams generated show four distinct patterns: dull uniformity; periodic time-dependence; fractal behavior; truly non-repetitive says broken than 300 fix \"errors\" Darwin, Newton, great ones corrected all. proposes radical notion development world, uncover fundamental universe. pattern-generating capabilities supplant difficult-to-solve yet-to-be-found just because resemble does mean work way. Furthermore, believed represent reality used make predictions agree observations. This Galileo's paradigm underpinning modern explanatory power authority stem ability verifiable predictions; otherwise mere post-hoc speculation. exactly what is. games speculation possibly compete horsepower F=ma E=mc2.Wolfram's boasting, throughout 1200 pages, minimum excessive. He writes, \"I vastly I ever thought possible, fact now touches area besides.\" writes ideas originating him, credits belong elsewhere. Alan Turing conceptualized simplest universal computer, machine. Thinking universe vast digital brainchild Edward Fredkin. use machine environment physical detailed Tommaso Toffoli Norman Margolus. Other Per Bak, Charles Bennett, Hans Meinhardt percolate properly credited. Writing person, relegating notes 350 pages grudgingly dismissively mentioning names, restricting list references own publications, dispel important shortcoming. took approach bypassing peer process. self-published acting author, editor, publisher. opening paragraph mostly favorable Time's (May 20, worth reflecting on: \"Cranks occupational hazard scientist eventually faces. Fortunately, these characters usually easy spot. If someone grand overturns centuries knowledge\u2014especially spans unrelated fields biology economics\u2014the odds good she crank. publishes standard journals general readers, watch out. And issued rather conventional publisher, case pretty much airtight.\" extravagant cold fusion\u2014a` la Stanley Pons Martin Fleischman\u2014and deserve proportionally vigilant scrutiny. validated nor subjected process rest mortals expected do. contrast old anti-Newtonian model predict anything. emperor no clothes. offense play brick build edifice call Bottom Line: fun reading pictures, bad recommendation. inspiration, read Newton's Principia Mathematica, Latin. solving Newtonian framework still best bet, one's better books mechanics."
    ],
    "b_categories":[
      "cs.FL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "The structure of musical harmony as an ordered phase of sound: A statistical mechanics approach to music theory"
    ],
    "c_abstract":[
      "Music, while allowing nearly unlimited creative expression, almost always conforms to a set of rigid rules at fundamental level. The description and study these rules, the ordered structures that arise from them, is basis field music theory. Here, I present theoretical formalism aims explain why basic patterns emerge in music, using same statistical mechanics framework describes emergent order across phase transitions physical systems. first apply mean approximation demonstrate occur this model disordered sound discrete sets pitches, including 12-fold octave division used Western music. Beyond model, use numerical simulation uncover musical harmony. These results provide new lens through which view discover ideas explore."
    ],
    "c_categories":[
      "cs.NA"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06414",
    "a_title":"Psycho Gundam: Electroencephalography based real-time robotic control\n  system with deep learning",
    "a_abstract":"The Psycho Frame, a sophisticated system primarily used in Universal Century\n(U.C.) series mobile suits for NEWTYPE pilots, has evolved as an integral\ncomponent in harnessing the latent potential of mental energy. Its ability to\namplify and resonate with the pilot's psyche enables real-time mental control,\ncreating unique applications such as psychomagnetic fields and sensory-based\nweaponry. This paper presents the development of a novel robotic control system\ninspired by the Psycho Frame, combining electroencephalography (EEG) and deep\nlearning for real-time control of robotic systems. By capturing and\ninterpreting brainwave data through EEG, the system extends human cognitive\ncommands to robotic actions, reflecting the seamless synchronization of thought\nand machine, much like the Psyco Frame's integration with a Newtype pilot's\nmental faculties. This research demonstrates how modern AI techniques can\nexpand the limits of human-machine interaction, potentially transcending\ntraditional input methods and enabling a deeper, more intuitive control of\ncomplex robotic systems.",
    "explanation":"This paper presents the development of a novel robotic control system inspired by the Psycho Frame, combining electroencephalograhy and deep learning for real-time control of robotic systems.",
    "b_id":[
      "b1",
      "b9"
    ],
    "b_title":[
      "An EEG-based brain-computer interface for real-time multi-task robotic control",
      "QEEGNet: Quantum Machine Learning for Enhanced Electroencephalography\n  Encoding"
    ],
    "b_abstract":[
      "The Brain Computer Interface (BCI) is the communication between human brain and computer. Electroencephalogram (EEG) one of biomedical signals which can be obtained by attaching electrodes to scalp. Some EEG related applications developed help disabled people, such as based wheelchair or robotic arm. A hybrid BCI real-time control system proposed a multi-tasks robot. In this system, sliding window online data segmentation strategy segment training data, enable learn dynamic features when subject's state transfer from rest task execution state. achieve ensure continuity executing actions. addition, Common Spatial Pattern (CSP) better extract spatial these continuous actions that multiple commands are accurately classified. experiment, three subjects' collected, trained tested performance reliability system. records robot's spending time, moving distance, number objects pushing down. Experimental results given show feasibility Compared remote controller, similar performance. Thus, able robot in environment used develop robot-aided arm methods on neurological rehabilitation principles for stroke injury patients.",
      "Electroencephalography (EEG) is a critical tool in neuroscience and clinical practice for monitoring analyzing brain activity. Traditional neural network models, such as EEGNet, have achieved considerable success decoding EEG signals but often struggle with the complexity high dimensionality of data. Recent advances quantum computing present new opportunities to enhance machine learning models through (QML) techniques. In this paper, we introduce Quantum-EEGNet (QEEGNet), novel hybrid that integrates classical EEGNet architecture improve encoding analysis, forward-looking approach, acknowledging results might not always surpass traditional methods it shows its potential. QEEGNet incorporates layers within network, allowing capture more intricate patterns data potentially offering computational advantages. We evaluate on benchmark dataset, BCI Competition IV 2a, demonstrating consistently outperforms most subjects other robustness noise. Our highlight significant potential quantum-enhanced networks suggesting directions both research practical applications field."
    ],
    "b_categories":[
      "cs.RO",
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Braincomputer interfaces for communication and control"
    ],
    "c_abstract":[
      "For many years people have speculated that electroencephalographic activity or other electrophysiological measures of brain function might provide a new non-muscular channel for sending messages and commands to the external world \u2013 a brain\u2013computer interface (BCI). Over the past 15 years, productive BCI research programs have arisen. Encouraged by new understanding of brain function, by the advent of powerful low-cost computer equipment, and by growing recognition of the needs and potentials of people with disabilities, these programs concentrate on developing new augmentative communication and control technology for those with severe neuromuscular disorders, such as amyotrophic lateral sclerosis, brainstem stroke, and spinal cord injury. The immediate goal is to provide these users, who may be completely paralyzed, or \u2018locked in\u2019, with basic communication capabilities so that they can express their wishes to caregivers or even operate word processing programs or neuroprostheses. Present-day BCIs determine the intent of the user from a variety of different electrophysiological signals. These signals include slow cortical potentials, P300 potentials, and mu or beta rhythms recorded from the scalp, and cortical neuronal activity recorded by implanted electrodes. They are translated in real-time into commands that operate a computer display or other device. Successful operation requires that the user encode commands in these signals and that the BCI derive the commands from the signals. Thus, the user and the BCI system need to adapt to each other both initially and continually so as to ensure stable performance. Current BCIs have maximum information transfer rates up to 10\u201325 bits\/min. This limited capacity can be valuable for people whose severe disabilities prevent them from using conventional augmentative communication methods. At the same time, many possible applications of BCI technology, such as neuroprosthesis control, may require higher information transfer rates. Future progress will depend on: recognition that BCI research and development is an interdisciplinary problem, involving neurobiology, psychology, engineering, mathematics, and computer science; identification of those signals, whether evoked potentials, spontaneous rhythms, or neuronal firing rates, that users are best able to control independent of activity in conventional motor output pathways; development of training methods for helping users to gain and maintain that control; delineation of the best algorithms for translating these signals into device commands; attention to the identification and elimination of artifacts such as electromyographic and electro-oculographic activity; adoption of precise and objective procedures for evaluating BCI performance; recognition of the need for long-term as well as short-term assessment of BCI performance; identification of appropriate BCI applications and appropriate matching of applications and users; and attention to factors that affect user acceptance of augmentative technology, including ease of use, cosmesis, and provision of those communication and control capacities that are most important to the user. Development of BCI technology will also benefit from greater emphasis on peer-reviewed research publications and avoidance of the hyperbolic and often misleading media attention that tends to generate unrealistic expectations in the public and skepticism in other researchers. With adequate recognition and effective engagement of all these issues, BCI systems could eventually provide an important new communication and control option for those with motor disabilities and might also give those without disabilities a supplementary control channel or a control channel useful in special circumstances."
    ],
    "c_categories":[
      "Neurophysiology"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.07453",
    "a_title":"Research on fault diagnosis of nuclear power first-second circuit based\n  on hierarchical multi-granularity classification network",
    "a_abstract":"The safe and reliable operation of complex electromechanical systems in\nnuclear power plants is crucial for the safe production of nuclear power plants\nand their nuclear power unit. Therefore, accurate and timely fault diagnosis of\nnuclear power systems is of great significance for ensuring the safe and\nreliable operation of nuclear power plants. The existing fault diagnosis\nmethods mainly target a single device or subsystem, making it difficult to\nanalyze the inherent connections and mutual effects between different types of\nfaults at the entire unit level. This article uses the AP1000 full-scale\nsimulator to simulate the important mechanical component failures of some key\nsystems in the primary and secondary circuits of nuclear power units, and\nconstructs a fault dataset. Meanwhile, a hierarchical multi granularity\nclassification fault diagnosis model based on the EfficientNet large model is\nproposed, aiming to achieve hierarchical classification of nuclear power\nfaults. The results indicate that the proposed fault diagnosis model can\neffectively classify faults in different circuits and system components of\nnuclear power units into hierarchical categories. However, the fault dataset in\nthis study was obtained from a simulator, which may introduce additional\ninformation due to parameter redundancy, thereby affecting the diagnostic\nperformance of the model.",
    "explanation":"The existing fault diagnosis methods of power plants mainly target a single device or subsystem, making it difficult to analyze the inherent connections and mutual effects between different types of faults at the entire unit level. The use of EfficientNet for classify faults in different circuits through a simulator.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Review of Research on Condition Assessment of Nuclear Power Plant Equipment Based on Data-Driven"
    ],
    "b_abstract":[
      "The condition assessment of the entire life cycle of nuclear power equipment has a significant impact on improving the safety and economy of nuclear power plants. In the past, operation and maintenance of systems, equipment, and structures of domestic nuclear power plants, mostly relied on the alarm mechanism of equipments, the simple threshold judgments of parameters, or the empirical judgments of engineers. With the implementation of online monitoring system in nuclear power plants, a large number of equipment operation data have been accumulated, and the use of data-driven technology to assess the health of equipment has become the focus of attention in the industry. In this paper, the current situation of the online monitoring system of nuclear power equipment was introduced and the common malfunction of nuclear power equipment was analyzed. The condition assessment of nuclear power equipment were categorized into three major problems (i.e., anomaly detection, life prediction, and fault diagnosis), the situation of research and application were summarized respectively, and the application potential of deep learning technology in this field was emphasized. Based on this, the challenges and possible solutions to the condition assessment of nuclear power plant equipment were further analyzed."
    ],
    "b_categories":[
      "nucl-th"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"
    ],
    "c_abstract":[
      "Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth\/width\/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. \nTo go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 \/ 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at this https URL."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04775",
    "a_title":"Learning dynamical systems from data: Gradient-based dictionary\n  optimization",
    "a_abstract":"The Koopman operator plays a crucial role in analyzing the global behavior of\ndynamical systems. Existing data-driven methods for approximating the Koopman\noperator or discovering the governing equations of the underlying system\ntypically require a fixed set of basis functions, also called dictionary. The\noptimal choice of basis functions is highly problem-dependent and often\nrequires domain knowledge. We present a novel gradient descent-based\noptimization framework for learning suitable and interpretable basis functions\nfrom data and show how it can be used in combination with EDMD, SINDy, and\nPDE-FIND. We illustrate the efficacy of the proposed approach with the aid of\nvarious benchmark problems such as the Ornstein-Uhlenbeck process, Chua's\ncircuit, a nonlinear heat equation, as well as protein-folding data.",
    "explanation":"The optimal choice of basis functions for approximation the Koopman operator is highly problem-dependent and often requires domain knowledge. The paper presents a gradient descent-based optimization framework for learning suitable and interpretable basis function from data.",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "A Data\u2013Driven Approximation of the Koopman Operator: Extending Dynamic Mode Decomposition"
    ],
    "b_abstract":[
      "The Koopman operator is a linear but infinite dimensional operator that\ngoverns the evolution of scalar observables defined on the state space of an\nautonomous dynamical system, and is a powerful tool for the analysis and\ndecomposition of nonlinear dynamical systems. In this manuscript, we present a\ndata driven method for approximating the leading eigenvalues, eigenfunctions,\nand modes of the Koopman operator. The method requires a data set of snapshot\npairs and a dictionary of scalar observables, but does not require explicit\ngoverning equations or interaction with a \"black box\" integrator. We will show\nthat this approach is, in effect, an extension of Dynamic Mode Decomposition\n(DMD), which has been used to approximate the Koopman eigenvalues and modes.\nFurthermore, if the data provided to the method are generated by a Markov\nprocess instead of a deterministic dynamical system, the algorithm approximates\nthe eigenfunctions of the Kolmogorov backward equation, which could be\nconsidered as the \"stochastic Koopman operator\" [1]. Finally, four illustrative\nexamples are presented: two that highlight the quantitative performance of the\nmethod when presented with either deterministic or stochastic data, and two\nthat show potential applications of the Koopman eigenfunctions."
    ],
    "b_categories":[
      "Mathematical Analysis"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b21",
      "b14"
    ],
    "c_title":[
      "Towards Scalable Koopman Operator Learning: Convergence Rates and A Distributed Learning Algorithm",
      "VAMPnets for deep learning of molecular kinetics"
    ],
    "c_abstract":[
      "We propose an alternating optimization algorithm to the nonconvex Koopman operator learning problem for nonlinear dynamic systems. show that proposed will converge a critical point with rate O(1\/T) and $O\\left( {\\frac{1}{{\\log T}}} \\right)$ constant diminishing rates, respectively, under some mild conditions. To cope high dimensional dynamical systems, we present first-ever distributed algorithm. has same convergence properties as centralized learning, in absence of optimal tracker, so long basis functions satisfy set state-based decomposition Numerical experiments are provided complement our theoretical results.",
      "Abstract There is an increasing demand for computing the relevant structures, equilibria, and long-timescale kinetics of biomolecular processes, such as protein-drug binding, from high-throughput molecular dynamics simulations. Current methods employ transformation simulated coordinates into structural features, dimension reduction, clustering dimension-reduced data, estimation a Markov state model or related interconversion rates between structures. This handcrafted approach demands substantial amount modeling expertise, poor decisions at any step will lead to large errors. Here we variational processes (VAMP) develop deep learning framework using neural networks, dubbed VAMPnets. A VAMPnet encodes entire mapping states, thus combining whole data processing pipeline in single end-to-end framework. Our method performs equally better than state-of-the-art provides easily interpretable few-state kinetic models."
    ],
    "c_categories":[
      "cs.LG",
      "eess.SP"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17971",
    "a_title":"Graph Neural Network for Cerebral Blood Flow Prediction With Clinical\n  Datasets",
    "a_abstract":"Accurate prediction of cerebral blood flow is essential for the diagnosis and\ntreatment of cerebrovascular diseases. Traditional computational methods,\nhowever, often incur significant computational costs, limiting their\npracticality in real-time clinical applications. This paper proposes a graph\nneural network (GNN) to predict blood flow and pressure in previously unseen\ncerebral vascular network structures that were not included in training data.\nThe GNN was developed using clinical datasets from patients with stenosis,\nfeaturing complex and abnormal vascular geometries. Additionally, the GNN model\nwas trained on data incorporating a wide range of inflow conditions, vessel\ntopologies, and network connectivities to enhance its generalization\ncapability. The approach achieved Pearson's correlation coefficients of 0.727\nfor pressure and 0.824 for flow rate, with sufficient training data. These\nfindings demonstrate the potential of the GNN for real-time cerebrovascular\ndiagnostics, particularly in handling intricate and pathological vascular\nnetworks.",
    "explanation":"This paper proposes a graph neural network (GNN) to predict blood flow and pressure in previously unseen cerebral vascular network structures that were not included in training data.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Multiscale modeling and simulation of brain blood flow"
    ],
    "b_abstract":[
      "The aim of this work is to present an overview recent advances in multi-scale modeling brain blood flow. In particular, we some approaches that enable the silico study and multi-physics phenomena cerebral vasculature. We discuss formulation continuum atomistic approaches, a consistent framework for their concurrent coupling, list challenges one needs overcome achieving seamless scalable integration heterogeneous numerical solvers. effectiveness proposed demonstrated realistic case involving thrombus formation process taking place on wall patient-specific aneurysm. This highlights ability algorithms resolve important biophysical processes span several spatial temporal scales, potentially yielding new insight into key aspects flow health disease. Finally, open questions emerging topics future research."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Learning Reduced-Order Models for Cardiovascular Simulations with Graph Neural Networks"
    ],
    "c_abstract":[
      "Reduced-order models based on physics are a popular choice in cardiovascular modeling due to their efficiency, but they may experience loss in accuracy when working with anatomies that contain numerous junctions or pathological conditions. We develop one-dimensional reduced-order models that simulate blood flow dynamics using a graph neural network trained on three-dimensional hemodynamic simulation data. Given the initial condition of the system, the network iteratively predicts the pressure and flow rate at the vessel centerline nodes. Our numerical results demonstrate the accuracy and generalizability of our method in physiological geometries comprising a variety of anatomies and boundary conditions. Our findings demonstrate that our approach can achieve errors below 3% for pressure and flow rate, provided there is adequate training data. As a result, our method exhibits superior performance compared to physics-based one-dimensional models while maintaining high efficiency at inference time."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18141",
    "a_title":"Predicting Water Quality using Quantum Machine Learning: The Case of the\n  Umgeni Catchment (U20A) Study Region",
    "a_abstract":"In this study, we consider a real-world application of QML techniques to\nstudy water quality in the U20A region in Durban, South Africa. Specifically,\nwe applied the quantum support vector classifier (QSVC) and quantum neural\nnetwork (QNN), and we showed that the QSVC is easier to implement and yields a\nhigher accuracy. The QSVC models were applied for three kernels: Linear,\npolynomial, and radial basis function (RBF), and it was shown that the\npolynomial and RBF kernels had exactly the same performance. The QNN model was\napplied using different optimizers, learning rates, noise on the circuit\ncomponents, and weight initializations were considered, but the QNN\npersistently ran into the dead neuron problem. Thus, the QNN was compared only\nby accraucy and loss, and it was shown that with the Adam optimizer, the model\nhas the best performance, however, still less than the QSVC.",
    "explanation":"In this study, we consider a real-world application of QML techniques to study water quality in the U20A region in Durban, South Africa.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "Quantum machine learning in chemistry and materials"
    ],
    "b_abstract":[
      "Within the past few years, we have witnessed the rising of quantum machine learning (QML) models which infer electronic properties of molecules and materials, rather than solving approximations to the electronic Schr\u00f6dinger equation. The increasing availability of large quantum mechanics reference datasets has enabled these developments. We review the basic theories and key ingredients of popular QML models such as choice of regressor, data of varying trustworthiness, the role of the representation, and the effect of training set selection. Throughout we emphasize the indispensable role of learning curves when it comes to the comparative assessment of different QML models."
    ],
    "b_categories":[
      "cs.ET"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b26"
    ],
    "c_title":[
      "Durban's water wars, sewage spills, fish kills and blue flag beaches. Durban's Climate Gamble"
    ],
    "c_abstract":[
      "Water is one of the primary barometers of climate change: A rise in sea-levels, flooding, and extreme storms combined with general water stress and more severe and frequent droughts will escalate crises in municipal infrastructure, requiring continual upgrades for water purification, stormwater drainage, and sewage treatment, all of which will dramatically raise the price of water at the retail level. In South Africa, the dry western side will be most adversely affected by droughts (threatening the production of rooibos tea and Cape wines). According to the Academy of Science in South Africa (ASSAf), Durban is also at great risk and will experience higher temperatures and heat stress, volatile rainfall, up to 160 million cubic metres less water each year by 2100, a sea-level rise of up to a metre by 2100 across Durban\u2019s 100 km of developed coastline, lower biodiversity, higher disease levels (especially malaria and cholera), declining agricultural output (a one degree Celsius rise leaves the surrounding region unreliable for the staple maize production), and other economic stresses (ASSAf 2011: 27). Tourism, one of Durban\u2019s main economic engines, will be irreparably harmed. Swimmers and surfers think of Durban\u2019s beachfront as one of the world\u2019s finest in any urban context. After apartheid-era rules that prohibited black people from using the best beaches were lifted at the end of the 1980s, the area stretching from the Blue Lagoon\u2019s Umgeni River to South Beach\u2019s uShaka Marine World\u2013including the immensely popular North Beach area near the main restaurant strip\u2013represented one of South Africa\u2019s most impressive, open and democratic public spaces."
    ],
    "c_categories":[
      "cond-mat.mtrl-sci"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.16349",
    "a_title":"Machine learning for cerebral blood vessels' malformations",
    "a_abstract":"Cerebral aneurysms and arteriovenous malformations are life-threatening\nhemodynamic pathologies of the brain. While surgical intervention is often\nessential to prevent fatal outcomes, it carries significant risks both during\nthe procedure and in the postoperative period, making the management of these\nconditions highly challenging. Parameters of cerebral blood flow, routinely\nmonitored during medical interventions, could potentially be utilized in\nmachine learning-assisted protocols for risk assessment and therapeutic\nprognosis. To this end, we developed a linear oscillatory model of blood\nvelocity and pressure for clinical data acquired from neurosurgical operations.\nUsing the method of Sparse Identification of Nonlinear Dynamics (SINDy), the\nparameters of our model can be reconstructed online within milliseconds from a\nshort time series of the hemodynamic variables. The identified parameter values\nenable automated classification of the blood-flow pathologies by means of\nlogistic regression, achieving an accuracy of 73 %. Our results demonstrate the\npotential of this model for both diagnostic and prognostic applications,\nproviding a robust and interpretable framework for assessing cerebral blood\nvessel conditions.",
    "explanation":"Parameters of cerebral blood flow, routinely monitored during medical interventions or with modern noninvasive high-resolution imaging methods, could potentially be utilized in machine learning-assisted protocols for risk assessment and therapeutic prognosis.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Cerebral aneurysms. New Engl. J. Medicine"
    ],
    "b_abstract":[
      "Saccular intracranial aneurysms cause substantial morbidity and mortality. Recently, major changes have occurred in the way we think about and treat this disease. This review discusses the percutaneous endovascular treatment of intracranial aneurysms as compared with surgical intervention. The technological advances and supporting research contributing to this important change in practice patterns are reviewed."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "Data-driven science and engineering: machine learning, dynamical systems, and control"
    ],
    "c_abstract":[
      "\"Data-driven science and engineering: machine learning, dynamical systems, control.\" Contemporary Physics, 60(4), p. 320"
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19000",
    "a_title":"A Unified Platform for At-Home Post-Stroke Rehabilitation Enabled by\n  Wearable Technologies and Artificial Intelligence",
    "a_abstract":"At-home rehabilitation for post-stroke patients presents significant\nchallenges, as continuous, personalized care is often limited outside clinical\nsettings. Additionally, the absence of comprehensive solutions addressing\ndiverse rehabilitation needs in home environments complicates recovery efforts.\nHere, we introduce a smart home platform that integrates wearable sensors,\nambient monitoring, and large language model (LLM)-powered assistance to\nprovide seamless health monitoring and intelligent support. The system\nleverages machine learning enabled plantar pressure arrays for motor recovery\nassessment (94% classification accuracy), a wearable eye-tracking module for\ncognitive evaluation, and ambient sensors for precise smart home control (100%\noperational success, <1 s latency). Additionally, the LLM-powered agent,\nAuto-Care, offers real-time interventions, such as health reminders and\nenvironmental adjustments, enhancing user satisfaction by 29%. This work\nestablishes a fully integrated platform for long-term, personalized\nrehabilitation, offering new possibilities for managing chronic conditions and\nsupporting aging populations.",
    "explanation":"Here, we present a multimodal smart home platform designed for continuous, at-home rehabilitation of post-stroke patients, integrating wearable sensing, ambient monitoring, and adaptive automation.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Addressing disparities in the global epidemiology of stroke"
    ],
    "b_abstract":[
      "Stroke is the second leading cause of death and the third leading cause of disability worldwide. Though the burden of stroke worldwide seems to have declined in the past three decades, much of this effect reflects decreases in high-income countries (HICs). By contrast, the burden of stroke has grown rapidly in low-income and middle-income countries (LMICs), where epidemiological, socioeconomic and demographic shifts have increased the incidence of stroke and other non-communicable diseases. Furthermore, even in HICs, disparities in stroke epidemiology exist along racial, ethnic, socioeconomic and geographical lines. In this Review, we highlight the under-acknowledged disparities in the burden of stroke. We emphasize the shifting global landscape of stroke risk factors, critical gaps in stroke service delivery, and the need for a more granular analysis of the burden of stroke within and between LMICs and HICs to guide context-appropriate capacity-building. Finally, we review strategies for addressing key inequalities in stroke epidemiology, including improvements in epidemiological surveillance and context-specific research efforts in under-resourced regions, development of the global workforce of stroke care providers, expansion of access to preventive and treatment services through mobile and telehealth platforms, and scaling up of evidence-based strategies and policies that target local, national, regional and global stroke disparities."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "Artificial intelligence applications in stroke"
    ],
    "c_abstract":[
      "Management of stroke highly depends on information from imaging studies. Noncontrast computed tomography (CT) and magnetic resonance imaging (MRI) can both be used to distinguish between ischemic and hemorrhagic stroke, which is difficult based on clinical features. Hypodensity on CT and DWI hyperintensity on MRI identifies irreversibly damaged tissue, although the sensitivity of MRI is higher in the acute setting. Angiographic and perfusion imaging sequences can identify a large vessel occlusion and, along with perfusion imaging, can select patients for endovascular therapy. The FLAIR-DWI mismatch yields information about patients with unknown time of onset (including wake-up strokes). Stroke imaging also gives insight into prognosis, with current methods aiming to give a picture of the short-term consequences of successful reperfusion or continued large vessel occlusion. One important caveat about stroke imaging is that it must be done quickly, as faster treatment leads to better outcomes.1 However, most steps in the stroke imaging triage pathway require the presence of human radiologists and neurologists, and this is often the time-limiting step. The expertise required for these tasks may not be available at all sites or at all times. Therefore, there is interest in automated methods for stroke imaging evaluation. Artificial intelligence (AI) is a broad term reflecting the use of computers to perform tasks that humans may find difficult, often in ways that are hard to pinpoint. For example, although humans find high-level computation difficult, calculator technology is not considered AI because we know how to break this down into discrete steps and feel we understand it. However, facial recognition is a task that humans perform well, but an algorithm to identify faces is usually considered AI since we cannot articulate precisely how this is done. Machine learning (ML) is a subset of AI in which algorithms learn from the data itself without explicit programming. ML methods reflect a broad range of statistical techniques ranging from linear regression to more complex methods such as support vector machines and decision trees. ML methods can be further broken into supervised and unsupervised learning, which differ from one another in that the former requires access to gold standard labels although the latter attempts to find the answers implicitly in the data itself. While ML methods have grown more popular over recent years, the advent of a specific supervised ML method based on architectures resembling human neural networks over the past decade has led to a quantum leap in performance.2 This method, called deep learning (DL) because of many multiple internal layers, can be considered a transformative technology. Compared with previous methods that required humans to identify image features, a deep neural network trained on a dataset with known outputs can learn the best features for organizing the data. In this review, we will discuss ML methods applied to stroke imaging with an emphasis on DL applications. We refer to Figure for a graphical overview of the applications discussed in this review."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.10570",
    "a_title":"Normative Modeling for AD Diagnosis and Biomarker Identification",
    "a_abstract":"In this paper, we introduce a novel normative modeling approach that\nincorporates focal loss and adversarial autoencoders (FAAE) for Alzheimer's\nDisease (AD) diagnosis and biomarker identification. Our method is an\nend-to-end approach that embeds an adversarial focal loss discriminator within\nthe autoencoder structure, specifically designed to effectively target and\ncapture more complex and challenging cases. We first use the enhanced\nautoencoder to create a normative model based on data from healthy control (HC)\nindividuals. We then apply this model to estimate total and regional\nneuroanatomical deviation in AD patients. Through extensive experiments on the\nOASIS-3 and ADNI datasets, our approach significantly outperforms previous\nstate-of-the-art methods. This advancement not only streamlines the detection\nprocess but also provides a greater insight into the biomarker potential for\nAD. Our code can be found at \\url{https:\/\/github.com\/soz223\/FAAE}.",
    "explanation":"In this paper, we introduce a novel normative modeling ap proach that incorporates focal loss and adversarial autoencoders (FAAE) for Alzheimer\u2019s Disease (AD) diagnosis and biomarker identification",
    "b_id":[
      "b13"
    ],
    "b_title":[
      "Using deep autoencoders to identify abnormal brain structural patterns in neuropsychiatric disorders: A large\u2010scale multi\u2010sample study"
    ],
    "b_abstract":[
      "Machine learning is becoming an increasingly popular approach for investigating spatially distributed and subtle neuroanatomical alterations in brain\u2010based disorders. However, some machine learning models have been criticized for requiring a large number of cases in each experimental group, and for resembling a \u201cblack box\u201d that provides little or no insight into the nature of the data. In this article, we propose an alternative conceptual and practical approach for investigating brain\u2010based disorders which aim to overcome these limitations. We used an artificial neural network known as \u201cdeep autoencoder\u201d to create a normative model using structural magnetic resonance imaging data from 1,113 healthy people. We then used this model to estimate total and regional neuroanatomical deviation in individual patients with schizophrenia and autism spectrum disorder using two independent data sets (n =\u2009263). We report that the model was able to generate different values of total neuroanatomical deviation for each disease under investigation relative to their control group (p <\u2009.005). Furthermore, the model revealed distinct patterns of neuroanatomical deviations for the two diseases, consistent with the existing neuroimaging literature. We conclude that the deep autoencoder provides a flexible and promising framework for assessing total and regional neuroanatomical deviations in neuropsychiatric populations."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "Using normative modelling to detect disease progression in mild cognitive impairment and Alzheimer\u2019s disease in a cross-sectional multi-cohort study"
    ],
    "c_abstract":[
      "Normative modelling is an emerging method for quantifying how individuals deviate from the healthy populational pattern. Several machine learning models have been implemented to develop normative models to investigate brain disorders, including regression, support vector machines and Gaussian process models. With the advance of deep learning technology, the use of deep neural networks has also been proposed. In this study, we assessed normative models based on deep autoencoders using structural neuroimaging data from patients with Alzheimer\u2019s disease (n\u2009=\u2009206) and mild cognitive impairment (n\u2009=\u2009354). We first trained the autoencoder on an independent dataset (UK Biobank dataset) with 11,034 healthy controls. Then, we estimated how each patient deviated from this norm and established which brain regions were associated to this deviation. Finally, we compared the performance of our normative model against traditional classifiers. As expected, we found that patients exhibited deviations according to the severity of their clinical condition. The model identified medial temporal regions, including the hippocampus, and the ventricular system as critical regions for the calculation of the deviation score. Overall, the normative model had comparable cross-cohort generalizability to traditional classifiers. To promote open science, we are making all scripts and the trained models available to the wider research community."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.14474",
    "a_title":"Attention-guided Spectrogram Sequence Modeling with CNNs for Music Genre\n  Classification",
    "a_abstract":"Music genre classification is a critical component of music recommendation\nsystems, generation algorithms, and cultural analytics. In this work, we\npresent an innovative model for classifying music genres using attention-based\ntemporal signature modeling. By processing spectrogram sequences through\nConvolutional Neural Networks (CNNs) and multi-head attention layers, our\napproach captures the most temporally significant moments within each piece,\ncrafting a unique \"signature\" for genre identification. This temporal focus not\nonly enhances classification accuracy but also reveals insights into\ngenre-specific characteristics that can be intuitively mapped to listener\nperceptions. Our findings offer potential applications in personalized music\nrecommendation systems by highlighting cross-genre similarities and\ndistinctiveness, aligning closely with human musical intuition. This work\nbridges the gap between technical classification tasks and the nuanced, human\nexperience of genre.",
    "explanation":"In this work, we present an innovative model for classifying music genres using attention based temporal signature modeling. By processing spectrogram sequences through Convolutional Neural Networks (CNNs) and multi-head attention layers, our approach captures the most temporally significant moments within each piece, crafting a unique \u201dsignature\u201d for genre identification",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Convolutional recurrent neural networks for music classification"
    ],
    "b_abstract":[
      "We introduce a convolutional recurrent neural network (CRNN) for music tagging. CRNNs take advantage of networks (CNNs) local feature extraction and temporal summarisation the extracted features. compare CRNN with three CNN structures that have been used tagging while controlling number parameters respect to their performance training time per sample. Overall, we found show strong parameter time, indicating effectiveness its hybrid structure in summarisation."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "A deep representation for invariance and music classification"
    ],
    "c_abstract":[
      "Representations in the auditory cortex might be based on mechanisms similar to visual ventral stream; modules for building invariance transformations and multiple layers compositionality selectivity. In this paper we propose use of such computational extracting invariant discriminative audio representations. Building a theory hierarchical architectures, novel, mid-level representation acoustical signals, using empirical distributions projections set templates their transformations. Under assumption that, by construction, dictionary is composed from classes, samples orbit variance-inducing signal (such as shift scale), resulting signature theoretically guaranteed unique, stable deformations. Modules projection pooling can then constitute deep networks, learning composite We present main theoretical aspects framework unsupervised representations, empirically evaluated music genre classification."
    ],
    "c_categories":[
      "physics.class-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.14975",
    "a_title":"Exploring Foundation Models Fine-Tuning for Cytology Classification",
    "a_abstract":"Cytology slides are essential tools in diagnosing and staging cancer, but\ntheir analysis is time-consuming and costly. Foundation models have shown great\npotential to assist in these tasks. In this paper, we explore how existing\nfoundation models can be applied to cytological classification. More\nparticularly, we focus on low-rank adaptation, a parameter-efficient\nfine-tuning method suited to few-shot learning. We evaluated five foundation\nmodels across four cytological classification datasets. Our results demonstrate\nthat fine-tuning the pre-trained backbones with LoRA significantly improves\nmodel performance compared to fine-tuning only the classifier head, achieving\nstate-of-the-art results on both simple and complex classification tasks while\nrequiring fewer data samples.",
    "explanation":"In this paper, we explore how existing foundation models can be applied to cytological classification",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "HiCervix: An Extensive Hierarchical Dataset and Benchmark for Cervical Cytology Classification"
    ],
    "b_abstract":[
      "Cervical cytology is a critical screening strategy for early detection of pre-cancerous and cancerous cervical lesions. The challenge lies in accurately classifying various cell types. Existing automated methods are primarily trained on databases covering narrow range coarse-grained types, which fail to provide comprehensive detailed performance analysis that represents real-world cytopathology conditions. To overcome these limitations, we introduce HiCervix, the most extensive, multi-center dataset currently available public. HiCervix includes 40,229 cells from 4,496 whole slide images, categorized into 29 annotated classes. These classes organized within three-level hierarchical tree capture fine-grained subtype information. exploit semantic correlation inherent this tree, propose HierSwin, vision transformer-based classification network. HierSwin serves as benchmark feature learning both coarse-level fine-level cancer tasks. In our experiments, demonstrated remarkable performance, achieving 92.08% accuracy 82.93% averaged across all three levels. When compared board-certified cytopathologists, achieved high (0.8293 versus 0.7359 accuracy), highlighting its potential clinical applications. This newly released dataset, along with method, poised make substantial impact advancement deep algorithms rapid greatly improve prevention patient outcomes settings."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b17"
    ],
    "c_title":[
      "LoRA: Low-Rank Adaptation of Large Language Models"
    ],
    "c_abstract":[
      "An important paradigm of natural language processing consists large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances fine-tuned each with is prohibitively expensive. We propose Low-Rank Adaptation, LoRA, freezes the pre-trained weights injects trainable rank decomposition matrices into layer Transformer architecture, greatly reducing number parameters for downstream tasks. Compared Adam, LoRA can reduce by 10,000 times GPU memory requirement 3 times. performs on-par better than fine-tuning in quality RoBERTa, DeBERTa, GPT-2, GPT-3, despite having fewer a higher training throughput, and, unlike adapters, no additional inference latency. also provide empirical investigation rank-deficiency adaptation, sheds light efficacy LoRA. release package that facilitates integration PyTorch models our implementations checkpoints GPT-2 at https:\/\/github.com\/microsoft\/LoRA."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.15331",
    "a_title":"GeoScatt-GNN: A Geometric Scattering Transform-Based Graph Neural\n  Network Model for Ames Mutagenicity Prediction",
    "a_abstract":"This paper tackles the pressing challenge of mutagenicity prediction by\nintroducing three ground-breaking approaches. First, it showcases the superior\nperformance of 2D scattering coefficients extracted from molecular images,\ncompared to traditional molecular descriptors. Second, it presents a hybrid\napproach that combines geometric graph scattering (GGS), Graph Isomorphism\nNetworks (GIN), and machine learning models, achieving strong results in\nmutagenicity prediction. Third, it introduces a novel graph neural network\narchitecture, MOLG3-SAGE, which integrates GGS node features into a fully\nconnected graph structure, delivering outstanding predictive accuracy.\nExperimental results on the ZINC dataset demonstrate significant improvements,\nemphasizing the effectiveness of blending 2D and geometric scattering\ntechniques with graph neural networks. This study illustrates the potential of\nGNNs and GGS for mutagenicity prediction, with broad implications for drug\ndiscovery and chemical safety assessment.",
    "explanation":"This study illustrates the potential of GNNs and GGS for mutagenicity prediction, with broad implications for drug discovery and chemical safety assessment",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Improvement of quantitative structure\u2013activity relationship (QSAR) tools for predicting Ames mutagenicity: outcomes of the Ames\/QSAR International Challenge Project"
    ],
    "b_abstract":[
      "The International Conference on Harmonization (ICH) M7 guideline allows the use of in silico approaches for predicting Ames mutagenicity initial assessment impurities pharmaceuticals. This is first international that addresses quantitative structure\u2013activity relationship (QSAR) models lieu actual toxicological studies human health assessment. Therefore, QSAR now require higher predictive power identifying mutagenic chemicals. To increase models, larger experimental datasets from reliable sources are required. Division Genetics and Mutagenesis, National Institute Health Sciences (DGM\/NIHS) Japan recently established a unique proprietary database containing 12140 new chemicals have not been previously used developing models. DGM\/NIHS provided this to vendors validate improve their tools. Ames\/QSAR Challenge Project was initiated 2014 with 12 testing 17 tools against these compounds three phases. We present final results. All were considerably improved by participation project. Most achieved >50% sensitivity (positive prediction among all positives) (accuracy) as high 80%, almost equivalent inter-laboratory reproducibility tests. further tools, accumulation additional test data required well re-evaluation some previous Indeed, Ames-positive or Ames-negative may incorrectly classified because methodological weakness, resulting false-positive false-negative predictions These incorrect hamper source noise development It thus essential establish large benchmark consisting only well-validated results build more accurate"
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Mutagenpred-gcnns: a graph convolutional neural network-based classification model for mutagenicity prediction with data-driven molecular fingerprints"
    ],
    "c_abstract":[
      "An important task in the early stage of drug discovery is the identification of mutagenic compounds. Mutagenicity prediction models that can interpret relationships between toxicological endpoints and compound structures are especially favorable. In this research, we used an advanced graph convolutional neural network (GCNN) architecture to identify the molecular representation and develop predictive models based on these representations. The predictive model based on features extracted by GCNNs can not only predict the mutagenicity of compounds but also identify the structure alerts in compounds. In fivefold cross-validation and external validation, the highest area under the curve was 0.8782 and 0.8382, respectively; the highest accuracy (Q) was 80.98% and 76.63%, respectively; the highest sensitivity was 83.27% and 78.92%, respectively; and the highest specificity was 78.83% and 76.32%, respectively. Additionally, our model also identified some toxicophores, such as aromatic nitro, three-membered heterocycles, quinones, and nitrogen and sulfur mustard. These results indicate that GCNNs could learn the features of mutagens effectively. In summary, we developed a mutagenicity classification model with high predictive performance and interpretability based on a data-driven molecular representation trained through GCNNs."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03341",
    "a_title":"Interpretable Embeddings for Segmentation-Free Single-Cell Analysis in\n  Multiplex Imaging",
    "a_abstract":"Multiplex Imaging (MI) enables the simultaneous visualization of multiple\nbiological markers in separate imaging channels at subcellular resolution,\nproviding valuable insights into cell-type heterogeneity and spatial\norganization. However, current computational pipelines rely on cell\nsegmentation algorithms, which require laborious fine-tuning and can introduce\ndownstream errors due to inaccurate single-cell representations. We propose a\nsegmentation-free deep learning approach that leverages grouped convolutions to\nlearn interpretable embedded features from each imaging channel, enabling\nrobust cell-type identification without manual feature selection. Validated on\nan Imaging Mass Cytometry dataset of 1.8 million cells from neuroblastoma\npatients, our method enables the accurate identification of known cell types,\nshowcasing its scalability and suitability for high-dimensional MI data.",
    "explanation":"Validated on an Imaging Mass Cytometry dataset of 1.8 million cells from neuroblastoma patients.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Highly multiplexed imaging of tumor tissues with subcellular resolution by mass cytometry"
    ],
    "b_abstract":[
      "Mass cytometry enables high-dimensional, single-cell analysis of cell type and state. In mass cytometry, rare earth metals are used as reporters on antibodies. Analysis of metal abundances using the mass cytometer allows determination of marker expression in individual cells. Mass cytometry has previously been applied only to cell suspensions. To gain spatial information, we have coupled immunohistochemical and immunocytochemical methods with high-resolution laser ablation to CyTOF mass cytometry. This approach enables the simultaneous imaging of 32 proteins and protein modifications at subcellular resolution; with the availability of additional isotopes, measurement of over 100 markers will be possible. We applied imaging mass cytometry to human breast cancer samples, allowing delineation of cell subpopulations and cell-cell interactions and highlighting tumor heterogeneity. Imaging mass cytometry complements existing imaging approaches. It will enable basic studies of tissue heterogeneity and function and support the transition of medicine toward individualized molecularly targeted diagnosis and therapies."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "A ConvNet for the 2020s"
    ],
    "c_abstract":[
      "The \"Roaring 20s\" of visual recognition began with the introduction Vision Transformers (ViTs), which quickly superseded ConvNets as state-of-the-art image classification model. A vanilla ViT, on other hand, faces difficulties when applied to general computer vision tasks such object detection and semantic segmentation. It is hierarchical (e.g., Swin Transformers) that reintroduced several ConvNet priors, making practically viable a generic backbone demonstrating remarkable performance wide variety tasks. However, effectiveness hybrid approaches still largely credited intrinsic superiority Transformers, rather than inherent inductive biases convolutions. In this work, we reexamine design spaces test limits what pure can achieve. We gradually \"modernize\" standard ResNet toward Transformer, discover key components contribute difference along way. outcome exploration family models dubbed ConvNeXt. Constructed entirely from modules, ConvNeXts compete favorably in terms accuracy scalability, achieving 87.8% ImageNet top-1 outperforming COCO ADE20K segmentation, while maintaining simplicity efficiency ConvNets."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.11399",
    "a_title":"Quantization of Climate Change Impacts on Renewable Energy Generation\n  Capacity: A Super-Resolution Recurrent Diffusion Model",
    "a_abstract":"Driven by global climate change and the ongoing energy transition, the\ncoupling between power supply capabilities and meteorological factors has\nbecome increasingly significant. Over the long term, accurately quantifying the\npower generation capacity of renewable energy under the influence of climate\nchange is essential for the development of sustainable power systems. However,\ndue to interdisciplinary differences in data requirements, climate data often\nlacks the necessary hourly resolution to capture the short-term variability and\nuncertainties of renewable energy resources. To address this limitation, a\nsuper-resolution recurrent diffusion model (SRDM) has been developed to enhance\nthe temporal resolution of climate data and model the short-term uncertainty.\nThe SRDM incorporates a pre-trained decoder and a denoising network, that\ngenerates long-term, high-resolution climate data through a recurrent coupling\nmechanism. The high-resolution climate data is then converted into power value\nusing the mechanism model, enabling the simulation of wind and photovoltaic\n(PV) power generation capacity on future long-term scales. Case studies were\nconducted in the Ejina region of Inner Mongolia, China, using fifth-generation\nreanalysis (ERA5) and coupled model intercomparison project (CMIP6) data under\ntwo climate pathways: SSP126 and SSP585. The results demonstrate that the SRDM\noutperforms existing generative models in generating super-resolution climate\ndata. For the Ejina region, under a high-emission pathway, the annual\nutilization hours of wind power are projected to decrease by 2.82 hours\/year,\nwhile those for PV power are projected to decrease by 0.26 hours\/year.\nFurthermore, the research highlights the estimation biases introduced when\nlow-resolution climate data is used for power conversion.",
    "explanation":"CLimate data often lacks the necessary hourly resolution to capture the shot-term variability and uncertainties of renewable energy resources. TO address this limitation, a super-resolution recurrent diffusiion model (SRDM) has been developed toenhance the temporal resolution of climate data and model the short-term uncertainty.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "Forecasting the inevitable: A review on the impacts of climate change on renewable energy resources"
    ],
    "b_abstract":[
      "Understanding the relationship and quantifying impacts of climate change on energy production is key to meeting our objectives achieving a sustainable future. Here we review current state art methodologies forecast future climate, potential changes in renewable main findings regarding role renewables decarbonisation supply. Most studies used model power equations estimate output. The largest variation estimated was for long-term scenarios, with non-significant variations reported short-term. highest variability found wind followed by hydro, both long-term, overall low solar any period. Additionally, efforts point investments as one pillars reducing fossil fuel dependency. Current knowledge gaps about uncertainty modelling results combined effects resources. Future should focus increasing resolution models improving input data, well assess entire electricity system not concentrate single source, which will aid defining strategies."
    ],
    "b_categories":[
      "Physical Geography"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "High-Resolution Image Synthesis with Latent Diffusion Models"
    ],
    "c_abstract":[
      "By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on data and beyond. Additionally, their formulation allows for guiding mechanism to control generation without retraining. However, since these typically operate directly in pixel space, optimization powerful DMs often consumes hundreds GPU days inference is expensive due evaluations. To enable DM training limited computational resources while retaining quality flexibility, we apply them latent space pretrained autoencoders. In contrast previous work, such representation first time reach near-optimal point between complexity reduction detail preservation, greatly boosting visual fidelity. introducing cross-attention layers model architecture, turn flexible generators general conditioning inputs as text or bounding boxes high-resolution becomes possible convolutional manner. Our (LDMs) new state art scores inpainting class-conditional highly competitive performance various tasks, including unconditional generation, text-to-image synthesis, super-resolution, significantly reducing requirements compared pixel-based DMs."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.18649",
    "a_title":"FITS: Ensuring Safe and Effective Touchscreen Use in Moving Vehicles",
    "a_abstract":"Touch interfaces are replacing physical buttons, dials, and switches in the\nnew generation of cars, aircraft, and vessels. However, vehicle vibrations and\naccelerations perturb finger movements and cause erroneous touchscreen inputs\nby users. Furthermore, unlike physical buttons, touchscreens cannot be operated\nby touch alone and always require users' visual focus. Hence, despite their\nnumerous benefits, touchscreens are not inherently suited for use in vehicles,\nwhich results in an increased risk of accidents. In a recently awarded research\nproject titled \"Right Touch Right Time: Future In-vehicle Touchscreens (FITS)\",\nwe aim to address these problems by developing novel in-vehicle touchscreens\nthat actively predict and correct perturbed finger movements and simulate\nphysical touch interactions with artificial tactile feedback.",
    "explanation":"The paper address the tactile feedback problems by developing novel in-vehicle touchscreens that actively predict and correct perturbed finger movements and simulate physical touch interactions with artificial tactile feedback.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "A Review of Surface Haptics: Enabling Tactile Effects on Touch Surfaces"
    ],
    "b_abstract":[
      "In this article, we review the current technology underlying surface haptics that converts passive touch surfaces to active ones (machine haptics), our perception of tactile stimuli displayed through (human their potential applications (human-machine interaction), and finally, challenges ahead us in making them available commercial systems. This article primarily covers interactions human fingers or hands with surface-haptics displays by focusing on three most popular actuation methods: vibrotactile, electrostatic, ultrasonic."
    ],
    "b_categories":[
      "cs.HC"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Biophysical properties of the human finger for touch comprehension: influences of ageing and gender"
    ],
    "c_abstract":[
      "The human finger plays an extremely important role in tactile perception, but little is known about how age and gender affect its biophysical properties their perception. We combined studies on contact characteristics, mechanical surface topography to understand effects the finger. values obtained regarding characteristics (i.e. adhesive force) were significantly higher for women than men. As Young's modulus E), a significant positive correlation with was observed found be women. A between arithmetic mean of roughness However, inverse effect highlighted have never been reported previously literature. These results open new perspectives understanding weakening perception across ages it differs men"
    ],
    "c_categories":[
      "Biodynamic"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06560",
    "a_title":"ElectricityEmissions.jl: A Framework for the Comparison of Carbon\n  Intensity Signals",
    "a_abstract":"An increasing number of individuals, companies and organizations are\ninterested in computing and minimizing the carbon emissions associated with\ntheir real-time electricity consumption. To achieve this, they require a carbon\nsignal, i.e. a metric that defines the real-time carbon intensity of their\nelectricity supply. Unfortunately, in a grid with multiple generation sources\nand multiple consumers, there is no unambiguous way to trace electricity from\nsource to sink. This makes it hard to define an appropriate signal, leading to\na raging discussion about how to best quantify the carbon footprint of\nelectricity.\n  This paper seeks to inform the discussion about which carbon signal is better\nor more suitable for two important use cases, namely carbon-informed load\nshifting and carbon accounting. We do this by developing a new software package\nElectricityEmissions$.$jl, that computes several established and newly proposed\ncarbon emission metrics for standard electric grid test cases. We also\ndemonstrate how the package can be used to investigate the effects of using\nthese metrics to guide load shifting. Our results affirm previous research,\nwhich showed that the choice of carbon emission metric has significant impact\non shifting results and associated carbon emission reductions. In addition, we\ndemonstrate the impact of load shifting on both the consumers that perform the\nshifting and consumers that do not. Disconcertingly, we observe that shifting\naccording to common metrics such as average carbon emissions can reduce the\namount of emissions allocated to data center, but cause an increase in the\ntotal emissions of the system.",
    "explanation":"The paper proposes a software package that computes several established and newly proposed carbon emission metrics for standard electric grid test cases.",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Tracing Power With Circuit Theory"
    ],
    "b_abstract":[
      "Power tracing is the task of disaggregating power injection a generator (or load) into sum constituent components that can unambiguously be attributed to loads (generators) and losses. Applications range broad spectrum of: transmission services pricing, loss allocation in distribution networks, fixed-cost allocation, modelling bilateral transactions, financial storage rights. This paper develops an analytical approach leveraging elementary circuit laws. The method rigorous from system-theoretic vantage point, it yields unambiguous results are consistent with constitutive principles describe steady-state behaviour networks. Moreover, implemented limited computational burden, applies networks arbitrary topologies, preserves coupling between activeand reactive-power injections. Numerical experiments indicate given solved power-flow solution, disaggregations computed for test system 2383 buses, 327 generators, 2056 4.34 s on personal computer, hence establishing scalability. Furthermore, applications demonstrated case studies focused quantifying impact distributed generation extracting nodal contributions respectively."
    ],
    "b_categories":[
      "Digital Circuits"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Carbon-Aware Optimal Power Flow"
    ],
    "c_abstract":[
      "To facilitate effective decarbonization of the electric power sector, this paper introduces generic Carbon-aware Optimal Power Flow (C-OPF) method for system decision-making that considers demand-side carbon accounting and emission management. Built upon classic optimal flow (OPF) model, C-OPF incorporates equations constraints, as well carbon-related objectives, to jointly optimize flow. In particular, establishes invertibility matrix proposes modeling linearization techniques address issues undetermined directions bilinear terms in model. Additionally, two novel models, together with schemes, energy storage systems are developed integrated into Numerical simulations demonstrate characteristics effectiveness method, comparison OPF solutions."
    ],
    "c_categories":[
      "physics.soc-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05443",
    "a_title":"ClusterGraph: a new tool for visualization and compression of\n  multidimensional data",
    "a_abstract":"Understanding the global organization of complicated and high dimensional\ndata is of primary interest for many branches of applied sciences. It is\ntypically achieved by applying dimensionality reduction techniques mapping the\nconsidered data into lower dimensional space. This family of methods, while\npreserving local structures and features, often misses the global structure of\nthe dataset. Clustering techniques are another class of methods operating on\nthe data in the ambient space. They group together points that are similar\naccording to a fixed similarity criteria, however unlike dimensionality\nreduction techniques, they do not provide information about the global\norganization of the data. Leveraging ideas from Topological Data Analysis, in\nthis paper we provide an additional layer on the output of any clustering\nalgorithm. Such data structure, ClusterGraph, provides information about the\nglobal layout of clusters, obtained from the considered clustering algorithm.\nAppropriate measures are provided to assess the quality and usefulness of the\nobtained representation. Subsequently the ClusterGraph, possibly with an\nappropriate structure--preserving simplification, can be visualized and used in\nsynergy with state of the art exploratory data analysis techniques.",
    "explanation":"Understanding the global organization of complicated and high dimensional data is of primary interest for many branches of applied sciences. It is typically\nachieved by applying dimensionality reduction techniques mapping the considered data into lower dimensional space.\nThe paper proposes ClusterGraph, obtained through clustering algorithm, to be use in synergy with state of the art exploratory data analysis techniques.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Topological Methods for the Analysis of High Dimensional Data Sets and 3D Object Recognition. The Eurographics Association"
    ],
    "b_abstract":[
      "We present a computational method for extracting simple descriptions of high dimensional data sets in the form of simplicial complexes. Our method, called Mapper, is based on the idea of partial clustering of the data guided by a set of functions defined on the data. The proposed method is not dependent on any particular clustering algorithm, i.e. any clustering algorithm may be used with Mapper. We implement this method and present a few sample applications in which simple descriptions of the data present important information about its structure."
    ],
    "b_categories":[
      "cs.DC"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "A Global Geometric Framework for Nonlinear Dimensionality Reduction"
    ],
    "c_abstract":[
      "Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem dimensionality reduction: finding meaningful low-dimensional structures hidden in their observations. The brain confronts same everyday perception, extracting from its sensory inputs\u201430,000 auditory nerve fibers 106 optic fibers\u2014a manageably small number perceptually relevant features. Here we describe an approach to solving reduction problems that uses easily measured local metric information learn underlying geometry a data set. Unlike classical techniques principal component analysis (PCA) and multidimensional scaling (MDS), our is capable discovering nonlinear degrees freedom underlie complex natural observations, handwriting images face under different viewing conditions. In contrast previous algorithms for reduction, ours efficiently computes globally optimal solution, and, important class manifolds, guaranteed converge asymptotically true structure."
    ],
    "c_categories":[
      "math.ST"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04992",
    "a_title":"Which bits went where? Past and future transfer entropy decomposition\n  with the information bottleneck",
    "a_abstract":"Whether the system under study is a shoal of fish, a collection of neurons,\nor a set of interacting atmospheric and oceanic processes, transfer entropy\nmeasures the flow of information between time series and can detect possible\ncausal relationships. Much like mutual information, transfer entropy is\ngenerally reported as a single value summarizing an amount of shared variation,\nyet a more fine-grained accounting might illuminate much about the processes\nunder study. Here we propose to decompose transfer entropy and localize the\nbits of variation on both sides of information flow: that of the originating\nprocess's past and that of the receiving process's future. We employ the\ninformation bottleneck (IB) to compress the time series and identify the\ntransferred entropy. We apply our method to decompose the transfer entropy in\nseveral synthetic recurrent processes and an experimental mouse dataset of\nconcurrent behavioral and neural activity. Our approach highlights the nuanced\ndynamics within information flow, laying a foundation for future explorations\ninto the intricate interplay of temporal processes in complex systems.",
    "explanation":"Much like mutual information, transfer entropy is generally reported as a single\nvalue summarizing an amount of shared variation, yet a more fine-grained accounting might illuminate much about the processes under study. The paper propose to decompose transfer entropy and localize the bits of variation on both sides of information flow.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Transfer Entropy Bottleneck: Learning Sequence to Sequence Information Transfer"
    ],
    "b_abstract":[
      "When presented with a data stream of two statistically dependent variables, predicting the future one variables (the target stream) can benefit from information about both its history and other variable source stream). For example, fluctuations in temperature at weather station be predicted using temperatures barometric readings. However, challenge when modelling such is that it easy for neural network to rely on greatest joint correlations within stream, which may ignore crucial but small transfer stream. As well, there are often situations where have previously been modelled independently would useful use model inform new model. Here, we develop an bottleneck approach conditional learning streams data. Our method, call Transfer Entropy Bottleneck (TEB), allows learn bottlenecks directed transferred variable, while quantifying this such, TEB provides order make predictions them."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Symbolic Transfer Entropy"
    ],
    "c_abstract":[
      "We propose to estimate transfer entropy using a technique of symbolization. demonstrate numerically that symbolic is robust and computationally fast method quantify the dominating direction information flow between time series from structurally identical nonidentical coupled systems. Analyzing multiday, multichannel electroencephalographic recordings 15 epilepsy patients our approach allowed us reliably identify hemisphere containing epileptic focus without observing actual seizure activity."
    ],
    "c_categories":[
      "physics.data-an"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06447",
    "a_title":"Multi-Parameter Molecular MRI Quantification using Physics-Informed\n  Self-Supervised Learning",
    "a_abstract":"Biophysical model fitting plays a key role in obtaining quantitative\nparameters from physiological signals and images. However, the model complexity\nfor molecular magnetic resonance imaging (MRI) often translates into excessive\ncomputation time, which makes clinical use impractical. Here, we present a\ngeneric computational approach for solving the parameter extraction inverse\nproblem posed by ordinary differential equation (ODE) modeling coupled with\nexperimental measurement of the system dynamics. This is achieved by\nformulating a numerical ODE solver to function as a step-wise analytical one,\nthereby making it compatible with automatic differentiation-based optimization.\nThis enables efficient gradient-based model fitting, and provides a new\napproach to parameter quantification based on self-supervised learning from a\nsingle data observation. The neural-network-based train-by-fit pipeline was\nused to quantify semisolid magnetization transfer (MT) and chemical exchange\nsaturation transfer (CEST) amide proton exchange parameters in the human brain,\nin an in-vivo molecular MRI study (n=4). The entire pipeline of the first whole\nbrain quantification was completed in 18.3$\\pm$8.3 minutes, which is an\norder-of-magnitude faster than comparable alternatives. Reusing the\nsingle-subject-trained network for inference in new subjects took 1.0$\\pm$0.2\ns, to provide results in agreement with literature values and scan-specific fit\nresults (Pearson's r>0.98, p<0.0001).",
    "explanation":"The model complexity for molecular magnetic resonance imaging (MRI) often translates into excessive computation time, which makes clinical use impractical. Here, we present a generic computational approach for solving the parameter extraction inverse problem posed by ordinary differential equation (ODE) modeling coupled with experimental measurement of the system dynamics. This is achieved by formulating a numerical ODE solver to function as a step-wise analytical one, thereby making it compatible with automatic differentiation-based optimization. This enables efficient gradient-based model fitting, and provides a new approach to parameter quantification based on self-supervised learning from a single data observation.",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "A deep learning approach for magnetization transfer contrast MR fingerprinting and chemical exchange saturation transfer imaging"
    ],
    "b_abstract":[
      "Semisolid magnetization transfer contrast (MTC) and chemical exchange saturation (CEST) MRI based on MT phenomenon have shown potential to evaluate brain development, neurological, psychiatric, neurodegenerative diseases. However, a qualitative ratio (MTR) metric commonly used in conventional MTC imaging is limited the assessment of quantitative semisolid macromolecular proton rates concentrations. In addition, CEST signals measured by MTR asymmetry analysis are unavoidably contaminated upfield nuclear Overhauser enhancement (NOE) mobile macromolecules. To address these issues, we developed an MTC-MR fingerprinting (MTC-MRF) technique quantify tissue parameters, which further allows estimation accurate at certain frequency offset. A pseudorandomized RF scheme was generate unique signal evolutions for different tissues supervised deep neural network designed extract properties from MTC-MRF signals. Through detailed Bloch equation-based digital phantom vivo studies, demonstrated that can characteristics with high accuracy computational efficiency, compared equation fitting approach, provide baseline reference NOE imaging. For validation, images were synthesized using parameters estimated deep-learning method experimentally acquired as standard. The proposed framework 3D MTC, CEST, human within clinically acceptable scan time."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Magnetic resonance fingerprinting"
    ],
    "c_abstract":[
      "Magnetic Resonance Fingerprinting (MRF) is a new approach to quantitative magnetic resonance imaging that allows simultaneous measurement of multiple tissue properties in a single, time-efficient acquisition. The ability to reproducibly and quantitatively measure tissue properties could enable more objective tissue diagnosis, comparisons of scans acquired at different locations and time points, longitudinal follow-up of individual patients and development of imaging biomarkers. This review provides a general overview of MRF technology, current preclinical and clinical applications and potential future directions. MRF has been initially evaluated in brain, prostate, liver, cardiac, musculoskeletal imaging, and measurement of perfusion and microvascular properties through MR vascular fingerprinting."
    ],
    "c_categories":[
      "nucl-th"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.10822",
    "a_title":"A Data-Efficient Sequential Learning Framework for Melt Pool Defect\n  Classification in Laser Powder Bed Fusion",
    "a_abstract":"Ensuring the quality and reliability of Metal Additive Manufacturing (MAM)\ncomponents is crucial, especially in the Laser Powder Bed Fusion (L-PBF)\nprocess, where melt pool defects such as keyhole, balling, and lack of fusion\ncan significantly compromise structural integrity. This study presents SL-RF+\n(Sequentially Learned Random Forest with Enhanced Sampling), a novel Sequential\nLearning (SL) framework for melt pool defect classification designed to\nmaximize data efficiency and model accuracy in data-scarce environments. SL-RF+\nutilizes RF classifier combined with Least Confidence Sampling (LCS) and Sobol\nsequence-based synthetic sampling to iteratively select the most informative\nsamples to learn from, thereby refining the model's decision boundaries with\nminimal labeled data. Results show that SL-RF+ outperformed traditional machine\nlearning models across key performance metrics, including accuracy, precision,\nrecall, and F1 score, demonstrating significant robustness in identifying melt\npool defects with limited data. This framework efficiently captures complex\ndefect patterns by focusing on high-uncertainty regions in the process\nparameter space, ultimately achieving superior classification performance\nwithout the need for extensive labeled datasets. While this study utilizes\npre-existing experimental data, SL-RF+ shows strong potential for real-world\napplications in pure sequential learning settings, where data is acquired and\nlabeled incrementally, mitigating the high costs and time constraints of sample\nacquisition.",
    "explanation":"Ensuring the quality and reliability of Metal Additive Manufacturing (MAM) components is crucial, especially in the Laser Powder Bed Fusion (L-PBF) process, where melt pool defects such as keyhole, balling, and lack of fusion can significantly compromise structural integrity. This study presents SL-RF+ (Sequentially Learned Random Forest with Enhanced Sampling), a novel Sequential Learning (SL) framework for melt pool defect classification designed to maximize data efficiency and model accuracy in data-scarce environments.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Additive manufacturing and sustainability: an exploratory study of the advantages and challenges"
    ],
    "b_abstract":[
      "The emergence of advanced manufacturing technologies, coupled with consumer demands for more customised products and services, are causing shifts in the scale distribution manufacturing. In this paper, consideration is given to role one such process technology: additive consequences adopting novel production technology on industrial sustainability not well understood exploratory study draws publically available data provide insights into impacts sustainability. Benefits found exist across product material life cycles through redesign, improvements input processing, make-to-order component manufacturing, closing loop. As an immature technology, there substantial challenges these benefits being realised at each stage cycle. This paper summarises advantages challenges, discusses implications terms sources innovation, business models, configuration value chains."
    ],
    "b_categories":[
      "cond-mat.mtrl-sci"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Machine learning in additive manufacturing: State-of-the-art and perspectives"
    ],
    "c_abstract":[
      "Additive manufacturing (AM) has emerged as a disruptive digital manufacturing technology. However, its broad adoption in industry is still hindered by high entry barriers of design for additive manufacturing (DfAM), limited materials library, various processing defects, and inconsistent product quality. In recent years, machine learning (ML) has gained increasing attention in AM due to its unprecedented performance in data tasks such as classification, regression and clustering. This article provides a comprehensive review on the state-of-the-art of ML applications in a variety of AM domains. In the DfAM, ML can be leveraged to output new high-performance metamaterials and optimized topological designs. In AM processing, contemporary ML algorithms can help to optimize process parameters, and conduct examination of powder spreading and in-process defect monitoring. On the production of AM, ML is able to assist practitioners in pre-manufacturing planning, and product quality assessment and control. Moreover, there has been an increasing concern about data security in AM as data breaches could occur with the aid of ML techniques. Lastly, it concludes with a section summarizing the main findings from the literature and providing perspectives on some selected interesting applications of ML in research and development of AM."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04323",
    "a_title":"Efficient Symmetry-Aware Materials Generation via Hierarchical\n  Generative Flow Networks",
    "a_abstract":"Discovering new solid-state materials requires rapidly exploring the vast\nspace of crystal structures and locating stable regions. Generating stable\nmaterials with desired properties and compositions is extremely difficult as we\nsearch for very small isolated pockets in the exponentially many possibilities,\nconsidering elements from the periodic table and their 3D arrangements in\ncrystal lattices. Materials discovery necessitates both optimized solution\nstructures and diversity in the generated material structures. Existing methods\nstruggle to explore large material spaces and generate diverse samples with\ndesired properties and requirements. We propose the Symmetry-aware Hierarchical\nArchitecture for Flow-based Traversal (SHAFT), a novel generative model\nemploying a hierarchical exploration strategy to efficiently exploit the\nsymmetry of the materials space to generate crystal structures given desired\nproperties. In particular, our model decomposes the exponentially large\nmaterials space into a hierarchy of subspaces consisting of symmetric space\ngroups, lattice parameters, and atoms. We demonstrate that SHAFT significantly\noutperforms state-of-the-art iterative generative methods, such as Generative\nFlow Networks (GFlowNets) and Crystal Diffusion Variational AutoEncoders\n(CDVAE), in crystal structure generation tasks, achieving higher validity,\ndiversity, and stability of generated structures optimized for target\nproperties and requirements.",
    "explanation":"Materials discovery necessitates both optimized solution structures and diversity in the generated material structures. We propose the Symmetry-aware\nHierarchical Architecture for Flow-based Traversal (SHAFT),a novel generative model employing a hierarchical exploration strategy to efficiently exploit the symmetry of the materials space to generate crystal structures given desired properties.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation"
    ],
    "b_abstract":[
      "This paper is about the problem of learning a stochastic policy for generating an object (like molecular graph) from sequence actions, such that probability proportional to given positive reward object. Whereas standard return maximization tends converge single return-maximizing sequence, there are cases where we would like sample diverse set high-return solutions. These arise, example, in black-box function optimization when few rounds possible, each with large batches queries, should be diverse, e.g., design new molecules. One can also see this as approximately converting energy generative distribution. While MCMC methods achieve that, they expensive and generally only perform local exploration. Instead, training amortizes cost search during yields fast generation. Using insights Temporal Difference learning, propose GFlowNet, based on view process flow network, making it possible handle tricky case different trajectories yield same final state, many ways sequentially add atoms generate some graph. We cast convert consistency equations into objective, akin casting Bellman methods. prove any global minimum proposed objectives which samples desired distribution, demonstrate improved performance diversity GFlowNet simple domain modes function, molecule synthesis task."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals"
    ],
    "c_abstract":[
      "Graph networks are a new machine learning (ML) paradigm that supports both relational reasoning and combinatorial generalization. Here, we develop universal MatErials Network (MEGNet) models for accurate property prediction in molecules crystals. We demonstrate the MEGNet outperform prior ML such as SchNet 11 out of 13 properties QM9 molecule data set. Similarly, show trained on \u223c60 000 crystals Materials Project substantially formation energies, band gaps, elastic moduli crystals, achieving better than density functional theory accuracy over much larger present two strategies to address limitations common materials science chemistry. First, physically intuitive approach unify four separate molecular internal energy at 0 K room temperature, enthalpy, Gibbs free into single model by incorporating pressure, entropy global state inputs. Second, learned element embeddings encode periodic chemical trends can be transfer-learned from set (formation energies) improve with smaller amounts (band gaps moduli)."
    ],
    "c_categories":[
      "cond-mat.mtrl-sci"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.2062",
    "a_title":"Construction and optimization of health behavior prediction model for   the elderly in smart elderly care",
    "a_abstract":"With the intensification of global aging, health management of the elderly has become a focus of social attention. This study designs and implements a smart elderly care service model to address issues such as data diversity, health status complexity, long-term dependence and data loss, sudden changes in behavior, and data privacy in the prediction of health behaviors of the elderly. The model achieves accurate prediction and dynamic management of health behaviors of the elderly through modules such as multimodal data fusion, data loss processing, nonlinear prediction, emergency detection, and privacy protection. In the experimental design, based on multi-source data sets and market research results, the model demonstrates excellent performance in health behavior prediction, emergency detection, and personalized services. The experimental results show that the model can effectively improve the accuracy and robustness of health behavior prediction and meet the actual application needs in the field of smart elderly care. In the future, with the integration of more data and further optimization of technology, the model will provide more powerful technical support for smart elderly care services.",
    "explanation":"This study designs and implements a smart elderly care service model to\naddress issues such as data diversity, health status complexity, long-term dependence and data loss, sudden changes in behavior, and data privacy in the prediction of health behaviors of the elderly. The model achieves accurate prediction and dynamic management of health behaviors of the elderly through modules such as multimodal data fusion, data loss processing, nonlinear prediction, emergency detection, and privacy protection.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Artificial intelligence in elderly healthcare: A scoping review"
    ],
    "b_abstract":[
      "The ageing population has led to a surge in the adoption of artificial intelligence (AI) technologies in elderly healthcare worldwide. However, in the advancement of AI technologies, there is currently a lack of clarity about the types and roles of AI technologies in elderly healthcare. This scoping review aimed to provide a comprehensive overview of AI technologies in elderly healthcare by exploring the types of AI technologies employed, and identifying their roles in elderly healthcare based on existing studies. A total of 10 databases were searched for this review, from January 1 2000 to July 31 2022. Based on the inclusion criteria, 105 studies were included. The AI devices utilized in elderly healthcare were summarised as robots, exoskeleton devices, intelligent homes, AI-enabled health smart applications and wearables, voice-activated devices, and virtual reality. Five roles of AI technologies were identified: rehabilitation therapists, emotional supporters, social facilitators, supervisors, and cognitive promoters. Results showed that the impact of AI technologies on elderly healthcare is promising and that AI technologies are capable of satisfying the unmet care needs of older adults and demonstrating great potential in its further development in this area. More well-designed randomised controlled trials are needed in the future to validate the roles of AI technologies in elderly healthcare."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Digital health platforms for the elderly? Key adoption and usage barriers and ways to address them"
    ],
    "c_abstract":[
      "Digital healthcare platforms (DHPs) represent a relatively new phenomenon that could provide valuable complement to physical primary care \u2013 for example, by reducing costs, improving access healthcare, and allowing patient monitoring. However, such are mainly used today the younger generations, which creates \"digital divide\" between elderly. This article aims identify: i) perceived key barriers inhibit adoption usage of DHPs elderly, ii) what DHP providers can do facilitate increased The draws on qualitative interviews with elderly complementary process data from major Swedish DHP. We find perceives two initial DHPs: negative attitudes technology anxiety one barrier affecting both lack trust. analysis also identifies multiple development suggestions improvement better accommodate needs including application tailored education activities. an integrated framework outlining ways address them. In so doing, we contribute literature mHealth in healthcare."
    ],
    "c_categories":[
      "Healthcare"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.16896",
    "a_title":"Enhancing Fluorescence Lifetime Parameter Estimation Accuracy with\n  Differential Transformer Based Deep Learning Model Incorporating Pixelwise\n  Instrument Response Function",
    "a_abstract":"Fluorescence Lifetime Imaging (FLI) is a critical molecular imaging modality\nthat provides unique information about the tissue microenvironment, which is\ninvaluable for biomedical applications. FLI operates by acquiring and analyzing\nphoton time-of-arrival histograms to extract quantitative parameters associated\nwith temporal fluorescence decay. These histograms are influenced by the\nintrinsic properties of the fluorophore, instrument parameters, time-of-flight\ndistributions associated with pixel-wise variations in the topographic and\noptical characteristics of the sample. Recent advancements in Deep Learning\n(DL) have enabled improved fluorescence lifetime parameter estimation. However,\nexisting models are primarily designed for planar surface samples, limiting\ntheir applicability in translational scenarios involving complex surface\nprofiles, such as \\textit{in-vivo} whole-animal or imaged guided surgical\napplications. To address this limitation, we present MFliNet (Macroscopic FLI\nNetwork), a novel DL architecture that integrates the Instrument Response\nFunction (IRF) as an additional input alongside experimental photon\ntime-of-arrival histograms. Leveraging the capabilities of a Differential\nTransformer encoder-decoder architecture, MFliNet effectively focuses on\ncritical input features, such as variations in photon time-of-arrival\ndistributions. We evaluate MFliNet using rigorously designed tissue-mimicking\nphantoms and preclinical in-vivo cancer xenograft models. Our results\ndemonstrate the model's robustness and suitability for complex macroscopic FLI\napplications, offering new opportunities for advanced biomedical imaging in\ndiverse and challenging settings.",
    "explanation":"Recent advancements in Deep Learning (DL) have enabled improved fluorescence lifetime parameter estimation",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Characterization of fluorescence lifetime of organic fluorophores for molecular imaging in the shortwave infrared window"
    ],
    "b_abstract":[
      "SignificanceFluorescence lifetime imaging in the shortwave infrared (SWIR) is expected to enable high-resolution multiplexed molecular highly scattering tissue.AimTo characterize brightness and fluorescence of commercially available organic SWIR fluorophores benchmark them against tail emission conventional NIR-excited probes.ApproachCharacterization was performed through our established time-domain mesoscopic tomography system integrated around a time-correlated single-photon counting-single-photon avalanche diode array. Brightness were measured for NIR probes >1000 nm. Simultaneous probe then assess their potential studies.ResultsThe outperformed while mean lifetimes extremely short. The phantom study demonstrated feasibility multiplexing window with both probes.ConclusionsLong-tail Fluorescence readily detectable window, where showed shorter compared probes. We demonstrate which paves way vivo studies intact tissues at improved resolution."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b27"
    ],
    "c_title":[
      "Fast fit-free analysis of fluorescence lifetime imaging via deep learning"
    ],
    "c_abstract":[
      "Fluorescence lifetime imaging (FLI) provides unique quantitative information in biomedical and molecular biology studies but relies on complex data-fitting techniques to derive the quantities of interest. Herein, we propose a fit-free approach FLI image formation that is based deep learning (DL) quantify fluorescence decays simultaneously over whole at fast speeds. We report neural network (DNN) architecture, named (FLI-Net) designed trained for different classes experiments, including visible near-infrared (NIR) microscopy (FLIM) NIR gated macroscopy (MFLI). FLI-Net outputs quantitatively spatially resolved lifetime-based parameters are typically employed field. validate utility framework by performing microscopic preclinical across spectra, as well 2 main data acquisition technologies. These results demonstrate suited accurately lifetimes cells and, real time, intact animals without any parameter settings. Hence, paves way reproducible unprecedented speeds, improved dissemination impact many important applications ranging from fundamental discoveries cellular clinical translation."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.16961",
    "a_title":"Glo-In-One-v2: Holistic Identification of Glomerular Cells, Tissues, and\n  Lesions in Human and Mouse Histopathology",
    "a_abstract":"Segmenting glomerular intraglomerular tissue and lesions traditionally\ndepends on detailed morphological evaluations by expert nephropathologists, a\nlabor-intensive process susceptible to interobserver variability. Our group\npreviously developed the Glo-In-One toolkit for integrated detection and\nsegmentation of glomeruli. In this study, we leverage the Glo-In-One toolkit to\nversion 2 with fine-grained segmentation capabilities, curating 14 distinct\nlabels for tissue regions, cells, and lesions across a dataset of 23,529\nannotated glomeruli across human and mouse histopathology data. To our\nknowledge, this dataset is among the largest of its kind to date.In this study,\nwe present a single dynamic head deep learning architecture designed to segment\n14 classes within partially labeled images of human and mouse pathology data.\nOur model was trained using a training set derived from 368 annotated kidney\nwhole-slide images (WSIs) to identify 5 key intraglomerular tissues covering\nBowman's capsule, glomerular tuft, mesangium, mesangial cells, and podocytes.\nAdditionally, the network segments 9 glomerular lesion classes including\nadhesion, capsular drop, global sclerosis, hyalinosis, mesangial lysis,\nmicroaneurysm, nodular sclerosis, mesangial expansion, and segmental sclerosis.\nThe glomerulus segmentation model achieved a decent performance compared with\nbaselines, and achieved a 76.5 % average Dice Similarity Coefficient (DSC).\nAdditional, transfer learning from rodent to human for glomerular lesion\nsegmentation model has enhanced the average segmentation accuracy across\ndifferent types of lesions by more than 3 %, as measured by Dice scores. The\nGlo-In-One-v2 model and trained weight have been made publicly available at\nhttps: \/\/github.com\/hrlblab\/Glo-In-One_v2.",
    "explanation":"In this study, we present a single dynamic head deep learning architecture designed to segment 14 classes within partially labeled images of human and mouse pathology data",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Pathology image analysis using segmentation deep learning algorithms"
    ],
    "b_abstract":[
      "With the rapid development of image scanning techniques and visualization software, whole slide imaging (WSI) is becoming a routine diagnostic method. Accelerating clinical diagnosis from pathology images and automating image analysis efficiently and accurately remain significant challenges. Recently, deep learning algorithms have shown great promise in pathology image analysis, such as in tumor region identification, metastasis detection, and patient prognosis. Many machine learning algorithms, including convolutional neural networks, have been proposed to automatically segment pathology images. Among these algorithms, segmentation deep learning algorithms such as fully convolutional networks stand out for their accuracy, computational efficiency, and generalizability. Thus, deep learning\u2013based pathology image segmentation has become an important tool in WSI analysis. In this review, the pathology image segmentation process using deep learning algorithms is described in detail. The goals are to provide quick guidance for implementing deep learning into pathology image analysis and to provide some potential ways of further improving segmentation performance. Although there have been previous reviews on using machine learning methods in digital pathology image analysis, this is the first in-depth review of the applications of deep learning algorithms for segmentation in WSI analysis."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "Comparative gene expression profiles of intestinal transporters in mice, rats and humans"
    ],
    "c_abstract":[
      "We have studied gene expression profiles of intestinal transporters in model animals and humans. Total RNA was isolated from duodenum and the mRNA expression was measured using Affymetrix GeneChip oligonucleotide arrays. Detected genes from the intestine of mice, rats, and humans were about 60% of 22,690 sequences, 40% of 8739, and 47% of 12,559, respectively. A total of 86 genes involving transporters expressed in mice, 50 genes in rats, and 61 genes in humans were detected. Mice exhibited abundant mRNA expressions for peptide transporter HPT1, amino acid transporters CSNU3, CT1 and ASC1, nucleoside transporter CNT2, organic cation transporter SFXN1, organic anion transporter NBC3, glucose transporter SGLT1, and fatty acid transporters FABP1 and FABP2. Rats showed high expression profiles of peptide transporter PEPT1, amino acid transporters CSNU1 and 4F2HC, nucleoside transporter CNT2, organic cation transporter OCT5, organic anion transporter SDCT1, glucose transporter GLUT2 and GLUT5, and folate carrier FOLT. In humans, the highly expressed genes were peptide transporter HPT1, amino acid transporters LAT3, 4F2HC and PROT, nucleoside transporter CNT2, organic cation transporter OCTN2, organic anion transporters NADC1, NBC1 and SBC2, glucose transporters SGLT1 and GLUT5, multidrug resistance-associated protein RHO12, fatty acid transporters FABP1 and FABP2, and phosphate carrier PHC. Overall these data reveal diverse transcriptomic profiles for intestinal transporters among these species. Therefore, this transcriptional data may lead to more effective use of the laboratory animals as a model for oral drug development."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.02083",
    "a_title":"Implementing An Artificial Quantum Perceptron",
    "a_abstract":"A Perceptron is a fundamental building block of a neural network. The\nflexibility and scalability of perceptron make it ubiquitous in building\nintelligent systems. Studies have shown the efficacy of a single neuron in\nmaking intelligent decisions. Here, we examined and compared two perceptrons\nwith distinct mechanisms, and developed a quantum version of one of those\nperceptrons. As a part of this modeling, we implemented the quantum circuit for\nan artificial perception, generated a dataset, and simulated the training.\nThrough these experiments, we show that there is an exponential growth\nadvantage and test different qubit versions. Our findings show that this\nquantum model of an individual perceptron can be used as a pattern classifier.\nFor the second type of model, we provide an understanding to design and\nsimulate a spike-dependent quantum perceptron. Our code is available at\n\\url{https:\/\/github.com\/ashutosh1919\/quantum-perceptron}",
    "explanation":"Studies have shown the efficacy of a single neuron in making intelligent decisions. Here, we examined and compared two perceptrons with distinct mechanisms, and developed a quantum version of one of those perceptrons",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Learning internal representations by back-propagating errors"
    ],
    "b_abstract":[
      "We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal \u2018hidden\u2019 units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "Quantum algorithms for supervised and unsupervised machine learning"
    ],
    "c_abstract":[
      "Machine-learning tasks frequently involve problems of manipulating and classifying large numbers vectors in high-dimensional spaces. Classical algorithms for solving such typically take time polynomial the number dimension space. Quantum computers are good at tensor product This paper provides supervised unsupervised quantum machine learning cluster assignment finding. can logarithmic both their dimension, an exponential speed-up over classical algorithms."
    ],
    "c_categories":[
      "Quantum Physics"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.06750",
    "a_title":"SynStitch: a Self-Supervised Learning Network for Ultrasound Image\n  Stitching Using Synthetic Training Pairs and Indirect Supervision",
    "a_abstract":"Ultrasound (US) image stitching can expand the field-of-view (FOV) by\ncombining multiple US images from varied probe positions. However, registering\nUS images with only partially overlapping anatomical contents is a challenging\ntask. In this work, we introduce SynStitch, a self-supervised framework\ndesigned for 2DUS stitching. SynStitch consists of a synthetic stitching pair\ngeneration module (SSPGM) and an image stitching module (ISM). SSPGM utilizes a\npatch-conditioned ControlNet to generate realistic 2DUS stitching pairs with\nknown affine matrix from a single input image. ISM then utilizes this synthetic\npaired data to learn 2DUS stitching in a supervised manner. Our framework was\nevaluated against multiple leading methods on a kidney ultrasound dataset,\ndemonstrating superior 2DUS stitching performance through both qualitative and\nquantitative analyses. The code will be made public upon acceptance of the\npaper.",
    "explanation":"Ultrasound (US) image stitching can expand the field-of view (FOV) by combining multiple US images from varied probe positions [...] In this work, we introduce SynStitch, a self-supervised framework designed for 2DUS stitching",
    "b_id":[
      "b3",
      "b21"
    ],
    "b_title":[
      "3-D ultrasound imaging: a review",
      "Generative AI for Medical Imaging: extending the MONAI Framework"
    ],
    "b_abstract":[
      "The development of 3-D ultrasound imaging is a way to address the disadvantages conventional imaging. In this article authors review approaches that have been attempted in such as B-mode, color Doppler, and power Doppler systems. Acquisition, reconstruction, rendering techniques for are discussed, well applications limitations.",
      "Recent advances in generative AI have brought incredible breakthroughs several areas, including medical imaging. These models tremendous potential not only to help safely share data via synthetic datasets but also perform an array of diverse applications, such as anomaly detection, image-to-image translation, denoising, and MRI reconstruction. However, due the complexity these models, their implementation reproducibility can be difficult. This hinder progress, act a use barrier, dissuade comparison new methods with existing works. In this study, we present MONAI Generative Models, freely available open-source platform that allows researchers developers easily train, evaluate, deploy related applications. Our reproduces state-of-art studies standardised way involving different architectures (such diffusion autoregressive transformers, GANs), provides pre-trained for community. We implemented generalisable fashion, illustrating results extended 2D or 3D scenarios, images modalities (like CT, MRI, X-Ray data) from anatomical areas. Finally, adopt modular extensible approach, ensuring long-term maintainability extension current applications future features."
    ],
    "b_categories":[
      "cs.CV",
      "eess.IV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Symmetric diffeomorphic image registration with crosscorrelation: evaluating automated labeling of elderly and neurodegenerative brain"
    ],
    "c_abstract":[
      "One of the most challenging problems in modern neuroimaging is detailed characterization of neurodegeneration. Quantifying spatial and longitudinal atrophy patterns is an important component of this process. These spatiotemporal signals will aid in discriminating between related diseases, such as frontotemporal dementia (FTD) and Alzheimer's disease (AD), which manifest themselves in the same at-risk population. Here, we develop a novel symmetric image normalization method (SyN) for maximizing the cross-correlation within the space of diffeomorphic maps and provide the Euler-Lagrange equations necessary for this optimization. We then turn to a careful evaluation of our method. Our evaluation uses gold standard, human cortical segmentation to contrast SyN's performance with a related elastic method and with the standard ITK implementation of Thirion's Demons algorithm. The new method compares favorably with both approaches, in particular when the distance between the template brain and the target brain is large. We then report the correlation of volumes gained by algorithmic cortical labelings of FTD and control subjects with those gained by the manual rater. This comparison shows that, of the three methods tested, SyN's volume measurements are the most strongly correlated with volume measurements gained by expert labeling. This study indicates that SyN, with cross-correlation, is a reliable method for normalizing and making anatomical measurements in volumetric MRI of patients and at-risk elderly individuals."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17420",
    "a_title":"Cross-modal Medical Image Generation Based on Pyramid Convolutional\n  Attention Network",
    "a_abstract":"The integration of multimodal medical imaging can provide complementary and\ncomprehensive information for the diagnosis of Alzheimer's disease (AD).\nHowever, in clinical practice, since positron emission tomography (PET) is\noften missing, multimodal images might be incomplete. To address this problem,\nwe propose a method that can efficiently utilize structural magnetic resonance\nimaging (sMRI) image information to generate high-quality PET images. Our\ngeneration model efficiently utilizes pyramid convolution combined with channel\nattention mechanism to extract multi-scale local features in sMRI, and injects\nglobal correlation information into these features using self-attention\nmechanism to ensure the restoration of the generated PET image on local texture\nand global structure. Additionally, we introduce additional loss functions to\nguide the generation model in producing higher-quality PET images. Through\nexperiments conducted on publicly available ADNI databases, the generated\nimages outperform previous research methods in various performance indicators\n(average absolute error: 0.0194, peak signal-to-noise ratio: 29.65, structural\nsimilarity: 0.9486) and are close to real images. In promoting AD diagnosis,\nthe generated images combined with their corresponding sMRI also showed\nexcellent performance in AD diagnosis tasks (classification accuracy: 94.21 %),\nand outperformed previous research methods of the same type. The experimental\nresults demonstrate that our method outperforms other competing methods in\nquantitative metrics, qualitative visualization, and evaluation criteria.",
    "explanation":"Our generation model efficiently utilizes pyramid convolution combined with channel attention mechanism to extract multi-scale local features in sMRI, and injects global correlation information into these features using self-attention mechanism to ensure the restoration of the generated PET image on local texture and global structure",
    "b_id":[
      "b3",
      "b17"
    ],
    "b_title":[
      "Deep learning-based classification of healthy aging controls, mild cognitive impairment and alzheimer's disease using fusion of mri-pet imaging",
      "Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"
    ],
    "b_abstract":[
      "Automated detection of dementia stage using multimodal imaging modalities will be helpful for improving the clinical diagnosis. In this study, we develop the Inception-ResNet wrapper model in differentiating the healthy controls (HC), mild cognitive impairment (MCI), and Alzheimer\u2019s disease (AD) using conjoint magnetic resonance imaging (MRI) and positron emission tomography (PET) scans. We use T1-weighted MR and PET images of individuals aged between 42 and 95 years, including HC, MCI and AD patients. We first perform 3D tissue segmentation of MR images after skull striping. The atlas-based segmented MR image tissue is fused with PET image. Then we transform PET images from RGB to HSI color space and apply fusion of MRI with PET images using two-dimensional Fourier and discrete wavelet transform (DWT) and then reconstruct the MR-PET fused image using inverse Fourier and DWT methods. After the fusion of MRI and PET imaging modalities, we used 60 % training, 20 % for validation and the remaining 20 % as a test set using various convolutional neural networks. We found the proposed model as the best classifier with an accuracy of 95.5 %, 94.1 % and 95.9 % in classifying HC vs MCI, MCI vs AD and AD vs HC respectively when compared to the existing methods. We conclude that the proposed deep learning model has potential in automated classification of healthy and dementia stages using combined MRI and PET modalities with good performance.",
      "Image-to-image translation is a class of vision and graphics problems where the goal to learn mapping between an input image output using training set aligned pairs. However, for many tasks, paired data will not be available. We present approach learning translate from source domain X target Y in absence examples. Our G : \u2192 such that distribution images G(X) indistinguishable adversarial loss. Because this highly under-constrained, we couple it with inverse F introduce cycle consistency loss push F(G(X)) \u2248 (and vice versa). Qualitative results are presented on several tasks does exist, including collection style transfer, object transfiguration, season photo enhancement, etc. Quantitative comparisons against prior methods demonstrate superiority our approach."
    ],
    "b_categories":[
      "cs.CV",
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b19"
    ],
    "c_title":[
      "Bidirectional Mapping of Brain MRI and PET With 3D Reversible GAN for the Diagnosis of Alzheimer\u2019s Disease"
    ],
    "c_abstract":[
      "<jats:p>Combining multi-modality data for brain disease diagnosis such as Alzheimer\u2019s disease (AD) commonly leads to improved performance than those using a single modality. However, it is still challenging to train a multi-modality model since it is difficult in clinical practice to obtain complete data that includes all modality data. Generally speaking, it is difficult to obtain both magnetic resonance images (MRI) and positron emission tomography (PET) images of a single patient. PET is expensive and requires the injection of radioactive substances into the patient\u2019s body, while MR images are cheaper, safer, and more widely used in practice. Discarding samples without PET data is a common method in previous studies, but the reduction in the number of samples will result in a decrease in model performance. To take advantage of multi-modal complementary information, we first adopt the Reversible Generative Adversarial Network (RevGAN) model to reconstruct the missing data. After that, a 3D convolutional neural network (CNN) classification model with multi-modality input was proposed to perform AD diagnosis. We have evaluated our method on the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database, and compared the performance of the proposed method with those using state-of-the-art methods. The experimental results show that the structural and functional information of brain tissue can be mapped well and that the image synthesized by our method is close to the real image. In addition, the use of synthetic data is beneficial for the diagnosis and prediction of Alzheimer\u2019s disease, demonstrating the effectiveness of the proposed framework.<\/jats:p>"
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.16425",
    "a_title":"Patherea: Cell Detection and Classification for the 2020s",
    "a_abstract":"This paper presents a Patherea, a framework for point-based cell detection\nand classification that provides a complete solution for developing and\nevaluating state-of-the-art approaches. We introduce a large-scale dataset\ncollected to directly replicate a clinical workflow for Ki-67 proliferation\nindex estimation and use it to develop an efficient point-based approach that\ndirectly predicts point-based predictions, without the need for intermediate\nrepresentations. The proposed approach effectively utilizes point proposal\ncandidates with the hybrid Hungarian matching strategy and a flexible\narchitecture that enables the usage of various backbones and (pre)training\nstrategies. We report state-of-the-art results on existing public datasets -\nLizard, BRCA-M2C, BCData, and the newly proposed Patherea dataset. We show that\nthe performance on existing public datasets is saturated and that the newly\nproposed Patherea dataset represents a significantly harder challenge for the\nrecently proposed approaches. We also demonstrate the effectiveness of recently\nproposed pathology foundational models that our proposed approach can natively\nutilize and benefit from. We also revisit the evaluation protocol that is used\nin the broader field of cell detection and classification and identify the\nerroneous calculation of performance metrics. Patherea provides a benchmarking\nutility that addresses the identified issues and enables a fair comparison of\ndifferent approaches. The dataset and the code will be publicly released upon\nacceptance.",
    "explanation":"This paper presents a Patherea, a framework for point-based cell detection and classification that provides a complete solution for developing and evaluating state-of-the-art approaches.",
    "b_id":[
      "b40"
    ],
    "b_title":[
      "Whole Slide Imaging Versus Microscopy for Primary Diagnosis in Surgical Pathology: A Multicenter Blinded Randomized Noninferiority Study of 1992 Cases (Pivotal Study)"
    ],
    "b_abstract":[
      "Most prior studies of primary diagnosis in surgical pathology using whole slide imaging (WSI) versus microscopy have focused on specific organ systems or included relatively few cases. The objective this study was to demonstrate that WSI is noninferior for pathology. A blinded randomized noninferiority conducted across the entire range cases (biopsies and resections, including hematoxylin eosin, immunohistochemistry, special stains) from 4 institutions original sign-out (baseline diagnosis) as reference standard. Cases were scanned, converted randomized. Sixteen pathologists interpreted by WSI, followed a wash-out period \u22654 weeks, after which read same observers other modality. Major discordances identified an adjudication panel, differences between major discordance rates both (against standard) calculated. total 1992 included, resulting 15,925 reads. rate with standard 4.9% 4.6% microscopy. difference 0.4% (95% confidence interval, -0.30% 1.01%). highest endocrine (1.8%), neoplastic kidney (1.5%), urinary bladder (1.3%), gynecologic (1.2%). Detailed analysis these revealed no instances where interpretation consistently inaccurate compared multiple observers. We conclude pathology, biopsies resections stained immunohistochemistry stains. This conclusion valid wide variety specimen types."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    ],
    "c_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01019",
    "a_title":"A lightweight Convolutional Neural Network based on U shape structure\n  and Attention Mechanism for Anterior Mediastinum Segmentation",
    "a_abstract":"To automatically detect Anterior Mediastinum Lesions (AMLs) in the Anterior\nMediastinum (AM), the primary requirement will be an automatic segmentation\nmodel specifically designed for the AM. The prevalence of AML is extremely low,\nmaking it challenging to conduct screening research similar to lung cancer\nscreening. Retrospectively reviewing chest CT scans over a specific period to\ninvestigate the prevalence of AML requires substantial time. Therefore,\ndeveloping an Artificial Intelligence (AI) model to find location of AM helps\nradiologist to enhance their ability to manage workloads and improve diagnostic\naccuracy for AMLs. In this paper, we introduce a U-shaped structure network to\nsegment AM. Two attention mechanisms were used for maintaining long-range\ndependencies and localization. In order to have the potential of Multi-Head\nSelf-Attention (MHSA) and a lightweight network, we designed a parallel MHSA\nnamed Wide-MHSA (W-MHSA). Maintaining long-range dependencies is crucial for\nsegmentation when we upsample feature maps. Therefore, we designed a Dilated\nDepth-Wise Parallel Path connection (DDWPP) for this purpose. In order to\ndesign a lightweight architecture, we introduced an expanding convolution block\nand combine it with the proposed W-MHSA for feature extraction in the encoder\npart of the proposed U-shaped network. The proposed network was trained on 2775\nAM cases, which obtained an average Dice Similarity Coefficient (DSC) of\n87.83%, mean Intersection over Union (IoU) of 79.16%, and Sensitivity of\n89.60%. Our proposed architecture exhibited superior segmentation performance\ncompared to the most advanced segmentation networks, such as Trans Unet,\nAttention Unet, Res Unet, and Res Unet++.",
    "explanation":"It's leveraging AI in another diffrent domain, namely medical science, to detect Anterior Mediastinum Lesions.",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Anterior mediastinal nodular lesion segmentation from chest computed tomography imaging using UNet based neural network with attention mechanisms"
    ],
    "b_abstract":[
      "Automated detection of anterior mediastinal nodular lesions (AMLs) has significance for clinical usage as it is challenging for radiologists to accurately identify AMLs from chest computed tomography (CT) imaging due to various factors, including poor resolution, variations in intensity and the similarity of the AMLs to other tissues. To assist radiologists in AML detection from chest CT imaging, a UNet-based computer-aided detection (CADe) system is proposed to segment AMLs from slice images of the chest CT scans. The proposed network adopts a modified UNet architecture. To guide the proposed network to selectively focus on AMLs and potentially disregard others in the image, different attention mechanisms are utilized in the proposed network, including the self-attention mechanism and the convolutional block attention module (CBAM). The proposed network was trained and evaluated on 180 chest CT scans which consist of 180 AMLs. 90 AMLs were identified as thymic cysts, and 90 AMLs were diagnosed as thymoma. The proposed network achieved an average dice similarity coefficient (DSC) of 93.23 with 5-fold cross-validation, for which the mean Intersection over Union (IoU), sensitivity and specificity were 90.29, 93.98 and 95.68 respectively. Our method demonstrated an improved segmentation performance over state-of-the-art segmentation networks, including UNet, ResUNet, TransUNet and UNet++. The proposed network employing attention mechanisms exhibited a promising result for segmenting AMLs from chest CT imaging and could be used to automate the AML detection process for achieving improved diagnostic reliability."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.19343"
    ],
    "c_title":[
      "Effect of a new type of healthy and live food supplement on osteoporosis\n  blood parameters and induced rheumatoid arthritis in Wistar rats"
    ],
    "c_abstract":[
      "Summary Osteoporosis is a skeletal disorder, characterized by a decrease in\nbone strength and puts the individual at risk for fracture. On the other hand,\nrheumatoid arthritis is a systemic disease of unknown etiology that causes\ninflammation of the joints of the organs. Purpose Due to the destructive\neffects of these diseases and its increasing prevalence and lack of appropriate\nmedication for treatment, the present study aimed to evaluate the therapeutic\neffect of a new type of healthy and live food supplement on rheumatoid\narthritis and induced osteoporosis in rats. Methods In this research, healthy\nand live food powder were synthesized by a new and green route. This organic\nbiomaterial was named NBS. The NBS food supplement had various vitamins, macro\nand micro molecules, and ingredients. The new healthy and nutritious diet\nshowed that the use of this supplement led to the return of the parameters to\nnormal levels. Results The concentration of 12.5 mg\/ kg showed the least\ntherapeutic effect and 50 mg\/ kg had the highest therapeutic effect for\nosteoporosis. The results of blood parameters involved in inflammation in both\nhealthy and patient groups showed that the use of complete adjuvant induction\ncauses joint inflammation. In the study of the interaction of the\nconcentrations, it was observed that the concentration of 50 mg\/ kg had the\nhighest therapeutic effect against the disease in the studied mice. Conclusion\nThe results showed that the new healthy and viable supplement restores the\nblood osteoporotic and rheumatoid factors of the mice to normal."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.01019",
    "a_title":"A lightweight Convolutional Neural Network based on U shape structure\n  and Attention Mechanism for Anterior Mediastinum Segmentation",
    "a_abstract":"To automatically detect Anterior Mediastinum Lesions (AMLs) in the Anterior\nMediastinum (AM), the primary requirement will be an automatic segmentation\nmodel specifically designed for the AM. The prevalence of AML is extremely low,\nmaking it challenging to conduct screening research similar to lung cancer\nscreening. Retrospectively reviewing chest CT scans over a specific period to\ninvestigate the prevalence of AML requires substantial time. Therefore,\ndeveloping an Artificial Intelligence (AI) model to find location of AM helps\nradiologist to enhance their ability to manage workloads and improve diagnostic\naccuracy for AMLs. In this paper, we introduce a U-shaped structure network to\nsegment AM. Two attention mechanisms were used for maintaining long-range\ndependencies and localization. In order to have the potential of Multi-Head\nSelf-Attention (MHSA) and a lightweight network, we designed a parallel MHSA\nnamed Wide-MHSA (W-MHSA). Maintaining long-range dependencies is crucial for\nsegmentation when we upsample feature maps. Therefore, we designed a Dilated\nDepth-Wise Parallel Path connection (DDWPP) for this purpose. In order to\ndesign a lightweight architecture, we introduced an expanding convolution block\nand combine it with the proposed W-MHSA for feature extraction in the encoder\npart of the proposed U-shaped network. The proposed network was trained on 2775\nAM cases, which obtained an average Dice Similarity Coefficient (DSC) of\n87.83%, mean Intersection over Union (IoU) of 79.16%, and Sensitivity of\n89.60%. Our proposed architecture exhibited superior segmentation performance\ncompared to the most advanced segmentation networks, such as Trans Unet,\nAttention Unet, Res Unet, and Res Unet++.",
    "explanation":"It's leveraging AI in another diffrent domain, namely medical science, to detect Anterior Mediastinum Lesions.",
    "b_id":[
      "b6",
      "b1"
    ],
    "b_title":[
      "Screening for lung cancer: 2023 guideline update from the American Cancer Society",
      "Incidental Anterior Mediastinal Nodular Lesions on\u00a0Chest CT in Asymptomatic Subjects"
    ],
    "b_abstract":[
      "Abstract Lung cancer is the leading cause of mortality and person\u2010years life lost from among US men women. Early detection has been shown to be associated with reduced lung mortality. Our objective was update American Cancer Society (ACS) 2013 screening (LCS) guideline for adults at high risk cancer. The intended provide guidance health care providers their patients who are due a history smoking. ACS Guideline Development Group (GDG) utilized systematic review LCS literature commissioned Preventive Services Task Force 2021 recommendation update; second years since quitting smoking (YSQ); published 2021; two Intervention Surveillance Modeling Network\u2010validated models assess benefits harms screening; an epidemiologic modeling analysis examining effect YSQ aging on risk; updated benefit\u2010to\u2010radiation\u2010risk ratios follow\u2010up examinations. GDG also examined disease burden data National Institute\u2019s Surveillance, Epidemiology, End Results program. Formulation recommendations based quality evidence judgment (incorporating values preferences) about balance harms. judged that overall moderate sufficient support strong individuals meet eligibility criteria. in women aged 50\u201380 reduction deaths across range study designs, inferential supports older than 80 good health. recommends annual low\u2010dose computed tomography asymptomatic currently smoke or formerly smoked have \u226520 pack\u2010year ( , ). Before decision made initiate LCS, should engage shared decision\u2010making discussion qualified professional. For smoked, number not criterion begin stop screening. Individuals receive counseling quit connected cessation resources. comorbid conditions substantially limit expectancy screened. These considered by discussions LCS. If fully implemented, these likelihood significantly reducing death suffering United States.",
      "Objective: The aim of this study was to investigate the prevalence and characteristics of nodular lesions in the anterior mediastinum that had been found incidentally on screening chest computed tomography (CT) in asymptomatic subjects. Methods: We included 56,358 consecutive participants (mean age 52.4 \u00b1 10.5 years; male-female ratio 35,306:21,052) who underwent a baseline low-dose chest CT scan as part of a health checkup from 2006 through 2013. After the presence of anterior mediastinal nodular lesion had been confirmed, their CT findings, confirmatory diagnosis, and interval CT scan were reviewed. The standardized prevalence ratio for thymic epithelial tumor was calculated on the basis of the Republic of Korea cancer statistics for 2014. Results: Of the 56,358 participants, 413 (0.73%) had lesions (95% confidence interval: 0.66-0.80%); the prevalence increased with age (p <0.001) and a history of malignancy (p = 0.005). Of the lesions, 85.2% were smaller than 2 cm, 61.3% were round, and 80.2% had CT attenuation higher than 20 Hounsfield units. Among 51 proven cases, 39 lesions (76.9%) were benign and 12 (23.1%) were malignant. The standardized prevalence ratio for thymic epithelial tumor was 2.04 (95% confidence interval: 1.01-3.42). Of 11 resected thymic epithelial tumors, five were carcinomas, 10 were stage I or II, and all were completely resected without recurrence. Of the 237 unconfirmed cases with a follow-up CT scan, 82.2% were stable, 8.9% had increased, and the other 8.9% had decreased. Conclusions: The prevalence of incidental nodular lesion was 0.73%. Most lesions had CT features that were indistinguishable from thymic epithelial tumors, but a considerable portion of the lesions were suspected to be benign. Incidental thymic epithelial tumors were more prevalent than clinically detected tumors, were early-stage cancer, and showed favorable outcomes."
    ],
    "b_categories":[
      "q-bio.TO",
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.07709"
    ],
    "c_title":[
      "MAGELLAN: Metacognitive predictions of learning progress guide autotelic\n  LLM agents in large goal spaces"
    ],
    "c_abstract":[
      "Open-ended learning agents must efficiently prioritize goals in vast\npossibility spaces, focusing on those that maximize learning progress (LP).\nWhen such autotelic exploration is achieved by LLM agents trained with online\nRL in high-dimensional and evolving goal spaces, a key challenge for LP\nprediction is modeling one's own competence, a form of metacognitive\nmonitoring. Traditional approaches either require extensive sampling or rely on\nbrittle expert-defined goal groupings. We introduce MAGELLAN, a metacognitive\nframework that lets LLM agents learn to predict their competence and LP online.\nBy capturing semantic relationships between goals, MAGELLAN enables\nsample-efficient LP estimation and dynamic adaptation to evolving goal spaces\nthrough generalization. In an interactive learning environment, we show that\nMAGELLAN improves LP prediction efficiency and goal prioritization, being the\nonly method allowing the agent to fully master a large and evolving goal space.\nThese results demonstrate how augmenting LLM agents with a metacognitive\nability for LP predictions can effectively scale curriculum learning to\nopen-ended goal spaces."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.11084",
    "a_title":"BarcodeMamba: State Space Models for Biodiversity Analysis",
    "a_abstract":"DNA barcodes are crucial in biodiversity analysis for building automatic\nidentification systems that recognize known species and discover unseen\nspecies. Unlike human genome modeling, barcode-based invertebrate\nidentification poses challenges in the vast diversity of species and taxonomic\ncomplexity. Among Transformer-based foundation models, BarcodeBERT excelled in\nspecies-level identification of invertebrates, highlighting the effectiveness\nof self-supervised pretraining on barcode-specific datasets. Recently,\nstructured state space models (SSMs) have emerged, with a time complexity that\nscales sub-quadratically with the context length. SSMs provide an efficient\nparameterization of sequence modeling relative to attention-based\narchitectures. Given the success of Mamba and Mamba-2 in natural language, we\ndesigned BarcodeMamba, a performant and efficient foundation model for DNA\nbarcodes in biodiversity analysis. We conducted a comprehensive ablation study\non the impacts of self-supervised training and tokenization methods, and\ncompared both versions of Mamba layers in terms of expressiveness and their\ncapacity to identify \"unseen\" species held back from training. Our study shows\nthat BarcodeMamba has better performance than BarcodeBERT even when using only\n8.3% as many parameters, and improves accuracy to 99.2% on species-level\naccuracy in linear probing without fine-tuning for \"seen\" species. In our\nscaling study, BarcodeMamba with 63.6% of BarcodeBERT's parameters achieved\n70.2% genus-level accuracy in 1-nearest neighbor (1-NN) probing for unseen\nspecies. The code repository to reproduce our experiments is available at\nhttps:\/\/github.com\/bioscan-ml\/BarcodeMamba.",
    "explanation":"The paper talks about the use of BarcodeMamba for better scores in DNA barcode analysis of genomes.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Biological identifications through DNA barcodes"
    ],
    "b_abstract":[
      "Although much biological research depends upon species diagnoses, taxonomic expertise is collapsing.We are convinced that the sole prospect for a sustainable identification capability lies in construction of systems employ DNA sequences as taxon 'barcodes'.We establish mitochondrial gene cytochrome c oxidase I (COI) can serve core global bioidentification system animals.First, we demonstrate COI profiles, derived from low-density sampling higher categories, ordinarily assign newly analysed taxa to appropriate phylum or order.Second, species-level assignments be obtained by creating comprehensive profiles.A model profile, based analysis single individual each 200 closely allied lepidopterans, was 100% successful correctly identifying subsequent specimens.When fully developed, will provide reliable, cost-effective and accessible solution current problem identification.Its assembly also generate important new insights into diversification life rules molecular evolution."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.15985"
    ],
    "c_title":[
      "Exploring the Reliability of Self-explanation and its Relationship with\n  Classification in Language Model-driven Financial Analysis"
    ],
    "c_abstract":[
      "Language models (LMs) have exhibited exceptional versatility in reasoning and\nin-depth financial analysis through their proprietary information processing\ncapabilities. Previous research focused on evaluating classification\nperformance while often overlooking explainability or pre-conceived that\nrefined explanation corresponds to higher classification accuracy. Using a\npublic dataset in finance domain, we quantitatively evaluated self-explanations\nby LMs, focusing on their factuality and causality. We identified the\nstatistically significant relationship between the accuracy of classifications\nand the factuality or causality of self-explanations. Our study built an\nempirical foundation for approximating classification confidence through\nself-explanations and for optimizing classification via proprietary reasoning."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.11084",
    "a_title":"BarcodeMamba: State Space Models for Biodiversity Analysis",
    "a_abstract":"DNA barcodes are crucial in biodiversity analysis for building automatic\nidentification systems that recognize known species and discover unseen\nspecies. Unlike human genome modeling, barcode-based invertebrate\nidentification poses challenges in the vast diversity of species and taxonomic\ncomplexity. Among Transformer-based foundation models, BarcodeBERT excelled in\nspecies-level identification of invertebrates, highlighting the effectiveness\nof self-supervised pretraining on barcode-specific datasets. Recently,\nstructured state space models (SSMs) have emerged, with a time complexity that\nscales sub-quadratically with the context length. SSMs provide an efficient\nparameterization of sequence modeling relative to attention-based\narchitectures. Given the success of Mamba and Mamba-2 in natural language, we\ndesigned BarcodeMamba, a performant and efficient foundation model for DNA\nbarcodes in biodiversity analysis. We conducted a comprehensive ablation study\non the impacts of self-supervised training and tokenization methods, and\ncompared both versions of Mamba layers in terms of expressiveness and their\ncapacity to identify \"unseen\" species held back from training. Our study shows\nthat BarcodeMamba has better performance than BarcodeBERT even when using only\n8.3% as many parameters, and improves accuracy to 99.2% on species-level\naccuracy in linear probing without fine-tuning for \"seen\" species. In our\nscaling study, BarcodeMamba with 63.6% of BarcodeBERT's parameters achieved\n70.2% genus-level accuracy in 1-nearest neighbor (1-NN) probing for unseen\nspecies. The code repository to reproduce our experiments is available at\nhttps:\/\/github.com\/bioscan-ml\/BarcodeMamba.",
    "explanation":"The paper talks about the use of BarcodeMamba for better scores in DNA barcode analysis of genomes.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "BarcodeBERT: Transformers for Biodiversity Analysis"
    ],
    "b_abstract":[
      "Understanding biodiversity is a global challenge, in which DNA barcodes - short snippets of that cluster by species play pivotal role. In particular, invertebrates, highly diverse and under-explored group, pose unique taxonomic complexities. We explore machine learning approaches, comparing supervised CNNs, fine-tuned foundation models, barcode-specific masking strategy across datasets varying complexity. While simpler tasks favor CNNs or transformers, challenging species-level identification demands paradigm shift towards self-supervised pretraining. propose BarcodeBERT, the first method for general analysis, leveraging 1.5 M invertebrate barcode reference library. This work highlights how dataset specifics coverage impact model selection, underscores role pretraining achieving high-accuracy barcode-based at genus level. Indeed, without fine-tuning step, BarcodeBERT pretrained on large outperforms DNABERT DNABERT-2 multiple downstream classification tasks. The code repository available https:\/\/github.com\/Kari-Genomics-Lab\/BarcodeBERT"
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04869"
    ],
    "c_title":[
      "Transcriptome signature for the identification of bevacizumab responders\n  in ovarian cancer"
    ],
    "c_abstract":[
      "The standard of care for ovarian cancer comprises cytoreductive surgery,\nfollowed by adjuvant platinum-based chemotherapy plus taxane therapy and\nmaintenance therapy with the antiangiogenic compound bevacizumab and\/or a PARP\ninhibitor. Nevertheless, there is currently no clear clinical indication for\nthe use of bevacizumab, highlighting the urgent need for biomarkers to assess\nthe response to bevacizumab. In the present study, based on a novel RNA-seq\ndataset (n=181) and a previously published microarray-based dataset (n=377), we\nhave identified an expression signature potentially associated with benefit\nfrom bevacizumab addition and assumed to reflect cancer stemness acquisition\ndriven by activation of CTCFL. Patients with this signature demonstrated\nimproved overall survival when bevacizumab was added to standard chemotherapy\nin both novel (HR=0.41(0.23-0.74), adj.p-value=7.70e-03) and previously\npublished cohorts (HR=0.51(0.34-0.75), adj.p-value=3.25e-03), while no\nsignificant differences in survival explained by treatment were observed in\npatients negative for this signature. In addition to the CTCFL signature, we\nfound several other reproducible expression signatures which may also represent\nbiomarker candidates not related to established molecular subtypes of ovarian\ncancer and require further validation studies based on additional RNA-seq data."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00609",
    "a_title":"Tumor Location-weighted MRI-Report Contrastive Learning: A Framework for\n  Improving the Explainability of Pediatric Brain Tumor Diagnosis",
    "a_abstract":"Despite the promising performance of convolutional neural networks (CNNs) in\nbrain tumor diagnosis from magnetic resonance imaging (MRI), their integration\ninto the clinical workflow has been limited. That is mainly due to the fact\nthat the features contributing to a model's prediction are unclear to\nradiologists and hence, clinically irrelevant, i.e., lack of explainability. As\nthe invaluable sources of radiologists' knowledge and expertise, radiology\nreports can be integrated with MRI in a contrastive learning (CL) framework,\nenabling learning from image-report associations, to improve CNN\nexplainability. In this work, we train a multimodal CL architecture on 3D brain\nMRI scans and radiology reports to learn informative MRI representations.\nFurthermore, we integrate tumor location, salient to several brain tumor\nanalysis tasks, into this framework to improve its generalizability. We then\napply the learnt image representations to improve explainability and\nperformance of genetic marker classification of pediatric Low-grade Glioma, the\nmost prevalent brain tumor in children, as a downstream task. Our results\nindicate a Dice score of 31.1% between the model's attention maps and manual\ntumor segmentation (as an explainability measure) with test classification\nperformance of 87.7%, significantly outperforming the baselines. These\nenhancements can build trust in our model among radiologists, facilitating its\nintegration into clinical practices for more efficient tumor diagnosis.",
    "explanation":"The article presents a research involving the use of Computer Science methods to treat problems in Medicine. In this case, applying the use of Convolutional Neural Networks (CNN) for the recognition of pediatric tumors in medical images and Contrastive Learning (CL) to improve the explainability of the model.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Pediatric low-grade glioma: State-of-the-art and ongoing challenges"
    ],
    "b_abstract":[
      "Abstract The most common childhood central nervous system (CNS) tumor is pediatric low-grade glioma (pLGG), representing 30%\u201340% of all CNS tumors in children. Although there high associated morbidity, tumor-related mortality relatively rare. pLGG now conceptualized as a chronic disease, underscoring the importance functional outcomes and quality-of-life measures. A wealth data has emerged about these tumors, including better understanding their natural history molecular drivers, paving way for use targeted inhibitors. While treatments have heralded tremendous promise, challenges remain how to best optimize use, long-term toxicities with inhibitors unknown. International Pediatric Low-Grade Glioma Coalition (iPLGGc) global group physicians scientists expertise focused on addressing key issues. Here, iPLGGc provides an overview current state-of-the-art pLGG, epidemiology, histology, landscape, treatment paradigms, survival outcomes, imaging response, ongoing challenges. This paper also serves introduction 3 other manuscripts (1) preclinical models, (2) consensus framework conducting early-phase clinical trials (3) resistance, rebound, recurrence."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.11062"
    ],
    "c_title":[
      "Active Learning from Scene Embeddings for End-to-End Autonomous Driving"
    ],
    "c_abstract":[
      "In the field of autonomous driving, end-to-end deep learning models show\ngreat potential by learning driving decisions directly from sensor data.\nHowever, training these models requires large amounts of labeled data, which is\ntime-consuming and expensive. Considering that the real-world driving data\nexhibits a long-tailed distribution where simple scenarios constitute a\nmajority part of the data, we are thus inspired to identify the most\nchallenging scenarios within it. Subsequently, we can efficiently improve the\nperformance of the model by training with the selected data of the highest\nvalue. Prior research has focused on the selection of valuable data by\nempirically designed strategies. However, manually designed methods suffer from\nbeing less generalizable to new data distributions. Observing that the BEV\n(Bird's Eye View) features in end-to-end models contain all the information\nrequired to represent the scenario, we propose an active learning framework\nthat relies on these vectorized scene-level features, called SEAD. The\nframework selects initial data based on driving-environmental information and\nincremental data based on BEV features. Experiments show that we only need 30\\%\nof the nuScenes training data to achieve performance close to what can be\nachieved with the full dataset. The source code will be released."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00609",
    "a_title":"Tumor Location-weighted MRI-Report Contrastive Learning: A Framework for\n  Improving the Explainability of Pediatric Brain Tumor Diagnosis",
    "a_abstract":"Despite the promising performance of convolutional neural networks (CNNs) in\nbrain tumor diagnosis from magnetic resonance imaging (MRI), their integration\ninto the clinical workflow has been limited. That is mainly due to the fact\nthat the features contributing to a model's prediction are unclear to\nradiologists and hence, clinically irrelevant, i.e., lack of explainability. As\nthe invaluable sources of radiologists' knowledge and expertise, radiology\nreports can be integrated with MRI in a contrastive learning (CL) framework,\nenabling learning from image-report associations, to improve CNN\nexplainability. In this work, we train a multimodal CL architecture on 3D brain\nMRI scans and radiology reports to learn informative MRI representations.\nFurthermore, we integrate tumor location, salient to several brain tumor\nanalysis tasks, into this framework to improve its generalizability. We then\napply the learnt image representations to improve explainability and\nperformance of genetic marker classification of pediatric Low-grade Glioma, the\nmost prevalent brain tumor in children, as a downstream task. Our results\nindicate a Dice score of 31.1% between the model's attention maps and manual\ntumor segmentation (as an explainability measure) with test classification\nperformance of 87.7%, significantly outperforming the baselines. These\nenhancements can build trust in our model among radiologists, facilitating its\nintegration into clinical practices for more efficient tumor diagnosis.",
    "explanation":"The article presents a research involving the use of Computer Science methods to treat problems in Medicine. In this case, applying the use of Convolutional Neural Networks (CNN) for the recognition of pediatric tumors in medical images and Contrastive Learning (CL) to improve the explainability of the model.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Improving Pediatric Low-Grade Neuroepithelial Tumors Molecular Subtype\n  Identification Using a Novel AUROC Loss Function for Convolutional Neural\n  Networks"
    ],
    "b_abstract":[
      "Pediatric Low-Grade Neuroepithelial Tumors (PLGNT) are the most common pediatric cancer type, accounting for 40% of brain tumors in children, and identifying PLGNT molecular subtype is crucial treatment planning. However, gold standard to determine biopsy, which can be impractical or dangerous patients. This research improves performance Convolutional Neural Networks (CNNs) classifying subtypes through MRI scans by introducing a loss function that specifically model's Area Under Receiver Operating Characteristic (ROC) Curve (AUROC), offering non-invasive diagnostic alternative. In this study, retrospective dataset 339 children with (143 BRAF fusion, 71 V600E mutation, 125 non-BRAF) was curated. We employed CNN model Monte Carlo random data splitting. The baseline trained using binary cross entropy (BCE), achieved an AUROC 86.11% differentiating fusion mutations, improved 87.71% our proposed (p-value 0.045). With multiclass classification, from 74.42% 76. 59% 0.0016)."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.12092"
    ],
    "c_title":[
      "Using economic value signals from primate prefrontal cortex in\n  neuro-engineering applications"
    ],
    "c_abstract":[
      "Neural signals related to movement can be measured from intracranial\nrecordings and used in brain-machine interface devices (BMI) to restore\nphysical function in impaired patients. In this study, we explore the use of\nmore abstract neural signals related to economic value in a BMI context. Using\ndata collected from the orbitofrontal cortex in non-human primates, we develop\ndeep learning-based neural decoders that can predict the monkey's choice in a\nvalue-based decision-making task. Out-of-sample performance was improved by\naugmenting the training set with synthesized data, showing the feasibility of\nusing limited training data. We further demonstrate that we can predict the\nmonkey's choice sooner using a neural forecasting module that is equipped with\ntask-related information. These findings support the feasibility of user\npreference-informed neuroengineering devices that leverage abstract cognitive\nsignals."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00726",
    "a_title":"Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading\n  with Cataract",
    "a_abstract":"Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a\ncommon complication of diabetes. As two different imaging tools for DR grading,\ncolor fundus photography (CFP) and infrared fundus photography (IFP) are\nhighly-correlated and complementary in clinical applications. To the best of\nour knowledge, this is the first study that explores a novel multi-modal deep\nlearning framework to fuse the information from CFP and IFP towards more\naccurate DR grading. Specifically, we construct a dual-stream architecture\nCross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus\nimage modalities. In particular, a meticulously engineered Cross-Fundus\nAttention (CFA) module is introduced to capture the correspondence between CFP\nand IFP images. Moreover, we adopt both the single-modality and multi-modality\nsupervisions to maximize the overall performance for DR grading. Extensive\nexperiments on a clinical dataset consisting of 1,713 pairs of multi-modal\nfundus images demonstrate the superiority of our proposed method. Our code will\nbe released for public access.",
    "explanation":"The work combines transformers with two distinct methods that evaluate the quality of retinopathy",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Relation Between Retinal Vasculature and Retinal Thickness in Macular Edema"
    ],
    "b_abstract":[
      "This study has investigated the relationship of retinal vasculature and thickness for Macular Edema (ME) subjects. Ninety sets Fluorescein Angiograph (FA) Optical Coherence Tomography (OCT) 54 participants were analyzed. Multivariate analysis using binary logistic regression model was used to association between vessel parameters thickness. The results reveal feature i.e. fractal dimension (FD) as most sensitive parameter changes in associated with ME. Thus, indicating a direct which is caused due neovascular causing exudates, leakages hemorrhages, applications alternate modality detection"
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.06501"
    ],
    "c_title":[
      "Learning Clustering-based Prototypes for Compositional Zero-shot\n  Learning"
    ],
    "c_abstract":[
      "Learning primitive (i.e., attribute and object) concepts from seen\ncompositions is the primary challenge of Compositional Zero-Shot Learning\n(CZSL). Existing CZSL solutions typically rely on oversimplified data\nassumptions, e.g., modeling each primitive with a single centroid primitive\nrepresentation, ignoring the natural diversities of the attribute (resp.\nobject) when coupled with different objects (resp. attribute). In this work, we\ndevelop ClusPro, a robust clustering-based prototype mining framework for CZSL\nthat defines the conceptual boundaries of primitives through a set of\ndiversified prototypes. Specifically, ClusPro conducts within-primitive\nclustering on the embedding space for automatically discovering and dynamically\nupdating prototypes. These representative prototypes are subsequently used to\nrepaint a well-structured and independent primitive embedding space, ensuring\nintra-primitive separation and inter-primitive decorrelation through\nprototype-based contrastive learning and decorrelation learning. Moreover,\nClusPro efficiently performs prototype clustering in a non-parametric fashion\nwithout the introduction of additional learnable parameters or computational\nbudget during testing. Experiments on three benchmarks demonstrate ClusPro\noutperforms various top-leading CZSL solutions under both closed-world and\nopen-world settings."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00726",
    "a_title":"Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading\n  with Cataract",
    "a_abstract":"Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a\ncommon complication of diabetes. As two different imaging tools for DR grading,\ncolor fundus photography (CFP) and infrared fundus photography (IFP) are\nhighly-correlated and complementary in clinical applications. To the best of\nour knowledge, this is the first study that explores a novel multi-modal deep\nlearning framework to fuse the information from CFP and IFP towards more\naccurate DR grading. Specifically, we construct a dual-stream architecture\nCross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus\nimage modalities. In particular, a meticulously engineered Cross-Fundus\nAttention (CFA) module is introduced to capture the correspondence between CFP\nand IFP images. Moreover, we adopt both the single-modality and multi-modality\nsupervisions to maximize the overall performance for DR grading. Extensive\nexperiments on a clinical dataset consisting of 1,713 pairs of multi-modal\nfundus images demonstrate the superiority of our proposed method. Our code will\nbe released for public access.",
    "explanation":"The work combines transformers with two distinct methods that evaluate the quality of retinopathy",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    ],
    "b_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.11130"
    ],
    "c_title":[
      "Advanced 3D-Printed Multiphasic Scaffold with Optimal PRP Dosage for\n  Chondrogenesis of BM-MSCs in Osteochondral Tissue Engineering"
    ],
    "c_abstract":[
      "In osteochondral tissue engineering (OCTE), simultaneously regenerating\nsubchondral bone and cartilage tissue presents a significant challenge.\nMultiphasic scaffolds were created and manufactured using 3D printing to\naddress this issue. Excellent interfacial mechanical properties and\nbiocompatibility enhance the growth and chondrogenic differentiation of bone\nmarrow mesenchymal stem cells (BM-MSCs). The subchondral bone bottom layer is\nmimicked by incorporating varying concentrations of graphene oxide (GO) (0%,\n1%, and 2% w\/v) into a bioink composed of alginate (Alg) and gelatin (Gel).\nBased on evaluations of mechanical and biocompatibility properties, 1% GO is\nselected for further studies. Subsequently, the GO concentration is kept\nconstant while varying the platelet-rich plasma (PRP) dosage in the multiphasic\nscaffolds. Different PRP dosages (0%, 1%, 2%, and 3% w\/v) are integrated into\nthe Alg-Gel bioink to simulate cartilage tissues. Results indicate that\n3D-printed scaffolds containing 1% or 2% PRP exhibit favorable biomechanical\nproperties, with no significant differences observed. However, BM-MSCs exposed\nto 2% PRP demonstrate enhanced adhesion, growth, and viability. Additionally,\nreal-time PCR and Alcian blue staining confirm increased chondrogenic\nexpression and glycosaminoglycans (GAGs) synthesis. This work highlights the\npromising potential of 3D-printed multiphasic frameworks in the development of\nOCTE."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05236",
    "a_title":"Designing a Light-based Communication System with a Biomolecular\n  Receiver",
    "a_abstract":"Biological systems transduce signals from their surroundings in numerous\nways. This paper introduces a communication system using the light-gated ion\nchannel Channelrhodopsin-2 (ChR2), which causes an ion current to flow in\nresponse to light. Our design includes a ChR2-based receiver along with\nencoding, modulation techniques and detection. Analyzing the resulting\ncommunication system, we discuss the effect of different parameters on the\nperformance of the system. Finally, we discuss its potential design in the\ncontext of bio-engineering and light-based communication and show that the data\nrate scales up with the number of receptors, indicating that high-speed\ncommunication may be possible.",
    "explanation":"The paper is interdisciplinary because it aims to use channelrhodopsin-2 (ChR2), a biomolecule, as a receiver to design a light-based communication system, which is a work related to engineering.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Channelrhodopsin-2, a directly light-gated cation-selective membrane channel"
    ],
    "b_abstract":[
      "Microbial-type rhodopsins are found in archaea, prokaryotes, and eukaryotes. Some of them represent membrane ion transport proteins such as bacteriorhodopsin, a light-driven proton pump, or channelrhodopsin-1 (ChR1), recently identified light-gated channel from the green alga Chlamydomonas reinhardtii . ChR1 ChR2, related microbial-type rhodopsin C. , were shown to be involved generation photocurrents this alga. We demonstrate by functional expression, both oocytes Xenopus laevis mammalian cells, that ChR2 is directly light-switched cation-selective channel. This opens rapidly after absorption photon generate large permeability for monovalent divalent cations. desensitizes continuous light smaller steady-state conductance. Recovery desensitization accelerated extracellular H + negative potential, whereas closing decelerated intracellular expressed mainly under low-light conditions, suggesting involvement photoreception dark-adapted cells. The predicted seven-transmembrane \u03b1 helices characteristic G protein-coupled receptors but reflect different motif Finally, we may used depolarize small simply illumination."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.02782"
    ],
    "c_title":[
      "A Comprehensive Survey on Feature Extraction Techniques Using I\/Q\n  Imbalance in RFFI"
    ],
    "c_abstract":[
      "The proliferation of Internet of Things (IoT) devices has increased the need\nfor secure authentication. While traditional encryption-based solutions can be\nrobust, they often impose high computational and energy overhead on\nresource-limited IoT nodes. As an alternative, radio frequency fingerprint\nidentification (RFFI) leverages hardware-induced imperfections-such as\nInphase\/Quadrature (I\/Q) imbalance-in Radio Frequency (RF) front-end components\nas unique identifiers that are inherently difficult to clone or spoof. Despite\nrecent advances, significant challenges remain in standardizing feature\nextraction methods, maintaining high accuracy across diverse environments, and\nefficiently handling large-scale IoT deployments. This paper addresses these\ngaps by providing a comprehensive review of feature extraction techniques that\nutilize I\/Q imbalance for RFFI. We also discuss other hardware-based RF\nfingerprinting sources, including power amplifier nonlinearity and oscillator\nimperfections, and examine modern machine learning (ML) and deep learning (DL)\napproaches that enhance device identification performance."
    ],
    "c_categories":[
      "eess.SP"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05236",
    "a_title":"Designing a Light-based Communication System with a Biomolecular\n  Receiver",
    "a_abstract":"Biological systems transduce signals from their surroundings in numerous\nways. This paper introduces a communication system using the light-gated ion\nchannel Channelrhodopsin-2 (ChR2), which causes an ion current to flow in\nresponse to light. Our design includes a ChR2-based receiver along with\nencoding, modulation techniques and detection. Analyzing the resulting\ncommunication system, we discuss the effect of different parameters on the\nperformance of the system. Finally, we discuss its potential design in the\ncontext of bio-engineering and light-based communication and show that the data\nrate scales up with the number of receptors, indicating that high-speed\ncommunication may be possible.",
    "explanation":"The paper is interdisciplinary because it aims to use channelrhodopsin-2 (ChR2), a biomolecule, as a receiver to design a light-based communication system, which is a work related to engineering.",
    "b_id":[
      "b2",
      "b0"
    ],
    "b_title":[
      "Shannon capacity of signal transduction for multiple independent receptors",
      "DESIGN AND IMPLEMENTATION OF VISIBLE LIGHT COMMUNICATION SYSTEM IN INDOOR ENVIRONMENT"
    ],
    "b_abstract":[
      "Cyclic adenosine monophosphate (cAMP) is considered a model system for signal transduction, the mechanism by which cells exchange chemical messages. Our previous work calculated Shannon capacity of single cAMP receptor; however, typical cell may have thousands receptors operating in parallel. In this paper, we calculate transduction with an arbitrary number independent, indistinguishable receptors. By leveraging prior results on feedback receptor, show (somewhat unexpectedly) that achieved IID input distribution, and n times receptor.",
      "Visible Light communication (VLC) using White Light Emitting Diode (LED) is a promising technology for next generation communication for short range, high speed wireless data transmission. In this paper inexpensive transmitter and receiver of VLC system is designed and its performance is evaluated. The effect of natural and artificial ambient light noise sources is also considered. Experimental results show that the data transmission distance achieved upto 0.45m.Performance analysis is done with respect to optical power, photo sensitivity of photodiode at the receiver and the increase in distance between the transmitter and receiver."
    ],
    "b_categories":[
      "cs.SY",
      "eess.SP"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04258"
    ],
    "c_title":[
      "How Large is the Universe of RNA-Like Motifs? A Clustering Analysis of\n  RNA Graph Motifs Using Topological Descriptors"
    ],
    "c_abstract":[
      "We introduce a computational topology-based approach with unsupervised\nmachine-learning algorithms to estimate the database size and content of\nRNA-like graph topologies. Specifically, we apply graph theory enumeration to\ngenerate all 110,667 possible 2D dual graphs for vertex numbers ranging from 2\nto 9. Among them, only 0.11% graphs correspond to approximately 200,000 known\nRNA atomic fragments (collected in 2021) using the RNA-as-Graphs (RAG) mapping\nmethod. The remaining 99.89% of the dual graphs may be RNA-like or\nnon-RNA-like. To determine which dual graphs in the 99.89% hypothetical set are\nmore likely to be associated with RNA structures, we apply computational\ntopology descriptors using the Persistent Spectral Graphs (PSG) method to\ncharacterize each graph using 19 PSG-based features and use clustering\nalgorithms that partition all possible dual graphs into two clusters, RNA-like\ncluster and non-RNA-like cluster. The distance of each dual graph to the center\nof the RNA-like cluster represents the likelihood of it belonging to RNA\nstructures. From validation, our PSG-based RNA-like cluster includes 97.3% of\nthe 121 known RNA dual graphs, suggesting good performance. Furthermore,\n46.017% of the hypothetical RNAs are predicted to be RNA-like. Significantly,\nwe observe that all the top 15 RNA-like dual graphs can be separated into\nmultiple subgraphs, whereas the top 15 non-RNA-like dual graphs tend not to\nhave any subgraphs. Moreover, a significant topological difference between top\nRNA-like and non-RNA-like graphs is evident when comparing their topological\nfeatures. These findings provide valuable insights into the size of the RNA\nmotif universe and RNA design strategies, offering a novel framework for\npredicting RNA graph topologies and guiding the discovery of novel RNA motifs,\nperhaps anti-viral therapeutics by subgraph assembly."
    ],
    "c_categories":[
      "q-bio.BM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.02815",
    "a_title":"Artificial Intelligence-Enhanced Couinaud Segmentation for Precision\n  Liver Cancer Therapy",
    "a_abstract":"Precision therapy for liver cancer necessitates accurately delineating liver\nsub-regions to protect healthy tissue while targeting tumors, which is\nessential for reducing recurrence and improving survival rates. However, the\nsegmentation of hepatic segments, known as Couinaud segmentation, is\nchallenging due to indistinct sub-region boundaries and the need for extensive\nannotated datasets. This study introduces LiverFormer, a novel Couinaud\nsegmentation model that effectively integrates global context with low-level\nlocal features based on a 3D hybrid CNN-Transformer architecture. Additionally,\na registration-based data augmentation strategy is equipped to enhance the\nsegmentation performance with limited labeled data. Evaluated on CT images from\n123 patients, LiverFormer demonstrated high accuracy and strong concordance\nwith expert annotations across various metrics, allowing for enhanced treatment\nplanning for surgery and radiation therapy. It has great potential to reduces\ncomplications and minimizes potential damages to surrounding tissue, leading to\nimproved outcomes for patients undergoing complex liver cancer treatments.",
    "explanation":"The paper presents a tool that uses Convolutional Neural Networks (CNN) and Transformers, technologies from Computer Science, to improve the accuracy and efficiency of Couinaud segmentation in liver cancer treatment, a challenge in the field of Medicine.",
    "b_id":[
      "b36",
      "b33"
    ],
    "b_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "Automated segmentation of liver segment on portal venous phase MR images using a 3D convolutional neural network"
    ],
    "b_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train.",
      "We aim to develop and validate a three-dimensional convolutional neural network (3D-CNN) model for automatic liver segment segmentation on MRI images.This retrospective study evaluated an automated method using deep that was trained, validated, tested with 367, 157, 158 portal venous phase MR images, respectively. The Dice similarity coefficient (DSC), mean surface distance (MSD), Hausdorff (HD), volume ratio (RV) were used quantitatively measure the accuracy of segmentation. time consumed manual also compared. In addition, applied 100 consecutive cases from real clinical scenario qualitative evaluation indirect evaluation.In quantitative evaluation, achieved high DSC, MSD, HD RV (0.920, 3.34, 3.61 1.01, respectively). Compared segmentation, reduced 26 min 8 s. quality rated as good in 79% cases, moderate 15% poor 6%. 93.4% (99\/106) lesions could be assigned correct by only referring results segmentation.The proposed may serve effective tool anatomical region annotation images."
    ],
    "b_categories":[
      "cs.CV",
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.18661"
    ],
    "c_title":[
      "Geometric immunosuppression in CAR-T cell treatment: Insights from\n  mathematical modeling"
    ],
    "c_abstract":[
      "Chimeric antigen receptor T (CAR-T) cell therapy has emerged as a promising\ntreatment for hematological malignancies, offering a targeted approach to\ncancer treatment. Understanding the complexities of CAR-T cell therapy within\nsolid tumors poses challenges due to the intricate interactions within the\ntumor microenvironment. Mathematical modeling may serve as a valuable tool to\nunravel the dynamics of CAR-T cell therapy and improve its effectiveness in\nsolid tumors. This study aimed to investigate the impact of spatial aspects in\nCAR-T therapy of solid tumors, utilizing cellular automata for modeling\npurposes. Our main objective was to deepen our understanding of treatment\neffects by analyzing scenarios with different spatial distributions and varying\nthe initial quantities of tumor and CAR-T cells. Tumor geometry significantly\ninfluenced treatment efficacy in-silico, with notable differences observed\nbetween tumors with block-like arrangements and those with sparse cell\ndistributions, leading to the concept of immune suppression due to geometrical\neffects. This research delves into the intricate relationship between spatial\ndynamics and the effectiveness of CAR-T therapy in solid tumors, highlighting\nthe relevance of tumor geometry in the outcome of cellular immunotherapy\ntreatments. Our results provide a basis for improving the efficacy of CAR-T\ncell treatments by combining them with other ones reducing the density of\ncompact tumor areas and thus opening access ways for tumor killing T-cells."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.02815",
    "a_title":"Artificial Intelligence-Enhanced Couinaud Segmentation for Precision\n  Liver Cancer Therapy",
    "a_abstract":"Precision therapy for liver cancer necessitates accurately delineating liver\nsub-regions to protect healthy tissue while targeting tumors, which is\nessential for reducing recurrence and improving survival rates. However, the\nsegmentation of hepatic segments, known as Couinaud segmentation, is\nchallenging due to indistinct sub-region boundaries and the need for extensive\nannotated datasets. This study introduces LiverFormer, a novel Couinaud\nsegmentation model that effectively integrates global context with low-level\nlocal features based on a 3D hybrid CNN-Transformer architecture. Additionally,\na registration-based data augmentation strategy is equipped to enhance the\nsegmentation performance with limited labeled data. Evaluated on CT images from\n123 patients, LiverFormer demonstrated high accuracy and strong concordance\nwith expert annotations across various metrics, allowing for enhanced treatment\nplanning for surgery and radiation therapy. It has great potential to reduces\ncomplications and minimizes potential damages to surrounding tissue, leading to\nimproved outcomes for patients undergoing complex liver cancer treatments.",
    "explanation":"The paper presents a tool that uses Convolutional Neural Networks (CNN) and Transformers, technologies from Computer Science, to improve the accuracy and efficiency of Couinaud segmentation in liver cancer treatment, a challenge in the field of Medicine.",
    "b_id":[
      "b13"
    ],
    "b_title":[
      "Liver Anatomy: Portal (and Suprahepatic) or Biliary Segmentation"
    ],
    "b_abstract":[
      "In liver anatomy and surgery, is portal hepatic vein segmentation (French segmentation) to be preferred over arteriobiliary (Healey Schroy, North American segmentation)?Several embryological arguments an analysis of anatomical data from a personal collection 110 vasculobiliary casts were made.Embryological arguments: Portal branching appears first, secondly follows the distribution. Segment II (the left lateral sector) development right lobe. The umbilical enters portion middle lobe, forming segment IV on III left: this paramedian sector. So fissure (between lobes) transversally crosses classical which not unit. VI late secondary prominence VII, reaching anterior margin only in man. Anatomical must added segmentation; academic lobe sector, separates lobes. preferred: duplication branches first order occurs 23.5% cases, while first-order noted 50% livers, being much simpler.Portal seems more accurate."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.16065"
    ],
    "c_title":[
      "CILP-FGDI: Exploiting Vision-Language Model for Generalizable Person\n  Re-Identification"
    ],
    "c_abstract":[
      "The Visual Language Model, known for its robust cross-modal capabilities, has\nbeen extensively applied in various computer vision tasks. In this paper, we\nexplore the use of CLIP (Contrastive Language-Image Pretraining), a\nvision-language model pretrained on large-scale image-text pairs to align\nvisual and textual features, for acquiring fine-grained and domain-invariant\nrepresentations in generalizable person re-identification. The adaptation of\nCLIP to the task presents two primary challenges: learning more fine-grained\nfeatures to enhance discriminative ability, and learning more domain-invariant\nfeatures to improve the model's generalization capabilities. To mitigate the\nfirst challenge thereby enhance the ability to learn fine-grained features, a\nthree-stage strategy is proposed to boost the accuracy of text descriptions.\nInitially, the image encoder is trained to effectively adapt to person\nre-identification tasks. In the second stage, the features extracted by the\nimage encoder are used to generate textual descriptions (i.e., prompts) for\neach image. Finally, the text encoder with the learned prompts is employed to\nguide the training of the final image encoder. To enhance the model's\ngeneralization capabilities to unseen domains, a bidirectional guiding method\nis introduced to learn domain-invariant image features. Specifically,\ndomain-invariant and domain-relevant prompts are generated, and both positive\n(pulling together image features and domain-invariant prompts) and negative\n(pushing apart image features and domain-relevant prompts) views are used to\ntrain the image encoder. Collectively, these strategies contribute to the\ndevelopment of an innovative CLIP-based framework for learning fine-grained\ngeneralized features in person re-identification."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00561",
    "a_title":"Automated Classification of Cell Shapes: A Comparative Evaluation of\n  Shape Descriptors",
    "a_abstract":"This study addresses the challenge of classifying cell shapes from noisy\ncontours, such as those obtained through cell instance segmentation of\nhistological images. We assess the performance of various features for shape\nclassification, including Elliptical Fourier Descriptors, curvature features,\nand lower dimensional representations. Using an annotated synthetic dataset of\nnoisy contours, we identify the most suitable shape descriptors and apply them\nto a set of real images for qualitative analysis. Our aim is to provide a\ncomprehensive evaluation of descriptors for classifying cell shapes, which can\nsupport cell type identification and tissue characterization-critical tasks in\nboth biological research and histopathological assessments.",
    "explanation":"This study addresses the challenge of classifying cell shapes from noisy contours, such as those obtained through cell instance segmentation of histological images.\n\nOur aim is to provide a comprehensive evaluation of descriptors for classifying cell shapes, which can support cell type identification and tissue characterization\u2014critical tasks in both biological research and histopathological assessments.\n",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "Retrieval and classification of shape-based objects using Fourier, generic Fourier, and wavelet-Fourier descriptors technique: A comparative study"
    ],
    "b_abstract":[
      "In this paper, we report retrieval and classification of shape-based objects employing three techniques-conventional Fourier descriptors (FD), generic Fourier descriptors (GFD) and wavelet-Fourier descriptors (WFD) techniques. All the three techniques have been applied to a database of seven different types of shapes. The centroid distance based shape signatures have been used for the derivation of descriptors. The Euclidean distance has been calculated as a similarity measure parameter for shape classification. For WFD technique, a Mexican-hat wavelet function was used. Classification results from all the three techniques were compared and it was observed that WFD performs better than FD and GFD technique. To study the effect of the noise on the retrieval and classification of shapes of different objects, additive and multiplicative noise of various variances were applied to the database. Precision and recall were also measured as parameters of performance metric."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.05607"
    ],
    "c_title":[
      "Prediction of Binding Affinity for ErbB Inhibitors Using Deep Neural\n  Network Model with Morgan Fingerprints as Features"
    ],
    "c_abstract":[
      "The ErbB receptor family, including EGFR and HER2, plays a crucial role in\ncell growth and survival and is associated with the progression of various\ncancers such as breast and lung cancer. In this study, we developed a deep\nlearning model to predict the binding affinity of ErbB inhibitors using\nmolecular fingerprints derived from SMILES representations. The SMILES\nrepresentations for each ErbB inhibitor were obtained from the ChEMBL database.\nWe first generated Morgan fingerprints from the SMILES strings and applied\nAutoDock Vina docking to calculate the binding affinity values. After filtering\nthe dataset based on binding affinity, we trained a deep neural network (DNN)\nmodel to predict binding affinity values from the molecular fingerprints. The\nmodel achieved significant performance, with a Mean Squared Error (MSE) of\n0.2591, Mean Absolute Error (MAE) of 0.3658, and an R-squared value of 0.9389\non the training set. Although performance decreased slightly on the test set (R\nsquared = 0.7731), the model still demonstrated robust generalization\ncapabilities. These results indicate that the deep learning approach is highly\neffective for predicting the binding affinity of ErbB inhibitors, offering a\nvaluable tool for virtual screening and drug discovery."
    ],
    "c_categories":[
      "q-bio.BM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00561",
    "a_title":"Automated Classification of Cell Shapes: A Comparative Evaluation of\n  Shape Descriptors",
    "a_abstract":"This study addresses the challenge of classifying cell shapes from noisy\ncontours, such as those obtained through cell instance segmentation of\nhistological images. We assess the performance of various features for shape\nclassification, including Elliptical Fourier Descriptors, curvature features,\nand lower dimensional representations. Using an annotated synthetic dataset of\nnoisy contours, we identify the most suitable shape descriptors and apply them\nto a set of real images for qualitative analysis. Our aim is to provide a\ncomprehensive evaluation of descriptors for classifying cell shapes, which can\nsupport cell type identification and tissue characterization-critical tasks in\nboth biological research and histopathological assessments.",
    "explanation":"This study addresses the challenge of classifying cell shapes from noisy contours, such as those obtained through cell instance segmentation of histological images.\n\nOur aim is to provide a comprehensive evaluation of descriptors for classifying cell shapes, which can support cell type identification and tissue characterization\u2014critical tasks in both biological research and histopathological assessments.\n",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "What is a cell type, really? The quest to categorize life's myriad forms."
    ],
    "b_abstract":[
      "The problem of cell type became clear to genome biologist Jason Buenrostro in 2013. He was studying a cell line derived from someone with cancer, trying to map out how the DNA was arranged in the nucleus. The cells should have been pretty much identical, he thought. But the more Buenrostro looked at the DNA, the more differences he found in how it was packaged1. \u201cI realized that there were probably hundreds of flavours,\u201d recalls Buenrostro, who was a graduate student at Stanford University in California at the time."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.03137"
    ],
    "c_title":[
      "L2R: Learning to Reduce Search Space for Generalizable Neural Routing\n  Solver"
    ],
    "c_abstract":[
      "Constructive neural combinatorial optimization (NCO) has attracted growing\nresearch attention due to its ability to solve complex routing problems without\nrelying on handcrafted rules. However, existing NCO methods face significant\nchallenges in generalizing to large-scale problems due to high computational\ncomplexity and inefficient capture of structural patterns. To address this\nissue, we propose a novel learning-based search space reduction method that\nadaptively selects a small set of promising candidate nodes at each step of the\nconstructive NCO process. Unlike traditional methods that rely on fixed\nheuristics, our selection model dynamically prioritizes nodes based on learned\npatterns, significantly reducing the search space while maintaining solution\nquality. Experimental results demonstrate that our method, trained solely on\n100-node instances from uniform distribution, generalizes remarkably well to\nlarge-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing\nProblem (CVRP) instances with up to 1 million nodes from the uniform\ndistribution and over 80K nodes from other distributions."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00922",
    "a_title":"Lung tumor segmentation in MRI mice scans using 3D nnU-Net with minimum\n  annotations",
    "a_abstract":"In drug discovery, accurate lung tumor segmentation is an important step for\nassessing tumor size and its progression using \\textit{in-vivo} imaging such as\nMRI. While deep learning models have been developed to automate this process,\nthe focus has predominantly been on human subjects, neglecting the pivotal role\nof animal models in pre-clinical drug development. In this work, we focus on\noptimizing lung tumor segmentation in mice. First, we demonstrate that the\nnnU-Net model outperforms the U-Net, U-Net3+, and DeepMeta models. Most\nimportantly, we achieve better results with nnU-Net 3D models than 2D models,\nindicating the importance of spatial context for segmentation tasks in MRI mice\nscans. This study demonstrates the importance of 3D input over 2D input images\nfor lung tumor segmentation in MRI scans. Finally, we outperform the prior\nstate-of-the-art approach that involves the combined segmentation of lungs and\ntumors within the lungs. Our work achieves comparable results using only lung\ntumor annotations requiring fewer annotations, saving time and annotation\nefforts. This work\n(https:\/\/anonymous.4open.science\/r\/lung-tumour-mice-mri-64BB) is an important\nstep in automating pre-clinical animal studies to quantify the efficacy of\nexperimental drugs, particularly in assessing tumor changes.",
    "explanation":"In this work, we focus on optimizing lung tumor segmen-\ntation in mice. First, we demonstrate that the nnU-Net model outper-\nforms the U-Net, U-Net3+, and DeepMeta models.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Deep learning model for automatic segmentation of lungs and pulmonary metastasis in small animal MR images"
    ],
    "b_abstract":[
      "Lungs are the most frequent site of metastases growth. The amount and size pulmonary acquired from MRI imaging data important criteria to assess efficacy new drugs in preclinical models. While efficient solutions both for MR downstream automatic segmentation have been proposed human patients, lung animal models remains challenging due physiological motion (respiratory cardiac movements), low protons this organ particular challenge precise metastases. As a consequence post-mortem analysis is currently required obtain information on metastatic volume. In work, we developed complete methodological pipeline automated lungs mice, consisting an sequence image acquisition deep learning method On one hand, optimized mouse with high contrast detection sensitivity. other hand DeepMeta, multiclass U-Net 3+ model automatically segment images. To if able provide accurate metastases, longitudinally imaged mice fast- slow-growing metastasis. Fifty-five balb\/c were injected two different derivatives renal carcinoma cells. Mice SG-bSSFP (self-gated balanced steady state free precession) at time points after injection cancer Both segmentations manually performed by experts. DeepMeta was trained perform based resulting ground truth annotations. Volumes as well number per measured separate test dataset Thanks SG method, 3D bSSFP images artifact-free, enabling serial follow-up Moreover, accurately soon they reached volume \u223c0.02mm3 . Thus distinguish groups terms slow versus fast patterns growth We shown that our methodology combining learning, enables processing whole thus viable alternative histology alone."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.21130"
    ],
    "c_title":[
      "Fast and Accurate Gigapixel Pathological Image Classification with\n  Hierarchical Distillation Multi-Instance Learning"
    ],
    "c_abstract":[
      "Although multi-instance learning (MIL) has succeeded in pathological image\nclassification, it faces the challenge of high inference costs due to\nprocessing numerous patches from gigapixel whole slide images (WSIs). To\naddress this, we propose HDMIL, a hierarchical distillation multi-instance\nlearning framework that achieves fast and accurate classification by\neliminating irrelevant patches. HDMIL consists of two key components: the\ndynamic multi-instance network (DMIN) and the lightweight instance\npre-screening network (LIPN). DMIN operates on high-resolution WSIs, while LIPN\noperates on the corresponding low-resolution counterparts. During training,\nDMIN are trained for WSI classification while generating attention-score-based\nmasks that indicate irrelevant patches. These masks then guide the training of\nLIPN to predict the relevance of each low-resolution patch. During testing,\nLIPN first determines the useful regions within low-resolution WSIs, which\nindirectly enables us to eliminate irrelevant regions in high-resolution WSIs,\nthereby reducing inference time without causing performance degradation. In\naddition, we further design the first Chebyshev-polynomials-based\nKolmogorov-Arnold classifier in computational pathology, which enhances the\nperformance of HDMIL through learnable activation layers. Extensive experiments\non three public datasets demonstrate that HDMIL outperforms previous\nstate-of-the-art methods, e.g., achieving improvements of 3.13% in AUC while\nreducing inference time by 28.6% on the Camelyon16 dataset."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00922",
    "a_title":"Lung tumor segmentation in MRI mice scans using 3D nnU-Net with minimum\n  annotations",
    "a_abstract":"In drug discovery, accurate lung tumor segmentation is an important step for\nassessing tumor size and its progression using \\textit{in-vivo} imaging such as\nMRI. While deep learning models have been developed to automate this process,\nthe focus has predominantly been on human subjects, neglecting the pivotal role\nof animal models in pre-clinical drug development. In this work, we focus on\noptimizing lung tumor segmentation in mice. First, we demonstrate that the\nnnU-Net model outperforms the U-Net, U-Net3+, and DeepMeta models. Most\nimportantly, we achieve better results with nnU-Net 3D models than 2D models,\nindicating the importance of spatial context for segmentation tasks in MRI mice\nscans. This study demonstrates the importance of 3D input over 2D input images\nfor lung tumor segmentation in MRI scans. Finally, we outperform the prior\nstate-of-the-art approach that involves the combined segmentation of lungs and\ntumors within the lungs. Our work achieves comparable results using only lung\ntumor annotations requiring fewer annotations, saving time and annotation\nefforts. This work\n(https:\/\/anonymous.4open.science\/r\/lung-tumour-mice-mri-64BB) is an important\nstep in automating pre-clinical animal studies to quantify the efficacy of\nexperimental drugs, particularly in assessing tumor changes.",
    "explanation":"In this work, we focus on optimizing lung tumor segmen-\ntation in mice. First, we demonstrate that the nnU-Net model outper-\nforms the U-Net, U-Net3+, and DeepMeta models.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "b_abstract":[
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.01319"
    ],
    "c_title":[
      "Photodynamic, UV-curable and fibre-forming polyvinyl alcohol derivative\n  with broad processability and staining-free antibacterial capability"
    ],
    "c_abstract":[
      "Antimicrobial photodynamic therapy (APDT) is a promising antibiotic-free\nstrategy for broad-spectrum infection control in chronic wounds, minimising\nbacterial resistance risks. However, rapid photosensitiser diffusion, tissue\nstaining, side toxicity, and short-lived antimicrobial effects present\nsignificant clinical limitations for integrating APDT into wound dressings. To\naddress these challenges, we present the design of a bespoke polyvinyl alcohol\n(PVA) derivative conjugated with both phenothiazine and methacrylate\nfunctionalities, enabling staining-free antibacterial photodynamic effects,\ncellular tolerability and processability into various wound dressing formats,\nincluding films, textile fibres and nanoscale coatings. Tosylation of PVA is\nleveraged for the covalent coupling of toluidine blue, as confirmed by UV-Vis\nspectroscopy and the minimal release of TB in vitro. UV-induced network\nformation is exploited to accomplish cast films and nanoscale integrated wound\ndressing coatings. UV curing is also successfully coupled with an in-house wet\nspinning process to realise individual, water-insoluble fibres as the building\nblocks of fibrous wound dressings. A fluorometric assay supports the generation\nof reactive oxygen species when the UV-cured samples are exposed to work, but\nnot UV, light, yielding a mean log10 reduction of up to 2.13 in S. aureus, and\nthe complete eradication of P. aeruginosa. Direct and extract cytotoxicity\ntests with UV-cured films and fibres demonstrate the viability of L929\nfibroblasts following 60-min light irradiation and 72-hour cell culture. The\nbespoke molecular architecture, broad processability and cellular tolerability\nof this PVA derivative are highly attractive aiming to integrate durable\nstaining-free photodynamic capability in a wide range of healthcare\ntechnologies, from chronic wound dressings up to minimally invasive localised\ntherapy."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03522",
    "a_title":"Exploring the Potentials and Challenges of Using Large Language Models\n  for the Analysis of Transcriptional Regulation of Long Non-coding RNAs",
    "a_abstract":"Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.",
    "explanation":"Given the tremendous success of large language mod-\nels (LLMs) in capturing complex dependencies in sequential data, this study aims to systematically explore the potential and limitations of LLMs in the sequence analysis related to the transcriptional regulation of lncRNA genes. ",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Language Models are Few-Shot Learners"
    ],
    "b_abstract":[
      "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training a large corpus of text followed fine-tuning specific task. While typically task-agnostic in architecture, this method still requires task-specific datasets thousands or tens examples. By contrast, humans can generally perform new language task from only few examples simple instructions - something which current systems largely struggle to do. Here we show that scaling up models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art approaches. Specifically, train GPT-3, an autoregressive model 175 billion parameters, 10x more than any previous non-sparse model, test its performance the setting. For all tasks, GPT-3 is applied without gradient updates fine-tuning, demonstrations specified purely via interaction model. achieves strong datasets, including translation, question-answering, cloze as well several require on-the-fly reasoning domain adaptation, such unscrambling words, using novel word sentence, performing 3-digit arithmetic. At same time, also identify some where GPT-3's learning struggles, faces methodological issues related training web corpora. Finally, find generate samples news articles human evaluators have difficulty distinguishing written humans. We discuss broader societal impacts finding general."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.01834"
    ],
    "c_title":[
      "Intercellular contact is sufficient to drive Fibroblast to Myofibroblast\n  transitions"
    ],
    "c_abstract":[
      "Fibroblast cells play a key role in maintaining the extracellular matrix.\nDuring wound healing, fibroblasts differentiate into highly contractile\nmyofibroblasts, which secrete extracellular matrix proteins like collagen to\nfacilitate tissue repair. Under normal conditions, myofibroblasts undergo\nprogrammed cell death after healing to prevent excessive scar formation.\nHowever, in diseases like fibrosis, the myofibroblasts remain active even after\nthe wound is closed, resulting in excessive collagen buildup and a stiff,\nfibrotic matrix. The reasons for the persistence of myofibroblasts in fibrosis\nare not well understood. Here we show the existence of a mechanism where direct\nphysical contact between a fibroblast and a myofibroblast is sufficient for\nfibroblasts to transition into myofibroblasts. We show that\nfibroblast-myofibroblast transition can occur even in the absence of known\nbiochemical cues such as growth factor activation or mechanical cues from a\nstiff, fibrotic matrix. Further, we show that contact-based\nfibroblast-myofibroblast activation can be blocked by G{\\alpha}q\/11\/14\ninhibitor FR9003591, which inhibits the formation of myofibroblasts. These\nfindings offer new insights into the persistence of fibrosis despite\ntherapeutic interventions and suggest a potential strategy to target\nfibroblast-to-myofibroblast transition in fibrosis."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03522",
    "a_title":"Exploring the Potentials and Challenges of Using Large Language Models\n  for the Analysis of Transcriptional Regulation of Long Non-coding RNAs",
    "a_abstract":"Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.",
    "explanation":"Given the tremendous success of large language mod-\nels (LLMs) in capturing complex dependencies in sequential data, this study aims to systematically explore the potential and limitations of LLMs in the sequence analysis related to the transcriptional regulation of lncRNA genes. ",
    "b_id":[
      "b20"
    ],
    "b_title":[
      "Long non-coding RNAs: definitions, functions, challenges and recommendations"
    ],
    "b_abstract":[
      "Genes specifying long non-coding RNAs (lncRNAs) occupy a large fraction of the genomes of complex organisms. The term \u2018lncRNAs\u2019 encompasses RNA polymerase I (Pol I), Pol II and Pol III transcribed RNAs, and RNAs from processed introns. The various functions of lncRNAs and their many isoforms and interleaved relationships with other genes make lncRNA classification and annotation difficult. Most lncRNAs evolve more rapidly than protein-coding sequences, are cell type specific and regulate many aspects of cell differentiation and development and other physiological processes. Many lncRNAs associate with chromatin-modifying complexes, are transcribed from enhancers and nucleate phase separation of nuclear condensates and domains, indicating an intimate link between lncRNA expression and the spatial control of gene expression during development. lncRNAs also have important roles in the cytoplasm and beyond, including in the regulation of translation, metabolism and signalling. lncRNAs often have a modular structure and are rich in repeats, which are increasingly being shown to be relevant to their function. In this Consensus Statement, we address the definition and nomenclature of lncRNAs and their conservation, expression, phenotypic visibility, structure and functions. We also discuss research challenges and provide recommendations to advance the understanding of the roles of lncRNAs in development, cell biology and disease."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.11041"
    ],
    "c_title":[
      "Enhancing Semantic Consistency of Large Language Models through Model\n  Editing: An Interpretability-Oriented Approach"
    ],
    "c_abstract":[
      "A Large Language Model (LLM) tends to generate inconsistent and sometimes\ncontradictory outputs when presented with a prompt that has equivalent\nsemantics but is expressed differently from the original prompt. To achieve\nsemantic consistency of an LLM, one of the key approaches is to finetune the\nmodel with prompt-output pairs with semantically equivalent meanings. Despite\nits effectiveness, a data-driven finetuning method incurs substantial\ncomputation costs in data preparation and model optimization. In this regime,\nan LLM is treated as a ``black box'', restricting our ability to gain deeper\ninsights into its internal mechanism. In this paper, we are motivated to\nenhance the semantic consistency of LLMs through a more interpretable method\n(i.e., model editing) to this end. We first identify the model components\n(i.e., attention heads) that have a key impact on the semantic consistency of\nan LLM. We subsequently inject biases into the output of these model components\nalong the semantic-consistency activation direction. It is noteworthy that\nthese modifications are cost-effective, without reliance on mass manipulations\nof the original model parameters. Through comprehensive experiments on the\nconstructed NLU and open-source NLG datasets, our method demonstrates\nsignificant improvements in the semantic consistency and task performance of\nLLMs. Additionally, our method exhibits promising generalization capabilities\nby performing well on tasks beyond the primary tasks."
    ],
    "c_categories":[
      "cs.CL"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00688",
    "a_title":"Why do we regularise in every iteration for imaging inverse problems?",
    "a_abstract":"Regularisation is commonly used in iterative methods for solving imaging\ninverse problems. Many algorithms involve the evaluation of the proximal\noperator of the regularisation term in every iteration, leading to a\nsignificant computational overhead since such evaluation can be costly. In this\ncontext, the ProxSkip algorithm, recently proposed for federated learning\npurposes, emerges as an solution. It randomly skips regularisation steps,\nreducing the computational time of an iterative algorithm without affecting its\nconvergence. Here we explore for the first time the efficacy of ProxSkip to a\nvariety of imaging inverse problems and we also propose a novel PDHGSkip\nversion. Extensive numerical results highlight the potential of these methods\nto accelerate computations while maintaining high-quality reconstructions.",
    "explanation":"Regularisation is commonly used in iterative methods for solving imaging inverse problems. Here we explore for the first time the efficacy of ProxSkip to a variety of imaging inverse problems and we also propose a novel PDHGSkip version.",
    "b_id":[
      "b19"
    ],
    "b_title":[
      "Parameter-Free FISTA by Adaptive Restart and Backtracking"
    ],
    "b_abstract":[
      "We consider a combined restarting and adaptive backtracking strategy for the\npopular Fast Iterative Shrinking-Thresholding Algorithm frequently employed for\naccelerating the convergence speed of large-scale structured convex\noptimization problems. Several variants of FISTA enjoy a provable linear\nconvergence rate for the function values $F(x_n)$ of the form $\\mathcal{O}(\ne^{-K\\sqrt{\\mu\/L}~n})$ under the prior knowledge of problem conditioning, i.e.\nof the ratio between the (\\L ojasiewicz) parameter $\\mu$ determining the growth\nof the objective function and the Lipschitz constant $L$ of its smooth\ncomponent. These parameters are nonetheless hard to estimate in many practical\ncases. Recent works address the problem by estimating either parameter via\nsuitable adaptive strategies. In our work both parameters can be estimated at\nthe same time by means of an algorithmic restarting scheme where, at each\nrestart, a non-monotone estimation of $L$ is performed. For this scheme,\ntheoretical convergence results are proved, showing that a $\\mathcal{O}(\ne^{-K\\sqrt{\\mu\/L}n})$ convergence speed can still be achieved along with\nquantitative estimates of the conditioning. The resulting Free-FISTA algorithm\nis therefore parameter-free. Several numerical results are reported to confirm\nthe practical interest of its use in many exemplar problems."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2501.09799"
    ],
    "c_title":[
      "Scan-Adaptive MRI Undersampling Using Neighbor-based Optimization (SUNO)"
    ],
    "c_abstract":[
      "Accelerated MRI involves collecting partial k-space measurements to reduce\nacquisition time, patient discomfort, and motion artifacts, and typically uses\nregular undersampling patterns or hand-designed schemes. Recent works have\nstudied population-adaptive sampling patterns that are learned from a group of\npatients (or scans) based on population-specific metrics. However, such a\ngeneral sampling pattern can be sub-optimal for any specific scan since it may\nlack scan or slice adaptive details. To overcome this issue, we propose a\nframework for jointly learning scan-adaptive Cartesian undersampling patterns\nand a corresponding reconstruction model from a training set. We use an\nalternating algorithm for learning the sampling patterns and reconstruction\nmodel where we use an iterative coordinate descent (ICD) based offline\noptimization of scan-adaptive k-space sampling patterns for each example in the\ntraining set. A nearest neighbor search is then used to select the\nscan-adaptive sampling pattern at test time from initially acquired\nlow-frequency k-space information. We applied the proposed framework (dubbed\nSUNO) to the fastMRI multi-coil knee and brain datasets, demonstrating improved\nperformance over currently used undersampling patterns at both 4x and 8x\nacceleration factors in terms of both visual quality and quantitative metrics.\nThe code for the proposed framework is available at\nhttps:\/\/github.com\/sidgautam95\/adaptive-sampling-mri-suno."
    ],
    "c_categories":[
      "eess.IV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00688",
    "a_title":"Why do we regularise in every iteration for imaging inverse problems?",
    "a_abstract":"Regularisation is commonly used in iterative methods for solving imaging\ninverse problems. Many algorithms involve the evaluation of the proximal\noperator of the regularisation term in every iteration, leading to a\nsignificant computational overhead since such evaluation can be costly. In this\ncontext, the ProxSkip algorithm, recently proposed for federated learning\npurposes, emerges as an solution. It randomly skips regularisation steps,\nreducing the computational time of an iterative algorithm without affecting its\nconvergence. Here we explore for the first time the efficacy of ProxSkip to a\nvariety of imaging inverse problems and we also propose a novel PDHGSkip\nversion. Extensive numerical results highlight the potential of these methods\nto accelerate computations while maintaining high-quality reconstructions.",
    "explanation":"Regularisation is commonly used in iterative methods for solving imaging inverse problems. Here we explore for the first time the efficacy of ProxSkip to a variety of imaging inverse problems and we also propose a novel PDHGSkip version.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Convex generalizations of total variation based on the structure tensor with applications to inverse problems"
    ],
    "b_abstract":[
      "We introduce a generic convex energy functional that is suitable for both grayscale and vector-valued images. Our functional is based on the eigenvalues of the structure tensor, therefore it penalizes image variation at every point by taking into account the information from its neighborhood. It generalizes several existing variational penalties, such as the Total Variation and vectorial extensions of it. By introducing the concept of patch-based Jacobian operator, we derive an equivalent formulation of the proposed regularizer that is based on the Schatten norm of this operator. Using this new formulation, we prove convexity and develop a dual definition for the proposed energy, which gives rise to an efficient and parallelizable minimization algorithm. Moreover, we establish a connection between the minimization of the proposed convex regularizer and a generic type of nonlinear anisotropic diffusion that is driven by a spatially regularized and adaptive diffusion tensor. Finally, we perform extensive experiments with image denoising and deblurring for grayscale and color images. The results show the effectiveness of the proposed approach as well as its improved performance compared to Total Variation and existing vectorial extensions of it."
    ],
    "b_categories":[
      "eess.IV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.14981"
    ],
    "c_title":[
      "Convex Analysis in Spectral Decomposition Systems"
    ],
    "c_abstract":[
      "This work is concerned with convex analysis of so-called spectral functions\nof matrices that only depend on eigenvalues of the matrix. An abstract\nframework of spectral decomposition systems is proposed that covers a wide\nrange of previously studied settings, including eigenvalue decomposition of\nHermitian matrices and singular value decomposition of rectangular matrices and\nallows deriving new results in more general settings such as Euclidean Jordan\nalgebras. The main results characterize convexity, lower semicontinuity,\nFenchel conjugates, convex subdifferentials, and Bregman proximity operators of\nspectral functions in terms of the reduced functions. As a byproduct, a\ngeneralization of the Ky Fan majorization theorem is obtained."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00036",
    "a_title":"Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial\n  Market Dynamics",
    "a_abstract":"We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.",
    "explanation":"The paper proposes the use of a new method using diffusion model generative methodology to produce synthetic market scenarios.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "On the Distribution of the Two-Sample Cramer-von Mises Criterion"
    ],
    "b_abstract":[
      "The Cramer-von Mises $\\omega^2$ criterion for testing that a sample, $x_1, \\cdots, x_N$, has been drawn from specified continuous distribution $F(x)$ is \\begin{equation*}\\tag{1}\\omega^2 = \\int^\\infty_{-\\infty} \\lbrack F_N(x) - F(x)\\rbrack^2 dF(x),\\end{equation*} where $F_N(x)$ the empirical function of sample; is, $F_N(x) k\/N$ if exactly $k$ observations are less than or equal to $x(k 0, 1, N)$. If there second $y_1, y_M$, test hypothesis two samples come same (unspecified) can be based on analogue $N\\omega^2$, namely \\begin{equation*}\\tag{2} T NM\/(N + M)\\rbrack G_M(x)\\rbrack^2 dH_{N+M}(x),\\end{equation*} $G_M(x)$ sample and $H_{N+M}(x)$ together [that $(N M)H_{N+M}(x) NF_N(x) MG_M(x)\\rbrack$. limiting $N\\omega^2$ as $N \\rightarrow \\infty$ tabulated [2], it shown ([3], [4a], [7]) $T$ \\infty, M \\infty$, $N\/M \\lambda$, $\\lambda$ any finite positive constant. In this note we consider small values $N$ $M$ present tables permit use at some conventional significance levels $M$. seems surprisingly good approximation exact moderate sizes (corresponding feature [6]). accuracy better in case two-sample Kolmogorov-Smirnov statistic studied by Hodges [4]."
    ],
    "b_categories":[
      "q-fin.GN"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "2503.08065"
    ],
    "c_title":[
      "STGDPM:Vessel Trajectory Prediction with Spatio-Temporal Graph Diffusion\n  Probabilistic Model"
    ],
    "c_abstract":[
      "Vessel trajectory prediction is a critical component for ensuring maritime\ntraffic safety and avoiding collisions. Due to the inherent uncertainty in\nvessel behavior, trajectory prediction systems must adopt a multimodal approach\nto accurately model potential future motion states. However, existing vessel\ntrajectory prediction methods lack the ability to comprehensively model\nbehavioral multi-modality. To better capture multimodal behavior in interactive\nscenarios, we propose modeling interactions as dynamic graphs, replacing\ntraditional aggregation-based techniques that rely on vessel states. By\nleveraging the natural multimodal capabilities of diffusion models, we frame\nthe trajectory prediction task as an inverse process of motion uncertainty\ndiffusion, wherein uncertainties across potential navigational areas are\nprogressively eliminated until the desired trajectories is produced. In\nsummary, we pioneer the integration of Spatio-Temporal Graph (STG) with\ndiffusion models in ship trajectory prediction. Extensive experiments on real\nAutomatic Identification System (AIS) data validate the superiority of our\napproach."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00036",
    "a_title":"Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial\n  Market Dynamics",
    "a_abstract":"We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.",
    "explanation":"The paper proposes the use of a new method using diffusion model generative methodology to produce synthetic market scenarios.",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "Quant GANs: deep generation of financial time series"
    ],
    "b_abstract":[
      "Modeling financial time series by stochastic processes is a challenging task and a central area of research in financial mathematics. As an alternative, we introduce Quant GANs, a data-driven model which is inspired by the recent success of generative adversarial networks (GANs). Quant GANs consist of a generator and discriminator function, which utilize temporal convolutional networks (TCNs) and thereby achieve to capture long-range dependencies such as the presence of volatility clusters. The generator function is explicitly constructed such that the induced stochastic process allows a transition to its risk-neutral distribution. Our numerical results highlight that distributional properties for small and large lags are in an excellent agreement and dependence properties such as volatility clusters, leverage effects, and serial autocorrelations can be generated by the generator function of Quant GANs, demonstrably in high fidelity."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.15557"
    ],
    "c_title":[
      "Preventing Household Bankruptcy: The One-Third Rule in Financial\n  Planning with Mathematical Validation and Game-Theoretic Insights"
    ],
    "c_abstract":[
      "This paper analyzes the 1\/3 Financial Rule, a method of allocating income\nequally among debt repayment, savings, and living expenses. Through\nmathematical modeling, game theory, behavioral finance, and technological\nanalysis, we examine the rule's potential for supporting household financial\nstability and reducing bankruptcy risk. The research develops theoretical\nfoundations using utility maximization theory, demonstrating how equal\nallocation emerges as a solution under standard economic assumptions. The\ngame-theoretic analysis explores the rule's effectiveness across different\nhousehold structures, revealing potential strategic advantages in financial\ndecision-making. We investigate psychological factors influencing financial\nchoices, including cognitive biases and neurobiological mechanisms that impact\neconomic behavior. Technological approaches, such as AI-driven personalization,\nblockchain tracking, and smart contract applications, are examined for their\npotential to support financial planning. Empirical validation using U.S. Census\ndata and longitudinal studies assesses the rule's performance across various\nhousehold types. Stress testing under different economic conditions provides\ninsights into its adaptability and resilience. The research integrates\nmathematical analysis with behavioral insights and technological perspectives\nto develop a comprehensive approach to household financial management."
    ],
    "c_categories":[
      "q-fin.GN"
    ],
    "c_fields":[
      "Economics and Quantitative Finance"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00640",
    "a_title":"Adding Error Bars to Evals: A Statistical Approach to Language Model\n  Evaluations",
    "a_abstract":"Evaluations are critical for understanding the capabilities of large language\nmodels (LLMs). Fundamentally, evaluations are experiments; but the literature\non evaluations has largely ignored the literature from other sciences on\nexperiment analysis and planning. This article shows researchers with some\ntraining in statistics how to think about and analyze data from language model\nevaluations. Conceptualizing evaluation questions as having been drawn from an\nunseen super-population, we present formulas for analyzing evaluation data,\nmeasuring differences between two models, and planning an evaluation\nexperiment. We make a number of specific recommendations for running language\nmodel evaluations and reporting experiment results in a way that minimizes\nstatistical noise and maximizes informativeness.",
    "explanation":"This is an interdisciplinary work because it combines two different subjects: LLM and statistics. This suggests that we could also consider the error bars in the evaluations. ",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "Quantifying Variance in Evaluation Benchmarks"
    ],
    "b_abstract":[
      "Evaluation benchmarks are the cornerstone of measuring capabilities large language models (LLMs), as well driving progress in said capabilities. Originally designed to make claims about (or lack thereof) fully pretrained models, evaluation now also extensively used decide between various training choices. Despite this widespread usage, we rarely quantify variance our benchmarks, which dictates whether differences performance meaningful. Here, define and measure a range metrics geared towards including seed across initialisations, monotonicity during training. By studying number -- both openly available from scratch provide empirical estimates for variety metrics, with considerations recommendations practitioners. We evaluate utility tradeoffs continuous versus discrete measures explore options better understanding reducing variance. find that simple changes, such framing choice tasks (like MMLU) completion tasks, can often reduce smaller scale ($\\sim$7B) while more involved methods inspired human testing literature (such item analysis response theory) struggle meaningfully Overall, work provides insights into suggests LM-specific techniques variance, generally encourages practitioners carefully factor when comparing models."
    ],
    "b_categories":[
      "stat.ME"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2502.19308"
    ],
    "c_title":[
      "WOFOSTGym: A Crop Simulator for Learning Annual and Perennial Crop\n  Management Strategies"
    ],
    "c_abstract":[
      "We introduce WOFOSTGym, a novel crop simulation environment designed to train\nreinforcement learning (RL) agents to optimize agromanagement decisions for\nannual and perennial crops in single and multi-farm settings. Effective crop\nmanagement requires optimizing yield and economic returns while minimizing\nenvironmental impact, a complex sequential decision-making problem well suited\nfor RL. However, the lack of simulators for perennial crops in multi-farm\ncontexts has hindered RL applications in this domain. Existing crop simulators\nalso do not support multiple annual crops. WOFOSTGym addresses these gaps by\nsupporting 23 annual crops and two perennial crops, enabling RL agents to learn\ndiverse agromanagement strategies in multi-year, multi-crop, and multi-farm\nsettings. Our simulator offers a suite of challenging tasks for learning under\npartial observability, non-Markovian dynamics, and delayed feedback.\nWOFOSTGym's standard RL interface allows researchers without agricultural\nexpertise to explore a wide range of agromanagement problems. Our experiments\ndemonstrate the learned behaviors across various crop varieties and soil types,\nhighlighting WOFOSTGym's potential for advancing RL-driven decision support in\nagriculture."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00640",
    "a_title":"Adding Error Bars to Evals: A Statistical Approach to Language Model\n  Evaluations",
    "a_abstract":"Evaluations are critical for understanding the capabilities of large language\nmodels (LLMs). Fundamentally, evaluations are experiments; but the literature\non evaluations has largely ignored the literature from other sciences on\nexperiment analysis and planning. This article shows researchers with some\ntraining in statistics how to think about and analyze data from language model\nevaluations. Conceptualizing evaluation questions as having been drawn from an\nunseen super-population, we present formulas for analyzing evaluation data,\nmeasuring differences between two models, and planning an evaluation\nexperiment. We make a number of specific recommendations for running language\nmodel evaluations and reporting experiment results in a way that minimizes\nstatistical noise and maximizes informativeness.",
    "explanation":"This is an interdisciplinary work because it combines two different subjects: LLM and statistics. This suggests that we could also consider the error bars in the evaluations. ",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "The Llama 3 Herd of Models"
    ],
    "b_abstract":[
      "Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.03065"
    ],
    "c_title":[
      "Meta-analysis of median survival times with inverse-variance weighting"
    ],
    "c_abstract":[
      "We consider the problem of meta-analyzing outcome measures based on median\nsurvival times, such as the difference of median survival times between groups.\nPrimary studies with time-to-event outcomes often report estimates of median\nsurvival times and corresponding confidence intervals based on the Kaplan-Meier\nestimator. However, applying conventional inverse-variance weighted methods to\nmeta-analyze outcome measures based on median survival is often challenging\nbecause within-study standard error estimates are typically not available in\nthis setting. In this article, we consider an inverse-variance weighted\napproach to meta-analyze median survival times that estimates the within-study\nstandard errors from the reported confidence intervals. We conduct a series of\nsimulation studies evaluating the performance of this approach at the study\nlevel (i.e., for estimating the standard error of median survival) and the\nmeta-analytic level (i.e., for estimating the pooled median, difference of\nmedians, and ratio of medians). We find that this approach often performs\ncomparable to a benchmark approach that uses the true within-study standard\nerrors for meta-analyzing median-based outcome measures. We then illustrate an\napplication of this approach in a meta-analysis evaluating survival benefits of\nbeing assigned to experimental arms versus comparator arms in randomized trials\nfor non-small cell lung cancer therapies."
    ],
    "c_categories":[
      "stat.ME"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06785",
    "a_title":"White-Box Diffusion Transformer for single-cell RNA-seq generation",
    "a_abstract":"As a powerful tool for characterizing cellular subpopulations and cellular\nheterogeneity, single cell RNA sequencing (scRNA-seq) technology offers\nadvantages of high throughput and multidimensional analysis. However, the\nprocess of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a hybrid model\nbased on Diffusion model and White-Box transformer that aims to generate\nsynthetic and biologically plausible scRNA-seq data. Diffusion model\nprogressively introduce noise into the data and then recover the original data\nthrough a denoising process, a forward and reverse process that is particularly\nsuitable for generating complex data distributions. White-Box transformer is a\ndeep learning architecture that emphasizes mathematical interpretability. By\nminimizing the encoding rate of the data and maximizing the sparsity of the\nrepresentation, it not only reduces the computational burden, but also provides\nclear insight into underlying structure. Our White-Box Diffusion Transformer\ncombines the generative capabilities of Diffusion model with the mathematical\ninterpretability of White-Box transformer. Through experiments using six\ndifferent single-cell RNA-Seq datasets, we visualize both generated and real\ndata using t-SNE dimensionality reduction technique, as well as quantify\nsimilarity between generated and real data using various metrics to demonstrate\ncomparable performance of White-Box Diffusion Transformer and Diffusion\nTransformer in generating scRNA-seq data alongside significant improvements in\ntraining efficiency and resource utilization. Our code is available at\nhttps:\/\/github.com\/lingximamo\/White-Box-Diffusion-Transformer",
    "explanation":"As a powerful tool for characterizing cellular subpopulations and cellular heterogeneity, single cell\nRNA sequencing (scRNA-seq) technology offers advantages of high throughput and multidimensional\nanalysis. However, the process of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a model based on Diffusion model\nand White-Box transformer that aims to generate synthetic and biologically plausible scRNA-seq\ndata.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "RNA-Seq: a revolutionary tool for transcriptomics"
    ],
    "b_abstract":[
      "RNA-Seq is a recently developed approach to transcriptome profiling that uses deep-sequencing technologies. Studies using this method have already altered our view of the extent and complexity of eukaryotic transcriptomes. RNA-Seq also provides a far more precise measurement of levels of transcripts and their isoforms than other methods. This article describes the RNA-Seq approach, the challenges associated with its application, and the advances made so far in characterizing several eukaryote transcriptomes."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.04583"
    ],
    "c_title":[
      "Overcoming Fake Solutions in Semi-Dual Neural Optimal Transport: A\n  Smoothing Approach for Learning the Optimal Transport Plan"
    ],
    "c_abstract":[
      "We address the convergence problem in learning the Optimal Transport (OT)\nmap, where the OT Map refers to a map from one distribution to another while\nminimizing the transport cost. Semi-dual Neural OT, a widely used approach for\nlearning OT Maps with neural networks, often generates fake solutions that fail\nto transfer one distribution to another accurately. We identify a sufficient\ncondition under which the max-min solution of Semi-dual Neural OT recovers the\ntrue OT Map. Moreover, to address cases when this sufficient condition is not\nsatisfied, we propose a novel method, OTP, which learns both the OT Map and the\nOptimal Transport Plan, representing the optimal coupling between two\ndistributions. Under sharp assumptions on the distributions, we prove that our\nmodel eliminates the fake solution issue and correctly solves the OT problem.\nOur experiments show that the OTP model recovers the optimal transport map\nwhere existing methods fail and outperforms current OT-based models in\nimage-to-image translation tasks. Notably, the OTP model can learn stochastic\ntransport maps when deterministic OT Maps do not exist, such as one-to-many\ntasks like colorization."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06785",
    "a_title":"White-Box Diffusion Transformer for single-cell RNA-seq generation",
    "a_abstract":"As a powerful tool for characterizing cellular subpopulations and cellular\nheterogeneity, single cell RNA sequencing (scRNA-seq) technology offers\nadvantages of high throughput and multidimensional analysis. However, the\nprocess of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a hybrid model\nbased on Diffusion model and White-Box transformer that aims to generate\nsynthetic and biologically plausible scRNA-seq data. Diffusion model\nprogressively introduce noise into the data and then recover the original data\nthrough a denoising process, a forward and reverse process that is particularly\nsuitable for generating complex data distributions. White-Box transformer is a\ndeep learning architecture that emphasizes mathematical interpretability. By\nminimizing the encoding rate of the data and maximizing the sparsity of the\nrepresentation, it not only reduces the computational burden, but also provides\nclear insight into underlying structure. Our White-Box Diffusion Transformer\ncombines the generative capabilities of Diffusion model with the mathematical\ninterpretability of White-Box transformer. Through experiments using six\ndifferent single-cell RNA-Seq datasets, we visualize both generated and real\ndata using t-SNE dimensionality reduction technique, as well as quantify\nsimilarity between generated and real data using various metrics to demonstrate\ncomparable performance of White-Box Diffusion Transformer and Diffusion\nTransformer in generating scRNA-seq data alongside significant improvements in\ntraining efficiency and resource utilization. Our code is available at\nhttps:\/\/github.com\/lingximamo\/White-Box-Diffusion-Transformer",
    "explanation":"As a powerful tool for characterizing cellular subpopulations and cellular heterogeneity, single cell\nRNA sequencing (scRNA-seq) technology offers advantages of high throughput and multidimensional\nanalysis. However, the process of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a model based on Diffusion model\nand White-Box transformer that aims to generate synthetic and biologically plausible scRNA-seq\ndata.",
    "b_id":[
      "b25"
    ],
    "b_title":[
      "White-Box Transformers via Sparse Rate Reduction"
    ],
    "b_abstract":[
      "In this paper, we contend that the objective of representation learning is to compress and transform distribution data, say sets tokens, towards a mixture low-dimensional Gaussian distributions supported on incoherent subspaces. The quality final can be measured by unified function called sparse rate reduction. From perspective, popular deep networks such as transformers naturally viewed realizing iterative schemes optimize incrementally. Particularly, show standard transformer block derived from alternating optimization complementary parts objective: multi-head self-attention operator gradient descent step token minimizing their lossy coding rate, subsequent multi-layer perceptron attempting sparsify tokens. This leads family white-box transformer-like network architectures which are mathematically fully interpretable. Despite simplicity, experiments these indeed learn designed they representations large-scale real-world vision datasets ImageNet, achieve performance very close thoroughly engineered ViT."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.15472"
    ],
    "c_title":[
      "GiantHunter: Accurate detection of giant virus in metagenomic data using\n  reinforcement-learning and Monte Carlo tree search"
    ],
    "c_abstract":[
      "Motivation: Nucleocytoplasmic large DNA viruses (NCLDVs) are notable for\ntheir large genomes and extensive gene repertoires, which contribute to their\nwidespread environmental presence and critical roles in processes such as host\nmetabolic reprogramming and nutrient cycling. Metagenomic sequencing has\nemerged as a powerful tool for uncovering novel NCLDVs in environmental\nsamples. However, identifying NCLDV sequences in metagenomic data remains\nchallenging due to their high genomic diversity, limited reference genomes, and\nshared regions with other microbes. Existing alignment-based and machine\nlearning methods struggle with achieving optimal trade-offs between sensitivity\nand precision. Results: In this work, we present GiantHunter, a reinforcement\nlearning-based tool for identifying NCLDVs from metagenomic data. By employing\na Monte Carlo tree search strategy, GiantHunter dynamically selects\nrepresentative non-NCLDV sequences as the negative training data, enabling the\nmodel to establish a robust decision boundary. Benchmarking on rigorously\ndesigned experiments shows that GiantHunter achieves high precision while\nmaintaining competitive sensitivity, improving the F1-score by 10% and reducing\ncomputational cost by 90% compared to the second-best method. To demonstrate\nits real-world utility, we applied GiantHunter to 60 metagenomic datasets\ncollected from six cities along the Yangtze River, located both upstream and\ndownstream of the Three Gorges Dam. The results reveal significant differences\nin NCLDV diversity correlated with proximity to the dam, likely influenced by\nreduced flow velocity caused by the dam. These findings highlight the potential\nof GiantSeeker to advance our understanding of NCLDVs and their ecological\nroles in diverse environments."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00868",
    "a_title":"Quantifying perturbation impacts for large language models",
    "a_abstract":"We consider the problem of quantifying how an input perturbation impacts the\noutputs of large language models (LLMs), a fundamental task for model\nreliability and post-hoc interpretability. A key obstacle in this domain is\ndisentangling the meaningful changes in model responses from the intrinsic\nstochasticity of LLM outputs. To overcome this, we introduce Distribution-Based\nPerturbation Analysis (DBPA), a framework that reformulates LLM perturbation\nanalysis as a frequentist hypothesis testing problem. DBPA constructs empirical\nnull and alternative output distributions within a low-dimensional semantic\nsimilarity space via Monte Carlo sampling. Comparisons of Monte Carlo estimates\nin the reduced dimensionality space enables tractable frequentist inference\nwithout relying on restrictive distributional assumptions. The framework is\nmodel-agnostic, supports the evaluation of arbitrary input perturbations on any\nblack-box LLM, yields interpretable p-values, supports multiple perturbation\ntesting via controlled error rates, and provides scalar effect sizes for any\nchosen similarity or distance metric. We demonstrate the effectiveness of DBPA\nin evaluating perturbation impacts, showing its versatility for perturbation\nanalysis.",
    "explanation":"\"We consider the problem of quantifying how an input perturbation impacts the outputs of large language models (LLMs), a fundamental task for model reliability and post-hoc interpretability.\"",
    "b_id":[
      "b22"
    ],
    "b_title":[
      "Context-Aware Testing: A New Paradigm for Model Testing with Large\n  Language Models"
    ],
    "b_abstract":[
      "The predominant de facto paradigm of testing ML models relies on either using\nonly held-out data to compute aggregate evaluation metrics or by assessing the\nperformance on different subgroups. However, such data-only testing methods\noperate under the restrictive assumption that the available empirical data is\nthe sole input for testing ML models, disregarding valuable contextual\ninformation that could guide model testing. In this paper, we challenge the\ngo-to approach of data-only testing and introduce context-aware testing (CAT)\nwhich uses context as an inductive bias to guide the search for meaningful\nmodel failures. We instantiate the first CAT system, SMART Testing, which\nemploys large language models to hypothesize relevant and likely failures,\nwhich are evaluated on data using a self-falsification mechanism. Through\nempirical evaluations in diverse settings, we show that SMART automatically\nidentifies more relevant and impactful failures than alternatives,\ndemonstrating the potential of CAT as a testing paradigm."
    ],
    "b_categories":[
      "stat.ME"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2502.10197"
    ],
    "c_title":[
      "MathConstruct: Challenging LLM Reasoning with Constructive Proofs"
    ],
    "c_abstract":[
      "While Large Language Models (LLMs) demonstrate impressive performance in\nmathematics, existing math benchmarks come with significant limitations. Many\nfocus on problems with fixed ground-truth answers, and are often saturated due\nto problem simplicity or the viability of guessing or memorization. Crucially,\nthey capture only a narrow subset of relevant math problems. To address this\nresearch gap, we introduce \\mc, a new benchmark of 126 challenging problems\nsourced from various math competitions, which targets constructive proofs, a\nwidely encountered problem type requiring the construction of mathematical\nobjects with specific properties. These proofs are particularly suitable for\nLLM evaluation, as solution correctness can be easily verified. Our automated\nverifiers also enable MathConstruct to generate problem variations, used to\nevaluate robustness. State-of-the-art LLMs solve only 54% of MathConstruct\nproblems, highlighting its complexity and importance for LLM evaluation."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00868",
    "a_title":"Quantifying perturbation impacts for large language models",
    "a_abstract":"We consider the problem of quantifying how an input perturbation impacts the\noutputs of large language models (LLMs), a fundamental task for model\nreliability and post-hoc interpretability. A key obstacle in this domain is\ndisentangling the meaningful changes in model responses from the intrinsic\nstochasticity of LLM outputs. To overcome this, we introduce Distribution-Based\nPerturbation Analysis (DBPA), a framework that reformulates LLM perturbation\nanalysis as a frequentist hypothesis testing problem. DBPA constructs empirical\nnull and alternative output distributions within a low-dimensional semantic\nsimilarity space via Monte Carlo sampling. Comparisons of Monte Carlo estimates\nin the reduced dimensionality space enables tractable frequentist inference\nwithout relying on restrictive distributional assumptions. The framework is\nmodel-agnostic, supports the evaluation of arbitrary input perturbations on any\nblack-box LLM, yields interpretable p-values, supports multiple perturbation\ntesting via controlled error rates, and provides scalar effect sizes for any\nchosen similarity or distance metric. We demonstrate the effectiveness of DBPA\nin evaluating perturbation impacts, showing its versatility for perturbation\nanalysis.",
    "explanation":"\"We consider the problem of quantifying how an input perturbation impacts the outputs of large language models (LLMs), a fundamental task for model reliability and post-hoc interpretability.\"",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "How resilient are language models to text perturbations"
    ],
    "b_abstract":[
      "Large language models typically rely on highly curated datasets that lack common irregularities such as typos and contractions, resulting in a mismatch between their training environments and real-world applications. This study evaluates the resilience of four prominent models in five different NLP tasks when confronted with perturbed inputs. We investigate three categories of perturbations: character-level, word-level and miscellaneous perturbations. By comparing performance on original and altered datasets, our results reveal a significant sensitivity to input perturbations across all models, with varying degrees of vulnerability depending on both the specific task and the type of perturbation. In particular, the XLNet model consistently shows superior robustness, while tasks involving grammatical coherence are most adversely affected."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.00579"
    ],
    "c_title":[
      "Intrinsic Random Functions and Parametric Covariance Models of\n  Spatio-Temporal Random Processes on the Sphere"
    ],
    "c_abstract":[
      "Identifying an appropriate covariance function is one of the primary\ninterests in spatial and spatio-temporal statistics because it allows\nresearchers to analyze the dependence structure of the random process. For this\npurpose, spatial homogeneity and temporal stationarity are widely used\nassumptions, and many parametric covariance models have been developed under\nthese assumptions. However, these are strong and unrealistic conditions in many\ncases. In addition, on the sphere, although different statistical approaches\nfrom those on Euclidean space should be applied to build a proper covariance\nmodel considering its unique characteristics, relevant studies are rare. In\nthis research, we introduce novel parameterized models of the covariance\nfunction for spatially non-homogeneous and temporally non-stationary random\nprocesses on the sphere. To alleviate the spatial homogeneity assumption and\ntemporal stationarity, and to consider the spherical domain and time domain\ntogether, this research will apply the theories of Intrinsic Random Functions\n(IRF). We also provide a methodology to estimate the associated parameters for\nthe model. Finally, through a simulation study and analysis of a real-world\ndata set about global temperature anomaly, we demonstrate validity of the\nsuggested covariance model with its advantage of interpretability."
    ],
    "c_categories":[
      "stat.ME"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.01668",
    "a_title":"Linear Quadratic Mean Field Games with Quantile-Dependent Cost\n  Coefficients",
    "a_abstract":"This paper studies a class of linear quadratic mean field games where the\ncoefficients of quadratic cost functions depend on both the mean and the\nvariance of the population's state distribution through its quantile function.\nSuch a formulation allows for modelling agents that are sensitive to not only\nthe population average but also the population variance. The corresponding mean\nfield game equilibrium is identified, which involves solving two coupled\ndifferential equations: one is a Riccati equation and the other the variance\nevolution equation. Furthermore, the conditions for the existence and\nuniqueness of the mean field equilibrium are established. Finally, numerical\nresults are presented to illustrate the behavior of two coupled differential\nequations and the performance of the mean field game solution.",
    "explanation":"\"This paper studies a class of linear quadratic mean field games where the coefficients of quadratic cost functions depend on both the mean and the variance of the population\u2019s state distribution through its quantile function. \"\n\n\n",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Mean\u2010field games with differing beliefs for algorithmic trading"
    ],
    "b_abstract":[
      "Abstract Even when confronted with the same data, agents often disagree on a model of real world. Here, we address question how interacting heterogeneous agents, who what world follows, optimize their trading actions. The market has latent factors that drive prices, and account for permanent impact they have prices. This leads to large stochastic game, where each performance criteria are computed under different probability measure. We analyze mean\u2010field game (MFG) limit show Nash equilibrium is given by solution nonstandard vector\u2010valued forward\u2013backward differential equation. Under some mild assumptions, construct in terms expectations filtered states. Furthermore, prove MFG strategy forms an \u03b5\u2010Nash finite player game. Finally, present least square Monte Carlo based algorithm computing equilibria through simulations increasing disagreement may increase price volatility activity."
    ],
    "b_categories":[
      "q-fin.MF"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "2501.12533"
    ],
    "c_title":[
      "Multi-objective and hierarchical control for coupled stochastic\n  parabolic systems"
    ],
    "c_abstract":[
      "We study the Stackelberg-Nash null controllability of a coupled system\ngoverned by two linear forward stochastic parabolic equations. The system\nincludes one leader control localized in a subset of the domain, two additional\nleader controls in the diffusion terms, and \\( m \\) follower controls, where \\(\nm \\geq 2 \\). We consider two different scenarios for the followers: first, when\nthe followers minimize a functional involving both components of the system's\nstate, and second, when they minimize a functional involving only the second\ncomponent of the state. For fixed leader controls, we first establish the\nexistence and uniqueness of the Nash equilibrium in both scenarios and provide\nits characterization. As a byproduct, the problem is reformulated as a\nclassical null controllability issue for the associated coupled\nforward-backward stochastic parabolic system. To address this, we derive new\nCarleman estimates for the adjoint stochastic systems. As far as we know, this\nproblem is among the first to be discussed for stochastic coupled systems."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.01668",
    "a_title":"Linear Quadratic Mean Field Games with Quantile-Dependent Cost\n  Coefficients",
    "a_abstract":"This paper studies a class of linear quadratic mean field games where the\ncoefficients of quadratic cost functions depend on both the mean and the\nvariance of the population's state distribution through its quantile function.\nSuch a formulation allows for modelling agents that are sensitive to not only\nthe population average but also the population variance. The corresponding mean\nfield game equilibrium is identified, which involves solving two coupled\ndifferential equations: one is a Riccati equation and the other the variance\nevolution equation. Furthermore, the conditions for the existence and\nuniqueness of the mean field equilibrium are established. Finally, numerical\nresults are presented to illustrate the behavior of two coupled differential\nequations and the performance of the mean field game solution.",
    "explanation":"\"This paper studies a class of linear quadratic mean field games where the coefficients of quadratic cost functions depend on both the mean and the variance of the population\u2019s state distribution through its quantile function. \"\n\n\n",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Linear-quadratic mean field games"
    ],
    "b_abstract":[
      "In this article, we provide a comprehensive study of the linear-quadratic mean field games via the adjoint equation approach; although the problem has been considered in the literature by Huang, Caines and Malhame (HCM, 2007a), their method is based on Dynamic Programming. It turns out that two methods are not equivalent, as far as giving sufficient condition for the existence of a solution is concerned. Due to the linearity of the adjoint equations, the optimal mean field term satisfies a linear forward-backward ordinary differential equation. For the one dimensional case, we show that the equilibrium strategy always exists uniquely. For dimension greater than one, by choosing a suitable norm and then applying the Banach Fixed Point Theorem, a sufficient condition, which is independent of the solution of the standard Riccati differential equation, for the unique existence of the equilibrium strategy is provided. As a by-product, we also establish a neat and instructive sufficient condition for the unique existence of the solution for a class of non-trivial nonsymmetric Riccati equations. Numerical examples of non-existence of the equilibrium strategy and the comparison of HCM's approach will also be provided."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2503.01040"
    ],
    "c_title":[
      "Pricing time-capped American options using Least Squares Monte Carlo\n  method"
    ],
    "c_abstract":[
      "In this paper, we adopt the least squares Monte Carlo (LSMC) method to price\ntime-capped American options. The aforementioned cap can be an independent\nrandom variable or dependent on asset price at random time. We allow various\ntime caps. In particular, we give an algorithm for pricing the American options\ncapped by the first drawdown epoch. We focus on the geometric L\\'evy market. We\nprove that our estimator converges to the true price as one takes the\ndiscretisation step tending to zero and the number of trajectories going to\ninfinity."
    ],
    "c_categories":[
      "q-fin.MF"
    ],
    "c_fields":[
      "Economics and Quantitative Finance"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.00575",
    "a_title":"A Semi-Discrete Optimal Transport Scheme for the 3D Incompressible\n  Semi-Geostrophic Equations",
    "a_abstract":"We describe a mesh-free three-dimensional numerical scheme for solving the\nincompressible semi-geostrophic equations based on semi-discrete optimal\ntransport techniques. These results generalise previous two-dimensional\nimplementations. The optimal transport methods we adopt are known for their\nstructural preservation and energy conservation qualities and achieve an\nexcellent level of efficiency and numerical energy-conservation. We use this\nscheme to generate numerical simulations of an important cyclone benchmark\nproblem. To our knowledge, this is the first fully three-dimensional simulation\nof the semi-geostrophic equations, evidencing semi-discrete optimal transport\nas a novel, robust numerical tool for meteorological and oceanographic\nmodelling.",
    "explanation":"We describe a mesh-free three-dimensional numerical scheme for solving the in-\ncompressible semi-geostrophic equations based on semi-discrete optimal transport techniques.\nThese results generalise previous two-dimensional implementations.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Weak Existence for the Semigeostrophic Equations Formulated as a Coupled Monge--Amp\u00e8re\/Transport Problem"
    ],
    "b_abstract":[
      "Hoskins's semigeostrophic equations are reformulated as a coupled Monge--Amp\u00e8re\/ transport problem [B. J. Hoskins, Quart. Royal Met. Soc., 97 (1971), pp. 139--153]. Existence of global weak solutions is obtained for this formulation."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2501.03866"
    ],
    "c_title":[
      "Disjointly non-singular operators and various topologies on Banach\n  lattices"
    ],
    "c_abstract":[
      "We continue the study of dispersed subspaces and disjointly non-singular\n(DNS) operators on Banach lattices using topological methods. In particular, we\nprovide a simple proof of the fact that in an order continuous Banach lattice\nan operator is DNS if and only if it is $n$-DNS, for some $n\\in\\mathbb{N}$. We\ncharacterize Banach lattices with order continuous dual in terms of dispersed\nsubspaces and absolute weak topology. We also connect these topics with the\nrecently launched study of phase retrieval in Banach lattices."
    ],
    "c_categories":[
      "math.FA",
      "math.GN"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.00575",
    "a_title":"A Semi-Discrete Optimal Transport Scheme for the 3D Incompressible\n  Semi-Geostrophic Equations",
    "a_abstract":"We describe a mesh-free three-dimensional numerical scheme for solving the\nincompressible semi-geostrophic equations based on semi-discrete optimal\ntransport techniques. These results generalise previous two-dimensional\nimplementations. The optimal transport methods we adopt are known for their\nstructural preservation and energy conservation qualities and achieve an\nexcellent level of efficiency and numerical energy-conservation. We use this\nscheme to generate numerical simulations of an important cyclone benchmark\nproblem. To our knowledge, this is the first fully three-dimensional simulation\nof the semi-geostrophic equations, evidencing semi-discrete optimal transport\nas a novel, robust numerical tool for meteorological and oceanographic\nmodelling.",
    "explanation":"We describe a mesh-free three-dimensional numerical scheme for solving the in-\ncompressible semi-geostrophic equations based on semi-discrete optimal transport techniques.\nThese results generalise previous two-dimensional implementations.",
    "b_id":[
      "b22"
    ],
    "b_title":[
      "Vertical slice modelling of nonlinear Eady waves using a compatible finite element method"
    ],
    "b_abstract":[
      "A vertical slice model is developed for the Euler-Boussinesq equations with a\nconstant temperature gradient in the direction normal to the slice (the\nEady-Boussinesq model). The model is a solution of the full three-dimensional\nequations with no variation normal to the slice, which is an idealized problem\nused to study the formation and subsequent evolution of weather fronts. A\ncompatible finite element method is used to discretise the governing equations.\nTo extend the Charney-Phillips grid staggering in the compatible finite element\nframework, we use the same node locations for buoyancy as the vertical part of\nvelocity and apply a transport scheme for a partially continuous finite element\nspace. For the time discretisation, we solve the semi-implicit equations\ntogether with an explicit strong-stability-preserving Runge-Kutta scheme to all\nof the advection terms. The model reproduces several quasi-periodic lifecycles\nof fronts despite the presence of strong discontinuities. An asymptotic limit\nanalysis based on the semi-geostrophic theory shows that the model solutions\nare converging to a solution in cross-front geostrophic balance. The results\nare consistent with the previous results using finite difference methods,\nindicating that the compatible finite element method is performing as well as\nfinite difference methods for this test problem. We observe dissipation of\nkinetic energy of the cross-front velocity in the model due to the lack of\nresolution at the fronts, even though the energy loss is not likely to account\nfor the large gap on the strength of the fronts between the model result and\nthe semi-geostrophic limit solution."
    ],
    "b_categories":[
      "math.MP"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2501.12533"
    ],
    "c_title":[
      "Multi-objective and hierarchical control for coupled stochastic\n  parabolic systems"
    ],
    "c_abstract":[
      "We study the Stackelberg-Nash null controllability of a coupled system\ngoverned by two linear forward stochastic parabolic equations. The system\nincludes one leader control localized in a subset of the domain, two additional\nleader controls in the diffusion terms, and \\( m \\) follower controls, where \\(\nm \\geq 2 \\). We consider two different scenarios for the followers: first, when\nthe followers minimize a functional involving both components of the system's\nstate, and second, when they minimize a functional involving only the second\ncomponent of the state. For fixed leader controls, we first establish the\nexistence and uniqueness of the Nash equilibrium in both scenarios and provide\nits characterization. As a byproduct, the problem is reformulated as a\nclassical null controllability issue for the associated coupled\nforward-backward stochastic parabolic system. To address this, we derive new\nCarleman estimates for the adjoint stochastic systems. As far as we know, this\nproblem is among the first to be discussed for stochastic coupled systems."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.00578",
    "a_title":"Federated Voxel Scene Graph for Intracranial Hemorrhage",
    "a_abstract":"Intracranial Hemorrhage is a potentially lethal condition whose manifestation\nis vastly diverse and shifts across clinical centers worldwide.\nDeep-learning-based solutions are starting to model complex relations between\nbrain structures, but still struggle to generalize. While gathering more\ndiverse data is the most natural approach, privacy regulations often limit the\nsharing of medical data. We propose the first application of Federated Scene\nGraph Generation. We show that our models can leverage the increased training\ndata diversity. For Scene Graph Generation, they can recall up to 20% more\nclinically relevant relations across datasets compared to models trained on a\nsingle centralized dataset. Learning structured data representation in a\nfederated setting can open the way to the development of new methods that can\nleverage this finer information to regularize across clients more effectively.",
    "explanation":"intracranial Hemorrhage is a potentially lethal condition whose manifestation is vastly diverse and shifts across\nclinical centers worldwide. Deep-learning-based solutions are starting to model complex relations between brain\nstructures, but still struggle to generalize.",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "American Heart Association\/American Stroke Association. 2022 guideline for the management of patients with spontaneous intracerebral hemorrhage: A guideline from the american heart association\/american stroke association"
    ],
    "b_abstract":[
      "Approximately 10% of the 795\u2009000 strokes per year in the United States are intracerebral hemorrhages (ICHs),1 defined by brain injury attributable to acute blood extravasation into the brain parenchyma from a ruptured cerebral blood vessel. The clinical impact of ICH appears disproportionately high among lower-resource populations both in the United States and internationally. In US-based studies, ICH incidence has been reported to be \u22481.6-fold greater among Black than White people2 and 1.6-fold greater among Mexican American than non-Hispanic White people.3 Internationally, ICH incidence is substantially higher in low- and middle-income versus high-income countries, both as a proportion of all strokes and in absolute incidence rates.4,5 Several additional features of ICH make it a greater public health threat than conveyed by incidence numbers alone. ICH is arguably the deadliest form of acute stroke, with early-term mortality about 30% to 40% and no or minimal trend toward improvement over more recent time epochs.6\u20139 Incidence of ICH increases sharply with age and is therefore expected to remain substantial as the population ages, even with counterbalancing public health improvements in blood pressure (BP) control.8 Another growing source of ICH is more widespread use of anticoagulants,10 a trend likely to counterbalance the reduced ICH risk associated with increasing prescription of direct oral anticoagulants (DOACs) relative to vitamin K antagonists (VKAs).11 ICH thus remains in need of novel treatments and improved application of established approaches for every aspect of the disease: primary and secondary prevention, acute inpatient care, and poststroke rehabilitation and recovery. This guideline seeks to synthesize data in the ICH field into practical recommendations for clinical practice."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.10186"
    ],
    "c_title":[
      "Generative Artificial Intelligence: Implications for Biomedical and\n  Health Professions Education"
    ],
    "c_abstract":[
      "Generative AI has had a profound impact on biomedicine and health, both in\nprofessional work and in education. Based on large language models (LLMs),\ngenerative AI has been found to perform as well as humans in simulated\nsituations taking medical board exams, answering clinical questions, solving\nclinical cases, applying clinical reasoning, and summarizing information.\nGenerative AI is also being used widely in education, performing well in\nacademic courses and their assessments. This review summarizes the successes of\nLLMs and highlights some of their challenges in the context of education, most\nnotably aspects that may undermines the acquisition of knowledge and skills for\nprofessional work. It then provides recommendations for best practices\novercoming shortcomings for LLM use in education. Although there are challenges\nfor use of generative AI in education, all students and faculty, in biomedicine\nand health and beyond, must have understanding and be competent in its use."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00578",
    "a_title":"Federated Voxel Scene Graph for Intracranial Hemorrhage",
    "a_abstract":"Intracranial Hemorrhage is a potentially lethal condition whose manifestation\nis vastly diverse and shifts across clinical centers worldwide.\nDeep-learning-based solutions are starting to model complex relations between\nbrain structures, but still struggle to generalize. While gathering more\ndiverse data is the most natural approach, privacy regulations often limit the\nsharing of medical data. We propose the first application of Federated Scene\nGraph Generation. We show that our models can leverage the increased training\ndata diversity. For Scene Graph Generation, they can recall up to 20% more\nclinically relevant relations across datasets compared to models trained on a\nsingle centralized dataset. Learning structured data representation in a\nfederated setting can open the way to the development of new methods that can\nleverage this finer information to regularize across clients more effectively.",
    "explanation":"intracranial Hemorrhage is a potentially lethal condition whose manifestation is vastly diverse and shifts across\nclinical centers worldwide. Deep-learning-based solutions are starting to model complex relations between brain\nstructures, but still struggle to generalize.",
    "b_id":[
      "b25"
    ],
    "b_title":[
      "Voxel Scene Graph for Intracranial Hemorrhage"
    ],
    "b_abstract":[
      "Patients with Intracranial Hemorrhage (ICH) face a potentially life-threatening condition, and patient-centered individualized treatment remains challenging due to possible clinical complications. Deep-Learning-based methods can efficiently analyze the routinely acquired head CTs support decision-making. The majority of early work focuses on detection segmentation ICH, but do not model complex relations between ICH adjacent brain structures. In this work, we design tailored object method for which unite segmentation-grounded Scene Graph Generation (SGG) learn holistic representation cerebral scene. To best our knowledge, is first application SGG 3D voxel images. We evaluate two head-CT datasets demonstrate that recall up 74% clinically relevant relations. This lays foundation towards data. generated Graphs already provide insights clinician, are also valuable all downstream tasks as compact interpretable representation."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.19343"
    ],
    "c_title":[
      "Effect of a new type of healthy and live food supplement on osteoporosis\n  blood parameters and induced rheumatoid arthritis in Wistar rats"
    ],
    "c_abstract":[
      "Summary Osteoporosis is a skeletal disorder, characterized by a decrease in\nbone strength and puts the individual at risk for fracture. On the other hand,\nrheumatoid arthritis is a systemic disease of unknown etiology that causes\ninflammation of the joints of the organs. Purpose Due to the destructive\neffects of these diseases and its increasing prevalence and lack of appropriate\nmedication for treatment, the present study aimed to evaluate the therapeutic\neffect of a new type of healthy and live food supplement on rheumatoid\narthritis and induced osteoporosis in rats. Methods In this research, healthy\nand live food powder were synthesized by a new and green route. This organic\nbiomaterial was named NBS. The NBS food supplement had various vitamins, macro\nand micro molecules, and ingredients. The new healthy and nutritious diet\nshowed that the use of this supplement led to the return of the parameters to\nnormal levels. Results The concentration of 12.5 mg\/ kg showed the least\ntherapeutic effect and 50 mg\/ kg had the highest therapeutic effect for\nosteoporosis. The results of blood parameters involved in inflammation in both\nhealthy and patient groups showed that the use of complete adjuvant induction\ncauses joint inflammation. In the study of the interaction of the\nconcentrations, it was observed that the concentration of 50 mg\/ kg had the\nhighest therapeutic effect against the disease in the studied mice. Conclusion\nThe results showed that the new healthy and viable supplement restores the\nblood osteoporotic and rheumatoid factors of the mice to normal."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00614",
    "a_title":"Fast and scalable Wasserstein-1 neural optimal transport solver for\n  single-cell perturbation prediction",
    "a_abstract":"Predicting single-cell perturbation responses requires mapping between two\nunpaired single-cell data distributions. Optimal transport (OT) theory provides\na principled framework for constructing such mappings by minimizing transport\ncost. Recently, Wasserstein-2 ($W_2$) neural optimal transport solvers\n(\\textit{e.g.}, CellOT) have been employed for this prediction task. However,\n$W_2$ OT relies on the general Kantorovich dual formulation, which involves\noptimizing over two conjugate functions, leading to a complex min-max\noptimization problem that converges slowly. To address these challenges, we\npropose a novel solver based on the Wasserstein-1 ($W_1$) dual formulation.\nUnlike $W_2$, the $W_1$ dual simplifies the optimization to a maximization\nproblem over a single 1-Lipschitz function, thus eliminating the need for\ntime-consuming min-max optimization. While solving the $W_1$ dual only reveals\nthe transport direction and does not directly provide a unique optimal\ntransport map, we incorporate an additional step using adversarial training to\ndetermine an appropriate transport step size, effectively recovering the\ntransport map. Our experiments demonstrate that the proposed $W_1$ neural\noptimal transport solver can mimic the $W_2$ OT solvers in finding a unique and\n``monotonic\" map on 2D datasets. Moreover, the $W_1$ OT solver achieves\nperformance on par with or surpasses $W_2$ OT solvers on real single-cell\nperturbation datasets. Furthermore, we show that $W_1$ OT solver achieves $25\n\\sim 45\\times$ speedup, scales better on high dimensional transportation task,\nand can be directly applied on single-cell RNA-seq dataset with highly variable\ngenes. Our implementation and experiments are open-sourced at\n\\url{https:\/\/github.com\/poseidonchan\/w1ot}.",
    "explanation":"Predicting single-cell perturbation responses requires mapping between two unpaired single-\ncell data distributions. Optimal transport (OT) theory provides a principled framework for constructing\nsuch mappings by minimizing transport cost.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Multimodal pooled Perturb-CITE-seq screens in patient models define mechanisms of cancer immune evasion"
    ],
    "b_abstract":[
      "Resistance to immune checkpoint inhibitors (ICIs) is a key challenge in cancer therapy. To elucidate underlying mechanisms, we developed Perturb-CITE-sequencing (Perturb-CITE-seq), enabling pooled clustered regularly interspaced short palindromic repeat (CRISPR)\u2013Cas9 perturbations with single-cell transcriptome and protein readouts. In patient-derived melanoma cells and autologous tumor-infiltrating lymphocyte (TIL) co-cultures, we profiled transcriptomes and 20\u2009proteins in ~218,000\u2009cells under ~750\u2009perturbations associated with cancer cell-intrinsic ICI resistance (ICR). We recover known mechanisms of resistance, including defects in the interferon-\u03b3 (IFN-\u03b3)\u2013JAK\/STAT and antigen-presentation pathways in RNA, protein and perturbation space, and new ones, including loss\/downregulation of CD58. Loss of CD58 conferred immune evasion in multiple co-culture models and was downregulated in tumors of melanoma patients with ICR. CD58 protein expression was not induced by IFN-\u03b3 signaling, and CD58 loss conferred immune evasion without compromising major histocompatibility complex (MHC) expression, suggesting that it acts orthogonally to known mechanisms of ICR. This work provides a framework for the deciphering of complex mechanisms by large-scale perturbation screens with multimodal, single-cell readouts, and discovers potentially clinically relevant mechanisms of immune evasion."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.03470"
    ],
    "c_title":[
      "Positivstellens\\\"atze for polynomial matrices with universal quantifiers"
    ],
    "c_abstract":[
      "This paper studies Positivstellens\\\"atze for a polynomial matrix subject to\npolynomial matrix inequality constraints with universal quantifiers. We first\npresent a Scherer-Hol-type Positivstellensatz under the Archimedean condition.\nWhen the objective is a scalar polynomial, we further provide a sparse\nScherer-Hol-type Positivstellensatz in the presence of correlative sparsity.\nNext, without assuming the Archimedean condition, we derive\nPutinar-Vasilescu-type, P\\'olya-type, and Lasserre-Netzer-type\nPositivstellens\\\"atze under the same setting. These results can be viewed as\ncommon generalizations of corresponding Positivstellens\\\"atze in the cases of\npolynomials, polynomials with universal quantifiers, and polynomial matrices.\nFor the proofs, techniques from *-algebra, real algebraic geometry, operator\ntheory, and convex optimization are employed. Applications of the established\nPositivstellens\\\"atze to robust polynomial matrix optimization are also\ndiscussed."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00614",
    "a_title":"Fast and scalable Wasserstein-1 neural optimal transport solver for\n  single-cell perturbation prediction",
    "a_abstract":"Predicting single-cell perturbation responses requires mapping between two\nunpaired single-cell data distributions. Optimal transport (OT) theory provides\na principled framework for constructing such mappings by minimizing transport\ncost. Recently, Wasserstein-2 ($W_2$) neural optimal transport solvers\n(\\textit{e.g.}, CellOT) have been employed for this prediction task. However,\n$W_2$ OT relies on the general Kantorovich dual formulation, which involves\noptimizing over two conjugate functions, leading to a complex min-max\noptimization problem that converges slowly. To address these challenges, we\npropose a novel solver based on the Wasserstein-1 ($W_1$) dual formulation.\nUnlike $W_2$, the $W_1$ dual simplifies the optimization to a maximization\nproblem over a single 1-Lipschitz function, thus eliminating the need for\ntime-consuming min-max optimization. While solving the $W_1$ dual only reveals\nthe transport direction and does not directly provide a unique optimal\ntransport map, we incorporate an additional step using adversarial training to\ndetermine an appropriate transport step size, effectively recovering the\ntransport map. Our experiments demonstrate that the proposed $W_1$ neural\noptimal transport solver can mimic the $W_2$ OT solvers in finding a unique and\n``monotonic\" map on 2D datasets. Moreover, the $W_1$ OT solver achieves\nperformance on par with or surpasses $W_2$ OT solvers on real single-cell\nperturbation datasets. Furthermore, we show that $W_1$ OT solver achieves $25\n\\sim 45\\times$ speedup, scales better on high dimensional transportation task,\nand can be directly applied on single-cell RNA-seq dataset with highly variable\ngenes. Our implementation and experiments are open-sourced at\n\\url{https:\/\/github.com\/poseidonchan\/w1ot}.",
    "explanation":"Predicting single-cell perturbation responses requires mapping between two unpaired single-\ncell data distributions. Optimal transport (OT) theory provides a principled framework for constructing\nsuch mappings by minimizing transport cost.",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Causal identification of single-cell experimental perturbation effects with CINEMA-OT"
    ],
    "b_abstract":[
      "Abstract Recent advancements in single-cell technologies allow characterization of experimental perturbations at resolution. While methods have been developed to analyze such experiments, the application a strict causal framework has not yet explored for inference treatment effects level. Here we present causal-inference-based approach perturbation analysis, termed CINEMA-OT (causal independent effect module attribution + optimal transport). separates confounding sources variation from obtain an transport matching that reflects counterfactual cell pairs. These pairs represent responses permitting number novel analyses, as individual treatment-effect response clustering, and synergy analysis. We benchmark on array estimation tasks several simulated real datasets show it outperforms other analysis methods. Finally, perform two newly generated datasets: (1) rhinovirus cigarette-smoke-exposed airway organoids, (2) combinatorial cytokine stimulation immune cells. In these reveals potential mechanisms by which cigarette-smoke exposure dulls antiviral response, well logic governs chemokine secretion peripheral recruitment."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2501.05607"
    ],
    "c_title":[
      "Prediction of Binding Affinity for ErbB Inhibitors Using Deep Neural\n  Network Model with Morgan Fingerprints as Features"
    ],
    "c_abstract":[
      "The ErbB receptor family, including EGFR and HER2, plays a crucial role in\ncell growth and survival and is associated with the progression of various\ncancers such as breast and lung cancer. In this study, we developed a deep\nlearning model to predict the binding affinity of ErbB inhibitors using\nmolecular fingerprints derived from SMILES representations. The SMILES\nrepresentations for each ErbB inhibitor were obtained from the ChEMBL database.\nWe first generated Morgan fingerprints from the SMILES strings and applied\nAutoDock Vina docking to calculate the binding affinity values. After filtering\nthe dataset based on binding affinity, we trained a deep neural network (DNN)\nmodel to predict binding affinity values from the molecular fingerprints. The\nmodel achieved significant performance, with a Mean Squared Error (MSE) of\n0.2591, Mean Absolute Error (MAE) of 0.3658, and an R-squared value of 0.9389\non the training set. Although performance decreased slightly on the test set (R\nsquared = 0.7731), the model still demonstrated robust generalization\ncapabilities. These results indicate that the deep learning approach is highly\neffective for predicting the binding affinity of ErbB inhibitors, offering a\nvaluable tool for virtual screening and drug discovery."
    ],
    "c_categories":[
      "q-bio.BM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00749",
    "a_title":"PathoGen-X: A Cross-Modal Genomic Feature Trans-Align Network for\n  Enhanced Survival Prediction from Histopathology Images",
    "a_abstract":"Accurate survival prediction is essential for personalized cancer treatment.\nHowever, genomic data - often a more powerful predictor than pathology data -\nis costly and inaccessible. We present the cross-modal genomic feature\ntranslation and alignment network for enhanced survival prediction from\nhistopathology images (PathoGen-X). It is a deep learning framework that\nleverages both genomic and imaging data during training, relying solely on\nimaging data at testing. PathoGen-X employs transformer-based networks to align\nand translate image features into the genomic feature space, enhancing weaker\nimaging signals with stronger genomic signals. Unlike other methods, PathoGen-X\ntranslates and aligns features without projecting them to a shared latent space\nand requires fewer paired samples. Evaluated on TCGA-BRCA, TCGA-LUAD, and\nTCGA-GBM datasets, PathoGen-X demonstrates strong survival prediction\nperformance, emphasizing the potential of enriched imaging models for\naccessible cancer prognosis.",
    "explanation":"Accurate survival prediction is essential for personalized\ncancer treatment. . It is a\ndeep learning framework that leverages both genomic and\nimaging data during training, relying solely on imaging data\nat testing. ",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "A 2021 update on cancer image analytics with deep learning"
    ],
    "b_abstract":[
      "Deep learning (DL)-based interpretation of medical images has reached a critical juncture of expanding outside research projects into translational ones, and is ready to make its way to the clinics. Advances over the last decade in data availability, DL techniques, as well as computing capabilities have accelerated this journey. Through this journey, today we have a better understanding of the challenges to and pitfalls of wider adoption of DL into clinical care, which, according to us, should and will drive the advances in this field in the next few years. The most important among these challenges are the lack of an appropriately digitized environment within healthcare institutions, the lack of adequate open and representative datasets on which DL algorithms can be trained and tested, and the lack of robustness of widely used DL training algorithms to certain pervasive pathological characteristics of medical images and repositories. In this review, we provide an overview of the role of imaging in oncology, the different techniques that are shaping the way DL algorithms are being made ready for clinical use, and also the problems that DL techniques still need to address before DL can find a home in clinics. Finally, we also provide a summary of how DL can potentially drive the adoption of digital pathology, vendor neutral archives, and picture archival and communication systems. We caution that the respective researchers may find the coverage of their own fields to be at a high-level. This is so by design as this format is meant to only introduce those looking in from outside of deep learning and medical research, respectively, to gain an appreciation for the main concerns and limitations of these two fields instead of telling them something new about their own."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.16938"
    ],
    "c_title":[
      "Interpretable Machine Learning for Oral Lesion Diagnosis through\n  Prototypical Instances Identification"
    ],
    "c_abstract":[
      "Decision-making processes in healthcare can be highly complex and\nchallenging. Machine Learning tools offer significant potential to assist in\nthese processes. However, many current methodologies rely on complex models\nthat are not easily interpretable by experts. This underscores the need to\ndevelop interpretable models that can provide meaningful support in clinical\ndecision-making. When approaching such tasks, humans typically compare the\nsituation at hand to a few key examples and representative cases imprinted in\ntheir memory. Using an approach which selects such exemplary cases and grounds\nits predictions on them could contribute to obtaining high-performing\ninterpretable solutions to such problems. To this end, we evaluate PivotTree,\nan interpretable prototype selection model, on an oral lesion detection\nproblem, specifically trying to detect the presence of neoplastic, aphthous and\ntraumatic ulcerated lesions from oral cavity images. We demonstrate the\nefficacy of using such method in terms of performance and offer a qualitative\nand quantitative comparison between exemplary cases and ground-truth prototypes\nselected by experts."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00749",
    "a_title":"PathoGen-X: A Cross-Modal Genomic Feature Trans-Align Network for\n  Enhanced Survival Prediction from Histopathology Images",
    "a_abstract":"Accurate survival prediction is essential for personalized cancer treatment.\nHowever, genomic data - often a more powerful predictor than pathology data -\nis costly and inaccessible. We present the cross-modal genomic feature\ntranslation and alignment network for enhanced survival prediction from\nhistopathology images (PathoGen-X). It is a deep learning framework that\nleverages both genomic and imaging data during training, relying solely on\nimaging data at testing. PathoGen-X employs transformer-based networks to align\nand translate image features into the genomic feature space, enhancing weaker\nimaging signals with stronger genomic signals. Unlike other methods, PathoGen-X\ntranslates and aligns features without projecting them to a shared latent space\nand requires fewer paired samples. Evaluated on TCGA-BRCA, TCGA-LUAD, and\nTCGA-GBM datasets, PathoGen-X demonstrates strong survival prediction\nperformance, emphasizing the potential of enriched imaging models for\naccessible cancer prognosis.",
    "explanation":"Accurate survival prediction is essential for personalized\ncancer treatment. . It is a\ndeep learning framework that leverages both genomic and\nimaging data during training, relying solely on imaging data\nat testing. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classification"
    ],
    "b_abstract":[
      "Multiple instance learning (MIL) is a powerful tool to solve the weakly supervised classification in whole slide image (WSI) based pathology diagnosis. However, current MIL methods are usually on independent and identical distribution hypothesis, thus neglect correlation among different instances. To address this problem, we proposed new framework, called correlated MIL, provided proof for convergence. Based devised Transformer (TransMIL), which explored both morphological spatial information. The TransMIL can effectively deal with unbalanced\/balanced binary\/multiple great visualization interpretability. We conducted various experiments three computational problems achieved better performance faster convergence compared state-of-the-art methods. test AUC binary tumor be up 93.09% over CAMELYON16 dataset. And cancer subtypes 96.03% 98.82% TCGA-NSCLC dataset TCGA-RCC dataset, respectively. Implementation available at: https:\/\/github.com\/szc19990412\/TransMIL."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.03001"
    ],
    "c_title":[
      "Multicellular self-organization in Escherichia coli"
    ],
    "c_abstract":[
      "Escherichia coli has long been a trusty companion, maintaining health in our\nguts and advancing biological knowledge in the laboratory. In light of recent\nfindings, we discuss multicellular self-organization in E. coli and develop\ngeneral ideas for multicellularity, including the necessity for multicellular\ndynamics and interpretation by dynamic graphs, applicable to both unicellular\nand multicellular organisms. In this context, we next discuss the documented\nbehaviors of E. coli self-organization (rosette formation, multicellular\nextension, and attached dormancy) and two potential behaviors (internal\ncommunication and mating). Finally, by comparing the dynamic graphs for\ndifferent communities, we develop principles relevant to the theory of\nmulticellularity."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00758",
    "a_title":"Inverse methods for freeform optical design",
    "a_abstract":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design, based on Hamilton's characteristic functions and\nconservation of luminous flux, and briefly explain the connection with the\nmathematical theory of optimal transport. We outline several iterative\nleast-squares solvers for our models and demonstrate their performance for a\nfew challenging problems.",
    "explanation":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design .We outline several iterative least-squares solvers for our models and demonstrate their\nperformance for a few challenging problems.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Introduction to Nonimaging Optics, second edition"
    ],
    "b_abstract":[
      "Introduction to Nonimaging Optics covers the theoretical foundations and design methods of nonimaging optics, as well as key concepts from related fields. This fully updated, revised, and expanded Second Edition: \u2022 Features a new and intuitive introduction with a basic description of the advantages of nonimaging optics \u2022 Adds new chapters on wavefronts for a prescribed output (irradiance or intensity), infinitesimal \u00e9tendue optics (generalization of the aplanatic optics), and K\u00f6hler optics and color mixing \u2022 Incorporates new material on the simultaneous multiple surface (SMS) design method in 3-D, integral invariants, and \u00e9tendue 2-D \u2022 Contains 21 chapters, 24 fully worked and several other examples, and 1,000+ illustrations, including photos of real devices \u2022 Addresses applications ranging from solar energy concentration to illumination engineering Introduction to Nonimaging Optics, Second Edition invites newcomers to explore the growing field of nonimaging optics, while providing seasoned veterans with an extensive reference book."
    ],
    "b_categories":[
      "physics.optics"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2501.08789"
    ],
    "c_title":[
      "On Erlang Queue with Multiple Arrivals and its Time-changed Variant"
    ],
    "c_abstract":[
      "We introduce and study a queue with the Erlang service system and whose\narrivals are governed by a counting process in which there is a possibility of\nfinitely many arrivals in an infinitesimal time interval. We call it the Erlang\nqueue with multiple arrivals. Some of its distributional properties are\nobtained that includes the state-phase probabilities, the mean queue length and\nthe distribution of busy period etc. Also, we study a time-changed variant of\nit by subordinating it with an independent inverse stable subordinator where we\nobtain its state probabilities and the mean queue length."
    ],
    "c_categories":[
      "math.PR"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.00758",
    "a_title":"Inverse methods for freeform optical design",
    "a_abstract":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design, based on Hamilton's characteristic functions and\nconservation of luminous flux, and briefly explain the connection with the\nmathematical theory of optimal transport. We outline several iterative\nleast-squares solvers for our models and demonstrate their performance for a\nfew challenging problems.",
    "explanation":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design .We outline several iterative least-squares solvers for our models and demonstrate their\nperformance for a few challenging problems.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "Inverse methods for illumination optics"
    ],
    "b_abstract":[
      "\u2022 A submitted manuscript is the version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website. \u2022 The final author version and the galley proof are versions of the publication after peer review. \u2022 The final published version features the final layout of the paper including the volume, issue and page numbers."
    ],
    "b_categories":[
      "math.MP"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2503.16249"
    ],
    "c_title":[
      "A GHz fiber comb on silica"
    ],
    "c_abstract":[
      "We present a 1 GHz Yb-fiber laser frequency comb built on silica substrates,\nutilizing \"optical cubes\" to house all optical components, ensuring long-term\nstability and practical operation. Both the femtosecond laser and f-to-2f\ninterferometer are constructed to silica bricks, with a compact footprint of\n290 mm $\\times$ 250 mm, and a total weight of 1.8 kg. This system provides a\nstable repetition rate, offset frequency, and a supercontinuum spanning\n460-1560 nm without requiring amplification. The carrier-envelop offset\nfrequency exhibits exceptional stability, with a fractional frequency\ninstability of $3.07\\times 10^{-18}$ at a 1 second averaging time, improving to\n$2.12\\times 10^{-20}$ at a 10,000 second, maintaining uninterrupted operation\nfor over 60 hours. This work demonstrates a high-performance GHz fiber-based\nfrequency comb, paving the way for applications beyond laboratory environments,\nincluding dual-comb spectroscopy, astronomical spectrograph calibration, and\nportable optical clocks."
    ],
    "c_categories":[
      "physics.optics"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.01291",
    "a_title":"Deep Multi-contrast Cardiac MRI Reconstruction via vSHARP with Auxiliary\n  Refinement Network",
    "a_abstract":"Cardiac MRI (CMRI) is a cornerstone imaging modality that provides in-depth\ninsights into cardiac structure and function. Multi-contrast CMRI (MCCMRI),\nwhich acquires sequences with varying contrast weightings, significantly\nenhances diagnostic capabilities by capturing a wide range of cardiac tissue\ncharacteristics. However, MCCMRI is often constrained by lengthy acquisition\ntimes and susceptibility to motion artifacts. To mitigate these challenges,\naccelerated imaging techniques that use k-space undersampling via different\nsampling schemes at acceleration factors have been developed to shorten scan\ndurations. In this context, we propose a deep learning-based reconstruction\nmethod for 2D dynamic multi-contrast, multi-scheme, and multi-acceleration MRI.\nOur approach integrates the state-of-the-art vSHARP model, which utilizes\nhalf-quadratic variable splitting and ADMM optimization, with a Variational\nNetwork serving as an Auxiliary Refinement Network (ARN) to better adapt to the\ndiverse nature of MCCMRI data. Specifically, the subsampled k-space data is fed\ninto the ARN, which produces an initial prediction for the denoising step used\nby vSHARP. This, along with the subsampled k-space, is then used by vSHARP to\ngenerate high-quality 2D sequence predictions. Our method outperforms\ntraditional reconstruction techniques and other vSHARP-based models.",
    "explanation":"Cardiac MRI (CMRI) is a cornerstone imaging modality that\nprovides in-depth insights into cardiac structure and function.  Our approach integrates the state-of-the-art vSHARP model, which uti-\nlizes half-quadratic variable splitting and ADMM optimization, with a\nVariational Network serving as an Auxiliary Refinement Network (ARN)\nto better adapt to the diverse nature of MCCMRI data. ",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting\n  Universal Machine Learning for Accelerated Cardiac MRI"
    ],
    "b_abstract":[
      "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically gold-standard technique for diagnosing cardiac diseases, thanks to its ability provide diverse information with multiple modalities and anatomical views. Accelerated MRI is highly expected achieve time-efficient patient-friendly imaging, then advanced image reconstruction approaches are required recover high-quality, interpretable images from undersampled measurements. However, the lack of publicly available k-space dataset in terms both quantity diversity severely hindered substantial technological progress, particularly data-driven artificial intelligence. Here, we standardized, diverse, high-quality CMRxRecon2024 facilitate technical development, fair evaluation, clinical transfer approaches, towards promoting universal frameworks that enable fast robust reconstructions across different protocols practice. To best our knowledge, largest most dataset. It acquired 330 healthy volunteers, covering commonly used modalities, views, acquisition trajectories workflows. Besides, an open platform tutorials, benchmarks, data processing tools provided usage, method performance evaluation."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.06561"
    ],
    "c_title":[
      "Where to Go Next Day: Multi-scale Spatial-Temporal Decoupled Model for\n  Mid-term Human Mobility Prediction"
    ],
    "c_abstract":[
      "Predicting individual mobility patterns is crucial across various\napplications. While current methods mainly focus on predicting the next\nlocation for personalized services like recommendations, they often fall short\nin supporting broader applications such as traffic management and epidemic\ncontrol, which require longer period forecasts of human mobility. This study\naddresses mid-term mobility prediction, aiming to capture daily travel patterns\nand forecast trajectories for the upcoming day or week. We propose a novel\nMulti-scale Spatial-Temporal Decoupled Predictor (MSTDP) designed to\nefficiently extract spatial and temporal information by decoupling daily\ntrajectories into distinct location-duration chains. Our approach employs a\nhierarchical encoder to model multi-scale temporal patterns, including daily\nrecurrence and weekly periodicity, and utilizes a transformer-based decoder to\nglobally attend to predicted information in the location or duration chain.\nAdditionally, we introduce a spatial heterogeneous graph learner to capture\nmulti-scale spatial relationships, enhancing semantic-rich representations.\nExtensive experiments, including statistical physics analysis, are conducted on\nlarge-scale mobile phone records in five cities (Boston, Los Angeles, SF Bay\nArea, Shanghai, and Tokyo), to demonstrate MSTDP's advantages. Applied to\nepidemic modeling in Boston, MSTDP significantly outperforms the\nbest-performing baseline, achieving a remarkable 62.8% reduction in MAE for\ncumulative new cases."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.01291",
    "a_title":"Deep Multi-contrast Cardiac MRI Reconstruction via vSHARP with Auxiliary\n  Refinement Network",
    "a_abstract":"Cardiac MRI (CMRI) is a cornerstone imaging modality that provides in-depth\ninsights into cardiac structure and function. Multi-contrast CMRI (MCCMRI),\nwhich acquires sequences with varying contrast weightings, significantly\nenhances diagnostic capabilities by capturing a wide range of cardiac tissue\ncharacteristics. However, MCCMRI is often constrained by lengthy acquisition\ntimes and susceptibility to motion artifacts. To mitigate these challenges,\naccelerated imaging techniques that use k-space undersampling via different\nsampling schemes at acceleration factors have been developed to shorten scan\ndurations. In this context, we propose a deep learning-based reconstruction\nmethod for 2D dynamic multi-contrast, multi-scheme, and multi-acceleration MRI.\nOur approach integrates the state-of-the-art vSHARP model, which utilizes\nhalf-quadratic variable splitting and ADMM optimization, with a Variational\nNetwork serving as an Auxiliary Refinement Network (ARN) to better adapt to the\ndiverse nature of MCCMRI data. Specifically, the subsampled k-space data is fed\ninto the ARN, which produces an initial prediction for the denoising step used\nby vSHARP. This, along with the subsampled k-space, is then used by vSHARP to\ngenerate high-quality 2D sequence predictions. Our method outperforms\ntraditional reconstruction techniques and other vSHARP-based models.",
    "explanation":"Cardiac MRI (CMRI) is a cornerstone imaging modality that\nprovides in-depth insights into cardiac structure and function.  Our approach integrates the state-of-the-art vSHARP model, which uti-\nlizes half-quadratic variable splitting and ADMM optimization, with a\nVariational Network serving as an Auxiliary Refinement Network (ARN)\nto better adapt to the diverse nature of MCCMRI data. ",
    "b_id":[
      "b19"
    ],
    "b_title":[
      "vSHARP: variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse-Problems"
    ],
    "b_abstract":[
      "Medical Imaging (MI) tasks, such as accelerated parallel Magnetic Resonance Imaging (MRI), often involve reconstructing an image from noisy or incomplete measurements. This amounts to solving ill-posed inverse problems, where a satisfactory closed-form analytical solution is not available. Traditional methods such as Compressed Sensing (CS) in MRI reconstruction can be time-consuming or prone to obtaining low-fidelity images. Recently, a plethora of Deep Learning (DL) approaches have demonstrated superior performance in inverse-problem solving, surpassing conventional methods. In this study, we propose vSHARP (variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse Problems), a novel DL-based method for solving ill-posed inverse problems arising in MI. vSHARP utilizes the Half-Quadratic Variable Splitting method and employs the Alternating Direction Method of Multipliers (ADMM) to unroll the optimization process. For data consistency, vSHARP unrolls a differentiable gradient descent process in the image domain, while a DL-based denoiser, such as a U-Net architecture, is applied to enhance image quality. vSHARP also employs a dilated-convolution DL-based model to predict the Lagrange multipliers for the ADMM initialization. We evaluate vSHARP on tasks of accelerated parallel MRI Reconstruction using two distinct datasets and on accelerated parallel dynamic MRI Reconstruction using another dataset. Our comparative analysis with state-of-the-art methods demonstrates the superior performance of vSHARP in these applications."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04504"
    ],
    "c_title":[
      "Integrating anatomy and electrophysiology in the healthy human heart:\n  Insights from biventricular statistical shape analysis using universal\n  coordinates"
    ],
    "c_abstract":[
      "A cardiac digital twin is a virtual replica of a patient-specific heart,\nmimicking its anatomy and physiology. A crucial step of building a cardiac\ndigital twin is anatomical twinning, where the computational mesh of the\ndigital twin is tailored to the patient-specific cardiac anatomy. In a number\nof studies, the effect of anatomical variation on clinically relevant\nfunctional measurements like electrocardiograms (ECGs) is investigated, using\ncomputational simulations. While such a simulation environment provides\nresearchers with a carefully controlled ground truth, the impact of anatomical\ndifferences on functional measurements in real-world patients remains\nunderstudied. In this study, we develop a biventricular statistical shape model\nand use it to quantify the effect of biventricular anatomy on ECG-derived and\ndemographic features, providing novel insights for the development of digital\ntwins of cardiac electrophysiology. To this end, a dataset comprising\nhigh-resolution cardiac CT scans from 271 healthy individuals, including\nathletes, is utilized. Furthermore, a novel, universal, ventricular\ncoordinate-based method is developed to establish lightweight shape\ncorrespondence. The performance of the shape model is rigorously established,\nfocusing on its dimensionality reduction capabilities and the training data\nrequirements. Additionally, a comprehensive synthetic cohort is made available,\nfeaturing ready-to-use biventricular meshes with fiber structures and\nanatomical region annotations. These meshes are well-suited for\nelectrophysiological simulations."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.01758",
    "a_title":"Disentangled PET Lesion Segmentation",
    "a_abstract":"PET imaging is an invaluable tool in clinical settings as it captures the\nfunctional activity of both healthy anatomy and cancerous lesions. Developing\nautomatic lesion segmentation methods for PET images is crucial since manual\nlesion segmentation is laborious and prone to inter- and intra-observer\nvariability. We propose PET-Disentangler, a 3D disentanglement method that uses\na 3D UNet-like encoder-decoder architecture to disentangle disease and normal\nhealthy anatomical features with losses for segmentation, reconstruction, and\nhealthy component plausibility. A critic network is used to encourage the\nhealthy latent features to match the distribution of healthy samples and thus\nencourages these features to not contain any lesion-related features. Our\nquantitative results show that PET-Disentangler is less prone to incorrectly\ndeclaring healthy and high tracer uptake regions as cancerous lesions, since\nsuch uptake pattern would be assigned to the disentangled healthy component.",
    "explanation":"PET imaging is an invaluable tool in clinical settings as it\ncaptures the functional activity of both healthy anatomy and\ncancerous lesions. Developing automatic lesion segmentation\nmethods for PET images is crucial since manual lesion seg-\nmentation is laborious and prone to inter- and intra-observer\nvariability. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Multi-site quality and variability analysis of 3D FDG PET segmentations based on phantom and clinical image data"
    ],
    "b_abstract":[
      "Purpose: Radiomics utilizes a large number of image-derived features for quantifying tumor characteristics that can in turn be correlated with response and prognosis. Unfortunately, extraction and analysis of such image-based features is subject to measurement variability and bias. The challenge for radiomics is particularly acute in Positron Emission Tomography (PET) where limited resolution, a high noise component related to the limited stochastic nature of the raw data, and the wide variety of reconstruction options confound quantitative feature metrics. Extracted feature quality is also affected by tumor segmentation methods used to define regions over which to calculate features, making it challenging to produce consistent radiomics analysis results across multiple institutions that use different segmentation algorithms in their PET image analysis. Understanding each element contributing to these inconsistencies in quantitative image feature and metric generation is paramount for ultimate utilization of these methods in multi-institutional trials and clinical oncology decision making. Methods: To assess segmentation quality and consistency at the multi-institutional level, we conducted a study of seven institutional members of the National Cancer Institute Quantitative Imaging Network. For the study, members were asked to segment a common set of phantom PET scans acquired over a range of imaging conditions as well as a second set of head and neck cancer (HNC) PET scans. Segmentations were generated at each institution using their preferred approach. In addition, participants were asked to repeat segmentations with a time interval between initial and repeat segmentation. This procedure resulted in overall 806 phantom insert and 641 lesion segmentations. Subsequently, the volume was computed from the segmentations and compared to the corresponding reference volume by means of statistical analysis. Results: On the two test sets (phantom and HNC PET scans), the performance of the seven segmentation approaches was as follows. On the phantom test set, the mean relative volume errors ranged from 29.9 to 87.8% of the ground truth reference volumes, and the repeat difference for each institution ranged between -36.4 to 39.9%. On the HNC test set, the mean relative volume error ranged between -50.5 to 701.5%, and the repeat difference for each institution ranged between -37.7 to 31.5%. In addition, performance measures per phantom insert\/lesion size categories are given in the paper. On phantom data, regression analysis resulted in coefficient of variation (CV) components of 42.5% for scanners, 26.8% for institutional approaches, 21.1% for repeated segmentations, 14.3% for relative contrasts, 5.3% for count statistics (acquisition times), and 0.0% for repeated scans. Analysis showed that the CV components for approaches and repeated segmentations were significantly larger on the HNC test set with increases by 112.7% and 102.4%, respectively. Conclusion: Analysis results underline the importance of PET scanner reconstruction harmonization and imaging protocol standardization for quantification of lesion volumes. In addition, to enable a distributed multi-site analysis of FDG PET images, harmonization of analysis approaches and operator training in combination with highly automated segmentation methods seems to be advisable. Future work will focus on quantifying the impact of segmentation variation on radiomics system performance."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.07540"
    ],
    "c_title":[
      "AI-Enabled Knowledge Sharing for Enhanced Collaboration and\n  Decision-Making in Non-Profit Healthcare Organizations: A Scoping Review\n  Protocol"
    ],
    "c_abstract":[
      "This protocol outlines a scoping review designed to systematically map the\nexisting body of evidence on AI-enabled knowledge sharing in resource-limited\nnon-profit healthcare organizations. The review aims to investigate how such\ntechnologies enhance collaboration and decision-making, particularly in the\ncontext of reduced external support following the cessation of USAID\noperations. Guided by three theoretical frameworks namely, the Resource-Based\nView, Dynamic Capabilities Theory, and Absorptive Capacity Theory, this study\nwill explore the dual role of AI as a strategic resource and an enabler of\norganizational learning and agility. The protocol details a rigorous\nmethodological approach based on PRISMA-ScR guidelines, encompassing a\nsystematic search strategy across multiple databases, inclusion and exclusion\ncriteria, and a structured data extraction process. By integrating theoretical\ninsights with empirical evidence, this scoping review seeks to identify\ncritical gaps in the literature and inform the design of effective,\nresource-optimized AI solutions in non-profit healthcare settings."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.01758",
    "a_title":"Disentangled PET Lesion Segmentation",
    "a_abstract":"PET imaging is an invaluable tool in clinical settings as it captures the\nfunctional activity of both healthy anatomy and cancerous lesions. Developing\nautomatic lesion segmentation methods for PET images is crucial since manual\nlesion segmentation is laborious and prone to inter- and intra-observer\nvariability. We propose PET-Disentangler, a 3D disentanglement method that uses\na 3D UNet-like encoder-decoder architecture to disentangle disease and normal\nhealthy anatomical features with losses for segmentation, reconstruction, and\nhealthy component plausibility. A critic network is used to encourage the\nhealthy latent features to match the distribution of healthy samples and thus\nencourages these features to not contain any lesion-related features. Our\nquantitative results show that PET-Disentangler is less prone to incorrectly\ndeclaring healthy and high tracer uptake regions as cancerous lesions, since\nsuch uptake pattern would be assigned to the disentangled healthy component.",
    "explanation":"PET imaging is an invaluable tool in clinical settings as it\ncaptures the functional activity of both healthy anatomy and\ncancerous lesions. Developing automatic lesion segmentation\nmethods for PET images is crucial since manual lesion seg-\nmentation is laborious and prone to inter- and intra-observer\nvariability. ",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "A review on segmentation of positron emission tomography images"
    ],
    "b_abstract":[
      "Positron Emission Tomography (PET), a non-invasive functional imaging method at the molecular level, images the distribution of biologically targeted radiotracers with high sensitivity. PET imaging provides detailed quantitative information about many diseases and is often used to evaluate inflammation, infection, and cancer by detecting emitted photons from a radiotracer localized to abnormal cells. In order to differentiate abnormal tissue from surrounding areas in PET images, image segmentation methods play a vital role; therefore, accurate image segmentation is often necessary for proper disease detection, diagnosis, treatment planning, and follow-ups. In this review paper, we present state-of-the-art PET image segmentation methods, as well as the recent advances in image segmentation techniques. In order to make this manuscript self-contained, we also briefly explain the fundamentals of PET imaging, the challenges of diagnostic PET image analysis, and the effects of these challenges on the segmentation results."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.03001"
    ],
    "c_title":[
      "Multicellular self-organization in Escherichia coli"
    ],
    "c_abstract":[
      "Escherichia coli has long been a trusty companion, maintaining health in our\nguts and advancing biological knowledge in the laboratory. In light of recent\nfindings, we discuss multicellular self-organization in E. coli and develop\ngeneral ideas for multicellularity, including the necessity for multicellular\ndynamics and interpretation by dynamic graphs, applicable to both unicellular\nand multicellular organisms. In this context, we next discuss the documented\nbehaviors of E. coli self-organization (rosette formation, multicellular\nextension, and attached dormancy) and two potential behaviors (internal\ncommunication and mating). Finally, by comparing the dynamic graphs for\ndifferent communities, we develop principles relevant to the theory of\nmulticellularity."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03389",
    "a_title":"Neurons for Neutrons: A Transformer Model for Computation Load\n  Estimation on Domain-Decomposed Neutron Transport Problems",
    "a_abstract":"Domain decomposition is a technique used to reduce memory overhead on large\nneutron transport problems. Currently, the optimal load-balanced processor\nallocation for these domains is typically determined through small-scale\nsimulations of the problem, which can be time-consuming for researchers and\nmust be repeated anytime a problem input is changed. We propose a Transformer\nmodel with a unique 3D input embedding, and input representations designed for\ndomain-decomposed neutron transport problems, which can predict the subdomain\ncomputation loads generated by small-scale simulations. We demonstrate that\nsuch a model trained on domain-decomposed Small Modular Reactor (SMR)\nsimulations achieves 98.2% accuracy while being able to skip the small-scale\nsimulation step entirely. Tests of the model's robustness on variant fuel\nassemblies, other problem geometries, and changes in simulation parameters are\nalso discussed.",
    "explanation":"Currently, the optimal load-\nbalanced processor allocation for these domains is typically determined\nthrough small-scale simulations of the problem, which can be time-consuming\nfor researchers and must be repeated anytime a problem input is changed.\nWe propose a Transformer model with a unique 3D input embedding, and\ninput representations designed for domain-decomposed neutron transport\nproblems, which can predict the subdomain computation loads generated\nby small-scale simulations.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Attention Is All You Need"
    ],
    "b_abstract":[
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. best performing also connect the encoder and decoder through attention mechanism. We propose a new simple network architecture, Transformer, solely mechanisms, dispensing with recurrence convolutions entirely. Experiments two machine translation tasks show these to be superior quality while being more parallelizable requiring significantly less time train. Our model achieves 28.4 BLEU WMT 2014 English-to-German task, improving over existing results, including ensembles by 2 BLEU. On English-to-French our establishes single-model state-of-the-art score of 41.8 after training for 3.5 days eight GPUs, small fraction costs from literature. that Transformer generalizes well other applying it successfully English constituency parsing both large limited data."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.10153"
    ],
    "c_title":[
      "Contemporaneous optical-radio observations of a fast radio burst in a\n  close galaxy pair"
    ],
    "c_abstract":[
      "We present the MeerKAT discovery and MeerLICHT contemporaneous optical\nobservations of the Fast Radio Burst (FRB) 20230808F, which was found to have a\ndispersion measure of $\\mathrm{DM}=653.2\\pm0.4\\mathrm{\\,pc\\,cm^{-3}}$. FRB\n20230808F has a scattering timescale $\\tau_{s}=3.1\\pm0.1\\,\\mathrm{ms}$ at\n$1563.6$ MHz, a rotation measure\n$\\mathrm{RM}=169.4\\pm0.2\\,\\mathrm{rad\\,m^{-2}}$, and a radio fluence\n$F_{\\mathrm{radio}}=1.72\\pm0.01\\,\\mathrm{Jy\\,ms}$. We find no optical\ncounterpart in the time immediately after the FRB, nor in the three months\nafter the FRB during which we continued to monitor the field of the FRB. We set\nan optical upper flux limit in MeerLICHT's $q$-band of $11.7\\,\\mathrm{\\mu Jy}$\nfor a 60 s exposure which started $\\sim3.4$ s after the burst, which\ncorresponds to an optical fluence, $F_{\\mathrm{opt}}$, of\n$0.039\\,\\mathrm{Jy\\,ms}$ on a timescale of $\\sim3.4$ s. We obtain an estimate\nfor the $q-$band luminosity limit of $vL_{v}\\sim\n1.3\\times10^{43}\\,\\mathrm{erg\\,s^{-1}}$. We localise the burst to a close\ngalaxy pair at a redshift of $z_{\\mathrm{spec}}=0.3472\\pm0.0002$. Our time\ndelay of $\\sim3.4$ s between the FRB arrival time and the start of our optical\nexposure is the shortest ever for an as yet non-repeating FRB, and hence the\nclosest to simultaneous optical follow-up that exists for such an FRB."
    ],
    "c_categories":[
      "astro-ph.HE"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03389",
    "a_title":"Neurons for Neutrons: A Transformer Model for Computation Load\n  Estimation on Domain-Decomposed Neutron Transport Problems",
    "a_abstract":"Domain decomposition is a technique used to reduce memory overhead on large\nneutron transport problems. Currently, the optimal load-balanced processor\nallocation for these domains is typically determined through small-scale\nsimulations of the problem, which can be time-consuming for researchers and\nmust be repeated anytime a problem input is changed. We propose a Transformer\nmodel with a unique 3D input embedding, and input representations designed for\ndomain-decomposed neutron transport problems, which can predict the subdomain\ncomputation loads generated by small-scale simulations. We demonstrate that\nsuch a model trained on domain-decomposed Small Modular Reactor (SMR)\nsimulations achieves 98.2% accuracy while being able to skip the small-scale\nsimulation step entirely. Tests of the model's robustness on variant fuel\nassemblies, other problem geometries, and changes in simulation parameters are\nalso discussed.",
    "explanation":"Currently, the optimal load-\nbalanced processor allocation for these domains is typically determined\nthrough small-scale simulations of the problem, which can be time-consuming\nfor researchers and must be repeated anytime a problem input is changed.\nWe propose a Transformer model with a unique 3D input embedding, and\ninput representations designed for domain-decomposed neutron transport\nproblems, which can predict the subdomain computation loads generated\nby small-scale simulations.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Continuous-energy Monte Carlo neutron transport on GPUs in the Shift code"
    ],
    "b_abstract":[
      "A continuous-energy Monte Carlo neutron transport solver executing on GPUs has been developed within the Shift code. Several algorithmic approaches are considered, including both history-based and event-based implementations. Unlike in previous work involving multigroup Monte Carlo transport, it is demonstrated that event-based algorithms significantly outperform a history-based approach for continuous-energy transport as a result of increased device occupancy and reduced thread divergence. Numerical results are presented for detailed full-core models of a small modular reactor (SMR), including a model containing depleted fuel materials. These results demonstrate the substantial gains in performance that are possible with the latest-generation of GPUs. On the depleted SMR core configuration, an NVIDIA P100 GPU with 56 streaming multiprocessors provides performance equivalent to 90 CPU cores, and the latest V100 GPU with 80 multiprocessors offers the performance of more than 150 CPU cores."
    ],
    "b_categories":[
      "astro-ph.HE"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.07540"
    ],
    "c_title":[
      "AI-Enabled Knowledge Sharing for Enhanced Collaboration and\n  Decision-Making in Non-Profit Healthcare Organizations: A Scoping Review\n  Protocol"
    ],
    "c_abstract":[
      "This protocol outlines a scoping review designed to systematically map the\nexisting body of evidence on AI-enabled knowledge sharing in resource-limited\nnon-profit healthcare organizations. The review aims to investigate how such\ntechnologies enhance collaboration and decision-making, particularly in the\ncontext of reduced external support following the cessation of USAID\noperations. Guided by three theoretical frameworks namely, the Resource-Based\nView, Dynamic Capabilities Theory, and Absorptive Capacity Theory, this study\nwill explore the dual role of AI as a strategic resource and an enabler of\norganizational learning and agility. The protocol details a rigorous\nmethodological approach based on PRISMA-ScR guidelines, encompassing a\nsystematic search strategy across multiple databases, inclusion and exclusion\ncriteria, and a structured data extraction process. By integrating theoretical\ninsights with empirical evidence, this scoping review seeks to identify\ncritical gaps in the literature and inform the design of effective,\nresource-optimized AI solutions in non-profit healthcare settings."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04682",
    "a_title":"DNN-based 3D Cloud Retrieval for Variable Solar Illumination and\n  Multiview Spaceborne Imaging",
    "a_abstract":"Climate studies often rely on remotely sensed images to retrieve\ntwo-dimensional maps of cloud properties. To advance volumetric analysis, we\nfocus on recovering the three-dimensional (3D) heterogeneous extinction\ncoefficient field of shallow clouds using multiview remote sensing data.\nClimate research requires large-scale worldwide statistics. To enable scalable\ndata processing, previous deep neural networks (DNNs) can infer at spaceborne\nremote sensing downlink rates. However, prior methods are limited to a fixed\nsolar illumination direction. In this work, we introduce the first scalable\nDNN-based system for 3D cloud retrieval that accommodates varying camera poses\nand solar directions. By integrating multiview cloud intensity images with\ncamera poses and solar direction data, we achieve greater flexibility in\nrecovery. Training of the DNN is performed by a novel two-stage scheme to\naddress the high number of degrees of freedom in this problem. Our approach\nshows substantial improvements over previous state-of-the-art, particularly in\nhandling variations in the sun's zenith angle.",
    "explanation":"Climate studies often rely on remotely sensed im-\nages to retrieve two-dimensional maps of cloud properties. To\nadvance volumetric analysis, we focus on recovering the three-\ndimensional (3D) heterogeneous extinction coefficient field of\nshallow clouds using multiview remote sensing data. \n\n\nTo enable\nscalable data processing, previous deep neural networks (DNNs)\ncan infer at spaceborne remote sensing downlink rates. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Distributed Sky Imaging Radiometry and Tomography"
    ],
    "b_abstract":[
      "The composition of the atmosphere is significant to our ecosystem. Accordingly, there a need sense distributions atmospheric scatterers such as aerosols and cloud droplets. There growing interest in recovering these scattering fields three-dimensions (3D). Even so, current observations usually use expensive unscalable equipment. Moreover, analysis retrieves partial information (e.g., cloud-base altitudes, water droplet size at tops) based on simplified 1D models. To advance retrievals, we develop new computational imaging approach for sensing analyzing atmosphere, volumetrically. Our comprises ground-based network cameras. We deployed it conjunction with additional remote equipment, including Raman lidar sunphotometer, which provide initialization algorithms ground truth. camera scalable, low cost, enables 3D high spatial temporal resolution. describe how system calibrated absolute radiometric readouts light field. Consequently, recover volumetric field scatterers, using tomography. tomography process adapted relative prior art, run large-scale domains being in-situ within scatterer fields. empirically demonstrate feasibility clouds, data."
    ],
    "b_categories":[
      "astro-ph.EP"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.02330"
    ],
    "c_title":[
      "Exploring Simple Siamese Network for High-Resolution Video Quality\n  Assessment"
    ],
    "c_abstract":[
      "In the research of video quality assessment (VQA), two-branch network has\nemerged as a promising solution. It decouples VQA with separate technical and\naesthetic branches to measure the perception of low-level distortions and\nhigh-level semantics respectively. However, we argue that while technical and\naesthetic perspectives are complementary, the technical perspective itself\nshould be measured in semantic-aware manner. We hypothesize that existing\ntechnical branch struggles to perceive the semantics of high-resolution videos,\nas it is trained on local mini-patches sampled from videos. This issue can be\nhidden by apparently good results on low-resolution videos, but indeed becomes\ncritical for high-resolution VQA. This work introduces SiamVQA, a simple but\neffective Siamese network for highre-solution VQA. SiamVQA shares weights\nbetween technical and aesthetic branches, enhancing the semantic perception\nability of technical branch to facilitate technical-quality representation\nlearning. Furthermore, it integrates a dual cross-attention layer for fusing\ntechnical and aesthetic features. SiamVQA achieves state-of-the-art accuracy on\nhigh-resolution benchmarks, and competitive results on lower-resolution\nbenchmarks. Codes will be available at: https:\/\/github.com\/srcn-ivl\/SiamVQA"
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04682",
    "a_title":"DNN-based 3D Cloud Retrieval for Variable Solar Illumination and\n  Multiview Spaceborne Imaging",
    "a_abstract":"Climate studies often rely on remotely sensed images to retrieve\ntwo-dimensional maps of cloud properties. To advance volumetric analysis, we\nfocus on recovering the three-dimensional (3D) heterogeneous extinction\ncoefficient field of shallow clouds using multiview remote sensing data.\nClimate research requires large-scale worldwide statistics. To enable scalable\ndata processing, previous deep neural networks (DNNs) can infer at spaceborne\nremote sensing downlink rates. However, prior methods are limited to a fixed\nsolar illumination direction. In this work, we introduce the first scalable\nDNN-based system for 3D cloud retrieval that accommodates varying camera poses\nand solar directions. By integrating multiview cloud intensity images with\ncamera poses and solar direction data, we achieve greater flexibility in\nrecovery. Training of the DNN is performed by a novel two-stage scheme to\naddress the high number of degrees of freedom in this problem. Our approach\nshows substantial improvements over previous state-of-the-art, particularly in\nhandling variations in the sun's zenith angle.",
    "explanation":"Climate studies often rely on remotely sensed im-\nages to retrieve two-dimensional maps of cloud properties. To\nadvance volumetric analysis, we focus on recovering the three-\ndimensional (3D) heterogeneous extinction coefficient field of\nshallow clouds using multiview remote sensing data. \n\n\nTo enable\nscalable data processing, previous deep neural networks (DNNs)\ncan infer at spaceborne remote sensing downlink rates. ",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "Variable Imaging Projection Cloud Scattering Tomography"
    ],
    "b_abstract":[
      "Scattering-based computed tomography (CT) recovers a heterogeneous volumetric scattering medium using images taken from multiple directions. It is nonlinear problem. Prior art mainly approached it by explicit physics-based optimization of image-fitting, being slow and difficult to scale. Scale particularly important when the objects constitute large cloud fields, where recovery for climate studies. Besides speed, imaging need be flexible, efficiently handle variable viewing geometries resolutions. These can caused perturbation in camera poses or fusion data different types observational sensors. There fast projection clouds (VIP-CT). We develop learning-based solution, deep-neural network (DNN) which trains on labeled dataset. The DNN parameters are oblivious domain scale, hence work with arbitrarily domains. VIP-CT offers much better quality than state art. inference speed flexibility make effectively real-time context spaceborne observations. paper first demonstrate CT real empirical directly DNN. may offer model solution problems other scientific Our code available online."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.13332"
    ],
    "c_title":[
      "Solar System objects observed with TESS -- Early Data Release 2: I.\n  Spin-shape recovery potential of multi-epoch TESS observations"
    ],
    "c_abstract":[
      "Using multidirectional measurements from the Transiting Exoplanet Survey\nSatellite (TESS), we investigated the viability of determining the approximate\nshape and spin axis orientations for 44 selected main belt asteroids, using\nlight curve inversion, assuming Lommel-Seeliger ellipsoids. This study aims to\ninvestigate the applicability of low-degree-of-freedom shape models in those\ncases when rotation periods can be accurately determined, but light curves are\nonly available in a limited number of geometries or orbital phases. Our results\nare compared with the shape and spin axis solutions obtained for the same set\nof asteroids by more complex light curve inversion methods using mainly\nground-based measurements, available via the Database of Asteroid Models from\nInversion Techniques (DAMIT).The best-fit spin-axis orientations show a\nmoderately good match with the DAMIT solutions; however, a better agreement is\nreached with triaxial ellipsoid solution obtained from other large, independent\nsurveys. This suggests that while TESS-only data works well for finding\nrotation periods, it has its limitations when determining asteroid shape and\nspin-axis orientation. We discuss the challenges and potential applications of\nthis approach for studying large number of asteroids observed by TESS."
    ],
    "c_categories":[
      "astro-ph.EP"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03156",
    "a_title":"Unleashing the power of novel conditional generative approaches for new\n  materials discovery",
    "a_abstract":"For a very long time, computational approaches to the design of new materials\nhave relied on an iterative process of finding a candidate material and\nmodeling its properties. AI has played a crucial role in this regard, helping\nto accelerate the discovery and optimization of crystal properties and\nstructures through advanced computational methodologies and data-driven\napproaches. To address the problem of new materials design and fasten the\nprocess of new materials search, we have applied latest generative approaches\nto the problem of crystal structure design, trying to solve the inverse\nproblem: by given properties generate a structure that satisfies them without\nutilizing supercomputer powers. In our work we propose two approaches: 1)\nconditional structure modification: optimization of the stability of an\narbitrary atomic configuration, using the energy difference between the most\nenergetically favorable structure and all its less stable polymorphs and 2)\nconditional structure generation. We used a representation for materials that\nincludes the following information: lattice, atom coordinates, atom types,\nchemical features, space group and formation energy of the structure. The loss\nfunction was optimized to take into account the periodic boundary conditions of\ncrystal structures. We have applied Diffusion models approach, Flow matching,\nusual Autoencoder (AE) and compared the results of the models and approaches.\nAs a metric for the study, physical PyMatGen matcher was employed: we compare\ntarget structure with generated one using default tolerances. So far, our\nmodifier and generator produce structures with needed properties with accuracy\n41% and 82% respectively. To prove the offered methodology efficiency,\ninference have been carried out, resulting in several potentially new\nstructures with formation energy below the AFLOW-derived convex hulls.",
    "explanation":"\" In our work we propose two approaches: 1) conditional structure modification: optimization of the stability of an arbitrary atomic configuration, using the energy difference between the most energetically favorable structure and all its less stable polymorphs and 2) conditional structure generation.\"",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Physics guided deep learning for generative design of crystal materials with symmetry constraints"
    ],
    "b_abstract":[
      "Abstract Discovering new materials is a challenging task in science crucial to the progress of human society. Conventional approaches based on experiments and simulations are labor-intensive or costly with success heavily depending experts\u2019 heuristic knowledge. Here, we propose deep learning Physics Guided Crystal Generative Model (PGCGM) for efficient crystal material design high structural diversity symmetry. Our model increases generation validity by more than 700% compared FTCP, one latest structure generators 45% our previous CubicGAN model. Density Functional Theory (DFT) calculations used validate generated structures 1869 out 2000 successfully optimized deposited into Carolina Materials Database www.carolinamatdb.org , which 39.6% have negative formation energy 5.3% energy-above-hull less 0.25 eV\/atom, indicating their thermodynamic stability potential synthesizability."
    ],
    "b_categories":[
      "physics.comp-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.00594"
    ],
    "c_title":[
      "Estimation of total body fat using symbolic regression and evolutionary\n  algorithms"
    ],
    "c_abstract":[
      "Body fat percentage is an increasingly popular alternative to Body Mass Index\nto measure overweight and obesity, offering a more accurate representation of\nbody composition. In this work, we evaluate three evolutionary computation\ntechniques, Grammatical Evolution, Context-Free Grammar Genetic Programming,\nand Dynamic Structured Grammatical Evolution, to derive an interpretable\nmathematical expression to estimate the percentage of body fat that are also\naccurate. Our primary objective is to obtain a model that balances accuracy\nwith explainability, making it useful for clinical and health applications. We\ncompare the performance of the three variants on a public anthropometric\ndataset and compare the results obtained with the QLattice framework.\nExperimental results show that grammatical evolution techniques can obtain\ncompetitive results in performance and interpretability."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03156",
    "a_title":"Unleashing the power of novel conditional generative approaches for new\n  materials discovery",
    "a_abstract":"For a very long time, computational approaches to the design of new materials\nhave relied on an iterative process of finding a candidate material and\nmodeling its properties. AI has played a crucial role in this regard, helping\nto accelerate the discovery and optimization of crystal properties and\nstructures through advanced computational methodologies and data-driven\napproaches. To address the problem of new materials design and fasten the\nprocess of new materials search, we have applied latest generative approaches\nto the problem of crystal structure design, trying to solve the inverse\nproblem: by given properties generate a structure that satisfies them without\nutilizing supercomputer powers. In our work we propose two approaches: 1)\nconditional structure modification: optimization of the stability of an\narbitrary atomic configuration, using the energy difference between the most\nenergetically favorable structure and all its less stable polymorphs and 2)\nconditional structure generation. We used a representation for materials that\nincludes the following information: lattice, atom coordinates, atom types,\nchemical features, space group and formation energy of the structure. The loss\nfunction was optimized to take into account the periodic boundary conditions of\ncrystal structures. We have applied Diffusion models approach, Flow matching,\nusual Autoencoder (AE) and compared the results of the models and approaches.\nAs a metric for the study, physical PyMatGen matcher was employed: we compare\ntarget structure with generated one using default tolerances. So far, our\nmodifier and generator produce structures with needed properties with accuracy\n41% and 82% respectively. To prove the offered methodology efficiency,\ninference have been carried out, resulting in several potentially new\nstructures with formation energy below the AFLOW-derived convex hulls.",
    "explanation":"\" In our work we propose two approaches: 1) conditional structure modification: optimization of the stability of an arbitrary atomic configuration, using the energy difference between the most energetically favorable structure and all its less stable polymorphs and 2) conditional structure generation.\"",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "High\u2010Throughput Discovery of Novel Cubic Crystal Materials Using Deep Generative Neural Networks"
    ],
    "b_abstract":[
      "Abstract High\u2010throughput screening has become one of the major strategies for discovery novel functional materials. However, its effectiveness is severely limited by lack sufficient and diverse materials in current repositories such as open quantum database (OQMD). Recent progress deep learning have enabled generative that learn implicit chemical rules creating hypothetical with new compositions structures. models difficulty generating structurally diverse, chemically valid, stable Here we propose CubicGAN, a adversarial network (GAN) based neural model large scale design cubic When trained on 375 749 ternary from OQMD database, authors show able to not only rediscover most currently known but also generate structure prototypes. A total 506 been verified phonon dispersion calculation. Considering importance wide applications solar panels, GAN provides promising approach significantly expand existing repositories, enabling via screening. The crystal structures discovered are freely accessible at www.carolinamatdb.org ."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.06578"
    ],
    "c_title":[
      "Generalized exchange cluster algorithm to compute efficiently\n  covariances and susceptibilities in Monte Carlo"
    ],
    "c_abstract":[
      "We present a Monte Carlo method to compute efficiently susceptibilites or\ncovariances of two physical variables. The method relies on a generalization of\nthe exchange cluster algorithm to any model of interacting particles with any\n$2$-body interactions. The principle is to select clusters of variables\nbelonging to two independent replicas of the system. An improved estimator of\nthe covariance of two physical variables (in one replica) is then proposed.\nThis estimator has the zero-variance property in the limit wh ere these\nvariables are independent.In practice the scaling of the statistical\nfluctuations as a function of the number of degrees of freedom $N$ is reduced\nfrom $O(N ^2)$ to $O(N)$. This lower scaling is illustrated on a Lennard Jones\nmodel."
    ],
    "c_categories":[
      "physics.comp-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05055",
    "a_title":"Integrating Large Language Models for Genetic Variant Classification",
    "a_abstract":"The classification of genetic variants, particularly Variants of Uncertain\nSignificance (VUS), poses a significant challenge in clinical genetics and\nprecision medicine. Large Language Models (LLMs) have emerged as transformative\ntools in this realm. These models can uncover intricate patterns and predictive\ninsights that traditional methods might miss, thus enhancing the predictive\naccuracy of genetic variant pathogenicity.\n  This study investigates the integration of state-of-the-art LLMs, including\nGPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for\nvariant classification. Our approach evaluates these integrated models using\nthe well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in\nclassification performance. The models were rigorously tested on a set of\nchallenging variants, demonstrating substantial improvements over existing\nstate-of-the-art tools, especially in handling ambiguous and clinically\nuncertain variants.\n  The results of this research underline the efficacy of combining multiple\nmodeling approaches to significantly refine the accuracy and reliability of\ngenetic variant classification systems. These findings support the deployment\nof these advanced computational models in clinical environments, where they can\nsignificantly enhance the diagnostic processes for genetic disorders,\nultimately pushing the boundaries of personalized medicine by offering more\ndetailed and actionable genetic insights.",
    "explanation":"This study investigates the integration of state-of-the-art LLMs,\nincluding GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for variant classification.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"
    ],
    "b_abstract":[
      "TensorFlow is an interface for expressing machine learning algorithms, and implementation executing such algorithms. A computation expressed using can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices as phones tablets up to large-scale distributed systems hundreds machines thousands computational GPU cards. The system flexible used express including training inference algorithms deep neural network models, it has been conducting research deploying into production across more than dozen areas computer science other fields, speech recognition, vision, robotics, information retrieval, natural language processing, geographic extraction, drug discovery. This paper describes the that we have built at Google. API reference were released open-source package under Apache 2.0 license in November, 2015 are available www.tensorflow.org."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.08363"
    ],
    "c_title":[
      "TopoLa: A Universal Framework to Enhance Cell Representations for\n  Single-cell and Spatial Omics through Topology-encoded Latent Hyperbolic\n  Geometry"
    ],
    "c_abstract":[
      "Recent advances in cellular research demonstrate that scRNA-seq characterizes\ncellular heterogeneity, while spatial transcriptomics reveals the spatial\ndistribution of gene expression. Cell representation is the fundamental issue\nin the two fields. Here, we propose Topology-encoded Latent Hyperbolic Geometry\n(TopoLa), a computational framework enhancing cell representations by capturing\nfine-grained intercellular topological relationships. The framework introduces\na new metric, TopoLa distance (TLd), which quantifies the geometric distance\nbetween cells within latent hyperbolic space, capturing the network's\ntopological structure more effectively. With this framework, the cell\nrepresentation can be enhanced considerably by performing convolution on its\nneighboring cells. Performance evaluation across seven biological tasks,\nincluding scRNA-seq data clustering and spatial transcriptomics domain\nidentification, shows that TopoLa significantly improves the performance of\nseveral state-of-the-art models. These results underscore the generalizability\nand robustness of TopoLa, establishing it as a valuable tool for advancing both\nbiological discovery and computational methodologies."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05055",
    "a_title":"Integrating Large Language Models for Genetic Variant Classification",
    "a_abstract":"The classification of genetic variants, particularly Variants of Uncertain\nSignificance (VUS), poses a significant challenge in clinical genetics and\nprecision medicine. Large Language Models (LLMs) have emerged as transformative\ntools in this realm. These models can uncover intricate patterns and predictive\ninsights that traditional methods might miss, thus enhancing the predictive\naccuracy of genetic variant pathogenicity.\n  This study investigates the integration of state-of-the-art LLMs, including\nGPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for\nvariant classification. Our approach evaluates these integrated models using\nthe well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in\nclassification performance. The models were rigorously tested on a set of\nchallenging variants, demonstrating substantial improvements over existing\nstate-of-the-art tools, especially in handling ambiguous and clinically\nuncertain variants.\n  The results of this research underline the efficacy of combining multiple\nmodeling approaches to significantly refine the accuracy and reliability of\ngenetic variant classification systems. These findings support the deployment\nof these advanced computational models in clinical environments, where they can\nsignificantly enhance the diagnostic processes for genetic disorders,\nultimately pushing the boundaries of personalized medicine by offering more\ndetailed and actionable genetic insights.",
    "explanation":"This study investigates the integration of state-of-the-art LLMs,\nincluding GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for variant classification.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Predicting Functional Effect of Human Missense Mutations Using PolyPhen\u20102"
    ],
    "b_abstract":[
      "Abstract PolyPhen\u20102 (Polymorphism Phenotyping v2), available as software and via a Web server, predicts the possible impact of amino acid substitutions on stability function human proteins using structural comparative evolutionary considerations. It performs functional annotation single\u2010nucleotide polymorphisms (SNPs), maps coding SNPs to gene transcripts, extracts protein sequence annotations attributes, builds conservation profiles. then estimates probability missense mutation being damaging based combination all these properties. features include high\u2010quality multiple alignment pipeline prediction method employing machine\u2010learning classification. The also integrates UCSC Genome Browser's genome MultiZ alignments vertebrate genomes with genome. is capable analyzing large volumes data produced by next\u2010generation sequencing projects, thanks built\u2010in support for high\u2010performance computing environments like Grid Engine Platform LSF. Curr. Protoc. Hum. Genet . 76:7.20.1\u20107.20.41. \u00a9 2013 John Wiley &amp; Sons, Inc."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.04506"
    ],
    "c_title":[
      "When One LLM Drools, Multi-LLM Collaboration Rules"
    ],
    "c_abstract":[
      "This position paper argues that in many realistic (i.e., complex,\ncontextualized, subjective) scenarios, one LLM is not enough to produce a\nreliable output. We challenge the status quo of relying solely on a single\ngeneral-purpose LLM and argue for multi-LLM collaboration to better represent\nthe extensive diversity of data, skills, and people. We first posit that a\nsingle LLM underrepresents real-world data distributions, heterogeneous skills,\nand pluralistic populations, and that such representation gaps cannot be\ntrivially patched by further training a single LLM. We then organize existing\nmulti-LLM collaboration methods into a hierarchy, based on the level of access\nand information exchange, ranging from API-level, text-level, logit-level, to\nweight-level collaboration. Based on these methods, we highlight how multi-LLM\ncollaboration addresses challenges that a single LLM struggles with, such as\nreliability, democratization, and pluralism. Finally, we identify the\nlimitations of existing multi-LLM methods and motivate future work. We envision\nmulti-LLM collaboration as an essential path toward compositional intelligence\nand collaborative AI development."
    ],
    "c_categories":[
      "cs.CL"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.18156",
    "a_title":"scReader: Prompting Large Language Models to Interpret scRNA-seq Data",
    "a_abstract":"Large language models (LLMs) have demonstrated remarkable advancements,\nprimarily due to their capabilities in modeling the hidden relationships within\ntext sequences. This innovation presents a unique opportunity in the field of\nlife sciences, where vast collections of single-cell omics data from multiple\nspecies provide a foundation for training foundational models. However, the\nchallenge lies in the disparity of data scales across different species,\nhindering the development of a comprehensive model for interpreting genetic\ndata across diverse organisms. In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of LLMs with\ndomain-specific representation models for single-cell omics data\ninterpretation. We begin by focusing on genes as the fundamental unit of\nrepresentation. Gene representations are initialized using functional\ndescriptions, leveraging the strengths of mature language models such as\nLLaMA-2. By inputting single-cell gene-level expression data with prompts, we\neffectively model cellular representations based on the differential expression\nlevels of genes across various species and cell types. In the experiments, we\nconstructed developmental cells from humans and mice, specifically targeting\ncells that are challenging to annotate. We evaluated our methodology through\nbasic tasks such as cell annotation and visualization analysis. The results\ndemonstrate the efficacy of our approach compared to other methods using LLMs,\nhighlighting significant improvements in accuracy and interoperability. Our\nhybrid approach enhances the representation of single-cell data and offers a\nrobust framework for future research in cross-species genetic analysis.",
    "explanation":". In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of\nLLMs with domain-specific representation models for single-cell\nomics data interpretation.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Llamafactory: Unified efficient fine-tuning of 100+ language models"
    ],
    "b_abstract":[
      "Efficient fine-tuning is vital for adapting large language models (LLMs) to downstream tasks. However, it requires non-trivial efforts to implement these methods on different models. We present LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It provides a solution for flexibly customizing the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard. We empirically validate the efficiency and effectiveness of our framework on language modeling and text generation tasks."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.02284"
    ],
    "c_title":[
      "Origin of $\\alpha$-satellite repeat arrays from mitochondrial molecular\n  fossils -- sequential insertion, expansion, and evolution in the nuclear\n  genome"
    ],
    "c_abstract":[
      "Alpha satellite DNA is large tandem arrays of 150-400 bp units, and its\norigin remains an evolutionary mystery. In this research, we identified 1,545\nalpha-satellite-like (SatL) repeat units in the nuclear genome of jewel wasp\nNasonia vitripennis. Among them, thirty-nine copies of SatL were organized in\ntwo palindromic arrays in mitochondria, resulting in a 50% increase in the\ngenome size. Strikingly, genomic neighborhood analyses of 1,516 nuclear SatL\nrepeats revealed that they are located in NuMT (nuclear mitochondrial DNA)\nregions, and SatL phylogeny matched perfectly with mitochondrial genes and NuMT\npseudogenes. These results support that SatL arrays originated from ten\nindependent mitochondria insertion events into the nuclear genome within the\nlast 500,000 years, after divergence from its sister species N. giraulti.\nDramatic repeat GC-percent elevation (from 33.9% to 50.4%) is a hallmark of\nrapid SatL sequence evolution in mitochondria due to GC-biased gene conversion\nfacilitated by the palindromic sequence pairing of the two mitochondrial SatL\narrays. The nuclear SatL repeat arrays underwent substantial copy number\nexpansion, from 12-15 (SatL1) to over 400 copies (SatL4). The oldest SatL4B\narray consists of four types of repeat units derived from deletions in the\nAT-rich region of ancestral repeats, and complex high-order structures have\nevolved through duplications. We also discovered similar repeat insertions into\nthe nuclear genome of Muscidifurax, suggesting this mechanism can be common in\ninsects. This is the first report of the mitochondrial origin of nuclear\nsatellite sequences, and our findings shed new light on the origin and\nevolution of satellite DNA."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.18156",
    "a_title":"scReader: Prompting Large Language Models to Interpret scRNA-seq Data",
    "a_abstract":"Large language models (LLMs) have demonstrated remarkable advancements,\nprimarily due to their capabilities in modeling the hidden relationships within\ntext sequences. This innovation presents a unique opportunity in the field of\nlife sciences, where vast collections of single-cell omics data from multiple\nspecies provide a foundation for training foundational models. However, the\nchallenge lies in the disparity of data scales across different species,\nhindering the development of a comprehensive model for interpreting genetic\ndata across diverse organisms. In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of LLMs with\ndomain-specific representation models for single-cell omics data\ninterpretation. We begin by focusing on genes as the fundamental unit of\nrepresentation. Gene representations are initialized using functional\ndescriptions, leveraging the strengths of mature language models such as\nLLaMA-2. By inputting single-cell gene-level expression data with prompts, we\neffectively model cellular representations based on the differential expression\nlevels of genes across various species and cell types. In the experiments, we\nconstructed developmental cells from humans and mice, specifically targeting\ncells that are challenging to annotate. We evaluated our methodology through\nbasic tasks such as cell annotation and visualization analysis. The results\ndemonstrate the efficacy of our approach compared to other methods using LLMs,\nhighlighting significant improvements in accuracy and interoperability. Our\nhybrid approach enhances the representation of single-cell data and offers a\nrobust framework for future research in cross-species genetic analysis.",
    "explanation":". In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of\nLLMs with domain-specific representation models for single-cell\nomics data interpretation.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "GeneCompass: Deciphering Universal Gene Regulatory Mechanisms with Knowledge-Informed Cross-Species Foundation Model"
    ],
    "b_abstract":[
      "Abstract Deciphering the universal gene regulatory mechanisms in diverse organisms holds great potential to advance our knowledge of fundamental life process and facilitate research on clinical applications. However, traditional paradigm primarily focuses individual model organisms, resulting limited collection integration complex features various cell types across species. Recent breakthroughs single-cell sequencing advancements deep learning techniques present an unprecedented opportunity tackle this challenge. In study, we developed GeneCompass, first knowledge-informed, cross-species foundation pre-trained extensive dataset over 120 million transcriptomes from human mouse. During pre-training, GeneCompass effectively integrates four biological prior enhance understanding a self-supervised manner. Fine-tuning towards multiple downstream tasks, outperforms competing state-of-the-art models tasks single species unlocks new realms investigation. Overall, marks milestone advancing accelerating discovery key fate regulators candidate targets for drug development."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.12583"
    ],
    "c_title":[
      "LongFaith: Enhancing Long-Context Reasoning in LLMs with Faithful\n  Synthetic Data"
    ],
    "c_abstract":[
      "Despite the growing development of long-context large language models (LLMs),\ndata-centric approaches relying on synthetic data have been hindered by issues\nrelated to faithfulness, which limit their effectiveness in enhancing model\nperformance on tasks such as long-context reasoning and question answering\n(QA). These challenges are often exacerbated by misinformation caused by lack\nof verification, reasoning without attribution, and potential knowledge\nconflicts. We propose LongFaith, a novel pipeline for synthesizing faithful\nlong-context reasoning instruction datasets. By integrating ground truth and\ncitation-based reasoning prompts, we eliminate distractions and improve the\naccuracy of reasoning chains, thus mitigating the need for costly verification\nprocesses. We open-source two synthesized datasets, LongFaith-SFT and\nLongFaith-PO, which systematically address multiple dimensions of faithfulness,\nincluding verified reasoning, attribution, and contextual grounding. Extensive\nexperiments on multi-hop reasoning datasets and LongBench demonstrate that\nmodels fine-tuned on these datasets significantly improve performance. Our\nablation studies highlight the scalability and adaptability of the LongFaith\npipeline, showcasing its broad applicability in developing long-context LLMs."
    ],
    "c_categories":[
      "cs.CL"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.07871",
    "a_title":"Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in\n  Alzheimer's Disease",
    "a_abstract":"The rapid advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have shown great potential in medical diagnostics, particularly\nin radiology, where datasets such as X-rays are paired with human-generated\ndiagnostic reports. However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer's disease, due\nto the lack of comprehensive diagnostic reports that can be utilized for model\nfine-tuning. This paper addresses this gap by generating synthetic diagnostic\nreports using GPT-4o-mini on structured data from the OASIS-4 dataset, which\ncomprises 663 patients. Using the synthetic reports as ground truth for\ntraining and validation, we then generated neurological reports directly from\nthe images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.\nOur proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,\nand METEOR score of 0.4163, revealing its potential in generating clinically\nrelevant and accurate diagnostic reports.",
    "explanation":"However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer\u2019s\ndisease, due to the lack of comprehensive diagnostic reports that\ncan be utilized for model fine-tuning. This paper addresses this\ngap by generating synthetic diagnostic reports using GPT-4o-mini\non structured data from the OASIS-4 dataset, which comprises\n663 patients",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "2016 Alzheimer's disease facts and figures"
    ],
    "b_abstract":[
      "This report describes the public health impact of Alzheimer's disease, including incidence and prevalence, mortality rates, costs care, overall on caregivers society. It also examines in detail financial families, annual to families difficult decisions must often make pay those costs. An estimated 5.4 million Americans have disease. By mid-century, number people living with disease United States is projected grow 13.8 million, fueled large part by aging baby boom generation. Today, someone country develops every 66 seconds. 2050, one new case expected develop 33 seconds, resulting nearly 1 cases per year. In 2013, official death certificates recorded 84,767 deaths from making it sixth leading cause fifth age \u2265 65 years. Between 2000 stroke, heart prostate cancer decreased 23%, 14%, 11%, respectively, whereas increased 71%. The actual which contributes likely much larger than certificates. 2016, an 700,000 years will die many them because complications caused 2015, more 15 family members other unpaid provided 18.1 billion hours care dementias, a contribution valued at $221 billion. Average per-person Medicare payments for services beneficiaries dementias are two half times as great all without these conditions, Medicaid 19 great. Total 2016 long-term hospice dementia be $236 may place substantial burden who take money out their retirement savings, cut back buying food, reduce own trips doctor. addition, incorrectly believe that pays nursing home types care. Such findings highlight need solutions prevent dementia-related jeopardizing security dementias."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.15840"
    ],
    "c_title":[
      "Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents"
    ],
    "c_abstract":[
      "While Large Language Models (LLMs) can exhibit impressive proficiency in\nisolated, short-term tasks, they often fail to maintain coherent performance\nover longer time horizons. In this paper, we present Vending-Bench, a simulated\nenvironment designed to specifically test an LLM-based agent's ability to\nmanage a straightforward, long-running business scenario: operating a vending\nmachine. Agents must balance inventories, place orders, set prices, and handle\ndaily fees - tasks that are each simple but collectively, over long horizons\n(>20M tokens per run) stress an LLM's capacity for sustained, coherent\ndecision-making. Our experiments reveal high variance in performance across\nmultiple LLMs: Claude 3.5 Sonnet and o3-mini manage the machine well in most\nruns and turn a profit, but all models have runs that derail, either through\nmisinterpreting delivery schedules, forgetting orders, or descending into\ntangential \"meltdown\" loops from which they rarely recover. We find no clear\ncorrelation between failures and the point at which the model's context window\nbecomes full, suggesting that these breakdowns do not stem from memory limits.\nApart from highlighting the high variance in performance over long time\nhorizons, Vending-Bench also tests models' ability to acquire capital, a\nnecessity in many hypothetical dangerous AI scenarios. We hope the benchmark\ncan help in preparing for the advent of stronger AI systems."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.07871",
    "a_title":"Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in\n  Alzheimer's Disease",
    "a_abstract":"The rapid advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have shown great potential in medical diagnostics, particularly\nin radiology, where datasets such as X-rays are paired with human-generated\ndiagnostic reports. However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer's disease, due\nto the lack of comprehensive diagnostic reports that can be utilized for model\nfine-tuning. This paper addresses this gap by generating synthetic diagnostic\nreports using GPT-4o-mini on structured data from the OASIS-4 dataset, which\ncomprises 663 patients. Using the synthetic reports as ground truth for\ntraining and validation, we then generated neurological reports directly from\nthe images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.\nOur proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,\nand METEOR score of 0.4163, revealing its potential in generating clinically\nrelevant and accurate diagnostic reports.",
    "explanation":"However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer\u2019s\ndisease, due to the lack of comprehensive diagnostic reports that\ncan be utilized for model fine-tuning. This paper addresses this\ngap by generating synthetic diagnostic reports using GPT-4o-mini\non structured data from the OASIS-4 dataset, which comprises\n663 patients",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "Computer-aided diagnosis of Alzheimer\u2019s disease and neurocognitive disorders with multimodal Bi-Vision Transformer (BiViT)"
    ],
    "b_abstract":[
      "<jats:title>Abstract<\/jats:title><jats:p>Cognitive disorders affect various cognitive functions that can have a substantial impact on individual\u2019s daily life. Alzheimer\u2019s disease (AD) is one of such well-known cognitive disorders. Early detection and treatment of cognitive diseases using artificial intelligence can help contain them. However, the complex spatial relationships and long-range dependencies found in medical imaging data present challenges in achieving the objective. Moreover, for a few years, the application of transformers in imaging has emerged as a promising area of research. A reason can be transformer\u2019s impressive capabilities of tackling spatial relationships and long-range dependency challenges in two ways, i.e., (1) using their self-attention mechanism to generate comprehensive features, and (2) capture complex patterns by incorporating global context and long-range dependencies. In this work, a Bi-Vision Transformer (BiViT) architecture is proposed for classifying different stages of AD, and multiple types of cognitive disorders from 2-dimensional MRI imaging data. More specifically, the transformer is composed of two novel modules, namely Mutual Latent Fusion (MLF) and Parallel Coupled Encoding Strategy (PCES), for effective feature learning. Two different datasets have been used to evaluate the performance of proposed BiViT-based architecture. The first dataset contain several classes such as mild or moderate demented stages of the AD. The other dataset is composed of samples from patients with AD and different cognitive disorders such as mild, early, or moderate impairments. For comprehensive comparison, a multiple transfer learning algorithm and a deep autoencoder have been each trained on both datasets. The results show that the proposed BiViT-based model achieves an accuracy of 96.38% on the AD dataset. However, when applied to cognitive disease data, the accuracy slightly decreases below 96% which can be resulted due to smaller amount of data and imbalance in data distribution. Nevertheless, given the results, it can be hypothesized that the proposed algorithm can perform better if the imbalanced distribution and limited availability problems in data can be addressed.<\/jats:p>\n                <jats:p><jats:bold>Graphical abstract<\/jats:bold><\/jats:p>"
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.21217"
    ],
    "c_title":[
      "Dynamic Markov Blanket Detection for Macroscopic Physics Discovery"
    ],
    "c_abstract":[
      "The free energy principle (FEP), along with the associated constructs of\nMarkov blankets and ontological potentials, have recently been presented as the\ncore components of a generalized modeling method capable of mathematically\ndescribing arbitrary objects that persist in random dynamical systems; that is,\na mathematical theory of ``every'' ``thing''. Here, we leverage the FEP to\ndevelop a mathematical physics approach to the identification of objects,\nobject types, and the macroscopic, object-type-specific rules that govern their\nbehavior. We take a generative modeling approach and use variational Bayesian\nexpectation maximization to develop a dynamic Markov blanket detection\nalgorithm that is capable of identifying and classifying macroscopic objects,\ngiven partial observation of microscopic dynamics. This unsupervised algorithm\nuses Bayesian attention to explicitly label observable microscopic elements\naccording to their current role in a given system, as either the internal or\nboundary elements of a given macroscopic object; and it identifies macroscopic\nphysical laws that govern how the object interacts with its environment.\nBecause these labels are dynamic or evolve over time, the algorithm is capable\nof identifying complex objects that travel through fixed media or exchange\nmatter with their environment. This approach leads directly to a flexible class\nof structured, unsupervised algorithms that sensibly partition complex\nmany-particle or many-component systems into collections of interacting\nmacroscopic subsystems, namely, ``objects'' or ``things''. We derive a few\nexamples of this kind of macroscopic physics discovery algorithm and\ndemonstrate its utility with simple numerical experiments, in which the\nalgorithm correctly labels the components of Newton's cradle, a burning fuse,\nthe Lorenz attractor, and a simulated cell."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.08073",
    "a_title":"LoRA-BERT: a Natural Language Processing Model for Robust and Accurate\n  Prediction of long non-coding RNAs",
    "a_abstract":"Long non-coding RNAs (lncRNAs) serve as crucial regulators in numerous\nbiological processes. Although they share sequence similarities with messenger\nRNAs (mRNAs), lncRNAs perform entirely different roles, providing new avenues\nfor biological research. The emergence of next-generation sequencing\ntechnologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify\nlong non-coding RNAs (lncRNAs). These advanced methods have significantly\nenhanced the efficiency of identifying lncRNAs. However, many of these methods\nare devoid of robustness and accuracy due to the extended length of the\nsequences involved. To tackle this issue, we have introduced a novel\npre-trained bidirectional encoder representation called LoRA-BERT. LoRA-BERT is\ndesigned to capture the importance of nucleotide-level information during\nsequence classification, leading to more robust and satisfactory outcomes. In a\ncomprehensive comparison with commonly used sequence prediction tools, we have\ndemonstrated that LoRA-BERT outperforms them in terms of accuracy and\nefficiency. Our results indicate that, when utilizing the transformer model,\nLoRA-BERT achieves state-of-the-art performance in predicting both lncRNAs and\nmRNAs for human and mouse species. Through the utilization of LoRA-BERT, we\nacquire valuable insights into the traits of lncRNAs and mRNAs, offering the\npotential to aid in the comprehension and detection of diseases linked to\nlncRNAs in humans.",
    "explanation":"The emergence of next-\ngeneration sequencing technologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify long non-coding\nRNAs (lncRNAs). ",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome"
    ],
    "b_abstract":[
      "Abstract Motivation Deciphering the language of non-coding DNA is one fundamental problems in genome research. Gene regulatory code highly complex due to existence polysemy and distant semantic relationship, which previous informatics methods often fail capture especially data-scarce scenarios. Results To address this challenge, we developed a novel pre-trained bidirectional encoder representation, named DNABERT, global transferrable understanding genomic sequences based on up downstream nucleotide contexts. We compared DNABERT most widely used programs for genome-wide elements prediction demonstrate its ease use, accuracy efficiency. show that single transformers model can simultaneously achieve state-of-the-art performance promoters, splice sites transcription factor binding sites, after easy fine-tuning using small task-specific labeled data. Further, enables direct visualization nucleotide-level importance relationship within input better interpretability accurate identification conserved sequence motifs functional genetic variant candidates. Finally, with human even be readily applied other organisms exceptional performance. anticipate fined tuned many analyses tasks. Availability implementation The source code, pretrained finetuned are available at GitHub (https:\/\/github.com\/jerryji1993\/DNABERT). Supplementary information data Bioinformatics online."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.17418"
    ],
    "c_title":[
      "Application of Single-cell Deep Learning in Elucidating the Mapping\n  Relationship Between Visceral and Body Surface Inflammatory Patterns"
    ],
    "c_abstract":[
      "As a system of integrated homeostasis, life is susceptible to disruptions by\nvisceral inflammation, which can disturb internal environment equilibrium. The\nrole of body-spread subcutaneous fascia (scFascia) in this process is poorly\nunderstood. In the rat model of Salmonella-induced dysentery, scRNA-seq of\nscFascia and deep-learning analysis revealed Warburg-like metabolic\nreprogramming in macrophages (MPs) with reduced citrate cycle activity.\nCd34+\/Pdgfra+ telocytes (CPTCs) regulated MPs differentiation and proliferation\nvia Wnt\/Fgf signal, suggesting a pathological crosstalk pattern in the\nscFascia, herein termed the fascia-visceral inflammatory crosstalk pattern\n(FVICP). PySCENIC analysis indicated increased activity transcription factors\nFosl1, Nfkb2, and Atf4, modulated by CPTCs signaling to MPs, downregulating\naerobic respiration and upregulating cell cycle, DNA replication, and\ntranscription. This study highlights scFascia's role in immunomodulation and\nmetabolic reprogramming during visceral inflammation, underscoring its function\nin systemic homeostasis."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.08073",
    "a_title":"LoRA-BERT: a Natural Language Processing Model for Robust and Accurate\n  Prediction of long non-coding RNAs",
    "a_abstract":"Long non-coding RNAs (lncRNAs) serve as crucial regulators in numerous\nbiological processes. Although they share sequence similarities with messenger\nRNAs (mRNAs), lncRNAs perform entirely different roles, providing new avenues\nfor biological research. The emergence of next-generation sequencing\ntechnologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify\nlong non-coding RNAs (lncRNAs). These advanced methods have significantly\nenhanced the efficiency of identifying lncRNAs. However, many of these methods\nare devoid of robustness and accuracy due to the extended length of the\nsequences involved. To tackle this issue, we have introduced a novel\npre-trained bidirectional encoder representation called LoRA-BERT. LoRA-BERT is\ndesigned to capture the importance of nucleotide-level information during\nsequence classification, leading to more robust and satisfactory outcomes. In a\ncomprehensive comparison with commonly used sequence prediction tools, we have\ndemonstrated that LoRA-BERT outperforms them in terms of accuracy and\nefficiency. Our results indicate that, when utilizing the transformer model,\nLoRA-BERT achieves state-of-the-art performance in predicting both lncRNAs and\nmRNAs for human and mouse species. Through the utilization of LoRA-BERT, we\nacquire valuable insights into the traits of lncRNAs and mRNAs, offering the\npotential to aid in the comprehension and detection of diseases linked to\nlncRNAs in humans.",
    "explanation":"The emergence of next-\ngeneration sequencing technologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify long non-coding\nRNAs (lncRNAs). ",
    "b_id":[
      "b20"
    ],
    "b_title":[
      "A primer on deep learning in genomics"
    ],
    "b_abstract":[
      "Deep learning methods are a class of machine learning techniques capable of identifying highly complex patterns in large datasets. Here, we provide a perspective and primer on deep learning applications for genome analysis. We discuss successful applications in the fields of regulatory genomics, variant calling and pathogenicity scores. We include general guidance for how to effectively use deep learning methods as well as a practical guide to tools and resources. This primer is accompanied by an interactive online tutorial."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.15840"
    ],
    "c_title":[
      "Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents"
    ],
    "c_abstract":[
      "While Large Language Models (LLMs) can exhibit impressive proficiency in\nisolated, short-term tasks, they often fail to maintain coherent performance\nover longer time horizons. In this paper, we present Vending-Bench, a simulated\nenvironment designed to specifically test an LLM-based agent's ability to\nmanage a straightforward, long-running business scenario: operating a vending\nmachine. Agents must balance inventories, place orders, set prices, and handle\ndaily fees - tasks that are each simple but collectively, over long horizons\n(>20M tokens per run) stress an LLM's capacity for sustained, coherent\ndecision-making. Our experiments reveal high variance in performance across\nmultiple LLMs: Claude 3.5 Sonnet and o3-mini manage the machine well in most\nruns and turn a profit, but all models have runs that derail, either through\nmisinterpreting delivery schedules, forgetting orders, or descending into\ntangential \"meltdown\" loops from which they rarely recover. We find no clear\ncorrelation between failures and the point at which the model's context window\nbecomes full, suggesting that these breakdowns do not stem from memory limits.\nApart from highlighting the high variance in performance over long time\nhorizons, Vending-Bench also tests models' ability to acquire capital, a\nnecessity in many hypothetical dangerous AI scenarios. We hope the benchmark\ncan help in preparing for the advent of stronger AI systems."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.15211",
    "a_title":"LightLLM: A Versatile Large Language Model for Predictive Light Sensing",
    "a_abstract":"We propose LightLLM, a model that fine tunes pre-trained large language\nmodels (LLMs) for light-based sensing tasks. It integrates a sensor data\nencoder to extract key features, a contextual prompt to provide environmental\ninformation, and a fusion layer to combine these inputs into a unified\nrepresentation. This combined input is then processed by the pre-trained LLM,\nwhich remains frozen while being fine-tuned through the addition of\nlightweight, trainable components, allowing the model to adapt to new tasks\nwithout altering its original parameters. This approach enables flexible\nadaptation of LLM to specialized light sensing tasks with minimal computational\noverhead and retraining effort. We have implemented LightLLM for three light\nsensing tasks: light-based localization, outdoor solar forecasting, and indoor\nsolar estimation. Using real-world experimental datasets, we demonstrate that\nLightLLM significantly outperforms state-of-the-art methods, achieving 4.4x\nimprovement in localization accuracy and 3.4x improvement in indoor solar\nestimation when tested in previously unseen environments. We further\ndemonstrate that LightLLM outperforms ChatGPT-4 with direct prompting,\nhighlighting the advantages of LightLLM's specialized architecture for sensor\ndata fusion with textual prompts.",
    "explanation":"We propose LightLLM, a model that fine tunes pre-trained\nlarge language models (LLMs) for light-based sensing tasks.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Solar Cells for Indoor Applications: Progress and Development"
    ],
    "b_abstract":[
      "The Internet of things (IoT) has been rapidly growing in the past few years. IoT connects numerous devices, such as wireless sensors, actuators, and wearable to optimize monitor daily activities. Most these devices require power microwatt range operate indoors. To this end, a self-sustainable source, photovoltaic (PV) cell, which can harvest low-intensity indoor light, is appropriate. Recently, development highly efficient PV cells for applications attracted tremendous attention. Therefore, different types materials, inorganic, dye-sensitized, organic, perovskite have employed harvesting light energy. Although considerable efforts made by researchers develop low-cost, stable, applications, Extensive investigation necessary resolve some critical issues concerning cells, environmental stability, lifetime, large-area fabrication, mechanical flexibility, production cost. address issues, systematic review aspects will be useful research community. This study discusses current status based on previous reports. First, we provided relevant background information. Then, described sources, subsequently critically reviewed reports regarding solar active materials perovskite. Finally, placed an attempt provide insight into factors needed further improve feasibility technology applications."
    ],
    "b_categories":[
      "astro-ph.SR"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.04530"
    ],
    "c_title":[
      "SOLAR: Scalable Optimization of Large-scale Architecture for Reasoning"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) excel in reasoning but remain constrained by\ntheir Chain-of-Thought (CoT) approach, which struggles with complex tasks\nrequiring more nuanced topological reasoning. We introduce SOLAR, Scalable\nOptimization of Large-scale Architecture for Reasoning, a framework that\ndynamically optimizes various reasoning topologies to enhance accuracy and\nefficiency.\n  Our Topological Annotation Generation (TAG) system automates topological\ndataset creation and segmentation, improving post-training and evaluation.\nAdditionally, we propose Topological-Scaling, a reward-driven framework that\naligns training and inference scaling, equipping LLMs with adaptive, task-aware\nreasoning.\n  SOLAR achieves substantial gains on MATH and GSM8K: +5% accuracy with\nTopological Tuning, +9% with Topological Reward, and +10.02% with Hybrid\nScaling. It also reduces response length by over 5% for complex problems,\nlowering inference latency.\n  To foster the reward system, we train a multi-task Topological Reward Model\n(M-TRM), which autonomously selects the best reasoning topology and answer in a\nsingle pass, eliminating the need for training and inference on multiple\nsingle-task TRMs (S-TRMs), thus reducing both training cost and inference\nlatency. In addition, in terms of performance, M-TRM surpasses all S-TRMs,\nimproving accuracy by +10% and rank correlation by +9%.\n  To the best of our knowledge, SOLAR sets a new benchmark for scalable,\nhigh-precision LLM reasoning while introducing an automated annotation process\nand a dynamic reasoning topology competition mechanism."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.15211",
    "a_title":"LightLLM: A Versatile Large Language Model for Predictive Light Sensing",
    "a_abstract":"We propose LightLLM, a model that fine tunes pre-trained large language\nmodels (LLMs) for light-based sensing tasks. It integrates a sensor data\nencoder to extract key features, a contextual prompt to provide environmental\ninformation, and a fusion layer to combine these inputs into a unified\nrepresentation. This combined input is then processed by the pre-trained LLM,\nwhich remains frozen while being fine-tuned through the addition of\nlightweight, trainable components, allowing the model to adapt to new tasks\nwithout altering its original parameters. This approach enables flexible\nadaptation of LLM to specialized light sensing tasks with minimal computational\noverhead and retraining effort. We have implemented LightLLM for three light\nsensing tasks: light-based localization, outdoor solar forecasting, and indoor\nsolar estimation. Using real-world experimental datasets, we demonstrate that\nLightLLM significantly outperforms state-of-the-art methods, achieving 4.4x\nimprovement in localization accuracy and 3.4x improvement in indoor solar\nestimation when tested in previously unseen environments. We further\ndemonstrate that LightLLM outperforms ChatGPT-4 with direct prompting,\nhighlighting the advantages of LightLLM's specialized architecture for sensor\ndata fusion with textual prompts.",
    "explanation":"We propose LightLLM, a model that fine tunes pre-trained\nlarge language models (LLMs) for light-based sensing tasks.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
    ],
    "b_abstract":[
      "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent models, BERT is designed to pre-train deep bidirectional representations unlabeled text by jointly conditioning on both left and right context in all layers. As result, the pre-trained can be fine-tuned with just one additional output layer create state-of-the-art models wide range of tasks, such as question answering inference, without substantial task-specific architecture modifications. conceptually simple empirically powerful. It obtains results eleven natural processing including pushing GLUE score 80.5% (7.7% point absolute improvement), MultiNLI accuracy 86.7% (4.6% SQuAD v1.1 Test F1 93.2 (1.5 improvement) v2.0 83.1 (5.1 improvement)."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.02976"
    ],
    "c_title":[
      "Spectroscopic Diagnosis of a B-Class Flare and an Associated Filament\n  Eruption"
    ],
    "c_abstract":[
      "The flare ribbon and an associated filament eruption are diagnosed using O iv\n1401.16 A, Si iv 1402.77 A, and Mg ii k 2796.35 A spectral lines provided by\nIRIS. The flare ribbons have downflow (redshifts) in all these lines, and this\nredshift decreases from the transition region to the chromosphere. While the\noverlapping region (flare-ribbon+filament rise\/eruption is dominated by\nupflows(blueshifts) in all three spectral lines. We found an extremely\nblueshifted Si iv profile (i.e., blueshift around -180 km\/s) in the overlapping\nregion. The mean non-thermal velocity (v_nt) in the flare ribbons is higher in\nO iv than Si iv. While, in the overlapping region, O iv have lower v_nt than Si\niv. Note that very high v_nt around 80 km\/s (in Si iv) exists in this weak\nB-class flare. The Mg ii k line widths are almost the same in the flare ribbon\nand overlapping region but, they are extremely broad than previously reported.\nWe found double peak profiles of Si iv and O iv in the overlapping region. Most\nprobably, one peak is due to downflow (flare ribbon) and another due to upflow\n(filament rise\/eruption). We report a high redshift of more than 150 km\/s in\nthe weak B-class flare. In some cases, both peaks show upflows which might be\nthe result of the superposition of two different sources, i.e., overlapping of\ntwo different velocity distributions in the line of sight."
    ],
    "c_categories":[
      "astro-ph.SR"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00129",
    "a_title":"Scaling Particle Collision Data Analysis",
    "a_abstract":"For decades, researchers have developed task-specific models to address\nscientific challenges across diverse disciplines. Recently, large language\nmodels (LLMs) have shown enormous capabilities in handling general tasks;\nhowever, these models encounter difficulties in addressing real-world\nscientific problems, particularly in domains involving large-scale numerical\ndata analysis, such as experimental high energy physics. This limitation is\nprimarily due to BPE tokenization's inefficacy with numerical data. In this\npaper, we propose a task-agnostic architecture, BBT-Neutron, which employs a\nbinary tokenization method to facilitate pretraining on a mixture of textual\nand large-scale numerical experimental data. We demonstrate the application of\nBBT-Neutron to Jet Origin Identification (JoI), a critical categorization\nchallenge in high-energy physics that distinguishes jets originating from\nvarious quarks or gluons. Our results indicate that BBT-Neutron achieves\ncomparable performance to state-of-the-art task-specific JoI models.\nFurthermore, we examine the scaling behavior of BBT-Neutron's performance with\nincreasing data volume, suggesting the potential for BBT-Neutron to serve as a\nfoundational model for particle physics data analysis, with possible extensions\nto a broad spectrum of scientific computing applications for Big Science\nexperiments, industrial manufacturing and spacial computing. The project code\nis available at https:\/\/github.com\/supersymmetry-technologies\/bbt-neutron.",
    "explanation":"In this paper, we propose a task-agnostic architecture,\nBBT-Neutron, which employs a binary tokenization method to facilitate pre-\ntraining on a mixture of textual and large-scale numerical experimental data. We\ndemonstrate the application of BBT-Neutron to Jet Origin Identification (JoI),\na critical categorization challenge in high-energy physics that distinguishes jets\noriginating from various quarks or gluons",
    "b_id":[
      "b23"
    ],
    "b_title":[
      "DARWIN Series: Domain Specific Large Language Models for Natural Science"
    ],
    "b_abstract":[
      "Emerging tools bring forth fresh approaches to work, and the field of natural science is no different. In science, traditional manual, serial, labour-intensive work being augmented by automated, parallel, iterative processes driven artificial intelligence-based experimental automation more. To add new capabilities in enabling acceleration enrichment discovery process, we present DARWIN, a series tailored LLMs for mainly physics, chemistry, material science. This relies on open-source LLM, incorporating structured unstructured scientific knowledge from public datasets literature. We fine-tuned models using over 60,000 instruction data points, emphasizing factual correctness. During fine-tuning, introduce Scientific Instruction Generation (SIG) model, automating generation texts. eliminates need manual extraction or domain-specific graphs efficiently injects into model. also explore multi-task training strategies, revealing interconnections between tasks. DARWIN not only achieves state-of-the-art results various tasks but diminishes reliance closed-source AI models. Our research showcases ability LLM domain, with overarching goal fostering prosperity within broader community."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.07049"
    ],
    "c_title":[
      "The timing and spectral properties of the 2022 outburst of SGR\n  J1935+2154 observed with NICER"
    ],
    "c_abstract":[
      "The magnetar SGR J1935+2154 entered a new active episode on October 10, 2022,\nwith X-ray bursts and enhanced persistent emission. At the tail of high burst\nrate interval, lasting several hours, radio bursts were detected, revealing the\nconnection between the X-ray activities and radio emissions. We analyzed\nobservations of SGR J1935+2154 for nearly three months, using data from Neutron\nStar Interior Composition Explorer (NICER). We report the timing and spectral\nresults following the onset of this outburst. In general, the X-ray flux of the\npersistent emission decays exponentially. While a flare is evident on the light\ncurve, a fast radio burst (FRB) was detected immediately following the peak of\nthis flare. We found a phase jump of pulse profile, with a deviation of\n$0.16\\pm0.03$ phase, which is related to the glitch. The spectra are well fit\nwith the combination of a blackbody and a power law model. The decay of the\noutburst is dominated by the drop of the non-thermal component, which also\nleads to the increase of thermal proportion. The photon index of the power law\nis inversely correlated with both the unabsorbed flux and the burst rate. We\nfind that unlike the large variety of the persistent emission around FRB\n221014, the X-ray properties are very stable when FRBs 221021 and 221201\nhappened. These results manifest the connection between glitch, phase jump,\nX-ray burst, and radio burst, crucial for studying the mutation in twisted\nmagnetic fields and constraining the trigger mechanism of radio bursts."
    ],
    "c_categories":[
      "astro-ph.HE"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00129",
    "a_title":"Scaling Particle Collision Data Analysis",
    "a_abstract":"For decades, researchers have developed task-specific models to address\nscientific challenges across diverse disciplines. Recently, large language\nmodels (LLMs) have shown enormous capabilities in handling general tasks;\nhowever, these models encounter difficulties in addressing real-world\nscientific problems, particularly in domains involving large-scale numerical\ndata analysis, such as experimental high energy physics. This limitation is\nprimarily due to BPE tokenization's inefficacy with numerical data. In this\npaper, we propose a task-agnostic architecture, BBT-Neutron, which employs a\nbinary tokenization method to facilitate pretraining on a mixture of textual\nand large-scale numerical experimental data. We demonstrate the application of\nBBT-Neutron to Jet Origin Identification (JoI), a critical categorization\nchallenge in high-energy physics that distinguishes jets originating from\nvarious quarks or gluons. Our results indicate that BBT-Neutron achieves\ncomparable performance to state-of-the-art task-specific JoI models.\nFurthermore, we examine the scaling behavior of BBT-Neutron's performance with\nincreasing data volume, suggesting the potential for BBT-Neutron to serve as a\nfoundational model for particle physics data analysis, with possible extensions\nto a broad spectrum of scientific computing applications for Big Science\nexperiments, industrial manufacturing and spacial computing. The project code\nis available at https:\/\/github.com\/supersymmetry-technologies\/bbt-neutron.",
    "explanation":"In this paper, we propose a task-agnostic architecture,\nBBT-Neutron, which employs a binary tokenization method to facilitate pre-\ntraining on a mixture of textual and large-scale numerical experimental data. We\ndemonstrate the application of BBT-Neutron to Jet Origin Identification (JoI),\na critical categorization challenge in high-energy physics that distinguishes jets\noriginating from various quarks or gluons",
    "b_id":[
      "b29"
    ],
    "b_title":[
      "Study of Fermion pair production in e+e- collisions at 130-183 GeV"
    ],
    "b_abstract":[
      "The cross sections and forward-backward asymmetries of hadronic and leptonic\nevents produced in e+e- collisions at centre-of-mass energies of 130-183 GeV\nare presented. Results for ee, mumu, tautau, qq, bb and cc production show no\nsignificant deviation from the Standard Model predictions. This enable\nconstraints to be set upon physics beyond the Standard Model such as\nfour-fermion contact interactions, leptoquarks, Z' bosons and R-parity\nviolating squarks and sneutrinos. Limits on the energy scale Lambda of eeff\ncontact interactions are typically in the range from 2-10 TeV. Limits on\nR-parity violating sneutrinos reach masses of a few hundred GeV for large\nvalues of their Yukawa couplings."
    ],
    "b_categories":[
      "astro-ph.HE"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.01275"
    ],
    "c_title":[
      "Enhancing Non-English Capabilities of English-Centric Large Language\n  Models through Deep Supervision Fine-Tuning"
    ],
    "c_abstract":[
      "Large language models (LLMs) have demonstrated significant progress in\nmultilingual language understanding and generation. However, due to the\nimbalance in training data, their capabilities in non-English languages are\nlimited. Recent studies revealed the English-pivot multilingual mechanism of\nLLMs, where LLMs implicitly convert non-English queries into English ones at\nthe bottom layers and adopt English for thinking at the middle layers. However,\ndue to the absence of explicit supervision for cross-lingual alignment in the\nintermediate layers of LLMs, the internal representations during these stages\nmay become inaccurate. In this work, we introduce a deep supervision\nfine-tuning method (DFT) that incorporates additional supervision in the\ninternal layers of the model to guide its workflow. Specifically, we introduce\ntwo training objectives on different layers of LLMs: one at the bottom layers\nto constrain the conversion of the target language into English, and another at\nthe middle layers to constrain reasoning in English. To effectively achieve the\nguiding purpose, we designed two types of supervision signals: logits and\nfeature, which represent a stricter constraint and a relatively more relaxed\nguidance. Our method guides the model to not only consider the final generated\nresult when processing non-English inputs but also ensure the accuracy of\ninternal representations. We conducted extensive experiments on typical\nEnglish-centric large models, LLaMA-2 and Gemma-2, and the results on multiple\nmultilingual datasets show that our method significantly outperforms\ntraditional fine-tuning methods."
    ],
    "c_categories":[
      "cs.CL"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.19475",
    "a_title":"Effective Fine-Tuning of Vision-Language Models for Accurate Galaxy\n  Morphology Analysis",
    "a_abstract":"Galaxy morphology analysis involves classifying galaxies by their shapes and\nstructures. For this task, directly training domain-specific models on large,\nannotated astronomical datasets is effective but costly. In contrast,\nfine-tuning vision foundation models on a smaller set of astronomical images is\nmore resource-efficient but generally results in lower accuracy. To harness the\nbenefits of both approaches and address their shortcomings, we propose\nGalaxAlign, a novel method that fine-tunes pre-trained foundation models to\nachieve high accuracy on astronomical tasks. Specifically, our method extends a\ncontrastive learning architecture to align three types of data in fine-tuning:\n(1) a set of schematic symbols representing galaxy shapes and structures, (2)\ntextual labels of these symbols, and (3) galaxy images. This way, GalaxAlign\nnot only eliminates the need for expensive pretraining but also enhances the\neffectiveness of fine-tuning. Extensive experiments on galaxy classification\nand similarity search demonstrate that our method effectively fine-tunes\ngeneral pre-trained models for astronomical tasks by incorporating\ndomain-specific multi-modal knowledge.",
    "explanation":"To harness the benefits of\nboth approaches and address their shortcomings, we pro-\npose GalaxAlign, a novel method that fine-tunes pre-trained\nfoundation models to achieve high accuracy on astronom-\nical tasks.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Radio galaxy zoo EMU: Towards a semantic radio galaxy morphology taxonomy"
    ],
    "b_abstract":[
      "ABSTRACT We present a novel natural language processing (NLP) approach to deriving plain English descriptors for science cases otherwise restricted by obfuscating technical terminology. address the limitations of common radio galaxy morphology classifications applying this approach. experimentally derive set semantic tags Radio Galaxy Zoo EMU (Evolutionary Map Universe) project and wider astronomical community. collect 8486 annotations morphology, from which we taxonomy tags. The are English. result is an extensible framework, more flexible, easily communicated, sensitive rare feature combinations, indescribable using current framework astronomy classifications."
    ],
    "b_categories":[
      "astro-ph.CO"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.10568"
    ],
    "c_title":[
      "Autoregressive Image Generation with Randomized Parallel Decoding"
    ],
    "c_abstract":[
      "We introduce ARPG, a novel visual autoregressive model that enables\nrandomized parallel generation, addressing the inherent limitations of\nconventional raster-order approaches, which hinder inference efficiency and\nzero-shot generalization due to their sequential, predefined token generation\norder. Our key insight is that effective random-order modeling necessitates\nexplicit guidance for determining the position of the next predicted token. To\nthis end, we propose a novel guided decoding framework that decouples\npositional guidance from content representation, encoding them separately as\nqueries and key-value pairs. By directly incorporating this guidance into the\ncausal attention mechanism, our approach enables fully random-order training\nand generation, eliminating the need for bidirectional attention. Consequently,\nARPG readily generalizes to zero-shot tasks such as image inpainting,\noutpainting, and resolution expansion. Furthermore, it supports parallel\ninference by concurrently processing multiple queries using a shared KV cache.\nOn the ImageNet-1K 256 benchmark, our approach attains an FID of 1.94 with only\n64 sampling steps, achieving over a 20-fold increase in throughput while\nreducing memory consumption by over 75% compared to representative recent\nautoregressive models at a similar scale."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.19475",
    "a_title":"Effective Fine-Tuning of Vision-Language Models for Accurate Galaxy\n  Morphology Analysis",
    "a_abstract":"Galaxy morphology analysis involves classifying galaxies by their shapes and\nstructures. For this task, directly training domain-specific models on large,\nannotated astronomical datasets is effective but costly. In contrast,\nfine-tuning vision foundation models on a smaller set of astronomical images is\nmore resource-efficient but generally results in lower accuracy. To harness the\nbenefits of both approaches and address their shortcomings, we propose\nGalaxAlign, a novel method that fine-tunes pre-trained foundation models to\nachieve high accuracy on astronomical tasks. Specifically, our method extends a\ncontrastive learning architecture to align three types of data in fine-tuning:\n(1) a set of schematic symbols representing galaxy shapes and structures, (2)\ntextual labels of these symbols, and (3) galaxy images. This way, GalaxAlign\nnot only eliminates the need for expensive pretraining but also enhances the\neffectiveness of fine-tuning. Extensive experiments on galaxy classification\nand similarity search demonstrate that our method effectively fine-tunes\ngeneral pre-trained models for astronomical tasks by incorporating\ndomain-specific multi-modal knowledge.",
    "explanation":"To harness the benefits of\nboth approaches and address their shortcomings, we pro-\npose GalaxAlign, a novel method that fine-tunes pre-trained\nfoundation models to achieve high accuracy on astronom-\nical tasks.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "ImageNet: A large-scale hierarchical image database"
    ],
    "b_abstract":[
      "The explosion of image data on the Internet has potential to foster more sophisticated and robust models algorithms index, retrieve, organize interact with images multimedia data. But exactly how such can be harnessed organized remains a critical problem. We introduce here new database called \"ImageNet\", large-scale ontology built upon backbone WordNet structure. ImageNet aims populate majority 80,000 synsets an average 500\u20131000 clean full resolution images. This will result in tens millions annotated by semantic hierarchy WordNet. paper offers detailed analysis its current state: 12 subtrees 5247 3.2 million total. show that is much larger scale diversity accurate than datasets. Constructing challenging task. describe collection scheme Amazon Mechanical Turk. Lastly, we illustrate usefulness through three simple applications object recognition, classification automatic clustering. hope scale, accuracy, hierarchical structure offer unparalleled opportunities researchers computer vision community beyond."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.10844"
    ],
    "c_title":[
      "Cosmic filament spin -- II: filament spin and its impact on galaxy\n  spin-filament alignment in a cosmological simulation"
    ],
    "c_abstract":[
      "Observational studies have reported that cosmic filaments on the megaparsec\nscale exhibit rotational motion. Subsequent simulation studies have shown\nqualitative agreement with these findings, but quantitative discrepancies\nremain due to differences in data and methods, which require verification. To\naddress this issue, we adopt the same methodology as used in the observations\nto identify filament spin from the galaxy distribution constructed from a\nhydrodynamic simulation. Using the same approach to measure filament spin, we\nfind that the simulation results closely match the observational findings, with\nonly minor discrepancies arising from slight differences in the fraction of\nfilaments classified as dynamically cold or hot based on their dynamic\ntemperature. Additionally, an analysis of how filament spin affects the galaxy\nspin-filament correlation shows that filaments with strong spin signals and\ndynamically cold have a greater impact on the galaxy spin-filament correlation\nthan those with weaker spin signals and dynamically hot filaments. These\nresults not only provide further evidence that cosmic filaments exhibit spin,\nbut also highlight the importance of this rotation in the acquisition of\nangular momentum by individual galaxies. Future studies exploring the influence\nof filament spin on galaxy spin may shed light on the physical origins of\nfilaments and the angular momentum of galaxies."
    ],
    "c_categories":[
      "astro-ph.CO"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.15395",
    "a_title":"ChatBCI: A P300 Speller BCI Leveraging Large Language Models for\n  Improved Sentence Composition in Realistic Scenarios",
    "a_abstract":"P300 speller BCIs allow users to compose sentences by selecting target keys\non a GUI through the detection of P300 component in their EEG signals following\nvisual stimuli. Most P300 speller BCIs require users to spell words letter by\nletter, or the first few initial letters, resulting in high keystroke demands\nthat increase time, cognitive load, and fatigue. This highlights the need for\nmore efficient, user-friendly methods for faster sentence composition. In this\nwork, we introduce ChatBCI, a P300 speller BCI that leverages the zero-shot\nlearning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing\nkeystrokes and accelerating sentence composition. ChatBCI retrieves word\nsuggestions through remote queries to the GPT-3.5 API. A new GUI, displaying\nGPT-3.5 word suggestions as extra keys is designed. SWLDA is used for the P300\nclassification. Seven subjects completed two online spelling tasks: 1)\ncopy-spelling a self-composed sentence using ChatBCI, and 2) improvising a\nsentence using ChatBCI's word suggestions. Results demonstrate that in Task 1,\non average, ChatBCI outperforms letter-by-letter BCI spellers, reducing time\nand keystrokes by 62.14% and 53.22%, respectively, and increasing information\ntransfer rate by 198.96%. In Task 2, ChatBCI achieves 80.68% keystroke savings\nand a record 8.53 characters\/min for typing speed. Overall, ChatBCI, by\nemploying remote LLM queries, enhances sentence composition in realistic\nscenarios, significantly outperforming traditional spellers without requiring\nlocal model training or storage. ChatBCI's (multi-) word predictions, combined\nwith its new GUI, pave the way for developing next-generation speller BCIs that\nare efficient and effective for real-time communication, especially for users\nwith communication and motor disabilities.",
    "explanation":"In this work, we introduce ChatBCI, a P300 speller BCI that leverages the zero-\nshot learning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing keystrokes\nand accelerating sentence composition. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Brain\u2013Computer Interface Spellers: A Review"
    ],
    "b_abstract":[
      "A Brain\u2013Computer Interface (BCI) provides a novel non-muscular communication method via brain signals. BCI-speller can be considered as one of the first published BCI applications and has opened gate for many advances in field. Although BCI-spellers have been developed during last few decades, to our knowledge, no reviews described different spellers proposed studied this vital The presented speller systems are categorized according major paradigms: P300, steady-state visual evoked potential (SSVEP), motor imagery (MI). Different paradigms require specific electroencephalogram (EEG) signal features lead development appropriate Graphical User Interfaces (GUIs). purpose review is consolidate most successful since 2010, while mentioning some other older which were built explicitly spelling purposes. We aim assist researchers concerned individuals field by illustrating highlights presenting them review. It almost impossible carry out an objective comparison between spellers, each its variables, parameters, conditions. However, gathered information provided taxonomy about helpful, it could identify suitable first-hand users, well opportunities learning from previous studies researchers."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.10114"
    ],
    "c_title":[
      "Infrastructure for AI Agents"
    ],
    "c_abstract":[
      "Increasingly many AI systems can plan and execute interactions in open-ended\nenvironments, such as making phone calls or buying online goods. As developers\ngrow the space of tasks that such AI agents can accomplish, we will need tools\nboth to unlock their benefits and manage their risks. Current tools are largely\ninsufficient because they are not designed to shape how agents interact with\nexisting institutions (e.g., legal and economic systems) or actors (e.g.,\ndigital service providers, humans, other AI agents). For example, alignment\ntechniques by nature do not assure counterparties that some human will be held\naccountable when a user instructs an agent to perform an illegal action. To\nfill this gap, we propose the concept of agent infrastructure: technical\nsystems and shared protocols external to agents that are designed to mediate\nand influence their interactions with and impacts on their environments. Agent\ninfrastructure comprises both new tools and reconfigurations or extensions of\nexisting tools. For example, to facilitate accountability, protocols that tie\nusers to agents could build upon existing systems for user authentication, such\nas OpenID. Just as the Internet relies on infrastructure like HTTPS, we argue\nthat agent infrastructure will be similarly indispensable to ecosystems of\nagents. We identify three functions for agent infrastructure: 1) attributing\nactions, properties, and other information to specific agents, their users, or\nother actors; 2) shaping agents' interactions; and 3) detecting and remedying\nharmful actions from agents. We propose infrastructure that could help achieve\neach function, explaining use cases, adoption, limitations, and open questions.\nMaking progress on agent infrastructure can prepare society for the adoption of\nmore advanced agents."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.15395",
    "a_title":"ChatBCI: A P300 Speller BCI Leveraging Large Language Models for\n  Improved Sentence Composition in Realistic Scenarios",
    "a_abstract":"P300 speller BCIs allow users to compose sentences by selecting target keys\non a GUI through the detection of P300 component in their EEG signals following\nvisual stimuli. Most P300 speller BCIs require users to spell words letter by\nletter, or the first few initial letters, resulting in high keystroke demands\nthat increase time, cognitive load, and fatigue. This highlights the need for\nmore efficient, user-friendly methods for faster sentence composition. In this\nwork, we introduce ChatBCI, a P300 speller BCI that leverages the zero-shot\nlearning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing\nkeystrokes and accelerating sentence composition. ChatBCI retrieves word\nsuggestions through remote queries to the GPT-3.5 API. A new GUI, displaying\nGPT-3.5 word suggestions as extra keys is designed. SWLDA is used for the P300\nclassification. Seven subjects completed two online spelling tasks: 1)\ncopy-spelling a self-composed sentence using ChatBCI, and 2) improvising a\nsentence using ChatBCI's word suggestions. Results demonstrate that in Task 1,\non average, ChatBCI outperforms letter-by-letter BCI spellers, reducing time\nand keystrokes by 62.14% and 53.22%, respectively, and increasing information\ntransfer rate by 198.96%. In Task 2, ChatBCI achieves 80.68% keystroke savings\nand a record 8.53 characters\/min for typing speed. Overall, ChatBCI, by\nemploying remote LLM queries, enhances sentence composition in realistic\nscenarios, significantly outperforming traditional spellers without requiring\nlocal model training or storage. ChatBCI's (multi-) word predictions, combined\nwith its new GUI, pave the way for developing next-generation speller BCIs that\nare efficient and effective for real-time communication, especially for users\nwith communication and motor disabilities.",
    "explanation":"In this work, we introduce ChatBCI, a P300 speller BCI that leverages the zero-\nshot learning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing keystrokes\nand accelerating sentence composition. ",
    "b_id":[
      "b17"
    ],
    "b_title":[
      "Language Model-Guided Classifier Adaptation for Brain-Computer Interfaces for Communication"
    ],
    "b_abstract":[
      "Brain-computer interfaces (BCIs), such as the P300 speller, can provide a means of communication for individuals with severe neuromuscular limitations. BCIs interpret electroencephalography (EEG) signals in order to translate embedded information about user's intent into executable commands control external devices. However, EEG are inherently noisy and nonstationary, posing challenge extended BCI use. Conventionally, classifier is trained via supervised learning an offline calibration session; once trained, deployed online use not updated. As statistics data change over time, performance static may decline It therefore desirable automatically adapt current without requiring recalibration. In existing semi-supervised approach, on labeled then updated using incoming unlabeled classifier-predicted labels. To reduce risk from incorrect predictions, threshold imposed exclude low-confidence label predictions expanded training set when retraining adaptive classifier. this work, we propose language model spelling error correction disambiguation correctness during learning. Results simulations multi-session speller user demonstrate that our language-guided approach significantly improves accuracy relative conventional threshold-based"
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.09672"
    ],
    "c_title":[
      "Mechanoreceptive A$\\beta$ primary afferents discriminate naturalistic\n  social touch inputs at a functionally relevant time scale"
    ],
    "c_abstract":[
      "Interpersonal touch is an important channel of social emotional interaction.\nHow these physical skin-to-skin touch expressions are processed in the\nperipheral nervous system is not well understood. From microneurography\nrecordings in humans, we evaluated the capacity of six subtypes of cutaneous\nmechanoreceptive afferents to differentiate human-delivered social touch\nexpressions. Leveraging statistical and classification analyses, we found that\nsingle units of multiple mechanoreceptive A$\\beta$ subtypes, especially slowly\nadapting type II (SA-II) and fast adapting hair follicle afferents (HFA), can\nreliably differentiate social touch expressions at accuracies similar to human\nrecognition. We then identified the most informative firing patterns of SA-II\nand HFA afferents, which indicate that average durations of 3-4 s of firing\nprovide sufficient discriminative information. Those two subtypes also exhibit\nrobust tolerance to spike-timing shifts of up to 10-20 ms, varying with touch\nexpressions due to their specific firing properties. Greater shifts in\nspike-timing, however, can change a firing pattern's envelope to resemble that\nof another expression and drastically compromise an afferent's discrimination\ncapacity. Altogether, the findings indicate that SA-II and HFA afferents\ndifferentiate the skin contact of social touch at time scales relevant for such\ninteractions, which are 1-2 orders of magnitude longer than those for\nnon-social touch."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.08063",
    "a_title":"MatPilot: an LLM-enabled AI Materials Scientist under the Framework of\n  Human-Machine Collaboration",
    "a_abstract":"The rapid evolution of artificial intelligence, particularly large language\nmodels, presents unprecedented opportunities for materials science research. We\nproposed and developed an AI materials scientist named MatPilot, which has\nshown encouraging abilities in the discovery of new materials. The core\nstrength of MatPilot is its natural language interactive human-machine\ncollaboration, which augments the research capabilities of human scientist\nteams through a multi-agent system. MatPilot integrates unique cognitive\nabilities, extensive accumulated experience, and ongoing curiosity of\nhuman-beings with the AI agents' capabilities of advanced abstraction, complex\nknowledge storage and high-dimensional information processing. It could\ngenerate scientific hypotheses and experimental schemes, and employ predictive\nmodels and optimization algorithms to drive an automated experimental platform\nfor experiments. It turns out that our system demonstrates capabilities for\nefficient validation, continuous learning, and iterative optimization.",
    "explanation":"proposed and\ndeveloped an AI materials scientist named MatPilot, which has shown encouraging\nabilities in the discovery of new materials. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "A Data-Science Approach to Predict the Heat Capacity of Nanoporous Materials"
    ],
    "b_abstract":[
      "The heat capacity of a material is a fundamental property of great practical importance. For example, in a carbon capture process, the heat required to regenerate a solid sorbent is directly related to the heat capacity of the material. However, for most materials suitable for carbon capture applications, the heat capacity is not known, and thus the standard procedure is to assume the same value for all materials. In this work, we developed a machine learning approach, trained on density functional theory simulations, to accurately predict the heat capacity of these materials, that is, zeolites, metal\u2013organic frameworks and covalent\u2013organic frameworks. The accuracy of our prediction is confirmed with experimental data. Finally, for a temperature swing adsorption process that captures carbon from the flue gas of a coal-fired power plant, we show that for some materials, the heat requirement is reduced by as much as a factor of two using the correct heat capacity. Heat capacity of nanoporous materials is important for processes such as carbon capture, as this can affect process design energy requirements. Here, a machine learning approach for heat capacity prediction, trained on density functional theory simulations, is presented and experimentally verified."
    ],
    "b_categories":[
      "cond-mat.mtrl-sci"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.03274"
    ],
    "c_title":[
      "A Scalable Approach to Probabilistic Neuro-Symbolic Verification"
    ],
    "c_abstract":[
      "Neuro-Symbolic Artificial Intelligence (NeSy AI) has emerged as a promising\ndirection for integrating neural learning with symbolic reasoning. In the\nprobabilistic variant of such systems, a neural network first extracts a set of\nsymbols from sub-symbolic input, which are then used by a symbolic component to\nreason in a probabilistic manner towards answering a query. In this work, we\naddress the problem of formally verifying the robustness of such NeSy\nprobabilistic reasoning systems, therefore paving the way for their safe\ndeployment in critical domains. We analyze the complexity of solving this\nproblem exactly, and show that it is $\\mathrm{NP}^{\\# \\mathrm{P}}$-hard. To\novercome this issue, we propose the first approach for approximate,\nrelaxation-based verification of probabilistic NeSy systems. We demonstrate\nexperimentally that the proposed method scales exponentially better than\nsolver-based solutions and apply our technique to a real-world autonomous\ndriving dataset, where we verify a safety property under large input\ndimensionalities and network sizes."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.08063",
    "a_title":"MatPilot: an LLM-enabled AI Materials Scientist under the Framework of\n  Human-Machine Collaboration",
    "a_abstract":"The rapid evolution of artificial intelligence, particularly large language\nmodels, presents unprecedented opportunities for materials science research. We\nproposed and developed an AI materials scientist named MatPilot, which has\nshown encouraging abilities in the discovery of new materials. The core\nstrength of MatPilot is its natural language interactive human-machine\ncollaboration, which augments the research capabilities of human scientist\nteams through a multi-agent system. MatPilot integrates unique cognitive\nabilities, extensive accumulated experience, and ongoing curiosity of\nhuman-beings with the AI agents' capabilities of advanced abstraction, complex\nknowledge storage and high-dimensional information processing. It could\ngenerate scientific hypotheses and experimental schemes, and employ predictive\nmodels and optimization algorithms to drive an automated experimental platform\nfor experiments. It turns out that our system demonstrates capabilities for\nefficient validation, continuous learning, and iterative optimization.",
    "explanation":"proposed and\ndeveloped an AI materials scientist named MatPilot, which has shown encouraging\nabilities in the discovery of new materials. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "A deep-learning approach to realizing functionality in nanoelectronic devices"
    ],
    "b_abstract":[
      "Many nanoscale devices require precise optimization to function. Tuning them to the desired operation regime becomes increasingly difficult and time-consuming when the number of terminals and couplings grows. Imperfections and device-to-device variations hinder optimization that uses physics-based models. Deep neural networks (DNNs) can model various complex physical phenomena but, so far, are mainly used as predictive tools. Here, we propose a generic deep-learning approach to efficiently optimize complex, multi-terminal nanoelectronic devices for desired functionality. We demonstrate our approach for realizing functionality in a disordered network of dopant atoms in silicon. We model the input\u2013output characteristics of the device with a DNN, and subsequently optimize control parameters in the DNN model through gradient descent to realize various classification tasks. When the corresponding control settings are applied to the physical device, the resulting functionality is as predicted by the DNN model. We expect our approach to contribute to fast, in situ optimization of complex (quantum) nanoelectronic devices."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.02853"
    ],
    "c_title":[
      "BaTiO$_3$ -- SrTiO$_3$ composites: a microscopic study on paraelectric\n  cubic inclusions"
    ],
    "c_abstract":[
      "Composites of ferroelectric and paraelectric perovskites have attracted a lot\nof attention due to their application potential in energy storage as well as\nnovel computing and memory devices. So far the main focus of research has been\non superlattices and ferroelectric particles in a paraelectric matrix, while\nthe impact of paraelectric inclusions on the ferroelectric matrix is\nsurprisingly underrepresented. To close this gap in knowledge we perform\nmolecular dynamics simulations using an $ab\\ initio$ derived effective\nHamiltonian for BaTiO$_3$--SrTiO$_3$ and reveal the dependency of phase\nstability and phase transitions on the size and distances of paraelectric\ninclusions. We discuss how the combination of compressive strain and\ndepolarization fields at the SrTiO$_3$ interfaces induces large local\npolarization, complex domain structures and coexisting phases as well as\ndiffuse phase transitions and reduced coercive fields."
    ],
    "c_categories":[
      "cond-mat.mtrl-sci"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.13126",
    "a_title":"A Knowledge-enhanced Pathology Vision-language Foundation Model for\n  Cancer Diagnosis",
    "a_abstract":"Deep learning has enabled the development of highly robust foundation models\nfor various pathological tasks across diverse diseases and patient cohorts.\nAmong these models, vision-language pre-training, which leverages large-scale\npaired data to align pathology image and text embedding spaces, and provides a\nnovel zero-shot paradigm for downstream tasks. However, existing models have\nbeen primarily data-driven and lack the incorporation of domain-specific\nknowledge, which limits their performance in cancer diagnosis, especially for\nrare tumor subtypes. To address this limitation, we establish a\nKnowledge-enhanced Pathology (KEEP) foundation model that harnesses disease\nknowledge to facilitate vision-language pre-training. Specifically, we first\nconstruct a disease knowledge graph (KG) that covers 11,454 human diseases with\n139,143 disease attributes, including synonyms, definitions, and hypernym\nrelations. We then systematically reorganize the millions of publicly available\nnoisy pathology image-text pairs, into 143K well-structured semantic groups\nlinked through the hierarchical relations of the disease KG. To derive more\nnuanced image and text representations, we propose a novel knowledge-enhanced\nvision-language pre-training approach that integrates disease knowledge into\nthe alignment within hierarchical semantic groups instead of unstructured\nimage-text pairs. Validated on 18 diverse benchmarks with more than 14,000\nwhole slide images (WSIs), KEEP achieves state-of-the-art performance in\nzero-shot cancer diagnostic tasks. Notably, for cancer detection, KEEP\ndemonstrates an average sensitivity of 89.8% at a specificity of 95.0% across 7\ncancer types. For cancer subtyping, KEEP achieves a median balanced accuracy of\n0.456 in subtyping 30 rare brain cancers, indicating strong generalizability\nfor diagnosing rare tumors.",
    "explanation":"However, existing models have been primarily data-driven and\nlack the incorporation of domain-specific knowledge, which limits their performance in cancer diagnosis,\nespecially for rare tumor subtypes. To address this limitation, we establish a KnowledgE-Enhanced\nPathology (KEEP) foundation model that harnesses disease knowledge to facilitate vision-language\npre-training.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Machine Learning-driven Histotype Diagnosis of Ovarian Carcinoma: Insights from the OCEAN AI Challenge"
    ],
    "b_abstract":[
      "Ovarian cancer poses a significant health burden as one of the deadliest malignancies affecting women globally. Histotype assignment of epithelial ovarian cancers can be challenging due to morphologic overlap, inter-observer variability, and the lack of ancillary diagnostic techniques in some areas of the world. Moreover, rare cancers can pose particular diagnostic difficulties because of a relative lack of familiarity with them, underscoring the necessity for robust diagnostic methodologies. The emergence of Artificial Intelligence (AI) has brought promising prospects to the realm of ovarian cancer diagnosis. While various studies have underscored AI's promise, its validation across multiple healthcare centers and hospitals has been limited. Inspired by innovations in medical imaging driven by public competitions, we initiated the Ovarian Cancer subtypE clAssification and outlier detectioN (OCEAN) challenge, the most extensive histopathology competition to date."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.18947"
    ],
    "c_title":[
      "Trait-structured chemotaxis: Exploring ligand-receptor dynamics and\n  travelling wave properties in a Keller-Segel model"
    ],
    "c_abstract":[
      "A novel trait-structured Keller-Segel model that explores the dynamics of a\nmigrating cell population guided by chemotaxis in response to an external\nligand concentration is derived and analysed. Unlike traditional Keller-Segel\nmodels, this framework introduces an explicit representation of ligand-receptor\nbindings on the cell membrane, where the percentage of occupied receptors\nconstitutes the trait that influences cellular phenotype. The model posits that\nthe cell's phenotypic state directly modulates its capacity for chemotaxis and\nproliferation, governed by a trade-off due to a finite energy budget: cells\nhighly proficient in chemotaxis exhibit lower proliferation rates, while more\nproliferative cells show diminished chemotactic abilities. The model is derived\nfrom the principles of a biased random walk, resulting in a system of two\nnon-local partial differential equations, describing the densities of both\ncells and ligands. Using a Hopf-Cole transformation, we derive an equation that\ncharacterises the distribution of cellular traits within travelling wave\nsolutions for the total cell density, allowing us to uncover the monotonicity\nproperties of these waves. Numerical investigations are conducted to examine\nthe model's behaviour across various biological scenarios, providing insights\ninto the complex interplay between chemotaxis, proliferation, and phenotypic\ndiversity in migrating cell populations."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.13126",
    "a_title":"A Knowledge-enhanced Pathology Vision-language Foundation Model for\n  Cancer Diagnosis",
    "a_abstract":"Deep learning has enabled the development of highly robust foundation models\nfor various pathological tasks across diverse diseases and patient cohorts.\nAmong these models, vision-language pre-training, which leverages large-scale\npaired data to align pathology image and text embedding spaces, and provides a\nnovel zero-shot paradigm for downstream tasks. However, existing models have\nbeen primarily data-driven and lack the incorporation of domain-specific\nknowledge, which limits their performance in cancer diagnosis, especially for\nrare tumor subtypes. To address this limitation, we establish a\nKnowledge-enhanced Pathology (KEEP) foundation model that harnesses disease\nknowledge to facilitate vision-language pre-training. Specifically, we first\nconstruct a disease knowledge graph (KG) that covers 11,454 human diseases with\n139,143 disease attributes, including synonyms, definitions, and hypernym\nrelations. We then systematically reorganize the millions of publicly available\nnoisy pathology image-text pairs, into 143K well-structured semantic groups\nlinked through the hierarchical relations of the disease KG. To derive more\nnuanced image and text representations, we propose a novel knowledge-enhanced\nvision-language pre-training approach that integrates disease knowledge into\nthe alignment within hierarchical semantic groups instead of unstructured\nimage-text pairs. Validated on 18 diverse benchmarks with more than 14,000\nwhole slide images (WSIs), KEEP achieves state-of-the-art performance in\nzero-shot cancer diagnostic tasks. Notably, for cancer detection, KEEP\ndemonstrates an average sensitivity of 89.8% at a specificity of 95.0% across 7\ncancer types. For cancer subtyping, KEEP achieves a median balanced accuracy of\n0.456 in subtyping 30 rare brain cancers, indicating strong generalizability\nfor diagnosing rare tumors.",
    "explanation":"However, existing models have been primarily data-driven and\nlack the incorporation of domain-specific knowledge, which limits their performance in cancer diagnosis,\nespecially for rare tumor subtypes. To address this limitation, we establish a KnowledgE-Enhanced\nPathology (KEEP) foundation model that harnesses disease knowledge to facilitate vision-language\npre-training.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Viable and necrotic tumor assessment from whole slide images of osteosarcoma using machine-learning and deep-learning models"
    ],
    "b_abstract":[
      "Pathological estimation of tumor necrosis after chemotherapy is essential for patients with osteosarcoma. This study reports the first fully automated tool to assess viable and necrotic in osteosarcoma, employing advances histopathology digitization learning. We selected 40 digitized whole slide images representing heterogeneity osteosarcoma response. With goal labeling diverse regions tissue into tumor, non-tumor, we trained 13 machine-learning models top performing one (a Support Vector Machine) based on reported accuracy. also developed a deep-learning architecture it same data set. computed receiver-operator characteristic discrimination non-tumor from followed by conditional found our exceptionally well. then used identify interest image-tiles generated test images. The classification output visualized as tumor-prediction map, displaying extent image. Thus, lay foundation complete assessment pipeline original histology map generation. proposed can be adopted other types tumor."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.03274"
    ],
    "c_title":[
      "A Scalable Approach to Probabilistic Neuro-Symbolic Verification"
    ],
    "c_abstract":[
      "Neuro-Symbolic Artificial Intelligence (NeSy AI) has emerged as a promising\ndirection for integrating neural learning with symbolic reasoning. In the\nprobabilistic variant of such systems, a neural network first extracts a set of\nsymbols from sub-symbolic input, which are then used by a symbolic component to\nreason in a probabilistic manner towards answering a query. In this work, we\naddress the problem of formally verifying the robustness of such NeSy\nprobabilistic reasoning systems, therefore paving the way for their safe\ndeployment in critical domains. We analyze the complexity of solving this\nproblem exactly, and show that it is $\\mathrm{NP}^{\\# \\mathrm{P}}$-hard. To\novercome this issue, we propose the first approach for approximate,\nrelaxation-based verification of probabilistic NeSy systems. We demonstrate\nexperimentally that the proposed method scales exponentially better than\nsolver-based solutions and apply our technique to a real-world autonomous\ndriving dataset, where we verify a safety property under large input\ndimensionalities and network sizes."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17717",
    "a_title":"Comprehensive Methodology for Sample Augmentation in EEG Biomarker\n  Studies for Alzheimers Risk Classification",
    "a_abstract":"Background: Dementia, marked by cognitive decline, is a global health\nchallenge. Alzheimer's disease (AD), the leading type, accounts for ~70% of\ncases. Electroencephalography (EEG) measures show promise in identifying AD\nrisk, but obtaining large samples for reliable comparisons is challenging.\nObjective: This study integrates signal processing, harmonization, and\nstatistical techniques to enhance sample size and improve AD risk\nclassification reliability. Methods: We used advanced EEG preprocessing,\nfeature extraction, harmonization, and propensity score matching (PSM) to\nbalance healthy non-carriers (HC) and asymptomatic E280A mutation carriers\n(ACr). Data from four databases were harmonized to adjust site effects while\npreserving covariates like age and sex. PSM ratios (2:1, 5:1, 10:1) were\napplied to assess sample size impact on model performance. The final dataset\nunderwent machine learning analysis with decision trees and cross-validation\nfor robust results. Results: Balancing sample sizes via PSM significantly\nimproved classification accuracy, ranging from 0.92 to 0.96 across ratios. This\napproach enabled precise risk identification even with limited samples.\nConclusion: Integrating data processing, harmonization, and balancing\ntechniques improves AD risk classification accuracy, offering potential for\nother neurodegenerative diseases.",
    "explanation":"This study implements a\ncomprehensive methodology that integrates signal processing, data harmonization, and\nstatistical techniques to increase sample size and improve the reliability of Alzheimer's disease\nrisk classification models.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Neural biomarker diagnosis and prediction to mild cognitive impairment and Alzheimer\u2019s disease using EEG technology"
    ],
    "b_abstract":[
      "Background Electroencephalogram (EEG) has emerged as a non-invasive tool to detect the aberrant neuronal activity related to different stages of Alzheimer\u2019s disease (AD). However, the effectiveness of EEG in the precise diagnosis and assessment of AD and its preclinical stage, amnestic mild cognitive impairment (MCI), has yet to be fully elucidated. In this study, we aimed to identify key EEG biomarkers that are effective in distinguishing patients at the early stage of AD and monitoring the progression of AD. Methods A total of 890 participants, including 189 patients with MCI, 330 patients with AD, 125 patients with other dementias (frontotemporal dementia, dementia with Lewy bodies, and vascular cognitive impairment), and 246 healthy controls (HC) were enrolled. Biomarkers were extracted from resting-state EEG recordings for a three-level classification of HC, MCI, and AD. The optimal EEG biomarkers were then identified based on the classification performance. Random forest regression was used to train a series of models by combining participants\u2019 EEG biomarkers, demographic information (i.e., sex, age), CSF biomarkers, and APOE phenotype for assessing the disease progression and individual\u2019s cognitive function. Results The identified EEG biomarkers achieved over 70% accuracy in the three-level classification of HC, MCI, and AD. Among all six groups, the most prominent effects of AD-linked neurodegeneration on EEG metrics were localized at parieto-occipital regions. In the cross-validation predictive analyses, the optimal EEG features were more effective than the CSF + APOE biomarkers in predicting the age of onset and disease course, whereas the combination of EEG + CSF + APOE measures achieved the best performance for all targets of prediction. Conclusions Our study indicates that EEG can be used as a useful screening tool for the diagnosis and disease progression evaluation of MCI and AD."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.08070"
    ],
    "c_title":[
      "Normative Cerebral Perfusion Across the Lifespan"
    ],
    "c_abstract":[
      "Cerebral perfusion plays a crucial role in maintaining brain function and is\ntightly coupled with neuronal activity. While previous studies have examined\ncerebral perfusion trajectories across development and aging, precise\ncharacterization of its lifespan dynamics has been limited by small sample\nsizes and methodological inconsistencies. In this study, we construct the first\ncomprehensive normative model of cerebral perfusion across the human lifespan\n(birth to 85 years) using a large multi-site dataset of over 12,000\nhigh-quality arterial spin labeling (ASL) MRI scans. Leveraging generalized\nadditive models for location, scale, and shape (GAMLSS), we mapped nonlinear\ngrowth trajectories of cerebral perfusion at global, network, and regional\nlevels. We observed a rapid postnatal increase in cerebral perfusion, peaking\nat approximately 7.1 years, followed by a gradual decline into adulthood. Sex\ndifferences were evident, with distinct regional maturation patterns rather\nthan uniform differences across all brain regions. Beyond normative modeling,\nwe quantified individual deviations from expected CBF patterns in\nneurodegenerative and psychiatric conditions, identifying disease-specific\nperfusion abnormalities across four brain disorders. Using longitudinal data,\nwe established typical and atypical cerebral perfusion trajectories,\nhighlighting the prognostic value of perfusion-based biomarkers for detecting\ndisease progression. Our findings provide a robust normative framework for\ncerebral perfusion, facilitating precise characterization of brain health\nacross the lifespan and enhancing the early identification of neurovascular\ndysfunction in clinical populations."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17717",
    "a_title":"Comprehensive Methodology for Sample Augmentation in EEG Biomarker\n  Studies for Alzheimers Risk Classification",
    "a_abstract":"Background: Dementia, marked by cognitive decline, is a global health\nchallenge. Alzheimer's disease (AD), the leading type, accounts for ~70% of\ncases. Electroencephalography (EEG) measures show promise in identifying AD\nrisk, but obtaining large samples for reliable comparisons is challenging.\nObjective: This study integrates signal processing, harmonization, and\nstatistical techniques to enhance sample size and improve AD risk\nclassification reliability. Methods: We used advanced EEG preprocessing,\nfeature extraction, harmonization, and propensity score matching (PSM) to\nbalance healthy non-carriers (HC) and asymptomatic E280A mutation carriers\n(ACr). Data from four databases were harmonized to adjust site effects while\npreserving covariates like age and sex. PSM ratios (2:1, 5:1, 10:1) were\napplied to assess sample size impact on model performance. The final dataset\nunderwent machine learning analysis with decision trees and cross-validation\nfor robust results. Results: Balancing sample sizes via PSM significantly\nimproved classification accuracy, ranging from 0.92 to 0.96 across ratios. This\napproach enabled precise risk identification even with limited samples.\nConclusion: Integrating data processing, harmonization, and balancing\ntechniques improves AD risk classification accuracy, offering potential for\nother neurodegenerative diseases.",
    "explanation":"This study implements a\ncomprehensive methodology that integrates signal processing, data harmonization, and\nstatistical techniques to increase sample size and improve the reliability of Alzheimer's disease\nrisk classification models.",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "Quantitative EEG analysis disease during resting and memory task in carriers and non-carriers of PS-1 E280A mutation of familial Alzheimer's"
    ],
    "b_abstract":[
      "Background: Alzheimer\u2019s disease is the most leading cause of dementia in world; mutation PS-1 E280A alters gene Presenilin-1 and causes an early onset familial disease. This has been found large kindred Antioquia, Colombia. The objective this study was to find differences revealed by electroencephalogram between healthy subjects asymptomatic carriers that can be used as clinical markers population. Methods: EEG recorded 15 non during resting a memory task using 64 channels amplifier. Two conditions were analyzed: encoding retrieval, process recording evocating information, respectively. Power spectrum calculated delta (0.5\u20134.0 Hz), theta (4.0\u20138. 0 alpha-1 (8.0\u201310.0 alpha-2 (10.0\u201313.0 beta (13.0\u201325.0 Hz) gamma (25.0\u201350 frequency bands for four regions interest. Changes evaluated different ANOVA analysis. Results: In condition significant decrease (p=0. 0001) increase frequencies (p=0.037) compare with controls. During significantly lower compared controls 008) comparing versus retrieval each group, there more synchronization carriers. Conclusion: Early changes observed recordings, it could use Also seems activate additional cortical order conserve successful cognitive functions before impairment ."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.06727"
    ],
    "c_title":[
      "Application of Artificial Intelligence (AI) in Civil Engineering"
    ],
    "c_abstract":[
      "Hard computing generally deals with precise data, which provides ideal\nsolutions to problems. However, in the civil engineering field, amongst other\ndisciplines, that is not always the case as real-world systems are continuously\nchanging. Here lies the need to explore soft computing methods and artificial\nintelligence to solve civil engineering shortcomings. The integration of\nadvanced computational models, including Artificial Neural Networks (ANNs),\nFuzzy Logic, Genetic Algorithms (GAs), and Probabilistic Reasoning, has\nrevolutionized the domain of civil engineering. These models have significantly\nadvanced diverse sub-fields by offering innovative solutions and improved\nanalysis capabilities. Sub-fields such as: slope stability analysis, bearing\ncapacity, water quality and treatment, transportation systems, air quality,\nstructural materials, etc. ANNs predict non-linearities and provide accurate\nestimates. Fuzzy logic uses an efficient decision-making process to provide a\nmore precise assessment of systems. Lastly, while GAs optimizes models (based\non evolutionary processes) for better outcomes, probabilistic reasoning lowers\ntheir statistical uncertainties."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.16728",
    "a_title":"Maximizing the Impact of Deep Learning on Subseasonal-to-Seasonal\n  Climate Forecasting: The Essential Role of Optimization",
    "a_abstract":"Weather and climate forecasting is vital for sectors such as agriculture and\ndisaster management. Although numerical weather prediction (NWP) systems have\nadvanced, forecasting at the subseasonal-to-seasonal (S2S) scale, spanning 2 to\n6 weeks, remains challenging due to the chaotic and sparse atmospheric signals\nat this interval. Even state-of-the-art deep learning models struggle to\noutperform simple climatology models in this domain. This paper identifies that\noptimization, instead of network structure, could be the root cause of this\nperformance gap, and then we develop a novel multi-stage optimization strategy\nto close the gap. Extensive empirical studies demonstrate that our multi-stage\noptimization approach significantly improves key skill metrics, PCC and TCC,\nwhile utilizing the same backbone structure, surpassing the state-of-the-art\nNWP systems (ECMWF-S2S) by over \\textbf{19-91\\%}. Our research contests the\nrecent study that direct forecasting outperforms rolling forecasting for S2S\ntasks. Through theoretical analysis, we propose that the underperformance of\nrolling forecasting may arise from the accumulation of Jacobian matrix products\nduring training. Our multi-stage framework can be viewed as a form of teacher\nforcing to address this issue. Code is available at\n\\url{https:\/\/anonymous.4open.science\/r\/Baguan-S2S-23E7\/}",
    "explanation":"Weather and climate forecasting is vital for sectors such\nas agriculture and disaster management. Although numeri-\ncal weather prediction (NWP) systems have advanced, fore-\ncasting at the subseasonal-to-seasonal (S2S) scale, span-\nning 2 to 6 weeks, remains challenging due to the chaotic\nand sparse atmospheric signals at this interval.",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "FuXi-S2S: An accurate machine learning model for global subseasonal forecasts"
    ],
    "b_abstract":[
      "Skillful subseasonal forecasts beyond 2 weeks are crucial for a wide range of applications across various sectors society. Recently, state-of-the-art machine learning based weather forecasting models have made significant advancements, outperforming the high-resolution forecast (HRES) from European Centre Medium-Range Weather Forecasts (ECMWF). However, full potential in has yet to be fully explored. In this study, we introduce FuXi Subseasonal-to-Seasonal (FuXi-S2S), model that provides global daily mean up 42 days, covering 5 upper-air atmospheric variables at 13 pressure levels and 11 surface variables. FuXi-S2S integrates an enhanced base with perturbation module flow-dependent perturbations hidden features, incorporates Perlin noise perturb initial conditions. The is developed using 72 years statistics ECMWF ERA5 reanalysis data. When compared (S2S) reforecasts, demonstrate superior deterministic ensemble total precipitation (TP), outgoing longwave radiation (OLR), geopotential 500 hPa (Z500). Although it shows slightly inferior performance predicting 2-meter temperature (T2M), clear advantages over land area. Regarding extreme forecasts, outperforms S2S globally TP. Furthermore, surpass reforecasts Madden Julian Oscillation (MJO), key source predictability. They extend skillful prediction MJO 30 days 36 days."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.01476"
    ],
    "c_title":[
      "Sparse identification of evolution equations via Bayesian model\n  selection"
    ],
    "c_abstract":[
      "The quantitative formulation of evolution equations is the backbone for\nprediction, control, and understanding of dynamical systems across diverse\nscientific fields. Besides deriving differential equations for dynamical\nsystems based on basic scientific reasoning or prior knowledge in recent times\na growing interest emerged to infer these equations purely from data. In this\narticle, we introduce a novel method for the sparse identification of nonlinear\ndynamical systems from observational data, based on the observation how the key\nchallenges of the quality of time derivatives and sampling rates influence this\nproblem. Our approach combines system identification based on thresholded least\nsquares minimization with additional error measures that account for both the\ndeviation between the model and the time derivative of the data, and the\nintegrated performance of the model in forecasting dynamics. Specifically, we\nintegrate a least squares error as well as the Wasserstein metric for estimated\nmodels and combine them within a Bayesian optimization framework to efficiently\ndetermine optimal hyperparameters for thresholding and weighting of the\ndifferent error norms. Additionally, we employ distinct regularization\nparameters for each differential equation in the system, enhancing the method's\nprecision and flexibility. We demonstrate the capabilities of our approach\nthrough applications to dynamical fMRI data and the prototypical example of a\nwake flow behind a cylinder. In the wake flow problem, our method identifies a\nsparse, accurate model that correctly captures transient dynamics, oscillation\nperiods, and phase information, outperforming existing methods. In the fMRI\nexample, we show how our approach extracts insights from a trained recurrent\nneural network, offering a novel avenue for explainable AI by inferring\ndifferential equations that capture potentially causal relationships."
    ],
    "c_categories":[
      "physics.data-an"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.16728",
    "a_title":"Maximizing the Impact of Deep Learning on Subseasonal-to-Seasonal\n  Climate Forecasting: The Essential Role of Optimization",
    "a_abstract":"Weather and climate forecasting is vital for sectors such as agriculture and\ndisaster management. Although numerical weather prediction (NWP) systems have\nadvanced, forecasting at the subseasonal-to-seasonal (S2S) scale, spanning 2 to\n6 weeks, remains challenging due to the chaotic and sparse atmospheric signals\nat this interval. Even state-of-the-art deep learning models struggle to\noutperform simple climatology models in this domain. This paper identifies that\noptimization, instead of network structure, could be the root cause of this\nperformance gap, and then we develop a novel multi-stage optimization strategy\nto close the gap. Extensive empirical studies demonstrate that our multi-stage\noptimization approach significantly improves key skill metrics, PCC and TCC,\nwhile utilizing the same backbone structure, surpassing the state-of-the-art\nNWP systems (ECMWF-S2S) by over \\textbf{19-91\\%}. Our research contests the\nrecent study that direct forecasting outperforms rolling forecasting for S2S\ntasks. Through theoretical analysis, we propose that the underperformance of\nrolling forecasting may arise from the accumulation of Jacobian matrix products\nduring training. Our multi-stage framework can be viewed as a form of teacher\nforcing to address this issue. Code is available at\n\\url{https:\/\/anonymous.4open.science\/r\/Baguan-S2S-23E7\/}",
    "explanation":"Weather and climate forecasting is vital for sectors such\nas agriculture and disaster management. Although numeri-\ncal weather prediction (NWP) systems have advanced, fore-\ncasting at the subseasonal-to-seasonal (S2S) scale, span-\nning 2 to 6 weeks, remains challenging due to the chaotic\nand sparse atmospheric signals at this interval.",
    "b_id":[
      "b21"
    ],
    "b_title":[
      "Analysis methods for numerical weather prediction"
    ],
    "b_abstract":[
      "Abstract Bayesian probabilistic arguments are used to derive idealized equations for finding the best analysis numerical weather prediction. These compared with those from other published methods in light of physical characteristics NWP problem; namely predetermined nature basis analysis, need approximation because large\u2010order systems, underdeterminacy problem when using observations alone, and availability prior relationships resolve underdeterminacy. Prior result (1) knowledge time evolution model (which together use a distribution constitutes four\u2010dimensional data assimilation); (2) that atmosphere varies slowly (leading balance relationships); (3) nonlinear coupling parameters scales atmosphere. Methods discussed include variational techniques, smoothing splines, Kriging, optimal interpolation, successive corrections, constrained initialization, Kalman\u2010Bucy filter, adjoint assimilation. They all shown relate hence each other. Opinions given on particular might be more appropriate. By comparison method some insight is gained into appropriate choices practical methods."
    ],
    "b_categories":[
      "physics.data-an"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2501.07290"
    ],
    "c_title":[
      "Principles for Responsible AI Consciousness Research"
    ],
    "c_abstract":[
      "Recent research suggests that it may be possible to build conscious AI\nsystems now or in the near future. Conscious AI systems would arguably deserve\nmoral consideration, and it may be the case that large numbers of conscious\nsystems could be created and caused to suffer. Furthermore, AI systems or\nAI-generated characters may increasingly give the impression of being\nconscious, leading to debate about their moral status. Organisations involved\nin AI research must establish principles and policies to guide research and\ndeployment choices and public communication concerning consciousness. Even if\nan organisation chooses not to study AI consciousness as such, it will still\nneed policies in place, as those developing advanced AI systems risk\ninadvertently creating conscious entities. Responsible research and deployment\npractices are essential to address this possibility. We propose five principles\nfor responsible research and argue that research organisations should make\nvoluntary, public commitments to principles on these lines. Our principles\nconcern research objectives and procedures, knowledge sharing and public\ncommunications."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.02466",
    "a_title":"Weakly supervised deep learning model with size constraint for prostate\n  cancer detection in multiparametric MRI and generalization to unseen domains",
    "a_abstract":"Fully supervised deep models have shown promising performance for many\nmedical segmentation tasks. Still, the deployment of these tools in clinics is\nlimited by the very timeconsuming collection of manually expert-annotated data.\nMoreover, most of the state-ofthe-art models have been trained and validated on\nmoderately homogeneous datasets. It is known that deep learning methods are\noften greatly degraded by domain or label shifts and are yet to be built in\nsuch a way as to be robust to unseen data or label distributions. In the\nclinical setting, this problematic is particularly relevant as the deployment\ninstitutions may have different scanners or acquisition protocols than those\nfrom which the data has been collected to train the model. In this work, we\npropose to address these two challenges on the detection of clinically\nsignificant prostate cancer (csPCa) from bi-parametric MRI. We evaluate the\nmethod proposed by (Kervadec et al., 2018), which introduces a size constaint\nloss to produce fine semantic cancer lesions segmentations from weak circle\nscribbles annotations. Performance of the model is based on two public (PI-CAI\nand Prostate158) and one private databases. First, we show that the model\nachieves on-par performance with strong fully supervised baseline models, both\non in-distribution validation data and unseen test images. Second, we observe a\nperformance decrease for both fully supervised and weakly supervised models\nwhen tested on unseen data domains. This confirms the crucial need for\nefficient domain adaptation methods if deep learning models are aimed to be\ndeployed in a clinical environment. Finally, we show that ensemble predictions\nfrom multiple trainings increase generalization performance.",
    "explanation":"n this work, we propose to address these two challenges\non the detection of clinically significant prostate cancer (csPCa) from bi-parametric MRI.\nWe evaluate the method proposed by (Kervadec et al., 2018), which introduces a size con-\nstaint loss to produce fine semantic cancer lesions segmentations from weak circle scribbles\nannotations",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "A review of artificial intelligence in prostate cancer detection on imaging"
    ],
    "b_abstract":[
      "A multitude of studies have explored the role artificial intelligence (AI) in providing diagnostic support to radiologists, pathologists, and urologists prostate cancer detection, risk-stratification, management. This review provides a comprehensive overview relevant literature regarding use AI models (1) detecting on radiology images (magnetic resonance ultrasound imaging), (2) histopathology biopsy tissue, (3) assisting supporting tasks for detection (prostate gland segmentation, MRI-histopathology registration, MRI-ultrasound registration). We discuss both potential these assist clinical workflow diagnosis, as well current limitations including variability training data sets, algorithms, evaluation criteria. also ongoing challenges what is needed bridge gap between academic research commercial solutions that improve routine care."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.01834"
    ],
    "c_title":[
      "Intercellular contact is sufficient to drive Fibroblast to Myofibroblast\n  transitions"
    ],
    "c_abstract":[
      "Fibroblast cells play a key role in maintaining the extracellular matrix.\nDuring wound healing, fibroblasts differentiate into highly contractile\nmyofibroblasts, which secrete extracellular matrix proteins like collagen to\nfacilitate tissue repair. Under normal conditions, myofibroblasts undergo\nprogrammed cell death after healing to prevent excessive scar formation.\nHowever, in diseases like fibrosis, the myofibroblasts remain active even after\nthe wound is closed, resulting in excessive collagen buildup and a stiff,\nfibrotic matrix. The reasons for the persistence of myofibroblasts in fibrosis\nare not well understood. Here we show the existence of a mechanism where direct\nphysical contact between a fibroblast and a myofibroblast is sufficient for\nfibroblasts to transition into myofibroblasts. We show that\nfibroblast-myofibroblast transition can occur even in the absence of known\nbiochemical cues such as growth factor activation or mechanical cues from a\nstiff, fibrotic matrix. Further, we show that contact-based\nfibroblast-myofibroblast activation can be blocked by G{\\alpha}q\/11\/14\ninhibitor FR9003591, which inhibits the formation of myofibroblasts. These\nfindings offer new insights into the persistence of fibrosis despite\ntherapeutic interventions and suggest a potential strategy to target\nfibroblast-to-myofibroblast transition in fibrosis."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.02466",
    "a_title":"Weakly supervised deep learning model with size constraint for prostate\n  cancer detection in multiparametric MRI and generalization to unseen domains",
    "a_abstract":"Fully supervised deep models have shown promising performance for many\nmedical segmentation tasks. Still, the deployment of these tools in clinics is\nlimited by the very timeconsuming collection of manually expert-annotated data.\nMoreover, most of the state-ofthe-art models have been trained and validated on\nmoderately homogeneous datasets. It is known that deep learning methods are\noften greatly degraded by domain or label shifts and are yet to be built in\nsuch a way as to be robust to unseen data or label distributions. In the\nclinical setting, this problematic is particularly relevant as the deployment\ninstitutions may have different scanners or acquisition protocols than those\nfrom which the data has been collected to train the model. In this work, we\npropose to address these two challenges on the detection of clinically\nsignificant prostate cancer (csPCa) from bi-parametric MRI. We evaluate the\nmethod proposed by (Kervadec et al., 2018), which introduces a size constaint\nloss to produce fine semantic cancer lesions segmentations from weak circle\nscribbles annotations. Performance of the model is based on two public (PI-CAI\nand Prostate158) and one private databases. First, we show that the model\nachieves on-par performance with strong fully supervised baseline models, both\non in-distribution validation data and unseen test images. Second, we observe a\nperformance decrease for both fully supervised and weakly supervised models\nwhen tested on unseen data domains. This confirms the crucial need for\nefficient domain adaptation methods if deep learning models are aimed to be\ndeployed in a clinical environment. Finally, we show that ensemble predictions\nfrom multiple trainings increase generalization performance.",
    "explanation":"n this work, we propose to address these two challenges\non the detection of clinically significant prostate cancer (csPCa) from bi-parametric MRI.\nWe evaluate the method proposed by (Kervadec et al., 2018), which introduces a size con-\nstaint loss to produce fine semantic cancer lesions segmentations from weak circle scribbles\nannotations",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "Automatic Prostate Cancer Detection On Multi-Parametric Mri With Hierarchical Weakly Supervised Learning"
    ],
    "b_abstract":[
      "Multi-parametric MRI (mp-MRI) is one of the most commonly used non-invasive methods for prostate cancer (PCa) diagnosis. In recent years, computer aided diagnosis (CAD) PCa on mp-MRI based deep learning techniques has gained much attention and shown promising progress. The key success to obtain a large amount high quality region annotation such that network can accurately learn variation lesions. order precisely annotate mp-MRI, pathological whole mount data patient normally required as reference, which often difficult in real world clinical situations. Therefore, we are motivated propose new method integrate different levels information available screening workflow through multitask hierarchical weakly supervised framework detection mp-MRI. Experimental results show our achieves segmentation results."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.04261"
    ],
    "c_title":[
      "VirtualXAI: A User-Centric Framework for Explainability Assessment\n  Leveraging GPT-Generated Personas"
    ],
    "c_abstract":[
      "In today's data-driven era, computational systems generate vast amounts of\ndata that drive the digital transformation of industries, where Artificial\nIntelligence (AI) plays a key role. Currently, the demand for eXplainable AI\n(XAI) has increased to enhance the interpretability, transparency, and\ntrustworthiness of AI models. However, evaluating XAI methods remains\nchallenging: existing evaluation frameworks typically focus on quantitative\nproperties such as fidelity, consistency, and stability without taking into\naccount qualitative characteristics such as satisfaction and interpretability.\nIn addition, practitioners face a lack of guidance in selecting appropriate\ndatasets, AI models, and XAI methods -a major hurdle in human-AI collaboration.\nTo address these gaps, we propose a framework that integrates quantitative\nbenchmarking with qualitative user assessments through virtual personas based\non the \"Anthology\" of backstories of the Large Language Model (LLM). Our\nframework also incorporates a content-based recommender system that leverages\ndataset-specific characteristics to match new input data with a repository of\nbenchmarked datasets. This yields an estimated XAI score and provides tailored\nrecommendations for both the optimal AI model and the XAI method for a given\nscenario."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.02614",
    "a_title":"Divergent Domains, Convergent Grading: Enhancing Generalization in\n  Diabetic Retinopathy Grading",
    "a_abstract":"Diabetic Retinopathy (DR) constitutes 5% of global blindness cases. While\nnumerous deep learning approaches have sought to enhance traditional DR grading\nmethods, they often falter when confronted with new out-of-distribution data\nthereby impeding their widespread application. In this study, we introduce a\nnovel deep learning method for achieving domain generalization (DG) in DR\ngrading and make the following contributions. First, we propose a new way of\ngenerating image-to-image diagnostically relevant fundus augmentations\nconditioned on the grade of the original fundus image. These augmentations are\ntailored to emulate the types of shifts in DR datasets thus increase the\nmodel's robustness. Second, we address the limitations of the standard\nclassification loss in DG for DR fundus datasets by proposing a new DG-specific\nloss, domain alignment loss; which ensures that the feature vectors from all\ndomains corresponding to the same class converge onto the same manifold for\nbetter domain generalization. Third, we tackle the coupled problem of data\nimbalance across DR domains and classes by proposing to employ Focal loss which\nseamlessly integrates with our new alignment loss. Fourth, due to inevitable\nobserver variability in DR diagnosis that induces label noise, we propose\nleveraging self-supervised pretraining. This approach ensures that our DG model\nremains robust against early susceptibility to label noise, even when only a\nlimited dataset of non-DR fundus images is available for pretraining. Our\nmethod demonstrates significant improvements over the strong Empirical Risk\nMinimization baseline and other recently proposed state-of-the-art DG methods\nfor DR grading. Code is available at https:\/\/github.com\/sharonchokuwa\/dg-adr.",
    "explanation":"In this study, we introduce a novel deep learning\nmethod for achieving domain generalization (DG) in DR\ngrading and make the following contributions.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Medical diffusion on a budget: textual inversion for medical image generation"
    ],
    "b_abstract":[
      "Diffusion-based models for text-to-image generation have gained immense popularity due to recent advancements in efficiency, accessibility, and quality. Although it is becoming increasingly feasible perform inference with these systems using consumer-grade GPUs, training them from scratch still requires access large datasets significant computational resources. In the case of medical image generation, availability large, publicly accessible that include text reports limited legal ethical concerns. While a diffusion model on private dataset may address this issue, not always institutions lacking necessary This work demonstrates pre-trained Stable Diffusion models, originally trained natural images, can be adapted various imaging modalities by embeddings textual inversion. study, we conducted experiments comprising only 100 samples three modalities. Embeddings were matter hours, while retaining diagnostic relevance generation. Experiments designed achieve several objectives. Firstly, fine-tuned processes inversion, revealing larger more examples are required. Secondly, validated our approach demonstrating 2\\% increase accuracy (AUC) detecting prostate cancer MRI, which challenging multi-modal modality, 0.78 0.80. Thirdly, performed simulations interpolating between healthy diseased states, combining multiple pathologies, inpainting show embedding flexibility control disease appearance. Finally, study small (less than 1 MB), facilitates easy sharing data reduced privacy"
    ],
    "b_categories":[
      "q-bio.OT"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.04686"
    ],
    "c_title":[
      "Learning Strategic Language Agents in the Werewolf Game with Iterative\n  Latent Space Policy Optimization"
    ],
    "c_abstract":[
      "Large language model (LLM)-based agents have recently shown impressive\nprogress in a variety of domains, including open-ended conversation and\nmulti-step decision-making. However, applying these agents to social deduction\ngames such as Werewolf, which requires both strategic decision-making and\nfree-form language interaction, remains non-trivial. Traditional methods based\non Counterfactual Regret Minimization (CFR) or reinforcement learning (RL)\ntypically depend on a predefined action space, making them unsuitable for\nlanguage games with unconstrained text action space. Meanwhile, pure LLM-based\nagents often suffer from intrinsic biases and require prohibitively large\ndatasets for fine-tuning. We propose Latent Space Policy Optimization (LSPO),\nan iterative framework that addresses these challenges by first mapping\nfree-form text to a discrete latent space, where methods like CFR and RL can\nlearn strategic policy more effectively. We then translate the learned policy\nback into natural language dialogues, which are used to fine-tune an LLM via\nDirect Preference Optimization (DPO). By iteratively alternating between these\nstages, our LSPO agent progressively enhances both strategic reasoning and\nlanguage communication. Experiment results on the Werewolf game show that our\nmethod improves the agent's performance in each iteration and outperforms\nexisting Werewolf agents, underscoring its promise for free-form language\ndecision-making."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.02614",
    "a_title":"Divergent Domains, Convergent Grading: Enhancing Generalization in\n  Diabetic Retinopathy Grading",
    "a_abstract":"Diabetic Retinopathy (DR) constitutes 5% of global blindness cases. While\nnumerous deep learning approaches have sought to enhance traditional DR grading\nmethods, they often falter when confronted with new out-of-distribution data\nthereby impeding their widespread application. In this study, we introduce a\nnovel deep learning method for achieving domain generalization (DG) in DR\ngrading and make the following contributions. First, we propose a new way of\ngenerating image-to-image diagnostically relevant fundus augmentations\nconditioned on the grade of the original fundus image. These augmentations are\ntailored to emulate the types of shifts in DR datasets thus increase the\nmodel's robustness. Second, we address the limitations of the standard\nclassification loss in DG for DR fundus datasets by proposing a new DG-specific\nloss, domain alignment loss; which ensures that the feature vectors from all\ndomains corresponding to the same class converge onto the same manifold for\nbetter domain generalization. Third, we tackle the coupled problem of data\nimbalance across DR domains and classes by proposing to employ Focal loss which\nseamlessly integrates with our new alignment loss. Fourth, due to inevitable\nobserver variability in DR diagnosis that induces label noise, we propose\nleveraging self-supervised pretraining. This approach ensures that our DG model\nremains robust against early susceptibility to label noise, even when only a\nlimited dataset of non-DR fundus images is available for pretraining. Our\nmethod demonstrates significant improvements over the strong Empirical Risk\nMinimization baseline and other recently proposed state-of-the-art DG methods\nfor DR grading. Code is available at https:\/\/github.com\/sharonchokuwa\/dg-adr.",
    "explanation":"In this study, we introduce a novel deep learning\nmethod for achieving domain generalization (DG) in DR\ngrading and make the following contributions.",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Deep Learning Techniques for Diabetic Retinopathy Classification: A Survey"
    ],
    "b_abstract":[
      "Diabetic Retinopathy (DR) is a degenerative disease that impacts the eyes and consequence of Diabetes mellitus, where high blood glucose levels induce lesions on eye retina.Diabetic regarded as leading cause blindness for diabetic patients, especially working-age population in developing nations.Treatment involves sustaining patient's current grade vision since irreversible.Early detection crucial order to sustain effectively.The main issue involved with DR manual diagnosis process very time, money, effort consuming an ophthalmologist's examination retinal fundus images.The latter also proves be more difficult, particularly early stages when features are less prominent images.Machine learning-based medical image analysis has proven competency assessing images, utilization deep learning algorithms aided (DR).This paper reviews analyzes state-of-the-art methods supervised, self-supervised, Vision Transformer setups, proposing classification detection.For instance, referable, non-referable, proliferative classifications reviewed summarized.Moreover, discusses available datasets used tasks such detection, classification, segmentation.The assesses research gaps area detection\/classification addresses various challenges need further study investigation."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.14929"
    ],
    "c_title":[
      "Cytogenetic, Hematobiochemical, and Histopathological Assessment of\n  Albino Rats (Rattus norvegicus) Fed on Gluten Extracts"
    ],
    "c_abstract":[
      "Background: Literature shows that most of the information on the toxicity of\ngluten is generated from survey and observational studies, resulting in\ninconsistent outcomes and a decrease in the acceptability of gluten-rich foods.\nTo determine gluten's safety, an in-depth in vitro and in vivo toxicological\nexamination is required. This enables scientists to come up with ameliorative\nstrategies if it turns out to have side effects, and consumers' trust can be\nrestored. Objectives: The objective of this study was to assess the toxicity of\ngluten extracts on albino rats (Rattus norvegicus). Materials and Methods:\nTwenty-four rats were randomly selected and divided into four groups, each\ncomprising six rats. Group 1 (control) rats were fed on pellet feeds and groups\n2, 3, and 4 were fed on daily dosages of 0.5, 1.0, and 1.5 g gluten extracts,\nrespectively. The rats' body weights and reactions were observed for 90 days\nbefore blood samples were collected for hematobiochemical and micronucleus\ntests. Histopathological examinations of the liver and kidneys were also\nperformed. Results: There was no difference (P > 0.05) in body weight, blood\nglucose level, or micronuclei between the control and treated rats. The\nlymphocytes, alkaline phosphatase, alanine transaminase, total protein, and\ncalcium ions of the test rats were all significantly (P < 0.05) altered but\nremained within the normal ranges. Other hematobiochemical parameters,\nincluding packed cell volume, hemoglobin, white and red blood cells, aspartate\ntransaminase, albumin, sodium ions, potassium ions, chloride ions, and urea,\nrevealed no marked changes. The treated rats' livers and kidneys showed no\nhistopathological changes. Conclusion: Gluten had no adverse effects. However,\nit altered hematobiochemical parameters, particularly the lymphocytes, alkaline\nphosphatase, alanine transaminase, total protein, and calcium ions."
    ],
    "c_categories":[
      "q-bio.OT"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.18767",
    "a_title":"Multi-Task Learning for Integrated Automated Contouring and Voxel-Based\n  Dose Prediction in Radiotherapy",
    "a_abstract":"Deep learning-based automated contouring and treatment planning has been\nproven to improve the efficiency and accuracy of radiotherapy. However,\nconventional radiotherapy treatment planning process has the automated\ncontouring and treatment planning as separate tasks. Moreover in deep learning\n(DL), the contouring and dose prediction tasks for automated treatment planning\nare done independently. In this study, we applied the multi-task learning (MTL)\napproach in order to seamlessly integrate automated contouring and voxel-based\ndose prediction tasks, as MTL can leverage common information between the two\ntasks and be able able to increase the efficiency of the automated tasks. We\ndeveloped our MTL framework using the two datasets: in-house prostate cancer\ndataset and the publicly available head and neck cancer dataset, OpenKBP.\nCompared to the sequential DL contouring and treatment planning tasks, our\nproposed method using MTL improved the mean absolute difference of dose volume\nhistogram metrics of prostate and head and neck sites by 19.82% and 16.33%,\nrespectively. Our MTL model for automated contouring and dose prediction tasks\ndemonstrated enhanced dose prediction performance while maintaining or\nsometimes even improving the contouring accuracy. Compared to the baseline\nautomated contouring model with the dice score coefficients of 0.818 for\nprostate and 0.674 for head and neck datasets, our MTL approach achieved\naverage scores of 0.824 and 0.716 for these datasets, respectively. Our study\nhighlights the potential of the proposed automated contouring and planning\nusing MTL to support the development of efficient and accurate automated\ntreatment planning for radiotherapy.",
    "explanation":"Deep learning-based automated contouring and treatment planning has\nbeen proven to improve the efficiency and accuracy of radiotherapy.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "A Transformer-Embedded Multi-Task Model for Dose Distribution Prediction"
    ],
    "b_abstract":[
      "Radiation therapy is a fundamental cancer treatment in the clinic. However, to satisfy clinical requirements, radiologists have iteratively adjust radiotherapy plan based on experience, causing it extremely subjective and time-consuming obtain clinically acceptable plan. To this end, we introduce transformer-embedded multi-task dose prediction (TransMTDP) network automatically predict distribution radiotherapy. Specifically, achieve more stable accurate predictions, three highly correlated tasks are included our TransMTDP network, i.e. main task provide each pixel with fine-grained value, an auxiliary isodose lines produce coarse-grained ranges, gradient learn subtle information such as radiation patterns edges maps. The integrated through shared encoder, following learning strategy. strengthen connection of output layers for different tasks, further use two additional constraints, consistency loss loss, reinforce match between features generated by task. Additionally, considering many organs human body symmetrical maps present abundant global features, embed transformer into framework capture long-range dependencies Evaluated in-house rectum dataset public head neck dataset, method gains superior performance compared state-of-the-art ones. Code available at https:\/\/github.com\/luuuwen\/TransMTDP."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.03001"
    ],
    "c_title":[
      "Multicellular self-organization in Escherichia coli"
    ],
    "c_abstract":[
      "Escherichia coli has long been a trusty companion, maintaining health in our\nguts and advancing biological knowledge in the laboratory. In light of recent\nfindings, we discuss multicellular self-organization in E. coli and develop\ngeneral ideas for multicellularity, including the necessity for multicellular\ndynamics and interpretation by dynamic graphs, applicable to both unicellular\nand multicellular organisms. In this context, we next discuss the documented\nbehaviors of E. coli self-organization (rosette formation, multicellular\nextension, and attached dormancy) and two potential behaviors (internal\ncommunication and mating). Finally, by comparing the dynamic graphs for\ndifferent communities, we develop principles relevant to the theory of\nmulticellularity."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.18767",
    "a_title":"Multi-Task Learning for Integrated Automated Contouring and Voxel-Based\n  Dose Prediction in Radiotherapy",
    "a_abstract":"Deep learning-based automated contouring and treatment planning has been\nproven to improve the efficiency and accuracy of radiotherapy. However,\nconventional radiotherapy treatment planning process has the automated\ncontouring and treatment planning as separate tasks. Moreover in deep learning\n(DL), the contouring and dose prediction tasks for automated treatment planning\nare done independently. In this study, we applied the multi-task learning (MTL)\napproach in order to seamlessly integrate automated contouring and voxel-based\ndose prediction tasks, as MTL can leverage common information between the two\ntasks and be able able to increase the efficiency of the automated tasks. We\ndeveloped our MTL framework using the two datasets: in-house prostate cancer\ndataset and the publicly available head and neck cancer dataset, OpenKBP.\nCompared to the sequential DL contouring and treatment planning tasks, our\nproposed method using MTL improved the mean absolute difference of dose volume\nhistogram metrics of prostate and head and neck sites by 19.82% and 16.33%,\nrespectively. Our MTL model for automated contouring and dose prediction tasks\ndemonstrated enhanced dose prediction performance while maintaining or\nsometimes even improving the contouring accuracy. Compared to the baseline\nautomated contouring model with the dice score coefficients of 0.818 for\nprostate and 0.674 for head and neck datasets, our MTL approach achieved\naverage scores of 0.824 and 0.716 for these datasets, respectively. Our study\nhighlights the potential of the proposed automated contouring and planning\nusing MTL to support the development of efficient and accurate automated\ntreatment planning for radiotherapy.",
    "explanation":"Deep learning-based automated contouring and treatment planning has\nbeen proven to improve the efficiency and accuracy of radiotherapy.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Clinical integration of machine learning for curative-intent radiation treatment of patients with prostate cancer"
    ],
    "b_abstract":[
      "Machine learning (ML) holds great promise for impacting healthcare delivery; however, to date most methods are tested in \u2018simulated\u2019 environments that cannot recapitulate factors influencing real-world clinical practice. We prospectively deployed and evaluated a random forest algorithm for therapeutic curative-intent radiation therapy (RT) treatment planning for prostate cancer in a blinded, head-to-head study with full integration into the clinical workflow. ML- and human-generated RT treatment plans were directly compared in a retrospective simulation with retesting (n\u2009=\u200950) and a prospective clinical deployment (n\u2009=\u200950) phase. Consistently throughout the study phases, treating physicians assessed ML- and human-generated RT treatment plans in a blinded manner following a priori defined standardized criteria and peer review processes, with the selected RT plan in the prospective phase delivered for patient treatment. Overall, 89% of ML-generated RT plans were considered clinically acceptable and 72% were selected over human-generated RT plans in head-to-head comparisons. RT planning using ML reduced the median time required for the entire RT planning process by 60.1% (118 to 47\u2009h). While ML RT plan acceptability remained stable between the simulation and deployment phases (92 versus 86%), the number of ML RT plans selected for treatment was significantly reduced (83 versus 61%, respectively). These findings highlight that retrospective or simulated evaluation of ML methods, even under expert blinded review, may not be representative of algorithm acceptance in a real-world clinical setting when patient care is at stake."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.04686"
    ],
    "c_title":[
      "Learning Strategic Language Agents in the Werewolf Game with Iterative\n  Latent Space Policy Optimization"
    ],
    "c_abstract":[
      "Large language model (LLM)-based agents have recently shown impressive\nprogress in a variety of domains, including open-ended conversation and\nmulti-step decision-making. However, applying these agents to social deduction\ngames such as Werewolf, which requires both strategic decision-making and\nfree-form language interaction, remains non-trivial. Traditional methods based\non Counterfactual Regret Minimization (CFR) or reinforcement learning (RL)\ntypically depend on a predefined action space, making them unsuitable for\nlanguage games with unconstrained text action space. Meanwhile, pure LLM-based\nagents often suffer from intrinsic biases and require prohibitively large\ndatasets for fine-tuning. We propose Latent Space Policy Optimization (LSPO),\nan iterative framework that addresses these challenges by first mapping\nfree-form text to a discrete latent space, where methods like CFR and RL can\nlearn strategic policy more effectively. We then translate the learned policy\nback into natural language dialogues, which are used to fine-tune an LLM via\nDirect Preference Optimization (DPO). By iteratively alternating between these\nstages, our LSPO agent progressively enhances both strategic reasoning and\nlanguage communication. Experiment results on the Werewolf game show that our\nmethod improves the agent's performance in each iteration and outperforms\nexisting Werewolf agents, underscoring its promise for free-form language\ndecision-making."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.10004",
    "a_title":"EyeDiff: text-to-image diffusion model improves rare eye disease\n  diagnosis",
    "a_abstract":"The rising prevalence of vision-threatening retinal diseases poses a\nsignificant burden on the global healthcare systems. Deep learning (DL) offers\na promising solution for automatic disease screening but demands substantial\ndata. Collecting and labeling large volumes of ophthalmic images across various\nmodalities encounters several real-world challenges, especially for rare\ndiseases. Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and\nevaluate its applicability in diagnosing common and rare diseases. EyeDiff is\ntrained on eight large-scale datasets using the advanced latent diffusion\nmodel, covering 14 ophthalmic image modalities and over 80 ocular diseases, and\nis adapted to ten multi-country external datasets. The generated images\naccurately capture essential lesional characteristics, achieving high alignment\nwith text prompts as evaluated by objective metrics and human experts.\nFurthermore, integrating generated images significantly enhances the accuracy\nof detecting minority classes and rare eye diseases, surpassing traditional\noversampling methods in addressing data imbalance. EyeDiff effectively tackles\nthe issue of data imbalance and insufficiency typically encountered in rare\ndiseases and addresses the challenges of collecting large-scale annotated\nimages, offering a transformative solution to enhance the development of\nexpert-level diseases diagnosis models in ophthalmic field.",
    "explanation":"Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and evaluate its\napplicability in diagnosing common and rare diseases.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Artificial Intelligence for Pediatric Ophthalmology"
    ],
    "b_abstract":[
      "PURPOSE OF REVIEW: Despite the impressive results of recent artificial\nintelligence (AI) applications to general ophthalmology, comparatively less\nprogress has been made toward solving problems in pediatric ophthalmology using\nsimilar techniques. This article discusses the unique needs of pediatric\nophthalmology patients and how AI techniques can address these challenges,\nsurveys recent applications of AI to pediatric ophthalmology, and discusses\nfuture directions in the field.\n  RECENT FINDINGS: The most significant advances involve the automated\ndetection of retinopathy of prematurity (ROP), yielding results that rival\nexperts. Machine learning (ML) has also been successfully applied to the\nclassification of pediatric cataracts, prediction of post-operative\ncomplications following cataract surgery, detection of strabismus and\nrefractive error, prediction of future high myopia, and diagnosis of reading\ndisability via eye tracking. In addition, ML techniques have been used for the\nstudy of visual development, vessel segmentation in pediatric fundus images,\nand ophthalmic image synthesis.\n  SUMMARY: AI applications could significantly benefit clinical care for\npediatric ophthalmology patients by optimizing disease detection and grading,\nbroadening access to care, furthering scientific discovery, and improving\nclinical efficiency. These methods need to match or surpass physician\nperformance in clinical trials before deployment with patients. Due to\nwidespread use of closed-access data sets and software implementations, it is\ndifficult to directly compare the performance of these approaches, and\nreproducibility is poor. Open-access data sets and software implementations\ncould alleviate these issues, and encourage further AI applications to\npediatric ophthalmology.\n  KEYWORDS: pediatric ophthalmology, machine learning, artificial intelligence,\ndeep learning"
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.03661"
    ],
    "c_title":[
      "Bridging high resolution sub-cellular imaging with physiologically\n  relevant engineered tissues"
    ],
    "c_abstract":[
      "While high-resolution microscopic techniques are crucial for studying\ncellular structures in cell biology, obtaining such images from thick 3D\nengineered tissues remains challenging. In this review, we explore advancements\nin fluorescence microscopy, alongside the use of various fluorescent probes and\nmaterial processing techniques to address these challenges. We navigate through\nthe diverse array of imaging options available in tissue engineering field,\nfrom wide field to super-resolution microscopy, so researchers can make more\ninformed decisions based on the specific tissue and cellular structures of\ninterest. Finally, we provide some recent examples of how traditional\nlimitations on obtaining high-resolution images on sub-cellular architecture\nwithin 3D tissues have been overcome by combining imaging advancements with\ninnovative tissue engineering approaches."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.10004",
    "a_title":"EyeDiff: text-to-image diffusion model improves rare eye disease\n  diagnosis",
    "a_abstract":"The rising prevalence of vision-threatening retinal diseases poses a\nsignificant burden on the global healthcare systems. Deep learning (DL) offers\na promising solution for automatic disease screening but demands substantial\ndata. Collecting and labeling large volumes of ophthalmic images across various\nmodalities encounters several real-world challenges, especially for rare\ndiseases. Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and\nevaluate its applicability in diagnosing common and rare diseases. EyeDiff is\ntrained on eight large-scale datasets using the advanced latent diffusion\nmodel, covering 14 ophthalmic image modalities and over 80 ocular diseases, and\nis adapted to ten multi-country external datasets. The generated images\naccurately capture essential lesional characteristics, achieving high alignment\nwith text prompts as evaluated by objective metrics and human experts.\nFurthermore, integrating generated images significantly enhances the accuracy\nof detecting minority classes and rare eye diseases, surpassing traditional\noversampling methods in addressing data imbalance. EyeDiff effectively tackles\nthe issue of data imbalance and insufficiency typically encountered in rare\ndiseases and addresses the challenges of collecting large-scale annotated\nimages, offering a transformative solution to enhance the development of\nexpert-level diseases diagnosis models in ophthalmic field.",
    "explanation":"Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and evaluate its\napplicability in diagnosing common and rare diseases.",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Classification of Retinal Diseases in Optical Coherence Tomography Images Using Artificial Intelligence and Firefly Algorithm"
    ],
    "b_abstract":[
      "In recent years, the number of studies for automatic diagnosis biomedical diseases has increased. Many these have used Deep Learning, which gives extremely good results but requires a vast amount data and computing load. If processor is insufficient quality, this takes time places an excessive load on processor. On other hand, Machine Learning faster than does not much-needed load, it provide as high accuracy value Learning. Therefore, our goal to develop hybrid system that provides value, while requiring smaller less diagnose such retinal we chose study. For purpose, first, layer extraction was conducted through image preprocessing. Then, traditional feature extractors were combined with pre-trained extractors. To select best features, Firefly algorithm. end, multiple binary classifications instead multiclass classification classifiers. Two public datasets in The first dataset had mean 0.957, second 0.954."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.10197"
    ],
    "c_title":[
      "MathConstruct: Challenging LLM Reasoning with Constructive Proofs"
    ],
    "c_abstract":[
      "While Large Language Models (LLMs) demonstrate impressive performance in\nmathematics, existing math benchmarks come with significant limitations. Many\nfocus on problems with fixed ground-truth answers, and are often saturated due\nto problem simplicity or the viability of guessing or memorization. Crucially,\nthey capture only a narrow subset of relevant math problems. To address this\nresearch gap, we introduce \\mc, a new benchmark of 126 challenging problems\nsourced from various math competitions, which targets constructive proofs, a\nwidely encountered problem type requiring the construction of mathematical\nobjects with specific properties. These proofs are particularly suitable for\nLLM evaluation, as solution correctness can be easily verified. Our automated\nverifiers also enable MathConstruct to generate problem variations, used to\nevaluate robustness. State-of-the-art LLMs solve only 54% of MathConstruct\nproblems, highlighting its complexity and importance for LLM evaluation."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.01375",
    "a_title":"Scaling Laws with Hidden Structure",
    "a_abstract":"Statistical learning in high-dimensional spaces is challenging without a\nstrong underlying data structure. Recent advances with foundational models\nsuggest that text and image data contain such hidden structures, which help\nmitigate the curse of dimensionality. Inspired by results from nonparametric\nstatistics, we hypothesize that this phenomenon can be partially explained in\nterms of decomposition of complex tasks into simpler subtasks. In this paper,\nwe present a controlled experimental framework to test whether neural networks\ncan indeed exploit such ``hidden factorial structures.'' We find that they do\nleverage these latent patterns to learn discrete distributions more\nefficiently, and derive scaling laws linking model sizes, hidden\nfactorizations, and accuracy. We also study the interplay between our\nstructural assumptions and the models' capacity for generalization.",
    "explanation":"The key references I chose in Task 3 combined the concepts of Neural Networks with Discrete Distribution Theory to support this IDR paper. In the abstract, the following lines describe the integration of those selected references:\n\"In this paper, we present a controlled experimental framework to test whether neural networks can indeed exploit such \u201chidden factorial structures.\u201d\n\"We find that they do leverage these latent patterns to learn discrete distributions more efficiently. \"\n\n",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Learning Parities with Neural Networks"
    ],
    "b_abstract":[
      "In recent years we see a rapidly growing line of research which shows learnability various models via common neural network algorithms. Yet, besides very few outliers, these results show that can be learned using linear methods. Namely, such learning neural-networks with gradient-descent is competitive classifier on top data-independent representation the examples. This leaves much to desired, as networks are far more successful than Furthermore, conceptual level, don't seem capture deepness deep networks. this paper make step towards showing leanability inherently non-linear. We under certain distributions, sparse parities learnable gradient decent depth-two network. On other hand, same cannot efficiently by"
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.05908"
    ],
    "c_title":[
      "MCMC for multi-modal distributions"
    ],
    "c_abstract":[
      "We explain the fundamental challenges of sampling from multimodal\ndistributions, particularly for high-dimensional problems. We present the major\ntypes of MCMC algorithms that are designed for this purpose, including parallel\ntempering, mode jumping and Wang-Landau, as well as several state-of-the-art\napproaches that have recently been proposed. We demonstrate these methods using\nboth synthetic and real-world examples of multimodal distributions with\ndiscrete or continuous state spaces."
    ],
    "c_categories":[
      "stat.CO"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.01375",
    "a_title":"Scaling Laws with Hidden Structure",
    "a_abstract":"Statistical learning in high-dimensional spaces is challenging without a\nstrong underlying data structure. Recent advances with foundational models\nsuggest that text and image data contain such hidden structures, which help\nmitigate the curse of dimensionality. Inspired by results from nonparametric\nstatistics, we hypothesize that this phenomenon can be partially explained in\nterms of decomposition of complex tasks into simpler subtasks. In this paper,\nwe present a controlled experimental framework to test whether neural networks\ncan indeed exploit such ``hidden factorial structures.'' We find that they do\nleverage these latent patterns to learn discrete distributions more\nefficiently, and derive scaling laws linking model sizes, hidden\nfactorizations, and accuracy. We also study the interplay between our\nstructural assumptions and the models' capacity for generalization.",
    "explanation":"The key references I chose in Task 3 combined the concepts of Neural Networks with Discrete Distribution Theory to support this IDR paper. In the abstract, the following lines describe the integration of those selected references:\n\"In this paper, we present a controlled experimental framework to test whether neural networks can indeed exploit such \u201chidden factorial structures.\u201d\n\"We find that they do leverage these latent patterns to learn discrete distributions more efficiently. \"\n\n",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Testing conditional independence of discrete distributions"
    ],
    "b_abstract":[
      "We study the problem of testing *conditional independence* for discrete distributions. Specifically, given samples from a random variable (X, Y, Z) on domain [\u21131]\u00d7[\u21132] \u00d7 [n], we want to distinguish, with probability at least 2\/3, between case that X and Y are conditionally independent Z is \u0454-far, in \u21131-distance, every distribution has this property. Conditional independence concept central importance statistics important applications various scientific domains. As such, statistical task conditional been extensively studied forms within econometrics community nearly century. Perhaps surprisingly, not previously considered framework property particular no tester *sublinear* sample complexity known, even special domains binary."
    ],
    "b_categories":[
      "stat.CO"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2502.12555"
    ],
    "c_title":[
      "Warm Starting of CMA-ES for Contextual Optimization Problems"
    ],
    "c_abstract":[
      "Several practical applications of evolutionary computation possess objective\nfunctions that receive the design variables and externally given parameters.\nSuch problems are termed contextual optimization problems. These problems\nrequire finding the optimal solutions corresponding to the given context\nvectors. Existing contextual optimization methods train a policy model to\npredict the optimal solution from context vectors. However, the performance of\nsuch models is limited by their representation ability. By contrast, warm\nstarting methods have been used to initialize evolutionary algorithms on a\ngiven problem using the optimization results on similar problems. Because warm\nstarting methods do not consider the context vectors, their performances can be\nimproved on contextual optimization problems. Herein, we propose a covariance\nmatrix adaptation evolution strategy with contextual warm starting (CMA-ES-CWS)\nto efficiently optimize the contextual optimization problem with a given\ncontext vector. The CMA-ES-CWS utilizes the optimization results of past\ncontext vectors to train the multivariate Gaussian process regression.\nSubsequently, the CMA-ES-CWS performs warm starting for a given context vector\nby initializing the search distribution using posterior distribution of the\nGaussian process regression. The results of the numerical simulation suggest\nthat CMA-ES-CWS outperforms the existing contextual optimization and warm\nstarting methods."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2412.00544",
    "a_title":"RoBo6: Standardized MMT Light Curve Dataset for Rocket Body\n  Classification",
    "a_abstract":"Space debris presents a critical challenge for the sustainability of future\nspace missions, emphasizing the need for robust and standardized identification\nmethods. However, a comprehensive benchmark for rocket body classification\nremains absent. This paper addresses this gap by introducing the RoBo6 dataset\nfor rocket body classification based on light curves. The dataset, derived from\nthe Mini Mega Tortora database, includes light curves for six rocket body\nclasses: CZ-3B, Atlas 5 Centaur, Falcon 9, H-2A, Ariane 5, and Delta 4. With\n5,676 training and 1,404 test samples, it addresses data inconsistencies using\nresampling, normalization, and filtering techniques. Several machine learning\nmodels were evaluated, including CNN and transformer-based approaches, with\nAstroconformer reporting the best performance. The dataset establishes a common\nbenchmark for future comparisons and advancements in rocket body classification\ntasks.",
    "explanation":"The selected references in Task 3 were based from the following topics introduced in the abstract:\n\n\"Space debris presents a critical challenge for the sustainability of future space missions, emphasizing the need for robust and standardized identification methods.\"\n\"Several machine learning models were evaluated, including\nCNN and transformer-based approaches, with  Astroconformer reporting the best performance\"",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "Attention Is All You Need"
    ],
    "b_abstract":[
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. best performing also connect the encoder and decoder through attention mechanism. We propose a new simple network architecture, Transformer, solely mechanisms, dispensing with recurrence convolutions entirely. Experiments two machine translation tasks show these to be superior quality while being more parallelizable requiring significantly less time train. Our model achieves 28.4 BLEU WMT 2014 English-to-German task, improving over existing results, including ensembles by 2 BLEU. On English-to-French our establishes single-model state-of-the-art score of 41.8 after training for 3.5 days eight GPUs, small fraction costs from literature. that Transformer generalizes well other applying it successfully English constituency parsing both large limited data."
    ],
    "b_categories":[
      "cond-mat.dis-nn"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.19324"
    ],
    "c_title":[
      "Anisotropy signal of UHECRs from a structured magnetized Universe"
    ],
    "c_abstract":[
      "The surprising isotropy of the ultra-high-energy cosmic ray (UHECR) sky makes\nit difficult to identify their sources. Observables such as energy spectrum,\nmass composition and arrival directions are affected by interactions with\nbackground photon fields and by deflection in the extragalactic and galactic\nmagnetic fields (EGMF and GMF). In this work, we simulate the propagation of\nUHECRs with energy above 8 EeV in magnetized replicas of the local Universe,\nobtained from constrained simulations of the Large Scale Structure. We obtain\nthe real magnetic deflection in structured EGMF models with realistic\nthree-dimensional simulations. We investigate different scenarios for the UHECR\nsource distributions and densities. The effect of the GMF can be different\ndepending on the field model considered. In this work we consider the JF12\nmodel by mapping the arrival directions at the edge of the galaxy to those at\nEarth. We study the arrival direction distribution of the propagated UHECRs,\nand in particular their angular power spectrum, dipole and quadrupole moments.\nWe find that the properties of the source distribution affect the cosmic ray\nanisotropy more than the EGMF model considered. In particular, the low\nmultipole components depend on both the source distribution and the density. We\nalso find that it is difficult to simultaneously reproduce the observed dipole\nand quadrupole values above EeV. In general, we predict too large a quadrupole\nstrength, incompatible with observations."
    ],
    "c_categories":[
      "astro-ph.HE"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00544",
    "a_title":"RoBo6: Standardized MMT Light Curve Dataset for Rocket Body\n  Classification",
    "a_abstract":"Space debris presents a critical challenge for the sustainability of future\nspace missions, emphasizing the need for robust and standardized identification\nmethods. However, a comprehensive benchmark for rocket body classification\nremains absent. This paper addresses this gap by introducing the RoBo6 dataset\nfor rocket body classification based on light curves. The dataset, derived from\nthe Mini Mega Tortora database, includes light curves for six rocket body\nclasses: CZ-3B, Atlas 5 Centaur, Falcon 9, H-2A, Ariane 5, and Delta 4. With\n5,676 training and 1,404 test samples, it addresses data inconsistencies using\nresampling, normalization, and filtering techniques. Several machine learning\nmodels were evaluated, including CNN and transformer-based approaches, with\nAstroconformer reporting the best performance. The dataset establishes a common\nbenchmark for future comparisons and advancements in rocket body classification\ntasks.",
    "explanation":"The selected references in Task 3 were based from the following topics introduced in the abstract:\n\n\"Space debris presents a critical challenge for the sustainability of future space missions, emphasizing the need for robust and standardized identification methods.\"\n\"Several machine learning models were evaluated, including\nCNN and transformer-based approaches, with  Astroconformer reporting the best performance\"",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "Space objects classification via lightcurve measurements: deep convolutional neural networks and model-based transfer learning"
    ],
    "b_abstract":[
      "Developing a detailed understanding of the Space Object (SO) population is a fundamental goal of Space Situational Awareness (SSA). The current SO catalog includes simplified characteristic for the observed space objects, mainly the solar radiation pressure and\/or drag ballistic coefficients. Such simplified description limits the dynamic propagation model used for predicting the state of motion of SO to models that assume cannon ball shapes and generic surface properties. The future SO catalog and SSA systems will have to be capable of building a detailed picture of SO characteristics. Traditional measurement sources for SO tracking, such as radar and optical, provide information on SO characteristics. These measurements have been shown to be sensitive to shape, attitude, angular velocity, and surface parameters. State-of-the-art in the literature has been advanced over the past decades and in recent years seen the development of multiple models, nonlinear state estimation, and full Bayesian inversion approaches for SO characterization. The key shortcoming of approaches in literature is their overall computational cost and the limited flexibility to deal with a larger and larger amount of data. In this paper, we present a data-driven method to classification of SO based on a deep learning approach that takes advantage of the representational power of deep neural networks. Here, we design, train and validate a Convolutional Neural Network (CNN) capable of learning to classify SOs from collected light-curve measurements. The proposed methodology relies a physically-based model capable of accurately representing SO reflected light as function of time, size shape and state of motion. The model generates thousands of light-curves per selected class of SO which are employ to train a deep CNN to learn the functional relationship between light curves and SO class. Additionally, a deep CNN is trained using real SO light curves to evaluate the performance on a real, but limited training set. CNNs are compared with more conventional machine learning techniques (bagged trees, support vector machines) and are shown to outperform such methods especially when trained on real data. The concept of model-based transfer learning is proposed as possible path forward to increase the accuracy and speedup the training process."
    ],
    "b_categories":[
      "astro-ph.HE"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.16219"
    ],
    "c_title":[
      "Scaling of many-body localization transitions: Quantum dynamics in Fock\n  space and real space"
    ],
    "c_abstract":[
      "Many-body-localization (MBL) transitions are studied in a family of\nsingle-spin-flip spin-$\\frac12$ models, including the one-dimensional (1D)\nchain with nearest-neighbor interactions, the quantum dot (QD) model with\nall-to-all pair interactions, and the quantum random energy model (QREM). We\ninvestigate the generalized imbalance that characterizes propagation in Fock\nspace out of an initial basis state and, at the same time, can be efficiently\nprobed by real-space measurements. For all models considered, the average\nimbalance and its quantum and mesoscopic fluctuations provide excellent\nindicators for the position of the MBL transition $W_c(n)$, where $n$ is the\nnumber of spins. Combining these findings with earlier results on level\nstatistics, we determine phase diagrams of the MBL transitions in the $n$-$W$\nplane. Our results provide evidence for a direct transition between the ergodic\nand MBL phases for each of the models, without any intermediate phase. For QREM\nand QD model, $W_c(n)$ grows as a power law of $n$ (with logarithmic\ncorrections), in agreement with analytical predictions $W_c^{\\rm QREM}(n) \\sim\nn^{1\/2} \\ln n$ and $W_c^{\\rm QD}(n) \\gtrsim n^{3\/4} \\ln^{1\/2} n$. This growth\nis in stark contrast to the 1D model, where $W_c(n)$ is essentially independent\nof $n$, consistent with the analytic expectation $W_c^{\\rm 1D}(n\\to \\infty)=\n{\\rm const}$. We also determine the scaling of the transition width $\\Delta W\n(n) \/ W_c(n)$ and estimate the system size $n$ needed to study the asymptotic\nscaling behavior. While these values of $n$ are not accessible to exact\nsimulations on a classical computer, they are within the reach of quantum\nsimulators. Our results indicate feasibility of experimental studies of $n$-$W$\nphase diagrams and scaling properties of MBL transitions in models of 1D and QD\ntype and in their extensions to other spatial geometry or distance-dependent\ninteractions."
    ],
    "c_categories":[
      "cond-mat.dis-nn"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04840",
    "a_title":"Localized KBO with genetic dynamics for multi-modal optimization",
    "a_abstract":"In this paper, we introduce a novel approach to multi-modal optimization by\nenhancing the recently developed kinetic-based optimization (KBO) method with\ngenetic dynamics (GKBO). The proposed method targets objective functions with\nmultiple global minima, addressing a critical need in fields like engineering\ndesign, machine learning, and bioinformatics. By incorpo rating leader-follower\ndynamics and localized interactions, the algorithm efficiently navigates\nhigh-dimensional search spaces to detect multiple optimal solutions. After\nproviding a binary description, a mean-field approximation is derived, and\ndifferent numerical experiments are conducted to validate the results.",
    "explanation":"This IDR paper involves a combination of topics from different fields. In particular, I highlighted key references in Task 3 where topics in Genetics and the use of Data Structures and Algorithms come into play. Below are some sentences from the Abstract that reflect that:\n\n\"n this paper, we introduce a novel approach to multi-modal optimization by enhancing the recently developed kinetic-based optimization (KBO) method with genetic dynamics (GKBO)\"\n\" By incorporating leader-follower dynamics and localized interactions, the algorithm efficiently navigates high-dimensional search spaces to detect multiple optimal solution.\"",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Kinetic description and convergence analysis of genetic algorithms for global optimization"
    ],
    "b_abstract":[
      "Genetic Algorithms (GA) are a class of metaheuristic global optimization methods inspired by the process natural selection among individuals in population. Despite their widespread use, comprehensive theoretical analysis these remains challenging due to complexity heuristic mechanisms involved. In this work, relying on tools statistical physics, we take first step towards mathematical understanding GA showing how behavior for large number can be approximated through time-discrete kinetic model. This allows us prove convergence algorithm minimum under mild assumptions objective function popular choice mechanism. Furthermore, derive time-continuous model GA, represented Boltzmann-like partial differential equation, and establish relations with other mean-field dynamics optimization. Numerical experiments support validity proposed approximation investigate asymptotic configurations particle system different benchmark problems."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2503.02415"
    ],
    "c_title":[
      "On the sensitivity of CDAWG-grammars"
    ],
    "c_abstract":[
      "The compact directed acyclic word graphs (CDAWG) [Blumer et al. 1987] of a\nstring is the minimal compact automaton that recognizes all the suffixes of the\nstring. CDAWGs are known to be useful for various string tasks including text\npattern searching, data compression, and pattern discovery. The CDAWG-grammar\n[Belazzougui & Cunial 2017] is a grammar-based text compression based on the\nCDAWG. In this paper, we prove that the CDAWG-grammar size $g$ can increase by\nat most an additive factor of $4e + 4$ than the original after any\nsingle-character edit operation is performed on the input string, where $e$\ndenotes the number of edges in the corresponding CDAWG before the edit."
    ],
    "c_categories":[
      "cs.DS"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.04840",
    "a_title":"Localized KBO with genetic dynamics for multi-modal optimization",
    "a_abstract":"In this paper, we introduce a novel approach to multi-modal optimization by\nenhancing the recently developed kinetic-based optimization (KBO) method with\ngenetic dynamics (GKBO). The proposed method targets objective functions with\nmultiple global minima, addressing a critical need in fields like engineering\ndesign, machine learning, and bioinformatics. By incorpo rating leader-follower\ndynamics and localized interactions, the algorithm efficiently navigates\nhigh-dimensional search spaces to detect multiple optimal solutions. After\nproviding a binary description, a mean-field approximation is derived, and\ndifferent numerical experiments are conducted to validate the results.",
    "explanation":"This IDR paper involves a combination of topics from different fields. In particular, I highlighted key references in Task 3 where topics in Genetics and the use of Data Structures and Algorithms come into play. Below are some sentences from the Abstract that reflect that:\n\n\"n this paper, we introduce a novel approach to multi-modal optimization by enhancing the recently developed kinetic-based optimization (KBO) method with genetic dynamics (GKBO)\"\n\" By incorporating leader-follower dynamics and localized interactions, the algorithm efficiently navigates high-dimensional search spaces to detect multiple optimal solution.\"",
    "b_id":[
      "b25"
    ],
    "b_title":[
      "Genetic Algorithms + Data Structures = Evolution Programs"
    ],
    "b_abstract":[
      "Genetic algorithms are founded upon the principle of evolution, i.e., survival of the fittest. Hence evolution programming techniques, based on genetic algorithms, are applicable to many hard optimization problems, such as optimization of functions with linear and nonlinear constraints, the traveling salesman problem, and problems of scheduling, partitioning, and control. The importance of these techniques is still growing, since evolution programs are parallel in nature, and parallelism is one of the most promising directions in computer science. The book is self-contained and the only prerequisite is basic undergraduate mathematics. This third edition has been substantially revised and extended by three new chapters and by additional appendices containing working material to cover recent developments and a change in the perception of evolutionary computation."
    ],
    "b_categories":[
      "cs.DS"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.15419"
    ],
    "c_title":[
      "A primal-dual interior point trust region method for\n  inequality-constrained optimization problems on Riemannian manifolds"
    ],
    "c_abstract":[
      "We consider Riemannian inequality-constrained optimization problems and\npropose a Riemannian primal-dual interior point trust region method (RIPTRM)\nfor solving them. We prove its global convergence to an approximate\nKarush-Kuhn-Tucker point and a second-order stationary point. We also establish\nthe local near-quadratic convergence. To the best of our knowledge, this is the\nfirst algorithm that incorporates the trust region strategy and has the\nsecond-order convergence property for optimization problems on Riemannian\nmanifolds with nonlinear inequality constraints. It is also the first\nRiemannian interior point method that possesses both global and local\nconvergence properties. We conduct numerical experiments in which we introduce\na truncated conjugate gradient method and an eigenvalue-based subsolver for\nRIPTRM to approximately and exactly solve the trust region subproblems,\nrespectively. Empirical results show that RIPTRMs find solutions with higher\naccuracy compared to an existing Riemannian interior point method and other\nalgorithms. Additionally, we observe that RIPTRM with the exact search\ndirection shows significantly promising performance in an instance where the\nHessian of the Lagrangian has a large negative eigenvalue."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.17342",
    "a_title":"Automatic Skull Reconstruction by Deep Learnable Symmetry Enforcement",
    "a_abstract":"Every year, thousands of people suffer from skull damage and require\npersonalized implants to fill the cranial cavity. Unfortunately, the waiting\ntime for reconstruction surgery can extend to several weeks or even months,\nespecially in less developed countries. One factor contributing to the extended\nwaiting period is the intricate process of personalized implant modeling.\nCurrently, the preparation of these implants by experienced biomechanical\nexperts is both costly and time-consuming. Recent advances in artificial\nintelligence, especially in deep learning, offer promising potential for\nautomating the process. However, deep learning-based cranial reconstruction\nfaces several challenges: (i) the limited size of training datasets, (ii) the\nhigh resolution of the volumetric data, and (iii) significant data\nheterogeneity. In this work, we propose a novel approach to address these\nchallenges by enhancing the reconstruction through learnable symmetry\nenforcement. We demonstrate that it is possible to train a neural network\ndedicated to calculating skull symmetry, which can be utilized either as an\nadditional objective function during training or as a post-reconstruction\nobjective during the refinement step. We quantitatively evaluate the proposed\nmethod using open SkullBreak and SkullFix datasets, and qualitatively using\nreal clinical cases. The results indicate that the symmetry-preserving\nreconstruction network achieves considerably better outcomes compared to the\nbaseline (0.94\/0.94\/1.31 vs 0.84\/0.76\/2.43 in terms of DSC, bDSC, and HD95).\nMoreover, the results are comparable to the best-performing methods while\nrequiring significantly fewer computational resources (< 500 vs > 100,000 GPU\nhours). The proposed method is a considerable contribution to the field of\napplied artificial intelligence in medicine and is a step toward automatic\ncranial defect reconstruction in clinical practice.",
    "explanation":"This IDR paper is an applied research paper that focuses on combining Neural Networks to advance biomechanics. Below are some sentences in the abstract that reflect the references in Task 3:\n\n\"We demonstrate that it is possible to train a neural network dedicated to calculating skull symmetry,\"\n\n\"Every year, thousands of people suffer from skull damage and require personalized implants to fill the cranial cavity. Unfortunately, the waiting time for reconstruction surgery can extend to several weeks or even months, especially in less developed countries.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Reconstruction of cranial defect with patient-specific implants: Four different cost-effective techniques"
    ],
    "b_abstract":[
      "Cranial defects secondary to trauma, surgery or pathological causes, result in large cranial imperfection, which affects the appearance of patient as well results sinking flap syndrome. Rehabilitation such a defect can be done using prosthetic options like custom-made polymethyl methacrylate (PMMA) prosthesis surgical outer table calvarial graft segments. It is usually observed that conventional moulage impression defective site most difficult task. The accuracy affected by impression, cast and techniques fabricating wax pattern. Orthodox method mark tentative outline make site. However, this an arbitrary offers challenges accurate replication borders defect. Recently, medical imaging digital modeling dentistry have paved way for dental practice additive manufacturing replacing manual subtractive procedures. use computerized tomography scan obtain 3 D image replica with rapid prototyping has markedly improved at margin defect\/prosthesis interface, resulting better fit optimal contour lending itself esthetic outcome. more reliable implant prosthesis, requires minimum adjustment when on OT table. These case reports compare rehabilitation PMMA methods technique. seen expensive but gives"
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.05824"
    ],
    "c_title":[
      "Aerial Reliable Collaborative Communications for Terrestrial Mobile\n  Users via Evolutionary Multi-Objective Deep Reinforcement Learning"
    ],
    "c_abstract":[
      "Unmanned aerial vehicles (UAVs) have emerged as the potential aerial base\nstations (BSs) to improve terrestrial communications. However, the limited\nonboard energy and antenna power of a UAV restrict its communication range and\ntransmission capability. To address these limitations, this work employs\ncollaborative beamforming through a UAV-enabled virtual antenna array to\nimprove transmission performance from the UAV to terrestrial mobile users,\nunder interference from non-associated BSs and dynamic channel conditions.\nSpecifically, we introduce a memory-based random walk model to more accurately\ndepict the mobility patterns of terrestrial mobile users. Following this, we\nformulate a multi-objective optimization problem (MOP) focused on maximizing\nthe transmission rate while minimizing the flight energy consumption of the UAV\nswarm. Given the NP-hard nature of the formulated MOP and the highly dynamic\nenvironment, we transform this problem into a multi-objective Markov decision\nprocess and propose an improved evolutionary multi-objective reinforcement\nlearning algorithm. Specifically, this algorithm introduces an evolutionary\nlearning approach to obtain the approximate Pareto set for the formulated MOP.\nMoreover, the algorithm incorporates a long short-term memory network and\nhyper-sphere-based task selection method to discern the movement patterns of\nterrestrial mobile users and improve the diversity of the obtained Pareto set.\nSimulation results demonstrate that the proposed method effectively generates a\ndiverse range of non-dominated policies and outperforms existing methods.\nAdditional simulations demonstrate the scalability and robustness of the\nproposed CB-based method under different system parameters and various\nunexpected circumstances."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17342",
    "a_title":"Automatic Skull Reconstruction by Deep Learnable Symmetry Enforcement",
    "a_abstract":"Every year, thousands of people suffer from skull damage and require\npersonalized implants to fill the cranial cavity. Unfortunately, the waiting\ntime for reconstruction surgery can extend to several weeks or even months,\nespecially in less developed countries. One factor contributing to the extended\nwaiting period is the intricate process of personalized implant modeling.\nCurrently, the preparation of these implants by experienced biomechanical\nexperts is both costly and time-consuming. Recent advances in artificial\nintelligence, especially in deep learning, offer promising potential for\nautomating the process. However, deep learning-based cranial reconstruction\nfaces several challenges: (i) the limited size of training datasets, (ii) the\nhigh resolution of the volumetric data, and (iii) significant data\nheterogeneity. In this work, we propose a novel approach to address these\nchallenges by enhancing the reconstruction through learnable symmetry\nenforcement. We demonstrate that it is possible to train a neural network\ndedicated to calculating skull symmetry, which can be utilized either as an\nadditional objective function during training or as a post-reconstruction\nobjective during the refinement step. We quantitatively evaluate the proposed\nmethod using open SkullBreak and SkullFix datasets, and qualitatively using\nreal clinical cases. The results indicate that the symmetry-preserving\nreconstruction network achieves considerably better outcomes compared to the\nbaseline (0.94\/0.94\/1.31 vs 0.84\/0.76\/2.43 in terms of DSC, bDSC, and HD95).\nMoreover, the results are comparable to the best-performing methods while\nrequiring significantly fewer computational resources (< 500 vs > 100,000 GPU\nhours). The proposed method is a considerable contribution to the field of\napplied artificial intelligence in medicine and is a step toward automatic\ncranial defect reconstruction in clinical practice.",
    "explanation":"This IDR paper is an applied research paper that focuses on combining Neural Networks to advance biomechanics. Below are some sentences in the abstract that reflect the references in Task 3:\n\n\"We demonstrate that it is possible to train a neural network dedicated to calculating skull symmetry,\"\n\n\"Every year, thousands of people suffer from skull damage and require personalized implants to fill the cranial cavity. Unfortunately, the waiting time for reconstruction surgery can extend to several weeks or even months, especially in less developed countries.\"",
    "b_id":[
      "b35"
    ],
    "b_title":[
      "Deep learning-based framework for automatic cranial defect reconstruction and implant modeling"
    ],
    "b_abstract":[
      "This article presents a robust, fast, and fully automatic method for personalized cranial defect reconstruction implant modeling.We propose two-step deep learning-based using modified U-Net architecture to perform the reconstruction, dedicated iterative procedure improve geometry, followed by an generation of models ready 3-D printing. We cross-case augmentation based on imperfect image registration combining cases from different datasets. Additional ablation studies compare strategies other state-of-the-art methods.We evaluate three datasets introduced during AutoImplant 2021 challenge, organized jointly with MICCAI conference. quantitative evaluation Dice boundary coefficients, Hausdorff distance. The coefficient, 95th percentile distance averaged across all test sets, are 0.91, 0.94, 1.53 mm respectively. additional qualitative printing visualization in mixed reality confirm implant's usefulness.The proposes complete pipeline that enables one create model described is greatly extended version scored 1st place challenge tasks. freely release source code, which together open datasets, makes results reproducible. defects may enable manufacturing implants significantly shorter time, possibly allowing process directly given intervention. Moreover, we show usability further reduce surgery time."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.00197"
    ],
    "c_title":[
      "Unveiling sex dimorphism in the healthy cardiac anatomy: fundamental\n  differences between male and female heart shapes"
    ],
    "c_abstract":[
      "Sex-based differences in cardiovascular disease are well documented, yet the\nprecise nature and extent of these discrepancies in cardiac anatomy remain\nincompletely understood. Traditional scaling models often fail to capture the\ninterplay of age, blood pressure, and body size, prompting a more nuanced\ninvestigation. Here, we employ statistical shape modeling in a healthy subset\n(n=456) of the UK Biobank to explore sex-specific variations in biventricular\nanatomy. We reconstruct 3D meshes and perform multivariate analyses of shape\ncoefficients, controlling for age, blood pressure, and various body size\nmetrics. Our findings reveal that sex alone explains at least 25 percent of\nmorphological variability, with strong discrimination between men and women\n(AUC=0.96-0.71) persisting even after correction for confounders. Notably, the\nmost discriminative modes highlight pronounced differences in cardiac chamber\nvolumes, the anterior-posterior width of the right ventricle, and the relative\npositioning of the cardiac chambers. These results underscore that sex has a\nfundamental influence on cardiac morphology, which may have important clinical\nimplications for differing cardiac structural assessments in men and women.\nFuture work should investigate how these anatomical differences manifest in\nvarious cardiovascular conditions, ultimately paving the way for more precise\nrisk stratification and personalized therapeutic strategies for both men and\nwomen."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04747",
    "a_title":"Equivariant Graph Attention Networks with Structural Motifs for\n  Predicting Cell Line-Specific Synergistic Drug Combinations",
    "a_abstract":"Cancer is the second leading cause of death, with chemotherapy as one of the\nprimary forms of treatment. As a result, researchers are turning to drug\ncombination therapy to decrease drug resistance and increase efficacy. Current\nmethods of drug combination screening, such as in vivo and in vitro, are\ninefficient due to stark time and monetary costs. In silico methods have become\nincreasingly important for screening drugs, but current methods are inaccurate\nand generalize poorly to unseen anticancer drugs. In this paper, I employ a\ngeometric deep-learning model utilizing a graph attention network that is\nequivariant to 3D rotations, translations, and reflections with structural\nmotifs. Additionally, the gene expression of cancer cell lines is utilized to\nclassify synergistic drug combinations specific to each cell line. I compared\nthe proposed geometric deep learning framework to current state-of-the-art\n(SOTA) methods, and the proposed model architecture achieved greater\nperformance on all 12 benchmark tasks performed on the DrugComb dataset.\nSpecifically, the proposed framework outperformed other SOTA methods by an\naccuracy difference greater than 28%. Based on these results, I believe that\nthe equivariant graph attention network's capability of learning geometric data\naccounts for the large performance improvements. The model's ability to\ngeneralize to foreign drugs is thought to be due to the structural motifs\nproviding a better representation of the molecule. Overall, I believe that the\nproposed equivariant geometric deep learning framework serves as an effective\ntool for virtually screening anticancer drug combinations for further\nvalidation in a wet lab environment. The code for this work is made available\nonline at: https:\/\/github.com\/WeToTheMoon\/EGAT_DrugSynergy.",
    "explanation":"From the key references cited in Task 3, below are some sentences that point to the significance of those references that show how this paper is an IDR.\n\n\"Additionally, the gene expression of cancer cell lines is utilized to classify synergistic drug combinations specificto each cell line. \"\n\"I compared the proposed geometric deep learning\nframework to current state-of-the-art (SOTA) methods\"\n\"Based on these results, I believe that the equivariant graph attention network\u2019s capability of learning geometric data accounts for the large performance improvements.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Trends in Phase II Trials for Cancer Therapies"
    ],
    "b_abstract":[
      "Background: Drug combinations are the standard of care in cancer treatment. Identifying effective drug has become more challenging because increasing number drugs. However, a substantial drugs stumble at Phase III clinical trials despite exhibiting favourable efficacy earlier Phase. Methods: We analysed recent II comprising 2165 response rates to uncover trends therapies and used null model non-interacting agents infer synergistic antagonistic combinations. compared our latest dataset with previous assess progress therapy. Results: Targeted reach higher when combination cytotoxic identify four 10 based on observed expected rates. demonstrate that targeted have not significantly increased Conclusions: conclude either we making or rate measured by tumour shrinkage is reliable surrogate endpoint for agents."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.09976"
    ],
    "c_title":[
      "Dendritic Localized Learning: Toward Biologically Plausible Algorithm"
    ],
    "c_abstract":[
      "Backpropagation is the foundational algorithm for training neural networks\nand a key driver of deep learning's success. However, its biological\nplausibility has been challenged due to three primary limitations: weight\nsymmetry, reliance on global error signals, and the dual-phase nature of\ntraining, as highlighted by the existing literature. Although various\nalternative learning approaches have been proposed to address these issues,\nmost either fail to satisfy all three criteria simultaneously or yield\nsuboptimal results. Inspired by the dynamics and plasticity of pyramidal\nneurons, we propose Dendritic Localized Learning (DLL), a novel learning\nalgorithm designed to overcome these challenges. Extensive empirical\nexperiments demonstrate that DLL satisfies all three criteria of biological\nplausibility while achieving state-of-the-art performance among algorithms that\nmeet these requirements. Furthermore, DLL exhibits strong generalization across\na range of architectures, including MLPs, CNNs, and RNNs. These results,\nbenchmarked against existing biologically plausible learning algorithms, offer\nvaluable empirical insights for future research. We hope this study can inspire\nthe development of new biologically plausible algorithms for training\nmultilayer networks and advancing progress in both neuroscience and machine\nlearning."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04747",
    "a_title":"Equivariant Graph Attention Networks with Structural Motifs for\n  Predicting Cell Line-Specific Synergistic Drug Combinations",
    "a_abstract":"Cancer is the second leading cause of death, with chemotherapy as one of the\nprimary forms of treatment. As a result, researchers are turning to drug\ncombination therapy to decrease drug resistance and increase efficacy. Current\nmethods of drug combination screening, such as in vivo and in vitro, are\ninefficient due to stark time and monetary costs. In silico methods have become\nincreasingly important for screening drugs, but current methods are inaccurate\nand generalize poorly to unseen anticancer drugs. In this paper, I employ a\ngeometric deep-learning model utilizing a graph attention network that is\nequivariant to 3D rotations, translations, and reflections with structural\nmotifs. Additionally, the gene expression of cancer cell lines is utilized to\nclassify synergistic drug combinations specific to each cell line. I compared\nthe proposed geometric deep learning framework to current state-of-the-art\n(SOTA) methods, and the proposed model architecture achieved greater\nperformance on all 12 benchmark tasks performed on the DrugComb dataset.\nSpecifically, the proposed framework outperformed other SOTA methods by an\naccuracy difference greater than 28%. Based on these results, I believe that\nthe equivariant graph attention network's capability of learning geometric data\naccounts for the large performance improvements. The model's ability to\ngeneralize to foreign drugs is thought to be due to the structural motifs\nproviding a better representation of the molecule. Overall, I believe that the\nproposed equivariant geometric deep learning framework serves as an effective\ntool for virtually screening anticancer drug combinations for further\nvalidation in a wet lab environment. The code for this work is made available\nonline at: https:\/\/github.com\/WeToTheMoon\/EGAT_DrugSynergy.",
    "explanation":"From the key references cited in Task 3, below are some sentences that point to the significance of those references that show how this paper is an IDR.\n\n\"Additionally, the gene expression of cancer cell lines is utilized to classify synergistic drug combinations specificto each cell line. \"\n\"I compared the proposed geometric deep learning\nframework to current state-of-the-art (SOTA) methods\"\n\"Based on these results, I believe that the equivariant graph attention network\u2019s capability of learning geometric data accounts for the large performance improvements.\"",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "E(n) Equivariant Graph Neural Networks"
    ],
    "b_abstract":[
      "This paper introduces a new model to learn graph neural networks equivariant rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. addition, whereas methods are limited equivariance on 3 dimensional spaces, is easily scaled higher-dimensional spaces. We demonstrate the effectiveness of method dynamical systems modelling, representation learning autoencoders predicting molecular properties."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.18947"
    ],
    "c_title":[
      "Trait-structured chemotaxis: Exploring ligand-receptor dynamics and\n  travelling wave properties in a Keller-Segel model"
    ],
    "c_abstract":[
      "A novel trait-structured Keller-Segel model that explores the dynamics of a\nmigrating cell population guided by chemotaxis in response to an external\nligand concentration is derived and analysed. Unlike traditional Keller-Segel\nmodels, this framework introduces an explicit representation of ligand-receptor\nbindings on the cell membrane, where the percentage of occupied receptors\nconstitutes the trait that influences cellular phenotype. The model posits that\nthe cell's phenotypic state directly modulates its capacity for chemotaxis and\nproliferation, governed by a trade-off due to a finite energy budget: cells\nhighly proficient in chemotaxis exhibit lower proliferation rates, while more\nproliferative cells show diminished chemotactic abilities. The model is derived\nfrom the principles of a biased random walk, resulting in a system of two\nnon-local partial differential equations, describing the densities of both\ncells and ligands. Using a Hopf-Cole transformation, we derive an equation that\ncharacterises the distribution of cellular traits within travelling wave\nsolutions for the total cell density, allowing us to uncover the monotonicity\nproperties of these waves. Numerical investigations are conducted to examine\nthe model's behaviour across various biological scenarios, providing insights\ninto the complex interplay between chemotaxis, proliferation, and phenotypic\ndiversity in migrating cell populations."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00319",
    "a_title":"Improving speaker verification robustness with synthetic emotional\n  utterances",
    "a_abstract":"A speaker verification (SV) system offers an authentication service designed\nto confirm whether a given speech sample originates from a specific speaker.\nThis technology has paved the way for various personalized applications that\ncater to individual preferences. A noteworthy challenge faced by SV systems is\ntheir ability to perform consistently across a range of emotional spectra. Most\nexisting models exhibit high error rates when dealing with emotional utterances\ncompared to neutral ones. Consequently, this phenomenon often leads to missing\nout on speech of interest. This issue primarily stems from the limited\navailability of labeled emotional speech data, impeding the development of\nrobust speaker representations that encompass diverse emotional states.\n  To address this concern, we propose a novel approach employing the CycleGAN\nframework to serve as a data augmentation method. This technique synthesizes\nemotional speech segments for each specific speaker while preserving the unique\nvocal identity. Our experimental findings underscore the effectiveness of\nincorporating synthetic emotional data into the training process. The models\ntrained using this augmented dataset consistently outperform the baseline\nmodels on the task of verifying speakers in emotional speech scenarios,\nreducing equal error rate by as much as 3.64% relative.",
    "explanation":"A speaker verification (SV) system offers an authentication ser-\nvice designed to confirm whether a given speech sample orig-\ninates from a specific speaker. To address this concern, we propose a novel\napproach employing the CycleGAN framework to serve as a\ndata augmentation method. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Human-Centric Interfaces for Ambient Intelligence"
    ],
    "b_abstract":[
      "To create truly effective human-centric ambient intelligence systems both engineering and computing methods are needed. This is the first book to bridge data processing and intelligent reasoning methods for the creation of human-centered ambient intelligence systems. Interdisciplinary in nature, the book covers topics such as multi-modal interfaces, human-computer interaction, smart environments and pervasive computing, addressing principles, paradigms, methods and applications. This book will be an ideal reference for university researchers, R&amp;D engineers, computer engineers, and graduate students working in signal, speech and video processing, multi-modal interfaces, human-computer interaction and applications of ambient intelligence."
    ],
    "b_categories":[
      "physics.app-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.15762"
    ],
    "c_title":[
      "Dialogic Learning in Child-Robot Interaction: A Hybrid Approach to\n  Personalized Educational Content Generation"
    ],
    "c_abstract":[
      "Dialogic learning fosters motivation and deeper understanding in education\nthrough purposeful and structured dialogues. Foundational models offer a\ntransformative potential for child-robot interactions, enabling the design of\npersonalized, engaging, and scalable interactions. However, their integration\ninto educational contexts presents challenges in terms of ensuring\nage-appropriate and safe content and alignment with pedagogical goals. We\nintroduce a hybrid approach to designing personalized educational dialogues in\nchild-robot interactions. By combining rule-based systems with LLMs for\nselective offline content generation and human validation, the framework\nensures educational quality and developmental appropriateness. We illustrate\nthis approach through a project aimed at enhancing reading motivation, in which\na robot facilitated book-related dialogues."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00319",
    "a_title":"Improving speaker verification robustness with synthetic emotional\n  utterances",
    "a_abstract":"A speaker verification (SV) system offers an authentication service designed\nto confirm whether a given speech sample originates from a specific speaker.\nThis technology has paved the way for various personalized applications that\ncater to individual preferences. A noteworthy challenge faced by SV systems is\ntheir ability to perform consistently across a range of emotional spectra. Most\nexisting models exhibit high error rates when dealing with emotional utterances\ncompared to neutral ones. Consequently, this phenomenon often leads to missing\nout on speech of interest. This issue primarily stems from the limited\navailability of labeled emotional speech data, impeding the development of\nrobust speaker representations that encompass diverse emotional states.\n  To address this concern, we propose a novel approach employing the CycleGAN\nframework to serve as a data augmentation method. This technique synthesizes\nemotional speech segments for each specific speaker while preserving the unique\nvocal identity. Our experimental findings underscore the effectiveness of\nincorporating synthetic emotional data into the training process. The models\ntrained using this augmented dataset consistently outperform the baseline\nmodels on the task of verifying speakers in emotional speech scenarios,\nreducing equal error rate by as much as 3.64% relative.",
    "explanation":"A speaker verification (SV) system offers an authentication ser-\nvice designed to confirm whether a given speech sample orig-\ninates from a specific speaker. To address this concern, we propose a novel\napproach employing the CycleGAN framework to serve as a\ndata augmentation method. ",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Speaker Diarization with LSTM"
    ],
    "b_abstract":[
      "For many years, i-vector based audio embedding techniques were the dominant approach for speaker verification and diarization applications. However, mirroring rise of deep learning in various domains, neural network embeddings, also known as <i xmlns:mml=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" xmlns:xlink=\"http:\/\/www.w3.org\/1999\/xlink\">d-vectors<\/i> , have consistently demonstrated superior performance. In this paper, we build on success d-vector systems to develop a new diarization. Specifically, combine LSTM-based embeddings with recent work non-parametric clustering obtain state-of-the-art system. Our system is evaluated three standard public datasets, suggesting that offer significant advantages over traditional systems. We achieved 12.0% error rate NIST SRE 2000 CALLHOME, while our model trained out-of-domain data from voice search logs."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.07723"
    ],
    "c_title":[
      "Total acoustic transmission between fluids using a solid material with\n  emphasis on the air-water interface"
    ],
    "c_abstract":[
      "Total acoustic transmission between water and air is modeled using a purely\nsolid interface comprising two elastic plates separated by periodically spaced\nribs. The frequency of full transmission depends only on, and is inversely\nproportional to, the areal density of the plate facing the air. Total\ntransmission also requires a specific dependence of the rib spacing on the\nbending stiffness of the two plates. These relations are the result of an\nexplicit analytical solution for the transmitted and reflected acoustic waves\ncombined with asymptotic approximations based on the small parameter defined by\nthe air-to-water impedance ratio. Surprisingly, the total transmission effect\nis almost independent of the angle of incidence, even though the transmission\nconditions are predicated on normal incidence. Parametric studies are performed\nto examine the effect on the frequency bandwidth and Q-factor of the acoustic\ntransmissivity. A lower bound for the Q-factor of $30.6$ is simply related to\nthe water-air impedance ratio."
    ],
    "c_categories":[
      "physics.app-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00173",
    "a_title":"Spatial Clustering of Molecular Localizations with Graph Neural Networks",
    "a_abstract":"Single-molecule localization microscopy generates point clouds corresponding\nto fluorophore localizations. Spatial cluster identification and analysis of\nthese point clouds are crucial for extracting insights about molecular\norganization. However, this task becomes challenging in the presence of\nlocalization noise, high point density, or complex biological structures. Here,\nwe introduce MIRO (Multimodal Integration through Relational Optimization), an\nalgorithm that uses recurrent graph neural networks to transform the point\nclouds in order to improve clustering efficiency when applying conventional\nclustering techniques. We show that MIRO supports simultaneous processing of\nclusters of different shapes and at multiple scales, demonstrating improved\nperformance across varied datasets. Our comprehensive evaluation demonstrates\nMIRO's transformative potential for single-molecule localization applications,\nshowcasing its capability to revolutionize cluster analysis and provide\naccurate, reliable details of molecular architecture. In addition, MIRO's\nrobust clustering capabilities hold promise for applications in various fields\nsuch as neuroscience, for the analysis of neural connectivity patterns, and\nenvironmental science, for studying spatial distributions of ecological data.",
    "explanation":"Single-molecule localization microscopy generates point clouds corresponding to\nfluorophore localizations.  Here, we introduce MIRO (Mul-\ntimodal Integration through Relational Optimization), an algorithm that uses\nrecurrent graph neural networks to transform the point clouds in order to improve\nclustering efficiency when applying conventional clustering techniques.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Turning single-molecule localization microscopy into a quantitative bioanalytical tool"
    ],
    "b_abstract":[
      "Single-molecule localization microscopy (SMLM) generates super-resolution images by serially detecting individual fluorescent molecules. The power of SMLM, however, goes beyond images: biologically relevant information can be extracted from the mathematical relationships between the positions of the fluorophores in space and time. Here we review the history of SMLM and how recent progress in methods for spatial point analysis has enabled quantitative measurement of SMLM data, providing insights into biomolecule patterning, clustering and oligomerization in biological systems."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.20927"
    ],
    "c_title":[
      "Goal-Oriented Semantic Communication for Wireless Video Transmission via\n  Generative AI"
    ],
    "c_abstract":[
      "Efficient video transmission is essential for seamless communication and\ncollaboration within the visually-driven digital landscape. To achieve low\nlatency and high-quality video transmission over a bandwidth-constrained noisy\nwireless channel, we propose a stable diffusion (SD)-based goal-oriented\nsemantic communication (GSC) framework. In this framework, we first design a\nsemantic encoder that effectively identify the keyframes from video and extract\nthe relevant semantic information (SI) to reduce the transmission data size. We\nthen develop a semantic decoder to reconstruct the keyframes from the received\nSI and further generate the full video from the reconstructed keyframes using\nframe interpolation to ensure high-quality reconstruction. Recognizing the\nimpact of wireless channel noise on SI transmission, we also propose an\nSD-based denoiser for GSC (SD-GSC) condition on an instantaneous channel gain\nto remove the channel noise from the received noisy SI under a known channel.\nFor scenarios with an unknown channel, we further propose a parallel SD\ndenoiser for GSC (PSD-GSC) to jointly learn the distribution of channel gains\nand denoise the received SI. It is shown that, with the known channel, our\nproposed SD-GSC outperforms state-of-the-art ADJSCC, Latent-Diff DNSC, DeepWiVe\nand DVST, improving Peak Signal-to-Noise Ratio (PSNR) by 69%, 58%, 33% and 38%,\nreducing mean squared error (MSE) by 52%, 50%, 41% and 45%, and reducing\nFr\\'echet Video Distance (FVD) by 38%, 32%, 22% and 24%, respectively. With the\nunknown channel, our PSD-GSC achieves a 17% improvement in PSNR, a 29%\nreduction in MSE, and a 19% reduction in FVD compared to MMSE\nequalizer-enhanced SD-GSC. These significant performance improvements\ndemonstrate the robustness and superiority of our proposed methods in enhancing\nvideo transmission quality and efficiency under various channel conditions."
    ],
    "c_categories":[
      "eess.IV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00173",
    "a_title":"Spatial Clustering of Molecular Localizations with Graph Neural Networks",
    "a_abstract":"Single-molecule localization microscopy generates point clouds corresponding\nto fluorophore localizations. Spatial cluster identification and analysis of\nthese point clouds are crucial for extracting insights about molecular\norganization. However, this task becomes challenging in the presence of\nlocalization noise, high point density, or complex biological structures. Here,\nwe introduce MIRO (Multimodal Integration through Relational Optimization), an\nalgorithm that uses recurrent graph neural networks to transform the point\nclouds in order to improve clustering efficiency when applying conventional\nclustering techniques. We show that MIRO supports simultaneous processing of\nclusters of different shapes and at multiple scales, demonstrating improved\nperformance across varied datasets. Our comprehensive evaluation demonstrates\nMIRO's transformative potential for single-molecule localization applications,\nshowcasing its capability to revolutionize cluster analysis and provide\naccurate, reliable details of molecular architecture. In addition, MIRO's\nrobust clustering capabilities hold promise for applications in various fields\nsuch as neuroscience, for the analysis of neural connectivity patterns, and\nenvironmental science, for studying spatial distributions of ecological data.",
    "explanation":"Single-molecule localization microscopy generates point clouds corresponding to\nfluorophore localizations.  Here, we introduce MIRO (Mul-\ntimodal Integration through Relational Optimization), an algorithm that uses\nrecurrent graph neural networks to transform the point clouds in order to improve\nclustering efficiency when applying conventional clustering techniques.",
    "b_id":[
      "b22"
    ],
    "b_title":[
      "A framework for evaluating the performance of SMLM cluster analysis algorithms"
    ],
    "b_abstract":[
      "This analysis compares the performance of seven algorithms for cluster analysis of single-molecule localization microscopy data. The results provide a framework for comparing these types of methods and point users to the best tools. Single-molecule localization microscopy (SMLM) generates data in the form of coordinates of localized fluorophores. Cluster analysis is an attractive route for extracting biologically meaningful information from such data and has been widely applied. Despite a range of cluster analysis algorithms, there exists no consensus framework for the evaluation of their performance. Here, we use a systematic approach based on two metrics to score the success of clustering algorithms in simulated conditions mimicking experimental data. We demonstrate the framework using seven diverse analysis algorithms: DBSCAN, ToMATo, KDE, FOCAL, CAML, ClusterViSu and SR-Tesseler. Given that the best performer depended on the underlying distribution of localizations, we demonstrate an analysis pipeline based on statistical similarity measures that enables the selection of the most appropriate algorithm, and the optimized analysis parameters for real SMLM data. We propose that these standard simulated conditions, metrics and analysis pipeline become the basis for future analysis algorithm development and evaluation."
    ],
    "b_categories":[
      "eess.IV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04258"
    ],
    "c_title":[
      "How Large is the Universe of RNA-Like Motifs? A Clustering Analysis of\n  RNA Graph Motifs Using Topological Descriptors"
    ],
    "c_abstract":[
      "We introduce a computational topology-based approach with unsupervised\nmachine-learning algorithms to estimate the database size and content of\nRNA-like graph topologies. Specifically, we apply graph theory enumeration to\ngenerate all 110,667 possible 2D dual graphs for vertex numbers ranging from 2\nto 9. Among them, only 0.11% graphs correspond to approximately 200,000 known\nRNA atomic fragments (collected in 2021) using the RNA-as-Graphs (RAG) mapping\nmethod. The remaining 99.89% of the dual graphs may be RNA-like or\nnon-RNA-like. To determine which dual graphs in the 99.89% hypothetical set are\nmore likely to be associated with RNA structures, we apply computational\ntopology descriptors using the Persistent Spectral Graphs (PSG) method to\ncharacterize each graph using 19 PSG-based features and use clustering\nalgorithms that partition all possible dual graphs into two clusters, RNA-like\ncluster and non-RNA-like cluster. The distance of each dual graph to the center\nof the RNA-like cluster represents the likelihood of it belonging to RNA\nstructures. From validation, our PSG-based RNA-like cluster includes 97.3% of\nthe 121 known RNA dual graphs, suggesting good performance. Furthermore,\n46.017% of the hypothetical RNAs are predicted to be RNA-like. Significantly,\nwe observe that all the top 15 RNA-like dual graphs can be separated into\nmultiple subgraphs, whereas the top 15 non-RNA-like dual graphs tend not to\nhave any subgraphs. Moreover, a significant topological difference between top\nRNA-like and non-RNA-like graphs is evident when comparing their topological\nfeatures. These findings provide valuable insights into the size of the RNA\nmotif universe and RNA design strategies, offering a novel framework for\npredicting RNA graph topologies and guiding the discovery of novel RNA motifs,\nperhaps anti-viral therapeutics by subgraph assembly."
    ],
    "c_categories":[
      "q-bio.BM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.19450",
    "a_title":"Unsupervised Learning Approach to Anomaly Detection in Gravitational\n  Wave Data",
    "a_abstract":"Gravitational waves (GW), predicted by Einstein's General Theory of\nRelativity, provide a powerful probe of astrophysical phenomena and fundamental\nphysics. In this work, we propose an unsupervised anomaly detection method\nusing variational autoencoders (VAEs) to analyze GW time-series data. By\ntraining on noise-only data, the VAE accurately reconstructs noise inputs while\nfailing to reconstruct anomalies, such as GW signals, which results in\nmeasurable spikes in the reconstruction error. The method was applied to data\nfrom the LIGO H1 and L1 detectors. Evaluation on testing datasets containing\nboth noise and GW events demonstrated reliable detection, achieving an area\nunder the ROC curve (AUC) of 0.89. This study introduces VAEs as a robust,\nunsupervised approach for identifying anomalies in GW data, which offers a\nscalable framework for detecting known and potentially new phenomena in\nphysics.",
    "explanation":"Gravitational waves (GW), predicted by Einstein\u2019s General Theory of Relativity, provide a pow-\nerful probe of astrophysical phenomena and fundamental physics. In this work, we propose an\nunsupervised anomaly detection method using variational autoencoders (VAEs) to analyze GW\ntime-series data. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining"
    ],
    "b_abstract":[
      "It is our great pleasure to welcome you the 2017 ACM Conference on Knowledge Discovery and Data Mining -- KDD 2017. We hope that content professional networking opportunities at will help succeed professionally by enabling to: identify new technology trends; learn from contributed papers, presentations, posters; discover tools, processes practices; job opportunities; hire team members. The terms \"Data Science\", Mining\" \"Big Data\" have, in last few years, grown out of research labs gained presence media everyday conversations. also hear these social decision makers various level governments corporations. impact technologies felt almost every walk life. Importantly, current rapid progress data science facilitated timely sharing newly discovered developed representations algorithms between those working interested industrial deployment. hallmark conferences past they have been bridge theory practise, facilitator catalyst for this exchange. Researchers practitioners meet person interact a meaningful way over several days. conference program, with its three parallel tracks - Research Track, Applied Science Track Invited Speakers brings two groups together. Participants are freely attend any track, events common all tracks. year continues tradition strong tutorial workshop program leading edge issues mining during first days program. devoted technical describing both novel, important contributions, deployed, innovative solutions. Three keynote talks, Cynthia Dwork, Bin Yu, Ren\u00e9e J. Miller touch some hard, emerging before field mining. With growing industry around AI assistants, Panel together experts spawn discussions an exchanges ideas. outstanding lineup speakers their experiences expertise deploying continue hands-on which participants how use practical tools. In order broaden increase participation attendees who would greatly benefit but otherwise found it financially challenging attend, we reserved substantial budget travel grants. awarded record USD 145k student set aside 25k enable smaller startups attend. \"Meet Experts\" sessions, gives researchers unique opportunity form networks share perspectives others aspects science. serve as meeting ground researchers, practitioners, funding agencies investors create commercial products."
    ],
    "b_categories":[
      "physics.gen-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.06242"
    ],
    "c_title":[
      "LapSum -- One Method to Differentiate Them All: Ranking, Sorting and\n  Top-k Selection"
    ],
    "c_abstract":[
      "We present a novel technique for constructing differentiable order-type\noperations, including soft ranking, soft top-k selection, and soft\npermutations. Our approach leverages an efficient closed-form formula for the\ninverse of the function LapSum, defined as the sum of Laplace distributions.\nThis formulation ensures low computational and memory complexity in selecting\nthe highest activations, enabling losses and gradients to be computed in\n$O(n\\log{}n)$ time. Through extensive experiments, we demonstrate that our\nmethod outperforms state-of-the-art techniques for high-dimensional vectors and\nlarge $k$ values. Furthermore, we provide efficient implementations for both\nCPU and CUDA environments, underscoring the practicality and scalability of our\nmethod for large-scale ranking and differentiable ordering problems."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.19450",
    "a_title":"Unsupervised Learning Approach to Anomaly Detection in Gravitational\n  Wave Data",
    "a_abstract":"Gravitational waves (GW), predicted by Einstein's General Theory of\nRelativity, provide a powerful probe of astrophysical phenomena and fundamental\nphysics. In this work, we propose an unsupervised anomaly detection method\nusing variational autoencoders (VAEs) to analyze GW time-series data. By\ntraining on noise-only data, the VAE accurately reconstructs noise inputs while\nfailing to reconstruct anomalies, such as GW signals, which results in\nmeasurable spikes in the reconstruction error. The method was applied to data\nfrom the LIGO H1 and L1 detectors. Evaluation on testing datasets containing\nboth noise and GW events demonstrated reliable detection, achieving an area\nunder the ROC curve (AUC) of 0.89. This study introduces VAEs as a robust,\nunsupervised approach for identifying anomalies in GW data, which offers a\nscalable framework for detecting known and potentially new phenomena in\nphysics.",
    "explanation":"Gravitational waves (GW), predicted by Einstein\u2019s General Theory of Relativity, provide a pow-\nerful probe of astrophysical phenomena and fundamental physics. In this work, we propose an\nunsupervised anomaly detection method using variational autoencoders (VAEs) to analyze GW\ntime-series data. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Auto-Encoding Variational Bayes"
    ],
    "b_abstract":[
      "How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04045"
    ],
    "c_title":[
      "A new type of Multiverse, G\\\"odel theorems and the nonstandard logic of\n  classical, quantum mechanics and quantum gravity"
    ],
    "c_abstract":[
      "The problem is posed of establishing a possible relationship between a new\ntype of Multi-verse representation, G\\\"odel undecidability theorems and the\nlogic of classical, quantum mechanics and quantum gravity. For this purpose\nexample cases of multi-verses are first discussed in the context of\nnon-relativistic classical, quantum mechanics and quantum gravity. As a result,\nit is confirmed that thanks to G\\\"odel theorems non-relativistic classical and\nquantum mechanics, as well as quantum gravity theory are incomplete. As a\nconsequence, they necessarily admit undecidable logical propositions and\ntherefore obey a three-way boolean logical, i.e., a propositional logic with\nthe three different logical truth values true, false and undecidable."
    ],
    "c_categories":[
      "physics.gen-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.09927",
    "a_title":"Neural Vector Tomography for Reconstructing a Magnetization Vector Field",
    "a_abstract":"Discretized techniques for vector tomographic reconstructions are prone to\nproducing artifacts in the reconstructions. The quality of these\nreconstructions may further deteriorate as the amount of noise increases. In\nthis work, we instead model the underlying vector fields using smooth neural\nfields. Owing to the fact that the activation functions in the neural network\nmay be chosen to be smooth and the domain is no longer pixelated, the model\nresults in high-quality reconstructions, even under presence of noise. In the\ncase where we have underlying global continuous symmetry, we find that the\nneural network substantially improves the accuracy of the reconstruction over\nthe existing techniques.",
    "explanation":" In this work, we instead model the underlying\nvector fields using smooth neural fields",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Three-dimensional nanomagnetism"
    ],
    "b_abstract":[
      "Magnetic nanostructures are being developed for use in many aspects of our daily life, spanning areas such as data storage, sensing and biomedicine. Whereas patterned nanomagnets traditionally two-dimensional planar structures, recent work is expanding nanomagnetism into three dimensions; a move triggered by the advance unconventional synthesis methods discovery new magnetic effects. In three-dimensional more complex configurations become possible, with unprecedented properties. Here we review creation these structures their implications emergence physics, development instrumentation computational methods, exploitation numerous applications. Nanoscale devices play key role modern technologies but current applications involve only 2D like discs. authors progress fabrication understanding 3D nanostructures, enabling diverse functionalities."
    ],
    "b_categories":[
      "cond-mat.mes-hall"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2501.19140"
    ],
    "c_title":[
      "Transformation trees -- documentation of multimodal image registration"
    ],
    "c_abstract":[
      "Multimodal image registration plays a key role in creating digital patient\nmodels by combining data from different imaging techniques into a single\ncoordinate system. This process often involves multiple sequential and\ninterconnected transformations, which must be well-documented to ensure\ntransparency and reproducibility. In this paper, we propose the use of\ntransformation trees as a method for structured recording and management of\nthese transformations. This approach has been implemented in the dpVision\nsoftware and uses a dedicated .dpw file format to store hierarchical\nrelationships between images, transformations, and motion data. Transformation\ntrees allow precise tracking of all image processing steps, reduce the need to\nstore multiple copies of the same data, and enable the indirect registration of\nimages that do not share common reference points. This improves the\nreproducibility of the analyses and facilitates later processing and\nintegration of images from different sources. The practical application of this\nmethod is demonstrated with examples from orthodontics, including the\nintegration of 3D face scans, intraoral scans, and CBCT images, as well as the\ndocumentation of mandibular motion. Beyond orthodontics, this method can be\napplied in other fields that require systematic management of image\nregistration processes, such as maxillofacial surgery, oncology, and\nbiomechanical analysis. Maintaining long-term data consistency is essential for\nboth scientific research and clinical practice. It enables easier comparison of\nresults in longitudinal studies, improves retrospective analysis, and supports\nthe development of artificial intelligence algorithms by providing standardized\nand well-documented datasets. The proposed approach enhances data organization,\nallows for efficient analysis, and facilitates the reuse of information in\nfuture studies and diagnostic procedures."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.09927",
    "a_title":"Neural Vector Tomography for Reconstructing a Magnetization Vector Field",
    "a_abstract":"Discretized techniques for vector tomographic reconstructions are prone to\nproducing artifacts in the reconstructions. The quality of these\nreconstructions may further deteriorate as the amount of noise increases. In\nthis work, we instead model the underlying vector fields using smooth neural\nfields. Owing to the fact that the activation functions in the neural network\nmay be chosen to be smooth and the domain is no longer pixelated, the model\nresults in high-quality reconstructions, even under presence of noise. In the\ncase where we have underlying global continuous symmetry, we find that the\nneural network substantially improves the accuracy of the reconstruction over\nthe existing techniques.",
    "explanation":" In this work, we instead model the underlying\nvector fields using smooth neural fields",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "MagNet: machine learning enhanced three-dimensional magnetic reconstruction"
    ],
    "b_abstract":[
      "Three-dimensional (3D) magnetic reconstruction is vital to the study of novel materials for 3D spintronics. Vector field electron tomography (VFET) a major in house tool achieve that. However, conventional VFET exhibits significant artefacts due unavoidable presence missing wedges. In this article, we propose deep-learning enhanced method address issue. A textures library built by micromagnetic simulations. MagNet, an U-shaped convolutional neural network, trained and tested with dataset generated from library. We demonstrate that MagNet outperforms under wedge. Quality reconstructed induction fields significantly improved."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.12671"
    ],
    "c_title":[
      "Stability of Majorana modes in Coulomb-disordered topological insulator\n  nanowires"
    ],
    "c_abstract":[
      "We evaluate theoretically the possibility to realize Majorana zero modes in\nhybrid devices made from topological-insulator (TI) nanowires proximity-coupled\nto a superconductor. Such systems have been suggested as building blocks of\nfuture topological quantum computers, as they have been predicted to realize\nMajorana zero modes protected by large gaps. A main obstacle is, however, the\npresence of a relatively large density of charged impurities, $n_\\text{imp}\\sim\n10^{19}$cm$^{-3}$. Based on extensive numerical simulations, we show that the\nproximity to the superconductor leads to an efficient screening of the disorder\npotential. By analyzing the Majorana splitting energy, the size of the Andreev\ngap and the localization of edge modes, we show that robust Majorana modes can\nbe realized for realistic levels of impurity concentrations and wire radii."
    ],
    "c_categories":[
      "cond-mat.mes-hall"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.19927",
    "a_title":"Modeling Continuous Spatial-temporal Dynamics of Turbulent Flow with\n  Test-time Refinement",
    "a_abstract":"The precise simulation of turbulent flows holds immense significance across\nvarious scientific and engineering domains, including climate science,\nfreshwater science, and energy-efficient manufacturing. Within the realm of\nsimulating turbulent flows, large eddy simulation (LES) has emerged as a\nprevalent alternative to direct numerical simulation (DNS), offering\ncomputational efficiency. However, LES cannot accurately capture the full\nspectrum of turbulent transport scales and is present only at a lower spatial\nresolution. Reconstructing high-fidelity DNS data from the lower-resolution LES\ndata is essential for numerous applications, but it poses significant\nchallenges to existing super-resolution techniques, primarily due to the\ncomplex spatio-temporal nature of turbulent flows. This paper proposes a novel\nflow reconstruction approach that leverages physical knowledge to model flow\ndynamics. Different from traditional super-resolution techniques, the proposed\napproach uses LES data only in the testing phase through a degradation-based\nrefinement approach to enforce physical constraints and mitigate cumulative\nreconstruction errors over time. Furthermore, a feature sampling strategy is\ndeveloped to enable flow data reconstruction across different resolutions. The\nresults on two distinct sets of turbulent flow data indicate the effectiveness\nof the proposed method in reconstructing high-resolution DNS data, preserving\nthe inherent physical attributes of flow transport, and achieving DNS\nreconstruction at different resolutions.",
    "explanation":"his paper proposes a novel flow recon-\nstruction approach that leverages physical knowledge to\nmodel flow dynamics.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Model-free simulations of turbulent reactive flows"
    ],
    "b_abstract":[
      "A critical review of the modern computational methods for solving the transport equations of turbulent reacting single-phase flows is presented. Primary consideration is given to those methods which lead to \u2018model-free\u2019 simulations while some attention is devoted to \u2018turbulence modeling\u2019. Emphasis is placed upon the role of supercomputers and how their increased computational capacities may be exploited to allow better simulations of the physics of turbulent reactive flows. Comparisons between the commonly employed computational schemes for simulating these flows are given, with the advantages and the limitations associated with each scheme being highlighted. Examples are presented of recent applications of model-free simulations to a variety of unsteady reacting flows, with detailed discussions on the physical phenomena captured by such simulations. Due to the nature of this review, experimental contributions are mentioned only in the context of providing empirical evidence. References are made to other contributions which are not directly related to the computational efforts in order to provide a reasonably comprehensive bibliography for those interested in pursuing various topics in greater detail. Predictions of future accomplishments, as well as some suggestions for future work, are also given."
    ],
    "b_categories":[
      "physics.flu-dyn"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.17361"
    ],
    "c_title":[
      "A Closer Look at TabPFN v2: Strength, Limitation, and Extension"
    ],
    "c_abstract":[
      "Tabular datasets are inherently heterogeneous, posing significant challenges\nfor developing pre-trained foundation models. The recently introduced\ntransformer-based Tabular Prior-data Fitted Network v2 (TabPFN v2) achieves\nunprecedented in-context learning accuracy across multiple tabular datasets,\nmarking a pivotal advancement in tabular foundation models. In this paper, we\ncomprehensively evaluate TabPFN v2 on over 300 datasets, confirming its\nexceptional generalization capabilities on small- to medium-scale tasks. Our\nanalysis identifies randomized feature tokens as a key factor behind TabPFN\nv2's success, as they unify heterogeneous datasets into a fixed-dimensional\nrepresentation, enabling more effective training and inference. To further\nunderstand TabPFN v2's predictions, we propose a leave-one-fold-out approach,\ntransforming TabPFN v2 into a feature extractor and revealing its capability to\nsimplify data distributions and boost accuracy. Lastly, to address TabPFN v2's\nlimitations in high-dimensional, large-scale, and many-category tasks, we\nintroduce a divide-and-conquer mechanism inspired by Chain-of-Thought\nprompting, enabling scalable inference. By uncovering the mechanisms behind\nTabPFN v2's success and introducing strategies to expand its applicability,\nthis study provides key insights into the future of tabular foundation models."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.19927",
    "a_title":"Modeling Continuous Spatial-temporal Dynamics of Turbulent Flow with\n  Test-time Refinement",
    "a_abstract":"The precise simulation of turbulent flows holds immense significance across\nvarious scientific and engineering domains, including climate science,\nfreshwater science, and energy-efficient manufacturing. Within the realm of\nsimulating turbulent flows, large eddy simulation (LES) has emerged as a\nprevalent alternative to direct numerical simulation (DNS), offering\ncomputational efficiency. However, LES cannot accurately capture the full\nspectrum of turbulent transport scales and is present only at a lower spatial\nresolution. Reconstructing high-fidelity DNS data from the lower-resolution LES\ndata is essential for numerous applications, but it poses significant\nchallenges to existing super-resolution techniques, primarily due to the\ncomplex spatio-temporal nature of turbulent flows. This paper proposes a novel\nflow reconstruction approach that leverages physical knowledge to model flow\ndynamics. Different from traditional super-resolution techniques, the proposed\napproach uses LES data only in the testing phase through a degradation-based\nrefinement approach to enforce physical constraints and mitigate cumulative\nreconstruction errors over time. Furthermore, a feature sampling strategy is\ndeveloped to enable flow data reconstruction across different resolutions. The\nresults on two distinct sets of turbulent flow data indicate the effectiveness\nof the proposed method in reconstructing high-resolution DNS data, preserving\nthe inherent physical attributes of flow transport, and achieving DNS\nreconstruction at different resolutions.",
    "explanation":"his paper proposes a novel flow recon-\nstruction approach that leverages physical knowledge to\nmodel flow dynamics.",
    "b_id":[
      "b40"
    ],
    "b_title":[
      "Physics guided neural networks for spatio-temporal superresolution of turbulent flows"
    ],
    "b_abstract":[
      "Direct numerical simulation (DNS) of turbulent flows is computationally expensive and cannot be applied to flows with large Reynolds numbers. Low-resolution large eddy simulation (LES) is a popular alternative, but it is unable to capture all of the scales of turbulent transport accurately. Reconstructing DNS from low-resolution LES is critical for large-scale simulation in many scientific and engineering disciplines, but it poses many challenges to existing super-resolution methods due to the complexity of turbulent flows and computational cost of generating frequent LES data. We propose a physics-guided neural network for reconstructing frequent DNS from sparse LES data by enhancing its spatial resolution and temporal frequency. Our proposed method consists of a partial differential equation (PDE)-based recurrent unit for capturing underlying temporal processes and a physics-guided super-resolution model that incorporates additional physical constraints. We demonstrate the effectiveness of both components in reconstructing the Taylor-Green Vortex using sparse LES data. Moreover, we show that the proposed recurrent unit can preserve the physical characteristics of turbulent flows by leveraging the physical relationships in the Navier-Stokes equation."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.13966"
    ],
    "c_title":[
      "High-efficient machine learning projection method for incompressible\n  Navier-Stokes equations"
    ],
    "c_abstract":[
      "This study proposes a high-efficient machine learning (ML) projection method\nusing forward-generated data for incompressible Navier-Stokes equations. A\nPoisson neural network (Poisson-NN) embedded method and a wavelet transform\nconvolutional neural network multigrid (WTCNN-MG) method are proposed,\nintegrated into the projection method framework in patchwork and overall\ndifferentiable manners with MG method, respectively. The solution of the\npressure Poisson equation split from the Navier-Stokes equations is first\ngenerated either following a random field (e.g. Gaussian random field, GRF,\ncomputational complexity O(NlogN), N is the number of spatial points) or\nphysical laws (e.g. a kind of spectra, computational complexity O(NM), M is the\nnumber of modes), then the source terms, boundary conditions and initial\nconditions are constructed via balance of equations, avoiding the difficulties\nof obtaining high-fidelity training datasets. The feasibility of generated data\nfor training Poisson-NN and WTCNN as well as the acceleration performances of\nthe Poisson-NN embedded method and WTCNN-MG method are validated. The results\nindicate that even without any DNS data, the generated data can train these two\nmodels with excellent generalization and accuracy. The data following physical\nlaws can significantly improve the high-frequency approximation, convergence\nrate, generalization and accuracy than that generated following GRF. The ML\nprojection method offers significant improvements in computational efficiency.\nParticularly, the Poisson-NN embedded method achieves an average speed-up of\n5.83 times over the traditional MG method, while the WTCNN-MG method offers an\neven greater average speed-up of 7.03 times, demonstrating impressive\nacceleration performance."
    ],
    "c_categories":[
      "physics.flu-dyn"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.10196",
    "a_title":"High-dimensional Statistics Applications to Batch Effects in\n  Metabolomics",
    "a_abstract":"Batch effects are inevitable in large-scale metabolomics. Prior to formal\ndata analysis, batch effect correction (BEC) is applied to prevent from\nobscuring biological variations, and batch effect evaluation (BEE) is used for\ncorrection assessment. However, existing BEE algorithms neglect covariances\nbetween the variables, and existing BEC algorithms might fail to adequately\ncorrect the covariances. Therefore, we resort to recent advancements in\nhigh-dimensional statistics, and respectively propose \"quality control-based\nsimultaneous tests (QC-ST)\" and \"covariance correction (CoCo)\". Validated by\nthe simulation data, QC-ST can simultaneously detect the statistical\nsignificance of QC samples' mean vectors and covariance matrices across\ndifferent batches, and has a satisfactory statistical performance in empirical\nsizes, empirical powers, and computational speed. Then, we apply four QC-based\nBEC algorithms to two large cohort datasets, and find that extreme gradient\nboost (XGBoost) performs best in relative standard deviation (RSD) and\ndispersion-ratio (D-ratio). After prepositive BEC, if QC-ST still suggests that\nbatch effects between some two batches are significant, CoCo should be\nimplemented. And after CoCo (if necessary), the four metrics (i.e., RSD,\nD-ratio, classification performance, and QC-ST) might be further improved. In\nsummary, under the guidance of QC-ST, we can develop a matching strategy to\nintegrate multiple BEC algorithms more rationally and flexibly, and minimize\nbatch effects for reliable biological conclusions.",
    "explanation":"Batch effects are inevitable in large-scale metabolomics. Prior to formal data analysis, batch effect correction (BEC) is applied to prevent from obscuring biological variations, and batch effect evaluation (BEE) is used for correction assessment.we apply four QC-based BEC algorithms to two large cohort datasets, and find that extreme gradient boost (XGBoost) performs best in relative standard deviation (RSD) and dispersion-ratio (D-ratio).",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Quality assurance procedures for mass spectrometry untargeted metabolomics. a review"
    ],
    "b_abstract":[
      "Untargeted metabolomics, as a global approach, has already proven its great potential and capabilities for the investigation of health and disease, as well as the wide applicability for other research areas. Although great progress has been made on the feasibility of metabolomics experiments, there are still some challenges that should be faced and that includes all sources of fluctuations and bias affecting every step involved in multiplatform untargeted metabolomics studies. The identification and reduction of the main sources of unwanted variation regarding the pre-analytical, analytical and post-analytical phase of metabolomics experiments is essential to ensure high data quality. Nowadays, there is still a lack of information regarding harmonized guidelines for quality assurance as those available for targeted analysis. In this review, sources of variations to be considered and minimized along with methodologies and strategies for monitoring and improvement the quality of the results are discussed. The given information is based on evidences from different groups among our own experiences and recommendations for each stage of the metabolomics workflow. The comprehensive overview with tools presented here might serve other researchers interested in monitoring, controlling and improving the reliability of their findings by implementation of good experimental quality practices in the untargeted metabolomics study."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.07141"
    ],
    "c_title":[
      "Small steps no more: Global convergence of stochastic gradient bandits\n  for arbitrary learning rates"
    ],
    "c_abstract":[
      "We provide a new understanding of the stochastic gradient bandit algorithm by\nshowing that it converges to a globally optimal policy almost surely using\n\\emph{any} constant learning rate. This result demonstrates that the stochastic\ngradient algorithm continues to balance exploration and exploitation\nappropriately even in scenarios where standard smoothness and noise control\nassumptions break down. The proofs are based on novel findings about action\nsampling rates and the relationship between cumulative progress and noise, and\nextend the current understanding of how simple stochastic gradient methods\nbehave in bandit settings."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.10196",
    "a_title":"High-dimensional Statistics Applications to Batch Effects in\n  Metabolomics",
    "a_abstract":"Batch effects are inevitable in large-scale metabolomics. Prior to formal\ndata analysis, batch effect correction (BEC) is applied to prevent from\nobscuring biological variations, and batch effect evaluation (BEE) is used for\ncorrection assessment. However, existing BEE algorithms neglect covariances\nbetween the variables, and existing BEC algorithms might fail to adequately\ncorrect the covariances. Therefore, we resort to recent advancements in\nhigh-dimensional statistics, and respectively propose \"quality control-based\nsimultaneous tests (QC-ST)\" and \"covariance correction (CoCo)\". Validated by\nthe simulation data, QC-ST can simultaneously detect the statistical\nsignificance of QC samples' mean vectors and covariance matrices across\ndifferent batches, and has a satisfactory statistical performance in empirical\nsizes, empirical powers, and computational speed. Then, we apply four QC-based\nBEC algorithms to two large cohort datasets, and find that extreme gradient\nboost (XGBoost) performs best in relative standard deviation (RSD) and\ndispersion-ratio (D-ratio). After prepositive BEC, if QC-ST still suggests that\nbatch effects between some two batches are significant, CoCo should be\nimplemented. And after CoCo (if necessary), the four metrics (i.e., RSD,\nD-ratio, classification performance, and QC-ST) might be further improved. In\nsummary, under the guidance of QC-ST, we can develop a matching strategy to\nintegrate multiple BEC algorithms more rationally and flexibly, and minimize\nbatch effects for reliable biological conclusions.",
    "explanation":"Batch effects are inevitable in large-scale metabolomics. Prior to formal data analysis, batch effect correction (BEC) is applied to prevent from obscuring biological variations, and batch effect evaluation (BEE) is used for correction assessment.we apply four QC-based BEC algorithms to two large cohort datasets, and find that extreme gradient boost (XGBoost) performs best in relative standard deviation (RSD) and dispersion-ratio (D-ratio).",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "XGBoost: A Scalable Tree Boosting System"
    ],
    "b_abstract":[
      "Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.02971"
    ],
    "c_title":[
      "Bowel Incision Closure with a Semi-Automated Robot-Assisted Laser Tissue\n  Soldering System"
    ],
    "c_abstract":[
      "Traditional methods for closing gastrointestinal (GI) surgery incisions, like\nsuturing and stapling, present significant challenges, including potentially\nlife-threatening leaks. These techniques, especially in robot-assisted\nminimally invasive surgery (RAMIS), require advanced manual skills. While their\nrepetitive and time-consuming nature makes them suitable candidates for\nautomation, the automation process is complicated by the need for extensive\ncontact with the tissue. Addressing this, we demonstrate a semi-autonomous\ncontactless surgical procedure using our novel Robot-assisted Laser Tissue\nSoldering (RLTS) system on a live porcine bowel. Towards this in-vivo\ndemonstration, we optimized soldering protocols and system parameters in\nex-vivo experiments on porcine bowels and a porcine cadaver. To assess the RLTS\nsystem performance, we compared the pressure at which the anastomosis leaked\nbetween our robotic soldering and manual suturing. With the best setup, we\nadvanced to an in-vivo Heineke Mikulicz closure on small bowel incision in live\npigs and evaluated their healing for two weeks. All pigs successfully\ncompleting the procedure (N=5) survived without leaks and the histology\nindicated mucosal regeneration and fibrous tissue adhesion. This marks the\nfirst in-vivo semi-automated contactless incision closure, paving the way for\nautomating GI surgery incision closure which has the potential to become an\nalternative to traditional methods."
    ],
    "c_categories":[
      "q-bio.QM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00225",
    "a_title":"Meta-learning Loss Functions of Parametric Partial Differential\n  Equations Using Physics-Informed Neural Networks",
    "a_abstract":"This paper proposes a new way to learn Physics-Informed Neural Network loss\nfunctions using Generalized Additive Models. We apply our method by\nmeta-learning parametric partial differential equations, PDEs, on Burger's and\n2D Heat Equations. The goal is to learn a new loss function for each parametric\nPDE using meta-learning. The derived loss function replaces the traditional\ndata loss, allowing us to learn each parametric PDE more efficiently, improving\nthe meta-learner's performance and convergence.",
    "explanation":"This paper proposes a new way to learn Physics-Informed Neural Network loss functions using Generalized Additive Models.We apply our method by meta-learning parametric partial differential equations, PDEs, on Burger\u2019s and 2D Heat Equations.",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "The Burgers equation"
    ],
    "b_abstract":[
      "The Burgers equation is a simple equation to understand the main properties of the Navier-Stokes equations. In this one-dimensional equation the pressure is neglected but the effects of the nonlinear and viscous terms remain, hence as in the Navier-Stokes equations a Reynolds number can be defined. This number expresses the ratio between the advective and the viscous contribution in a flow. The present book deals with flows at high Reynolds numbers where the nonlinear terms play a fundamental role, and the physics is more complicated than that when the viscous term dominates. The simulation of the flow evolution then necessitates the use of accurate and robust numerical methods. In 3D turbulent flows, where the number of degrees of freedom is greater than in high Re laminar flows, to get solutions it is necessary to introduce some sort of closure to account for the impossibility to resolve the small scales. Before applying any new idea about numerical methods to 3D flows, the good sense suggests to find the simplest equation to test these ideas. This consideration explains why the Burgers equation was often used to check new numerical methods or closure for turbulent flows."
    ],
    "b_categories":[
      "math.AP"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2502.07709"
    ],
    "c_title":[
      "MAGELLAN: Metacognitive predictions of learning progress guide autotelic\n  LLM agents in large goal spaces"
    ],
    "c_abstract":[
      "Open-ended learning agents must efficiently prioritize goals in vast\npossibility spaces, focusing on those that maximize learning progress (LP).\nWhen such autotelic exploration is achieved by LLM agents trained with online\nRL in high-dimensional and evolving goal spaces, a key challenge for LP\nprediction is modeling one's own competence, a form of metacognitive\nmonitoring. Traditional approaches either require extensive sampling or rely on\nbrittle expert-defined goal groupings. We introduce MAGELLAN, a metacognitive\nframework that lets LLM agents learn to predict their competence and LP online.\nBy capturing semantic relationships between goals, MAGELLAN enables\nsample-efficient LP estimation and dynamic adaptation to evolving goal spaces\nthrough generalization. In an interactive learning environment, we show that\nMAGELLAN improves LP prediction efficiency and goal prioritization, being the\nonly method allowing the agent to fully master a large and evolving goal space.\nThese results demonstrate how augmenting LLM agents with a metacognitive\nability for LP predictions can effectively scale curriculum learning to\nopen-ended goal spaces."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00225",
    "a_title":"Meta-learning Loss Functions of Parametric Partial Differential\n  Equations Using Physics-Informed Neural Networks",
    "a_abstract":"This paper proposes a new way to learn Physics-Informed Neural Network loss\nfunctions using Generalized Additive Models. We apply our method by\nmeta-learning parametric partial differential equations, PDEs, on Burger's and\n2D Heat Equations. The goal is to learn a new loss function for each parametric\nPDE using meta-learning. The derived loss function replaces the traditional\ndata loss, allowing us to learn each parametric PDE more efficiently, improving\nthe meta-learner's performance and convergence.",
    "explanation":"This paper proposes a new way to learn Physics-Informed Neural Network loss functions using Generalized Additive Models.We apply our method by meta-learning parametric partial differential equations, PDEs, on Burger\u2019s and 2D Heat Equations.",
    "b_id":[
      "b17"
    ],
    "b_title":[
      "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations"
    ],
    "b_abstract":[
      "We introduce physics-informed neural networks \u2013 neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge\u2013Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction\u2013diffusion systems, and the propagation of nonlinear shallow-water waves."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.02049"
    ],
    "c_title":[
      "Normalized solutions to focusing Sobolev critical biharmonic\n  Schr\\\"{o}dinger equation with mixed dispersion"
    ],
    "c_abstract":[
      "This paper is concerned with the following focusing biharmonic\nSchr\\\"{o}dinger equation with mixed dispersion and Sobolev critical growth: $$\n\\begin{cases}\n  {\\Delta}^2u-\\Delta u-\\lambda u-\\mu|u|^{p-2}u-|u|^{4^*-2}u=0\\ \\ \\mbox{in}\\\n\\mathbb{R}^N, \\\\[0.1cm]\n  \\int_{\\mathbb{R}^N} u^2 dx = c, \\end{cases} $$ where $N \\geq 5$, $\\mu,c>0$,\n$2<p<4^*:=\\frac{2N}{N-4}$ and $\\lambda \\in \\mathbb{R}$ is a Lagrange\nmultiplier. For this problem, under the $L^2$-subcritical perturbation\n($2<p<2+\\frac{8}{N}$), we derive the existence and multiplicity of normalized\nsolutions via the truncation technique, concentration-compactness principle and\nthe genus theory presented by C.O. Alves et al. (Arxiv, (2021), doi:\n2103.07940v2). Compared to the results of C.O. Alves et al. we obtain a more\ngeneral result after removing the further assumptions given in (3.2) of their\npaper. In the case of $L^2$-supercritical perturbation ($2+\\frac{8}{N}<p<4^*$),\nwe explore the existence results of normalized solutions by applying the\nconstrained variational methods and the mountain pass theorem. Moreover, we\npropose a novel method to address the effects of the dispersion term $\\Delta\nu$. This approach allows us to extend the recent results obtained by X. Chang\net al. (Arxiv, (2023), doi: 2305.00327v1) to the mixed dispersion situation."
    ],
    "c_categories":[
      "math.AP"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05456",
    "a_title":"Comparative Study of Probabilistic Atlas and Deep Learning Approaches\n  for Automatic Brain Tissue Segmentation from MRI Using N4 Bias Field\n  Correction and Anisotropic Diffusion Pre-processing Techniques",
    "a_abstract":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI)\nimages is vital for accurate diagnosis and further analysis in medical imaging.\nDespite advancements in segmentation techniques, a comprehensive comparison\nbetween traditional statistical methods and modern deep learning approaches\nusing pre-processing techniques like N4 Bias Field Correction and Anisotropic\nDiffusion remains underexplored. This study provides a comparative analysis of\nvarious segmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and\nLinkNet, enhanced with these pre-processing techniques to segment brain tissues\n(white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF)) on the\nInternet Brain Segmentation Repository (IBSR18) dataset. Our results\ndemonstrate that the 3D nnU-Net model outperforms others, achieving the highest\nmean Dice Coefficient score (0.937 +- 0.012), while the 2D nnU-Net model\nrecorded the lowest mean Hausdorff Distance (5.005 +- 0.343 mm) and the lowest\nmean Absolute Volumetric Difference (3.695 +- 2.931 mm) across five unseen test\nsamples. The findings highlight the superiority of nnU-Net models in brain\ntissue segmentation, particularly when combined with N4 Bias Field Correction\nand Anisotropic Diffusion pre-processing techniques. Our implemented code can\nbe accessed via GitHub.",
    "explanation":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI) images is vital for accurate diagnosis and further analysis in medical imaging. \n\nThis study provides a comparative analysis of various\nsegmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and LinkNet, enhanced with these preprocessing techniques to segment brain tissue",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "MRI segmentation of the human brain: challenges, methods, and applications"
    ],
    "b_abstract":[
      "Image segmentation is one of the most important tasks in medical image analysis and is often the first and the most critical step in many clinical applications. In brain MRI analysis, image segmentation is commonly used for measuring and visualizing the brain\u2019s anatomical structures, for analyzing brain changes, for delineating pathological regions, and for surgical planning and image-guided interventions. In the last few decades, various segmentation techniques of different accuracy and degree of complexity have been developed and reported in the literature. In this paper we review the most popular methods commonly used for brain MRI segmentation. We highlight differences between them and discuss their capabilities, advantages, and limitations. To address the complexity and challenges of the brain MRI segmentation problem, we first introduce the basic concepts of image segmentation. Then, we explain different MRI preprocessing steps including image registration, bias field correction, and removal of nonbrain tissue. Finally, after reviewing different brain MRI segmentation methods, we discuss the validation problem in brain MRI segmentation."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.14102"
    ],
    "c_title":[
      "Explainable Distributed Constraint Optimization Problems"
    ],
    "c_abstract":[
      "The Distributed Constraint Optimization Problem (DCOP) formulation is a\npowerful tool to model cooperative multi-agent problems that need to be solved\ndistributively. A core assumption of existing approaches is that DCOP solutions\ncan be easily understood, accepted, and adopted, which may not hold, as\nevidenced by the large body of literature on Explainable AI. In this paper, we\npropose the Explainable DCOP (X-DCOP) model, which extends a DCOP to include\nits solution and a contrastive query for that solution. We formally define some\nkey properties that contrastive explanations must satisfy for them to be\nconsidered as valid solutions to X-DCOPs as well as theoretical results on the\nexistence of such valid explanations. To solve X-DCOPs, we propose a\ndistributed framework as well as several optimizations and suboptimal variants\nto find valid explanations. We also include a human user study that showed that\nusers, not surprisingly, prefer shorter explanations over longer ones. Our\nempirical evaluations showed that our approach can scale to large problems, and\nthe different variants provide different options for trading off explanation\nlengths for smaller runtimes. Thus, our model and algorithmic contributions\nextend the state of the art by reducing the barrier for users to understand\nDCOP solutions, facilitating their adoption in more real-world applications."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05456",
    "a_title":"Comparative Study of Probabilistic Atlas and Deep Learning Approaches\n  for Automatic Brain Tissue Segmentation from MRI Using N4 Bias Field\n  Correction and Anisotropic Diffusion Pre-processing Techniques",
    "a_abstract":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI)\nimages is vital for accurate diagnosis and further analysis in medical imaging.\nDespite advancements in segmentation techniques, a comprehensive comparison\nbetween traditional statistical methods and modern deep learning approaches\nusing pre-processing techniques like N4 Bias Field Correction and Anisotropic\nDiffusion remains underexplored. This study provides a comparative analysis of\nvarious segmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and\nLinkNet, enhanced with these pre-processing techniques to segment brain tissues\n(white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF)) on the\nInternet Brain Segmentation Repository (IBSR18) dataset. Our results\ndemonstrate that the 3D nnU-Net model outperforms others, achieving the highest\nmean Dice Coefficient score (0.937 +- 0.012), while the 2D nnU-Net model\nrecorded the lowest mean Hausdorff Distance (5.005 +- 0.343 mm) and the lowest\nmean Absolute Volumetric Difference (3.695 +- 2.931 mm) across five unseen test\nsamples. The findings highlight the superiority of nnU-Net models in brain\ntissue segmentation, particularly when combined with N4 Bias Field Correction\nand Anisotropic Diffusion pre-processing techniques. Our implemented code can\nbe accessed via GitHub.",
    "explanation":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI) images is vital for accurate diagnosis and further analysis in medical imaging. \n\nThis study provides a comparative analysis of various\nsegmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and LinkNet, enhanced with these preprocessing techniques to segment brain tissue",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "U-net: Convolutional networks for biomedical image segmentation"
    ],
    "b_abstract":[
      "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04147"
    ],
    "c_title":[
      "A Framework for Building Enviromics Matrices in Mixed Models"
    ],
    "c_abstract":[
      "This study introduces a framework for constructing enviromics matrices in\nmixed models to integrate genetic and environmental data to enhance phenotypic\npredictions in plant breeding. Enviromics utilizes diverse data sources, such\nas climate and soil, to characterize genotype-by-environment (GxE)\ninteractions. The approach employs block-diagonal structures in the design\nmatrix to incorporate random effects from genetic and envirotypic covariates\nacross trials. The covariance structure is modeled using the Kronecker product\nof the genetic relationship matrix and an identity matrix representing\nenvirotypic effects, capturing genetic and environmental variability. This dual\nrepresentation enables more accurate crop performance predictions across\nenvironments, improving selection strategies in breeding programs. The\nframework is compatible with existing mixed model software, including rrBLUP\nand BGLR, and can be extended for more complex interactions. By combining\ngenetic relationships and environmental influences, this approach offers a\npowerful tool for advancing GxE studies and accelerating the development of\nimproved crop varieties."
    ],
    "c_categories":[
      "q-bio.QM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05213",
    "a_title":"A chemostat model with variable dilution rate due to biofilm growth",
    "a_abstract":"In many real life applications, a continuous culture bioreactor may cease to\nfunction properly due to bioclogging which is typically caused by the microbial\novergrowth. This is a problem that has been largely overlooked in the chemostat\nmodeling literature, despite the fact that a number of models explicitly\naccounted for biofilm development inside the bioreactor. In a typical chemostat\nmodel, the physical volume of the biofilm is considered negligible when\ncompared to the volume of the fluid. In this paper, we investigate the\ntheoretical consequences of removing such assumption. Specifically, we\nformulate a novel mathematical model of a chemostat where the increase of the\nbiofilm volume occurs at the expense of the fluid volume of the bioreactor, and\nas a result the corresponding dilution rate increases reciprocally. We show\nthat our model is well-posed and describes the bioreactor that can operate in\nthree distinct types of dynamic regimes: the washout equilibrium, the\ncoexistence equilibrium, or a transient towards the clogged state which is\nreached in finite time. We analyze the multiplicity and the stability of the\ncorresponding equilibria. In particular, we delineate the parameter\ncombinations for which the chemostat never clogs up and those for which it\nclogs up in finite time. We also derive criteria for microbial persistence and\nextinction. Finally, we present a numerical evidence that a multistable\ncoexistence in the chemostat with variable dilution rate is feasible.",
    "explanation":"Specifically, we formulate a novel mathematical model of a chemostat where the increase of the biofilm volume occurs at the expense of the fluid volume of the bioreactor, and as a result the corresponding dilution rate increases reciprocally.",
    "b_id":[
      "b1",
      "b8"
    ],
    "b_title":[
      "Microreactors gain wider use as alternative to batch production",
      "How flocculation can explain coexistence in the chemostat"
    ],
    "b_abstract":[
      "The microreactors are gaining wide use among the pharmaceuticals and chemical companies as an alternative to batch production. They not only offers a flexible approach to continuous processing, but promises to save much of the time and effort consumed while expanding the chemistries at commercial scale. Most of the ten global pharma and chemical companies have acquired the Cytos Lab System,, a microreactor product developed by Cellular Process Chemistry Systems GmbH (CPC). Microreactors are comprised of plates with distinct channels in the submillimeter range, providing high surface-to-volume ratio, ultra fast mixing and high degree of control at all levels of production.",
      "We study a chemostat model in which two microbial species grow on single resource. show that coexistence is possible when the would normally win exclusive competition aggregates flocs. Our mathematical analysis exploits fact flocculation fast compared to biological growth, common hypothesis floc models. A numerical shows validity of this approach large parameter range. indicate how our yields mechanistic justification for so-called density-dependent growth."
    ],
    "b_categories":[
      "q-bio.OT"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.13285"
    ],
    "c_title":[
      "A Bayesian Record Linkage Approach to Applications in Tree Demography\n  Using Overlapping LiDAR Scans"
    ],
    "c_abstract":[
      "In the information age, it has become increasingly common for data containing\nrecords about overlapping individuals to be distributed across multiple\nsources, making it necessary to identify which records refer to the same\nindividual. The goal of record linkage is to estimate this unknown structure in\nthe absence of a unique identifiable attribute. We introduce a Bayesian\nhierarchical record linkage model for spatial location data motivated by the\nestimation of individual specific growth-size curves for conifer species using\ndata derived from overlapping LiDAR scans. Annual tree growth may be estimated\ndependent upon correctly identifying unique individuals across scans in the\npresence of noise. We formalize a two-stage modeling framework, connecting the\nrecord linkage model and a flexible downstream individual tree growth model,\nthat provides robust uncertainty quantification and propagation through both\nstages of the modeling pipeline via an extension of the linkage-averaging\napproach of Sadinle (2018). In this paper, we discuss the two-stage model\nformulation, outline the computational strategies required to achieve\nscalability, assess the model performance on simulated data, and fit the model\nto a bi-temporal dataset derived from LiDAR scans of the Upper Gunnison\nWatershed provided by the Rocky Mountain Biological Laboratory to assess the\nimpact of key topographic covariates on the growth behavior of conifer species\nin the Southern Rocky Mountains (USA)."
    ],
    "c_categories":[
      "stat.AP",
      "stat.ME"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.05213",
    "a_title":"A chemostat model with variable dilution rate due to biofilm growth",
    "a_abstract":"In many real life applications, a continuous culture bioreactor may cease to\nfunction properly due to bioclogging which is typically caused by the microbial\novergrowth. This is a problem that has been largely overlooked in the chemostat\nmodeling literature, despite the fact that a number of models explicitly\naccounted for biofilm development inside the bioreactor. In a typical chemostat\nmodel, the physical volume of the biofilm is considered negligible when\ncompared to the volume of the fluid. In this paper, we investigate the\ntheoretical consequences of removing such assumption. Specifically, we\nformulate a novel mathematical model of a chemostat where the increase of the\nbiofilm volume occurs at the expense of the fluid volume of the bioreactor, and\nas a result the corresponding dilution rate increases reciprocally. We show\nthat our model is well-posed and describes the bioreactor that can operate in\nthree distinct types of dynamic regimes: the washout equilibrium, the\ncoexistence equilibrium, or a transient towards the clogged state which is\nreached in finite time. We analyze the multiplicity and the stability of the\ncorresponding equilibria. In particular, we delineate the parameter\ncombinations for which the chemostat never clogs up and those for which it\nclogs up in finite time. We also derive criteria for microbial persistence and\nextinction. Finally, we present a numerical evidence that a multistable\ncoexistence in the chemostat with variable dilution rate is feasible.",
    "explanation":"Specifically, we formulate a novel mathematical model of a chemostat where the increase of the biofilm volume occurs at the expense of the fluid volume of the bioreactor, and as a result the corresponding dilution rate increases reciprocally.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Effect of bioclogging in porous media on complex conductivity signatures"
    ],
    "b_abstract":[
      "Flow through sand columns inoculated with Pseudomonas aeruginosa were used to investigate the effect of bioclogging on complex conductivity and flow transport properties. Complex (0.1\u20131000 Hz), bulk hydraulic (K), volumetric rate (Q), dispersivity (D), microbial cell concentrations monitored over time. Environmental scanning electron microscope images sands obtained at end experiment. Bioclogging resulting from increases in concentration production exopolymeric substances (EPS) had a large impact imaginary ( \u03c3 \u2033), K, Q, D, porosity (\u03a6). Changes electrical properties developed three stages: an initial stage 1 no significant changes all measured parameters (Days 1\u20138), which we attribute reversible irreversible attachment cells sand. In 2a 9\u201316), caused by growth biomass either as microcolonies filling pore throats and\/or uniform covering surfaces resulted maximum decrease Q but only moderate \u2033. 2b 17\u201324), EPS increase biofilm thickness higher \u2033 compared 2a. 3 25\u201332), reached quasi steady state insignificant are observed parameters. The results this study suggest that can provide complimentary information assessment porous media."
    ],
    "b_categories":[
      "math.MP"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2501.08650"
    ],
    "c_title":[
      "\\^Etre mineur non accompagn\\'e \\`a Paris: exploration des facteurs\n  d\\'eterminants des besoins en sant\\'e physique et mentale par une \\'etude\n  qualitative"
    ],
    "c_abstract":[
      "In France, government protection of unaccompanied minors (UMs) depends upon\nthe recognition of their minority status and often result in a rejection. A\nsignificant proportion of UMs therefore find themselves unprotected. This\nqualitative study explores the contextual and individual factors that shape the\nphysical and mental health needs of unprotected UMs in Paris. Interviews were\nconducted with UMs (n=12) and those working with them (n=36). A\ndeductive-inductive thematic analysis was carried out. The study contributes to\nthe analysis of the health determinants of unprotected UMs. It shows that\ninstitutional barriers limit the scope for action by civil society in the\npalliative care they receive. The consequence for them is living in conditions\nof instability and precariousness, with very little prospects for the future,\nwhich has a negative impact on their physical and mental health."
    ],
    "c_categories":[
      "q-bio.OT"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.07031",
    "a_title":"Evaluating the Accuracy of Chatbots in Financial Literature",
    "a_abstract":"We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview\nversions), and Gemini Advanced, in providing references on financial literature\nand employing novel methodologies. Alongside the conventional binary approach\ncommonly used in the literature, we developed a nonbinary approach and a\nrecency measure to assess how hallucination rates vary with how recent a topic\nis. After analyzing 150 citations, ChatGPT-4o had a hallucination rate of 20.0%\n(95% CI, 13.6%-26.4%), while the o1-preview had a hallucination rate of 21.3%\n(95% CI, 14.8%-27.9%). In contrast, Gemini Advanced exhibited higher\nhallucination rates: 76.7% (95% CI, 69.9%-83.4%). While hallucination rates\nincreased for more recent topics, this trend was not statistically significant\nfor Gemini Advanced. These findings emphasize the importance of verifying\nchatbot-provided references, particularly in rapidly evolving fields.",
    "explanation":"We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview versions), and Gemini Advanced, in providing references on financial literature and employing novel methodologies.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "ChatGPT Hallucinates Non-existent Citations: Evidence from Economics"
    ],
    "b_abstract":[
      "In this study, we generate prompts derived from every topic within the Journal of Economic Literature to assess abilities both GPT-3.5 and GPT-4 versions ChatGPT large language model (LLM) write about economic concepts. demonstrates considerable competency in offering general summaries but also cites non-existent references. More than 30% citations provided by version do not exist rate is only slightly reduced for version. Additionally, our findings suggest that reliability decreases as become more specific. We provide quantitative evidence errors output demonstrate importance LLM verification. JEL Codes: B4; O33; I2"
    ],
    "b_categories":[
      "q-fin.ST"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "2503.04153"
    ],
    "c_title":[
      "KidneyTalk-open: No-code Deployment of a Private Large Language Model\n  with Medical Documentation-Enhanced Knowledge Database for Kidney Disease"
    ],
    "c_abstract":[
      "Privacy-preserving medical decision support for kidney disease requires\nlocalized deployment of large language models (LLMs) while maintaining clinical\nreasoning capabilities. Current solutions face three challenges: 1) Cloud-based\nLLMs pose data security risks; 2) Local model deployment demands technical\nexpertise; 3) General LLMs lack mechanisms to integrate medical knowledge.\nRetrieval-augmented systems also struggle with medical document processing and\nclinical usability. We developed KidneyTalk-open, a desktop system integrating\nthree technical components: 1) No-code deployment of state-of-the-art (SOTA)\nopen-source LLMs (such as DeepSeek-r1, Qwen2.5) via local inference engine; 2)\nMedical document processing pipeline combining context-aware chunking and\nintelligent filtering; 3) Adaptive Retrieval and Augmentation Pipeline (AddRep)\nemploying agents collaboration for improving the recall rate of medical\ndocuments. A graphical interface was designed to enable clinicians to manage\nmedical documents and conduct AI-powered consultations without technical\nexpertise. Experimental validation on 1,455 challenging nephrology exam\nquestions demonstrates AddRep's effectiveness: achieving 29.1% accuracy (+8.1%\nover baseline) with intelligent knowledge integration, while maintaining\nrobustness through 4.9% rejection rate to suppress hallucinations. Comparative\ncase studies with the mainstream products (AnythingLLM, Chatbox, GPT4ALL)\ndemonstrate KidneyTalk-open's superior performance in real clinical query.\nKidneyTalk-open represents the first no-code medical LLM system enabling secure\ndocumentation-enhanced medical Q&A on desktop. Its designs establishes a new\nframework for privacy-sensitive clinical AI applications. The system\nsignificantly lowers technical barriers while improving evidence traceability,\nenabling more medical staff or patients to use SOTA open-source LLMs\nconveniently."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.07031",
    "a_title":"Evaluating the Accuracy of Chatbots in Financial Literature",
    "a_abstract":"We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview\nversions), and Gemini Advanced, in providing references on financial literature\nand employing novel methodologies. Alongside the conventional binary approach\ncommonly used in the literature, we developed a nonbinary approach and a\nrecency measure to assess how hallucination rates vary with how recent a topic\nis. After analyzing 150 citations, ChatGPT-4o had a hallucination rate of 20.0%\n(95% CI, 13.6%-26.4%), while the o1-preview had a hallucination rate of 21.3%\n(95% CI, 14.8%-27.9%). In contrast, Gemini Advanced exhibited higher\nhallucination rates: 76.7% (95% CI, 69.9%-83.4%). While hallucination rates\nincreased for more recent topics, this trend was not statistically significant\nfor Gemini Advanced. These findings emphasize the importance of verifying\nchatbot-provided references, particularly in rapidly evolving fields.",
    "explanation":"We evaluate the reliability of two chatbots, ChatGPT (4o and o1-preview versions), and Gemini Advanced, in providing references on financial literature and employing novel methodologies.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Accuracy of Chatbots in Citing Journal Articles"
    ],
    "b_abstract":[
      "This cross-sectional study quantifies the journal article citation error rate of an artificial intelligence chatbot."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.15787"
    ],
    "c_title":[
      "Analysis of the Impact of the Union Budget Announcements on the Indian\n  Stock Market: A Fractal Perspective"
    ],
    "c_abstract":[
      "The stock market closely monitors macroeconomic policy announcements, such as\nannual budget events, due to their substantial influence on various economic\nparticipants. These events tend to impact the stock markets initially before\naffecting the real sector. Our study aims to analyze the effects of the budget\non the Indian stock market, specifically focusing on the announcement for the\nyear 2024. We will compare this with the years 2023, 2022, and 2020, assessing\nits impact on the NIFTY50 index using average abnormal return (AAR) and\ncumulative average abnormal return (CAAR) over a period of -15 and +15 days,\nincluding the budget day. This study utilizes an innovative approach involving\nthe fractal interpolation function, paired with fractal dimensional analysis,\nto study the fluctuations arising from budget announcements. The fractal\nperspective on the data offers an effective framework for understanding complex\nvariations."
    ],
    "c_categories":[
      "q-fin.ST"
    ],
    "c_fields":[
      "Economics and Quantitative Finance"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06184",
    "a_title":"Alleviating Hyperparameter-Tuning Burden in SVM Classifiers for\n  Pulmonary Nodules Diagnosis with Multi-Task Bayesian Optimization",
    "a_abstract":"In the field of non-invasive medical imaging, radiomic features are utilized\nto measure tumor characteristics. However, these features can be affected by\nthe techniques used to discretize the images, ultimately impacting the accuracy\nof diagnosis. To investigate the influence of various image discretization\nmethods on diagnosis, it is common practice to evaluate multiple discretization\nstrategies individually. This approach often leads to redundant and\ntime-consuming tasks such as training predictive models and fine-tuning\nhyperparameters separately. This study examines the feasibility of employing\nmulti-task Bayesian optimization to accelerate the hyperparameters search for\nclassifying benign and malignant pulmonary nodules using RBF SVM. Our findings\nsuggest that multi-task Bayesian optimization significantly accelerates the\nsearch for hyperparameters in comparison to a single-task approach. To the best\nof our knowledge, this is the first investigation to utilize multi-task\nBayesian optimization in a critical medical context.",
    "explanation":"This study examines the feasibility of employing multi-task Bayesian optimization to accelerate the hyperparameters search for classifying benign and malignant pulmonary nodules using RBF SVM.",
    "b_id":[
      "b6",
      "b7"
    ],
    "b_title":[
      "Multi-Task Bayesian Optimization",
      "Taking the Human Out of the Loop: A Review of Bayesian Optimization"
    ],
    "b_abstract":[
      "Bayesian optimization has recently been proposed as a framework for automatically tuning the hyperparameters of machine learning models and shown to yield state-of-the-art performance with impressive ease efficiency. In this paper, we explore whether it is possible transfer knowledge gained from previous optimizations new tasks in order find optimal hyperparameter settings more efficiently. Our approach based on extending multi-task Gaussian processes optimization. We show that method significantly speeds up process when compared standard single-task approach. further propose straightforward extension our algorithm jointly minimize average error across multiple demonstrate how can be used greatly speed k-fold cross-validation. Lastly, an adaptation developed acquisition function, entropy search, cost-sensitive, setting. utility function by leveraging small dataset hyper-parameter large dataset. dynamically chooses which query most information per unit cost.",
      "Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing storage architectures. The construction such involves many distributed design choices. end products (e.g., recommendation medical analysis tools, real-time game engines, speech recognizers) thus involve tunable configuration parameters. These parameters often specified hard-coded into the by various developers or teams. If optimized jointly, these can result in significant improvements. Bayesian optimization is a powerful tool for joint choices that gaining great popularity recent years. It promises greater automation so as to increase both product quality human productivity. This review paper introduces optimization, highlights some its methodological aspects, showcases wide range applications."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2503.03131"
    ],
    "c_title":[
      "Spatially-Structured Models of Viral Dynamics: A Scoping Review"
    ],
    "c_abstract":[
      "There is growing recognition in both the experimental and modelling\nliterature of the importance of spatial structure to the dynamics of viral\ninfections in tissues. Aided by the evolution of computing power and motivated\nby recent biological insights, there has been an explosion of new,\nspatially-explicit models for within-host viral dynamics in recent years. This\ndevelopment has only been accelerated in the wake of the COVID-19 pandemic.\nSpatially-structured models offer improved biological realism and can account\nfor dynamics which cannot be well-described by conventional, mean-field\napproaches. However, despite their growing popularity, spatially-structured\nmodels of viral dynamics are underused in biological applications. One major\nobstacle to the wider application of such models is the huge variety in\napproaches taken, with little consensus as to which features should be included\nand how they should be implemented for a given biological context. Previous\nreviews of the field have focused on specific modelling frameworks or on models\nfor particular viral species. Here, we instead apply a scoping review approach\nto the literature of spatially-structured viral dynamics models as a whole to\nprovide an exhaustive update of the state of the field. Our analysis is\nstructured along two axes, methodology and viral species, in order to examine\nthe breadth of techniques used and the requirements of different biological\napplications. We then discuss the contributions of mathematical and\ncomputational modelling to our understanding of key spatially-structured\naspects of viral dynamics, and suggest key themes for future model development\nto improve robustness and biological utility."
    ],
    "c_categories":[
      "q-bio.QM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06184",
    "a_title":"Alleviating Hyperparameter-Tuning Burden in SVM Classifiers for\n  Pulmonary Nodules Diagnosis with Multi-Task Bayesian Optimization",
    "a_abstract":"In the field of non-invasive medical imaging, radiomic features are utilized\nto measure tumor characteristics. However, these features can be affected by\nthe techniques used to discretize the images, ultimately impacting the accuracy\nof diagnosis. To investigate the influence of various image discretization\nmethods on diagnosis, it is common practice to evaluate multiple discretization\nstrategies individually. This approach often leads to redundant and\ntime-consuming tasks such as training predictive models and fine-tuning\nhyperparameters separately. This study examines the feasibility of employing\nmulti-task Bayesian optimization to accelerate the hyperparameters search for\nclassifying benign and malignant pulmonary nodules using RBF SVM. Our findings\nsuggest that multi-task Bayesian optimization significantly accelerates the\nsearch for hyperparameters in comparison to a single-task approach. To the best\nof our knowledge, this is the first investigation to utilize multi-task\nBayesian optimization in a critical medical context.",
    "explanation":"This study examines the feasibility of employing multi-task Bayesian optimization to accelerate the hyperparameters search for classifying benign and malignant pulmonary nodules using RBF SVM.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "New Pathologic Classification of Lung Cancer: Relevance for Clinical Practice and Clinical Trials"
    ],
    "b_abstract":[
      "We summarize significant changes in pathologic classification of lung cancer resulting from the 2011 International Association for Study Lung Cancer\/American Thoracic Society\/European Respiratory Society (IASLC\/ATS\/ERS) adenocarcinoma classification. The was developed by an international core panel experts representing IASLC, ATS, and ERS with oncologists\/pulmonologists, pathologists, radiologists, molecular biologists, thoracic surgeons. Because 70% patients present advanced stages, a new approach to small biopsies cytology specific terminology criteria focused on need distinguishing squamous cell carcinoma testing EGFR mutations ALK rearrangement. Tumors previously classified as non-small-cell carcinoma, not otherwise specified, because lack clear or morphology should be further using limited immunohistochemical workup preserve tissue testing. terms \"bronchioloalveolar carcinoma\" \"mixed subtype adenocarcinoma\" have been discontinued. For resected adenocarcinomas, concepts situ minimally invasive define who, if they undergo complete resection, will 100% disease-free survival. Invasive adenocarcinomas are now predominant pattern after comprehensive histologic subtyping lepidic, acinar, papillary, solid patterns; micropapillary is added poor prognosis. Former mucinous bronchioloalveolar carcinomas called \"invasive adenocarcinoma.\" field rapidly evolving advances occurring frequent basis, particularly arena, this provides much needed standard diagnosis only patient care but also clinical trials TNM"
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.19000"
    ],
    "c_title":[
      "Bilevel optimization for the deployment of refuelling stations for\n  electric vehicles on road networks"
    ],
    "c_abstract":[
      "This work consists of a procedure to optimally select, among a group of\ncandidate sites where gas stations were already located, a sufficient number of\ncharging points in order to guarantee that an electric vehicle can make its\njourney without a problem of energy autonomy and that each selected charging\nstation has another one that serves as useful support in case of failure\n(reinforced coverage service). For this purpose, we propose a bilevel model\nthat, in a former level, minimizes the number of refuelling points necessary to\nguarantee a reinforced service coverage for all users who transit from their\norigin to destination and, as a second level, maximize the volume of demand\nthat can be satisfied subject to budgetary restrictions. With the first of the\nobjectives we are addressing the typical requirement of the administration,\nwhich consists of guaranteeing the viability of the solutions, and the second\nof the objectives is a criterion typically used by the private sector\ninitiative, compatible with the profit maximization."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.20675",
    "a_title":"Improved ICNN-LSTM Model Classification Based on Attitude Sensor Data\n  for Hazardous State Assessment of Magnetic Adhesion Climbing Wall Robots",
    "a_abstract":"Magnetic adhesion tracked climbing robots are widely utilized in\nhigh-altitude inspection, welding, and cleaning tasks due to their ability to\nperform various operations against gravity on vertical or inclined walls.\nHowever, during operation, the robot may experience overturning torque caused\nby its own weight and load, which can lead to the detachment of magnetic plates\nand subsequently pose safety risks. This paper proposes an improved ICNN-LSTM\nnetwork classification method based on Micro-Electro-Mechanical Systems (MEMS)\nattitude sensor data for real-time monitoring and assessment of hazardous\nstates in magnetic adhesion tracked climbing robots. Firstly, a data\nacquisition strategy for attitude sensors capable of capturing minute\nvibrations is designed. Secondly, a feature extraction and classification model\ncombining an Improved Convolutional Neural Network (ICNN) with a Long\nShort-Term Memory (LSTM) network is proposed. Experimental validation\ndemonstrates that the proposed minute vibration sensing method achieves\nsignificant results, and the proposed classification model consistently\nexhibits high accuracy compared to other models. The research findings provide\neffective technical support for the safe operation of climbing robots",
    "explanation":"This paper proposes an improved ICNN-LSTM network classification method based on Micro-Electro-Mechanical Systems (MEMS) attitude sensor data for real-time monitoring and assessment of hazardous states in magnetic adhesion tracked climbing robots.",
    "b_id":[
      "b13"
    ],
    "b_title":[
      "Discriminative feature learning using a multiscale convolutional capsule network from attitude data for fault diagnosis of industrial robots"
    ],
    "b_abstract":[
      "Effective fault diagnosis is important to ensure the reliability, safety, and efficiency of industrial robots. This article proposes a simple yet effective data acquisition strategy based on transmission mechanism analysis, using only one attitude sensor mounted on an end effector or an output component to monitor the attitude of all transmission components. Unlike widely used vibration-monitoring signals, attitude signals can provide fault features reflecting spatial relationships. Using one attitude sensor facilitates the data collection, but weakens fault features and introduces strong background noise in attitude signals. To learn discriminative features from the attitude data collected by the attitude sensor, a multiscale convolutional capsule network (MCCN) is proposed. In MCCN, integrating low-level and high-level features in a convolutional neural network (CNN) as multiscale features is conductive to noise reduction and robust feature extraction, and a capsule network (CapsNet) is used to recognize the spatial relationships in attitude data. The extracted multiscale features in CNN and the spatial-relational features in CapsNet are fused for effective fault diagnosis of industrial robots. The performance of MCCN is evaluated by attaching a softmax-based classifier and integrating it into different transfer learning frameworks to diagnose faults in industrial robots under single and variable working conditions, respectively. Fault diagnosis experiments were conducted on a 6-axis series industrial robot and a parallel robot-driven 3D printer. The superiority of the proposed MCCN was demonstrated by comparing its performance with the other feature learning methods."
    ],
    "b_categories":[
      "eess.SP"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04441"
    ],
    "c_title":[
      "Motif Discovery Framework for Psychiatric EEG Data Classification"
    ],
    "c_abstract":[
      "In current medical practice, patients undergoing depression treatment must\nwait four to six weeks before a clinician can assess medication response due to\nthe delayed noticeable effects of antidepressants. Identification of a\ntreatment response at any earlier stage is of great importance, since it can\nreduce the emotional and economic burden connected with the treatment. We\napproach the prediction of a patient response to a treatment as a\nclassification problem, by utilizing the dynamic properties of EEG recordings\non the 7th day of the treatment. We present a novel framework that applies\nmotif discovery to extract meaningful features from EEG data distinguishing\nbetween depression treatment responders and non-responders. We applied our\nframework also to classification tasks in other psychiatric EEG datasets,\nnamely to patients with symptoms of schizophrenia, pediatric patients with\nintractable seizures, and Alzheimer disease and dementia. We achieved high\nclassification precision in all data sets. The results demonstrate that the\ndynamic properties of the EEGs may support clinicians in decision making both\nin diagnosis and in the prediction depression treatment response as early as on\nthe 7th day of the treatment. To our best knowledge, our work is the first one\nusing motifs in the depression diagnostics in general."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.20675",
    "a_title":"Improved ICNN-LSTM Model Classification Based on Attitude Sensor Data\n  for Hazardous State Assessment of Magnetic Adhesion Climbing Wall Robots",
    "a_abstract":"Magnetic adhesion tracked climbing robots are widely utilized in\nhigh-altitude inspection, welding, and cleaning tasks due to their ability to\nperform various operations against gravity on vertical or inclined walls.\nHowever, during operation, the robot may experience overturning torque caused\nby its own weight and load, which can lead to the detachment of magnetic plates\nand subsequently pose safety risks. This paper proposes an improved ICNN-LSTM\nnetwork classification method based on Micro-Electro-Mechanical Systems (MEMS)\nattitude sensor data for real-time monitoring and assessment of hazardous\nstates in magnetic adhesion tracked climbing robots. Firstly, a data\nacquisition strategy for attitude sensors capable of capturing minute\nvibrations is designed. Secondly, a feature extraction and classification model\ncombining an Improved Convolutional Neural Network (ICNN) with a Long\nShort-Term Memory (LSTM) network is proposed. Experimental validation\ndemonstrates that the proposed minute vibration sensing method achieves\nsignificant results, and the proposed classification model consistently\nexhibits high accuracy compared to other models. The research findings provide\neffective technical support for the safe operation of climbing robots",
    "explanation":"This paper proposes an improved ICNN-LSTM network classification method based on Micro-Electro-Mechanical Systems (MEMS) attitude sensor data for real-time monitoring and assessment of hazardous states in magnetic adhesion tracked climbing robots.",
    "b_id":[
      "b21"
    ],
    "b_title":[
      "LSTM Based Bearing Fault Diagnosis of Electrical Machines using Motor Current Signal"
    ],
    "b_abstract":[
      "Rolling element bearings are one of the most critical components rotating machinery, with bearing faults amounting up to 50% in electrical machines. Therefore, fault diagnosis has attracted attention many researchers. Typically, is performed using vibration signals from machine. In addition, by deep learning algorithms on signals, detection accuracy close 100% can be achieved. However, measurement requires an additional sensor, which not present majority Nevertheless, alternative approach, stator current used for diagnosis. paper emphasizes current. The signal processing signature extraction that buried underneath noise signal. uses Paderborn University damaged dataset, contains data healthy, real inner raceway and outer different severity. For redundant frequencies filtered, then filtered eight features extracted time time-frequency domain wavelet packet decomposition (WPD). Then, these well known algorithm Long Short-Term Memory (LSTM), classification made. LSTM mostly speech recognition due its coherence, but this paper, ability also demonstrated 96%, outperforms perform method developed independent speed loading conditions."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.13339"
    ],
    "c_title":[
      "Joint Beamforming and Position Optimization for Fluid RIS-aided ISAC\n  Systems"
    ],
    "c_abstract":[
      "A fluid reconfigurable intelligent surface (fRIS)-aided integrated sensing\nand communications (ISAC) system is proposed to enhance multi-target sensing\nand multi-user communication. Unlike the conventional RIS, the fRIS\nincorporates movable elements whose positions can be flexibly adjusted to\nprovide extra spatial degrees of freedom. In this system, a joint optimization\nproblem is formulated to minimize sensing beampattern mismatch and\ncommunication symbol estimation error by optimizing the symbol estimator,\ntransmit beamformer, fRIS phase shifts, and element positions. To solve this\nproblem, an algorithm based on alternating minimization is devised, where\nsubproblems are solved leveraging augmented Lagrangian method, quadratic\nprogramming, semidefinite-relaxation, and majorization-minimization techniques.\nA key challenge exists that the fRIS element positions affect both the incident\nand reflective channels, leading to the high-order composite functions\nregarding the positions. As a remedy, it is proved that the high-order terms\ncan be transformed to linear and linear-difference forms using the\ncharacteristics of fRIS and structural channels, which facilitates the position\noptimization. Numerical results validate the effectiveness of the proposed\nscheme as compared to the conventional RIS-aided ISAC systems and other\nbenchmarks."
    ],
    "c_categories":[
      "eess.SP"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.10403",
    "a_title":"On the Foundation Model for Cardiac MRI Reconstruction",
    "a_abstract":"In recent years, machine learning (ML) based reconstruction has been widely\ninvestigated and employed in cardiac magnetic resonance (CMR) imaging. ML-based\nreconstructions can deliver clinically acceptable image quality under\nsubstantially accelerated scans. ML-based reconstruction, however, also\nrequires substantial data and computational time to train the neural network,\nwhich is often optimized for a fixed acceleration rate or image contrast. In\npractice, imaging parameters are often tuned to best suit the diagnosis, which\nmay differ from the training data. This can result in degraded image quality,\nand multiple trained networks are needed to fulfill the clinical demands. In\nthis study, we propose a foundation model that uses adaptive unrolling,\nchannel-shifting, and Pattern and Contrast-Prompt-UNet (PCP-UNet) to tackle the\nproblem. In particular, the undersampled data goes through a different number\nof unrolled iterations according to its acceleration rate. Channel-shifting\nimproves reconstructed data quality. The PCP-UNet is equipped with an image\ncontrast and sampling pattern prompt. In vivo CMR experiments were performed\nusing mixed combinations of image contrasts, acceleration rates, and\n(under)sampling patterns. The proposed foundation model has significantly\nimproved image quality for a wide range of CMR protocols and outperforms the\nconventional ML-based method.",
    "explanation":"n this study, we propose\na foundation model that uses adaptive unrolling, channel-shifting, and\nPattern and Contrast-Prompt-UNet (PCP-UNet) to tackle the problem.\nIn particular, the undersampled data goes through a different number\nof unrolled iterations according to its acceleration rate. Channel-shifting\nimproves reconstructed data quality.",
    "b_id":[
      "b14",
      "b1"
    ],
    "b_title":[
      "Sparse MRI: The application of compressed sensing for rapid MR imaging",
      "MoDL: Model-Based Deep Learning Architecture for Inverse Problems"
    ],
    "b_abstract":[
      "Abstract The sparsity which is implicit in MR images exploited to significantly undersample k \u2010space. Some such as angiograms are already sparse the pixel representation; other, more complicated have a representation some transform domain\u2013for example, terms of spatial finite\u2010differences or their wavelet coefficients. According recently developed mathematical theory compressed\u2010sensing, with can be recovered from randomly undersampled \u2010space data, provided an appropriate nonlinear recovery scheme used. Intuitively, artifacts due random undersampling add noise\u2010like interference. In domain significant coefficients stand out above A thresholding recover coefficients, effectively recovering image itself. this article, practical incoherent schemes and analyzed by means aliasing Incoherence introduced pseudo\u2010random variable\u2010density phase\u2010encodes. reconstruction performed minimizing \u2113 1 norm transformed image, subject data fidelity constraints. Examples demonstrate improved resolution accelerated acquisition for multislice fast spin\u2010echo brain imaging 3D contrast enhanced angiography. Magn Reson Med, 2007. \u00a9 2007 Wiley\u2010Liss, Inc.",
      "We introduce a model-based image reconstruction framework with convolution neural network (CNN)-based regularization prior. The proposed formulation provides systematic approach for deriving deep architectures inverse problems the arbitrary structure. Since forward model is explicitly accounted for, smaller fewer parameters sufficient to capture information compared direct inversion approaches. Thus, reducing demand training data and time. we rely on end-to-end weight sharing across iterations, CNN weights are customized model, thus offering improved performance over approaches that pre-trained denoisers. Our experiments show decoupling of number iterations from complexity offered by this benefits, including lower data, reduced risk overfitting, implementations significantly memory footprint. propose enforce data-consistency using numerical optimization blocks, such as conjugate gradients algorithm within network. This offers faster convergence per iteration, methods proximal steps consistency. translates performance, primarily when available GPU restricts iterations."
    ],
    "b_categories":[
      "cs.LG",
      "stat.CO"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science",
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2503.13627"
    ],
    "c_title":[
      "Optimal compound downselection to promote diversity and parallel\n  chemistry"
    ],
    "c_abstract":[
      "Early stage drug discovery and molecular design projects often follow\niterative design-make-test cycles. The selection of which compounds to\nsynthesize from all possible candidate compounds is a complex decision inherent\nto these design cycles that must weigh multiple factors. We build upon the\nalgorithmic downselection framework SPARROW that considers synthetic cost,\nsynthetic feasibility, and compound utility, extending it to address additional\ncritical factors related to the risk of synthesis failure, molecular diversity,\nand parallel chemistry capabilities. These design considerations further align\nalgorithmic compound selection with the true complexity of this decision-making\nprocess, allowing SPARROW to capture a broader set of principles typically\nreliant on expert chemist intuition. The application of these formulations to\nan exemplary case study highlights SPARROW's ability to promote the selection\nof diverse batches of compounds whose syntheses are amenable to parallel\nchemistry."
    ],
    "c_categories":[
      "q-bio.QM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.10403",
    "a_title":"On the Foundation Model for Cardiac MRI Reconstruction",
    "a_abstract":"In recent years, machine learning (ML) based reconstruction has been widely\ninvestigated and employed in cardiac magnetic resonance (CMR) imaging. ML-based\nreconstructions can deliver clinically acceptable image quality under\nsubstantially accelerated scans. ML-based reconstruction, however, also\nrequires substantial data and computational time to train the neural network,\nwhich is often optimized for a fixed acceleration rate or image contrast. In\npractice, imaging parameters are often tuned to best suit the diagnosis, which\nmay differ from the training data. This can result in degraded image quality,\nand multiple trained networks are needed to fulfill the clinical demands. In\nthis study, we propose a foundation model that uses adaptive unrolling,\nchannel-shifting, and Pattern and Contrast-Prompt-UNet (PCP-UNet) to tackle the\nproblem. In particular, the undersampled data goes through a different number\nof unrolled iterations according to its acceleration rate. Channel-shifting\nimproves reconstructed data quality. The PCP-UNet is equipped with an image\ncontrast and sampling pattern prompt. In vivo CMR experiments were performed\nusing mixed combinations of image contrasts, acceleration rates, and\n(under)sampling patterns. The proposed foundation model has significantly\nimproved image quality for a wide range of CMR protocols and outperforms the\nconventional ML-based method.",
    "explanation":"n this study, we propose\na foundation model that uses adaptive unrolling, channel-shifting, and\nPattern and Contrast-Prompt-UNet (PCP-UNet) to tackle the problem.\nIn particular, the undersampled data goes through a different number\nof unrolled iterations according to its acceleration rate. Channel-shifting\nimproves reconstructed data quality.",
    "b_id":[
      "b13"
    ],
    "b_title":[
      "Cardiovascular Flow Measurement with Phase-Contrast MR Imaging: Basic Facts and Implementation"
    ],
    "b_abstract":[
      "Phase-contrast magnetic resonance (MR) imaging is a well-known but undervalued method of obtaining quantitative information on blood flow. Applications this technique in cardiovascular MR are expanding. According to the sequences available, phase-contrast measurement can be performed breath hold or during normal respiration. Prospective as well retrospective gating techniques used. Common errors include mismatched encoding velocity, deviation plane, inadequate temporal resolution, spatial accelerated flow and misregistration, phase offset errors. Flow measurements most precise if plane perpendicular vessel interest set through-plane The sequence should repeated at least once, with high velocity used initially. If peak has estimated, an adapted velocity. overall error comprises prescription that occur image analysis data. With imaging, reduced less than 10%, acceptable level for routine clinical use."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.03604"
    ],
    "c_title":[
      "Bilevel ZOFO: Bridging Parameter-Efficient and Zeroth-Order Techniques\n  for Efficient LLM Fine-Tuning and Meta-Training"
    ],
    "c_abstract":[
      "Fine-tuning pre-trained Large Language Models (LLMs) for downstream tasks\nusing First-Order (FO) optimizers presents significant computational\nchallenges. Parameter-Efficient Fine-Tuning(PEFT) methods have been proposed to\naddress these challenges by freezing most model parameters and training only a\nsmall subset. While PEFT is efficient, it may not outperform full fine-tuning\nwhen high task-specific performance is required. Zeroth-Order (ZO) methods\noffer an alternative for fine-tuning the entire pre-trained model by\napproximating gradients using only the forward pass, thus eliminating the\ncomputational burden of back-propagation in first-order methods. However, when\nimplementing ZO methods, a hard prompt is crucial, and relying on simple, fixed\nhard prompts may not be optimal. In this paper, we propose a bilevel\noptimization framework that complements ZO methods with PEFT to mitigate\nsensitivity to hard prompts while efficiently and effectively fine-tuning LLMs.\nOur Bilevel ZOFO (Zeroth-Order-First-Order) method employs a double-loop\noptimization strategy, where only the gradient of the PEFT model and the\nforward pass of the base model are required. We provide convergence guarantees\nfor Bilevel ZOFO. Empirically, we demonstrate that Bilevel ZOFO outperforms\nboth PEFT and ZO methods in single-task settings while maintaining similar\nmemory efficiency. Additionally, we show its strong potential for multitask\nlearning. Compared to current first-order meta-training algorithms for\nmultitask learning, our method has significantly lower computational demands\nwhile maintaining or improving performance."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.15202",
    "a_title":"A Comparison of Machine Learning Algorithms for Predicting Sea Surface\n  Temperature in the Great Barrier Reef Region",
    "a_abstract":"Predicting Sea Surface Temperature (SST) in the Great Barrier Reef (GBR)\nregion is crucial for the effective management of its fragile ecosystems. This\nstudy provides a rigorous comparative analysis of several machine learning\ntechniques to identify the most effective method for SST prediction in this\narea. We evaluate the performance of ridge regression, Least Absolute Shrinkage\nand Selection Operator (LASSO), Random Forest, and Extreme Gradient Boosting\n(XGBoost) algorithms. Our results reveal that while LASSO and ridge regression\nperform well, Random Forest and XGBoost significantly outperform them in terms\nof predictive accuracy, as evidenced by lower Mean Squared Error (MSE), Mean\nAbsolute Error (MAE), and Root Mean Squared Prediction Error (RMSPE).\nAdditionally, XGBoost demonstrated superior performance in minimizing Kullback-\nLeibler Divergence (KLD), indicating a closer alignment of predicted\nprobability distributions with actual observations. These findings highlight\nthe efficacy of using ensemble methods, particularly XGBoost, for predicting\nsea surface temperatures, making them valuable tools for climatological and\nenvironmental modeling.",
    "explanation":"This study provides a rigorous comparative\nanalysis of several machine learning techniques to identify the most effective method for SST\nprediction in this area. We evaluate the performance of ridge regression, Least Absolute Shrinkage\nand Selection Operator (LASSO), Random Forest, and Extreme Gradient Boosting (XGBoost)\nalgorithms. Our results reveal that while LASSO and ridge regression perform well, Random Forest\nand XGBoost significantly outperform them in terms of predictive accuracy, as evidenced by lower\nMean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Prediction\nError (RMSPE).",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "The Great Barrier Reef: an environmental history"
    ],
    "b_abstract":[
      "Reconstructing changes in the Great Barrier Reef 15 3 The natural context of 33 4 spread European settlement coastal Queensland 43 5 beche--de ... mer, pearl shell and trochus fisheries 55 6 Impacts on marine turtles 72 7 dugongs 95 8 whales, sharks fish 9 impacts coral collecting 10 guano rock phosphate mining 11 vi Contents 12 Other reefs 13 Changes island biota 14 Conclusion"
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.13273"
    ],
    "c_title":[
      "Enhancing Robust Fairness via Confusional Spectral Regularization"
    ],
    "c_abstract":[
      "Recent research has highlighted a critical issue known as ``robust fairness\",\nwhere robust accuracy varies significantly across different classes,\nundermining the reliability of deep neural networks (DNNs). A common approach\nto address this has been to dynamically reweight classes during training,\ngiving more weight to those with lower empirical robust performance. However,\nwe find there is a divergence of class-wise robust performance between training\nset and testing set, which limits the effectiveness of these explicit\nreweighting methods, indicating the need for a principled alternative. In this\nwork, we derive a robust generalization bound for the worst-class robust error\nwithin the PAC-Bayesian framework, accounting for unknown data distributions.\nOur analysis shows that the worst-class robust error is influenced by two main\nfactors: the spectral norm of the empirical robust confusion matrix and the\ninformation embedded in the model and training set. While the latter has been\nextensively studied, we propose a novel regularization technique targeting the\nspectral norm of the robust confusion matrix to improve worst-class robust\naccuracy and enhance robust fairness. We validate our approach through\ncomprehensive experiments on various datasets and models, demonstrating its\neffectiveness in enhancing robust fairness."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.15202",
    "a_title":"A Comparison of Machine Learning Algorithms for Predicting Sea Surface\n  Temperature in the Great Barrier Reef Region",
    "a_abstract":"Predicting Sea Surface Temperature (SST) in the Great Barrier Reef (GBR)\nregion is crucial for the effective management of its fragile ecosystems. This\nstudy provides a rigorous comparative analysis of several machine learning\ntechniques to identify the most effective method for SST prediction in this\narea. We evaluate the performance of ridge regression, Least Absolute Shrinkage\nand Selection Operator (LASSO), Random Forest, and Extreme Gradient Boosting\n(XGBoost) algorithms. Our results reveal that while LASSO and ridge regression\nperform well, Random Forest and XGBoost significantly outperform them in terms\nof predictive accuracy, as evidenced by lower Mean Squared Error (MSE), Mean\nAbsolute Error (MAE), and Root Mean Squared Prediction Error (RMSPE).\nAdditionally, XGBoost demonstrated superior performance in minimizing Kullback-\nLeibler Divergence (KLD), indicating a closer alignment of predicted\nprobability distributions with actual observations. These findings highlight\nthe efficacy of using ensemble methods, particularly XGBoost, for predicting\nsea surface temperatures, making them valuable tools for climatological and\nenvironmental modeling.",
    "explanation":"This study provides a rigorous comparative\nanalysis of several machine learning techniques to identify the most effective method for SST\nprediction in this area. We evaluate the performance of ridge regression, Least Absolute Shrinkage\nand Selection Operator (LASSO), Random Forest, and Extreme Gradient Boosting (XGBoost)\nalgorithms. Our results reveal that while LASSO and ridge regression perform well, Random Forest\nand XGBoost significantly outperform them in terms of predictive accuracy, as evidenced by lower\nMean Squared Error (MSE), Mean Absolute Error (MAE), and Root Mean Squared Prediction\nError (RMSPE).",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Ilf-lstm: Enhanced loss function in lstm to predict the sea surface temperature"
    ],
    "b_abstract":[
      "Globe's primary issue is global warming, water temperatures have accompanied it as the sea surface temperature, and it is the primary attribute to balance the energy on the earth's surface. Sea surface temperature prediction is vital to climate forecast. Downwelling currents carry some of this heat to the ocean's bottom layers, which are also heating, covering far behind the increase in sea surface temperature. In deep learning models, the correct loss function will try to reduce the error and converge fast. The proposed improved loss function correctly estimates how close the predictions made by the long short-term memory match the observed values in the training data. This research considers location-specific sea surface temperature predictions using the improved loss function in the long short-term memory neural network at six different locations around India for daily, weekly, and monthly time horizons. Most existing research concentrated on periodic forecasts, but this paper focused on daily, weekly, and monthly predictions. The improved loss function\u2014long short-term memory, achieved 98.7% accuracy, and this improved loss function overcomes the limitations of the existing techniques and reduces the processing time to\u2009~\u20090.35 s. In this research, the sea surface temperature prediction using the improved loss function in the long short-term memory neural network gives better results than the standard prediction models and other existing techniques by considering the long-time dependencies and obtaining features from the spatial data."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.13627"
    ],
    "c_title":[
      "Optimal compound downselection to promote diversity and parallel\n  chemistry"
    ],
    "c_abstract":[
      "Early stage drug discovery and molecular design projects often follow\niterative design-make-test cycles. The selection of which compounds to\nsynthesize from all possible candidate compounds is a complex decision inherent\nto these design cycles that must weigh multiple factors. We build upon the\nalgorithmic downselection framework SPARROW that considers synthetic cost,\nsynthetic feasibility, and compound utility, extending it to address additional\ncritical factors related to the risk of synthesis failure, molecular diversity,\nand parallel chemistry capabilities. These design considerations further align\nalgorithmic compound selection with the true complexity of this decision-making\nprocess, allowing SPARROW to capture a broader set of principles typically\nreliant on expert chemist intuition. The application of these formulations to\nan exemplary case study highlights SPARROW's ability to promote the selection\nof diverse batches of compounds whose syntheses are amenable to parallel\nchemistry."
    ],
    "c_categories":[
      "q-bio.QM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06741",
    "a_title":"Methane projections from Canada's oil sands tailings using scientific\n  deep learning reveal significant underestimation",
    "a_abstract":"Bitumen extraction for the production of synthetic crude oil in Canada's\nAthabasca Oil Sands industry has recently come under spotlight for being a\nsignificant source of greenhouse gas emission. A major cause of concern is\nmethane, a greenhouse gas produced by the anaerobic biodegradation of\nhydrocarbons in oil sands residues, or tailings, stored in settle basins\ncommonly known as oil sands tailing ponds. In order to determine the methane\nemitting potential of these tailing ponds and have future methane projections,\nwe use real-time weather data, mechanistic models developed from laboratory\ncontrolled experiments, and industrial reports to train a physics constrained\nmachine learning model. Our trained model can successfully identify the\ndirections of active ponds and estimate their emission levels, which are\ngenerally hard to obtain due to data sampling restrictions. We found that each\nactive oil sands tailing pond could emit between 950 to 1500 tonnes of methane\nper year, whose environmental impact is equivalent to carbon dioxide emissions\nfrom at least 6000 gasoline powered vehicles. Although abandoned ponds are\noften presumed to have insignificant emissions, our findings indicate that\nthese ponds could become active over time and potentially emit up to 1000\ntonnes of methane each year. Taking an average over all datasets that was used\nin model training, we estimate that emissions around major oil sands regions\nwould need to be reduced by approximately 12% over a year, to reduce the\naverage methane concentrations to 2005 levels.",
    "explanation":"In order\nto determine the methane emitting potential of these tailing ponds and have future methane projections,\nwe use real-time weather data, mechanistic models developed from laboratory controlled experiments,\nand industrial reports to train a physics constrained machine learning model.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Learning Polynomials with Neural Networks"
    ],
    "b_abstract":[
      "We study the effectiveness of learning low degree polynomials using neural networks by gradient descent method. While have been shown to great expressive power, and has widely used in practice for networks, few theoretical guarantees are known such methods. In particular, it is well that can get stuck at local minima, even simple classes target functions. this paper, we present several positive results support networks. focus on twolayer where bottom layer a set non-linear hidden nodes, top node linear function, similar Barron (1993). First show randomly initialized network with sufficiently many units, generic algorithm learns any polynomial, assuming initialize weights randomly. Secondly, if use complex-valued (the function still be real), then under suitable conditions, there no robust minima: always escape minimum performing random perturbation. This property does not hold real-valued weights. Thirdly, discuss whether sparse learned small size dependent sparsity function."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.15462"
    ],
    "c_title":[
      "Fast simulation of soft x-ray near-edge spectra using a relativistic\n  state-interaction approach: Application to closed-shell transition metal\n  complexes"
    ],
    "c_abstract":[
      "Spectroscopic techniques based on core-level excitations provide powerful\ntools for probing molecular and electronic structures with high spatial\nresolution. However, accurately calculating spectral features at the L or M\nedges is challenging due to the significant influence of spin-orbit and\nmultiplet effects. While scalar-relativistic effects can be incorporated at\nminimal computational cost, accounting for spin-orbit interactions requires\nmore complex computational frameworks. In this work, we develop and apply the\nstate-interaction approach, incorporating relativistic effects using the\nZORA-Kohn-Sham Hamiltonian, to simulate near-edge soft X-ray absorption spectra\nfor closed-shell transition metal complexes. The computed spin-orbit splittings\nclosely match those obtained from more rigorous methods. This approach provides\na practical and cost-effective alternative to more rigorous two-component\nmethods, making it particularly valuable for large-scale calculations and\napplications such as resonant inelastic X-ray scattering simulations, where\ncapturing a large number of excited states is essential."
    ],
    "c_categories":[
      "physics.chem-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06741",
    "a_title":"Methane projections from Canada's oil sands tailings using scientific\n  deep learning reveal significant underestimation",
    "a_abstract":"Bitumen extraction for the production of synthetic crude oil in Canada's\nAthabasca Oil Sands industry has recently come under spotlight for being a\nsignificant source of greenhouse gas emission. A major cause of concern is\nmethane, a greenhouse gas produced by the anaerobic biodegradation of\nhydrocarbons in oil sands residues, or tailings, stored in settle basins\ncommonly known as oil sands tailing ponds. In order to determine the methane\nemitting potential of these tailing ponds and have future methane projections,\nwe use real-time weather data, mechanistic models developed from laboratory\ncontrolled experiments, and industrial reports to train a physics constrained\nmachine learning model. Our trained model can successfully identify the\ndirections of active ponds and estimate their emission levels, which are\ngenerally hard to obtain due to data sampling restrictions. We found that each\nactive oil sands tailing pond could emit between 950 to 1500 tonnes of methane\nper year, whose environmental impact is equivalent to carbon dioxide emissions\nfrom at least 6000 gasoline powered vehicles. Although abandoned ponds are\noften presumed to have insignificant emissions, our findings indicate that\nthese ponds could become active over time and potentially emit up to 1000\ntonnes of methane each year. Taking an average over all datasets that was used\nin model training, we estimate that emissions around major oil sands regions\nwould need to be reduced by approximately 12% over a year, to reduce the\naverage methane concentrations to 2005 levels.",
    "explanation":"In order\nto determine the methane emitting potential of these tailing ponds and have future methane projections,\nwe use real-time weather data, mechanistic models developed from laboratory controlled experiments,\nand industrial reports to train a physics constrained machine learning model.",
    "b_id":[
      "b20"
    ],
    "b_title":[
      "Physics-informed machine learning"
    ],
    "b_abstract":[
      "Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems."
    ],
    "b_categories":[
      "physics.chem-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.03693"
    ],
    "c_title":[
      "ILLC: Iterative Layer-by-Layer Compression for Enhancing Structural\n  Faithfulness in SpArX"
    ],
    "c_abstract":[
      "In the field of Explainable Artificial Intelligence (XAI), argumentative XAI\napproaches have been proposed to represent the internal reasoning process of\ndeep neural networks in a more transparent way by interpreting hidden nodes as\narguements. However, as the number of layers increases, existing compression\nmethods simplify all layers at once, which lead to high accumulative\ninformation loss. To compensate for this, we propose an iterative\nlayer-by-layer compression technique in which each layer is compressed\nseparately and the reduction error in the next layer is immediately compensated\nfor, thereby improving the overall input-output and structural fidelity of the\nmodel. Experiments on the Breast Cancer Diagnosis dataset show that, compared\nto traditional compression, the method reduces input-output and structural\nunfaithfulness, and maintains a more consistent attack-support relationship in\nthe Argumentative Explanation scheme. This is significant because it provides a\nnew way to make complex MLP models more compact while still conveying their\ninternal inference logic without distortion."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.18259",
    "a_title":"Transfer Learning for Deep Learning-based Prediction of Lattice Thermal\n  Conductivity",
    "a_abstract":"Machine learning promises to accelerate the material discovery by enabling\nhigh-throughput prediction of desirable macro-properties from atomic-level\ndescriptors or structures. However, the limited data available about precise\nvalues of these properties have been a barrier, leading to predictive models\nwith limited precision or the ability to generalize. This is particularly true\nof lattice thermal conductivity (LTC): existing datasets of precise (ab initio,\nDFT-based) computed values are limited to a few dozen materials with little\nvariability. Based on such datasets, we study the impact of transfer learning\non both the precision and generalizability of a deep learning model\n(ParAIsite). We start from an existing model (MEGNet~\\cite{Chen2019}) and show\nthat improvements are obtained by fine-tuning a pre-trained version on\ndifferent tasks. Interestingly, we also show that a much greater improvement is\nobtained when first fine-tuning it on a large datasets of low-quality\napproximations of LTC (based on the AGL model) and then applying a second phase\nof fine-tuning with our high-quality, smaller-scale datasets. The promising\nresults obtained pave the way not only towards a greater ability to explore\nlarge databases in search of low thermal conductivity materials but also to\nmethods enabling increasingly precise predictions in areas where quality data\nare rare.",
    "explanation":"Machine learning promises to accelerate the material discovery by enabling high-throughput pre-\ndiction of desirable macro-properties from atomic-level descriptors or structures.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Physics-informed machine learning"
    ],
    "b_abstract":[
      "Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.01547"
    ],
    "c_title":[
      "Magnetic properties of Ge, Re and Cr substituted Fe$_5$SiB$_2$"
    ],
    "c_abstract":[
      "One of the possible approaches to decrease the demand for critical elements\nsuch as rare earths is to develop new sustainable magnets. Iron-based materials\nare suitable for gap magnets applications since iron is the most abundant\nferromagnetic element on Earth. Fe$_5$SiB$_2$ is a candidate as gap magnet\nthanks to its high Curie temperature (T$_{\\text{C}} \\sim$ 800 K) and saturation\nmagnetization (M$_{\\text{S}}\\sim$ 140 Am$^2$kg$^{-1}$). However its anisotropy\nfield is too low for applications (H$_{\\text{A}} \\sim$ 0.8 T). In order to\nincrease the anisotropy value, we synthesized a series of Ge, Re and Cr\nsubstituted Fe$_5$SiB$_2$ samples and studied their magnetic properties. They\nall crystallize in the Cr$_5$B$_3$-type tetragonal structure with the $I4\/mcm$\nspace group. Curie temperature (T$_{\\text{C}}$ = 803 K) and saturation\nmagnetization (M$_{\\text{S}}$ = 138 Am$^2$kg$^{-1}$) are slightly decreased by\nelemental substitution with Re having the largest effect. Despite being\nreduced, T$_{\\text{C}}$ and M$_{\\text{S}}$ still maintain significant values\n(T$_{\\text{C}}>$ 750 K and M$_{\\text{S}}$ = 118 Am$^2$kg$^{-1}$). The room\ntemperature anisotropy field has been measured by Singular Point Detection\n(SPD) and increases by about 15% upon Re substitution, reaching 0.92 T for\nFe$_{4.75}$Re$_{0.25}$SiB$_2$. We have also used Nuclear Magnetic Resonance and\nSPD measurements to study the spin reorientation transition which takes place\nat 172 K and we have found that it is partially suppressed by substitution of\nGe from 172 K to 140 K and completely suppressed upon Cr and Re substitution."
    ],
    "c_categories":[
      "cond-mat.mtrl-sci"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.18259",
    "a_title":"Transfer Learning for Deep Learning-based Prediction of Lattice Thermal\n  Conductivity",
    "a_abstract":"Machine learning promises to accelerate the material discovery by enabling\nhigh-throughput prediction of desirable macro-properties from atomic-level\ndescriptors or structures. However, the limited data available about precise\nvalues of these properties have been a barrier, leading to predictive models\nwith limited precision or the ability to generalize. This is particularly true\nof lattice thermal conductivity (LTC): existing datasets of precise (ab initio,\nDFT-based) computed values are limited to a few dozen materials with little\nvariability. Based on such datasets, we study the impact of transfer learning\non both the precision and generalizability of a deep learning model\n(ParAIsite). We start from an existing model (MEGNet~\\cite{Chen2019}) and show\nthat improvements are obtained by fine-tuning a pre-trained version on\ndifferent tasks. Interestingly, we also show that a much greater improvement is\nobtained when first fine-tuning it on a large datasets of low-quality\napproximations of LTC (based on the AGL model) and then applying a second phase\nof fine-tuning with our high-quality, smaller-scale datasets. The promising\nresults obtained pave the way not only towards a greater ability to explore\nlarge databases in search of low thermal conductivity materials but also to\nmethods enabling increasingly precise predictions in areas where quality data\nare rare.",
    "explanation":"Machine learning promises to accelerate the material discovery by enabling high-throughput pre-\ndiction of desirable macro-properties from atomic-level descriptors or structures.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Quantifying the performance of machine learning models in materials discovery"
    ],
    "b_abstract":[
      "The predictive capabilities of machine learning (ML) models used in materials discovery are typically measured using simple statistics such as the root-mean-square error (RMSE) or coefficient determination ($r^2$) between ML-predicted property values and their known values. A tempting assumption is that with low should be effective at guiding discovery, conversely, high give poor performance. However, we observe no clear connection exists a \"static\" quantity averaged across an entire training set, RMSE, ML model's ability to dynamically guide iterative (and often extrapolative) novel targeted properties. In this work, simulate sequential (SL)-guided process demonstrate decoupling traditional model metrics performance discoveries. We show depends strongly on (1) target range within distribution (e.g., whether 1st 10th decile material desired); (2) incorporation uncertainty estimates SL acquisition function; (3) scientist interested one many targets; (4) how iterations allowed. To overcome limitations static robustly capture performance, recommend Discovery Yield ($DY$), measure high-performing were discovered during SL, Probability ($DP$), likelihood discovering any point process."
    ],
    "b_categories":[
      "cond-mat.mtrl-sci"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.02649"
    ],
    "c_title":[
      "Fully Autonomous AI Agents Should Not be Developed"
    ],
    "c_abstract":[
      "This paper argues that fully autonomous AI agents should not be developed. In\nsupport of this position, we build from prior scientific literature and current\nproduct marketing to delineate different AI agent levels and detail the ethical\nvalues at play in each, documenting trade-offs in potential benefits and risks.\nOur analysis reveals that risks to people increase with the autonomy of a\nsystem: The more control a user cedes to an AI agent, the more risks to people\narise. Particularly concerning are safety risks, which affect human life and\nimpact further values."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17617",
    "a_title":"An Ensemble Approach for Brain Tumor Segmentation and Synthesis",
    "a_abstract":"The integration of machine learning in magnetic resonance imaging (MRI),\nspecifically in neuroimaging, is proving to be incredibly effective, leading to\nbetter diagnostic accuracy, accelerated image analysis, and data-driven\ninsights, which can potentially transform patient care. Deep learning models\nutilize multiple layers of processing to capture intricate details of complex\ndata, which can then be used on a variety of tasks, including brain tumor\nclassification, segmentation, image synthesis, and registration. Previous\nresearch demonstrates high accuracy in tumor segmentation using various model\narchitectures, including nn-UNet and Swin-UNet. U-Mamba, which uses state space\nmodeling, also achieves high accuracy in medical image segmentation. To\nleverage these models, we propose a deep learning framework that ensembles\nthese state-of-the-art architectures to achieve accurate segmentation and\nproduce finely synthesized images.",
    "explanation":"The integration of machine learning in magnetic resonance\nimaging (MRI), specifically in neuroimaging, is proving to be incred-\nibly effective, leading to better diagnostic accuracy, accelerated image\nanalysis, and data-driven insights, which can potentially transform pa-\ntient care.",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "ALL-Net: Anatomical information lesion-wise loss function integrated into neural network for multiple sclerosis lesion segmentation"
    ],
    "b_abstract":[
      "Accurate detection and segmentation of multiple sclerosis (MS) brain lesions on magnetic resonance images are important for disease diagnosis treatment. This is a challenging task as vary greatly in size, shape, location, image contrast. The objective our study was to develop an algorithm based deep convolutional neural network integrated with anatomic information lesion-wise loss function (ALL-Net) fast accurate automated MS lesions. Distance transformation mapping used construct module that encoded lesion-specific anatomical information. To overcome the lesion size imbalance during training improve small lesions, developed which individual were modeled spheres equal size. On ISBI-2015 longitudinal challenge dataset (19 subjects total), ALL-Net achieved overall score 93.32 amongst top performing methods. larger Cornell (176 significantly improved both voxel-wise metrics (Dice improvement 3.9% 35.3% p-values ranging from p < 0.01 0.0001, AUC precision-recall curve 2.1% 29.8%) (lesion-wise F1 12.6% 29.8% all ROC 1.4% 20.0%) compared leading publicly available tools."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.03001"
    ],
    "c_title":[
      "Multicellular self-organization in Escherichia coli"
    ],
    "c_abstract":[
      "Escherichia coli has long been a trusty companion, maintaining health in our\nguts and advancing biological knowledge in the laboratory. In light of recent\nfindings, we discuss multicellular self-organization in E. coli and develop\ngeneral ideas for multicellularity, including the necessity for multicellular\ndynamics and interpretation by dynamic graphs, applicable to both unicellular\nand multicellular organisms. In this context, we next discuss the documented\nbehaviors of E. coli self-organization (rosette formation, multicellular\nextension, and attached dormancy) and two potential behaviors (internal\ncommunication and mating). Finally, by comparing the dynamic graphs for\ndifferent communities, we develop principles relevant to the theory of\nmulticellularity."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17617",
    "a_title":"An Ensemble Approach for Brain Tumor Segmentation and Synthesis",
    "a_abstract":"The integration of machine learning in magnetic resonance imaging (MRI),\nspecifically in neuroimaging, is proving to be incredibly effective, leading to\nbetter diagnostic accuracy, accelerated image analysis, and data-driven\ninsights, which can potentially transform patient care. Deep learning models\nutilize multiple layers of processing to capture intricate details of complex\ndata, which can then be used on a variety of tasks, including brain tumor\nclassification, segmentation, image synthesis, and registration. Previous\nresearch demonstrates high accuracy in tumor segmentation using various model\narchitectures, including nn-UNet and Swin-UNet. U-Mamba, which uses state space\nmodeling, also achieves high accuracy in medical image segmentation. To\nleverage these models, we propose a deep learning framework that ensembles\nthese state-of-the-art architectures to achieve accurate segmentation and\nproduce finely synthesized images.",
    "explanation":"The integration of machine learning in magnetic resonance\nimaging (MRI), specifically in neuroimaging, is proving to be incred-\nibly effective, leading to better diagnostic accuracy, accelerated image\nanalysis, and data-driven insights, which can potentially transform pa-\ntient care.",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "Deep learning-Based 3D inpainting of brain MR images"
    ],
    "b_abstract":[
      "Abstract The detailed anatomical information of the brain provided by 3D magnetic resonance imaging (MRI) enables various neuroscience research. However, due to long scan time for MR images, 2D images are mainly obtained in clinical environments. purpose this study is generate from a sparsely sampled using an inpainting deep neural network that has U-net-like structure and DenseNet sub-blocks. To train network, not only fidelity loss but also perceptual based on VGG were considered. Various methods used assess overall similarity between inpainted original data. In addition, morphological analyzes performed investigate whether data produced local features similar diagnostic ability was evaluated investigating pattern changes disease groups. Brain anatomy details efficiently recovered proposed network. voxel-based analysis gray matter volume cortical thickness, differences observed small clusters. method will be useful utilizing advanced neuroimaging techniques with MRI"
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.05388"
    ],
    "c_title":[
      "Ontology Generation using Large Language Models"
    ],
    "c_abstract":[
      "The ontology engineering process is complex, time-consuming, and error-prone,\neven for experienced ontology engineers. In this work, we investigate the\npotential of Large Language Models (LLMs) to provide effective OWL ontology\ndrafts directly from ontological requirements described using user stories and\ncompetency questions. Our main contribution is the presentation and evaluation\nof two new prompting techniques for automated ontology development: Memoryless\nCQbyCQ and Ontogenia. We also emphasize the importance of three structural\ncriteria for ontology assessment, alongside expert qualitative evaluation,\nhighlighting the need for a multi-dimensional evaluation in order to capture\nthe quality and usability of the generated ontologies. Our experiments,\nconducted on a benchmark dataset of ten ontologies with 100 distinct CQs and 29\ndifferent user stories, compare the performance of three LLMs using the two\nprompting techniques. The results demonstrate improvements over the current\nstate-of-the-art in LLM-supported ontology engineering. More specifically, the\nmodel OpenAI o1-preview with Ontogenia produces ontologies of sufficient\nquality to meet the requirements of ontology engineers, significantly\noutperforming novice ontology engineers in modelling ability. However, we still\nnote some common mistakes and variability of result quality, which is important\nto take into account when using LLMs for ontology authoring support. We discuss\nthese limitations and propose directions for future research."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06513",
    "a_title":"PRISM: Privacy-preserving Inter-Site MRI Harmonization via Disentangled\n  Representation Learning",
    "a_abstract":"Multi-site MRI studies often suffer from site-specific variations arising\nfrom differences in methodology, hardware, and acquisition protocols, thereby\ncompromising accuracy and reliability in clinical AI\/ML tasks. We present PRISM\n(Privacy-preserving Inter-Site MRI Harmonization), a novel Deep Learning\nframework for harmonizing structural brain MRI across multiple sites while\npreserving data privacy. PRISM employs a dual-branch autoencoder with\ncontrastive learning and variational inference to disentangle anatomical\nfeatures from style and site-specific variations, enabling unpaired image\ntranslation without traveling subjects or multiple MRI modalities. Our modular\ndesign allows harmonization to any target site and seamless integration of new\nsites without the need for retraining or fine-tuning. Using multi-site\nstructural MRI data, we demonstrate PRISM's effectiveness in downstream tasks\nsuch as brain tissue segmentation and validate its harmonization performance\nthrough multiple experiments. Our framework addresses key challenges in medical\nAI\/ML, including data privacy, distribution shifts, model generalizability and\ninterpretability. Code is available at https:\/\/github.com\/saranggalada\/PRISM",
    "explanation":"From the selected references in Task 3, the following sentences from the abstract reflect the interdisciplinary topics of this research paper, combining the field of medicine  (MRI Scans) with machine learning (AI\/ML tasks):\n\n\"Multi-site MRI studies often suffer from site-specific variations arising from differences in methodology, hardware,\nand acquisition protocols, thereby compromising accuracy\nand reliability in clinical AI\/ML tasks. \"\n\n\"We present PRISM (Privacy-preserving Inter-Site MRI Harmonization), a novel Deep Learning framework for harmonizing structural brain MRI across multiple sites while preserving data privacy.\"",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Advances and Open Problems in Federated Learning"
    ],
    "b_abstract":[
      "The term Federated Learning was coined as recently 2016 to describe a machine learning setting where multiple entities collaborate in solving problem, under the coordination of central server or service provider. Each client\u2019s raw data is stored locally and not exchanged transferred; instead, focused updates intended for immediate aggregation are used achieve objective. Since then, topic has gathered much interest across many different disciplines realization that these interdisciplinary problems likely requires just but techniques from distributed optimization, cryptography, security, differential privacy, fairness, compressed sensing, systems, information theory, statistics, more. This monograph contributions leading experts disciplines, who latest state-of-the art their perspective. These have been carefully curated into comprehensive treatment enables reader understand work done get pointers effort required solve before can become reality practical systems. Researchers working area systems will find this an enlightening read may inspire them on challenging issues outlined. up speed quickly easily what increasingly important topic: Learning."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.11130"
    ],
    "c_title":[
      "Advanced 3D-Printed Multiphasic Scaffold with Optimal PRP Dosage for\n  Chondrogenesis of BM-MSCs in Osteochondral Tissue Engineering"
    ],
    "c_abstract":[
      "In osteochondral tissue engineering (OCTE), simultaneously regenerating\nsubchondral bone and cartilage tissue presents a significant challenge.\nMultiphasic scaffolds were created and manufactured using 3D printing to\naddress this issue. Excellent interfacial mechanical properties and\nbiocompatibility enhance the growth and chondrogenic differentiation of bone\nmarrow mesenchymal stem cells (BM-MSCs). The subchondral bone bottom layer is\nmimicked by incorporating varying concentrations of graphene oxide (GO) (0%,\n1%, and 2% w\/v) into a bioink composed of alginate (Alg) and gelatin (Gel).\nBased on evaluations of mechanical and biocompatibility properties, 1% GO is\nselected for further studies. Subsequently, the GO concentration is kept\nconstant while varying the platelet-rich plasma (PRP) dosage in the multiphasic\nscaffolds. Different PRP dosages (0%, 1%, 2%, and 3% w\/v) are integrated into\nthe Alg-Gel bioink to simulate cartilage tissues. Results indicate that\n3D-printed scaffolds containing 1% or 2% PRP exhibit favorable biomechanical\nproperties, with no significant differences observed. However, BM-MSCs exposed\nto 2% PRP demonstrate enhanced adhesion, growth, and viability. Additionally,\nreal-time PCR and Alcian blue staining confirm increased chondrogenic\nexpression and glycosaminoglycans (GAGs) synthesis. This work highlights the\npromising potential of 3D-printed multiphasic frameworks in the development of\nOCTE."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06513",
    "a_title":"PRISM: Privacy-preserving Inter-Site MRI Harmonization via Disentangled\n  Representation Learning",
    "a_abstract":"Multi-site MRI studies often suffer from site-specific variations arising\nfrom differences in methodology, hardware, and acquisition protocols, thereby\ncompromising accuracy and reliability in clinical AI\/ML tasks. We present PRISM\n(Privacy-preserving Inter-Site MRI Harmonization), a novel Deep Learning\nframework for harmonizing structural brain MRI across multiple sites while\npreserving data privacy. PRISM employs a dual-branch autoencoder with\ncontrastive learning and variational inference to disentangle anatomical\nfeatures from style and site-specific variations, enabling unpaired image\ntranslation without traveling subjects or multiple MRI modalities. Our modular\ndesign allows harmonization to any target site and seamless integration of new\nsites without the need for retraining or fine-tuning. Using multi-site\nstructural MRI data, we demonstrate PRISM's effectiveness in downstream tasks\nsuch as brain tissue segmentation and validate its harmonization performance\nthrough multiple experiments. Our framework addresses key challenges in medical\nAI\/ML, including data privacy, distribution shifts, model generalizability and\ninterpretability. Code is available at https:\/\/github.com\/saranggalada\/PRISM",
    "explanation":"From the selected references in Task 3, the following sentences from the abstract reflect the interdisciplinary topics of this research paper, combining the field of medicine  (MRI Scans) with machine learning (AI\/ML tasks):\n\n\"Multi-site MRI studies often suffer from site-specific variations arising from differences in methodology, hardware,\nand acquisition protocols, thereby compromising accuracy\nand reliability in clinical AI\/ML tasks. \"\n\n\"We present PRISM (Privacy-preserving Inter-Site MRI Harmonization), a novel Deep Learning framework for harmonizing structural brain MRI across multiple sites while preserving data privacy.\"",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "The future of digital health with federated learning"
    ],
    "b_abstract":[
      "Abstract Data-driven machine learning (ML) has emerged as a promising approach for building accurate and robust statistical models from medical data, which is collected in huge volumes by modern healthcare systems. Existing data not fully exploited ML primarily because it sits silos privacy concerns restrict access to this data. However, without sufficient will be prevented reaching its full potential and, ultimately, making the transition research clinical practice. This paper considers key factors contributing issue, explores how federated (FL) may provide solution future of digital health highlights challenges considerations that need addressed."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.17784"
    ],
    "c_title":[
      "AdditiveLLM: Large Language Models Predict Defects in Additive\n  Manufacturing"
    ],
    "c_abstract":[
      "In this work we investigate the ability of large language models to predict\nadditive manufacturing defect regimes given a set of process parameter inputs.\nFor this task we utilize a process parameter defect dataset to fine-tune a\ncollection of models, titled AdditiveLLM, for the purpose of predicting\npotential defect regimes including Keyholing, Lack of Fusion, and Balling. We\ncompare different methods of input formatting in order to gauge the model's\nperformance to correctly predict defect regimes on our sparse Baseline dataset\nand our natural language Prompt dataset. The model displays robust predictive\ncapability, achieving an accuracy of 93\\% when asked to provide the defect\nregimes associated with a set of process parameters. The incorporation of\nnatural language input further simplifies the task of process parameters\nselection, enabling users to identify optimal settings specific to their build."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.16464",
    "a_title":"Generating social networks with static and dynamic utility-maximization\n  approaches",
    "a_abstract":"In this paper, we introduce a conceptual framework that model human social\nnetworks as an undirected dot-product graph of independent individuals. Their\nrelationships are only determined by a cost-benefit analysis, i.e. by\nmaximizing an objective function at the scale of the individual or of the whole\nnetwork. On this framework, we build a new artificial network generator in two\nversions. The first fits within the tradition of artificial network generators\nby being able to generate similar networks from empirical data. The second\nrelaxes the computational efficiency constraint and implements the same\nmicro-based decision algorithm, but in agent-based simulations with time and\nfully independent agents. This latter version enables social scientists to\nperform an in-depth analysis of the consequences of behavioral constraints\naffecting individuals on the network they form. This point is illustrated by a\ncase study of imperfect information.",
    "explanation":"The two key references selected in Task 3 reflect what makes this paper an IDR. The sentences copied from the abstract that relate to the references are shown below, combining economics and computational engineering.\n\n\"Their relationships are only determined by a cost-benefit analysis...\"\n\n\"The second relaxes the computational efficiency constraint\nand implements the same micro-based decision algorithm, but in agent-based simulations with time and fully independent agents.\"",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Meeting Strangers and Friends of Friends: How Random Are Social Networks?"
    ],
    "b_abstract":[
      "We present a dynamic model of network formation where nodes find other with whom to form links in two ways: some are found uniformly at random, while others by searching locally through the current structure (e.g., meeting friends friends). This combination processes results spectrum features exhibited large social networks, including presence more high- and low-degree than when formed independently having low distances between network, high clustering on local level. fit data from six networks impute relative ratio random network-based meetings link formation, which turns out vary dramatically across applications. show that as random\/network-based varies, resulting degree distributions can be ordered sense stochastic dominance, allows us infer how process affects average utility network. (JEL D85, Z13)"
    ],
    "b_categories":[
      "q-fin.EC"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "2502.12401"
    ],
    "c_title":[
      "Risk Assessment of Transmission Lines Against Grid-ignited Wildfires"
    ],
    "c_abstract":[
      "Wildfires ignited by the power lines have become increasingly common over the\npast decade. Enhancing the operational and financial resilience of power grids\nagainst wildfires involves a multifaceted approach. Key proactive measures\ninclude meticulous vegetation management, strategic grid hardening such as\ninfrastructure undergrounding, preemptive de-energization, and disaster risk\nfinancing, among others. Each measure should be tailored to prioritize efforts\nin mitigating the consequences of wildfires. This paper proposes a transmission\nline risk assessment method for grid-ignited wildfires, identifying the\ntransmission lines that could potentially lead to damage to the natural and\nbuilt environment and to other transmission lines if igniting a wildfire. Grid,\nmeteorological, and topological datasets are combined to enable a comprehensive\nanalysis. Numerical analysis on the standard IEEE 30-bus system demonstrates\nthe effectiveness of the proposed method."
    ],
    "c_categories":[
      "cs.CE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.16464",
    "a_title":"Generating social networks with static and dynamic utility-maximization\n  approaches",
    "a_abstract":"In this paper, we introduce a conceptual framework that model human social\nnetworks as an undirected dot-product graph of independent individuals. Their\nrelationships are only determined by a cost-benefit analysis, i.e. by\nmaximizing an objective function at the scale of the individual or of the whole\nnetwork. On this framework, we build a new artificial network generator in two\nversions. The first fits within the tradition of artificial network generators\nby being able to generate similar networks from empirical data. The second\nrelaxes the computational efficiency constraint and implements the same\nmicro-based decision algorithm, but in agent-based simulations with time and\nfully independent agents. This latter version enables social scientists to\nperform an in-depth analysis of the consequences of behavioral constraints\naffecting individuals on the network they form. This point is illustrated by a\ncase study of imperfect information.",
    "explanation":"The two key references selected in Task 3 reflect what makes this paper an IDR. The sentences copied from the abstract that relate to the references are shown below, combining economics and computational engineering.\n\n\"Their relationships are only determined by a cost-benefit analysis...\"\n\n\"The second relaxes the computational efficiency constraint\nand implements the same micro-based decision algorithm, but in agent-based simulations with time and fully independent agents.\"",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "An agent-based spatial urban social network generator: A case study of beijing, china"
    ],
    "b_abstract":[
      "This paper proposes an agent-based spatial social network model, which combines a utility function and heuristic algorithms, to formulate friendships of agents in a given synthetic population comprising individuals and households, as well as their attributes and locations. In order to better and explicitly represent the real social networks, the model attempts to generate both close and somewhat close social networks by linking agents with either close or somewhat close friendships, fitting both distributions of network degree and transitivity, which are two basic characteristics of a network. Here, a utility function, which incorporates the similarity between agents in individual attributes (e.g., sex), as well as the spatial closeness of their residential locations and workplaces, is developed to judge whether a friendship between a pair of agents can be built. Furthermore, the social network model is developed as a key component of an agent-and Geographic Information System (GIS)-based virtual city creator that is a set of synthesis methods used to generate spatially disaggregate urban data. Finally, Beijing, China is used as a case study. Both close and somewhat close social networks are generated with the target and generated distributions well matched, and the generated networks are further analysed from a geographical perspective."
    ],
    "b_categories":[
      "cs.CE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.12178"
    ],
    "c_title":[
      "Public Sector Efficiency in Delivering Social Services and Its Impact on\n  Human Development: A Comparative Study of Healthcare and Education Spending\n  in India, Pakistan, and Bangladesh"
    ],
    "c_abstract":[
      "The research investigates the effects of public spending on health and\neducation in shaping the human development in south Asian three countries:\nIndia, Pakistan and Bangladesh. The study uses the VAR (Vector Auto regression)\nmodel to estimate the effects on government spending on these sectors to\nevaluate the human development. The findings state that there are different\ndegrees of impact in these three countries. In Bangladesh and India, health\nspending increases the human development in short term. On the other hand\neducation spending shows the significance on the HDI.Moreover, the study also\nhighlights that there are different levels of effectiveness of government\nspending across these three countries. In order to maximize the human\ndevelopment an optimum country specific strategies should be adopted."
    ],
    "c_categories":[
      "econ.GN",
      "q-fin.EC"
    ],
    "c_fields":[
      "Economics and Quantitative Finance"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.17260",
    "a_title":"MiceBoneChallenge: Micro-CT public dataset and six solutions for\n  automatic growth plate detection in micro-CT mice bone scans",
    "a_abstract":"Detecting and quantifying bone changes in micro-CT scans of rodents is a\ncommon task in preclinical drug development studies. However, this task is\nmanual, time-consuming and subject to inter- and intra-observer variability. In\n2024, Anonymous Company organized an internal challenge to develop models for\nautomatic bone quantification. We prepared and annotated a high-quality dataset\nof 3D $\\mu$CT bone scans from $83$ mice. The challenge attracted over $80$ AI\nscientists from around the globe who formed $23$ teams. The participants were\ntasked with developing a solution to identify the plane where the bone growth\nhappens, which is essential for fully automatic segmentation of trabecular\nbone. As a result, six computer vision solutions were developed that can\naccurately identify the location of the growth plate plane. The solutions\nachieved the mean absolute error of $1.91\\pm0.87$ planes from the ground truth\non the test set, an accuracy level acceptable for practical use by a\nradiologist. The annotated 3D scans dataset along with the six solutions and\nsource code, is being made public, providing researchers with opportunities to\ndevelop and benchmark their own approaches. The code, trained models, and the\ndata will be shared.",
    "explanation":"This IDR combines various fields like computer science (Computer Vision and AI) and physical medicine (CT Scans) introduced in the abstract. The selected key references from Task 3 are described with a few sentences from the abstract shown below:\n\n\"We prepared and annotated a high-quality dataset of 3D \u03bcCT bone scans from 83 mice. \"\n\n\"As a result, six computer vision solutions were developed that can accurately identify the location of the growth plate plane. \"",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Differentiation of distal ureteral stones and pelvic phleboliths using a convolutional neural network"
    ],
    "b_abstract":[
      "Abstract The objectives were to develop and validate a Convolutional Neural Network (CNN) using local features for differentiating distal ureteral stones from pelvic phleboliths, compare the CNN method with semi-quantitative radiologists\u2019 assessments evaluate whether assessment of calcification its surroundings is sufficient discriminating phleboliths in non-contrast-enhanced CT (NECT). We retrospectively included 341 consecutive patients acute renal colic stone on NECT showing either stone, phlebolith or both. A 2.5-dimensional (2.5D-CNN) model was used, where perpendicular axial, coronal sagittal images through each used as input data CNN. trained 384 calcifications, evaluated an unseen dataset 50 phleboliths. compared by seven radiologists who reviewed 5 \u00d7 cm image stack surrounding calcification, cut-off values based attenuation volume calcifications. differentiated sensitivity, specificity accuracy 94%, 90% 92% AUC 0.95. This similar majority vote 93% significantly higher ( p = 0.03) than mean radiologist 86%. 49%. In conclusion, features. However, more are needed reach optimal discrimination."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.17930"
    ],
    "c_title":[
      "Determination of unscaled blood input for human dynamic FDG brain PET"
    ],
    "c_abstract":[
      "Objectives: Many existing techniques for the non-invasive quantification of\nthe blood input function in dynamic FDG-PET imaging require strong historical\ninformation or user input. The technique proposed in this work utilizes the\nassumption that a dynamic PET scan can be modeled by the Patlak plot to\ndetermine an unscaled blood input function. Materials and Methods: The time\nactivity curve (TAC) for each voxel in a dynamic image can be considered as an\nn-dimensional vector. In this context, a TAC follows the Patlak plot if and\nonly if the TAC is a linear combination of the blood input function and the\nintegral of the blood input function. Given a set of TACs which follow the\nPatlak plot, we can thus use PCA to determine a basis which spans the same\nvector space as the blood input function and the integral of the blood input\nfunction. We then seek to find two TACs in this vector space which best satisfy\nthat the estimated anti-derivative of one of the TACs is close to the other\nTAC; such TACs are candidates for the blood input function and the integral of\nthe blood input function. We were able to construct a low (2) dimensional\noptimization problem to find such TACs. Results: We applied our results to\nobtain predicted blood input functions and Ki maps for twelve normal subjects.\nScaling the predicted blood input function to best match the ground truth, we\nachieved an average SSE of $0.042 \\pm 0.032$ and an average DTW distance of\n$0.141 \\pm 0.053$. Matching the means of the predicted and ground truth Ki\nmaps, we achieved an average MAPE of $2.539 \\pm 0.928$ and an average SSIM of\n$0.991 \\pm 0.005$. Conclusion: While not often viewed as such, the assumption\nthat some dynamic data follows a kinetic model gives strong prior information.\nIn the case of the Patlak plot, we can use this assumption to estimate an\nunscaled blood input function and unscaled Ki map."
    ],
    "c_categories":[
      "physics.med-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17260",
    "a_title":"MiceBoneChallenge: Micro-CT public dataset and six solutions for\n  automatic growth plate detection in micro-CT mice bone scans",
    "a_abstract":"Detecting and quantifying bone changes in micro-CT scans of rodents is a\ncommon task in preclinical drug development studies. However, this task is\nmanual, time-consuming and subject to inter- and intra-observer variability. In\n2024, Anonymous Company organized an internal challenge to develop models for\nautomatic bone quantification. We prepared and annotated a high-quality dataset\nof 3D $\\mu$CT bone scans from $83$ mice. The challenge attracted over $80$ AI\nscientists from around the globe who formed $23$ teams. The participants were\ntasked with developing a solution to identify the plane where the bone growth\nhappens, which is essential for fully automatic segmentation of trabecular\nbone. As a result, six computer vision solutions were developed that can\naccurately identify the location of the growth plate plane. The solutions\nachieved the mean absolute error of $1.91\\pm0.87$ planes from the ground truth\non the test set, an accuracy level acceptable for practical use by a\nradiologist. The annotated 3D scans dataset along with the six solutions and\nsource code, is being made public, providing researchers with opportunities to\ndevelop and benchmark their own approaches. The code, trained models, and the\ndata will be shared.",
    "explanation":"This IDR combines various fields like computer science (Computer Vision and AI) and physical medicine (CT Scans) introduced in the abstract. The selected key references from Task 3 are described with a few sentences from the abstract shown below:\n\n\"We prepared and annotated a high-quality dataset of 3D \u03bcCT bone scans from 83 mice. \"\n\n\"As a result, six computer vision solutions were developed that can accurately identify the location of the growth plate plane. \"",
    "b_id":[
      "b27"
    ],
    "b_title":[
      "Micro-CT data of early physiological cancellous bone formation in the lumbar spine of female C57BL\/6 mice"
    ],
    "b_abstract":[
      "Micro-CT provides critical data for musculoskeletal research, yielding three-dimensional datasets containing distributions of mineral density. Using high-resolution scans, we quantified changes in the fine architecture of bone in the spine of young mice. This data is made available as a reference to physiological cancellous bone growth. The scans (n\u2009=\u200919) depict the extensive structural changes typical for female C57BL\/6 mice pups, aged 1-, 3-, 7-, 10- and 14-days post-partum, as they attain the\u00a0mature geometry. We reveal the micro-morphology down to individual\u00a0trabeculae in the spine that follow phases of mineral-tissue rearrangement in the growing lumbar vertebra on a micrometer length scale. Phantom data is provided to facilitate mineral density calibration. Conventional histomorphometry matched with our micro-CT data on selected samples confirms the validity and accuracy of our 3D scans. The data may thus serve as a reference for modeling normal bone growth and can be used to benchmark other experiments assessing the effects of biomaterials, tissue growth, healing, and regeneration. Measurement(s) bone growth \u2022 bone mineralization involved in bone maturation Technology Type(s) micro-computed tomography Factor Type(s) age Sample Characteristic - Organism Mus musculus Sample Characteristic - Environment biological_process Machine-accessible metadata file describing the reported data: https:\/\/doi.org\/10.6084\/m9.figshare.14062073"
    ],
    "b_categories":[
      "physics.med-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.02348"
    ],
    "c_title":[
      "YOLO-PRO: Enhancing Instance-Specific Object Detection with Full-Channel\n  Global Self-Attention"
    ],
    "c_abstract":[
      "This paper addresses the inherent limitations of conventional bottleneck\nstructures (diminished instance discriminability due to overemphasis on batch\nstatistics) and decoupled heads (computational redundancy) in object detection\nframeworks by proposing two novel modules: the Instance-Specific Bottleneck\nwith full-channel global self-attention (ISB) and the Instance-Specific\nAsymmetric Decoupled Head (ISADH). The ISB module innovatively reconstructs\nfeature maps to establish an efficient full-channel global attention mechanism\nthrough synergistic fusion of batch-statistical and instance-specific features.\nComplementing this, the ISADH module pioneers an asymmetric decoupled\narchitecture enabling hierarchical multi-dimensional feature integration via\ndual-stream batch-instance representation fusion. Extensive experiments on the\nMS-COCO benchmark demonstrate that the coordinated deployment of ISB and ISADH\nin the YOLO-PRO framework achieves state-of-the-art performance across all\ncomputational scales. Specifically, YOLO-PRO surpasses YOLOv8 by 1.0-1.6% AP\n(N\/S\/M\/L\/X scales) and outperforms YOLO11 by 0.1-0.5% AP in critical M\/L\/X\ngroups, while maintaining competitive computational efficiency. This work\nprovides practical insights for developing high-precision detectors deployable\non edge devices."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.14846",
    "a_title":"Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy\n  with Pre-training, Data Augmentation and Dual Flow UNet",
    "a_abstract":"Head and neck tumors and metastatic lymph nodes are crucial for treatment\nplanning and prognostic analysis. Accurate segmentation and quantitative\nanalysis of these structures require pixel-level annotation, making automated\nsegmentation techniques essential for the diagnosis and treatment of head and\nneck cancer. In this study, we investigated the effects of multiple strategies\non the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT)\nimages. For the segmentation of pre-RT images, we utilized: 1) a fully\nsupervised learning approach, and 2) the same approach enhanced with\npre-trained weights and the MixUp data augmentation technique. For mid-RT\nimages, we introduced a novel computational-friendly network architecture that\nfeatures separate encoders for mid-RT images and registered pre-RT images with\ntheir labels. The mid-RT encoder branch integrates information from pre-RT\nimages and labels progressively during the forward propagation. We selected the\nhighest-performing model from each fold and used their predictions to create an\nensemble average for inference. In the final test, our models achieved a\nsegmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on\naggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at\nhttps:\/\/github.com\/WltyBY\/HNTS-MRG2024_train_code.",
    "explanation":"In this IDR, mainly two topics from the two the two different fields of medical physics and artificial intelligence are being described. The use of MRI scans falls under the Medical Physics category and utilizing computer vision falls under AI. \n\nHere are a few sentences from the abstract that reflect the integration of this interdisciplinary ideas:\n\n\" In this study, we investigated the effects of multiple strategies on the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT) images.\"\n\"For mid-RT images, we introduced a novel computational-friendly network architecture that features separate encoders for mid-RT images and registered pre-RT images with their labels.\"",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Evaluation of the Impact of Magnetic Resonance Imaging (MRI) on Gross Tumor Volume (GTV) Definition for Radiation Treatment Planning (RTP) of Inoperable High Grade Gliomas (HGGs)"
    ],
    "b_abstract":[
      "Aim and Background . Inoperable high-grade gliomas (HGGs) comprise a specific group of brain tumors portending very poor prognosis. In the absence surgical management, radiation therapy (RT) offers primary local treatment modality for inoperable HGGs. Optimal target definition planning (RTP) HGGs is difficult task given diffusely infiltrative nature disease. this context, detailed multimodality imaging information may add to accuracy in We evaluated impact Magnetic Resonance Imaging (MRI) on Gross Tumor Volume (GTV) RTP study. Materials Methods Twenty-five patients with clinical diagnosis HGG were included GTV was based Computed Tomography- (CT-) simulation images only or both CT-simulation MR images, comparative assessment performed investigate incorporation MRI into Results Median volume acquired by using use CT 65.3 (39.6 - 94.3) cc 76.1 (46.8-108.9) cc, respectively. Incorporation has resulted median increase 12.61% (6%-19%) defined only, which statistically significant (p &lt; 0.05). Conclusion improve have implications dose escalation\/intensification strategies despite need further supporting evidence."
    ],
    "b_categories":[
      "physics.med-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.13137"
    ],
    "c_title":[
      "Theorem Prover as a Judge for Synthetic Data Generation"
    ],
    "c_abstract":[
      "The demand for synthetic data in mathematical reasoning has increased due to\nits potential to enhance the mathematical capabilities of large language models\n(LLMs). However, ensuring the validity of intermediate reasoning steps remains\na significant challenge, affecting data quality. While formal verification via\ntheorem provers effectively validates LLM reasoning, the autoformalisation of\nmathematical proofs remains error-prone. In response, we introduce iterative\nautoformalisation, an approach that iteratively refines theorem prover\nformalisation to mitigate errors, thereby increasing the execution rate on the\nLean prover from 60% to 87%. Building upon that, we introduce Theorem Prover as\na Judge (TP-as-a-Judge), a method that employs theorem prover formalisation to\nrigorously assess LLM intermediate reasoning, effectively integrating\nautoformalisation with synthetic data generation. Finally, we present\nReinforcement Learning from Theorem Prover Feedback (RLTPF), a framework that\nreplaces human annotation with theorem prover feedback in Reinforcement\nLearning from Human Feedback (RLHF). Across multiple LLMs, applying\nTP-as-a-Judge and RLTPF improves benchmarks with only 3,508 samples, achieving\n5.56% accuracy gain on Mistral-7B for MultiArith, 6.00% on Llama-2-7B for\nSVAMP, and 3.55% on Llama-3.1-8B for AQUA."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.14846",
    "a_title":"Head and Neck Tumor Segmentation of MRI from Pre- and Mid-radiotherapy\n  with Pre-training, Data Augmentation and Dual Flow UNet",
    "a_abstract":"Head and neck tumors and metastatic lymph nodes are crucial for treatment\nplanning and prognostic analysis. Accurate segmentation and quantitative\nanalysis of these structures require pixel-level annotation, making automated\nsegmentation techniques essential for the diagnosis and treatment of head and\nneck cancer. In this study, we investigated the effects of multiple strategies\non the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT)\nimages. For the segmentation of pre-RT images, we utilized: 1) a fully\nsupervised learning approach, and 2) the same approach enhanced with\npre-trained weights and the MixUp data augmentation technique. For mid-RT\nimages, we introduced a novel computational-friendly network architecture that\nfeatures separate encoders for mid-RT images and registered pre-RT images with\ntheir labels. The mid-RT encoder branch integrates information from pre-RT\nimages and labels progressively during the forward propagation. We selected the\nhighest-performing model from each fold and used their predictions to create an\nensemble average for inference. In the final test, our models achieved a\nsegmentation performance of 82.38% for pre-RT and 72.53% for mid-RT on\naggregated Dice Similarity Coefficient (DSC) as HiLab. Our code is available at\nhttps:\/\/github.com\/WltyBY\/HNTS-MRG2024_train_code.",
    "explanation":"In this IDR, mainly two topics from the two the two different fields of medical physics and artificial intelligence are being described. The use of MRI scans falls under the Medical Physics category and utilizing computer vision falls under AI. \n\nHere are a few sentences from the abstract that reflect the integration of this interdisciplinary ideas:\n\n\" In this study, we investigated the effects of multiple strategies on the segmentation of pre-radiotherapy (pre-RT) and mid-radiotherapy (mid-RT) images.\"\n\"For mid-RT images, we introduced a novel computational-friendly network architecture that features separate encoders for mid-RT images and registered pre-RT images with their labels.\"",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation"
    ],
    "b_abstract":[
      "Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able process 2D images while data used in clinical practice consists of 3D volumes. In this work we propose an approach segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end MRI volumes depicting prostate, learns predict for whole volume at once. We introduce novel objective function, that optimise during training, Dice coefficient. way can deal with situations where there strong imbalance between number foreground background voxels. To cope limited annotated available augment applying random non-linear transformations histogram matching. show our experimental evaluation achieves good performances challenging test requiring fraction processing time needed by other previous methods."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.17930"
    ],
    "c_title":[
      "Determination of unscaled blood input for human dynamic FDG brain PET"
    ],
    "c_abstract":[
      "Objectives: Many existing techniques for the non-invasive quantification of\nthe blood input function in dynamic FDG-PET imaging require strong historical\ninformation or user input. The technique proposed in this work utilizes the\nassumption that a dynamic PET scan can be modeled by the Patlak plot to\ndetermine an unscaled blood input function. Materials and Methods: The time\nactivity curve (TAC) for each voxel in a dynamic image can be considered as an\nn-dimensional vector. In this context, a TAC follows the Patlak plot if and\nonly if the TAC is a linear combination of the blood input function and the\nintegral of the blood input function. Given a set of TACs which follow the\nPatlak plot, we can thus use PCA to determine a basis which spans the same\nvector space as the blood input function and the integral of the blood input\nfunction. We then seek to find two TACs in this vector space which best satisfy\nthat the estimated anti-derivative of one of the TACs is close to the other\nTAC; such TACs are candidates for the blood input function and the integral of\nthe blood input function. We were able to construct a low (2) dimensional\noptimization problem to find such TACs. Results: We applied our results to\nobtain predicted blood input functions and Ki maps for twelve normal subjects.\nScaling the predicted blood input function to best match the ground truth, we\nachieved an average SSE of $0.042 \\pm 0.032$ and an average DTW distance of\n$0.141 \\pm 0.053$. Matching the means of the predicted and ground truth Ki\nmaps, we achieved an average MAPE of $2.539 \\pm 0.928$ and an average SSIM of\n$0.991 \\pm 0.005$. Conclusion: While not often viewed as such, the assumption\nthat some dynamic data follows a kinetic model gives strong prior information.\nIn the case of the Patlak plot, we can use this assumption to estimate an\nunscaled blood input function and unscaled Ki map."
    ],
    "c_categories":[
      "physics.med-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.16995",
    "a_title":"Leveraging Neural Networks to Optimize Heliostat Field Aiming Strategies\n  in Concentrating Solar Power Tower Plants",
    "a_abstract":"Concentrating Solar Power Tower (CSPT) plants rely on heliostat fields to\nfocus sunlight onto a central receiver. Although simple aiming strategies, such\nas directing all heliostats to the receivers equator, can maximize energy\ncollection, they often result in uneven flux distributions that lead to\nhotspots, thermal stresses, and reduced receiver lifetimes. This paper presents\na novel, data-driven approach that integrates constraint learning, neural\nnetwork-based surrogates, and mathematical optimization to overcome these\nchallenges. The methodology learns complex heliostat-to-receiver flux\ninteractions from simulation data, constructing a surrogate model that is\nembedded into a tractable optimization framework. By maximizing a tailored\nquality score that balances energy collection and flux uniformity, the approach\nyields smoothly distributed flux profiles and mitigates excessive thermal\npeaks. An iterative refinement process, guided by the trust region and\nprogressive data sampling, ensures the surrogate model improves the obtained\nsolution by exploring new spaces during the iterations. Results from a real\nCSPT case study demonstrate that the proposed approach surpasses conventional\nheuristic methods, offering flatter flux distributions and safer thermal\nconditions without a substantial loss in overall energy capture.",
    "explanation":"The two fields described in the references chosen in Task 3 were AI and Mathematics. This IDR talks a lot about mathematical optimization and control to overcome certain challenges as well as leverages AI and machine learning (neural networks).\n\nSentences from the abstract:\n\"This paper presents a novel, data-driven approach that integrates constraint learning, neural network-based surrogates, and mathematical optimization to overcome these challenges.\"\n",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Multi-objective performance optimization & thermodynamic analysis of solar powered supercritical co2 power cycles using machine learning methods & genetic algorithm"
    ],
    "b_abstract":[
      "The present study is focused on multi-objective performance optimization & thermodynamic analysis from the perspectives of energy and exergy for Recompression, Partial Cooling & Main Compression Intercooling supercritical CO2 (sCO2) Brayton cycles for concentrated solar power (CSP) applications using machine learning algorithms. The novelty of this work lies in the integration of artificial neural networks (ANN) and genetic algorithms (GA) for optimizing the performance of advanced sCO2 power cycles considering climatic variation, which has significant implications for both the scientific community and engineering applications in the renewable energy sector. The methodology employed includes thermodynamic analysis based on energy, exergy & environmental factors including system performance optimization. The system is modelled for net power production of 15 MW thermal output utilizing equations for the energy and exergy balance for each component. Subsequently, thermodynamic model extracted dataset used for prediction & evaluation of Random Forest, XGBoost, KNN, AdaBoost, ANN and LightGBM algorithm. Finally, considering climate conditions, multi-objective optimization is carried out for the CSP integrated sCO2 Power cycle for optimal power output, exergy destruction, thermal and exergetic efficiency. Genetic algorithm and TOPSIS (technique for order of preference by similarity to ideal solution), multi-objective decision-making tool, were used to determine the optimum operating conditions. The major findings of this work reveal significant improvements in the performance of the advanced sCO2 cycle by 1.68 % and 7.87 % compared to conventional recompression and partial cooling cycle, respectively. This research could advance renewable energy technologies, particularly concentrated solar power, by improving power cycle designs to increase system efficiency and economic feasibility. Optimized advanced supercritical CO2 power cycles in concentrated solar power plants might increase renewable energy use and energy generation infrastructure, potentially opening new research avenues."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2502.20379"
    ],
    "c_title":[
      "Multi-Agent Verification: Scaling Test-Time Compute with Multiple\n  Verifiers"
    ],
    "c_abstract":[
      "By utilizing more computational resources at test-time, large language models\n(LLMs) can improve without additional training. One common strategy uses\nverifiers to evaluate candidate outputs. In this work, we propose a novel\nscaling dimension for test-time compute: scaling the number of verifiers. We\nintroduce Multi-Agent Verification (MAV) as a test-time compute paradigm that\ncombines multiple verifiers to improve performance. We propose using Aspect\nVerifiers (AVs), off-the-shelf LLMs prompted to verify different aspects of\noutputs, as one possible choice for the verifiers in a MAV system. AVs are a\nconvenient building block for MAV since they can be easily combined without\nadditional training. Moreover, we introduce BoN-MAV, a simple multi-agent\nverification algorithm that combines best-of-n sampling with multiple\nverifiers. BoN-MAV demonstrates stronger scaling patterns than self-consistency\nand reward model verification, and we demonstrate both weak-to-strong\ngeneralization, where combining weak verifiers improves even stronger LLMs, and\nself-improvement, where the same base model is used to both generate and verify\noutputs. Our results establish scaling the number of verifiers as a promising\nnew dimension for improving language model performance at test-time."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.16995",
    "a_title":"Leveraging Neural Networks to Optimize Heliostat Field Aiming Strategies\n  in Concentrating Solar Power Tower Plants",
    "a_abstract":"Concentrating Solar Power Tower (CSPT) plants rely on heliostat fields to\nfocus sunlight onto a central receiver. Although simple aiming strategies, such\nas directing all heliostats to the receivers equator, can maximize energy\ncollection, they often result in uneven flux distributions that lead to\nhotspots, thermal stresses, and reduced receiver lifetimes. This paper presents\na novel, data-driven approach that integrates constraint learning, neural\nnetwork-based surrogates, and mathematical optimization to overcome these\nchallenges. The methodology learns complex heliostat-to-receiver flux\ninteractions from simulation data, constructing a surrogate model that is\nembedded into a tractable optimization framework. By maximizing a tailored\nquality score that balances energy collection and flux uniformity, the approach\nyields smoothly distributed flux profiles and mitigates excessive thermal\npeaks. An iterative refinement process, guided by the trust region and\nprogressive data sampling, ensures the surrogate model improves the obtained\nsolution by exploring new spaces during the iterations. Results from a real\nCSPT case study demonstrate that the proposed approach surpasses conventional\nheuristic methods, offering flatter flux distributions and safer thermal\nconditions without a substantial loss in overall energy capture.",
    "explanation":"The two fields described in the references chosen in Task 3 were AI and Mathematics. This IDR talks a lot about mathematical optimization and control to overcome certain challenges as well as leverages AI and machine learning (neural networks).\n\nSentences from the abstract:\n\"This paper presents a novel, data-driven approach that integrates constraint learning, neural network-based surrogates, and mathematical optimization to overcome these challenges.\"\n",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "A method for real-time optimal heliostat aiming strategy generation via deep learning"
    ],
    "b_abstract":[
      "Optimal aiming strategies are essential for efficient solar power tower technology operation. However, the high calculation complexity makes it difficult for existing optimization methods to solve the optimization problem in real-time directly. This work proposes a real-time optimal heliostat aiming strategy generation method via deep learning. First, a two-stage learning scheme where the neural network models are trained by genetic algorithm (GA) benchmark solutions to produce an optimal aiming strategy is presented. Then, an end-to-end model without needing GA solutions for training is developed and discussed. Furthermore, a robust end-to-end training method using randomly sampled flux maps is also proposed. The proposed models demonstrated comparable performance as GA with two orders of magnitude less computation time through case studies. Among the proposed models, the end-to-end model shows significantly better generalization ability than the pure data-driven two-stage model on the test set. A robust end-to-end model with data enhancement has better robustness on unseen flux maps."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.08403"
    ],
    "c_title":[
      "Solving Large-Scale Two-Echelon Location Routing Problems in City\n  Logistics"
    ],
    "c_abstract":[
      "Logistic service providers increasingly focus on two-echelon distribution\nsystems to efficiently manage thousands of deliveries in urban environments.\nEffectively operating such systems requires designing cost-efficient delivery\nnetworks while addressing the challenges of increasing e-commerce demands. In\nthis context, we focus on a two-echelon location routing problem with mobile\ndepots and direct shipment, where decisions involve locating micro-depots, and\ndesigning first and second-level routes. Our model also incorporates the\nflexibility of direct shipments from the main depot to customers.\n  To solve such large-scale problems efficiently, we propose a metaheuristic\napproach that integrates a set cover problem with an adaptive large\nneighborhood search (ALNS). Our ALNS approach generates a set of promising\nroutes and micro-depot locations using destroy and repair operators while using\na local search for intensification. We then utilize the set cover problem to\nfind better network configurations. Additionally, we present a\ndecomposition-based cluster-first, route-second approach to solve large-scale\ninstances efficiently. We show the efficacy of our algorithm on well-known\nbenchmark datasets and provide managerial insights based on a case study for\nthe city of Munich. Our decomposition approach provides comparable results\nwhile reducing computational times by a factor of 15. Our case study results\nshow that allowing direct shipment can reduce total costs by 4.7% and emissions\nby 11%, while increasing truck utilizations by 42%. We find that integrating\nboth stationary and mobile micro-depots, along with allowing direct shipments,\ncan reduce total costs by 5.9% compared to traditional two-echelon delivery\nstructures."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.07018",
    "a_title":"Data-Driven Gradient Optimization for Field Emission Management in a\n  Superconducting Radio-Frequency Linac",
    "a_abstract":"Field emission can cause significant problems in superconducting\nradio-frequency linear accelerators (linacs). When cavity gradients are pushed\nhigher, radiation levels within the linacs may rise exponentially, causing\ndegradation of many nearby systems. This research aims to utilize machine\nlearning with uncertainty quantification to predict radiation levels at\nmultiple locations throughout the linacs and ultimately optimize cavity\ngradients to reduce field emission induced radiation while maintaining the\ntotal linac energy gain necessary for the experimental physics program. The\noptimized solutions show over 40% reductions for both neutron and gamma\nradiation from the standard operational settings.",
    "explanation":"The field emission is one of the most detrimental problems in superconducting radio-frequency linear accelerators (linacs). The research aims to utilize machine learning with uncertainty quantification to predict radiation levels at multiple locations throughout the linacs.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Field Emission in Superconducting Accelerators: Instrumented Measurements for Its Understanding and Mitigation"
    ],
    "b_abstract":[
      "Several new accelerator projects are adopting superconducting RF (SRF) technology. When accelerating SRF cavities maintain high RF gradients, field emission, the emission of electrons from cavity walls, can occur and may impact operational cavity gradient, radiological environment via activated components, and reliability. In this talk, we will discuss instrumented measurements of field emission from the two 1.1 GeV superconducting continuous wave (CW) linacs in CEBAF. The goal is to improve the understanding of field emission sources originating from cryomodule production, installation and operation. Such basic knowledge is needed in guiding field emission control, mitigation, and reduction toward high gradient and reliable operation of superconducting accelerators."
    ],
    "b_categories":[
      "physics.acc-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.08355"
    ],
    "c_title":[
      "Loss Landscape Analysis for Reliable Quantized ML Models for Scientific\n  Sensing"
    ],
    "c_abstract":[
      "In this paper, we propose a method to perform empirical analysis of the loss\nlandscape of machine learning (ML) models. The method is applied to two ML\nmodels for scientific sensing, which necessitates quantization to be deployed\nand are subject to noise and perturbations due to experimental conditions. Our\nmethod allows assessing the robustness of ML models to such effects as a\nfunction of quantization precision and under different regularization\ntechniques -- two crucial concerns that remained underexplored so far. By\ninvestigating the interplay between performance, efficiency, and robustness by\nmeans of loss landscape analysis, we both established a strong correlation\nbetween gently-shaped landscapes and robustness to input and weight\nperturbations and observed other intriguing and non-obvious phenomena. Our\nmethod allows a systematic exploration of such trade-offs a priori, i.e.,\nwithout training and testing multiple models, leading to more efficient\ndevelopment workflows. This work also highlights the importance of\nincorporating robustness into the Pareto optimization of ML models, enabling\nmore reliable and adaptive scientific sensing systems."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.07018",
    "a_title":"Data-Driven Gradient Optimization for Field Emission Management in a\n  Superconducting Radio-Frequency Linac",
    "a_abstract":"Field emission can cause significant problems in superconducting\nradio-frequency linear accelerators (linacs). When cavity gradients are pushed\nhigher, radiation levels within the linacs may rise exponentially, causing\ndegradation of many nearby systems. This research aims to utilize machine\nlearning with uncertainty quantification to predict radiation levels at\nmultiple locations throughout the linacs and ultimately optimize cavity\ngradients to reduce field emission induced radiation while maintaining the\ntotal linac energy gain necessary for the experimental physics program. The\noptimized solutions show over 40% reductions for both neutron and gamma\nradiation from the standard operational settings.",
    "explanation":"The field emission is one of the most detrimental problems in superconducting radio-frequency linear accelerators (linacs). The research aims to utilize machine learning with uncertainty quantification to predict radiation levels at multiple locations throughout the linacs.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "Accelerating cavity fault prediction using deep learning at Jefferson laboratory"
    ],
    "b_abstract":[
      "Abstract Accelerating cavities are an integral part of the continuous electron beam accelerator facility (CEBAF) at Jefferson Laboratory. When any over 400 in CEBAF experiences a fault, it disrupts delivery to experimental user halls. In this study, we propose use deep learning model predict slowly developing cavity faults. By utilizing pre-fault signals, train long short-term memory-convolutional neural network binary classifier distinguish between radio-frequency (RF) signals during normal operation and RF indicative impending We optimize by adjusting fault confidence threshold implementing multiple consecutive window criterion identify events, ensuring low false positive rate. Results obtained from analysis real dataset collected accelerating simulating deployed scenario demonstrate model\u2019s ability with 99.99% accuracy correctly 80% Notably, these achievements were achieved context highly imbalanced dataset, predictions made several hundred milliseconds before onset fault. Anticipating faults enables preemptive measures improve operational efficiency preventing or mitigating their occurrence."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.13312"
    ],
    "c_title":[
      "High Power Fast Frequency Modulation"
    ],
    "c_abstract":[
      "A fast and highly efficient frequency modulation at a high power level is\ndescribed. The system incorporates ferroelectric phase shifters and a magic-T\nor a circulator. A magnetron may be considered as a potential application. The\nmagnetron output may be converted to a selected reference frequency with\nnegligible insertion loss. The method also allows simultaneous amplitude and\nphase control."
    ],
    "c_categories":[
      "physics.acc-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.19844",
    "a_title":"Musical composition and 2D cellular automata based on music intervals",
    "a_abstract":"This study is a theoretical approach for exploring the applicability of a 2D\ncellular automaton based on melodic and harmonic intervals in random arrays of\nmusical notes. The aim of this study was to explore alternatives uses for a\ncellular automaton in the musical context for better understanding the musical\ncreativity. We used the complex systems and humanities approaches as a\nframework for capturing the essence of creating music based on rules of music\ntheory. Findings suggested that such rules matter for generating large-scale\npatterns of organized notes. Therefore, our formulation provides a novel\napproach for understanding and replicating aspects of the musical creativity.",
    "explanation":"The study is a theorical approach for exploring thge applicability of a D cellular automaton based on moelodic and harmonic intervals in random arrays of musical notes.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "A New Kind of Science"
    ],
    "b_abstract":[
      "3R3. A New Kind of Science. - S Wolfram (Wolfram Res Inc, 100 Trade Center Dr, Champaign IL 61820-7237). Media, Champaign, IL. 2002. 1197 pp. ISBN 1-57955-008-8. $44.95. Reviewed by M Gad-el-Hak (Eng Build, Rm 303, Virginia Commonwealth Univ, 601 W Main St, PO Box 843015, Richmond, VA 23284-3015). Reviewing Science is like stepping in a minefield. The danger lies going against the deluge praise, proving relevance to this audience, and arguing proposed new science that allegedly set replace science, as we know it. Those issues will be addressed turn, but first brief background. Stephen considered many have been child prodigy: journal paper particle physics at age 15; stint Oxford; PhD from Caltech 20; youngest recipient MacArthur Prize; faculty positions Caltech, Princeton, Illinois; significant contributions cellular automata complexity theory; developer popular software Mathematica; successful entrepreneur, becoming multi-millionaire 30. Running his company via e-mail videoconference, spent last 10 years virtual seclusion, relentlessly, tirelessly, secretly, nocturnally working on an idea possessed him: generating simple computations, algorithms only few lines. book, targeting both scientists non-scientists, partially about using rules generate complex patterns. In task, author has succeeded beyond reproach not showing can done brilliantly beautifully, also explaining it lucidly enough for all understand, appreciate, savor. opinion several reviewers, including one, aspect book tour de force clarity, elegance, simplicity. problem huge leap takes since nature computer-generated patterns look or behave similarly natural man-made things around us\u2014a snow flake, turbulent flow, lung, mollusk shell, traffic jam, outbreak starfish coral reef, entire universe\u2014therefore must way works. Nature runs its course same computer program. That essence science: yield secrets universe, solve our long-standing problems, provide theory everything. More flight fancy later. Deluge: was widely anticipated before actual publication. Published May 14, 2002, quickly became Amazon.com bestseller promptly reviewed scientific press. Heavyweights former included York Times, Chicago Tribune, Newsweek, Time, Daily Telegraph, Le Monde, Frankfurter Allgemeine Zeitung, Economist. Except last, press went gaga over touting author's claim stand existing head. Economist (p 79, June 1, 2002) more subdued even provocatively titling review \"The Emperor's Theory.\" press, reviews were somewhat less glorious skeptical. Physics Today 55, July 2002), Leo Kadanoff's once pointed, subtle polite, concluding he cannot support view any \"new kind science\" displayed Wolfram's book. Newsweek 59, 27, quoted famed physicist Freeman Dyson: \"There's tradition approaching senility come up with grand, improbable theories. unusual he's doing 40s.\" Kadanoff Dyson express minority opinion, however, majority reviewers being excited reason every human mystery currently depressed stock market, free will, quantum field theory, entropy. For present reviewer, lurks high particularly so months behind who already anointed Isaac Newton 21st century. Relevance: As aims replacing readers Applied Mechanics Reviews stake matter. Mechanics\u2014classical most part occasionally quantum\u2014is underlying branch upon which almost applied mechanics based. mathematics here often form partial differential equations, where space time are indefinitely divisible continuum. example, most, all, fluid flows described well-known, well-posed Navier\u2013Stokes equations. those first-principles equations solved agreement experiment reproach. It problem, such frustrated scores him. search simpler alternative is, therefore, quite alluring. mechanics, when they solved, powerful predictive tool explain mechanical world us well help design machines. When analytical solutions unattainable, discretized brute numerical integration used. But possible some situations, example realistic high-Reynolds-number other multi-scale problems required computational memory speed overwhelm today's supercomputers. impenetrable certain degree empiricism introduced relatively faster computations then proceed. Heuristic turbulence modeling compromise. Despite limitations, traditional works exceedingly well, mechanicians happily practice their craft. Readers should, care passionately if laws supplanted science. Argument: Cellular late 1940s John von Neumann Stanislaw Ulam, although claims independently discovered three decades discrete dynamical systems whose behavior completely specified terms repetitive local relation. continuum represented uniform one-, two-, three-dimensional grid, each cell containing single bit data, 0 red, white, blue, etc, bits states. advances steps. state cell, location, computed step algorithm priori defined close neighbors. Simple programs could, fact, result researched one-dimensional arranged line. data updated based value two nearest cells. methodically studied identified total 256 different rules. Space\u2013time diagrams generated show four distinct patterns: dull uniformity; periodic time-dependence; fractal behavior; truly non-repetitive says broken than 300 fix \"errors\" Darwin, Newton, great ones corrected all. proposes radical notion development world, uncover fundamental universe. pattern-generating capabilities supplant difficult-to-solve yet-to-be-found just because resemble does mean work way. Furthermore, believed represent reality used make predictions agree observations. This Galileo's paradigm underpinning modern explanatory power authority stem ability verifiable predictions; otherwise mere post-hoc speculation. exactly what is. games speculation possibly compete horsepower F=ma E=mc2.Wolfram's boasting, throughout 1200 pages, minimum excessive. He writes, \"I vastly I ever thought possible, fact now touches area besides.\" writes ideas originating him, credits belong elsewhere. Alan Turing conceptualized simplest universal computer, machine. Thinking universe vast digital brainchild Edward Fredkin. use machine environment physical detailed Tommaso Toffoli Norman Margolus. Other Per Bak, Charles Bennett, Hans Meinhardt percolate properly credited. Writing person, relegating notes 350 pages grudgingly dismissively mentioning names, restricting list references own publications, dispel important shortcoming. took approach bypassing peer process. self-published acting author, editor, publisher. opening paragraph mostly favorable Time's (May 20, worth reflecting on: \"Cranks occupational hazard scientist eventually faces. Fortunately, these characters usually easy spot. If someone grand overturns centuries knowledge\u2014especially spans unrelated fields biology economics\u2014the odds good she crank. publishes standard journals general readers, watch out. And issued rather conventional publisher, case pretty much airtight.\" extravagant cold fusion\u2014a` la Stanley Pons Martin Fleischman\u2014and deserve proportionally vigilant scrutiny. validated nor subjected process rest mortals expected do. contrast old anti-Newtonian model predict anything. emperor no clothes. offense play brick build edifice call Bottom Line: fun reading pictures, bad recommendation. inspiration, read Newton's Principia Mathematica, Latin. solving Newtonian framework still best bet, one's better books mechanics."
    ],
    "b_categories":[
      "cs.FL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.11351"
    ],
    "c_title":[
      "Automatic Labelling & Semantic Segmentation with 4D Radar Tensors"
    ],
    "c_abstract":[
      "In this paper, an automatic labelling process is presented for automotive\ndatasets, leveraging on complementary information from LiDAR and camera. The\ngenerated labels are then used as ground truth with the corresponding 4D radar\ndata as inputs to a proposed semantic segmentation network, to associate a\nclass label to each spatial voxel. Promising results are shown by applying both\napproaches to the publicly shared RaDelft dataset, with the proposed network\nachieving over 65% of the LiDAR detection performance, improving 13.2% in\nvehicle detection probability, and reducing 0.54 m in terms of Chamfer\ndistance, compared to variants inspired from the literature."
    ],
    "c_categories":[
      "cs.CV",
      "eess.SP"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.19844",
    "a_title":"Musical composition and 2D cellular automata based on music intervals",
    "a_abstract":"This study is a theoretical approach for exploring the applicability of a 2D\ncellular automaton based on melodic and harmonic intervals in random arrays of\nmusical notes. The aim of this study was to explore alternatives uses for a\ncellular automaton in the musical context for better understanding the musical\ncreativity. We used the complex systems and humanities approaches as a\nframework for capturing the essence of creating music based on rules of music\ntheory. Findings suggested that such rules matter for generating large-scale\npatterns of organized notes. Therefore, our formulation provides a novel\napproach for understanding and replicating aspects of the musical creativity.",
    "explanation":"The study is a theorical approach for exploring thge applicability of a D cellular automaton based on moelodic and harmonic intervals in random arrays of musical notes.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "The structure of musical harmony as an ordered phase of sound: A statistical mechanics approach to music theory"
    ],
    "b_abstract":[
      "Music, while allowing nearly unlimited creative expression, almost always conforms to a set of rigid rules at fundamental level. The description and study these rules, the ordered structures that arise from them, is basis field music theory. Here, I present theoretical formalism aims explain why basic patterns emerge in music, using same statistical mechanics framework describes emergent order across phase transitions physical systems. first apply mean approximation demonstrate occur this model disordered sound discrete sets pitches, including 12-fold octave division used Western music. Beyond model, use numerical simulation uncover musical harmony. These results provide new lens through which view discover ideas explore."
    ],
    "b_categories":[
      "cs.NA"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.15391"
    ],
    "c_title":[
      "Counting Abstraction for the Verification of Structured Parameterized\n  Networks"
    ],
    "c_abstract":[
      "We consider the verification of parameterized networks of replicated\n  processes whose architecture is described by hyperedge-replacement\n  graph grammars. Due to the undecidability of verification problems\n  such as reachability or coverability of a given configuration, in\n  which we count the number of replicas in each local state, we\n  develop two orthogonal verification techniques. We present a\n  counting abstraction able to produce, from a graph grammar\n  describing a parameterized system, a finite set of Petri nets that\n  over-approximate the behaviors of the original system. The counting\n  abstraction is implemented in a prototype tool, evalutated on a\n  non-trivial set of test cases. Moreover, we identify a decidable\n  fragment, for which the coverability problem is in 2EXPTIME\n  and PSPACE-hard."
    ],
    "c_categories":[
      "cs.FL"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.07453",
    "a_title":"Research on fault diagnosis of nuclear power first-second circuit based\n  on hierarchical multi-granularity classification network",
    "a_abstract":"The safe and reliable operation of complex electromechanical systems in\nnuclear power plants is crucial for the safe production of nuclear power plants\nand their nuclear power unit. Therefore, accurate and timely fault diagnosis of\nnuclear power systems is of great significance for ensuring the safe and\nreliable operation of nuclear power plants. The existing fault diagnosis\nmethods mainly target a single device or subsystem, making it difficult to\nanalyze the inherent connections and mutual effects between different types of\nfaults at the entire unit level. This article uses the AP1000 full-scale\nsimulator to simulate the important mechanical component failures of some key\nsystems in the primary and secondary circuits of nuclear power units, and\nconstructs a fault dataset. Meanwhile, a hierarchical multi granularity\nclassification fault diagnosis model based on the EfficientNet large model is\nproposed, aiming to achieve hierarchical classification of nuclear power\nfaults. The results indicate that the proposed fault diagnosis model can\neffectively classify faults in different circuits and system components of\nnuclear power units into hierarchical categories. However, the fault dataset in\nthis study was obtained from a simulator, which may introduce additional\ninformation due to parameter redundancy, thereby affecting the diagnostic\nperformance of the model.",
    "explanation":"The existing fault diagnosis methods of power plants mainly target a single device or subsystem, making it difficult to analyze the inherent connections and mutual effects between different types of faults at the entire unit level. The use of EfficientNet for classify faults in different circuits through a simulator.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Review of Research on Condition Assessment of Nuclear Power Plant Equipment Based on Data-Driven"
    ],
    "b_abstract":[
      "The condition assessment of the entire life cycle of nuclear power equipment has a significant impact on improving the safety and economy of nuclear power plants. In the past, operation and maintenance of systems, equipment, and structures of domestic nuclear power plants, mostly relied on the alarm mechanism of equipments, the simple threshold judgments of parameters, or the empirical judgments of engineers. With the implementation of online monitoring system in nuclear power plants, a large number of equipment operation data have been accumulated, and the use of data-driven technology to assess the health of equipment has become the focus of attention in the industry. In this paper, the current situation of the online monitoring system of nuclear power equipment was introduced and the common malfunction of nuclear power equipment was analyzed. The condition assessment of nuclear power equipment were categorized into three major problems (i.e., anomaly detection, life prediction, and fault diagnosis), the situation of research and application were summarized respectively, and the application potential of deep learning technology in this field was emphasized. Based on this, the challenges and possible solutions to the condition assessment of nuclear power plant equipment were further analyzed."
    ],
    "b_categories":[
      "nucl-th"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.21245"
    ],
    "c_title":[
      "TimesBERT: A BERT-Style Foundation Model for Time Series Understanding"
    ],
    "c_abstract":[
      "Time series analysis is crucial in diverse scenarios. Beyond forecasting,\nconsiderable real-world tasks are categorized into classification, imputation,\nand anomaly detection, underscoring different capabilities termed time series\nunderstanding in this paper. While GPT-style models have been positioned as\nfoundation models for time series forecasting, the BERT-style architecture,\nwhich has made significant advances in natural language understanding, has not\nbeen fully unlocked for time series understanding, possibly attributed to the\nundesirable dropout of essential elements of BERT. In this paper, inspired by\nthe shared multi-granularity structure between multivariate time series and\nmultisentence documents, we design TimesBERT to learn generic representations\nof time series including temporal patterns and variate-centric characteristics.\nIn addition to a natural adaptation of masked modeling, we propose a parallel\ntask of functional token prediction to embody vital multi-granularity\nstructures. Our model is pre-trained on 260 billion time points across diverse\ndomains. Leveraging multi-granularity representations, TimesBERT achieves\nstate-of-the-art performance across four typical downstream understanding\ntasks, outperforming task-specific models and language pre-trained backbones,\npositioning it as a versatile foundation model for time series understanding."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.07453",
    "a_title":"Research on fault diagnosis of nuclear power first-second circuit based\n  on hierarchical multi-granularity classification network",
    "a_abstract":"The safe and reliable operation of complex electromechanical systems in\nnuclear power plants is crucial for the safe production of nuclear power plants\nand their nuclear power unit. Therefore, accurate and timely fault diagnosis of\nnuclear power systems is of great significance for ensuring the safe and\nreliable operation of nuclear power plants. The existing fault diagnosis\nmethods mainly target a single device or subsystem, making it difficult to\nanalyze the inherent connections and mutual effects between different types of\nfaults at the entire unit level. This article uses the AP1000 full-scale\nsimulator to simulate the important mechanical component failures of some key\nsystems in the primary and secondary circuits of nuclear power units, and\nconstructs a fault dataset. Meanwhile, a hierarchical multi granularity\nclassification fault diagnosis model based on the EfficientNet large model is\nproposed, aiming to achieve hierarchical classification of nuclear power\nfaults. The results indicate that the proposed fault diagnosis model can\neffectively classify faults in different circuits and system components of\nnuclear power units into hierarchical categories. However, the fault dataset in\nthis study was obtained from a simulator, which may introduce additional\ninformation due to parameter redundancy, thereby affecting the diagnostic\nperformance of the model.",
    "explanation":"The existing fault diagnosis methods of power plants mainly target a single device or subsystem, making it difficult to analyze the inherent connections and mutual effects between different types of faults at the entire unit level. The use of EfficientNet for classify faults in different circuits through a simulator.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"
    ],
    "b_abstract":[
      "Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth\/width\/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. \nTo go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 \/ 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at this https URL."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.02787"
    ],
    "c_title":[
      "Super-enhanced Nuclear Fusion in Metal-like Systems and in Condensed\n  Plasmas of Supernova Progenitors"
    ],
    "c_abstract":[
      "In the scheme of chemonuclear reaction, bulk of itinerant s-electrons\nrevealing the thermodynamical liquid activity in metallic systems undergo\ncontact interaction with atomic nuclei and therein nucleons, inducing\ncontagiously thermodynamical liquid activity among the bulk of nuclei under the\nirreversible action of Nature towards the chemical potential minimum resulting\nin the united spontaneous, irreversible atomic and nuclear reactions. The\nchemonuclear reaction, moreover, is enhanced with astronomical figures besides\nthe enhancement of few particle processes (e.g., in the electron-screened\npycnonuclear fusion). In the systems of metal-like hydride\/deuteride and\nelectron donor mixtures, self-sustained H-H and D-D chemonuclear fusion may\ntake place. In these systems, however, some unforeseen phenomena are induced,\ne.g., radiation-less fusion and $\\gamma$-ray missing positron annihilation."
    ],
    "c_categories":[
      "nucl-th"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17971",
    "a_title":"Graph Neural Network for Cerebral Blood Flow Prediction With Clinical\n  Datasets",
    "a_abstract":"Accurate prediction of cerebral blood flow is essential for the diagnosis and\ntreatment of cerebrovascular diseases. Traditional computational methods,\nhowever, often incur significant computational costs, limiting their\npracticality in real-time clinical applications. This paper proposes a graph\nneural network (GNN) to predict blood flow and pressure in previously unseen\ncerebral vascular network structures that were not included in training data.\nThe GNN was developed using clinical datasets from patients with stenosis,\nfeaturing complex and abnormal vascular geometries. Additionally, the GNN model\nwas trained on data incorporating a wide range of inflow conditions, vessel\ntopologies, and network connectivities to enhance its generalization\ncapability. The approach achieved Pearson's correlation coefficients of 0.727\nfor pressure and 0.824 for flow rate, with sufficient training data. These\nfindings demonstrate the potential of the GNN for real-time cerebrovascular\ndiagnostics, particularly in handling intricate and pathological vascular\nnetworks.",
    "explanation":"This paper proposes a graph neural network (GNN) to predict blood flow and pressure in previously unseen cerebral vascular network structures that were not included in training data.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Multiscale modeling and simulation of brain blood flow"
    ],
    "b_abstract":[
      "The aim of this work is to present an overview recent advances in multi-scale modeling brain blood flow. In particular, we some approaches that enable the silico study and multi-physics phenomena cerebral vasculature. We discuss formulation continuum atomistic approaches, a consistent framework for their concurrent coupling, list challenges one needs overcome achieving seamless scalable integration heterogeneous numerical solvers. effectiveness proposed demonstrated realistic case involving thrombus formation process taking place on wall patient-specific aneurysm. This highlights ability algorithms resolve important biophysical processes span several spatial temporal scales, potentially yielding new insight into key aspects flow health disease. Finally, open questions emerging topics future research."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.17669"
    ],
    "c_title":[
      "TDRI: Two-Phase Dialogue Refinement and Co-Adaptation for Interactive\n  Image Generation"
    ],
    "c_abstract":[
      "Although text-to-image generation technologies have made significant\nadvancements, they still face challenges when dealing with ambiguous prompts\nand aligning outputs with user intent.Our proposed framework, TDRI (Two-Phase\nDialogue Refinement and Co-Adaptation), addresses these issues by enhancing\nimage generation through iterative user interaction. It consists of two phases:\nthe Initial Generation Phase, which creates base images based on user prompts,\nand the Interactive Refinement Phase, which integrates user feedback through\nthree key modules. The Dialogue-to-Prompt (D2P) module ensures that user\nfeedback is effectively transformed into actionable prompts, which improves the\nalignment between user intent and model input. By evaluating generated outputs\nagainst user expectations, the Feedback-Reflection (FR) module identifies\ndiscrepancies and facilitates improvements. In an effort to ensure consistently\nhigh-quality results, the Adaptive Optimization (AO) module fine-tunes the\ngeneration process by balancing user preferences and maintaining prompt\nfidelity. Experimental results show that TDRI outperforms existing methods by\nachieving 33.6% human preference, compared to 6.2% for GPT-4 augmentation, and\nthe highest CLIP and BLIP alignment scores (0.338 and 0.336, respectively). In\niterative feedback tasks, user satisfaction increased to 88% after 8 rounds,\nwith diminishing returns beyond 6 rounds. Furthermore, TDRI has been found to\nreduce the number of iterations and improve personalization in the creation of\nfashion products. TDRI exhibits a strong potential for a wide range of\napplications in the creative and industrial domains, as it streamlines the\ncreative process and improves alignment with user preferences"
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17971",
    "a_title":"Graph Neural Network for Cerebral Blood Flow Prediction With Clinical\n  Datasets",
    "a_abstract":"Accurate prediction of cerebral blood flow is essential for the diagnosis and\ntreatment of cerebrovascular diseases. Traditional computational methods,\nhowever, often incur significant computational costs, limiting their\npracticality in real-time clinical applications. This paper proposes a graph\nneural network (GNN) to predict blood flow and pressure in previously unseen\ncerebral vascular network structures that were not included in training data.\nThe GNN was developed using clinical datasets from patients with stenosis,\nfeaturing complex and abnormal vascular geometries. Additionally, the GNN model\nwas trained on data incorporating a wide range of inflow conditions, vessel\ntopologies, and network connectivities to enhance its generalization\ncapability. The approach achieved Pearson's correlation coefficients of 0.727\nfor pressure and 0.824 for flow rate, with sufficient training data. These\nfindings demonstrate the potential of the GNN for real-time cerebrovascular\ndiagnostics, particularly in handling intricate and pathological vascular\nnetworks.",
    "explanation":"This paper proposes a graph neural network (GNN) to predict blood flow and pressure in previously unseen cerebral vascular network structures that were not included in training data.",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "Learning Reduced-Order Models for Cardiovascular Simulations with Graph Neural Networks"
    ],
    "b_abstract":[
      "Reduced-order models based on physics are a popular choice in cardiovascular modeling due to their efficiency, but they may experience loss in accuracy when working with anatomies that contain numerous junctions or pathological conditions. We develop one-dimensional reduced-order models that simulate blood flow dynamics using a graph neural network trained on three-dimensional hemodynamic simulation data. Given the initial condition of the system, the network iteratively predicts the pressure and flow rate at the vessel centerline nodes. Our numerical results demonstrate the accuracy and generalizability of our method in physiological geometries comprising a variety of anatomies and boundary conditions. Our findings demonstrate that our approach can achieve errors below 3% for pressure and flow rate, provided there is adequate training data. As a result, our method exhibits superior performance compared to physics-based one-dimensional models while maintaining high efficiency at inference time."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.13516"
    ],
    "c_title":[
      "A tumor-immune model of chronic myeloid leukemia with optimal\n  immunotherapeutic protocols"
    ],
    "c_abstract":[
      "The interactions between tumor cells and the immune system play a crucial\nrole in cancer evolution. In this study, we explore how these interactions\ninfluence cancer progression by modeling the relationships among naive T cells,\neffector T cells, and chronic myeloid leukemia cells. We examine the existence\nof equilibria, the asymptotic stability of the positive steady state, and the\nglobal stability of the tumor-free equilibrium. Additionally, we develop a\npartial differential equation to describe the conditions under which the\nconcentration of cancer cells reaches a level that allows for effective control\nof cancer evolution. Finally, we apply our proposed model to investigate\noptimal treatment strategies that aim to minimize both the concentration of\ncancer cells at the end of treatment and the accumulation of tumor burden, as\nwell as the cost associated with treatment during the intervention period. Our\nstudy reveals an optimal therapeutic protocol using optimal control theory. We\nperform numerical simulations to illustrate our theoretical results and to\nexplore the dynamic behavior of the system and optimal therapeutic protocols.\nThe simulations indicate that the optimal treatment strategy can be more\neffective than a constant treatment approach, even when applying the same\ntreatment interval and total drug input."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.18141",
    "a_title":"Predicting Water Quality using Quantum Machine Learning: The Case of the\n  Umgeni Catchment (U20A) Study Region",
    "a_abstract":"In this study, we consider a real-world application of QML techniques to\nstudy water quality in the U20A region in Durban, South Africa. Specifically,\nwe applied the quantum support vector classifier (QSVC) and quantum neural\nnetwork (QNN), and we showed that the QSVC is easier to implement and yields a\nhigher accuracy. The QSVC models were applied for three kernels: Linear,\npolynomial, and radial basis function (RBF), and it was shown that the\npolynomial and RBF kernels had exactly the same performance. The QNN model was\napplied using different optimizers, learning rates, noise on the circuit\ncomponents, and weight initializations were considered, but the QNN\npersistently ran into the dead neuron problem. Thus, the QNN was compared only\nby accraucy and loss, and it was shown that with the Adam optimizer, the model\nhas the best performance, however, still less than the QSVC.",
    "explanation":"In this study, we consider a real-world application of QML techniques to study water quality in the U20A region in Durban, South Africa.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "Quantum machine learning in chemistry and materials"
    ],
    "b_abstract":[
      "Within the past few years, we have witnessed the rising of quantum machine learning (QML) models which infer electronic properties of molecules and materials, rather than solving approximations to the electronic Schr\u00f6dinger equation. The increasing availability of large quantum mechanics reference datasets has enabled these developments. We review the basic theories and key ingredients of popular QML models such as choice of regressor, data of varying trustworthiness, the role of the representation, and the effect of training set selection. Throughout we emphasize the indispensable role of learning curves when it comes to the comparative assessment of different QML models."
    ],
    "b_categories":[
      "cs.ET"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.06355"
    ],
    "c_title":[
      "Charge-Density-Wave Oscillator Networks for Solving Combinatorial\n  Optimization Problems"
    ],
    "c_abstract":[
      "Many combinatorial optimization problems fall into the non-polynomial time\nNP-hard complexity class, characterized by computational demands that increase\nexponentially with the size of the problem in the worst case. Solving\nlarge-scale combinatorial optimization problems efficiently requires novel\nhardware solutions beyond the conventional von Neumann architecture. We propose\nan approach for solving a type of NP-hard problem based on coupled oscillator\nnetworks implemented with charge-density-wave condensate devices. Our prototype\nhardware, based on the 1T polymorph of TaS2, reveals the switching between the\ncharge-density-wave electron-phonon condensate phases, enabling\nroom-temperature operation of the network. The oscillator operation relies on\nhysteresis in current-voltage characteristics and bistability triggered by\napplied electrical bias. This work presents a network of injection-locked,\ncoupled oscillators whose phase dynamics follow the Kuramoto model and\ndemonstrates that such coupled quantum oscillators naturally evolve to a ground\nstate capable of solving combinatorial optimization problems. The coupled\noscillators based on charge-density-wave condensate phases can efficiently\nsolve NP-hard Max-Cut benchmark problems, offering advantages over other\nleading oscillator-based approaches. The nature of the transitions between the\ncharge-density-wave phases, distinctively different from resistive switching,\ncreates the potential for low-power operation and compatibility with\nconventional Si technology."
    ],
    "c_categories":[
      "cond-mat.mtrl-sci"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.18141",
    "a_title":"Predicting Water Quality using Quantum Machine Learning: The Case of the\n  Umgeni Catchment (U20A) Study Region",
    "a_abstract":"In this study, we consider a real-world application of QML techniques to\nstudy water quality in the U20A region in Durban, South Africa. Specifically,\nwe applied the quantum support vector classifier (QSVC) and quantum neural\nnetwork (QNN), and we showed that the QSVC is easier to implement and yields a\nhigher accuracy. The QSVC models were applied for three kernels: Linear,\npolynomial, and radial basis function (RBF), and it was shown that the\npolynomial and RBF kernels had exactly the same performance. The QNN model was\napplied using different optimizers, learning rates, noise on the circuit\ncomponents, and weight initializations were considered, but the QNN\npersistently ran into the dead neuron problem. Thus, the QNN was compared only\nby accraucy and loss, and it was shown that with the Adam optimizer, the model\nhas the best performance, however, still less than the QSVC.",
    "explanation":"In this study, we consider a real-world application of QML techniques to study water quality in the U20A region in Durban, South Africa.",
    "b_id":[
      "b26"
    ],
    "b_title":[
      "Durban's water wars, sewage spills, fish kills and blue flag beaches. Durban's Climate Gamble"
    ],
    "b_abstract":[
      "Water is one of the primary barometers of climate change: A rise in sea-levels, flooding, and extreme storms combined with general water stress and more severe and frequent droughts will escalate crises in municipal infrastructure, requiring continual upgrades for water purification, stormwater drainage, and sewage treatment, all of which will dramatically raise the price of water at the retail level. In South Africa, the dry western side will be most adversely affected by droughts (threatening the production of rooibos tea and Cape wines). According to the Academy of Science in South Africa (ASSAf), Durban is also at great risk and will experience higher temperatures and heat stress, volatile rainfall, up to 160 million cubic metres less water each year by 2100, a sea-level rise of up to a metre by 2100 across Durban\u2019s 100 km of developed coastline, lower biodiversity, higher disease levels (especially malaria and cholera), declining agricultural output (a one degree Celsius rise leaves the surrounding region unreliable for the staple maize production), and other economic stresses (ASSAf 2011: 27). Tourism, one of Durban\u2019s main economic engines, will be irreparably harmed. Swimmers and surfers think of Durban\u2019s beachfront as one of the world\u2019s finest in any urban context. After apartheid-era rules that prohibited black people from using the best beaches were lifted at the end of the 1980s, the area stretching from the Blue Lagoon\u2019s Umgeni River to South Beach\u2019s uShaka Marine World\u2013including the immensely popular North Beach area near the main restaurant strip\u2013represented one of South Africa\u2019s most impressive, open and democratic public spaces."
    ],
    "b_categories":[
      "cond-mat.mtrl-sci"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.17548"
    ],
    "c_title":[
      "Limitations in Parallel Ising Machine Networks: Theory and Practice"
    ],
    "c_abstract":[
      "Analog Ising machines (IMs) occupy an increasingly prominent area of computer\narchitecture research, offering high-quality and low latency\/energy solutions\nto intractable computing tasks. However, IMs have a fixed capacity, with little\nto no utility in out-of-capacity problems. Previous works have proposed\nparallel, multi-IM architectures to circumvent this limitation. In this work we\ntheoretically and numerically investigate tradeoffs in parallel IM networks to\nguide researchers in this burgeoning field. We propose formal models of\nparallel IM excution models, then provide theoretical guarantees for\nprobabilistic convergence. Numerical experiments illustrate our findings and\nprovide empirical insight into high and low synchronization frequency regimes.\nWe also provide practical heuristics for parameter\/model selection, informed by\nour theoretical and numerical findings."
    ],
    "c_categories":[
      "cs.ET"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.16349",
    "a_title":"Machine learning for cerebral blood vessels' malformations",
    "a_abstract":"Cerebral aneurysms and arteriovenous malformations are life-threatening\nhemodynamic pathologies of the brain. While surgical intervention is often\nessential to prevent fatal outcomes, it carries significant risks both during\nthe procedure and in the postoperative period, making the management of these\nconditions highly challenging. Parameters of cerebral blood flow, routinely\nmonitored during medical interventions, could potentially be utilized in\nmachine learning-assisted protocols for risk assessment and therapeutic\nprognosis. To this end, we developed a linear oscillatory model of blood\nvelocity and pressure for clinical data acquired from neurosurgical operations.\nUsing the method of Sparse Identification of Nonlinear Dynamics (SINDy), the\nparameters of our model can be reconstructed online within milliseconds from a\nshort time series of the hemodynamic variables. The identified parameter values\nenable automated classification of the blood-flow pathologies by means of\nlogistic regression, achieving an accuracy of 73 %. Our results demonstrate the\npotential of this model for both diagnostic and prognostic applications,\nproviding a robust and interpretable framework for assessing cerebral blood\nvessel conditions.",
    "explanation":"Parameters of cerebral blood flow, routinely monitored during medical interventions or with modern noninvasive high-resolution imaging methods, could potentially be utilized in machine learning-assisted protocols for risk assessment and therapeutic prognosis.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Cerebral aneurysms. New Engl. J. Medicine"
    ],
    "b_abstract":[
      "Saccular intracranial aneurysms cause substantial morbidity and mortality. Recently, major changes have occurred in the way we think about and treat this disease. This review discusses the percutaneous endovascular treatment of intracranial aneurysms as compared with surgical intervention. The technological advances and supporting research contributing to this important change in practice patterns are reviewed."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.14545"
    ],
    "c_title":[
      "An Entropic Metric for Measuring Calibration of Machine Learning Models"
    ],
    "c_abstract":[
      "Understanding the confidence with which a machine learning model classifies\nan input datum is an important, and perhaps under-investigated, concept. In\nthis paper, we propose a new calibration metric, the Entropic Calibration\nDifference (ECD). Based on existing research in the field of state estimation,\nspecifically target tracking (TT), we show how ECD may be applied to binary\nclassification machine learning models. We describe the relative importance of\nunder- and over-confidence and how they are not conflated in the TT literature.\nIndeed, our metric distinguishes under- from over-confidence. We consider this\nimportant given that algorithms that are under-confident are likely to be\n'safer' than algorithms that are over-confident, albeit at the expense of also\nbeing over-cautious and so statistically inefficient. We demonstrate how this\nnew metric performs on real and simulated data and compare with other metrics\nfor machine learning model probability calibration, including the Expected\nCalibration Error (ECE) and its signed counterpart, the Expected Signed\nCalibration Error (ESCE)."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.16349",
    "a_title":"Machine learning for cerebral blood vessels' malformations",
    "a_abstract":"Cerebral aneurysms and arteriovenous malformations are life-threatening\nhemodynamic pathologies of the brain. While surgical intervention is often\nessential to prevent fatal outcomes, it carries significant risks both during\nthe procedure and in the postoperative period, making the management of these\nconditions highly challenging. Parameters of cerebral blood flow, routinely\nmonitored during medical interventions, could potentially be utilized in\nmachine learning-assisted protocols for risk assessment and therapeutic\nprognosis. To this end, we developed a linear oscillatory model of blood\nvelocity and pressure for clinical data acquired from neurosurgical operations.\nUsing the method of Sparse Identification of Nonlinear Dynamics (SINDy), the\nparameters of our model can be reconstructed online within milliseconds from a\nshort time series of the hemodynamic variables. The identified parameter values\nenable automated classification of the blood-flow pathologies by means of\nlogistic regression, achieving an accuracy of 73 %. Our results demonstrate the\npotential of this model for both diagnostic and prognostic applications,\nproviding a robust and interpretable framework for assessing cerebral blood\nvessel conditions.",
    "explanation":"Parameters of cerebral blood flow, routinely monitored during medical interventions or with modern noninvasive high-resolution imaging methods, could potentially be utilized in machine learning-assisted protocols for risk assessment and therapeutic prognosis.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "Data-driven science and engineering: machine learning, dynamical systems, and control"
    ],
    "b_abstract":[
      "\"Data-driven science and engineering: machine learning, dynamical systems, control.\" Contemporary Physics, 60(4), p. 320"
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.12234"
    ],
    "c_title":[
      "Tumor microenvironment (Part I): Tissue integrity in a rat model of\n  peripheral neural cancer"
    ],
    "c_abstract":[
      "ICAM-1 (intercellular adhesion molecule 1) and MPZ (myelin protein zero) are\nthought to be a factor in the integrity of nerve tissues. In this report, we\nattempted to trace the expression of ICAM-1, responsible for cell-to-cell\nadhesion, and of MPZ, the main constituent of myelin sheath, in malignant\ntissues of the sciatic nerve (SN) in inbred male Copenhagen rats. AT-1 Cells\n(anaplastic tumor 1) were injected in the perineurial sheath, and tissues of\nthe SNs were collected after 7, 14 and 21 days and compared to a sham-operated\ngroup of rats (n = 6 each). Tissues were sectioned and histologically examined,\nunder light microscope, and stained for measuring the immunoreactivity of\nICAM-1 and MPZ under laser scanning microscope. The cancer model was\nestablished, and the tumor growth was confirmed. ICAM-1 showed severe\ndecreases, proportional to the growing anaplastic cells, as compared to the\nsham group. MPZ revealed, however, a distinct defensive pattern before\nsubstantially decreasing in a comparison with sham. These results support the\nnotion that malignancies damage peripheral nerves and cause severe axonal\ninjury and loss of neuronal integrity, and clearly define the role of ICAM-1\nand MPZ in safeguarding the nerve tissues."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.19000",
    "a_title":"A Unified Platform for At-Home Post-Stroke Rehabilitation Enabled by\n  Wearable Technologies and Artificial Intelligence",
    "a_abstract":"At-home rehabilitation for post-stroke patients presents significant\nchallenges, as continuous, personalized care is often limited outside clinical\nsettings. Additionally, the absence of comprehensive solutions addressing\ndiverse rehabilitation needs in home environments complicates recovery efforts.\nHere, we introduce a smart home platform that integrates wearable sensors,\nambient monitoring, and large language model (LLM)-powered assistance to\nprovide seamless health monitoring and intelligent support. The system\nleverages machine learning enabled plantar pressure arrays for motor recovery\nassessment (94% classification accuracy), a wearable eye-tracking module for\ncognitive evaluation, and ambient sensors for precise smart home control (100%\noperational success, <1 s latency). Additionally, the LLM-powered agent,\nAuto-Care, offers real-time interventions, such as health reminders and\nenvironmental adjustments, enhancing user satisfaction by 29%. This work\nestablishes a fully integrated platform for long-term, personalized\nrehabilitation, offering new possibilities for managing chronic conditions and\nsupporting aging populations.",
    "explanation":"Here, we present a multimodal smart home platform designed for continuous, at-home rehabilitation of post-stroke patients, integrating wearable sensing, ambient monitoring, and adaptive automation.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Addressing disparities in the global epidemiology of stroke"
    ],
    "b_abstract":[
      "Stroke is the second leading cause of death and the third leading cause of disability worldwide. Though the burden of stroke worldwide seems to have declined in the past three decades, much of this effect reflects decreases in high-income countries (HICs). By contrast, the burden of stroke has grown rapidly in low-income and middle-income countries (LMICs), where epidemiological, socioeconomic and demographic shifts have increased the incidence of stroke and other non-communicable diseases. Furthermore, even in HICs, disparities in stroke epidemiology exist along racial, ethnic, socioeconomic and geographical lines. In this Review, we highlight the under-acknowledged disparities in the burden of stroke. We emphasize the shifting global landscape of stroke risk factors, critical gaps in stroke service delivery, and the need for a more granular analysis of the burden of stroke within and between LMICs and HICs to guide context-appropriate capacity-building. Finally, we review strategies for addressing key inequalities in stroke epidemiology, including improvements in epidemiological surveillance and context-specific research efforts in under-resourced regions, development of the global workforce of stroke care providers, expansion of access to preventive and treatment services through mobile and telehealth platforms, and scaling up of evidence-based strategies and policies that target local, national, regional and global stroke disparities."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.02976"
    ],
    "c_title":[
      "Teaching AI to Handle Exceptions: Supervised Fine-Tuning with\n  Human-Aligned Judgment"
    ],
    "c_abstract":[
      "Large language models (LLMs), initially developed for generative AI, are now\nevolving into agentic AI systems, which make decisions in complex, real-world\ncontexts. Unfortunately, while their generative capabilities are\nwell-documented, their decision-making processes remain poorly understood. This\nis particularly evident when models are handling exceptions, a critical and\nchallenging aspect of decision-making made relevant by the inherent\nincompleteness of contracts. Here we demonstrate that LLMs, even ones that\nexcel at reasoning, deviate significantly from human judgments because they\nadhere strictly to policies, even when such adherence is impractical,\nsuboptimal, or even counterproductive. We then evaluate three approaches to\ntuning AI agents to handle exceptions: ethical framework prompting,\nchain-of-thought reasoning, and supervised fine-tuning. We find that while\nethical framework prompting fails and chain-of-thought prompting provides only\nslight improvements, supervised fine-tuning, specifically with human\nexplanations, yields markedly better results. Surprisingly, in our experiments,\nsupervised fine-tuning even enabled models to generalize human-like\ndecision-making to novel scenarios, demonstrating transfer learning of\nhuman-aligned decision-making across contexts. Furthermore, fine-tuning with\nexplanations, not just labels, was critical for alignment, suggesting that\naligning LLMs with human judgment requires explicit training on how decisions\nare made, not just which decisions are made. These findings highlight the need\nto address LLMs' shortcomings in handling exceptions in order to guide the\ndevelopment of agentic AI toward models that can effectively align with human\njudgment and simultaneously adapt to novel contexts."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.19000",
    "a_title":"A Unified Platform for At-Home Post-Stroke Rehabilitation Enabled by\n  Wearable Technologies and Artificial Intelligence",
    "a_abstract":"At-home rehabilitation for post-stroke patients presents significant\nchallenges, as continuous, personalized care is often limited outside clinical\nsettings. Additionally, the absence of comprehensive solutions addressing\ndiverse rehabilitation needs in home environments complicates recovery efforts.\nHere, we introduce a smart home platform that integrates wearable sensors,\nambient monitoring, and large language model (LLM)-powered assistance to\nprovide seamless health monitoring and intelligent support. The system\nleverages machine learning enabled plantar pressure arrays for motor recovery\nassessment (94% classification accuracy), a wearable eye-tracking module for\ncognitive evaluation, and ambient sensors for precise smart home control (100%\noperational success, <1 s latency). Additionally, the LLM-powered agent,\nAuto-Care, offers real-time interventions, such as health reminders and\nenvironmental adjustments, enhancing user satisfaction by 29%. This work\nestablishes a fully integrated platform for long-term, personalized\nrehabilitation, offering new possibilities for managing chronic conditions and\nsupporting aging populations.",
    "explanation":"Here, we present a multimodal smart home platform designed for continuous, at-home rehabilitation of post-stroke patients, integrating wearable sensing, ambient monitoring, and adaptive automation.",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Artificial intelligence applications in stroke"
    ],
    "b_abstract":[
      "Management of stroke highly depends on information from imaging studies. Noncontrast computed tomography (CT) and magnetic resonance imaging (MRI) can both be used to distinguish between ischemic and hemorrhagic stroke, which is difficult based on clinical features. Hypodensity on CT and DWI hyperintensity on MRI identifies irreversibly damaged tissue, although the sensitivity of MRI is higher in the acute setting. Angiographic and perfusion imaging sequences can identify a large vessel occlusion and, along with perfusion imaging, can select patients for endovascular therapy. The FLAIR-DWI mismatch yields information about patients with unknown time of onset (including wake-up strokes). Stroke imaging also gives insight into prognosis, with current methods aiming to give a picture of the short-term consequences of successful reperfusion or continued large vessel occlusion. One important caveat about stroke imaging is that it must be done quickly, as faster treatment leads to better outcomes.1 However, most steps in the stroke imaging triage pathway require the presence of human radiologists and neurologists, and this is often the time-limiting step. The expertise required for these tasks may not be available at all sites or at all times. Therefore, there is interest in automated methods for stroke imaging evaluation. Artificial intelligence (AI) is a broad term reflecting the use of computers to perform tasks that humans may find difficult, often in ways that are hard to pinpoint. For example, although humans find high-level computation difficult, calculator technology is not considered AI because we know how to break this down into discrete steps and feel we understand it. However, facial recognition is a task that humans perform well, but an algorithm to identify faces is usually considered AI since we cannot articulate precisely how this is done. Machine learning (ML) is a subset of AI in which algorithms learn from the data itself without explicit programming. ML methods reflect a broad range of statistical techniques ranging from linear regression to more complex methods such as support vector machines and decision trees. ML methods can be further broken into supervised and unsupervised learning, which differ from one another in that the former requires access to gold standard labels although the latter attempts to find the answers implicitly in the data itself. While ML methods have grown more popular over recent years, the advent of a specific supervised ML method based on architectures resembling human neural networks over the past decade has led to a quantum leap in performance.2 This method, called deep learning (DL) because of many multiple internal layers, can be considered a transformative technology. Compared with previous methods that required humans to identify image features, a deep neural network trained on a dataset with known outputs can learn the best features for organizing the data. In this review, we will discuss ML methods applied to stroke imaging with an emphasis on DL applications. We refer to Figure for a graphical overview of the applications discussed in this review."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.11591"
    ],
    "c_title":[
      "Morphological Neuron Classification Using Machine Learning"
    ],
    "c_abstract":[
      "Classification and quantitative characterization of neuronal morphologies\nfrom histological neuronal reconstruction is challenging since it is still\nunclear how to delineate a neuronal cell class and which are the best features\nto define them by. The morphological neuron characterization represents a\nprimary source to address anatomical comparisons, morphometric analysis of\ncells, or brain modeling. The objectives of this paper are (i) to develop and\nintegrate a pipeline that goes from morphological feature extraction to\nclassification and (ii) to assess and compare the accuracy of machine learning\nalgorithms to classify neuron morphologies. The algorithms were trained on 430\ndigitally reconstructed neurons subjectively classified into layers and\/or\nm-types using young and\/or adult development state population of the\nsomatosensory cortex in rats. For supervised algorithms, linear discriminant\nanalysis provided better classification results in comparison with others. For\nunsupervised algorithms, the affinity propagation and the Ward algorithms\nprovided slightly better results."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.10570",
    "a_title":"Normative Modeling for AD Diagnosis and Biomarker Identification",
    "a_abstract":"In this paper, we introduce a novel normative modeling approach that\nincorporates focal loss and adversarial autoencoders (FAAE) for Alzheimer's\nDisease (AD) diagnosis and biomarker identification. Our method is an\nend-to-end approach that embeds an adversarial focal loss discriminator within\nthe autoencoder structure, specifically designed to effectively target and\ncapture more complex and challenging cases. We first use the enhanced\nautoencoder to create a normative model based on data from healthy control (HC)\nindividuals. We then apply this model to estimate total and regional\nneuroanatomical deviation in AD patients. Through extensive experiments on the\nOASIS-3 and ADNI datasets, our approach significantly outperforms previous\nstate-of-the-art methods. This advancement not only streamlines the detection\nprocess but also provides a greater insight into the biomarker potential for\nAD. Our code can be found at \\url{https:\/\/github.com\/soz223\/FAAE}.",
    "explanation":"In this paper, we introduce a novel normative modeling ap proach that incorporates focal loss and adversarial autoencoders (FAAE) for Alzheimer\u2019s Disease (AD) diagnosis and biomarker identification",
    "b_id":[
      "b13"
    ],
    "b_title":[
      "Using deep autoencoders to identify abnormal brain structural patterns in neuropsychiatric disorders: A large\u2010scale multi\u2010sample study"
    ],
    "b_abstract":[
      "Machine learning is becoming an increasingly popular approach for investigating spatially distributed and subtle neuroanatomical alterations in brain\u2010based disorders. However, some machine learning models have been criticized for requiring a large number of cases in each experimental group, and for resembling a \u201cblack box\u201d that provides little or no insight into the nature of the data. In this article, we propose an alternative conceptual and practical approach for investigating brain\u2010based disorders which aim to overcome these limitations. We used an artificial neural network known as \u201cdeep autoencoder\u201d to create a normative model using structural magnetic resonance imaging data from 1,113 healthy people. We then used this model to estimate total and regional neuroanatomical deviation in individual patients with schizophrenia and autism spectrum disorder using two independent data sets (n =\u2009263). We report that the model was able to generate different values of total neuroanatomical deviation for each disease under investigation relative to their control group (p <\u2009.005). Furthermore, the model revealed distinct patterns of neuroanatomical deviations for the two diseases, consistent with the existing neuroimaging literature. We conclude that the deep autoencoder provides a flexible and promising framework for assessing total and regional neuroanatomical deviations in neuropsychiatric populations."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.11201"
    ],
    "c_title":[
      "Evolution of diverse (and advanced) cognitive abilities through adaptive\n  fine-tuning of learning and chunking mechanisms"
    ],
    "c_abstract":[
      "The evolution of cognition is frequently discussed as the evolution of\ncognitive abilities or the evolution of some neuronal structures in the brain.\nHowever, since such traits or abilities are often highly complex, understanding\ntheir evolution requires explaining how they could have gradually evolved\nthrough selection acting on heritable variations in simpler cognitive\nmechanisms. With this in mind, making use of a previously proposed theory, here\nwe show how the evolution of cognitive abilities can be captured by the\nfine-tuning of basic learning mechanisms and, in particular, chunking\nmechanisms. We use the term chunking broadly for all types of non-elemental\nlearning, claiming that the process by which elements are combined into chunks\nand associated with other chunks, or elements, is critical for what the brain\ncan do, and that it must be fine-tuned to ecological conditions. We discuss the\nrelevance of this approach to studies in animal cognition, using examples from\nanimal foraging and decision-making, problem solving, and cognitive\nflexibility. Finally, we explain how even the apparent human-animal gap in\nsequence learning ability can be explained in terms of different fine-tunings\nof a similar chunking process."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.10570",
    "a_title":"Normative Modeling for AD Diagnosis and Biomarker Identification",
    "a_abstract":"In this paper, we introduce a novel normative modeling approach that\nincorporates focal loss and adversarial autoencoders (FAAE) for Alzheimer's\nDisease (AD) diagnosis and biomarker identification. Our method is an\nend-to-end approach that embeds an adversarial focal loss discriminator within\nthe autoencoder structure, specifically designed to effectively target and\ncapture more complex and challenging cases. We first use the enhanced\nautoencoder to create a normative model based on data from healthy control (HC)\nindividuals. We then apply this model to estimate total and regional\nneuroanatomical deviation in AD patients. Through extensive experiments on the\nOASIS-3 and ADNI datasets, our approach significantly outperforms previous\nstate-of-the-art methods. This advancement not only streamlines the detection\nprocess but also provides a greater insight into the biomarker potential for\nAD. Our code can be found at \\url{https:\/\/github.com\/soz223\/FAAE}.",
    "explanation":"In this paper, we introduce a novel normative modeling ap proach that incorporates focal loss and adversarial autoencoders (FAAE) for Alzheimer\u2019s Disease (AD) diagnosis and biomarker identification",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "Using normative modelling to detect disease progression in mild cognitive impairment and Alzheimer\u2019s disease in a cross-sectional multi-cohort study"
    ],
    "b_abstract":[
      "Normative modelling is an emerging method for quantifying how individuals deviate from the healthy populational pattern. Several machine learning models have been implemented to develop normative models to investigate brain disorders, including regression, support vector machines and Gaussian process models. With the advance of deep learning technology, the use of deep neural networks has also been proposed. In this study, we assessed normative models based on deep autoencoders using structural neuroimaging data from patients with Alzheimer\u2019s disease (n\u2009=\u2009206) and mild cognitive impairment (n\u2009=\u2009354). We first trained the autoencoder on an independent dataset (UK Biobank dataset) with 11,034 healthy controls. Then, we estimated how each patient deviated from this norm and established which brain regions were associated to this deviation. Finally, we compared the performance of our normative model against traditional classifiers. As expected, we found that patients exhibited deviations according to the severity of their clinical condition. The model identified medial temporal regions, including the hippocampus, and the ventricular system as critical regions for the calculation of the deviation score. Overall, the normative model had comparable cross-cohort generalizability to traditional classifiers. To promote open science, we are making all scripts and the trained models available to the wider research community."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.00594"
    ],
    "c_title":[
      "Estimation of total body fat using symbolic regression and evolutionary\n  algorithms"
    ],
    "c_abstract":[
      "Body fat percentage is an increasingly popular alternative to Body Mass Index\nto measure overweight and obesity, offering a more accurate representation of\nbody composition. In this work, we evaluate three evolutionary computation\ntechniques, Grammatical Evolution, Context-Free Grammar Genetic Programming,\nand Dynamic Structured Grammatical Evolution, to derive an interpretable\nmathematical expression to estimate the percentage of body fat that are also\naccurate. Our primary objective is to obtain a model that balances accuracy\nwith explainability, making it useful for clinical and health applications. We\ncompare the performance of the three variants on a public anthropometric\ndataset and compare the results obtained with the QLattice framework.\nExperimental results show that grammatical evolution techniques can obtain\ncompetitive results in performance and interpretability."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.14474",
    "a_title":"Attention-guided Spectrogram Sequence Modeling with CNNs for Music Genre\n  Classification",
    "a_abstract":"Music genre classification is a critical component of music recommendation\nsystems, generation algorithms, and cultural analytics. In this work, we\npresent an innovative model for classifying music genres using attention-based\ntemporal signature modeling. By processing spectrogram sequences through\nConvolutional Neural Networks (CNNs) and multi-head attention layers, our\napproach captures the most temporally significant moments within each piece,\ncrafting a unique \"signature\" for genre identification. This temporal focus not\nonly enhances classification accuracy but also reveals insights into\ngenre-specific characteristics that can be intuitively mapped to listener\nperceptions. Our findings offer potential applications in personalized music\nrecommendation systems by highlighting cross-genre similarities and\ndistinctiveness, aligning closely with human musical intuition. This work\nbridges the gap between technical classification tasks and the nuanced, human\nexperience of genre.",
    "explanation":"In this work, we present an innovative model for classifying music genres using attention based temporal signature modeling. By processing spectrogram sequences through Convolutional Neural Networks (CNNs) and multi-head attention layers, our approach captures the most temporally significant moments within each piece, crafting a unique \u201dsignature\u201d for genre identification",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Convolutional recurrent neural networks for music classification"
    ],
    "b_abstract":[
      "We introduce a convolutional recurrent neural network (CRNN) for music tagging. CRNNs take advantage of networks (CNNs) local feature extraction and temporal summarisation the extracted features. compare CRNN with three CNN structures that have been used tagging while controlling number parameters respect to their performance training time per sample. Overall, we found show strong parameter time, indicating effectiveness its hybrid structure in summarisation."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.01247"
    ],
    "c_title":[
      "About the Keplerization of motion in any central force field"
    ],
    "c_abstract":[
      "The method of keplerization of one-body motion in any central force field,\nintroduced by Martinusi and Gurfil in 2012, is reviewed and reformulated into a\ngeneral homogenization method which applies to any kind of bounded motion. It\nis also shown how this extended method provides a proof of the existence of a\ndynamical symmetry group and how it can be used to extend that group to a\nglobal symmetry group, for any such system"
    ],
    "c_categories":[
      "physics.class-ph"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.14474",
    "a_title":"Attention-guided Spectrogram Sequence Modeling with CNNs for Music Genre\n  Classification",
    "a_abstract":"Music genre classification is a critical component of music recommendation\nsystems, generation algorithms, and cultural analytics. In this work, we\npresent an innovative model for classifying music genres using attention-based\ntemporal signature modeling. By processing spectrogram sequences through\nConvolutional Neural Networks (CNNs) and multi-head attention layers, our\napproach captures the most temporally significant moments within each piece,\ncrafting a unique \"signature\" for genre identification. This temporal focus not\nonly enhances classification accuracy but also reveals insights into\ngenre-specific characteristics that can be intuitively mapped to listener\nperceptions. Our findings offer potential applications in personalized music\nrecommendation systems by highlighting cross-genre similarities and\ndistinctiveness, aligning closely with human musical intuition. This work\nbridges the gap between technical classification tasks and the nuanced, human\nexperience of genre.",
    "explanation":"In this work, we present an innovative model for classifying music genres using attention based temporal signature modeling. By processing spectrogram sequences through Convolutional Neural Networks (CNNs) and multi-head attention layers, our approach captures the most temporally significant moments within each piece, crafting a unique \u201dsignature\u201d for genre identification",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "A deep representation for invariance and music classification"
    ],
    "b_abstract":[
      "Representations in the auditory cortex might be based on mechanisms similar to visual ventral stream; modules for building invariance transformations and multiple layers compositionality selectivity. In this paper we propose use of such computational extracting invariant discriminative audio representations. Building a theory hierarchical architectures, novel, mid-level representation acoustical signals, using empirical distributions projections set templates their transformations. Under assumption that, by construction, dictionary is composed from classes, samples orbit variance-inducing signal (such as shift scale), resulting signature theoretically guaranteed unique, stable deformations. Modules projection pooling can then constitute deep networks, learning composite We present main theoretical aspects framework unsupervised representations, empirically evaluated music genre classification."
    ],
    "b_categories":[
      "physics.class-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2501.11411"
    ],
    "c_title":[
      "Beyond the Hype: Benchmarking LLM-Evolved Heuristics for Bin Packing"
    ],
    "c_abstract":[
      "Coupling Large Language Models (LLMs) with Evolutionary Algorithms has\nrecently shown significant promise as a technique to design new heuristics that\noutperform existing methods, particularly in the field of combinatorial\noptimisation. An escalating arms race is both rapidly producing new heuristics\nand improving the efficiency of the processes evolving them. However, driven by\nthe desire to quickly demonstrate the superiority of new approaches, evaluation\nof the new heuristics produced for a specific domain is often cursory: testing\non very few datasets in which instances all belong to a specific class from the\ndomain, and on few instances per class. Taking bin-packing as an example, to\nthe best of our knowledge we conduct the first rigorous benchmarking study of\nnew LLM-generated heuristics, comparing them to well-known existing heuristics\nacross a large suite of benchmark instances using three performance metrics.\nFor each heuristic, we then evolve new instances won by the heuristic and\nperform an instance space analysis to understand where in the feature space\neach heuristic performs well. We show that most of the LLM heuristics do not\ngeneralise well when evaluated across a broad range of benchmarks in contrast\nto existing simple heuristics, and suggest that any gains from generating very\nspecialist heuristics that only work in small areas of the instance space need\nto be weighed carefully against the considerable cost of generating these\nheuristics."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.14975",
    "a_title":"Exploring Foundation Models Fine-Tuning for Cytology Classification",
    "a_abstract":"Cytology slides are essential tools in diagnosing and staging cancer, but\ntheir analysis is time-consuming and costly. Foundation models have shown great\npotential to assist in these tasks. In this paper, we explore how existing\nfoundation models can be applied to cytological classification. More\nparticularly, we focus on low-rank adaptation, a parameter-efficient\nfine-tuning method suited to few-shot learning. We evaluated five foundation\nmodels across four cytological classification datasets. Our results demonstrate\nthat fine-tuning the pre-trained backbones with LoRA significantly improves\nmodel performance compared to fine-tuning only the classifier head, achieving\nstate-of-the-art results on both simple and complex classification tasks while\nrequiring fewer data samples.",
    "explanation":"In this paper, we explore how existing foundation models can be applied to cytological classification",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "HiCervix: An Extensive Hierarchical Dataset and Benchmark for Cervical Cytology Classification"
    ],
    "b_abstract":[
      "Cervical cytology is a critical screening strategy for early detection of pre-cancerous and cancerous cervical lesions. The challenge lies in accurately classifying various cell types. Existing automated methods are primarily trained on databases covering narrow range coarse-grained types, which fail to provide comprehensive detailed performance analysis that represents real-world cytopathology conditions. To overcome these limitations, we introduce HiCervix, the most extensive, multi-center dataset currently available public. HiCervix includes 40,229 cells from 4,496 whole slide images, categorized into 29 annotated classes. These classes organized within three-level hierarchical tree capture fine-grained subtype information. exploit semantic correlation inherent this tree, propose HierSwin, vision transformer-based classification network. HierSwin serves as benchmark feature learning both coarse-level fine-level cancer tasks. In our experiments, demonstrated remarkable performance, achieving 92.08% accuracy 82.93% averaged across all three levels. When compared board-certified cytopathologists, achieved high (0.8293 versus 0.7359 accuracy), highlighting its potential clinical applications. This newly released dataset, along with method, poised make substantial impact advancement deep algorithms rapid greatly improve prevention patient outcomes settings."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.08175"
    ],
    "c_title":[
      "Privacy-Enhancing Paradigms within Federated Multi-Agent Systems"
    ],
    "c_abstract":[
      "LLM-based Multi-Agent Systems (MAS) have proven highly effective in solving\ncomplex problems by integrating multiple agents, each performing different\nroles. However, in sensitive domains, they face emerging privacy protection\nchallenges. In this paper, we introduce the concept of Federated MAS,\nhighlighting the fundamental differences between Federated MAS and traditional\nFL. We then identify key challenges in developing Federated MAS, including: 1)\nheterogeneous privacy protocols among agents, 2) structural differences in\nmulti-party conversations, and 3) dynamic conversational network structures. To\naddress these challenges, we propose Embedded Privacy-Enhancing Agents\n(EPEAgent), an innovative solution that integrates seamlessly into the\nRetrieval-Augmented Generation (RAG) phase and the context retrieval stage.\nThis solution minimizes data flows, ensuring that only task-relevant,\nagent-specific information is shared. Additionally, we design and generate a\ncomprehensive dataset to evaluate the proposed paradigm. Extensive experiments\ndemonstrate that EPEAgent effectively enhances privacy protection while\nmaintaining strong system performance. The code will be availiable at\nhttps:\/\/github.com\/ZitongShi\/EPEAgent"
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.14975",
    "a_title":"Exploring Foundation Models Fine-Tuning for Cytology Classification",
    "a_abstract":"Cytology slides are essential tools in diagnosing and staging cancer, but\ntheir analysis is time-consuming and costly. Foundation models have shown great\npotential to assist in these tasks. In this paper, we explore how existing\nfoundation models can be applied to cytological classification. More\nparticularly, we focus on low-rank adaptation, a parameter-efficient\nfine-tuning method suited to few-shot learning. We evaluated five foundation\nmodels across four cytological classification datasets. Our results demonstrate\nthat fine-tuning the pre-trained backbones with LoRA significantly improves\nmodel performance compared to fine-tuning only the classifier head, achieving\nstate-of-the-art results on both simple and complex classification tasks while\nrequiring fewer data samples.",
    "explanation":"In this paper, we explore how existing foundation models can be applied to cytological classification",
    "b_id":[
      "b17"
    ],
    "b_title":[
      "LoRA: Low-Rank Adaptation of Large Language Models"
    ],
    "b_abstract":[
      "An important paradigm of natural language processing consists large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances fine-tuned each with is prohibitively expensive. We propose Low-Rank Adaptation, LoRA, freezes the pre-trained weights injects trainable rank decomposition matrices into layer Transformer architecture, greatly reducing number parameters for downstream tasks. Compared Adam, LoRA can reduce by 10,000 times GPU memory requirement 3 times. performs on-par better than fine-tuning in quality RoBERTa, DeBERTa, GPT-2, GPT-3, despite having fewer a higher training throughput, and, unlike adapters, no additional inference latency. also provide empirical investigation rank-deficiency adaptation, sheds light efficacy LoRA. release package that facilitates integration PyTorch models our implementations checkpoints GPT-2 at https:\/\/github.com\/microsoft\/LoRA."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.18947"
    ],
    "c_title":[
      "Trait-structured chemotaxis: Exploring ligand-receptor dynamics and\n  travelling wave properties in a Keller-Segel model"
    ],
    "c_abstract":[
      "A novel trait-structured Keller-Segel model that explores the dynamics of a\nmigrating cell population guided by chemotaxis in response to an external\nligand concentration is derived and analysed. Unlike traditional Keller-Segel\nmodels, this framework introduces an explicit representation of ligand-receptor\nbindings on the cell membrane, where the percentage of occupied receptors\nconstitutes the trait that influences cellular phenotype. The model posits that\nthe cell's phenotypic state directly modulates its capacity for chemotaxis and\nproliferation, governed by a trade-off due to a finite energy budget: cells\nhighly proficient in chemotaxis exhibit lower proliferation rates, while more\nproliferative cells show diminished chemotactic abilities. The model is derived\nfrom the principles of a biased random walk, resulting in a system of two\nnon-local partial differential equations, describing the densities of both\ncells and ligands. Using a Hopf-Cole transformation, we derive an equation that\ncharacterises the distribution of cellular traits within travelling wave\nsolutions for the total cell density, allowing us to uncover the monotonicity\nproperties of these waves. Numerical investigations are conducted to examine\nthe model's behaviour across various biological scenarios, providing insights\ninto the complex interplay between chemotaxis, proliferation, and phenotypic\ndiversity in migrating cell populations."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.15331",
    "a_title":"GeoScatt-GNN: A Geometric Scattering Transform-Based Graph Neural\n  Network Model for Ames Mutagenicity Prediction",
    "a_abstract":"This paper tackles the pressing challenge of mutagenicity prediction by\nintroducing three ground-breaking approaches. First, it showcases the superior\nperformance of 2D scattering coefficients extracted from molecular images,\ncompared to traditional molecular descriptors. Second, it presents a hybrid\napproach that combines geometric graph scattering (GGS), Graph Isomorphism\nNetworks (GIN), and machine learning models, achieving strong results in\nmutagenicity prediction. Third, it introduces a novel graph neural network\narchitecture, MOLG3-SAGE, which integrates GGS node features into a fully\nconnected graph structure, delivering outstanding predictive accuracy.\nExperimental results on the ZINC dataset demonstrate significant improvements,\nemphasizing the effectiveness of blending 2D and geometric scattering\ntechniques with graph neural networks. This study illustrates the potential of\nGNNs and GGS for mutagenicity prediction, with broad implications for drug\ndiscovery and chemical safety assessment.",
    "explanation":"This study illustrates the potential of GNNs and GGS for mutagenicity prediction, with broad implications for drug discovery and chemical safety assessment",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Improvement of quantitative structure\u2013activity relationship (QSAR) tools for predicting Ames mutagenicity: outcomes of the Ames\/QSAR International Challenge Project"
    ],
    "b_abstract":[
      "The International Conference on Harmonization (ICH) M7 guideline allows the use of in silico approaches for predicting Ames mutagenicity initial assessment impurities pharmaceuticals. This is first international that addresses quantitative structure\u2013activity relationship (QSAR) models lieu actual toxicological studies human health assessment. Therefore, QSAR now require higher predictive power identifying mutagenic chemicals. To increase models, larger experimental datasets from reliable sources are required. Division Genetics and Mutagenesis, National Institute Health Sciences (DGM\/NIHS) Japan recently established a unique proprietary database containing 12140 new chemicals have not been previously used developing models. DGM\/NIHS provided this to vendors validate improve their tools. Ames\/QSAR Challenge Project was initiated 2014 with 12 testing 17 tools against these compounds three phases. We present final results. All were considerably improved by participation project. Most achieved >50% sensitivity (positive prediction among all positives) (accuracy) as high 80%, almost equivalent inter-laboratory reproducibility tests. further tools, accumulation additional test data required well re-evaluation some previous Indeed, Ames-positive or Ames-negative may incorrectly classified because methodological weakness, resulting false-positive false-negative predictions These incorrect hamper source noise development It thus essential establish large benchmark consisting only well-validated results build more accurate"
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.21108"
    ],
    "c_title":[
      "Large Language Model-Based Benchmarking Experiment Settings for\n  Evolutionary Multi-Objective Optimization"
    ],
    "c_abstract":[
      "When we manually design an evolutionary optimization algorithm, we implicitly\nor explicitly assume a set of target optimization problems. In the case of\nautomated algorithm design, target optimization problems are usually explicitly\nshown. Recently, the use of large language models (LLMs) for the design of\nevolutionary multi-objective optimization (EMO) algorithms have been examined\nin some studies. In those studies, target multi-objective problems are not\nalways explicitly shown. It is well known in the EMO community that the\nperformance evaluation results of EMO algorithms depend on not only test\nproblems but also many other factors such as performance indicators, reference\npoint, termination condition, and population size. Thus, it is likely that the\ndesigned EMO algorithms by LLMs depends on those factors. In this paper, we try\nto examine the implicit assumption about the performance comparison of EMO\nalgorithms in LLMs. For this purpose, we ask LLMs to design a benchmarking\nexperiment of EMO algorithms. Our experiments show that LLMs often suggest\nclassical benchmark settings: Performance examination of NSGA-II, MOEA\/D and\nNSGA-III on ZDT, DTLZ and WFG by HV and IGD under the standard parameter\nspecifications."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.15331",
    "a_title":"GeoScatt-GNN: A Geometric Scattering Transform-Based Graph Neural\n  Network Model for Ames Mutagenicity Prediction",
    "a_abstract":"This paper tackles the pressing challenge of mutagenicity prediction by\nintroducing three ground-breaking approaches. First, it showcases the superior\nperformance of 2D scattering coefficients extracted from molecular images,\ncompared to traditional molecular descriptors. Second, it presents a hybrid\napproach that combines geometric graph scattering (GGS), Graph Isomorphism\nNetworks (GIN), and machine learning models, achieving strong results in\nmutagenicity prediction. Third, it introduces a novel graph neural network\narchitecture, MOLG3-SAGE, which integrates GGS node features into a fully\nconnected graph structure, delivering outstanding predictive accuracy.\nExperimental results on the ZINC dataset demonstrate significant improvements,\nemphasizing the effectiveness of blending 2D and geometric scattering\ntechniques with graph neural networks. This study illustrates the potential of\nGNNs and GGS for mutagenicity prediction, with broad implications for drug\ndiscovery and chemical safety assessment.",
    "explanation":"This study illustrates the potential of GNNs and GGS for mutagenicity prediction, with broad implications for drug discovery and chemical safety assessment",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Mutagenpred-gcnns: a graph convolutional neural network-based classification model for mutagenicity prediction with data-driven molecular fingerprints"
    ],
    "b_abstract":[
      "An important task in the early stage of drug discovery is the identification of mutagenic compounds. Mutagenicity prediction models that can interpret relationships between toxicological endpoints and compound structures are especially favorable. In this research, we used an advanced graph convolutional neural network (GCNN) architecture to identify the molecular representation and develop predictive models based on these representations. The predictive model based on features extracted by GCNNs can not only predict the mutagenicity of compounds but also identify the structure alerts in compounds. In fivefold cross-validation and external validation, the highest area under the curve was 0.8782 and 0.8382, respectively; the highest accuracy (Q) was 80.98% and 76.63%, respectively; the highest sensitivity was 83.27% and 78.92%, respectively; and the highest specificity was 78.83% and 76.32%, respectively. Additionally, our model also identified some toxicophores, such as aromatic nitro, three-membered heterocycles, quinones, and nitrogen and sulfur mustard. These results indicate that GCNNs could learn the features of mutagens effectively. In summary, we developed a mutagenicity classification model with high predictive performance and interpretability based on a data-driven molecular representation trained through GCNNs."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.02284"
    ],
    "c_title":[
      "Origin of $\\alpha$-satellite repeat arrays from mitochondrial molecular\n  fossils -- sequential insertion, expansion, and evolution in the nuclear\n  genome"
    ],
    "c_abstract":[
      "Alpha satellite DNA is large tandem arrays of 150-400 bp units, and its\norigin remains an evolutionary mystery. In this research, we identified 1,545\nalpha-satellite-like (SatL) repeat units in the nuclear genome of jewel wasp\nNasonia vitripennis. Among them, thirty-nine copies of SatL were organized in\ntwo palindromic arrays in mitochondria, resulting in a 50% increase in the\ngenome size. Strikingly, genomic neighborhood analyses of 1,516 nuclear SatL\nrepeats revealed that they are located in NuMT (nuclear mitochondrial DNA)\nregions, and SatL phylogeny matched perfectly with mitochondrial genes and NuMT\npseudogenes. These results support that SatL arrays originated from ten\nindependent mitochondria insertion events into the nuclear genome within the\nlast 500,000 years, after divergence from its sister species N. giraulti.\nDramatic repeat GC-percent elevation (from 33.9% to 50.4%) is a hallmark of\nrapid SatL sequence evolution in mitochondria due to GC-biased gene conversion\nfacilitated by the palindromic sequence pairing of the two mitochondrial SatL\narrays. The nuclear SatL repeat arrays underwent substantial copy number\nexpansion, from 12-15 (SatL1) to over 400 copies (SatL4). The oldest SatL4B\narray consists of four types of repeat units derived from deletions in the\nAT-rich region of ancestral repeats, and complex high-order structures have\nevolved through duplications. We also discovered similar repeat insertions into\nthe nuclear genome of Muscidifurax, suggesting this mechanism can be common in\ninsects. This is the first report of the mitochondrial origin of nuclear\nsatellite sequences, and our findings shed new light on the origin and\nevolution of satellite DNA."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03341",
    "a_title":"Interpretable Embeddings for Segmentation-Free Single-Cell Analysis in\n  Multiplex Imaging",
    "a_abstract":"Multiplex Imaging (MI) enables the simultaneous visualization of multiple\nbiological markers in separate imaging channels at subcellular resolution,\nproviding valuable insights into cell-type heterogeneity and spatial\norganization. However, current computational pipelines rely on cell\nsegmentation algorithms, which require laborious fine-tuning and can introduce\ndownstream errors due to inaccurate single-cell representations. We propose a\nsegmentation-free deep learning approach that leverages grouped convolutions to\nlearn interpretable embedded features from each imaging channel, enabling\nrobust cell-type identification without manual feature selection. Validated on\nan Imaging Mass Cytometry dataset of 1.8 million cells from neuroblastoma\npatients, our method enables the accurate identification of known cell types,\nshowcasing its scalability and suitability for high-dimensional MI data.",
    "explanation":"Validated on an Imaging Mass Cytometry dataset of 1.8 million cells from neuroblastoma patients.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Highly multiplexed imaging of tumor tissues with subcellular resolution by mass cytometry"
    ],
    "b_abstract":[
      "Mass cytometry enables high-dimensional, single-cell analysis of cell type and state. In mass cytometry, rare earth metals are used as reporters on antibodies. Analysis of metal abundances using the mass cytometer allows determination of marker expression in individual cells. Mass cytometry has previously been applied only to cell suspensions. To gain spatial information, we have coupled immunohistochemical and immunocytochemical methods with high-resolution laser ablation to CyTOF mass cytometry. This approach enables the simultaneous imaging of 32 proteins and protein modifications at subcellular resolution; with the availability of additional isotopes, measurement of over 100 markers will be possible. We applied imaging mass cytometry to human breast cancer samples, allowing delineation of cell subpopulations and cell-cell interactions and highlighting tumor heterogeneity. Imaging mass cytometry complements existing imaging approaches. It will enable basic studies of tissue heterogeneity and function and support the transition of medicine toward individualized molecularly targeted diagnosis and therapies."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.17651"
    ],
    "c_title":[
      "Collaborative Temporal Consistency Learning for Point-supervised Natural\n  Language Video Localization"
    ],
    "c_abstract":[
      "Natural language video localization (NLVL) is a crucial task in video\nunderstanding that aims to localize the target moment in videos specified by a\ngiven language description. Recently, a point-supervised paradigm has been\npresented to address this task, requiring only a single annotated frame within\nthe target moment rather than complete temporal boundaries. Compared with the\nfully-supervised paradigm, it offers a balance between localization accuracy\nand annotation cost. However, due to the absence of complete annotation, it is\nchallenging to align the video content with language descriptions, consequently\nhindering accurate moment prediction. To address this problem, we propose a new\nCOllaborative Temporal consistEncy Learning (COTEL) framework that leverages\nthe synergy between saliency detection and moment localization to strengthen\nthe video-language alignment. Specifically, we first design a frame- and a\nsegment-level Temporal Consistency Learning (TCL) module that models semantic\nalignment across frame saliencies and sentence-moment pairs. Then, we design a\ncross-consistency guidance scheme, including a Frame-level Consistency Guidance\n(FCG) and a Segment-level Consistency Guidance (SCG), that enables the two\ntemporal consistency learning paths to reinforce each other mutually. Further,\nwe introduce a Hierarchical Contrastive Alignment Loss (HCAL) to\ncomprehensively align the video and text query. Extensive experiments on two\nbenchmarks demonstrate that our method performs favorably against SoTA\napproaches. We will release all the source codes."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03341",
    "a_title":"Interpretable Embeddings for Segmentation-Free Single-Cell Analysis in\n  Multiplex Imaging",
    "a_abstract":"Multiplex Imaging (MI) enables the simultaneous visualization of multiple\nbiological markers in separate imaging channels at subcellular resolution,\nproviding valuable insights into cell-type heterogeneity and spatial\norganization. However, current computational pipelines rely on cell\nsegmentation algorithms, which require laborious fine-tuning and can introduce\ndownstream errors due to inaccurate single-cell representations. We propose a\nsegmentation-free deep learning approach that leverages grouped convolutions to\nlearn interpretable embedded features from each imaging channel, enabling\nrobust cell-type identification without manual feature selection. Validated on\nan Imaging Mass Cytometry dataset of 1.8 million cells from neuroblastoma\npatients, our method enables the accurate identification of known cell types,\nshowcasing its scalability and suitability for high-dimensional MI data.",
    "explanation":"Validated on an Imaging Mass Cytometry dataset of 1.8 million cells from neuroblastoma patients.",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "A ConvNet for the 2020s"
    ],
    "b_abstract":[
      "The \"Roaring 20s\" of visual recognition began with the introduction Vision Transformers (ViTs), which quickly superseded ConvNets as state-of-the-art image classification model. A vanilla ViT, on other hand, faces difficulties when applied to general computer vision tasks such object detection and semantic segmentation. It is hierarchical (e.g., Swin Transformers) that reintroduced several ConvNet priors, making practically viable a generic backbone demonstrating remarkable performance wide variety tasks. However, effectiveness hybrid approaches still largely credited intrinsic superiority Transformers, rather than inherent inductive biases convolutions. In this work, we reexamine design spaces test limits what pure can achieve. We gradually \"modernize\" standard ResNet toward Transformer, discover key components contribute difference along way. outcome exploration family models dubbed ConvNeXt. Constructed entirely from modules, ConvNeXts compete favorably in terms accuracy scalability, achieving 87.8% ImageNet top-1 outperforming COCO ADE20K segmentation, while maintaining simplicity efficiency ConvNets."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.06672"
    ],
    "c_title":[
      "Efficient Spatial Estimation of Perceptual Thresholds for Retinal\n  Implants via Gaussian Process Regression"
    ],
    "c_abstract":[
      "Retinal prostheses restore vision by electrically stimulating surviving\nneurons, but calibrating perceptual thresholds - the minimum stimulus intensity\nrequired for perception - remains a time-intensive challenge, especially for\nhigh-electrode-count devices. Since neighboring electrodes exhibit spatial\ncorrelations, we propose a Gaussian Process Regression (GPR) framework to\npredict thresholds at unsampled locations while leveraging uncertainty\nestimates to guide adaptive sampling. Using perceptual threshold data from four\nArgus II users, we show that GPR with a Mat\\'ern kernel provides more accurate\nthreshold predictions than a Radial Basis Function (RBF) kernel (p < .001,\nWilcoxon signed-rank test). In addition, spatially optimized sampling yielded\nlower prediction error than uniform random sampling for Participants 1 and 3 (p\n< .05). While adaptive sampling dynamically selects electrodes based on model\nuncertainty, its accuracy gains over spatial sampling were not statistically\nsignificant (p > .05), though it approached significance for Participant 1 (p =\n.074). These findings establish GPR with spatial sampling as a scalable,\nefficient approach to retinal prosthesis calibration, minimizing patient burden\nwhile maintaining predictive accuracy. More broadly, this framework offers a\ngeneralizable solution for adaptive calibration in neuroprosthetic devices with\nspatially structured stimulation thresholds."
    ],
    "c_categories":[
      "q-bio.QM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05443",
    "a_title":"ClusterGraph: a new tool for visualization and compression of\n  multidimensional data",
    "a_abstract":"Understanding the global organization of complicated and high dimensional\ndata is of primary interest for many branches of applied sciences. It is\ntypically achieved by applying dimensionality reduction techniques mapping the\nconsidered data into lower dimensional space. This family of methods, while\npreserving local structures and features, often misses the global structure of\nthe dataset. Clustering techniques are another class of methods operating on\nthe data in the ambient space. They group together points that are similar\naccording to a fixed similarity criteria, however unlike dimensionality\nreduction techniques, they do not provide information about the global\norganization of the data. Leveraging ideas from Topological Data Analysis, in\nthis paper we provide an additional layer on the output of any clustering\nalgorithm. Such data structure, ClusterGraph, provides information about the\nglobal layout of clusters, obtained from the considered clustering algorithm.\nAppropriate measures are provided to assess the quality and usefulness of the\nobtained representation. Subsequently the ClusterGraph, possibly with an\nappropriate structure--preserving simplification, can be visualized and used in\nsynergy with state of the art exploratory data analysis techniques.",
    "explanation":"Understanding the global organization of complicated and high dimensional data is of primary interest for many branches of applied sciences. It is typically\nachieved by applying dimensionality reduction techniques mapping the considered data into lower dimensional space.\nThe paper proposes ClusterGraph, obtained through clustering algorithm, to be use in synergy with state of the art exploratory data analysis techniques.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Topological Methods for the Analysis of High Dimensional Data Sets and 3D Object Recognition. The Eurographics Association"
    ],
    "b_abstract":[
      "We present a computational method for extracting simple descriptions of high dimensional data sets in the form of simplicial complexes. Our method, called Mapper, is based on the idea of partial clustering of the data guided by a set of functions defined on the data. The proposed method is not dependent on any particular clustering algorithm, i.e. any clustering algorithm may be used with Mapper. We implement this method and present a few sample applications in which simple descriptions of the data present important information about its structure."
    ],
    "b_categories":[
      "cs.DC"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.14038"
    ],
    "c_title":[
      "On the Three Balls Inequality for Discrete Schr{\\\"o}dinger Operators on\n  Certain Periodic Graphs"
    ],
    "c_abstract":[
      "We investigate quantitative unique continuation properties for discrete\nmagnetic Schr{\\\"o}dinger operators in certain periodic graphs. This unique\ncontinuation property will be quantified through what is known in the\nliterature as a Three Balls Inequality. We are able to extend this inequality\nto another family of periodic graph which contains the Hexagonal lattice. We\nalso give a sketch of the proof for general star periodic graph.Our proofs are\nbased on Carleman estimates."
    ],
    "c_categories":[
      "math.CA",
      "math.CV",
      "math.FA"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05443",
    "a_title":"ClusterGraph: a new tool for visualization and compression of\n  multidimensional data",
    "a_abstract":"Understanding the global organization of complicated and high dimensional\ndata is of primary interest for many branches of applied sciences. It is\ntypically achieved by applying dimensionality reduction techniques mapping the\nconsidered data into lower dimensional space. This family of methods, while\npreserving local structures and features, often misses the global structure of\nthe dataset. Clustering techniques are another class of methods operating on\nthe data in the ambient space. They group together points that are similar\naccording to a fixed similarity criteria, however unlike dimensionality\nreduction techniques, they do not provide information about the global\norganization of the data. Leveraging ideas from Topological Data Analysis, in\nthis paper we provide an additional layer on the output of any clustering\nalgorithm. Such data structure, ClusterGraph, provides information about the\nglobal layout of clusters, obtained from the considered clustering algorithm.\nAppropriate measures are provided to assess the quality and usefulness of the\nobtained representation. Subsequently the ClusterGraph, possibly with an\nappropriate structure--preserving simplification, can be visualized and used in\nsynergy with state of the art exploratory data analysis techniques.",
    "explanation":"Understanding the global organization of complicated and high dimensional data is of primary interest for many branches of applied sciences. It is typically\nachieved by applying dimensionality reduction techniques mapping the considered data into lower dimensional space.\nThe paper proposes ClusterGraph, obtained through clustering algorithm, to be use in synergy with state of the art exploratory data analysis techniques.",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "A Global Geometric Framework for Nonlinear Dimensionality Reduction"
    ],
    "b_abstract":[
      "Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem dimensionality reduction: finding meaningful low-dimensional structures hidden in their observations. The brain confronts same everyday perception, extracting from its sensory inputs\u201430,000 auditory nerve fibers 106 optic fibers\u2014a manageably small number perceptually relevant features. Here we describe an approach to solving reduction problems that uses easily measured local metric information learn underlying geometry a data set. Unlike classical techniques principal component analysis (PCA) and multidimensional scaling (MDS), our is capable discovering nonlinear degrees freedom underlie complex natural observations, handwriting images face under different viewing conditions. In contrast previous algorithms for reduction, ours efficiently computes globally optimal solution, and, important class manifolds, guaranteed converge asymptotically true structure."
    ],
    "b_categories":[
      "math.ST"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2502.10820"
    ],
    "c_title":[
      "Performance analysis of mdx II: A next-generation cloud platform for\n  cross-disciplinary data science research"
    ],
    "c_abstract":[
      "mdx II is an Infrastructure-as-a-Service (IaaS) cloud platform designed to\naccelerate data science research and foster cross-disciplinary collaborations\namong universities and research institutions in Japan. Unlike traditional\nhigh-performance computing systems, mdx II leverages OpenStack to provide\ncustomizable and isolated computing environments consisting of virtual\nmachines, virtual networks, and advanced storage. This paper presents a\ncomprehensive performance evaluation of mdx II, including a comparison to\nAmazon Web Services (AWS). We evaluated the performance of a 16-vCPU VM from\nmultiple aspects including floating-point computing performance, memory\nthroughput, network throughput, file system and object storage performance, and\nreal-world application performance. Compared to an AWS 16-vCPU instance, the\nresults indicated that mdx II outperforms AWS in many aspects and demonstrated\nthat mdx II holds significant promise for high-performance data analytics\n(HPDA) workloads. We also evaluated the virtualization overhead using a\n224-vCPU VM occupying an entire host. The results suggested that the\nvirtualization overhead is minimal for compute-intensive benchmarks, while\nmemory-intensive benchmarks experienced larger overheads. These findings are\nexpected to help users of mdx II to obtain high performance for their data\nscience workloads and offer insights to the designers of future data-centric\ncloud platforms."
    ],
    "c_categories":[
      "cs.DC"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04992",
    "a_title":"Which bits went where? Past and future transfer entropy decomposition\n  with the information bottleneck",
    "a_abstract":"Whether the system under study is a shoal of fish, a collection of neurons,\nor a set of interacting atmospheric and oceanic processes, transfer entropy\nmeasures the flow of information between time series and can detect possible\ncausal relationships. Much like mutual information, transfer entropy is\ngenerally reported as a single value summarizing an amount of shared variation,\nyet a more fine-grained accounting might illuminate much about the processes\nunder study. Here we propose to decompose transfer entropy and localize the\nbits of variation on both sides of information flow: that of the originating\nprocess's past and that of the receiving process's future. We employ the\ninformation bottleneck (IB) to compress the time series and identify the\ntransferred entropy. We apply our method to decompose the transfer entropy in\nseveral synthetic recurrent processes and an experimental mouse dataset of\nconcurrent behavioral and neural activity. Our approach highlights the nuanced\ndynamics within information flow, laying a foundation for future explorations\ninto the intricate interplay of temporal processes in complex systems.",
    "explanation":"Much like mutual information, transfer entropy is generally reported as a single\nvalue summarizing an amount of shared variation, yet a more fine-grained accounting might illuminate much about the processes under study. The paper propose to decompose transfer entropy and localize the bits of variation on both sides of information flow.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Transfer Entropy Bottleneck: Learning Sequence to Sequence Information Transfer"
    ],
    "b_abstract":[
      "When presented with a data stream of two statistically dependent variables, predicting the future one variables (the target stream) can benefit from information about both its history and other variable source stream). For example, fluctuations in temperature at weather station be predicted using temperatures barometric readings. However, challenge when modelling such is that it easy for neural network to rely on greatest joint correlations within stream, which may ignore crucial but small transfer stream. As well, there are often situations where have previously been modelled independently would useful use model inform new model. Here, we develop an bottleneck approach conditional learning streams data. Our method, call Transfer Entropy Bottleneck (TEB), allows learn bottlenecks directed transferred variable, while quantifying this such, TEB provides order make predictions them."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.01476"
    ],
    "c_title":[
      "Sparse identification of evolution equations via Bayesian model\n  selection"
    ],
    "c_abstract":[
      "The quantitative formulation of evolution equations is the backbone for\nprediction, control, and understanding of dynamical systems across diverse\nscientific fields. Besides deriving differential equations for dynamical\nsystems based on basic scientific reasoning or prior knowledge in recent times\na growing interest emerged to infer these equations purely from data. In this\narticle, we introduce a novel method for the sparse identification of nonlinear\ndynamical systems from observational data, based on the observation how the key\nchallenges of the quality of time derivatives and sampling rates influence this\nproblem. Our approach combines system identification based on thresholded least\nsquares minimization with additional error measures that account for both the\ndeviation between the model and the time derivative of the data, and the\nintegrated performance of the model in forecasting dynamics. Specifically, we\nintegrate a least squares error as well as the Wasserstein metric for estimated\nmodels and combine them within a Bayesian optimization framework to efficiently\ndetermine optimal hyperparameters for thresholding and weighting of the\ndifferent error norms. Additionally, we employ distinct regularization\nparameters for each differential equation in the system, enhancing the method's\nprecision and flexibility. We demonstrate the capabilities of our approach\nthrough applications to dynamical fMRI data and the prototypical example of a\nwake flow behind a cylinder. In the wake flow problem, our method identifies a\nsparse, accurate model that correctly captures transient dynamics, oscillation\nperiods, and phase information, outperforming existing methods. In the fMRI\nexample, we show how our approach extracts insights from a trained recurrent\nneural network, offering a novel avenue for explainable AI by inferring\ndifferential equations that capture potentially causal relationships."
    ],
    "c_categories":[
      "physics.data-an"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04992",
    "a_title":"Which bits went where? Past and future transfer entropy decomposition\n  with the information bottleneck",
    "a_abstract":"Whether the system under study is a shoal of fish, a collection of neurons,\nor a set of interacting atmospheric and oceanic processes, transfer entropy\nmeasures the flow of information between time series and can detect possible\ncausal relationships. Much like mutual information, transfer entropy is\ngenerally reported as a single value summarizing an amount of shared variation,\nyet a more fine-grained accounting might illuminate much about the processes\nunder study. Here we propose to decompose transfer entropy and localize the\nbits of variation on both sides of information flow: that of the originating\nprocess's past and that of the receiving process's future. We employ the\ninformation bottleneck (IB) to compress the time series and identify the\ntransferred entropy. We apply our method to decompose the transfer entropy in\nseveral synthetic recurrent processes and an experimental mouse dataset of\nconcurrent behavioral and neural activity. Our approach highlights the nuanced\ndynamics within information flow, laying a foundation for future explorations\ninto the intricate interplay of temporal processes in complex systems.",
    "explanation":"Much like mutual information, transfer entropy is generally reported as a single\nvalue summarizing an amount of shared variation, yet a more fine-grained accounting might illuminate much about the processes under study. The paper propose to decompose transfer entropy and localize the bits of variation on both sides of information flow.",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "Symbolic Transfer Entropy"
    ],
    "b_abstract":[
      "We propose to estimate transfer entropy using a technique of symbolization. demonstrate numerically that symbolic is robust and computationally fast method quantify the dominating direction information flow between time series from structurally identical nonidentical coupled systems. Analyzing multiday, multichannel electroencephalographic recordings 15 epilepsy patients our approach allowed us reliably identify hemisphere containing epileptic focus without observing actual seizure activity."
    ],
    "b_categories":[
      "physics.data-an"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2501.04538"
    ],
    "c_title":[
      "HypeRL: Parameter-Informed Reinforcement Learning for Parametric PDEs"
    ],
    "c_abstract":[
      "In this work, we devise a new, general-purpose reinforcement learning\nstrategy for the optimal control of parametric partial differential equations\n(PDEs). Such problems frequently arise in applied sciences and engineering and\nentail a significant complexity when control and\/or state variables are\ndistributed in high-dimensional space or depend on varying parameters.\nTraditional numerical methods, relying on either iterative minimization\nalgorithms or dynamic programming, while reliable, often become computationally\ninfeasible. Indeed, in either way, the optimal control problem must be solved\nfor each instance of the parameters, and this is out of reach when dealing with\nhigh-dimensional time-dependent and parametric PDEs. In this paper, we propose\nHypeRL, a deep reinforcement learning (DRL) framework to overcome the\nlimitations shown by traditional methods. HypeRL aims at approximating the\noptimal control policy directly. Specifically, we employ an actor-critic DRL\napproach to learn an optimal feedback control strategy that can generalize\nacross the range of variation of the parameters. To effectively learn such\noptimal control laws, encoding the parameter information into the DRL policy\nand value function neural networks (NNs) is essential. To do so, HypeRL uses\ntwo additional NNs, often called hypernetworks, to learn the weights and biases\nof the value function and the policy NNs. We validate the proposed approach on\ntwo PDE-constrained optimal control benchmarks, namely a 1D\nKuramoto-Sivashinsky equation and a 2D Navier-Stokes equations, by showing that\nthe knowledge of the PDE parameters and how this information is encoded, i.e.,\nvia a hypernetwork, is an essential ingredient for learning parameter-dependent\ncontrol policies that can generalize effectively to unseen scenarios and for\nimproving the sample efficiency of such policies."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06447",
    "a_title":"Multi-Parameter Molecular MRI Quantification using Physics-Informed\n  Self-Supervised Learning",
    "a_abstract":"Biophysical model fitting plays a key role in obtaining quantitative\nparameters from physiological signals and images. However, the model complexity\nfor molecular magnetic resonance imaging (MRI) often translates into excessive\ncomputation time, which makes clinical use impractical. Here, we present a\ngeneric computational approach for solving the parameter extraction inverse\nproblem posed by ordinary differential equation (ODE) modeling coupled with\nexperimental measurement of the system dynamics. This is achieved by\nformulating a numerical ODE solver to function as a step-wise analytical one,\nthereby making it compatible with automatic differentiation-based optimization.\nThis enables efficient gradient-based model fitting, and provides a new\napproach to parameter quantification based on self-supervised learning from a\nsingle data observation. The neural-network-based train-by-fit pipeline was\nused to quantify semisolid magnetization transfer (MT) and chemical exchange\nsaturation transfer (CEST) amide proton exchange parameters in the human brain,\nin an in-vivo molecular MRI study (n=4). The entire pipeline of the first whole\nbrain quantification was completed in 18.3$\\pm$8.3 minutes, which is an\norder-of-magnitude faster than comparable alternatives. Reusing the\nsingle-subject-trained network for inference in new subjects took 1.0$\\pm$0.2\ns, to provide results in agreement with literature values and scan-specific fit\nresults (Pearson's r>0.98, p<0.0001).",
    "explanation":"The model complexity for molecular magnetic resonance imaging (MRI) often translates into excessive computation time, which makes clinical use impractical. Here, we present a generic computational approach for solving the parameter extraction inverse problem posed by ordinary differential equation (ODE) modeling coupled with experimental measurement of the system dynamics. This is achieved by formulating a numerical ODE solver to function as a step-wise analytical one, thereby making it compatible with automatic differentiation-based optimization. This enables efficient gradient-based model fitting, and provides a new approach to parameter quantification based on self-supervised learning from a single data observation.",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "A deep learning approach for magnetization transfer contrast MR fingerprinting and chemical exchange saturation transfer imaging"
    ],
    "b_abstract":[
      "Semisolid magnetization transfer contrast (MTC) and chemical exchange saturation (CEST) MRI based on MT phenomenon have shown potential to evaluate brain development, neurological, psychiatric, neurodegenerative diseases. However, a qualitative ratio (MTR) metric commonly used in conventional MTC imaging is limited the assessment of quantitative semisolid macromolecular proton rates concentrations. In addition, CEST signals measured by MTR asymmetry analysis are unavoidably contaminated upfield nuclear Overhauser enhancement (NOE) mobile macromolecules. To address these issues, we developed an MTC-MR fingerprinting (MTC-MRF) technique quantify tissue parameters, which further allows estimation accurate at certain frequency offset. A pseudorandomized RF scheme was generate unique signal evolutions for different tissues supervised deep neural network designed extract properties from MTC-MRF signals. Through detailed Bloch equation-based digital phantom vivo studies, demonstrated that can characteristics with high accuracy computational efficiency, compared equation fitting approach, provide baseline reference NOE imaging. For validation, images were synthesized using parameters estimated deep-learning method experimentally acquired as standard. The proposed framework 3D MTC, CEST, human within clinically acceptable scan time."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.18718"
    ],
    "c_title":[
      "Quantum Monte Carlo Calculations of neutron-$\\alpha$ Scattering via an\n  Integral Relation"
    ],
    "c_abstract":[
      "Nuclear physics seeks to describe both bound and unbound states within a\nunified predictive framework. While coordinate-space Quantum Monte Carlo (QMC)\nmethods have successfully computed bound states for systems with $A \\leq 12$,\ntheir application to unbound states remains limited. In this work, we extend\nthe QMC approach to enable a broader range of unbound-state calculations. Our\nmethod infers long-range amplitudes in the wave function from integrals over\nthe short-range interaction region. By evaluating these integrals using Green's\nFunction Monte Carlo wave functions with the Argonne $v_{18}$ potential, we\naccurately reproduce existing results for neutron-alpha scattering. This\napproach provides a systematic pathway for studying more complex nuclear\nsystems, including coupled-channel scattering and the effects of three-nucleon\nforces. It serves as a powerful tool for advancing $\\textit{ab initio}$\ncalculations in nuclear reactions, paving the way for a unified framework that\nconsistently describes both bound and scattering states within a single\ntheoretical approach."
    ],
    "c_categories":[
      "nucl-th"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06447",
    "a_title":"Multi-Parameter Molecular MRI Quantification using Physics-Informed\n  Self-Supervised Learning",
    "a_abstract":"Biophysical model fitting plays a key role in obtaining quantitative\nparameters from physiological signals and images. However, the model complexity\nfor molecular magnetic resonance imaging (MRI) often translates into excessive\ncomputation time, which makes clinical use impractical. Here, we present a\ngeneric computational approach for solving the parameter extraction inverse\nproblem posed by ordinary differential equation (ODE) modeling coupled with\nexperimental measurement of the system dynamics. This is achieved by\nformulating a numerical ODE solver to function as a step-wise analytical one,\nthereby making it compatible with automatic differentiation-based optimization.\nThis enables efficient gradient-based model fitting, and provides a new\napproach to parameter quantification based on self-supervised learning from a\nsingle data observation. The neural-network-based train-by-fit pipeline was\nused to quantify semisolid magnetization transfer (MT) and chemical exchange\nsaturation transfer (CEST) amide proton exchange parameters in the human brain,\nin an in-vivo molecular MRI study (n=4). The entire pipeline of the first whole\nbrain quantification was completed in 18.3$\\pm$8.3 minutes, which is an\norder-of-magnitude faster than comparable alternatives. Reusing the\nsingle-subject-trained network for inference in new subjects took 1.0$\\pm$0.2\ns, to provide results in agreement with literature values and scan-specific fit\nresults (Pearson's r>0.98, p<0.0001).",
    "explanation":"The model complexity for molecular magnetic resonance imaging (MRI) often translates into excessive computation time, which makes clinical use impractical. Here, we present a generic computational approach for solving the parameter extraction inverse problem posed by ordinary differential equation (ODE) modeling coupled with experimental measurement of the system dynamics. This is achieved by formulating a numerical ODE solver to function as a step-wise analytical one, thereby making it compatible with automatic differentiation-based optimization. This enables efficient gradient-based model fitting, and provides a new approach to parameter quantification based on self-supervised learning from a single data observation.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Magnetic resonance fingerprinting"
    ],
    "b_abstract":[
      "Magnetic Resonance Fingerprinting (MRF) is a new approach to quantitative magnetic resonance imaging that allows simultaneous measurement of multiple tissue properties in a single, time-efficient acquisition. The ability to reproducibly and quantitatively measure tissue properties could enable more objective tissue diagnosis, comparisons of scans acquired at different locations and time points, longitudinal follow-up of individual patients and development of imaging biomarkers. This review provides a general overview of MRF technology, current preclinical and clinical applications and potential future directions. MRF has been initially evaluated in brain, prostate, liver, cardiac, musculoskeletal imaging, and measurement of perfusion and microvascular properties through MR vascular fingerprinting."
    ],
    "b_categories":[
      "nucl-th"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.17410"
    ],
    "c_title":[
      "COSMOS: A Hybrid Adaptive Optimizer for Memory-Efficient Training of\n  LLMs"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) have demonstrated remarkable success across\nvarious domains, yet their optimization remains a significant challenge due to\nthe complex and high-dimensional loss landscapes they inhabit. While adaptive\noptimizers such as AdamW are widely used, they suffer from critical\nlimitations, including an inability to capture interdependencies between\ncoordinates and high memory consumption. Subsequent research, exemplified by\nSOAP, attempts to better capture coordinate interdependence but incurs greater\nmemory overhead, limiting scalability for massive LLMs. An alternative approach\naims to reduce memory consumption through low-dimensional projection, but this\nleads to substantial approximation errors, resulting in less effective\noptimization (e.g., in terms of per-token efficiency). In this paper, we\npropose COSMOS, a novel hybrid optimizer that leverages the varying importance\nof eigensubspaces in the gradient matrix to achieve memory efficiency without\ncompromising optimization performance. The design of COSMOS is motivated by our\nempirical insights and practical considerations. Specifically, COSMOS applies\nSOAP to the leading eigensubspace, which captures the primary optimization\ndynamics, and MUON to the remaining eigensubspace, which is less critical but\ncomputationally expensive to handle with SOAP. This hybrid strategy\nsignificantly reduces memory consumption while maintaining robust optimization\nperformance, making it particularly suitable for massive LLMs. Numerical\nexperiments on various datasets and transformer architectures are provided to\ndemonstrate the effectiveness of COSMOS. Our code is available at\nhttps:\/\/github.com\/lliu606\/COSMOS."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.10822",
    "a_title":"A Data-Efficient Sequential Learning Framework for Melt Pool Defect\n  Classification in Laser Powder Bed Fusion",
    "a_abstract":"Ensuring the quality and reliability of Metal Additive Manufacturing (MAM)\ncomponents is crucial, especially in the Laser Powder Bed Fusion (L-PBF)\nprocess, where melt pool defects such as keyhole, balling, and lack of fusion\ncan significantly compromise structural integrity. This study presents SL-RF+\n(Sequentially Learned Random Forest with Enhanced Sampling), a novel Sequential\nLearning (SL) framework for melt pool defect classification designed to\nmaximize data efficiency and model accuracy in data-scarce environments. SL-RF+\nutilizes RF classifier combined with Least Confidence Sampling (LCS) and Sobol\nsequence-based synthetic sampling to iteratively select the most informative\nsamples to learn from, thereby refining the model's decision boundaries with\nminimal labeled data. Results show that SL-RF+ outperformed traditional machine\nlearning models across key performance metrics, including accuracy, precision,\nrecall, and F1 score, demonstrating significant robustness in identifying melt\npool defects with limited data. This framework efficiently captures complex\ndefect patterns by focusing on high-uncertainty regions in the process\nparameter space, ultimately achieving superior classification performance\nwithout the need for extensive labeled datasets. While this study utilizes\npre-existing experimental data, SL-RF+ shows strong potential for real-world\napplications in pure sequential learning settings, where data is acquired and\nlabeled incrementally, mitigating the high costs and time constraints of sample\nacquisition.",
    "explanation":"Ensuring the quality and reliability of Metal Additive Manufacturing (MAM) components is crucial, especially in the Laser Powder Bed Fusion (L-PBF) process, where melt pool defects such as keyhole, balling, and lack of fusion can significantly compromise structural integrity. This study presents SL-RF+ (Sequentially Learned Random Forest with Enhanced Sampling), a novel Sequential Learning (SL) framework for melt pool defect classification designed to maximize data efficiency and model accuracy in data-scarce environments.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Additive manufacturing and sustainability: an exploratory study of the advantages and challenges"
    ],
    "b_abstract":[
      "The emergence of advanced manufacturing technologies, coupled with consumer demands for more customised products and services, are causing shifts in the scale distribution manufacturing. In this paper, consideration is given to role one such process technology: additive consequences adopting novel production technology on industrial sustainability not well understood exploratory study draws publically available data provide insights into impacts sustainability. Benefits found exist across product material life cycles through redesign, improvements input processing, make-to-order component manufacturing, closing loop. As an immature technology, there substantial challenges these benefits being realised at each stage cycle. This paper summarises advantages challenges, discusses implications terms sources innovation, business models, configuration value chains."
    ],
    "b_categories":[
      "cond-mat.mtrl-sci"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.01704"
    ],
    "c_title":[
      "DILEMMA: Joint LLM Quantization and Distributed LLM Inference Over Edge\n  Computing Systems"
    ],
    "c_abstract":[
      "With a recent trend of using Large Language Models (LLMs) for different\napplications within smart cities, there is a need for pushing these models\ntoward the edge of network while still preserving their performance. Edge\nComputing (EC) as a physically closer computing resource to the end users can\nhelp to reduce the communication delay for serving end users' tasks for\nLLM-dependent services. However, EC servers have limited capacity in terms of\ncommunication, computation, and storage capacity. This paper introduces\nDILEMMA, a novel framework addressing the challenges of deploying LLMs in EC\nsystems by jointly optimizing layer placement and layer quantization in EC\nsystems. DILEMMA formulates an Integer Linear Programming problem to minimize\ntotal inference delay while ensuring acceptable LLM performance levels,\nleveraging layer-wise quantization and knowledge distillation for LLM\nperformance control. Experimental evaluations on OPT-350 model using the SQuAD\ndataset demonstrate that DILEMMA achieves a quantization ratio of up to 12.75%\nwhile preserving model loss, highlighting its effectiveness in\nresource-constrained environments."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.10822",
    "a_title":"A Data-Efficient Sequential Learning Framework for Melt Pool Defect\n  Classification in Laser Powder Bed Fusion",
    "a_abstract":"Ensuring the quality and reliability of Metal Additive Manufacturing (MAM)\ncomponents is crucial, especially in the Laser Powder Bed Fusion (L-PBF)\nprocess, where melt pool defects such as keyhole, balling, and lack of fusion\ncan significantly compromise structural integrity. This study presents SL-RF+\n(Sequentially Learned Random Forest with Enhanced Sampling), a novel Sequential\nLearning (SL) framework for melt pool defect classification designed to\nmaximize data efficiency and model accuracy in data-scarce environments. SL-RF+\nutilizes RF classifier combined with Least Confidence Sampling (LCS) and Sobol\nsequence-based synthetic sampling to iteratively select the most informative\nsamples to learn from, thereby refining the model's decision boundaries with\nminimal labeled data. Results show that SL-RF+ outperformed traditional machine\nlearning models across key performance metrics, including accuracy, precision,\nrecall, and F1 score, demonstrating significant robustness in identifying melt\npool defects with limited data. This framework efficiently captures complex\ndefect patterns by focusing on high-uncertainty regions in the process\nparameter space, ultimately achieving superior classification performance\nwithout the need for extensive labeled datasets. While this study utilizes\npre-existing experimental data, SL-RF+ shows strong potential for real-world\napplications in pure sequential learning settings, where data is acquired and\nlabeled incrementally, mitigating the high costs and time constraints of sample\nacquisition.",
    "explanation":"Ensuring the quality and reliability of Metal Additive Manufacturing (MAM) components is crucial, especially in the Laser Powder Bed Fusion (L-PBF) process, where melt pool defects such as keyhole, balling, and lack of fusion can significantly compromise structural integrity. This study presents SL-RF+ (Sequentially Learned Random Forest with Enhanced Sampling), a novel Sequential Learning (SL) framework for melt pool defect classification designed to maximize data efficiency and model accuracy in data-scarce environments.",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "Machine learning in additive manufacturing: State-of-the-art and perspectives"
    ],
    "b_abstract":[
      "Additive manufacturing (AM) has emerged as a disruptive digital manufacturing technology. However, its broad adoption in industry is still hindered by high entry barriers of design for additive manufacturing (DfAM), limited materials library, various processing defects, and inconsistent product quality. In recent years, machine learning (ML) has gained increasing attention in AM due to its unprecedented performance in data tasks such as classification, regression and clustering. This article provides a comprehensive review on the state-of-the-art of ML applications in a variety of AM domains. In the DfAM, ML can be leveraged to output new high-performance metamaterials and optimized topological designs. In AM processing, contemporary ML algorithms can help to optimize process parameters, and conduct examination of powder spreading and in-process defect monitoring. On the production of AM, ML is able to assist practitioners in pre-manufacturing planning, and product quality assessment and control. Moreover, there has been an increasing concern about data security in AM as data breaches could occur with the aid of ML techniques. Lastly, it concludes with a section summarizing the main findings from the literature and providing perspectives on some selected interesting applications of ML in research and development of AM."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.07291"
    ],
    "c_title":[
      "Hydrogen Bond Strength Dictates the Rate-Limiting Steps of Diffusion in\n  Proton-Conducting Perovskites:A Critical Length Perspective"
    ],
    "c_abstract":[
      "Proton-conducting solid oxide fuel cells (PC-SOFCs) are pivotal for their\nhigh proton conductivity and superior performance. The proton conduction\nmechanism is commonly described by the Grotthuss mechanism, involving proton\nrotation and transfer. While proton transfer is often considered the\nrate-limiting step, the underlying reasons remain unclear. Through density\nfunctional theory calculations on undoped, A-site doped, and B-site doped\nBaHfO$_3$ systems, we demonstrate that the rate-limiting nature of proton\ntransfer stems from the formation of weaker hydrogen bonds. In systems with\nstrong hydrogen bonds, proton rotation becomes non-negligible. We identify a\ncritical hydrogen bond length that distinguishes strong from weak bonds, with\nshorter lengths correlating with distorted perovskite structures and\nconfigurations deviating from cubic. This insight into the necessity of\nrotation is crucial for screening and optimizing materials with superior proton\nconduction properties."
    ],
    "c_categories":[
      "cond-mat.mtrl-sci"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04323",
    "a_title":"Efficient Symmetry-Aware Materials Generation via Hierarchical\n  Generative Flow Networks",
    "a_abstract":"Discovering new solid-state materials requires rapidly exploring the vast\nspace of crystal structures and locating stable regions. Generating stable\nmaterials with desired properties and compositions is extremely difficult as we\nsearch for very small isolated pockets in the exponentially many possibilities,\nconsidering elements from the periodic table and their 3D arrangements in\ncrystal lattices. Materials discovery necessitates both optimized solution\nstructures and diversity in the generated material structures. Existing methods\nstruggle to explore large material spaces and generate diverse samples with\ndesired properties and requirements. We propose the Symmetry-aware Hierarchical\nArchitecture for Flow-based Traversal (SHAFT), a novel generative model\nemploying a hierarchical exploration strategy to efficiently exploit the\nsymmetry of the materials space to generate crystal structures given desired\nproperties. In particular, our model decomposes the exponentially large\nmaterials space into a hierarchy of subspaces consisting of symmetric space\ngroups, lattice parameters, and atoms. We demonstrate that SHAFT significantly\noutperforms state-of-the-art iterative generative methods, such as Generative\nFlow Networks (GFlowNets) and Crystal Diffusion Variational AutoEncoders\n(CDVAE), in crystal structure generation tasks, achieving higher validity,\ndiversity, and stability of generated structures optimized for target\nproperties and requirements.",
    "explanation":"Materials discovery necessitates both optimized solution structures and diversity in the generated material structures. We propose the Symmetry-aware\nHierarchical Architecture for Flow-based Traversal (SHAFT),a novel generative model employing a hierarchical exploration strategy to efficiently exploit the symmetry of the materials space to generate crystal structures given desired properties.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation"
    ],
    "b_abstract":[
      "This paper is about the problem of learning a stochastic policy for generating an object (like molecular graph) from sequence actions, such that probability proportional to given positive reward object. Whereas standard return maximization tends converge single return-maximizing sequence, there are cases where we would like sample diverse set high-return solutions. These arise, example, in black-box function optimization when few rounds possible, each with large batches queries, should be diverse, e.g., design new molecules. One can also see this as approximately converting energy generative distribution. While MCMC methods achieve that, they expensive and generally only perform local exploration. Instead, training amortizes cost search during yields fast generation. Using insights Temporal Difference learning, propose GFlowNet, based on view process flow network, making it possible handle tricky case different trajectories yield same final state, many ways sequentially add atoms generate some graph. We cast convert consistency equations into objective, akin casting Bellman methods. prove any global minimum proposed objectives which samples desired distribution, demonstrate improved performance diversity GFlowNet simple domain modes function, molecule synthesis task."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.08399"
    ],
    "c_title":[
      "Ferromagnetic Resonance in a Magnetically Dilute Percolating\n  Ferromagnet: An Experimental and Theoretical Study"
    ],
    "c_abstract":[
      "Ferromagnetic resonance (FMR) serves as a powerful probe of magnetization\ndynamics and anisotropy in percolating ferromagnets, where short-range\ninteractions govern long-range magnetic order. We apply this approach to\nGa$_{1-x}$Mn$_x$N ($x \\simeq 8$), a dilute ferromagnetic semiconductor,\ncombining FMR and superconducting quantum interference device magnetometry. Our\nresults confirm the percolative nature of ferromagnetism in (Ga,Mn)N, with a\nCurie temperature $T_{\\mathrm{C}} = 12$ K, and reveal that despite magnetic\ndilution, key features of conventional ferromagnets are retained. FMR\nmeasurements establish a robust uniaxial anisotropy, dictated by Mn$^{3+}$\nsingle-ion anisotropy, with an easy-plane character at low Mn content. While\nexcessive line broadening suppresses FMR signals below 9 K, they persist up to\n70 K, indicating the presence of non-percolating ferromagnetic clusters well\nabove $T_{\\mathrm{C}}$. The temperature dependence of the FMR intensity follows\nthat of the magnetization, underscoring the stability of these clusters.\nAnalysis of the FMR linewidth provides insights into relaxation processes,\nrevealing large Gilbert damping due to the low magnetization of the system.\nStrikingly, atomistic spin model simulations reproduce the experimentally\nobserved resonance fields, anisotropy trends, and linewidth evolution with\nremarkable accuracy. This agreement underscores the predictive power of our\nmodeling approach in describing percolating ferromagnets. This study advances\nthe understanding of percolating ferromagnetic systems, demonstrating that FMR\nis a key technique for probing their unique dynamic and anisotropic properties.\nOur findings contribute to the broader exploration of dilute ferromagnets and\nprovide new insights into percolating ferromagnetic systems, which will be\nrelevant for spintronic opportunities."
    ],
    "c_categories":[
      "cond-mat.mtrl-sci"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04323",
    "a_title":"Efficient Symmetry-Aware Materials Generation via Hierarchical\n  Generative Flow Networks",
    "a_abstract":"Discovering new solid-state materials requires rapidly exploring the vast\nspace of crystal structures and locating stable regions. Generating stable\nmaterials with desired properties and compositions is extremely difficult as we\nsearch for very small isolated pockets in the exponentially many possibilities,\nconsidering elements from the periodic table and their 3D arrangements in\ncrystal lattices. Materials discovery necessitates both optimized solution\nstructures and diversity in the generated material structures. Existing methods\nstruggle to explore large material spaces and generate diverse samples with\ndesired properties and requirements. We propose the Symmetry-aware Hierarchical\nArchitecture for Flow-based Traversal (SHAFT), a novel generative model\nemploying a hierarchical exploration strategy to efficiently exploit the\nsymmetry of the materials space to generate crystal structures given desired\nproperties. In particular, our model decomposes the exponentially large\nmaterials space into a hierarchy of subspaces consisting of symmetric space\ngroups, lattice parameters, and atoms. We demonstrate that SHAFT significantly\noutperforms state-of-the-art iterative generative methods, such as Generative\nFlow Networks (GFlowNets) and Crystal Diffusion Variational AutoEncoders\n(CDVAE), in crystal structure generation tasks, achieving higher validity,\ndiversity, and stability of generated structures optimized for target\nproperties and requirements.",
    "explanation":"Materials discovery necessitates both optimized solution structures and diversity in the generated material structures. We propose the Symmetry-aware\nHierarchical Architecture for Flow-based Traversal (SHAFT),a novel generative model employing a hierarchical exploration strategy to efficiently exploit the symmetry of the materials space to generate crystal structures given desired properties.",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals"
    ],
    "b_abstract":[
      "Graph networks are a new machine learning (ML) paradigm that supports both relational reasoning and combinatorial generalization. Here, we develop universal MatErials Network (MEGNet) models for accurate property prediction in molecules crystals. We demonstrate the MEGNet outperform prior ML such as SchNet 11 out of 13 properties QM9 molecule data set. Similarly, show trained on \u223c60 000 crystals Materials Project substantially formation energies, band gaps, elastic moduli crystals, achieving better than density functional theory accuracy over much larger present two strategies to address limitations common materials science chemistry. First, physically intuitive approach unify four separate molecular internal energy at 0 K room temperature, enthalpy, Gibbs free into single model by incorporating pressure, entropy global state inputs. Second, learned element embeddings encode periodic chemical trends can be transfer-learned from set (formation energies) improve with smaller amounts (band gaps moduli)."
    ],
    "b_categories":[
      "cond-mat.mtrl-sci"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.01704"
    ],
    "c_title":[
      "DILEMMA: Joint LLM Quantization and Distributed LLM Inference Over Edge\n  Computing Systems"
    ],
    "c_abstract":[
      "With a recent trend of using Large Language Models (LLMs) for different\napplications within smart cities, there is a need for pushing these models\ntoward the edge of network while still preserving their performance. Edge\nComputing (EC) as a physically closer computing resource to the end users can\nhelp to reduce the communication delay for serving end users' tasks for\nLLM-dependent services. However, EC servers have limited capacity in terms of\ncommunication, computation, and storage capacity. This paper introduces\nDILEMMA, a novel framework addressing the challenges of deploying LLMs in EC\nsystems by jointly optimizing layer placement and layer quantization in EC\nsystems. DILEMMA formulates an Integer Linear Programming problem to minimize\ntotal inference delay while ensuring acceptable LLM performance levels,\nleveraging layer-wise quantization and knowledge distillation for LLM\nperformance control. Experimental evaluations on OPT-350 model using the SQuAD\ndataset demonstrate that DILEMMA achieves a quantization ratio of up to 12.75%\nwhile preserving model loss, highlighting its effectiveness in\nresource-constrained environments."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.16896",
    "a_title":"Enhancing Fluorescence Lifetime Parameter Estimation Accuracy with\n  Differential Transformer Based Deep Learning Model Incorporating Pixelwise\n  Instrument Response Function",
    "a_abstract":"Fluorescence Lifetime Imaging (FLI) is a critical molecular imaging modality\nthat provides unique information about the tissue microenvironment, which is\ninvaluable for biomedical applications. FLI operates by acquiring and analyzing\nphoton time-of-arrival histograms to extract quantitative parameters associated\nwith temporal fluorescence decay. These histograms are influenced by the\nintrinsic properties of the fluorophore, instrument parameters, time-of-flight\ndistributions associated with pixel-wise variations in the topographic and\noptical characteristics of the sample. Recent advancements in Deep Learning\n(DL) have enabled improved fluorescence lifetime parameter estimation. However,\nexisting models are primarily designed for planar surface samples, limiting\ntheir applicability in translational scenarios involving complex surface\nprofiles, such as \\textit{in-vivo} whole-animal or imaged guided surgical\napplications. To address this limitation, we present MFliNet (Macroscopic FLI\nNetwork), a novel DL architecture that integrates the Instrument Response\nFunction (IRF) as an additional input alongside experimental photon\ntime-of-arrival histograms. Leveraging the capabilities of a Differential\nTransformer encoder-decoder architecture, MFliNet effectively focuses on\ncritical input features, such as variations in photon time-of-arrival\ndistributions. We evaluate MFliNet using rigorously designed tissue-mimicking\nphantoms and preclinical in-vivo cancer xenograft models. Our results\ndemonstrate the model's robustness and suitability for complex macroscopic FLI\napplications, offering new opportunities for advanced biomedical imaging in\ndiverse and challenging settings.",
    "explanation":"Recent advancements in Deep Learning (DL) have enabled improved fluorescence lifetime parameter estimation",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Characterization of fluorescence lifetime of organic fluorophores for molecular imaging in the shortwave infrared window"
    ],
    "b_abstract":[
      "SignificanceFluorescence lifetime imaging in the shortwave infrared (SWIR) is expected to enable high-resolution multiplexed molecular highly scattering tissue.AimTo characterize brightness and fluorescence of commercially available organic SWIR fluorophores benchmark them against tail emission conventional NIR-excited probes.ApproachCharacterization was performed through our established time-domain mesoscopic tomography system integrated around a time-correlated single-photon counting-single-photon avalanche diode array. Brightness were measured for NIR probes >1000 nm. Simultaneous probe then assess their potential studies.ResultsThe outperformed while mean lifetimes extremely short. The phantom study demonstrated feasibility multiplexing window with both probes.ConclusionsLong-tail Fluorescence readily detectable window, where showed shorter compared probes. We demonstrate which paves way vivo studies intact tissues at improved resolution."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.16481"
    ],
    "c_title":[
      "A Weight Adaptation Trigger Mechanism in Decomposition-based\n  Evolutionary Multi-Objective Optimisation"
    ],
    "c_abstract":[
      "Decomposition-based multi-objective evolutionary algorithms (MOEAs) are\nwidely used for solving multi-objective optimisation problems. However, their\neffectiveness depends on the consistency between the problems Pareto front\nshape and the weight distribution. Decomposition-based MOEAs, with uniformly\ndistributed weights (in a simplex), perform well on problems with a regular\n(simplex-like) Pareto front, but not on those with an irregular Pareto front.\nPrevious studies have focused on adapting the weights to approximate the\nirregular Pareto front during the evolutionary process. However, these\nadaptations can actually harm the performance on the regular Pareto front via\nchanging the weights during the search process that are eventually the best fit\nfor the Pareto front. In this paper, we propose an algorithm called the weight\nadaptation trigger mechanism for decomposition-based MOEAs (ATM-MOEA\/D) to\ntackle this issue. ATM-MOEA\/D uses an archive to gradually approximate the\nshape of the Pareto front during the search. When the algorithm detects\nevolution stagnation (meaning the population no longer improves significantly),\nit compares the distribution of the population with that of the archive to\ndistinguish between regular and irregular Pareto fronts. Only when an irregular\nPareto front is identified, the weights are adapted. Our experimental results\nshow that the proposed algorithm not only performs generally better than seven\nstate-of-the-art weight-adapting methods on irregular Pareto fronts but also is\nable to achieve the same results as fixed-weight methods like MOEA\/D on regular\nPareto fronts."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.16896",
    "a_title":"Enhancing Fluorescence Lifetime Parameter Estimation Accuracy with\n  Differential Transformer Based Deep Learning Model Incorporating Pixelwise\n  Instrument Response Function",
    "a_abstract":"Fluorescence Lifetime Imaging (FLI) is a critical molecular imaging modality\nthat provides unique information about the tissue microenvironment, which is\ninvaluable for biomedical applications. FLI operates by acquiring and analyzing\nphoton time-of-arrival histograms to extract quantitative parameters associated\nwith temporal fluorescence decay. These histograms are influenced by the\nintrinsic properties of the fluorophore, instrument parameters, time-of-flight\ndistributions associated with pixel-wise variations in the topographic and\noptical characteristics of the sample. Recent advancements in Deep Learning\n(DL) have enabled improved fluorescence lifetime parameter estimation. However,\nexisting models are primarily designed for planar surface samples, limiting\ntheir applicability in translational scenarios involving complex surface\nprofiles, such as \\textit{in-vivo} whole-animal or imaged guided surgical\napplications. To address this limitation, we present MFliNet (Macroscopic FLI\nNetwork), a novel DL architecture that integrates the Instrument Response\nFunction (IRF) as an additional input alongside experimental photon\ntime-of-arrival histograms. Leveraging the capabilities of a Differential\nTransformer encoder-decoder architecture, MFliNet effectively focuses on\ncritical input features, such as variations in photon time-of-arrival\ndistributions. We evaluate MFliNet using rigorously designed tissue-mimicking\nphantoms and preclinical in-vivo cancer xenograft models. Our results\ndemonstrate the model's robustness and suitability for complex macroscopic FLI\napplications, offering new opportunities for advanced biomedical imaging in\ndiverse and challenging settings.",
    "explanation":"Recent advancements in Deep Learning (DL) have enabled improved fluorescence lifetime parameter estimation",
    "b_id":[
      "b27"
    ],
    "b_title":[
      "Fast fit-free analysis of fluorescence lifetime imaging via deep learning"
    ],
    "b_abstract":[
      "Fluorescence lifetime imaging (FLI) provides unique quantitative information in biomedical and molecular biology studies but relies on complex data-fitting techniques to derive the quantities of interest. Herein, we propose a fit-free approach FLI image formation that is based deep learning (DL) quantify fluorescence decays simultaneously over whole at fast speeds. We report neural network (DNN) architecture, named (FLI-Net) designed trained for different classes experiments, including visible near-infrared (NIR) microscopy (FLIM) NIR gated macroscopy (MFLI). FLI-Net outputs quantitatively spatially resolved lifetime-based parameters are typically employed field. validate utility framework by performing microscopic preclinical across spectra, as well 2 main data acquisition technologies. These results demonstrate suited accurately lifetimes cells and, real time, intact animals without any parameter settings. Hence, paves way reproducible unprecedented speeds, improved dissemination impact many important applications ranging from fundamental discoveries cellular clinical translation."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.07671"
    ],
    "c_title":[
      "Steering Protein Family Design through Profile Bayesian Flow"
    ],
    "c_abstract":[
      "Protein family design emerges as a promising alternative by combining the\nadvantages of de novo protein design and mutation-based directed evolution.In\nthis paper, we propose ProfileBFN, the Profile Bayesian Flow Networks, for\nspecifically generative modeling of protein families. ProfileBFN extends the\ndiscrete Bayesian Flow Network from an MSA profile perspective, which can be\ntrained on single protein sequences by regarding it as a degenerate profile,\nthereby achieving efficient protein family design by avoiding large-scale MSA\ndata construction and training. Empirical results show that ProfileBFN has a\nprofound understanding of proteins. When generating diverse and novel family\nproteins, it can accurately capture the structural characteristics of the\nfamily. The enzyme produced by this method is more likely than the previous\napproach to have the corresponding function, offering better odds of generating\ndiverse proteins with the desired functionality."
    ],
    "c_categories":[
      "q-bio.BM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.16961",
    "a_title":"Glo-In-One-v2: Holistic Identification of Glomerular Cells, Tissues, and\n  Lesions in Human and Mouse Histopathology",
    "a_abstract":"Segmenting glomerular intraglomerular tissue and lesions traditionally\ndepends on detailed morphological evaluations by expert nephropathologists, a\nlabor-intensive process susceptible to interobserver variability. Our group\npreviously developed the Glo-In-One toolkit for integrated detection and\nsegmentation of glomeruli. In this study, we leverage the Glo-In-One toolkit to\nversion 2 with fine-grained segmentation capabilities, curating 14 distinct\nlabels for tissue regions, cells, and lesions across a dataset of 23,529\nannotated glomeruli across human and mouse histopathology data. To our\nknowledge, this dataset is among the largest of its kind to date.In this study,\nwe present a single dynamic head deep learning architecture designed to segment\n14 classes within partially labeled images of human and mouse pathology data.\nOur model was trained using a training set derived from 368 annotated kidney\nwhole-slide images (WSIs) to identify 5 key intraglomerular tissues covering\nBowman's capsule, glomerular tuft, mesangium, mesangial cells, and podocytes.\nAdditionally, the network segments 9 glomerular lesion classes including\nadhesion, capsular drop, global sclerosis, hyalinosis, mesangial lysis,\nmicroaneurysm, nodular sclerosis, mesangial expansion, and segmental sclerosis.\nThe glomerulus segmentation model achieved a decent performance compared with\nbaselines, and achieved a 76.5 % average Dice Similarity Coefficient (DSC).\nAdditional, transfer learning from rodent to human for glomerular lesion\nsegmentation model has enhanced the average segmentation accuracy across\ndifferent types of lesions by more than 3 %, as measured by Dice scores. The\nGlo-In-One-v2 model and trained weight have been made publicly available at\nhttps: \/\/github.com\/hrlblab\/Glo-In-One_v2.",
    "explanation":"In this study, we present a single dynamic head deep learning architecture designed to segment 14 classes within partially labeled images of human and mouse pathology data",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Pathology image analysis using segmentation deep learning algorithms"
    ],
    "b_abstract":[
      "With the rapid development of image scanning techniques and visualization software, whole slide imaging (WSI) is becoming a routine diagnostic method. Accelerating clinical diagnosis from pathology images and automating image analysis efficiently and accurately remain significant challenges. Recently, deep learning algorithms have shown great promise in pathology image analysis, such as in tumor region identification, metastasis detection, and patient prognosis. Many machine learning algorithms, including convolutional neural networks, have been proposed to automatically segment pathology images. Among these algorithms, segmentation deep learning algorithms such as fully convolutional networks stand out for their accuracy, computational efficiency, and generalizability. Thus, deep learning\u2013based pathology image segmentation has become an important tool in WSI analysis. In this review, the pathology image segmentation process using deep learning algorithms is described in detail. The goals are to provide quick guidance for implementing deep learning into pathology image analysis and to provide some potential ways of further improving segmentation performance. Although there have been previous reviews on using machine learning methods in digital pathology image analysis, this is the first in-depth review of the applications of deep learning algorithms for segmentation in WSI analysis."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.19343"
    ],
    "c_title":[
      "Effect of a new type of healthy and live food supplement on osteoporosis\n  blood parameters and induced rheumatoid arthritis in Wistar rats"
    ],
    "c_abstract":[
      "Summary Osteoporosis is a skeletal disorder, characterized by a decrease in\nbone strength and puts the individual at risk for fracture. On the other hand,\nrheumatoid arthritis is a systemic disease of unknown etiology that causes\ninflammation of the joints of the organs. Purpose Due to the destructive\neffects of these diseases and its increasing prevalence and lack of appropriate\nmedication for treatment, the present study aimed to evaluate the therapeutic\neffect of a new type of healthy and live food supplement on rheumatoid\narthritis and induced osteoporosis in rats. Methods In this research, healthy\nand live food powder were synthesized by a new and green route. This organic\nbiomaterial was named NBS. The NBS food supplement had various vitamins, macro\nand micro molecules, and ingredients. The new healthy and nutritious diet\nshowed that the use of this supplement led to the return of the parameters to\nnormal levels. Results The concentration of 12.5 mg\/ kg showed the least\ntherapeutic effect and 50 mg\/ kg had the highest therapeutic effect for\nosteoporosis. The results of blood parameters involved in inflammation in both\nhealthy and patient groups showed that the use of complete adjuvant induction\ncauses joint inflammation. In the study of the interaction of the\nconcentrations, it was observed that the concentration of 50 mg\/ kg had the\nhighest therapeutic effect against the disease in the studied mice. Conclusion\nThe results showed that the new healthy and viable supplement restores the\nblood osteoporotic and rheumatoid factors of the mice to normal."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.16961",
    "a_title":"Glo-In-One-v2: Holistic Identification of Glomerular Cells, Tissues, and\n  Lesions in Human and Mouse Histopathology",
    "a_abstract":"Segmenting glomerular intraglomerular tissue and lesions traditionally\ndepends on detailed morphological evaluations by expert nephropathologists, a\nlabor-intensive process susceptible to interobserver variability. Our group\npreviously developed the Glo-In-One toolkit for integrated detection and\nsegmentation of glomeruli. In this study, we leverage the Glo-In-One toolkit to\nversion 2 with fine-grained segmentation capabilities, curating 14 distinct\nlabels for tissue regions, cells, and lesions across a dataset of 23,529\nannotated glomeruli across human and mouse histopathology data. To our\nknowledge, this dataset is among the largest of its kind to date.In this study,\nwe present a single dynamic head deep learning architecture designed to segment\n14 classes within partially labeled images of human and mouse pathology data.\nOur model was trained using a training set derived from 368 annotated kidney\nwhole-slide images (WSIs) to identify 5 key intraglomerular tissues covering\nBowman's capsule, glomerular tuft, mesangium, mesangial cells, and podocytes.\nAdditionally, the network segments 9 glomerular lesion classes including\nadhesion, capsular drop, global sclerosis, hyalinosis, mesangial lysis,\nmicroaneurysm, nodular sclerosis, mesangial expansion, and segmental sclerosis.\nThe glomerulus segmentation model achieved a decent performance compared with\nbaselines, and achieved a 76.5 % average Dice Similarity Coefficient (DSC).\nAdditional, transfer learning from rodent to human for glomerular lesion\nsegmentation model has enhanced the average segmentation accuracy across\ndifferent types of lesions by more than 3 %, as measured by Dice scores. The\nGlo-In-One-v2 model and trained weight have been made publicly available at\nhttps: \/\/github.com\/hrlblab\/Glo-In-One_v2.",
    "explanation":"In this study, we present a single dynamic head deep learning architecture designed to segment 14 classes within partially labeled images of human and mouse pathology data",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Comparative gene expression profiles of intestinal transporters in mice, rats and humans"
    ],
    "b_abstract":[
      "We have studied gene expression profiles of intestinal transporters in model animals and humans. Total RNA was isolated from duodenum and the mRNA expression was measured using Affymetrix GeneChip oligonucleotide arrays. Detected genes from the intestine of mice, rats, and humans were about 60% of 22,690 sequences, 40% of 8739, and 47% of 12,559, respectively. A total of 86 genes involving transporters expressed in mice, 50 genes in rats, and 61 genes in humans were detected. Mice exhibited abundant mRNA expressions for peptide transporter HPT1, amino acid transporters CSNU3, CT1 and ASC1, nucleoside transporter CNT2, organic cation transporter SFXN1, organic anion transporter NBC3, glucose transporter SGLT1, and fatty acid transporters FABP1 and FABP2. Rats showed high expression profiles of peptide transporter PEPT1, amino acid transporters CSNU1 and 4F2HC, nucleoside transporter CNT2, organic cation transporter OCT5, organic anion transporter SDCT1, glucose transporter GLUT2 and GLUT5, and folate carrier FOLT. In humans, the highly expressed genes were peptide transporter HPT1, amino acid transporters LAT3, 4F2HC and PROT, nucleoside transporter CNT2, organic cation transporter OCTN2, organic anion transporters NADC1, NBC1 and SBC2, glucose transporters SGLT1 and GLUT5, multidrug resistance-associated protein RHO12, fatty acid transporters FABP1 and FABP2, and phosphate carrier PHC. Overall these data reveal diverse transcriptomic profiles for intestinal transporters among these species. Therefore, this transcriptional data may lead to more effective use of the laboratory animals as a model for oral drug development."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.16481"
    ],
    "c_title":[
      "A Weight Adaptation Trigger Mechanism in Decomposition-based\n  Evolutionary Multi-Objective Optimisation"
    ],
    "c_abstract":[
      "Decomposition-based multi-objective evolutionary algorithms (MOEAs) are\nwidely used for solving multi-objective optimisation problems. However, their\neffectiveness depends on the consistency between the problems Pareto front\nshape and the weight distribution. Decomposition-based MOEAs, with uniformly\ndistributed weights (in a simplex), perform well on problems with a regular\n(simplex-like) Pareto front, but not on those with an irregular Pareto front.\nPrevious studies have focused on adapting the weights to approximate the\nirregular Pareto front during the evolutionary process. However, these\nadaptations can actually harm the performance on the regular Pareto front via\nchanging the weights during the search process that are eventually the best fit\nfor the Pareto front. In this paper, we propose an algorithm called the weight\nadaptation trigger mechanism for decomposition-based MOEAs (ATM-MOEA\/D) to\ntackle this issue. ATM-MOEA\/D uses an archive to gradually approximate the\nshape of the Pareto front during the search. When the algorithm detects\nevolution stagnation (meaning the population no longer improves significantly),\nit compares the distribution of the population with that of the archive to\ndistinguish between regular and irregular Pareto fronts. Only when an irregular\nPareto front is identified, the weights are adapted. Our experimental results\nshow that the proposed algorithm not only performs generally better than seven\nstate-of-the-art weight-adapting methods on irregular Pareto fronts but also is\nable to achieve the same results as fixed-weight methods like MOEA\/D on regular\nPareto fronts."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06750",
    "a_title":"SynStitch: a Self-Supervised Learning Network for Ultrasound Image\n  Stitching Using Synthetic Training Pairs and Indirect Supervision",
    "a_abstract":"Ultrasound (US) image stitching can expand the field-of-view (FOV) by\ncombining multiple US images from varied probe positions. However, registering\nUS images with only partially overlapping anatomical contents is a challenging\ntask. In this work, we introduce SynStitch, a self-supervised framework\ndesigned for 2DUS stitching. SynStitch consists of a synthetic stitching pair\ngeneration module (SSPGM) and an image stitching module (ISM). SSPGM utilizes a\npatch-conditioned ControlNet to generate realistic 2DUS stitching pairs with\nknown affine matrix from a single input image. ISM then utilizes this synthetic\npaired data to learn 2DUS stitching in a supervised manner. Our framework was\nevaluated against multiple leading methods on a kidney ultrasound dataset,\ndemonstrating superior 2DUS stitching performance through both qualitative and\nquantitative analyses. The code will be made public upon acceptance of the\npaper.",
    "explanation":"Ultrasound (US) image stitching can expand the field-of view (FOV) by combining multiple US images from varied probe positions [...] In this work, we introduce SynStitch, a self-supervised framework designed for 2DUS stitching",
    "b_id":[
      "b3",
      "b21"
    ],
    "b_title":[
      "3-D ultrasound imaging: a review",
      "Generative AI for Medical Imaging: extending the MONAI Framework"
    ],
    "b_abstract":[
      "The development of 3-D ultrasound imaging is a way to address the disadvantages conventional imaging. In this article authors review approaches that have been attempted in such as B-mode, color Doppler, and power Doppler systems. Acquisition, reconstruction, rendering techniques for are discussed, well applications limitations.",
      "Recent advances in generative AI have brought incredible breakthroughs several areas, including medical imaging. These models tremendous potential not only to help safely share data via synthetic datasets but also perform an array of diverse applications, such as anomaly detection, image-to-image translation, denoising, and MRI reconstruction. However, due the complexity these models, their implementation reproducibility can be difficult. This hinder progress, act a use barrier, dissuade comparison new methods with existing works. In this study, we present MONAI Generative Models, freely available open-source platform that allows researchers developers easily train, evaluate, deploy related applications. Our reproduces state-of-art studies standardised way involving different architectures (such diffusion autoregressive transformers, GANs), provides pre-trained for community. We implemented generalisable fashion, illustrating results extended 2D or 3D scenarios, images modalities (like CT, MRI, X-Ray data) from anatomical areas. Finally, adopt modular extensible approach, ensuring long-term maintainability extension current applications future features."
    ],
    "b_categories":[
      "cs.CV",
      "eess.IV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.03741"
    ],
    "c_title":[
      "Neural encoding with affine feature response transforms"
    ],
    "c_abstract":[
      "Current linearizing encoding models that predict neural responses to sensory\ninput typically neglect neuroscience-inspired constraints that could enhance\nmodel efficiency and interpretability. To address this, we propose a new method\ncalled affine feature response transform (AFRT), which exploits the brain's\nretinotopic organization. Applying AFRT to encode multi-unit activity in areas\nV1, V4, and IT of the macaque brain, we demonstrate that AFRT reduces redundant\ncomputations and enhances the performance of current linearizing encoding\nmodels by segmenting each neuron's receptive field into an affine retinal\ntransform, followed by a localized feature response. Remarkably, by factorizing\nreceptive fields into a sequential affine component with three interpretable\nparameters (for shifting and scaling) and response components with a small\nnumber of feature weights per response, AFRT achieves encoding with orders of\nmagnitude fewer parameters compared to unstructured models. We show that the\nretinal transform of each neuron's encoding agrees well with the brain's\nreceptive field. Together, these findings suggest that this new subset within\nspatial transformer network can be instrumental in neural encoding models of\nnaturalistic stimuli."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06750",
    "a_title":"SynStitch: a Self-Supervised Learning Network for Ultrasound Image\n  Stitching Using Synthetic Training Pairs and Indirect Supervision",
    "a_abstract":"Ultrasound (US) image stitching can expand the field-of-view (FOV) by\ncombining multiple US images from varied probe positions. However, registering\nUS images with only partially overlapping anatomical contents is a challenging\ntask. In this work, we introduce SynStitch, a self-supervised framework\ndesigned for 2DUS stitching. SynStitch consists of a synthetic stitching pair\ngeneration module (SSPGM) and an image stitching module (ISM). SSPGM utilizes a\npatch-conditioned ControlNet to generate realistic 2DUS stitching pairs with\nknown affine matrix from a single input image. ISM then utilizes this synthetic\npaired data to learn 2DUS stitching in a supervised manner. Our framework was\nevaluated against multiple leading methods on a kidney ultrasound dataset,\ndemonstrating superior 2DUS stitching performance through both qualitative and\nquantitative analyses. The code will be made public upon acceptance of the\npaper.",
    "explanation":"Ultrasound (US) image stitching can expand the field-of view (FOV) by combining multiple US images from varied probe positions [...] In this work, we introduce SynStitch, a self-supervised framework designed for 2DUS stitching",
    "b_id":[
      "b13"
    ],
    "b_title":[
      "Symmetric diffeomorphic image registration with crosscorrelation: evaluating automated labeling of elderly and neurodegenerative brain"
    ],
    "b_abstract":[
      "One of the most challenging problems in modern neuroimaging is detailed characterization of neurodegeneration. Quantifying spatial and longitudinal atrophy patterns is an important component of this process. These spatiotemporal signals will aid in discriminating between related diseases, such as frontotemporal dementia (FTD) and Alzheimer's disease (AD), which manifest themselves in the same at-risk population. Here, we develop a novel symmetric image normalization method (SyN) for maximizing the cross-correlation within the space of diffeomorphic maps and provide the Euler-Lagrange equations necessary for this optimization. We then turn to a careful evaluation of our method. Our evaluation uses gold standard, human cortical segmentation to contrast SyN's performance with a related elastic method and with the standard ITK implementation of Thirion's Demons algorithm. The new method compares favorably with both approaches, in particular when the distance between the template brain and the target brain is large. We then report the correlation of volumes gained by algorithmic cortical labelings of FTD and control subjects with those gained by the manual rater. This comparison shows that, of the three methods tested, SyN's volume measurements are the most strongly correlated with volume measurements gained by expert labeling. This study indicates that SyN, with cross-correlation, is a reliable method for normalizing and making anatomical measurements in volumetric MRI of patients and at-risk elderly individuals."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.17792"
    ],
    "c_title":[
      "Topology preserving Image segmentation using the iterative\n  convolution-thresholding method"
    ],
    "c_abstract":[
      "Variational models are widely used in image segmentation, with various models\ndesigned to address different types of images by optimizing specific objective\nfunctionals. However, traditional segmentation models primarily focus on the\nvisual attributes of the image, often neglecting the topological properties of\nthe target objects. This limitation can lead to segmentation results that\ndeviate from the ground truth, particularly in images with complex topological\nstructures. In this paper, we introduce a topology-preserving constraint into\nthe iterative convolution-thresholding method (ICTM), resulting in the\ntopology-preserving ICTM (TP-ICTM). Extensive experiments demonstrate that, by\nexplicitly preserving the topological properties of target objects-such as\nconnectivity-the proposed algorithm achieves enhanced accuracy and robustness,\nparticularly in images with intricate structures or noise."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17420",
    "a_title":"Cross-modal Medical Image Generation Based on Pyramid Convolutional\n  Attention Network",
    "a_abstract":"The integration of multimodal medical imaging can provide complementary and\ncomprehensive information for the diagnosis of Alzheimer's disease (AD).\nHowever, in clinical practice, since positron emission tomography (PET) is\noften missing, multimodal images might be incomplete. To address this problem,\nwe propose a method that can efficiently utilize structural magnetic resonance\nimaging (sMRI) image information to generate high-quality PET images. Our\ngeneration model efficiently utilizes pyramid convolution combined with channel\nattention mechanism to extract multi-scale local features in sMRI, and injects\nglobal correlation information into these features using self-attention\nmechanism to ensure the restoration of the generated PET image on local texture\nand global structure. Additionally, we introduce additional loss functions to\nguide the generation model in producing higher-quality PET images. Through\nexperiments conducted on publicly available ADNI databases, the generated\nimages outperform previous research methods in various performance indicators\n(average absolute error: 0.0194, peak signal-to-noise ratio: 29.65, structural\nsimilarity: 0.9486) and are close to real images. In promoting AD diagnosis,\nthe generated images combined with their corresponding sMRI also showed\nexcellent performance in AD diagnosis tasks (classification accuracy: 94.21 %),\nand outperformed previous research methods of the same type. The experimental\nresults demonstrate that our method outperforms other competing methods in\nquantitative metrics, qualitative visualization, and evaluation criteria.",
    "explanation":"Our generation model efficiently utilizes pyramid convolution combined with channel attention mechanism to extract multi-scale local features in sMRI, and injects global correlation information into these features using self-attention mechanism to ensure the restoration of the generated PET image on local texture and global structure",
    "b_id":[
      "b3",
      "b17"
    ],
    "b_title":[
      "Deep learning-based classification of healthy aging controls, mild cognitive impairment and alzheimer's disease using fusion of mri-pet imaging",
      "Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks"
    ],
    "b_abstract":[
      "Automated detection of dementia stage using multimodal imaging modalities will be helpful for improving the clinical diagnosis. In this study, we develop the Inception-ResNet wrapper model in differentiating the healthy controls (HC), mild cognitive impairment (MCI), and Alzheimer\u2019s disease (AD) using conjoint magnetic resonance imaging (MRI) and positron emission tomography (PET) scans. We use T1-weighted MR and PET images of individuals aged between 42 and 95 years, including HC, MCI and AD patients. We first perform 3D tissue segmentation of MR images after skull striping. The atlas-based segmented MR image tissue is fused with PET image. Then we transform PET images from RGB to HSI color space and apply fusion of MRI with PET images using two-dimensional Fourier and discrete wavelet transform (DWT) and then reconstruct the MR-PET fused image using inverse Fourier and DWT methods. After the fusion of MRI and PET imaging modalities, we used 60 % training, 20 % for validation and the remaining 20 % as a test set using various convolutional neural networks. We found the proposed model as the best classifier with an accuracy of 95.5 %, 94.1 % and 95.9 % in classifying HC vs MCI, MCI vs AD and AD vs HC respectively when compared to the existing methods. We conclude that the proposed deep learning model has potential in automated classification of healthy and dementia stages using combined MRI and PET modalities with good performance.",
      "Image-to-image translation is a class of vision and graphics problems where the goal to learn mapping between an input image output using training set aligned pairs. However, for many tasks, paired data will not be available. We present approach learning translate from source domain X target Y in absence examples. Our G : \u2192 such that distribution images G(X) indistinguishable adversarial loss. Because this highly under-constrained, we couple it with inverse F introduce cycle consistency loss push F(G(X)) \u2248 (and vice versa). Qualitative results are presented on several tasks does exist, including collection style transfer, object transfiguration, season photo enhancement, etc. Quantitative comparisons against prior methods demonstrate superiority our approach."
    ],
    "b_categories":[
      "cs.CV",
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.09672"
    ],
    "c_title":[
      "Mechanoreceptive A$\\beta$ primary afferents discriminate naturalistic\n  social touch inputs at a functionally relevant time scale"
    ],
    "c_abstract":[
      "Interpersonal touch is an important channel of social emotional interaction.\nHow these physical skin-to-skin touch expressions are processed in the\nperipheral nervous system is not well understood. From microneurography\nrecordings in humans, we evaluated the capacity of six subtypes of cutaneous\nmechanoreceptive afferents to differentiate human-delivered social touch\nexpressions. Leveraging statistical and classification analyses, we found that\nsingle units of multiple mechanoreceptive A$\\beta$ subtypes, especially slowly\nadapting type II (SA-II) and fast adapting hair follicle afferents (HFA), can\nreliably differentiate social touch expressions at accuracies similar to human\nrecognition. We then identified the most informative firing patterns of SA-II\nand HFA afferents, which indicate that average durations of 3-4 s of firing\nprovide sufficient discriminative information. Those two subtypes also exhibit\nrobust tolerance to spike-timing shifts of up to 10-20 ms, varying with touch\nexpressions due to their specific firing properties. Greater shifts in\nspike-timing, however, can change a firing pattern's envelope to resemble that\nof another expression and drastically compromise an afferent's discrimination\ncapacity. Altogether, the findings indicate that SA-II and HFA afferents\ndifferentiate the skin contact of social touch at time scales relevant for such\ninteractions, which are 1-2 orders of magnitude longer than those for\nnon-social touch."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17420",
    "a_title":"Cross-modal Medical Image Generation Based on Pyramid Convolutional\n  Attention Network",
    "a_abstract":"The integration of multimodal medical imaging can provide complementary and\ncomprehensive information for the diagnosis of Alzheimer's disease (AD).\nHowever, in clinical practice, since positron emission tomography (PET) is\noften missing, multimodal images might be incomplete. To address this problem,\nwe propose a method that can efficiently utilize structural magnetic resonance\nimaging (sMRI) image information to generate high-quality PET images. Our\ngeneration model efficiently utilizes pyramid convolution combined with channel\nattention mechanism to extract multi-scale local features in sMRI, and injects\nglobal correlation information into these features using self-attention\nmechanism to ensure the restoration of the generated PET image on local texture\nand global structure. Additionally, we introduce additional loss functions to\nguide the generation model in producing higher-quality PET images. Through\nexperiments conducted on publicly available ADNI databases, the generated\nimages outperform previous research methods in various performance indicators\n(average absolute error: 0.0194, peak signal-to-noise ratio: 29.65, structural\nsimilarity: 0.9486) and are close to real images. In promoting AD diagnosis,\nthe generated images combined with their corresponding sMRI also showed\nexcellent performance in AD diagnosis tasks (classification accuracy: 94.21 %),\nand outperformed previous research methods of the same type. The experimental\nresults demonstrate that our method outperforms other competing methods in\nquantitative metrics, qualitative visualization, and evaluation criteria.",
    "explanation":"Our generation model efficiently utilizes pyramid convolution combined with channel attention mechanism to extract multi-scale local features in sMRI, and injects global correlation information into these features using self-attention mechanism to ensure the restoration of the generated PET image on local texture and global structure",
    "b_id":[
      "b19"
    ],
    "b_title":[
      "Bidirectional Mapping of Brain MRI and PET With 3D Reversible GAN for the Diagnosis of Alzheimer\u2019s Disease"
    ],
    "b_abstract":[
      "<jats:p>Combining multi-modality data for brain disease diagnosis such as Alzheimer\u2019s disease (AD) commonly leads to improved performance than those using a single modality. However, it is still challenging to train a multi-modality model since it is difficult in clinical practice to obtain complete data that includes all modality data. Generally speaking, it is difficult to obtain both magnetic resonance images (MRI) and positron emission tomography (PET) images of a single patient. PET is expensive and requires the injection of radioactive substances into the patient\u2019s body, while MR images are cheaper, safer, and more widely used in practice. Discarding samples without PET data is a common method in previous studies, but the reduction in the number of samples will result in a decrease in model performance. To take advantage of multi-modal complementary information, we first adopt the Reversible Generative Adversarial Network (RevGAN) model to reconstruct the missing data. After that, a 3D convolutional neural network (CNN) classification model with multi-modality input was proposed to perform AD diagnosis. We have evaluated our method on the Alzheimer\u2019s Disease Neuroimaging Initiative (ADNI) database, and compared the performance of the proposed method with those using state-of-the-art methods. The experimental results show that the structural and functional information of brain tissue can be mapped well and that the image synthesized by our method is close to the real image. In addition, the use of synthetic data is beneficial for the diagnosis and prediction of Alzheimer\u2019s disease, demonstrating the effectiveness of the proposed framework.<\/jats:p>"
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.12203"
    ],
    "c_title":[
      "Explainability for Vision Foundation Models: A Survey"
    ],
    "c_abstract":[
      "As artificial intelligence systems become increasingly integrated into daily\nlife, the field of explainability has gained significant attention. This trend\nis particularly driven by the complexity of modern AI models and their\ndecision-making processes. The advent of foundation models, characterized by\ntheir extensive generalization capabilities and emergent uses, has further\ncomplicated this landscape. Foundation models occupy an ambiguous position in\nthe explainability domain: their complexity makes them inherently challenging\nto interpret, yet they are increasingly leveraged as tools to construct\nexplainable models. In this survey, we explore the intersection of foundation\nmodels and eXplainable AI (XAI) in the vision domain. We begin by compiling a\ncomprehensive corpus of papers that bridge these fields. Next, we categorize\nthese works based on their architectural characteristics. We then discuss the\nchallenges faced by current research in integrating XAI within foundation\nmodels. Furthermore, we review common evaluation methodologies for these\ncombined approaches. Finally, we present key observations and insights from our\nsurvey, offering directions for future research in this rapidly evolving field."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.16425",
    "a_title":"Patherea: Cell Detection and Classification for the 2020s",
    "a_abstract":"This paper presents a Patherea, a framework for point-based cell detection\nand classification that provides a complete solution for developing and\nevaluating state-of-the-art approaches. We introduce a large-scale dataset\ncollected to directly replicate a clinical workflow for Ki-67 proliferation\nindex estimation and use it to develop an efficient point-based approach that\ndirectly predicts point-based predictions, without the need for intermediate\nrepresentations. The proposed approach effectively utilizes point proposal\ncandidates with the hybrid Hungarian matching strategy and a flexible\narchitecture that enables the usage of various backbones and (pre)training\nstrategies. We report state-of-the-art results on existing public datasets -\nLizard, BRCA-M2C, BCData, and the newly proposed Patherea dataset. We show that\nthe performance on existing public datasets is saturated and that the newly\nproposed Patherea dataset represents a significantly harder challenge for the\nrecently proposed approaches. We also demonstrate the effectiveness of recently\nproposed pathology foundational models that our proposed approach can natively\nutilize and benefit from. We also revisit the evaluation protocol that is used\nin the broader field of cell detection and classification and identify the\nerroneous calculation of performance metrics. Patherea provides a benchmarking\nutility that addresses the identified issues and enables a fair comparison of\ndifferent approaches. The dataset and the code will be publicly released upon\nacceptance.",
    "explanation":"This paper presents a Patherea, a framework for point-based cell detection and classification that provides a complete solution for developing and evaluating state-of-the-art approaches.",
    "b_id":[
      "b40"
    ],
    "b_title":[
      "Whole Slide Imaging Versus Microscopy for Primary Diagnosis in Surgical Pathology: A Multicenter Blinded Randomized Noninferiority Study of 1992 Cases (Pivotal Study)"
    ],
    "b_abstract":[
      "Most prior studies of primary diagnosis in surgical pathology using whole slide imaging (WSI) versus microscopy have focused on specific organ systems or included relatively few cases. The objective this study was to demonstrate that WSI is noninferior for pathology. A blinded randomized noninferiority conducted across the entire range cases (biopsies and resections, including hematoxylin eosin, immunohistochemistry, special stains) from 4 institutions original sign-out (baseline diagnosis) as reference standard. Cases were scanned, converted randomized. Sixteen pathologists interpreted by WSI, followed a wash-out period \u22654 weeks, after which read same observers other modality. Major discordances identified an adjudication panel, differences between major discordance rates both (against standard) calculated. total 1992 included, resulting 15,925 reads. rate with standard 4.9% 4.6% microscopy. difference 0.4% (95% confidence interval, -0.30% 1.01%). highest endocrine (1.8%), neoplastic kidney (1.5%), urinary bladder (1.3%), gynecologic (1.2%). Detailed analysis these revealed no instances where interpretation consistently inaccurate compared multiple observers. We conclude pathology, biopsies resections stained immunohistochemistry stains. This conclusion valid wide variety specimen types."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.10054"
    ],
    "c_title":[
      "Towards Polyp Counting In Full-Procedure Colonoscopy Videos"
    ],
    "c_abstract":[
      "Automated colonoscopy reporting holds great potential for enhancing quality\ncontrol and improving cost-effectiveness of colonoscopy procedures. A major\nchallenge lies in the automated identification, tracking, and re-association\n(ReID) of polyps tracklets across full-procedure colonoscopy videos. This is\nessential for precise polyp counting and enables automated computation of key\nquality metrics, such as Adenoma Detection Rate (ADR) and Polyps Per\nColonoscopy (PPC). However, polyp ReID is challenging due to variations in\npolyp appearance, frequent disappearance from the field of view, and\nocclusions. In this work, we leverage the REAL-Colon dataset, the first\nopen-access dataset providing full-procedure videos, to define tasks, data\nsplits and metrics for the problem of automatically count polyps in\nfull-procedure videos, establishing an open-access framework. We re-implement\npreviously proposed SimCLR-based methods for learning representations of polyp\ntracklets, both single-frame and multi-view, and adapt them to the polyp\ncounting task. We then propose an Affinity Propagation-based clustering method\nto further improve ReID based on these learned representations, ultimately\nenhancing polyp counting. Our approach achieves state-of-the-art performance,\nwith a polyp fragmentation rate of 6.30 and a false positive rate (FPR) below\n5% on the REAL-Colon dataset. We release code at\nhttps:\/\/github.com\/lparolari\/towards-polyp-counting."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.16425",
    "a_title":"Patherea: Cell Detection and Classification for the 2020s",
    "a_abstract":"This paper presents a Patherea, a framework for point-based cell detection\nand classification that provides a complete solution for developing and\nevaluating state-of-the-art approaches. We introduce a large-scale dataset\ncollected to directly replicate a clinical workflow for Ki-67 proliferation\nindex estimation and use it to develop an efficient point-based approach that\ndirectly predicts point-based predictions, without the need for intermediate\nrepresentations. The proposed approach effectively utilizes point proposal\ncandidates with the hybrid Hungarian matching strategy and a flexible\narchitecture that enables the usage of various backbones and (pre)training\nstrategies. We report state-of-the-art results on existing public datasets -\nLizard, BRCA-M2C, BCData, and the newly proposed Patherea dataset. We show that\nthe performance on existing public datasets is saturated and that the newly\nproposed Patherea dataset represents a significantly harder challenge for the\nrecently proposed approaches. We also demonstrate the effectiveness of recently\nproposed pathology foundational models that our proposed approach can natively\nutilize and benefit from. We also revisit the evaluation protocol that is used\nin the broader field of cell detection and classification and identify the\nerroneous calculation of performance metrics. Patherea provides a benchmarking\nutility that addresses the identified issues and enables a fair comparison of\ndifferent approaches. The dataset and the code will be publicly released upon\nacceptance.",
    "explanation":"This paper presents a Patherea, a framework for point-based cell detection and classification that provides a complete solution for developing and evaluating state-of-the-art approaches.",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    ],
    "b_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.17738"
    ],
    "c_title":[
      "Tumor-associated CD19$^+$ macrophages induce immunosuppressive\n  microenvironment in hepatocellular carcinoma"
    ],
    "c_abstract":[
      "Tumor-associated macrophages are a key component that contributes to the\nimmunosuppressive microenvironment in human cancers. However, therapeutic\ntargeting of macrophages has been a challenge in clinic due to the limited\nunderstanding of their heterogeneous subpopulations and distinct functions.\nHere, we identify a unique and clinically relevant CD19$^+$ subpopulation of\nmacrophages that is enriched in many types of cancer, particularly in\nhepatocellular carcinoma (HCC). The CD19$^+$ macrophages exhibit increased\nlevels of PD-L1 and CD73, enhanced mitochondrial oxidation, and compromised\nphagocytosis, indicating their immunosuppressive functions. Targeting CD19$^+$\nmacrophages with anti-CD19 chimeric antigen receptor T (CAR-T) cells inhibited\nHCC tumor growth. We identify PAX5 as a primary driver of up-regulated\nmitochondrial biogenesis in CD19$^+$ macrophages, which depletes cytoplasmic\nCa$^{2+}$, leading to lysosomal deficiency and consequent accumulation of CD73\nand PD-L1. Inhibiting CD73 or mitochondrial oxidation enhanced the efficacy of\nimmune checkpoint blockade therapy in treating HCC, suggesting great promise\nfor CD19$^+$ macrophage-targeting therapeutics."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  }
]