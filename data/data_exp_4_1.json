[
  {
    "id":"2411.01019",
    "a_title":"A lightweight Convolutional Neural Network based on U shape structure\n  and Attention Mechanism for Anterior Mediastinum Segmentation",
    "a_abstract":"To automatically detect Anterior Mediastinum Lesions (AMLs) in the Anterior\nMediastinum (AM), the primary requirement will be an automatic segmentation\nmodel specifically designed for the AM. The prevalence of AML is extremely low,\nmaking it challenging to conduct screening research similar to lung cancer\nscreening. Retrospectively reviewing chest CT scans over a specific period to\ninvestigate the prevalence of AML requires substantial time. Therefore,\ndeveloping an Artificial Intelligence (AI) model to find location of AM helps\nradiologist to enhance their ability to manage workloads and improve diagnostic\naccuracy for AMLs. In this paper, we introduce a U-shaped structure network to\nsegment AM. Two attention mechanisms were used for maintaining long-range\ndependencies and localization. In order to have the potential of Multi-Head\nSelf-Attention (MHSA) and a lightweight network, we designed a parallel MHSA\nnamed Wide-MHSA (W-MHSA). Maintaining long-range dependencies is crucial for\nsegmentation when we upsample feature maps. Therefore, we designed a Dilated\nDepth-Wise Parallel Path connection (DDWPP) for this purpose. In order to\ndesign a lightweight architecture, we introduced an expanding convolution block\nand combine it with the proposed W-MHSA for feature extraction in the encoder\npart of the proposed U-shaped network. The proposed network was trained on 2775\nAM cases, which obtained an average Dice Similarity Coefficient (DSC) of\n87.83%, mean Intersection over Union (IoU) of 79.16%, and Sensitivity of\n89.60%. Our proposed architecture exhibited superior segmentation performance\ncompared to the most advanced segmentation networks, such as Trans Unet,\nAttention Unet, Res Unet, and Res Unet++.",
    "explanation":"It's leveraging AI in another diffrent domain, namely medical science, to detect Anterior Mediastinum Lesions.",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Anterior mediastinal nodular lesion segmentation from chest computed tomography imaging using UNet based neural network with attention mechanisms"
    ],
    "b_abstract":[
      "Automated detection of anterior mediastinal nodular lesions (AMLs) has significance for clinical usage as it is challenging for radiologists to accurately identify AMLs from chest computed tomography (CT) imaging due to various factors, including poor resolution, variations in intensity and the similarity of the AMLs to other tissues. To assist radiologists in AML detection from chest CT imaging, a UNet-based computer-aided detection (CADe) system is proposed to segment AMLs from slice images of the chest CT scans. The proposed network adopts a modified UNet architecture. To guide the proposed network to selectively focus on AMLs and potentially disregard others in the image, different attention mechanisms are utilized in the proposed network, including the self-attention mechanism and the convolutional block attention module (CBAM). The proposed network was trained and evaluated on 180 chest CT scans which consist of 180 AMLs. 90 AMLs were identified as thymic cysts, and 90 AMLs were diagnosed as thymoma. The proposed network achieved an average dice similarity coefficient (DSC) of 93.23 with 5-fold cross-validation, for which the mean Intersection over Union (IoU), sensitivity and specificity were 90.29, 93.98 and 95.68 respectively. Our method demonstrated an improved segmentation performance over state-of-the-art segmentation networks, including UNet, ResUNet, TransUNet and UNet++. The proposed network employing attention mechanisms exhibited a promising result for segmenting AMLs from chest CT imaging and could be used to automate the AML detection process for achieving improved diagnostic reliability."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b6",
      "b1"
    ],
    "c_title":[
      "Screening for lung cancer: 2023 guideline update from the American Cancer Society",
      "Incidental Anterior Mediastinal Nodular Lesions on\u00a0Chest CT in Asymptomatic Subjects"
    ],
    "c_abstract":[
      "Abstract Lung cancer is the leading cause of mortality and person\u2010years life lost from among US men women. Early detection has been shown to be associated with reduced lung mortality. Our objective was update American Cancer Society (ACS) 2013 screening (LCS) guideline for adults at high risk cancer. The intended provide guidance health care providers their patients who are due a history smoking. ACS Guideline Development Group (GDG) utilized systematic review LCS literature commissioned Preventive Services Task Force 2021 recommendation update; second years since quitting smoking (YSQ); published 2021; two Intervention Surveillance Modeling Network\u2010validated models assess benefits harms screening; an epidemiologic modeling analysis examining effect YSQ aging on risk; updated benefit\u2010to\u2010radiation\u2010risk ratios follow\u2010up examinations. GDG also examined disease burden data National Institute\u2019s Surveillance, Epidemiology, End Results program. Formulation recommendations based quality evidence judgment (incorporating values preferences) about balance harms. judged that overall moderate sufficient support strong individuals meet eligibility criteria. in women aged 50\u201380 reduction deaths across range study designs, inferential supports older than 80 good health. recommends annual low\u2010dose computed tomography asymptomatic currently smoke or formerly smoked have \u226520 pack\u2010year ( , ). Before decision made initiate LCS, should engage shared decision\u2010making discussion qualified professional. For smoked, number not criterion begin stop screening. Individuals receive counseling quit connected cessation resources. comorbid conditions substantially limit expectancy screened. These considered by discussions LCS. If fully implemented, these likelihood significantly reducing death suffering United States.",
      "Objective: The aim of this study was to investigate the prevalence and characteristics of nodular lesions in the anterior mediastinum that had been found incidentally on screening chest computed tomography (CT) in asymptomatic subjects. Methods: We included 56,358 consecutive participants (mean age 52.4 \u00b1 10.5 years; male-female ratio 35,306:21,052) who underwent a baseline low-dose chest CT scan as part of a health checkup from 2006 through 2013. After the presence of anterior mediastinal nodular lesion had been confirmed, their CT findings, confirmatory diagnosis, and interval CT scan were reviewed. The standardized prevalence ratio for thymic epithelial tumor was calculated on the basis of the Republic of Korea cancer statistics for 2014. Results: Of the 56,358 participants, 413 (0.73%) had lesions (95% confidence interval: 0.66-0.80%); the prevalence increased with age (p <0.001) and a history of malignancy (p = 0.005). Of the lesions, 85.2% were smaller than 2 cm, 61.3% were round, and 80.2% had CT attenuation higher than 20 Hounsfield units. Among 51 proven cases, 39 lesions (76.9%) were benign and 12 (23.1%) were malignant. The standardized prevalence ratio for thymic epithelial tumor was 2.04 (95% confidence interval: 1.01-3.42). Of 11 resected thymic epithelial tumors, five were carcinomas, 10 were stage I or II, and all were completely resected without recurrence. Of the 237 unconfirmed cases with a follow-up CT scan, 82.2% were stable, 8.9% had increased, and the other 8.9% had decreased. Conclusions: The prevalence of incidental nodular lesion was 0.73%. Most lesions had CT features that were indistinguishable from thymic epithelial tumors, but a considerable portion of the lesions were suspected to be benign. Incidental thymic epithelial tumors were more prevalent than clinically detected tumors, were early-stage cancer, and showed favorable outcomes."
    ],
    "c_categories":[
      "q-bio.TO",
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.11084",
    "a_title":"BarcodeMamba: State Space Models for Biodiversity Analysis",
    "a_abstract":"DNA barcodes are crucial in biodiversity analysis for building automatic\nidentification systems that recognize known species and discover unseen\nspecies. Unlike human genome modeling, barcode-based invertebrate\nidentification poses challenges in the vast diversity of species and taxonomic\ncomplexity. Among Transformer-based foundation models, BarcodeBERT excelled in\nspecies-level identification of invertebrates, highlighting the effectiveness\nof self-supervised pretraining on barcode-specific datasets. Recently,\nstructured state space models (SSMs) have emerged, with a time complexity that\nscales sub-quadratically with the context length. SSMs provide an efficient\nparameterization of sequence modeling relative to attention-based\narchitectures. Given the success of Mamba and Mamba-2 in natural language, we\ndesigned BarcodeMamba, a performant and efficient foundation model for DNA\nbarcodes in biodiversity analysis. We conducted a comprehensive ablation study\non the impacts of self-supervised training and tokenization methods, and\ncompared both versions of Mamba layers in terms of expressiveness and their\ncapacity to identify \"unseen\" species held back from training. Our study shows\nthat BarcodeMamba has better performance than BarcodeBERT even when using only\n8.3% as many parameters, and improves accuracy to 99.2% on species-level\naccuracy in linear probing without fine-tuning for \"seen\" species. In our\nscaling study, BarcodeMamba with 63.6% of BarcodeBERT's parameters achieved\n70.2% genus-level accuracy in 1-nearest neighbor (1-NN) probing for unseen\nspecies. The code repository to reproduce our experiments is available at\nhttps:\/\/github.com\/bioscan-ml\/BarcodeMamba.",
    "explanation":"The paper talks about the use of BarcodeMamba for better scores in DNA barcode analysis of genomes.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Biological identifications through DNA barcodes"
    ],
    "b_abstract":[
      "Although much biological research depends upon species diagnoses, taxonomic expertise is collapsing.We are convinced that the sole prospect for a sustainable identification capability lies in construction of systems employ DNA sequences as taxon 'barcodes'.We establish mitochondrial gene cytochrome c oxidase I (COI) can serve core global bioidentification system animals.First, we demonstrate COI profiles, derived from low-density sampling higher categories, ordinarily assign newly analysed taxa to appropriate phylum or order.Second, species-level assignments be obtained by creating comprehensive profiles.A model profile, based analysis single individual each 200 closely allied lepidopterans, was 100% successful correctly identifying subsequent specimens.When fully developed, will provide reliable, cost-effective and accessible solution current problem identification.Its assembly also generate important new insights into diversification life rules molecular evolution."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "BarcodeBERT: Transformers for Biodiversity Analysis"
    ],
    "c_abstract":[
      "Understanding biodiversity is a global challenge, in which DNA barcodes - short snippets of that cluster by species play pivotal role. In particular, invertebrates, highly diverse and under-explored group, pose unique taxonomic complexities. We explore machine learning approaches, comparing supervised CNNs, fine-tuned foundation models, barcode-specific masking strategy across datasets varying complexity. While simpler tasks favor CNNs or transformers, challenging species-level identification demands paradigm shift towards self-supervised pretraining. propose BarcodeBERT, the first method for general analysis, leveraging 1.5 M invertebrate barcode reference library. This work highlights how dataset specifics coverage impact model selection, underscores role pretraining achieving high-accuracy barcode-based at genus level. Indeed, without fine-tuning step, BarcodeBERT pretrained on large outperforms DNABERT DNABERT-2 multiple downstream classification tasks. The code repository available https:\/\/github.com\/Kari-Genomics-Lab\/BarcodeBERT"
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00609",
    "a_title":"Tumor Location-weighted MRI-Report Contrastive Learning: A Framework for\n  Improving the Explainability of Pediatric Brain Tumor Diagnosis",
    "a_abstract":"Despite the promising performance of convolutional neural networks (CNNs) in\nbrain tumor diagnosis from magnetic resonance imaging (MRI), their integration\ninto the clinical workflow has been limited. That is mainly due to the fact\nthat the features contributing to a model's prediction are unclear to\nradiologists and hence, clinically irrelevant, i.e., lack of explainability. As\nthe invaluable sources of radiologists' knowledge and expertise, radiology\nreports can be integrated with MRI in a contrastive learning (CL) framework,\nenabling learning from image-report associations, to improve CNN\nexplainability. In this work, we train a multimodal CL architecture on 3D brain\nMRI scans and radiology reports to learn informative MRI representations.\nFurthermore, we integrate tumor location, salient to several brain tumor\nanalysis tasks, into this framework to improve its generalizability. We then\napply the learnt image representations to improve explainability and\nperformance of genetic marker classification of pediatric Low-grade Glioma, the\nmost prevalent brain tumor in children, as a downstream task. Our results\nindicate a Dice score of 31.1% between the model's attention maps and manual\ntumor segmentation (as an explainability measure) with test classification\nperformance of 87.7%, significantly outperforming the baselines. These\nenhancements can build trust in our model among radiologists, facilitating its\nintegration into clinical practices for more efficient tumor diagnosis.",
    "explanation":"The article presents a research involving the use of Computer Science methods to treat problems in Medicine. In this case, applying the use of Convolutional Neural Networks (CNN) for the recognition of pediatric tumors in medical images and Contrastive Learning (CL) to improve the explainability of the model.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Pediatric low-grade glioma: State-of-the-art and ongoing challenges"
    ],
    "b_abstract":[
      "Abstract The most common childhood central nervous system (CNS) tumor is pediatric low-grade glioma (pLGG), representing 30%\u201340% of all CNS tumors in children. Although there high associated morbidity, tumor-related mortality relatively rare. pLGG now conceptualized as a chronic disease, underscoring the importance functional outcomes and quality-of-life measures. A wealth data has emerged about these tumors, including better understanding their natural history molecular drivers, paving way for use targeted inhibitors. While treatments have heralded tremendous promise, challenges remain how to best optimize use, long-term toxicities with inhibitors unknown. International Pediatric Low-Grade Glioma Coalition (iPLGGc) global group physicians scientists expertise focused on addressing key issues. Here, iPLGGc provides an overview current state-of-the-art pLGG, epidemiology, histology, landscape, treatment paradigms, survival outcomes, imaging response, ongoing challenges. This paper also serves introduction 3 other manuscripts (1) preclinical models, (2) consensus framework conducting early-phase clinical trials (3) resistance, rebound, recurrence."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Improving Pediatric Low-Grade Neuroepithelial Tumors Molecular Subtype\n  Identification Using a Novel AUROC Loss Function for Convolutional Neural\n  Networks"
    ],
    "c_abstract":[
      "Pediatric Low-Grade Neuroepithelial Tumors (PLGNT) are the most common pediatric cancer type, accounting for 40% of brain tumors in children, and identifying PLGNT molecular subtype is crucial treatment planning. However, gold standard to determine biopsy, which can be impractical or dangerous patients. This research improves performance Convolutional Neural Networks (CNNs) classifying subtypes through MRI scans by introducing a loss function that specifically model's Area Under Receiver Operating Characteristic (ROC) Curve (AUROC), offering non-invasive diagnostic alternative. In this study, retrospective dataset 339 children with (143 BRAF fusion, 71 V600E mutation, 125 non-BRAF) was curated. We employed CNN model Monte Carlo random data splitting. The baseline trained using binary cross entropy (BCE), achieved an AUROC 86.11% differentiating fusion mutations, improved 87.71% our proposed (p-value 0.045). With multiclass classification, from 74.42% 76. 59% 0.0016)."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00726",
    "a_title":"Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading\n  with Cataract",
    "a_abstract":"Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a\ncommon complication of diabetes. As two different imaging tools for DR grading,\ncolor fundus photography (CFP) and infrared fundus photography (IFP) are\nhighly-correlated and complementary in clinical applications. To the best of\nour knowledge, this is the first study that explores a novel multi-modal deep\nlearning framework to fuse the information from CFP and IFP towards more\naccurate DR grading. Specifically, we construct a dual-stream architecture\nCross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus\nimage modalities. In particular, a meticulously engineered Cross-Fundus\nAttention (CFA) module is introduced to capture the correspondence between CFP\nand IFP images. Moreover, we adopt both the single-modality and multi-modality\nsupervisions to maximize the overall performance for DR grading. Extensive\nexperiments on a clinical dataset consisting of 1,713 pairs of multi-modal\nfundus images demonstrate the superiority of our proposed method. Our code will\nbe released for public access.",
    "explanation":"The work combines transformers with two distinct methods that evaluate the quality of retinopathy",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Relation Between Retinal Vasculature and Retinal Thickness in Macular Edema"
    ],
    "b_abstract":[
      "This study has investigated the relationship of retinal vasculature and thickness for Macular Edema (ME) subjects. Ninety sets Fluorescein Angiograph (FA) Optical Coherence Tomography (OCT) 54 participants were analyzed. Multivariate analysis using binary logistic regression model was used to association between vessel parameters thickness. The results reveal feature i.e. fractal dimension (FD) as most sensitive parameter changes in associated with ME. Thus, indicating a direct which is caused due neovascular causing exudates, leakages hemorrhages, applications alternate modality detection"
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    ],
    "c_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05236",
    "a_title":"Designing a Light-based Communication System with a Biomolecular\n  Receiver",
    "a_abstract":"Biological systems transduce signals from their surroundings in numerous\nways. This paper introduces a communication system using the light-gated ion\nchannel Channelrhodopsin-2 (ChR2), which causes an ion current to flow in\nresponse to light. Our design includes a ChR2-based receiver along with\nencoding, modulation techniques and detection. Analyzing the resulting\ncommunication system, we discuss the effect of different parameters on the\nperformance of the system. Finally, we discuss its potential design in the\ncontext of bio-engineering and light-based communication and show that the data\nrate scales up with the number of receptors, indicating that high-speed\ncommunication may be possible.",
    "explanation":"The paper is interdisciplinary because it aims to use channelrhodopsin-2 (ChR2), a biomolecule, as a receiver to design a light-based communication system, which is a work related to engineering.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Channelrhodopsin-2, a directly light-gated cation-selective membrane channel"
    ],
    "b_abstract":[
      "Microbial-type rhodopsins are found in archaea, prokaryotes, and eukaryotes. Some of them represent membrane ion transport proteins such as bacteriorhodopsin, a light-driven proton pump, or channelrhodopsin-1 (ChR1), recently identified light-gated channel from the green alga Chlamydomonas reinhardtii . ChR1 ChR2, related microbial-type rhodopsin C. , were shown to be involved generation photocurrents this alga. We demonstrate by functional expression, both oocytes Xenopus laevis mammalian cells, that ChR2 is directly light-switched cation-selective channel. This opens rapidly after absorption photon generate large permeability for monovalent divalent cations. desensitizes continuous light smaller steady-state conductance. Recovery desensitization accelerated extracellular H + negative potential, whereas closing decelerated intracellular expressed mainly under low-light conditions, suggesting involvement photoreception dark-adapted cells. The predicted seven-transmembrane \u03b1 helices characteristic G protein-coupled receptors but reflect different motif Finally, we may used depolarize small simply illumination."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2",
      "b0"
    ],
    "c_title":[
      "Shannon capacity of signal transduction for multiple independent receptors",
      "DESIGN AND IMPLEMENTATION OF VISIBLE LIGHT COMMUNICATION SYSTEM IN INDOOR ENVIRONMENT"
    ],
    "c_abstract":[
      "Cyclic adenosine monophosphate (cAMP) is considered a model system for signal transduction, the mechanism by which cells exchange chemical messages. Our previous work calculated Shannon capacity of single cAMP receptor; however, typical cell may have thousands receptors operating in parallel. In this paper, we calculate transduction with an arbitrary number independent, indistinguishable receptors. By leveraging prior results on feedback receptor, show (somewhat unexpectedly) that achieved IID input distribution, and n times receptor.",
      "Visible Light communication (VLC) using White Light Emitting Diode (LED) is a promising technology for next generation communication for short range, high speed wireless data transmission. In this paper inexpensive transmitter and receiver of VLC system is designed and its performance is evaluated. The effect of natural and artificial ambient light noise sources is also considered. Experimental results show that the data transmission distance achieved upto 0.45m.Performance analysis is done with respect to optical power, photo sensitivity of photodiode at the receiver and the increase in distance between the transmitter and receiver."
    ],
    "c_categories":[
      "eess.SP",
      "cs.SY"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.02815",
    "a_title":"Artificial Intelligence-Enhanced Couinaud Segmentation for Precision\n  Liver Cancer Therapy",
    "a_abstract":"Precision therapy for liver cancer necessitates accurately delineating liver\nsub-regions to protect healthy tissue while targeting tumors, which is\nessential for reducing recurrence and improving survival rates. However, the\nsegmentation of hepatic segments, known as Couinaud segmentation, is\nchallenging due to indistinct sub-region boundaries and the need for extensive\nannotated datasets. This study introduces LiverFormer, a novel Couinaud\nsegmentation model that effectively integrates global context with low-level\nlocal features based on a 3D hybrid CNN-Transformer architecture. Additionally,\na registration-based data augmentation strategy is equipped to enhance the\nsegmentation performance with limited labeled data. Evaluated on CT images from\n123 patients, LiverFormer demonstrated high accuracy and strong concordance\nwith expert annotations across various metrics, allowing for enhanced treatment\nplanning for surgery and radiation therapy. It has great potential to reduces\ncomplications and minimizes potential damages to surrounding tissue, leading to\nimproved outcomes for patients undergoing complex liver cancer treatments.",
    "explanation":"The paper presents a tool that uses Convolutional Neural Networks (CNN) and Transformers, technologies from Computer Science, to improve the accuracy and efficiency of Couinaud segmentation in liver cancer treatment, a challenge in the field of Medicine.",
    "b_id":[
      "b36",
      "b33"
    ],
    "b_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "Automated segmentation of liver segment on portal venous phase MR images using a 3D convolutional neural network"
    ],
    "b_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train.",
      "We aim to develop and validate a three-dimensional convolutional neural network (3D-CNN) model for automatic liver segment segmentation on MRI images.This retrospective study evaluated an automated method using deep that was trained, validated, tested with 367, 157, 158 portal venous phase MR images, respectively. The Dice similarity coefficient (DSC), mean surface distance (MSD), Hausdorff (HD), volume ratio (RV) were used quantitatively measure the accuracy of segmentation. time consumed manual also compared. In addition, applied 100 consecutive cases from real clinical scenario qualitative evaluation indirect evaluation.In quantitative evaluation, achieved high DSC, MSD, HD RV (0.920, 3.34, 3.61 1.01, respectively). Compared segmentation, reduced 26 min 8 s. quality rated as good in 79% cases, moderate 15% poor 6%. 93.4% (99\/106) lesions could be assigned correct by only referring results segmentation.The proposed may serve effective tool anatomical region annotation images."
    ],
    "b_categories":[
      "cs.CV",
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Liver Anatomy: Portal (and Suprahepatic) or Biliary Segmentation"
    ],
    "c_abstract":[
      "In liver anatomy and surgery, is portal hepatic vein segmentation (French segmentation) to be preferred over arteriobiliary (Healey Schroy, North American segmentation)?Several embryological arguments an analysis of anatomical data from a personal collection 110 vasculobiliary casts were made.Embryological arguments: Portal branching appears first, secondly follows the distribution. Segment II (the left lateral sector) development right lobe. The umbilical enters portion middle lobe, forming segment IV on III left: this paramedian sector. So fissure (between lobes) transversally crosses classical which not unit. VI late secondary prominence VII, reaching anterior margin only in man. Anatomical must added segmentation; academic lobe sector, separates lobes. preferred: duplication branches first order occurs 23.5% cases, while first-order noted 50% livers, being much simpler.Portal seems more accurate."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00561",
    "a_title":"Automated Classification of Cell Shapes: A Comparative Evaluation of\n  Shape Descriptors",
    "a_abstract":"This study addresses the challenge of classifying cell shapes from noisy\ncontours, such as those obtained through cell instance segmentation of\nhistological images. We assess the performance of various features for shape\nclassification, including Elliptical Fourier Descriptors, curvature features,\nand lower dimensional representations. Using an annotated synthetic dataset of\nnoisy contours, we identify the most suitable shape descriptors and apply them\nto a set of real images for qualitative analysis. Our aim is to provide a\ncomprehensive evaluation of descriptors for classifying cell shapes, which can\nsupport cell type identification and tissue characterization-critical tasks in\nboth biological research and histopathological assessments.",
    "explanation":"This study addresses the challenge of classifying cell shapes from noisy contours, such as those obtained through cell instance segmentation of histological images.\n\nOur aim is to provide a comprehensive evaluation of descriptors for classifying cell shapes, which can support cell type identification and tissue characterization\u2014critical tasks in both biological research and histopathological assessments.\n",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "Retrieval and classification of shape-based objects using Fourier, generic Fourier, and wavelet-Fourier descriptors technique: A comparative study"
    ],
    "b_abstract":[
      "In this paper, we report retrieval and classification of shape-based objects employing three techniques-conventional Fourier descriptors (FD), generic Fourier descriptors (GFD) and wavelet-Fourier descriptors (WFD) techniques. All the three techniques have been applied to a database of seven different types of shapes. The centroid distance based shape signatures have been used for the derivation of descriptors. The Euclidean distance has been calculated as a similarity measure parameter for shape classification. For WFD technique, a Mexican-hat wavelet function was used. Classification results from all the three techniques were compared and it was observed that WFD performs better than FD and GFD technique. To study the effect of the noise on the retrieval and classification of shapes of different objects, additive and multiplicative noise of various variances were applied to the database. Precision and recall were also measured as parameters of performance metric."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "What is a cell type, really? The quest to categorize life's myriad forms."
    ],
    "c_abstract":[
      "The problem of cell type became clear to genome biologist Jason Buenrostro in 2013. He was studying a cell line derived from someone with cancer, trying to map out how the DNA was arranged in the nucleus. The cells should have been pretty much identical, he thought. But the more Buenrostro looked at the DNA, the more differences he found in how it was packaged1. \u201cI realized that there were probably hundreds of flavours,\u201d recalls Buenrostro, who was a graduate student at Stanford University in California at the time."
    ],
    "c_categories":[
      "q-bio.BM"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01144",
    "a_title":"LEARNER: Learning Granular Labels from Coarse Labels using Contrastive\n  Learning",
    "a_abstract":"A crucial question in active patient care is determining if a treatment is\nhaving the desired effect, especially when changes are subtle over short\nperiods. We propose using inter-patient data to train models that can learn to\ndetect these fine-grained changes within a single patient. Specifically, can a\nmodel trained on multi-patient scans predict subtle changes in an individual\npatient's scans? Recent years have seen increasing use of deep learning (DL) in\npredicting diseases using biomedical imaging, such as predicting COVID-19\nseverity using lung ultrasound (LUS) data. While extensive literature exists on\nsuccessful applications of DL systems when well-annotated large-scale datasets\nare available, it is quite difficult to collect a large corpus of personalized\ndatasets for an individual. In this work, we investigate the ability of recent\ncomputer vision models to learn fine-grained differences while being trained on\ndata showing larger differences. We evaluate on an in-house LUS dataset and a\npublic ADNI brain MRI dataset. We find that models pre-trained on clips from\nmultiple patients can better predict fine-grained differences in scans from a\nsingle patient by employing contrastive learning.",
    "explanation":"Recent years have seen increasing use of deep learning\n(DL) in predicting diseases using biomedical imaging, such as\npredicting COVID-19 severity using lung ultrasound (LUS)\ndata.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Investigating training-test data splitting strategies for automated segmentation and scoring of COVID-19 lung ultrasound images."
    ],
    "b_abstract":[
      "Ultrasound in point-of-care lung assessment is becoming increasingly relevant. This is further reinforced in the context of the COVID-19 pandemic, where rapid decisions on the lung state must be made for staging and monitoring purposes. The lung structural changes due to severe COVID-19 modify the way ultrasound propagates in the parenchyma. This is reflected by changes in the appearance of the lung ultrasound images. In abnormal lungs, vertical artifacts known as B-lines appear and can evolve into white lung patterns in the more severe cases. Currently, these artifacts are assessed by trained physicians, and the diagnosis is qualitative and operator dependent. In this article, an automatic segmentation method using a convolutional neural network is proposed to automatically stage the progression of the disease. 1863 B-mode images from 203 videos obtained from 14 asymptomatic individual,14 confirmed COVID-19 cases, and 4 suspected COVID-19 cases were used. Signs of lung damage, such as the presence and extent of B-lines and white lung areas, are manually segmented and scored from zero to three (most severe). These manually scored images are considered as ground truth. Different test-training strategies are evaluated in this study. The results shed light on the efficient approaches and common challenges associated with automatic segmentation methods."
    ],
    "b_categories":[
      "Lung Ultrasound"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "A Simple Framework for Contrastive Learning of Visual Representations"
    ],
    "c_abstract":[
      "This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed self-supervised algorithms without requiring specialized architectures or memory bank. In order to understand what enables the prediction tasks learn useful representations, we systematically study major components our framework. show that (1) composition data augmentations plays critical role in defining effective predictive tasks, (2) introducing learnable nonlinear transformation between representation and loss substantially improves quality learned (3) benefits from larger batch sizes more training steps compared supervised learning. By combining these findings, are able considerably outperform previous methods semi-supervised on ImageNet. A linear classifier trained representations by SimCLR achieves 76.5% top-1 accuracy, which is 7% relative improvement over state-of-the-art, matching performance ResNet-50. When fine-tuned only 1% labels, achieve 85.8% top-5 outperforming AlexNet with 100X fewer labels."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00922",
    "a_title":"Lung tumor segmentation in MRI mice scans using 3D nnU-Net with minimum\n  annotations",
    "a_abstract":"In drug discovery, accurate lung tumor segmentation is an important step for\nassessing tumor size and its progression using \\textit{in-vivo} imaging such as\nMRI. While deep learning models have been developed to automate this process,\nthe focus has predominantly been on human subjects, neglecting the pivotal role\nof animal models in pre-clinical drug development. In this work, we focus on\noptimizing lung tumor segmentation in mice. First, we demonstrate that the\nnnU-Net model outperforms the U-Net, U-Net3+, and DeepMeta models. Most\nimportantly, we achieve better results with nnU-Net 3D models than 2D models,\nindicating the importance of spatial context for segmentation tasks in MRI mice\nscans. This study demonstrates the importance of 3D input over 2D input images\nfor lung tumor segmentation in MRI scans. Finally, we outperform the prior\nstate-of-the-art approach that involves the combined segmentation of lungs and\ntumors within the lungs. Our work achieves comparable results using only lung\ntumor annotations requiring fewer annotations, saving time and annotation\nefforts. This work\n(https:\/\/anonymous.4open.science\/r\/lung-tumour-mice-mri-64BB) is an important\nstep in automating pre-clinical animal studies to quantify the efficacy of\nexperimental drugs, particularly in assessing tumor changes.",
    "explanation":"In this work, we focus on optimizing lung tumor segmen-\ntation in mice. First, we demonstrate that the nnU-Net model outper-\nforms the U-Net, U-Net3+, and DeepMeta models.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Deep learning model for automatic segmentation of lungs and pulmonary metastasis in small animal MR images"
    ],
    "b_abstract":[
      "Lungs are the most frequent site of metastases growth. The amount and size pulmonary acquired from MRI imaging data important criteria to assess efficacy new drugs in preclinical models. While efficient solutions both for MR downstream automatic segmentation have been proposed human patients, lung animal models remains challenging due physiological motion (respiratory cardiac movements), low protons this organ particular challenge precise metastases. As a consequence post-mortem analysis is currently required obtain information on metastatic volume. In work, we developed complete methodological pipeline automated lungs mice, consisting an sequence image acquisition deep learning method On one hand, optimized mouse with high contrast detection sensitivity. other hand DeepMeta, multiclass U-Net 3+ model automatically segment images. To if able provide accurate metastases, longitudinally imaged mice fast- slow-growing metastasis. Fifty-five balb\/c were injected two different derivatives renal carcinoma cells. Mice SG-bSSFP (self-gated balanced steady state free precession) at time points after injection cancer Both segmentations manually performed by experts. DeepMeta was trained perform based resulting ground truth annotations. Volumes as well number per measured separate test dataset Thanks SG method, 3D bSSFP images artifact-free, enabling serial follow-up Moreover, accurately soon they reached volume \u223c0.02mm3 . Thus distinguish groups terms slow versus fast patterns growth We shown that our methodology combining learning, enables processing whole thus viable alternative histology alone."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b12"
    ],
    "c_title":[
      "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "c_abstract":[
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.02695",
    "a_title":"An ADHD Diagnostic Interface Based on EEG Spectrograms and Deep Learning\n  Techniques",
    "a_abstract":"This paper introduces an innovative approach to\nAttention-deficit\/hyperactivity disorder (ADHD) diagnosis by employing deep\nlearning (DL) techniques on electroencephalography (EEG) signals. This method\naddresses the limitations of current behavior-based diagnostic methods, which\noften lead to misdiagnosis and gender bias. By utilizing a publicly available\nEEG dataset and converting the signals into spectrograms, a Resnet-18\nconvolutional neural network (CNN) architecture was used to extract features\nfor ADHD classification. The model achieved a high precision, recall, and an\noverall F1 score of 0.9. Feature extraction highlighted significant brain\nregions (frontopolar, parietal, and occipital lobes) associated with ADHD.\nThese insights guided the creation of a three-part digital diagnostic system,\nfacilitating cost-effective and accessible ADHD screening, especially in school\nenvironments. This system enables earlier and more accurate identification of\nstudents at risk for ADHD, providing timely support to enhance their\ndevelopmental outcomes. This study showcases the potential of integrating EEG\nanalysis with DL to enhance ADHD diagnostics, presenting a viable alternative\nto traditional methods.",
    "explanation":"his paper introduces an innovative approach to\nAttention-deficit\/hyperactivity disorder (ADHD) diagnosis by em-\nploying deep learning (DL) techniques on electroencephalography\n(EEG) signals.  By utilizing a publicly available EEG\ndataset and converting the signals into spectrograms, a Resnet-18\nconvolutional neural network (CNN) architecture was used to ex-\ntract features for ADHD classification. ",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "EEG data for ADHD \/ Control children"
    ],
    "b_abstract":[
      "Participants were 61 children with ADHD and 60 healthy controls (boys and girls, ages 7-12). The ADHD children were diagnosed by an experienced psychiatrist to DSM-IV criteria, and have taken Ritalin for up to 6 months. None of the children in the control group had a history of psychiatric disorders, epilepsy, or any report of high-risk behaviors. EEG recording was performed based on 10-20 standard by 19 channels (Fz, Cz, Pz, C3, T3, C4, T4, Fp1, Fp2, F3, F4, F7, F8, P3, P4, T5, T6, O1, O2) at 128 Hz sampling frequency. The A1 and A2 electrodes were the references located on earlobes. Since one of the deficits in ADHD children is visual attention, the EEG recording protocol was based on visual attention tasks. In the task, a set of pictures of cartoon characters was shown to the children and they were asked to count the characters. The number of characters in each image was randomly selected between 5 and 16, and the size of the pictures was large enough to be easily visible and countable by children. To have a continuous stimulus during the signal recording, each image was displayed immediately and uninterrupted after the child\u2019s response. Thus, the duration of EEG recording throughout this cognitive visual task was dependent on the child\u2019s performance (i.e. response speed)."
    ],
    "b_categories":[
      "Neurotherapeutics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Deep Residual Learning for Image Recognition"
    ],
    "c_abstract":[
      "Deeper neural networks are more difficult to train. We present a residual learning framework ease the training of that substantially deeper than those used previously. explicitly reformulate layers as functions with reference layer inputs, instead unreferenced functions. provide comprehensive empirical evidence showing these easier optimize, and can gain accuracy from considerably increased depth. On ImageNet dataset we evaluate nets depth up 152 - 8\u00d7 VGG [40] but still having lower complexity. An ensemble achieves 3.57% error on test set. This result won 1st place ILSVRC 2015 classification task. also analysis CIFAR-10 100 1000 layers. The representations is central importance for many visual recognition tasks. Solely due our extremely deep representations, obtain 28% relative improvement COCO object detection dataset. Deep foundations submissions & competitions1, where places tasks detection, localization, segmentation."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03522",
    "a_title":"Exploring the Potentials and Challenges of Using Large Language Models\n  for the Analysis of Transcriptional Regulation of Long Non-coding RNAs",
    "a_abstract":"Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.",
    "explanation":"Given the tremendous success of large language mod-\nels (LLMs) in capturing complex dependencies in sequential data, this study aims to systematically explore the potential and limitations of LLMs in the sequence analysis related to the transcriptional regulation of lncRNA genes. ",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Language Models are Few-Shot Learners"
    ],
    "b_abstract":[
      "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training a large corpus of text followed fine-tuning specific task. While typically task-agnostic in architecture, this method still requires task-specific datasets thousands or tens examples. By contrast, humans can generally perform new language task from only few examples simple instructions - something which current systems largely struggle to do. Here we show that scaling up models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art approaches. Specifically, train GPT-3, an autoregressive model 175 billion parameters, 10x more than any previous non-sparse model, test its performance the setting. For all tasks, GPT-3 is applied without gradient updates fine-tuning, demonstrations specified purely via interaction model. achieves strong datasets, including translation, question-answering, cloze as well several require on-the-fly reasoning domain adaptation, such unscrambling words, using novel word sentence, performing 3-digit arithmetic. At same time, also identify some where GPT-3's learning struggles, faces methodological issues related training web corpora. Finally, find generate samples news articles human evaluators have difficulty distinguishing written humans. We discuss broader societal impacts finding general."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b20"
    ],
    "c_title":[
      "Long non-coding RNAs: definitions, functions, challenges and recommendations"
    ],
    "c_abstract":[
      "Genes specifying long non-coding RNAs (lncRNAs) occupy a large fraction of the genomes of complex organisms. The term \u2018lncRNAs\u2019 encompasses RNA polymerase I (Pol I), Pol II and Pol III transcribed RNAs, and RNAs from processed introns. The various functions of lncRNAs and their many isoforms and interleaved relationships with other genes make lncRNA classification and annotation difficult. Most lncRNAs evolve more rapidly than protein-coding sequences, are cell type specific and regulate many aspects of cell differentiation and development and other physiological processes. Many lncRNAs associate with chromatin-modifying complexes, are transcribed from enhancers and nucleate phase separation of nuclear condensates and domains, indicating an intimate link between lncRNA expression and the spatial control of gene expression during development. lncRNAs also have important roles in the cytoplasm and beyond, including in the regulation of translation, metabolism and signalling. lncRNAs often have a modular structure and are rich in repeats, which are increasingly being shown to be relevant to their function. In this Consensus Statement, we address the definition and nomenclature of lncRNAs and their conservation, expression, phenotypic visibility, structure and functions. We also discuss research challenges and provide recommendations to advance the understanding of the roles of lncRNAs in development, cell biology and disease."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17702",
    "a_title":"Finding \"Good Views\" of Electrocardiogram Signals for Inferring\n  Abnormalities in Cardiac Condition",
    "a_abstract":"Electrocardiograms (ECGs) are an established technique to screen for abnormal\ncardiac signals. Recent work has established that it is possible to detect\narrhythmia directly from the ECG signal using deep learning algorithms. While a\nfew prior approaches with contrastive learning have been successful, the best\nway to define a positive sample remains an open question. In this project, we\ninvestigate several ways to define positive samples, and assess which approach\nyields the best performance in a downstream task of classifying arrhythmia. We\nexplore spatiotemporal invariances, generic augmentations, demographic\nsimilarities, cardiac rhythms, and wave attributes of ECG as potential ways to\nmatch positive samples. We then evaluate each strategy with downstream task\nperformance, and find that learned representations invariant to patient\nidentity are powerful in arrhythmia detection. We made our code available in:\nhttps:\/\/github.com\/mandiehyewon\/goodviews_ecg.git",
    "explanation":"Recent work has established that it is possible to de-\ntect arrhythmia directly from the ECG signal using deep learning algorithms. While a few prior approaches with contrastive learning have been successful,\nthe best way to define a positive sample remains an open question.",
    "b_id":[
      "b5",
      "b11"
    ],
    "b_title":[
      "Patient Contrastive Learning: a Performant, Expressive, and Practical Approach to ECG Modeling.",
      "CLOCS: Contrastive Learning of Cardiac Signals Across Space, Time, and Patients"
    ],
    "b_abstract":[
      "Supervised machine learning applications in health care are often limited due to a scarcity of labeled training data. To mitigate this effect small sample size, we introduce pre-training approach, Patient Contrastive Learning Representations (PCLR), which creates latent representations ECGs from large number unlabeled examples. The resulting expressive, performant, and practical across wide spectrum clinical tasks. We develop PCLR using system with over 3.2 million 12-lead ECGs, demonstrate substantial improvements multiple new tasks when there fewer than 5,000 labels.",
      "The healthcare industry generates troves of unlabelled physiological data. This data can be exploited via contrastive learning, a self-supervised pre-training method that encourages representations instances to similar one another. We propose family learning methods, CLOCS, across space, time, \\textit{and} patients show CLOCS consistently outperforms the state-of-the-art BYOL and SimCLR, when performing linear evaluation of, fine-tuning on, downstream tasks. also achieves strong generalization performance with only 25\\% labelled training Furthermore, our procedure naturally patient-specific used quantify patient-similarity."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "Screening for cardiac contractile dysfunction using an artificial intelligence-enabled electrocardiogram"
    ],
    "c_abstract":[
      "Asymptomatic left ventricular dysfunction (ALVD) is present in 3-6% of the general population, is associated with reduced quality of life and longevity, and is treatable when found1-4. An inexpensive, noninvasive screening tool for ALVD in the doctor's office is not available. We tested the hypothesis that application of artificial intelligence (AI) to the electrocardiogram (ECG), a routine method of measuring the heart's electrical activity, could identify ALVD. Using paired 12-lead ECG and echocardiogram data, including the left ventricular ejection fraction (a measure of contractile function), from 44,959 patients at the Mayo Clinic, we trained a convolutional neural network to identify patients with ventricular dysfunction, defined as ejection fraction \u226435%, using the ECG data alone. When tested on an independent set of 52,870 patients, the network model yielded values for the area under the curve, sensitivity, specificity, and accuracy of 0.93, 86.3%, 85.7%, and 85.7%, respectively. In patients without ventricular dysfunction, those with a positive AI screen were at 4 times the risk (hazard ratio, 4.1; 95% confidence interval, 3.3 to 5.0) of developing future ventricular dysfunction compared with those with a negative screen. Application of AI to the ECG-a ubiquitous, low-cost test-permits the ECG to serve as a powerful screening tool in asymptomatic individuals to identify ALVD."
    ],
    "c_categories":[
      "Cardio"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2412.20007",
    "a_title":"Uncertainty Quantified Deep Learning and Regression Analysis Framework\n  for Image Segmentation of Skin Cancer Lesions",
    "a_abstract":"Deep learning models (DLMs) frequently achieve accurate segmentation and\nclassification of tumors from medical images. However, DLMs lacking feedback on\ntheir image segmentation mechanisms, such as Dice coefficients and confidence\nin their performance, face challenges when processing previously unseen images\nin real-world clinical settings. Uncertainty estimates to identify DLM\npredictions at the cellular or single-pixel level that require clinician review\ncan enhance trust. However, their deployment requires significant computational\nresources. This study reports two DLMs, one trained from scratch and another\nbased on transfer learning, with Monte Carlo dropout or Bayes-by-backprop\nuncertainty estimations to segment lesions from the publicly available The\nInternational Skin Imaging Collaboration-19 dermoscopy image database with\ncancerous lesions. A novel approach to compute pixel-by-pixel uncertainty\nestimations of DLM segmentation performance in multiple clinical regions from a\nsingle dermoscopy image with corresponding Dice scores is reported for the\nfirst time. Image-level uncertainty maps demonstrated correspondence between\nimperfect DLM segmentation and high uncertainty levels in specific skin tissue\nregions, with or without lesions. Four new linear regression models that can\npredict the Dice performance of DLM segmentation using constants and\nuncertainty measures, either individually or in combination from lesions,\ntissue structures, and non-tissue pixel regions critical for clinical diagnosis\nand prognostication in skin images (Spearman's correlation, p < 0.05), are\nreported for the first time for low-compute uncertainty estimation workflows.",
    "explanation":"Deep learning models (DLMs) frequently achieve\naccurate segmentation and classification of tumors from medical\nimages.  DLMs lacking feedback on their image seg-\nmentation mechanisms such as Dice coefficients and confidence in\ntheir performance face challenges processing previously unseen\nimages in real-world clinical settings. A novel\napproach to compute pixel-by-pixel uncertainty estimations of\nDLM segmentation performance in multiple clinical regions from\na single dermatoscopy image with corresponding Dice scores\nis reported for the first time. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning"
    ],
    "b_abstract":[
      "Deep learning tools have gained tremendous attention in applied machine learning. However such for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about uncertainty, but usually come with prohibitive computational cost. this paper we develop new theoretical casting dropout training deep neural networks (NNs) as approximate inference Gaussian processes. A direct result of theory gives us uncertainty NNs -- extracting information from existing that has been thrown away so far. This mitigates the problem representing without sacrificing either complexity or test accuracy. We perform an extensive study properties dropout's Various network architectures non-linearities are assessed on tasks classification, using MNIST example. show considerable improvement predictive log-likelihood RMSE compared state-of-the-art methods, finish by reinforcement"
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "The HAM10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions"
    ],
    "c_abstract":[
      "Training of neural networks for automated diagnosis pigmented skin lesions is hampered by the small size and lack diversity available datasets dermatoscopic images. We tackle this problem releasing HAM10000 (\"Human Against Machine with 10000 training images\") dataset. collected images from different populations acquired stored modalities. Given we had to apply acquisition cleaning methods developed semi-automatic workflows utilizing specifically trained networks. The final dataset consists 10015 which are released as a set academic machine learning purposes publicly through ISIC archive. This benchmark can be used comparisons human experts. Cases include representative collection all important diagnostic categories in realm lesions. More than 50% have been confirmed pathology, while ground truth rest cases was either follow-up, expert consensus, or confirmation in-vivo confocal microscopy."
    ],
    "c_categories":[
      "Data"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05188",
    "a_title":"AGE2HIE: Transfer Learning from Brain Age to Predicting Neurocognitive\n  Outcome for Infant Brain Injury",
    "a_abstract":"Hypoxic-Ischemic Encephalopathy (HIE) affects 1 to 5 out of every 1,000\nnewborns, with 30% to 50% of cases resulting in adverse neurocognitive\noutcomes. However, these outcomes can only be reliably assessed as early as age\n2. Therefore, early and accurate prediction of HIE-related neurocognitive\noutcomes using deep learning models is critical for improving clinical\ndecision-making, guiding treatment decisions and assessing novel therapies.\nHowever, a major challenge in developing deep learning models for this purpose\nis the scarcity of large, annotated HIE datasets. We have assembled the first\nand largest public dataset, however it contains only 156 cases with 2-year\nneurocognitive outcome labels. In contrast, we have collected 8,859 normal\nbrain black Magnetic Resonance Imagings (MRIs) with 0-97 years of age that are\navailable for brain age estimation using deep learning models. In this paper,\nwe introduce AGE2HIE to transfer knowledge learned by deep learning models from\nhealthy controls brain MRIs to a diseased cohort, from structural to diffusion\nMRIs, from regression of continuous age estimation to prediction of the binary\nneurocognitive outcomes, and from lifespan age (0-97 years) to infant (0-2\nweeks). Compared to training from scratch, transfer learning from brain age\nestimation significantly improves not only the prediction accuracy (3% or 2%\nimprovement in same or multi-site), but also the model generalization across\ndifferent sites (5% improvement in cross-site validation).",
    "explanation":"Hypoxic-Ischemic Encephalopathy (HIE) affects 1 to 5 out of\nevery 1,000 newborns, with 30% to 50% of cases resulting in\nadverse neurocognitive outcomes. However, these outcomes\ncan only be reliably assessed as early as age 2. Therefore,\nearly and accurate prediction of HIE-related neurocognitive\noutcomes using deep learning models is critical for improv-\ning clinical decision-making, guiding treatment decisions and\nassessing novel therapies",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Limitations of conventional magnetic resonance imaging as a predictor of death or disability following neonatal hypoxic-ischemic encephalopathy in the late hypothermia trial"
    ],
    "b_abstract":[
      "Objective: To investigate if magnetic resonance imaging (MRI) is an accurate predictor for death or moderate-severe disability at 18-22 months of age among infants with neonatal encephalopathy in a trial of cooling initiated at 6-24 hours. Study design: Subgroup analysis of infants \u226536 weeks of gestation with moderate-severe neonatal encephalopathy randomized at 6-24 postnatal hours to hypothermia or usual care in a multicenter trial of late hypothermia. MRI scans were performed per each center's practice and interpreted by 2 central readers using the Eunice Kennedy Shriver National Institute of Child Health and Human Development injury score (6 levels, normal to hemispheric devastation). Neurodevelopmental outcomes were assessed at 18-22 months of age. Results: Of 168 enrollees, 128 had an interpretable MRI and were seen in follow-up (n = 119) or died (n = 9). MRI findings were predominantly acute injury and did not differ by cooling treatment. At 18-22 months, death or severe disability occurred in 20.3%. No infant had moderate disability. Agreement between central readers was moderate (weighted kappa 0.56, 95% CI 0.45-0.67). The adjusted odds of death or severe disability increased 3.7-fold (95% CI 1.8-7.9) for each increment of injury score. The area under the curve for severe MRI patterns to predict death or severe disability was 0.77 and the positive and negative predictive values were 36% and 100%, respectively. Conclusions: MRI injury scores were associated with neurodevelopmental outcome at 18-22 months among infants in the Late Hypothermia Trial. However, the results suggest caution when using qualitative interpretations of MRI images to provide prognostic information to families following perinatal hypoxia-ischemia."
    ],
    "b_categories":[
      "Pediatrics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "What is being transferred in transfer learning?"
    ],
    "c_abstract":[
      "One desired capability for machines is the ability to transfer their knowledge of one domain another where data (usually) scarce. Despite ample adaptation learning in various deep applications, we yet do not understand what enables a successful and which part network responsible that. In this paper, provide new tools analyses address these fundamental questions. Through series on transferring block-shuffled images, separate effect feature reuse from low-level statistics show that some benefit comes latter. We present when training pre-trained weights, model stays same basin loss landscape different instances such are similar space close parameter space."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19345",
    "a_title":"3D Wasserstein generative adversarial network with dense U-Net based\n  discriminator for preclinical fMRI denoising",
    "a_abstract":"Functional magnetic resonance imaging (fMRI) is extensively used in clinical\nand preclinical settings to study brain function, however, fMRI data is\ninherently noisy due to physiological processes, hardware, and external noise.\nDenoising is one of the main preprocessing steps in any fMRI analysis pipeline.\nThis process is challenging in preclinical data in comparison to clinical data\ndue to variations in brain geometry, image resolution, and low signal-to-noise\nratios. In this paper, we propose a structure-preserved algorithm based on a 3D\nWasserstein generative adversarial network with a 3D dense U-net based\ndiscriminator called, 3D U-WGAN. We apply a 4D data configuration to\neffectively denoise temporal and spatial information in analyzing preclinical\nfMRI data. GAN-based denoising methods often utilize a discriminator to\nidentify significant differences between denoised and noise-free images,\nfocusing on global or local features. To refine the fMRI denoising model, our\nmethod employs a 3D dense U-Net discriminator to learn both global and local\ndistinctions. To tackle potential over-smoothing, we introduce an adversarial\nloss and enhance perceptual similarity by measuring feature space distances.\nExperiments illustrate that 3D U-WGAN significantly improves image quality in\nresting-state and task preclinical fMRI data, enhancing signal-to-noise ratio\nwithout introducing excessive structural changes in existing methods. The\nproposed method outperforms state-of-the-art methods when applied to simulated\nand real data in a fMRI analysis pipeline.",
    "explanation":"Denoising is one of the main preprocessing steps in any fMRI analysis pipeline. In this\npaper, we propose a structure-preserved algorithm based on a 3D Wasserstein\ngenerative adversarial network with a 3D dense U-net based discriminator called,\n3D U-WGAN. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "On the use of preclinical imaging to explore the principles of brain function in rodent models and their relevance for illnesses of the human mind"
    ],
    "b_abstract":[
      "Dear Editor, We recently published in Translational Psychiatry an article that examine the strategies for evaluating brain function at the wholebrain level [1]. In this review, we covered several methods, from functional MRI to functional ultrasound to calcium imaging. For each technique, we wrote a brief history of its development, the physical notion, some key applications, its potentials, and its limitations. We concluded that methods for imaging the rodent brain at the network level are growing and will advance our understanding of brain function. A commentary by Zhuo and colleagues further enhances the complexity of addressing the issue of \u201ctranslation\u201d from animal models to patients for the discipline of psychiatry [2]. They propose that the approaches employed to develop an animal model for a psychiatric disease need to be thoroughly scrutinized and, perhaps, revised. For example, most rodent models of mental diseases are to-date established using a simple pharmacological infusion [3] and\/or psychosocial stimulation [4]. The key concern posed, however, is how these manipulations change the brain\u2019s structure and function, and whether these models genuinely reflect the pathophysiology of human mental illnesses. Especially since it is difficult to evaluate whether one can speak of inverse inference from rodents to humans. This is a true and acceptable statement. However, this is exactly what preclinical imaging aims to deliver. By mapping the dynamic responses of brain networks in animal models and compare them, if possible, with those reported in clinical studies, we can obtain quantitative data and parameters to establish whether our models are effectively translational [5]. If these metrics demonstrate temporal and spatial similarity in network-level modifications as those observed in humans, we can pursue further inquiry utilizing more intrusive and more specific methods for brain recordings in animal models. Otherwise, we must have the confidence and the correctness to move forward and attempt other solutions. Two recent examples. In 2019 we established a causal association between activity of the noradrenergic nucleus locus coeruleus (LC) and the engagement of numerous large-scale brain networks in mice, in particular of the salience and amygdala networks [6]. In addition, we could link network-changes with direct markers of norepinephrine (NE) turnover and with the distribution of NE receptors over the entire brain. The hypothesis that specific brain networks dynamics are related to LC activity and to NE receptor density derives from stress-research and pharmacological studies in humans [7, 8]. However, since it is impossible to selectively stimulate LC in people, it has remained a hypothesis for more than a decade. Our preclinical work helped confirm this causal relationship and this has direct implications for interpreting the results of clinical imaging studies on stress and anxiety behavior. More recently, the Gozzi lab described how chronic local neuronal suppression via overexpression of a potassium channel or acute silencing via chemogenetics result in a paradoxical hyperconnectivity [9]; an intriguing finding often reported in humans after stroke [10] and in early stages of Alzheimer\u2019s disease [11], but never truly understood. Using in vivo electrophysiology, they showed local inhibition improves low frequency (0.1\u20134 Hz) oscillatory power via suppression of neuronal activity not phaselocked to slow rhythms, resulting in increased slow and \u03b4 band coherence between areas that display fMRI overconnectivity. These data present causal evidence that cortical inactivation can counterintuitively augment fMRI connectivity via greater, lesslocalized slow oscillatory processes. Once again, this could be only achieved by combining functional MRI and electrophysiology with neuromodulation in animal models. These and other examples give a peek of what the future of preclinical imaging might look like: a field of research capable of delivering causal explanations to the hypotheses presented by human neuroscience, neurology and psychiatry. Lastly, I would argue against statements like \u201cthe computational complexity of human brains is billions of times that of mouse brain\u201d. While this may be true from a numerical standpoint of mere neuronal counts, preclinical neuroimaging\u2019s objective should not be per se to map every single neuron in real time but of identifying the general neural and cellular principles governing the assembly of brain networks and its breakdown in brain disorders. The field is relatively new but is moving fast and has already produced some important insights. The future is challenging and will require time, devotion and an optimal synergy between engineering, chemistry, biology, and computer science. If the community will be patient and supportive enough, there will be further important discoveries in the future."
    ],
    "b_categories":[
      "Psychiatry"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "GAN\uff08Generative Adversarial Nets\uff09"
    ],
    "c_abstract":[
      "We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: model G that captures the data distribution, and discriminative D estimates probability sample came from training rather than G. The procedure is to maximize of making mistake. This corresponds minimax two-player game. In space arbitrary functions D, unique solution exists, with recovering distribution equal \u00bd everywhere. case where are defined by multilayer perceptrons, entire system can be trained backpropagation. There no need any Markov chains or unrolled approximate inference networks during either generation samples. Experiments demonstrate potential through qualitative quantitative evaluation generated"
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00688",
    "a_title":"Why do we regularise in every iteration for imaging inverse problems?",
    "a_abstract":"Regularisation is commonly used in iterative methods for solving imaging\ninverse problems. Many algorithms involve the evaluation of the proximal\noperator of the regularisation term in every iteration, leading to a\nsignificant computational overhead since such evaluation can be costly. In this\ncontext, the ProxSkip algorithm, recently proposed for federated learning\npurposes, emerges as an solution. It randomly skips regularisation steps,\nreducing the computational time of an iterative algorithm without affecting its\nconvergence. Here we explore for the first time the efficacy of ProxSkip to a\nvariety of imaging inverse problems and we also propose a novel PDHGSkip\nversion. Extensive numerical results highlight the potential of these methods\nto accelerate computations while maintaining high-quality reconstructions.",
    "explanation":"Regularisation is commonly used in iterative methods for solving imaging inverse problems. Here we explore for the first time the efficacy of ProxSkip to a variety of imaging inverse problems and we also propose a novel PDHGSkip version.",
    "b_id":[
      "b19"
    ],
    "b_title":[
      "Parameter-Free FISTA by Adaptive Restart and Backtracking"
    ],
    "b_abstract":[
      "We consider a combined restarting and adaptive backtracking strategy for the\npopular Fast Iterative Shrinking-Thresholding Algorithm frequently employed for\naccelerating the convergence speed of large-scale structured convex\noptimization problems. Several variants of FISTA enjoy a provable linear\nconvergence rate for the function values $F(x_n)$ of the form $\\mathcal{O}(\ne^{-K\\sqrt{\\mu\/L}~n})$ under the prior knowledge of problem conditioning, i.e.\nof the ratio between the (\\L ojasiewicz) parameter $\\mu$ determining the growth\nof the objective function and the Lipschitz constant $L$ of its smooth\ncomponent. These parameters are nonetheless hard to estimate in many practical\ncases. Recent works address the problem by estimating either parameter via\nsuitable adaptive strategies. In our work both parameters can be estimated at\nthe same time by means of an algorithmic restarting scheme where, at each\nrestart, a non-monotone estimation of $L$ is performed. For this scheme,\ntheoretical convergence results are proved, showing that a $\\mathcal{O}(\ne^{-K\\sqrt{\\mu\/L}n})$ convergence speed can still be achieved along with\nquantitative estimates of the conditioning. The resulting Free-FISTA algorithm\nis therefore parameter-free. Several numerical results are reported to confirm\nthe practical interest of its use in many exemplar problems."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Convex generalizations of total variation based on the structure tensor with applications to inverse problems"
    ],
    "c_abstract":[
      "We introduce a generic convex energy functional that is suitable for both grayscale and vector-valued images. Our functional is based on the eigenvalues of the structure tensor, therefore it penalizes image variation at every point by taking into account the information from its neighborhood. It generalizes several existing variational penalties, such as the Total Variation and vectorial extensions of it. By introducing the concept of patch-based Jacobian operator, we derive an equivalent formulation of the proposed regularizer that is based on the Schatten norm of this operator. Using this new formulation, we prove convexity and develop a dual definition for the proposed energy, which gives rise to an efficient and parallelizable minimization algorithm. Moreover, we establish a connection between the minimization of the proposed convex regularizer and a generic type of nonlinear anisotropic diffusion that is driven by a spatially regularized and adaptive diffusion tensor. Finally, we perform extensive experiments with image denoising and deblurring for grayscale and color images. The results show the effectiveness of the proposed approach as well as its improved performance compared to Total Variation and existing vectorial extensions of it."
    ],
    "c_categories":[
      "eess.IV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00036",
    "a_title":"Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial\n  Market Dynamics",
    "a_abstract":"We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.",
    "explanation":"The paper proposes the use of a new method using diffusion model generative methodology to produce synthetic market scenarios.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "On the Distribution of the Two-Sample Cramer-von Mises Criterion"
    ],
    "b_abstract":[
      "The Cramer-von Mises $\\omega^2$ criterion for testing that a sample, $x_1, \\cdots, x_N$, has been drawn from specified continuous distribution $F(x)$ is \\begin{equation*}\\tag{1}\\omega^2 = \\int^\\infty_{-\\infty} \\lbrack F_N(x) - F(x)\\rbrack^2 dF(x),\\end{equation*} where $F_N(x)$ the empirical function of sample; is, $F_N(x) k\/N$ if exactly $k$ observations are less than or equal to $x(k 0, 1, N)$. If there second $y_1, y_M$, test hypothesis two samples come same (unspecified) can be based on analogue $N\\omega^2$, namely \\begin{equation*}\\tag{2} T NM\/(N + M)\\rbrack G_M(x)\\rbrack^2 dH_{N+M}(x),\\end{equation*} $G_M(x)$ sample and $H_{N+M}(x)$ together [that $(N M)H_{N+M}(x) NF_N(x) MG_M(x)\\rbrack$. limiting $N\\omega^2$ as $N \\rightarrow \\infty$ tabulated [2], it shown ([3], [4a], [7]) $T$ \\infty, M \\infty$, $N\/M \\lambda$, $\\lambda$ any finite positive constant. In this note we consider small values $N$ $M$ present tables permit use at some conventional significance levels $M$. seems surprisingly good approximation exact moderate sizes (corresponding feature [6]). accuracy better in case two-sample Kolmogorov-Smirnov statistic studied by Hodges [4]."
    ],
    "b_categories":[
      "q-fin.GN"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "b24"
    ],
    "c_title":[
      "Quant GANs: deep generation of financial time series"
    ],
    "c_abstract":[
      "Modeling financial time series by stochastic processes is a challenging task and a central area of research in financial mathematics. As an alternative, we introduce Quant GANs, a data-driven model which is inspired by the recent success of generative adversarial networks (GANs). Quant GANs consist of a generator and discriminator function, which utilize temporal convolutional networks (TCNs) and thereby achieve to capture long-range dependencies such as the presence of volatility clusters. The generator function is explicitly constructed such that the induced stochastic process allows a transition to its risk-neutral distribution. Our numerical results highlight that distributional properties for small and large lags are in an excellent agreement and dependence properties such as volatility clusters, leverage effects, and serial autocorrelations can be generated by the generator function of Quant GANs, demonstrably in high fidelity."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00640",
    "a_title":"Adding Error Bars to Evals: A Statistical Approach to Language Model\n  Evaluations",
    "a_abstract":"Evaluations are critical for understanding the capabilities of large language\nmodels (LLMs). Fundamentally, evaluations are experiments; but the literature\non evaluations has largely ignored the literature from other sciences on\nexperiment analysis and planning. This article shows researchers with some\ntraining in statistics how to think about and analyze data from language model\nevaluations. Conceptualizing evaluation questions as having been drawn from an\nunseen super-population, we present formulas for analyzing evaluation data,\nmeasuring differences between two models, and planning an evaluation\nexperiment. We make a number of specific recommendations for running language\nmodel evaluations and reporting experiment results in a way that minimizes\nstatistical noise and maximizes informativeness.",
    "explanation":"This is an interdisciplinary work because it combines two different subjects: LLM and statistics. This suggests that we could also consider the error bars in the evaluations. ",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "Quantifying Variance in Evaluation Benchmarks"
    ],
    "b_abstract":[
      "Evaluation benchmarks are the cornerstone of measuring capabilities large language models (LLMs), as well driving progress in said capabilities. Originally designed to make claims about (or lack thereof) fully pretrained models, evaluation now also extensively used decide between various training choices. Despite this widespread usage, we rarely quantify variance our benchmarks, which dictates whether differences performance meaningful. Here, define and measure a range metrics geared towards including seed across initialisations, monotonicity during training. By studying number -- both openly available from scratch provide empirical estimates for variety metrics, with considerations recommendations practitioners. We evaluate utility tradeoffs continuous versus discrete measures explore options better understanding reducing variance. find that simple changes, such framing choice tasks (like MMLU) completion tasks, can often reduce smaller scale ($\\sim$7B) while more involved methods inspired human testing literature (such item analysis response theory) struggle meaningfully Overall, work provides insights into suggests LM-specific techniques variance, generally encourages practitioners carefully factor when comparing models."
    ],
    "b_categories":[
      "stat.ME"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "The Llama 3 Herd of Models"
    ],
    "c_abstract":[
      "Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18784",
    "a_title":"MRI Breast tissue segmentation using nnU-Net for biomechanical modeling",
    "a_abstract":"Integrating 2D mammography with 3D magnetic resonance imaging (MRI) is\ncrucial for improving breast cancer diagnosis and treatment planning. However,\nthis integration is challenging due to differences in imaging modalities and\nthe need for precise tissue segmentation and alignment. This paper addresses\nthese challenges by enhancing biomechanical breast models in two main aspects:\nimproving tissue identification using nnU-Net segmentation models and\nevaluating finite element (FE) biomechanical solvers, specifically comparing\nNiftySim and FEBio. We performed a detailed six-class segmentation of breast\nMRI data using the nnU-Net architecture, achieving Dice Coefficients of 0.94\nfor fat, 0.88 for glandular tissue, and 0.87 for pectoral muscle. The overall\nforeground segmentation reached a mean Dice Coefficient of 0.83 through an\nensemble of 2D and 3D U-Net configurations, providing a solid foundation for 3D\nreconstruction and biomechanical modeling. The segmented data was then used to\ngenerate detailed 3D meshes and develop biomechanical models using NiftySim and\nFEBio, which simulate breast tissue's physical behaviors under compression. Our\nresults include a comparison between NiftySim and FEBio, providing insights\ninto the accuracy and reliability of these simulations in studying breast\ntissue responses under compression. The findings of this study have the\npotential to improve the integration of 2D and 3D imaging modalities, thereby\nenhancing diagnostic accuracy and treatment planning for breast cancer.",
    "explanation":"Integrating 2D mammography with 3D magnetic resonance\nimaging (MRI) is crucial for improving breast cancer diagnosis and treat-\nment planning. However, this integration is challenging due to differences\nin imaging modalities and the need for precise tissue segmentation and\nalignment. This paper addresses these challenges by enhancing biome-\nchanical breast models in two main aspects: improving tissue identifica-\ntion using nnU-Net segmentation models and evaluating finite element\n(FE) biomechanical solvers, specifically comparing NiftySim and FEBio.\u00a0",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "nnu-net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "b_abstract":[
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Multimodal Breast Parenchymal Patterns Correlation Using a Patient-Specific Biomechanical Model"
    ],
    "c_abstract":[
      "In this paper, we aim to produce a realistic 2-D projection of the breast parenchymal distribution from a 3-D breast magnetic resonance image (MRI). To evaluate the accuracy of our simulation, we compare our results with the local breast density (i.e., density map) obtained from the complementary full-field digital mammogram. To achieve this goal, we have developed a fully automatic framework, which registers MRI volumes to X-ray mammograms using a subject-specific biomechanical model of the breast. The optimization step modifies the position, orientation, and elastic parameters of the breast model to perform the alignment between the images. When the model reaches an optimal solution, the MRI glandular tissue is projected and compared with the one obtained from the corresponding mammograms. To reduce the loss of information during the ray-casting, we introduce a new approach that avoids resampling the MRI volume. In the results, we focus our efforts on evaluating the agreement of the distributions of glandular tissue, the degree of structural similarity, and the correlation between the real and synthetic density maps. Our approach obtained a high-structural agreement regardless the glandularity of the breast, whilst the similarity of the glandular tissue distributions and correlation between both images increase in denser breasts. Furthermore, the synthetic images show continuity with respect to large structures in the density maps."
    ],
    "c_categories":[
      "Imaging"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00663",
    "a_title":"Deep Learning for Longitudinal Gross Tumor Volume Segmentation in\n  MRI-Guided Adaptive Radiotherapy for Head and Neck Cancer",
    "a_abstract":"Accurate segmentation of gross tumor volume (GTV) is essential for effective\nMRI-guided adaptive radiotherapy (MRgART) in head and neck cancer. However,\nmanual segmentation of the GTV over the course of therapy is time-consuming and\nprone to interobserver variability. Deep learning (DL) has the potential to\novercome these challenges by automatically delineating GTVs. In this study, our\nteam, $\\textit{UW LAIR}$, tackled the challenges of both pre-radiotherapy\n(pre-RT) (Task 1) and mid-radiotherapy (mid-RT) (Task 2) tumor volume\nsegmentation. To this end, we developed a series of DL models for longitudinal\nGTV segmentation. The backbone of our models for both tasks was SegResNet with\ndeep supervision. For Task 1, we trained the model using a combined dataset of\npre-RT and mid-RT MRI data, which resulted in the improved aggregated Dice\nsimilarity coefficient (DSCagg) on an internal testing set compared to models\ntrained solely on pre-RT MRI data. In Task 2, we introduced mask-aware\nattention modules, enabling pre-RT GTV masks to influence intermediate features\nlearned from mid-RT data. This attention-based approach yielded slight\nimprovements over the baseline method, which concatenated mid-RT MRI with\npre-RT GTV masks as input. In the final testing phase, the ensemble of 10\npre-RT segmentation models achieved an average DSCagg of 0.794, with 0.745 for\nprimary GTV (GTVp) and 0.844 for metastatic lymph nodes (GTVn) in Task 1. For\nTask 2, the ensemble of 10 mid-RT segmentation models attained an average\nDSCagg of 0.733, with 0.607 for GTVp and 0.859 for GTVn, leading us to\n$\\textbf{achieve 1st place}$. In summary, we presented a collection of DL\nmodels that could facilitate GTV segmentation in MRgART, offering the potential\nto streamline radiation oncology workflows. Our code and model weights are\navailable at https:\/\/github.com\/xtie97\/HNTS-MRG24-UWLAIR.",
    "explanation":"In this study, our team, UW LAIR, tackled the challenges of both pre-radiotherapy\n(pre-RT) (Task 1) and mid-radiotherapy (mid-RT) (Task 2) tumor volume seg-\nmentation. To this end, we developed a series of DL models for longitudinal GTV\nsegmentation",
    "b_id":[
      "b4",
      "b2"
    ],
    "b_title":[
      "Deep Learning for Automatic Gross Tumor Volumes Contouring in Esophageal Cancer Based on Contrast-Enhanced Computed Tomography Images: A Multi-Institutional Study",
      "ConTEXTual Net: A Multimodal Vision-Language Model for Segmentation of Pneumothorax"
    ],
    "b_abstract":[
      "Purpose To develop and externally validate an automatic artificial intelligence (AI) tool for delineating gross tumor volume (GTV) in patients with esophageal squamous cell carcinoma (ESCC), which can assist in neo-adjuvant or radical radiation therapy treatment planning. Methods and Materials In this multi-institutional study, contrast-enhanced CT images from 580 eligible ESCC patients were retrospectively collected. The GTV contours delineated by 2 experts via consensus were used as ground truth. A 3-dimensional deep learning model was developed for GTV contouring in the training cohort and internally and externally validated in 3 validation cohorts. The AI tool was compared against 12 board-certified experts in 25 patients randomly selected from the external validation cohort to evaluate its assistance in improving contouring performance and reducing variation. Contouring performance was measured using dice similarity coefficient (DSC) and average surface distance. Additionally, our previously established radiomics model for predicting pathologic complete response was used to compare AI-generated and ground truth contours, to assess the potential of the AI contouring tool in radiomics analysis. Results The AI tool demonstrated good GTV contouring performance in multicenter validation cohorts, with median DSC values of 0.865, 0.876, and 0.866 and median average surface distance values of 0.939, 0.789, and 0.875 mm, respectively. Furthermore, the AI tool significantly improved contouring performance for half of 12 board-certified experts (DSC values, 0.794-0.835 vs 0.856-0.881, P = .003-0.048), reduced the intra- and interobserver variations by 37.4% and 55.2%, respectively, and saved contouring time by 77.6%. In the radiomics analysis, 88.7% of radiomic features from ground truth and AI-generated contours demonstrated stable reproducibility, and similar pathologic complete response prediction performance for these contours (P = .430) was observed. Conclusions Our AI contouring tool can improve GTV contouring performance and facilitate radiomics analysis in ESCC patients, which indicates its potential for GTV contouring during radiation therapy treatment planning and radiomics studies.",
      "Radiology narrative reports often describe characteristics of a patient's disease, including its location, size, and shape. Motivated by the recent success multimodal learning, we hypothesized that this descriptive text could guide medical image analysis algorithms. We proposed novel vision-language model, ConTEXTual Net, for task pneumothorax segmentation on chest radiographs. Net extracts language features from physician-generated free-form radiology using pre-trained model. then introduced cross-attention between intermediate embeddings an encoder-decoder convolutional neural network to enable guidance analysis. was trained CANDID-PTX dataset consisting 3196 positive cases with annotations 6 different physicians as well clinical reports. Using cross-validation, achieved Dice score 0.716\u00b10.016, which similar degree inter-reader variability (0.712\u00b10.044) computed subset data. It outperformed vision-only models (Swin UNETR: 0.670\u00b10.015, ResNet50 U-Net: 0.677\u00b10.015, GLoRIA: 0.686\u00b10.014, nnUNet 0.694\u00b10.016) competing model (LAVT: 0.706\u00b10.009). Ablation studies confirmed it information led performance gains. Additionally, show certain augmentation methods degraded Net's breaking image-text concordance. also evaluated effects activation functions in module, highlighting efficacy our chosen architectural design."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "MRI-Guided Adaptive Radiation Therapy"
    ],
    "c_abstract":[
      "Magnetic resonance imaging-guided radiation therapy (MRIgRT) has improved soft tissue contrast over computed tomography (CT) based image-guided RT. Superior visualization of the target and surrounding radiosensitive structures has the potential to improve oncological outcomes partly due to safer dose-escalation and adaptive planning. In this review, we highlight the workflow of adaptive MRIgRT planning, which includes simulation imaging, daily MRI, identifying isocenter shifts, contouring, plan optimization, quality control, and delivery. Increased utilization of MRIgRT will depend on addressing technical limitations of this technology, while addressing treatment efficacy, cost-effectiveness, and workflow training."
    ],
    "c_categories":[
      "Oncology"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18602",
    "a_title":"Evaluating and Improving the Effectiveness of Synthetic Chest X-Rays for\n  Medical Image Analysis",
    "a_abstract":"Purpose: To explore best-practice approaches for generating synthetic chest\nX-ray images and augmenting medical imaging datasets to optimize the\nperformance of deep learning models in downstream tasks like classification and\nsegmentation. Materials and Methods: We utilized a latent diffusion model to\ncondition the generation of synthetic chest X-rays on text prompts and\/or\nsegmentation masks. We explored methods like using a proxy model and using\nradiologist feedback to improve the quality of synthetic data. These synthetic\nimages were then generated from relevant disease information or geometrically\ntransformed segmentation masks and added to ground truth training set images\nfrom the CheXpert, CANDID-PTX, SIIM, and RSNA Pneumonia datasets to measure\nimprovements in classification and segmentation model performance on the test\nsets. F1 and Dice scores were used to evaluate classification and segmentation\nrespectively. One-tailed t-tests with Bonferroni correction assessed the\nstatistical significance of performance improvements with synthetic data.\nResults: Across all experiments, the synthetic data we generated resulted in a\nmaximum mean classification F1 score improvement of 0.150453 (CI:\n0.099108-0.201798; P=0.0031) compared to using only real data. For\nsegmentation, the maximum Dice score improvement was 0.14575 (CI:\n0.108267-0.183233; P=0.0064). Conclusion: Best practices for generating\nsynthetic chest X-ray images for downstream tasks include conditioning on\nsingle-disease labels or geometrically transformed segmentation masks, as well\nas potentially using proxy modeling for fine-tuning such generations.",
    "explanation":"We utilized a latent diffusion model to condition the generation of synthetic chest X-rays on text prompts and\/or segmentation masks",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Rsna pneumonia detection challenge"
    ],
    "b_abstract":[
      "In this competition, you\u2019re challenged to build an algorithm to detect a visual signal for pneumonia in medical images. Specifically, your algorithm needs to automatically locate lung opacities on chest radiographs. Here\u2019s the backstory and why solving this problem matters. Pneumonia accounts for over 15% of all deaths of children under 5 years old internationally. In 2015, 920,000 children under the age of 5 died from the disease. In the United States, pneumonia accounts for over 500,000 visits to emergency departments [1] and over 50,000 deaths in 2015 [2], keeping the ailment on the list of top 10 causes of death in the country. While common, accurately diagnosing pneumonia is a tall order. It requires review of a chest radiograph (CXR) by highly trained specialists and confirmation through clinical history, vital signs and laboratory exams. Pneumonia usually manifests as an area or areas of increased opacity [3] on CXR. However, the diagnosis of pneumonia on CXR is complicated because of a number of other conditions in the lungs such as fluid overload (pulmonary edema), bleeding, volume loss (atelectasis or collapse), lung cancer, or post-radiation or surgical changes. Outside of the lungs, fluid in the pleural space (pleural effusion) also appears as increased opacity on CXR. When available, comparison of CXRs of the patient taken at different time points and correlation with clinical symptoms and history are helpful in making the diagnosis. CXRs are the most commonly performed diagnostic imaging study. A number of factors such as positioning of the patient and depth of inspiration can alter the appearance of the CXR [4], complicating interpretation further. In addition, clinicians are faced with reading high volumes of images every shift. To improve the efficiency and reach of diagnostic services, the Radiological Society of North America (RSNA\u00ae) has reached out to Kaggle\u2019s machine learning community and collaborated with the US National Institutes of Health, The Society of Thoracic Radiology, and MD.ai to develop a rich dataset for this challenge. The RSNA is an international society of radiologists, medical physicists and other medical professionals with more than 54,000 members from 146 countries across the globe. They see the potential for ML to automate initial detection (imaging screening) of potential pneumonia cases in order to prioritize and expedite their review. Challenge participants may be invited to present their AI models and methodologies during an award ceremony at the RSNA Annual Meeting which will be held in Chicago, Illinois, USA, from November 25-30, 2018."
    ],
    "b_categories":[
      "Imaging"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b14",
      "b9"
    ],
    "c_title":[
      "Adding Conditional Control to Text-to-Image Diffusion Models",
      "Highresolution image synthesis with latent diffusion models"
    ],
    "c_abstract":[
      "We present ControlNet, a neural network architecture to add spatial conditioning controls large, pretrained text-to-image diffusion models. ControlNet locks the production-ready large models, and reuses their deep robust encoding layers with billions of images as strong backbone learn diverse set conditional controls. The is connected \"zero convolutions\" (zero-initialized convolution layers) that progressively grow parameters from zero ensure no harmful noise could affect finetuning. test various controls, e.g., edges, depth, segmentation, human pose, etc., Stable Diffusion, using single or multiple conditions, without prompts. show training ControlNets small (<50k) (>1m) datasets. Extensive results may facilitate wider applications control image",
      "By decomposing the image formation process into a sequential application of denoising autoencoders, diffusion models (DMs) achieve state-of-the-art synthesis results on image data and beyond. Additionally, their formulation allows for a guiding mechanism to control the image generation process without retraining. However, since these models typically operate directly in pixel space, optimization of powerful DMs often consumes hundreds of GPU days and inference is expensive due to sequential evaluations. To enable DM training on limited computational resources while retaining their quality and flexibility, we apply them in the latent space of powerful pretrained autoencoders. In contrast to previous work, training diffusion models on such a representation allows for the first time to reach a near-optimal point between complexity reduction and detail preservation, greatly boosting visual fidelity. By introducing cross-attention layers into the model architecture, we turn diffusion models into powerful and flexible generators for general conditioning inputs such as text or bounding boxes and high-resolution synthesis becomes possible in a convolutional manner. Our latent diffusion models (LDMs) achieve a new state of the art for image inpainting and highly competitive performance on various tasks, including unconditional image generation, semantic scene synthesis, and super-resolution, while significantly reducing computational requirements compared to pixel-based DMs."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18902",
    "a_title":"MSEMG: Surface Electromyography Denoising with a Mamba-based Efficient\n  Network",
    "a_abstract":"Surface electromyography (sEMG) recordings can be contaminated by\nelectrocardiogram (ECG) signals when the monitored muscle is closed to the\nheart. Traditional signal-processing-based approaches, such as high-pass\nfiltering and template subtraction, have been used to remove ECG interference\nbut are often limited in their effectiveness. Recently, neural-network-based\nmethods have shown greater promise for sEMG denoising, but they still struggle\nto balance both efficiency and effectiveness. In this study, we introduce\nMSEMG, a novel system that integrates the Mamba State Space Model with a\nconvolutional neural network to serve as a lightweight sEMG denoising model. We\nevaluated MSEMG using sEMG data from the Non-Invasive Adaptive Prosthetics\ndatabase and ECG signals from the MIT-BIH Normal Sinus Rhythm Database. The\nresults show that MSEMG outperforms existing methods, generating higher-quality\nsEMG signals with fewer parameters. The source code for MSEMG is available at\nhttps:\/\/github.com\/tonyliu0910\/MSEMG.",
    "explanation":"Surface electromyography (sEMG) recordings can\nbe contaminated by electrocardiogram (ECG) signals when the\nmonitored muscle is closed to the heart. In this study, we introduce MSEMG, a novel\nsystem that integrates the Mamba state space model with a\nconvolutional neural network to serve as a lightweight sEMG\ndenoising mode",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "Biomechanics and motor control of human movement"
    ],
    "b_abstract":[
      "Preface to the Fourth Edition. 1 Biomechanics as an Interdiscipline. 1.0 Introduction. 1.1 Measurement, Description, Analysis, and Assessment. 1.2 its Relationship with Physiology Anatomy. 1.3 Scope of Textbook. 1.4 References. 2 Signal Processing. 2.0 2.1 Auto- Cross-Correlation Analyses. 2.2 Frequency Analysis. 2.3 Ensemble Averaging Repetitive Waveforms. 2.4 3 Kinematics. 3.0 Historical Development Complexity Problem. 3.1 Kinematic Conventions. 3.2 Direct Measurement Techniques. 3.3 Imaging 3.4 Processing Raw Data. 3.5 Calculation Other Variables. 3.6 Problems Based on 3.7 4 Anthropometry. 4.0 Anthropometry in Movement Biomechanics. 4.1 Density, Mass, Inertial Properties. 4.2 Experimental Measures. 4.3 Muscle 4.4 Anthropometric 4.5 5 Kinetics: Forces Moments Force. 5.0 Biomechanical Models. 5.1 Basic Link-Segment Equations-the Free-Body Diagram. 5.2 Force Transducers Plates. 5.3 Bone-on-Bone During Dynamic Conditions. 5.4 Kinetic 5.5 6 Mechanical Work, Energy, Power. 6.0 6.1 Efficiency. 6.2 Forms Energy Storage. 6.3 Internal External Work. 6.4 Power Balances at Joints Within Segments. 6.5 6.6 7 Three-Dimensional Kinematics Kinetics. 7.0 7.1 Axes Systems. 7.2 Marker Anatomical 7.3 Determination Segment Angular Velocities Accelerations. 7.4 Analysis Reaction Moments. 7.5 Suggested Further Reading. 7.6 8 Synthesis Human Movement-Forward Solutions. 8.0 8.1 Review Forward Solution 8.2 Mathematical Formulation. 8.3 System Energy. 8.4 Torques. 8.5 Designation Joints. 8.6 Illustrative Example. 8.7 Conclusions. 8.8 9 Mechanics. 9.0 9.1 Force-Length Characteristics Muscles. 9.2 Force-Velocity Characteristics. 9.3 Modeling. 9.4 10 Kinesiological Electromyography. 10.0 10.1 Electrophysiology Contraction. 10.2 Recording Electromyogram. 10.3 Electromyogram,. 10.4 between Electromyogram 10.5 11 Synergies. 11.0 11.1 The Support Moment Synergy. 11.2 Medial\/Lateral Anterior\/Posterior Balance Standing. 11.3 during Walking. 11.4 APPENDICES. A. Kinematic, Kinetic, Figure A.1 Walking Trial-Marker Locations Mass Frame Rate Information. Table Coordinate Data (cm). A.2( a ) Filtered Kinematics-Rib Cage Greater Trochanter (Hip). b Kinematics-Femoral Lateral Epicondyle (Knee) Head Fibula. c Kinematics-Lateral Malleolus (Ankle) Heel. d Kinematics-Fifth Metatarsal Toe. A.3( Linear Kinematics-Foot. Kinematics-Leg. Kinematics-Thigh. Kinematics-1\/2 HAT. A.4 Relative Joint Kinematics-Ankle, Knee, Hip. A.5( Force-Ankle Knee. Force-Hip. A.6 Potential, Total Energies-Foot, Leg, Thigh, and1\/2 A.7 Generation\/Absorption Transfer-Ankle, B. Units Definitions Related Electromyographical Measurements. B.1 Base SI Units. B.2 Derived Index."
    ],
    "b_categories":[
      "Biomechanics"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b13"
    ],
    "c_title":[
      "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"
    ],
    "c_abstract":[
      "Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution recurrent structured state space models (SSMs) have been developed to address Transformers' computational inefficiency long sequences, but they not performed well important modalities language. We identify that a key weakness is their inability perform content-based reasoning, make several improvements. First, simply letting SSM parameters be functions input addresses with discrete modalities, allowing model selectively propagate or forget information along sequence length dimension depending current token. Second, even though this change prevents use efficient convolutions, we design hardware-aware parallel algorithm mode. integrate these selective SSMs into simplified end-to-end neural network without MLP blocks (Mamba). Mamba enjoys fast inference (5$\\times$ higher throughput than Transformers) scaling length, performance improves real data up million-length sequences. As general backbone, achieves state-of-the-art across language, audio, genomics. On language modeling, our Mamba-3B outperforms Transformers same size matches twice size, both pretraining downstream evaluation."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03551",
    "a_title":"Enhancing Weakly Supervised Semantic Segmentation for Fibrosis via\n  Controllable Image Generation",
    "a_abstract":"Fibrotic Lung Disease (FLD) is a severe condition marked by lung stiffening\nand scarring, leading to respiratory decline. High-resolution computed\ntomography (HRCT) is critical for diagnosing and monitoring FLD; however,\nfibrosis appears as irregular, diffuse patterns with unclear boundaries,\nleading to high inter-observer variability and time-intensive manual\nannotation. To tackle this challenge, we propose DiffSeg, a novel weakly\nsupervised semantic segmentation (WSSS) method that uses image-level\nannotations to generate pixel-level fibrosis segmentation, reducing the need\nfor fine-grained manual labeling. Additionally, our DiffSeg incorporates a\ndiffusion-based generative model to synthesize HRCT images with different\nlevels of fibrosis from healthy slices, enabling the generation of the\nfibrosis-injected slices and their paired fibrosis location. Experiments\nindicate that our method significantly improves the accuracy of pseudo masks\ngenerated by existing WSSS methods, greatly reducing the complexity of manual\nlabeling and enhancing the consistency of the generated masks.",
    "explanation":"However, fibrosis appears\nas irregular, diffuse patterns with unclear boundaries, lead-\ning to high inter-observer variability and time-intensive man-\nual annotation. To tackle this challenge, we propose DiffSeg,\na novel weakly supervised semantic segmentation (WSSS)\nmethod that uses image-level annotations to generate pixel-\nlevel fibrosis segmentation, reducing the need for fine-grained\nmanual labeling. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Interobserver Variability in the CT Assessment of Honeycombing in the Lungs"
    ],
    "b_abstract":[
      "To quantify observer agreement and analyze causes of disagreement in identifying honeycombing at chest computed tomography (CT).The institutional review board approved this multiinstitutional HIPAA-compliant retrospective study, informed patient consent was not required. Five core study members scored 80 CT images with a five-point scale (5 = definitely yes to 1 no) establish reference standard for the identification honeycombing. Forty-three observers from various subspecialties geographic regions by using same scoring system. Weighted \u03ba values scores compared were analyzed investigate intergroup differences. Images divided into four groups allow analysis imaging features cases which there disagreement: on presence honeycombing, absence other (none preceding three applied).Agreement 43 moderate (Cohen weighted values: 0.40-0.58). There no significant differences among defined either subspecialty or region (Tukey-Kramer test, P .38 >.99). In 29% cases, These included mixed traction bronchiectasis, large cysts, superimposed pulmonary emphysema.Identification is subjective, largely caused conditions that mimic"
    ],
    "b_categories":[
      "Radiology"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "DuPL: Dual Student with Trustworthy Progressive Learning for Robust Weakly Supervised Semantic Segmentation"
    ],
    "c_abstract":[
      "Recently, One-stage Weakly Supervised Semantic Segmentation (WSSS) with image-level labels has gained increasing interest due to simplification over its cumbersome multi-stage counterpart. Limited by the inherent ambiguity of Class Activation Map (CAM), we observe that one-stage pipelines often encounter confirmation bias caused by incorrect CAM pseudo-labels, impairing their final segmentation performance. Although recent works discard many unreliable pseudo-labels to implicitly alleviate this issue, they fail to exploit sufficient supervision for their models. To this end, we propose a dual student framework with trustworthy progressive learning (DuPL). Specifically, we propose a dual student network with a discrepancy loss to yield diverse CAMs for each sub-net. The two sub-nets generate supervision for each other, mitigating the confirmation bias caused by learning their own incorrect pseudo-labels. In this process, we progressively introduce more trustworthy pseudo-labels to be involved in the supervision through dynamic threshold adjustment with an adaptive noise filtering strategy. Moreover, we believe that every pixel, even discarded from supervision due to its unreliability, is important for WSSS. Thus, we develop consistency regularization on these discarded regions, providing supervision of every pixel. Experiment results demonstrate the superiority of the proposed DuPL over the recent state-of-the-art alternatives on PASCAL VOC 2012 and MS COCO datasets."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.09469",
    "a_title":"An Explainable Attention Model for Cervical Precancer Risk\n  Classification using Colposcopic Images",
    "a_abstract":"Cervical cancer remains a major worldwide health issue, with early\nidentification and risk assessment playing critical roles in effective\npreventive interventions. This paper presents the Cervix-AID-Net model for\ncervical precancer risk classification. The study designs and evaluates the\nproposed Cervix-AID-Net model based on patients colposcopy images. The model\ncomprises a Convolutional Block Attention Module (CBAM) and convolutional\nlayers that extract interpretable and representative features of colposcopic\nimages to distinguish high-risk and low-risk cervical precancer. In addition,\nthe proposed Cervix-AID-Net model integrates four explainable techniques,\nnamely gradient class activation maps, Local Interpretable Model-agnostic\nExplanations, CartoonX, and pixel rate distortion explanation based on output\nfeature maps and input features. The evaluation using holdout and ten-fold\ncross-validation techniques yielded a classification accuracy of 99.33\\% and\n99.81\\%. The analysis revealed that CartoonX provides meticulous explanations\nfor the decision of the Cervix-AID-Net model due to its ability to provide the\nrelevant piece-wise smooth part of the image. The effect of Gaussian noise and\nblur on the input shows that the performance remains unchanged up to Gaussian\nnoise of 3\\% and blur of 10\\%, while the performance reduces thereafter. A\ncomparison study of the proposed model's performance compared to other deep\nlearning approaches highlights the Cervix-AID-Net model's potential as a\nsupplemental tool for increasing the effectiveness of cervical precancer risk\nassessment. The proposed method, which incorporates the CBAM and explainable\nartificial integration, has the potential to influence cervical cancer\nprevention and early detection, improving patient outcomes and lowering the\nworldwide burden of this preventable disease.",
    "explanation":"This paper presents the Cervix-AID-Net model for cervical precancer risk classification. The study designs and evaluates the proposed Cervix-\nAID-Net model based on patients colposcopy images. The model comprises a Convolutional Block\nAttention Module (CBAM) and convolutional layers that extract interpretable and representative\nfeatures of colposcopic images to distinguish high-risk and low-risk cervical precancer. ",
    "b_id":[
      "b36"
    ],
    "b_title":[
      "CBAM: Convolutional block attention module"
    ],
    "b_abstract":[
      "We propose Convolutional Block Attention Module (CBAM), a simple yet effective attention module for feed-forward convolutional neural networks. Given an intermediate feature map, our module sequentially infers attention maps along two separate dimensions, channel and spatial, then the attention maps are multiplied to the input feature map for adaptive feature refinement. Because CBAM is a lightweight and general module, it can be integrated into any CNN architectures seamlessly with negligible overheads and is end-to-end trainable along with base CNNs. We validate our CBAM through extensive experiments on ImageNet-1K, MS~COCO detection, and VOC~2007 detection datasets. Our experiments show consistent improvements in classification and detection performances with various models, demonstrating the wide applicability of CBAM. The code and models will be publicly available."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "The accuracy of colposcopic biopsy: Analyses from the placebo arm of the Gardasil clinical trials"
    ],
    "c_abstract":[
      "We evaluated the overall agreement between colposcopically directed biopsies and definitive excisional specimens within context of three clinical trials. A total 737 women aged 16-45 who had a cervical biopsy taken 6 months before their therapy were included. Per-protocol, colposcopists to also obtain representative immediately therapy. Using adjudicated histological diagnoses, initial same day correlated with surgically excised specimens. The therapy, diagnoses was 42% (weighted kappa = 0.34) (95% CI: 0.29-0.39). underestimation intraepithelial neoplasia grade 2\/3 or adenocarcinoma in situ (CIN2-3\/AIS) CIN3\/AIS 26 42%, respectively. When allowing for one degree variance correlation, 92% CIN2-3\/AIS. specimen 56% 0.41) 0.36-0.47), CIN2-3\/AIS 57%. There significant associations when patients stratified by age, number biopsies, lesion size, presence human papillomavirus (HPV)16\/18 region. Of 178 diagnostic endocervical curettages performed, 14 (7.9%) found any HPV disease. Colposcopic accuracy improved CIN2 grouped as single predictive measure high-grade Colposcopy functioned well allowed one-degree difference surgical histologic interpretations, done practice. Taking more than colposcopic could improve patient management."
    ],
    "c_categories":[
      "Clinical Trial"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.14752",
    "a_title":"Comparative Analysis of nnUNet and MedNeXt for Head and Neck Tumor\n  Segmentation in MRI-guided Radiotherapy",
    "a_abstract":"Radiation therapy (RT) is essential in treating head and neck cancer (HNC),\nwith magnetic resonance imaging(MRI)-guided RT offering superior soft tissue\ncontrast and functional imaging. However, manual tumor segmentation is\ntime-consuming and complex, and therfore remains a challenge. In this study, we\npresent our solution as team TUMOR to the HNTS-MRG24 MICCAI Challenge which is\nfocused on automated segmentation of primary gross tumor volumes (GTVp) and\nmetastatic lymph node gross tumor volume (GTVn) in pre-RT and mid-RT MRI\nimages. We utilized the HNTS-MRG2024 dataset, which consists of 150 MRI scans\nfrom patients diagnosed with HNC, including original and registered pre-RT and\nmid-RT T2-weighted images with corresponding segmentation masks for GTVp and\nGTVn. We employed two state-of-the-art models in deep learning, nnUNet and\nMedNeXt. For Task 1, we pretrained models on pre-RT registered and mid-RT\nimages, followed by fine-tuning on original pre-RT images. For Task 2, we\ncombined registered pre-RT images, registered pre-RT segmentation masks, and\nmid-RT data as a multi-channel input for training. Our solution for Task 1\nachieved 1st place in the final test phase with an aggregated Dice Similarity\nCoefficient of 0.8254, and our solution for Task 2 ranked 8th with a score of\n0.7005. The proposed solution is publicly available at Github Repository.",
    "explanation":"Radiation therapy (RT) is essential in treating head and neck cancer\n(HNC), with magnetic resonance imaging(MRI)-guided RT offering superior soft tis-\nsue contrast and functional imaging. However, manual tumor segmentation is time-\nconsuming and complex, and therfore remains a challenge. In this study, we present\nour solution as team TUMOR to the HNTS-MRG24 MICCAI Challenge which is\nfocused on automated segmentation of primary gross tumor volumes (GTVp) and\nmetastatic lymph node gross tumor volume (GTVn) in pre-RT and mid-RT MRI im-\nages. We employed two state-of-the-art models in deep learning, nnUNet and MedNeXt.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "\u201cApr\u00e8s Mois, Le D\u00e9luge\u201d: Preparing for the Coming Data Flood in the MRI-Guided Radiotherapy Era"
    ],
    "b_abstract":[
      "Magnetic resonance imaging provides a sea of quantitative and semi-quantitative data. While radiation oncologists already navigate pool clinical (semantic) data, the tide will swell with advent hybrid MRI\/linear accelerator devices increasing interest in MRI-guided radiotherapy (MRIgRT), including adaptive MRIgRT. The variety MR sequences (of greater complexity than single parameter Hounsfield unit CT scanning routinely used radiotherapy), workflow fractionation, sheer quantity daily images acquired are challenges for scaling this technology. Biomedical informatics, which is science information biomedicine, can provide helpful insights looming transition. Funneling MRIgRT data into clinically meaningful streams requires committing to flow inter-institutional accessibility interoperability initiatives, standardizing dosimetry methods, streamlining linear workflow, MRI acquisition post-processing, current topic review attempt conceptually ford using informatics approaches as theoretical bridge."
    ],
    "b_categories":[
      "Oncology"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "MedNeXt: Transformer-driven Scaling of ConvNets for Medical Image Segmentation",
      "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "c_abstract":[
      "There has been exploding interest in embracing Transformer-based architectures for medical image segmentation. However, the lack of large-scale annotated medical datasets make achieving performances equivalent to those in natural images challenging. Convolutional networks, in contrast, have higher inductive biases and consequently, are easily trainable to high performance. Recently, the ConvNeXt architecture attempted to modernize the standard ConvNet by mirroring Transformer blocks. In this work, we improve upon this to design a modernized and scalable convolutional architecture customized to challenges of data-scarce medical settings. We introduce MedNeXt, a Transformer-inspired large kernel segmentation network which introduces - 1) A fully ConvNeXt 3D Encoder-Decoder Network for medical image segmentation, 2) Residual ConvNeXt up and downsampling blocks to preserve semantic richness across scales, 3) A novel technique to iteratively increase kernel sizes by upsampling small kernel networks, to prevent performance saturation on limited medical data, 4) Compound scaling at multiple levels (depth, width, kernel size) of MedNeXt. This leads to state-of-the-art performance on 4 tasks on CT and MRI modalities and varying dataset sizes, representing a modernized deep architecture for medical image segmentation. Our code is made publicly available at: https:\/\/github.com\/MIC-DKFZ\/MedNeXt.",
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.06785",
    "a_title":"White-Box Diffusion Transformer for single-cell RNA-seq generation",
    "a_abstract":"As a powerful tool for characterizing cellular subpopulations and cellular\nheterogeneity, single cell RNA sequencing (scRNA-seq) technology offers\nadvantages of high throughput and multidimensional analysis. However, the\nprocess of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a hybrid model\nbased on Diffusion model and White-Box transformer that aims to generate\nsynthetic and biologically plausible scRNA-seq data. Diffusion model\nprogressively introduce noise into the data and then recover the original data\nthrough a denoising process, a forward and reverse process that is particularly\nsuitable for generating complex data distributions. White-Box transformer is a\ndeep learning architecture that emphasizes mathematical interpretability. By\nminimizing the encoding rate of the data and maximizing the sparsity of the\nrepresentation, it not only reduces the computational burden, but also provides\nclear insight into underlying structure. Our White-Box Diffusion Transformer\ncombines the generative capabilities of Diffusion model with the mathematical\ninterpretability of White-Box transformer. Through experiments using six\ndifferent single-cell RNA-Seq datasets, we visualize both generated and real\ndata using t-SNE dimensionality reduction technique, as well as quantify\nsimilarity between generated and real data using various metrics to demonstrate\ncomparable performance of White-Box Diffusion Transformer and Diffusion\nTransformer in generating scRNA-seq data alongside significant improvements in\ntraining efficiency and resource utilization. Our code is available at\nhttps:\/\/github.com\/lingximamo\/White-Box-Diffusion-Transformer",
    "explanation":"As a powerful tool for characterizing cellular subpopulations and cellular heterogeneity, single cell\nRNA sequencing (scRNA-seq) technology offers advantages of high throughput and multidimensional\nanalysis. However, the process of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a model based on Diffusion model\nand White-Box transformer that aims to generate synthetic and biologically plausible scRNA-seq\ndata.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "RNA-Seq: a revolutionary tool for transcriptomics"
    ],
    "b_abstract":[
      "RNA-Seq is a recently developed approach to transcriptome profiling that uses deep-sequencing technologies. Studies using this method have already altered our view of the extent and complexity of eukaryotic transcriptomes. RNA-Seq also provides a far more precise measurement of levels of transcripts and their isoforms than other methods. This article describes the RNA-Seq approach, the challenges associated with its application, and the advances made so far in characterizing several eukaryote transcriptomes."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "White-Box Transformers via Sparse Rate Reduction"
    ],
    "c_abstract":[
      "In this paper, we contend that the objective of representation learning is to compress and transform distribution data, say sets tokens, towards a mixture low-dimensional Gaussian distributions supported on incoherent subspaces. The quality final can be measured by unified function called sparse rate reduction. From perspective, popular deep networks such as transformers naturally viewed realizing iterative schemes optimize incrementally. Particularly, show standard transformer block derived from alternating optimization complementary parts objective: multi-head self-attention operator gradient descent step token minimizing their lossy coding rate, subsequent multi-layer perceptron attempting sparsify tokens. This leads family white-box transformer-like network architectures which are mathematically fully interpretable. Despite simplicity, experiments these indeed learn designed they representations large-scale real-world vision datasets ImageNet, achieve performance very close thoroughly engineered ViT."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00868",
    "a_title":"Quantifying perturbation impacts for large language models",
    "a_abstract":"We consider the problem of quantifying how an input perturbation impacts the\noutputs of large language models (LLMs), a fundamental task for model\nreliability and post-hoc interpretability. A key obstacle in this domain is\ndisentangling the meaningful changes in model responses from the intrinsic\nstochasticity of LLM outputs. To overcome this, we introduce Distribution-Based\nPerturbation Analysis (DBPA), a framework that reformulates LLM perturbation\nanalysis as a frequentist hypothesis testing problem. DBPA constructs empirical\nnull and alternative output distributions within a low-dimensional semantic\nsimilarity space via Monte Carlo sampling. Comparisons of Monte Carlo estimates\nin the reduced dimensionality space enables tractable frequentist inference\nwithout relying on restrictive distributional assumptions. The framework is\nmodel-agnostic, supports the evaluation of arbitrary input perturbations on any\nblack-box LLM, yields interpretable p-values, supports multiple perturbation\ntesting via controlled error rates, and provides scalar effect sizes for any\nchosen similarity or distance metric. We demonstrate the effectiveness of DBPA\nin evaluating perturbation impacts, showing its versatility for perturbation\nanalysis.",
    "explanation":"\"We consider the problem of quantifying how an input perturbation impacts the outputs of large language models (LLMs), a fundamental task for model reliability and post-hoc interpretability.\"",
    "b_id":[
      "b22"
    ],
    "b_title":[
      "Context-Aware Testing: A New Paradigm for Model Testing with Large\n  Language Models"
    ],
    "b_abstract":[
      "The predominant de facto paradigm of testing ML models relies on either using\nonly held-out data to compute aggregate evaluation metrics or by assessing the\nperformance on different subgroups. However, such data-only testing methods\noperate under the restrictive assumption that the available empirical data is\nthe sole input for testing ML models, disregarding valuable contextual\ninformation that could guide model testing. In this paper, we challenge the\ngo-to approach of data-only testing and introduce context-aware testing (CAT)\nwhich uses context as an inductive bias to guide the search for meaningful\nmodel failures. We instantiate the first CAT system, SMART Testing, which\nemploys large language models to hypothesize relevant and likely failures,\nwhich are evaluated on data using a self-falsification mechanism. Through\nempirical evaluations in diverse settings, we show that SMART automatically\nidentifies more relevant and impactful failures than alternatives,\ndemonstrating the potential of CAT as a testing paradigm."
    ],
    "b_categories":[
      "stat.ME"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "How resilient are language models to text perturbations"
    ],
    "c_abstract":[
      "Large language models typically rely on highly curated datasets that lack common irregularities such as typos and contractions, resulting in a mismatch between their training environments and real-world applications. This study evaluates the resilience of four prominent models in five different NLP tasks when confronted with perturbed inputs. We investigate three categories of perturbations: character-level, word-level and miscellaneous perturbations. By comparing performance on original and altered datasets, our results reveal a significant sensitivity to input perturbations across all models, with varying degrees of vulnerability depending on both the specific task and the type of perturbation. In particular, the XLNet model consistently shows superior robustness, while tasks involving grammatical coherence are most adversely affected."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01668",
    "a_title":"Linear Quadratic Mean Field Games with Quantile-Dependent Cost\n  Coefficients",
    "a_abstract":"This paper studies a class of linear quadratic mean field games where the\ncoefficients of quadratic cost functions depend on both the mean and the\nvariance of the population's state distribution through its quantile function.\nSuch a formulation allows for modelling agents that are sensitive to not only\nthe population average but also the population variance. The corresponding mean\nfield game equilibrium is identified, which involves solving two coupled\ndifferential equations: one is a Riccati equation and the other the variance\nevolution equation. Furthermore, the conditions for the existence and\nuniqueness of the mean field equilibrium are established. Finally, numerical\nresults are presented to illustrate the behavior of two coupled differential\nequations and the performance of the mean field game solution.",
    "explanation":"\"This paper studies a class of linear quadratic mean field games where the coefficients of quadratic cost functions depend on both the mean and the variance of the population\u2019s state distribution through its quantile function. \"\n\n\n",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Mean\u2010field games with differing beliefs for algorithmic trading"
    ],
    "b_abstract":[
      "Abstract Even when confronted with the same data, agents often disagree on a model of real world. Here, we address question how interacting heterogeneous agents, who what world follows, optimize their trading actions. The market has latent factors that drive prices, and account for permanent impact they have prices. This leads to large stochastic game, where each performance criteria are computed under different probability measure. We analyze mean\u2010field game (MFG) limit show Nash equilibrium is given by solution nonstandard vector\u2010valued forward\u2013backward differential equation. Under some mild assumptions, construct in terms expectations filtered states. Furthermore, prove MFG strategy forms an \u03b5\u2010Nash finite player game. Finally, present least square Monte Carlo based algorithm computing equilibria through simulations increasing disagreement may increase price volatility activity."
    ],
    "b_categories":[
      "q-fin.MF"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Linear-quadratic mean field games"
    ],
    "c_abstract":[
      "In this article, we provide a comprehensive study of the linear-quadratic mean field games via the adjoint equation approach; although the problem has been considered in the literature by Huang, Caines and Malhame (HCM, 2007a), their method is based on Dynamic Programming. It turns out that two methods are not equivalent, as far as giving sufficient condition for the existence of a solution is concerned. Due to the linearity of the adjoint equations, the optimal mean field term satisfies a linear forward-backward ordinary differential equation. For the one dimensional case, we show that the equilibrium strategy always exists uniquely. For dimension greater than one, by choosing a suitable norm and then applying the Banach Fixed Point Theorem, a sufficient condition, which is independent of the solution of the standard Riccati differential equation, for the unique existence of the equilibrium strategy is provided. As a by-product, we also establish a neat and instructive sufficient condition for the unique existence of the solution for a class of non-trivial nonsymmetric Riccati equations. Numerical examples of non-existence of the equilibrium strategy and the comparison of HCM's approach will also be provided."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.00575",
    "a_title":"A Semi-Discrete Optimal Transport Scheme for the 3D Incompressible\n  Semi-Geostrophic Equations",
    "a_abstract":"We describe a mesh-free three-dimensional numerical scheme for solving the\nincompressible semi-geostrophic equations based on semi-discrete optimal\ntransport techniques. These results generalise previous two-dimensional\nimplementations. The optimal transport methods we adopt are known for their\nstructural preservation and energy conservation qualities and achieve an\nexcellent level of efficiency and numerical energy-conservation. We use this\nscheme to generate numerical simulations of an important cyclone benchmark\nproblem. To our knowledge, this is the first fully three-dimensional simulation\nof the semi-geostrophic equations, evidencing semi-discrete optimal transport\nas a novel, robust numerical tool for meteorological and oceanographic\nmodelling.",
    "explanation":"We describe a mesh-free three-dimensional numerical scheme for solving the in-\ncompressible semi-geostrophic equations based on semi-discrete optimal transport techniques.\nThese results generalise previous two-dimensional implementations.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Weak Existence for the Semigeostrophic Equations Formulated as a Coupled Monge--Amp\u00e8re\/Transport Problem"
    ],
    "b_abstract":[
      "Hoskins's semigeostrophic equations are reformulated as a coupled Monge--Amp\u00e8re\/ transport problem [B. J. Hoskins, Quart. Royal Met. Soc., 97 (1971), pp. 139--153]. Existence of global weak solutions is obtained for this formulation."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b22"
    ],
    "c_title":[
      "Vertical slice modelling of nonlinear Eady waves using a compatible finite element method"
    ],
    "c_abstract":[
      "A vertical slice model is developed for the Euler-Boussinesq equations with a\nconstant temperature gradient in the direction normal to the slice (the\nEady-Boussinesq model). The model is a solution of the full three-dimensional\nequations with no variation normal to the slice, which is an idealized problem\nused to study the formation and subsequent evolution of weather fronts. A\ncompatible finite element method is used to discretise the governing equations.\nTo extend the Charney-Phillips grid staggering in the compatible finite element\nframework, we use the same node locations for buoyancy as the vertical part of\nvelocity and apply a transport scheme for a partially continuous finite element\nspace. For the time discretisation, we solve the semi-implicit equations\ntogether with an explicit strong-stability-preserving Runge-Kutta scheme to all\nof the advection terms. The model reproduces several quasi-periodic lifecycles\nof fronts despite the presence of strong discontinuities. An asymptotic limit\nanalysis based on the semi-geostrophic theory shows that the model solutions\nare converging to a solution in cross-front geostrophic balance. The results\nare consistent with the previous results using finite difference methods,\nindicating that the compatible finite element method is performing as well as\nfinite difference methods for this test problem. We observe dissipation of\nkinetic energy of the cross-front velocity in the model due to the lack of\nresolution at the fronts, even though the energy loss is not likely to account\nfor the large gap on the strength of the fronts between the model result and\nthe semi-geostrophic limit solution."
    ],
    "c_categories":[
      "math.MP"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.00578",
    "a_title":"Federated Voxel Scene Graph for Intracranial Hemorrhage",
    "a_abstract":"Intracranial Hemorrhage is a potentially lethal condition whose manifestation\nis vastly diverse and shifts across clinical centers worldwide.\nDeep-learning-based solutions are starting to model complex relations between\nbrain structures, but still struggle to generalize. While gathering more\ndiverse data is the most natural approach, privacy regulations often limit the\nsharing of medical data. We propose the first application of Federated Scene\nGraph Generation. We show that our models can leverage the increased training\ndata diversity. For Scene Graph Generation, they can recall up to 20% more\nclinically relevant relations across datasets compared to models trained on a\nsingle centralized dataset. Learning structured data representation in a\nfederated setting can open the way to the development of new methods that can\nleverage this finer information to regularize across clients more effectively.",
    "explanation":"intracranial Hemorrhage is a potentially lethal condition whose manifestation is vastly diverse and shifts across\nclinical centers worldwide. Deep-learning-based solutions are starting to model complex relations between brain\nstructures, but still struggle to generalize.",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "American Heart Association\/American Stroke Association. 2022 guideline for the management of patients with spontaneous intracerebral hemorrhage: A guideline from the american heart association\/american stroke association"
    ],
    "b_abstract":[
      "Approximately 10% of the 795\u2009000 strokes per year in the United States are intracerebral hemorrhages (ICHs),1 defined by brain injury attributable to acute blood extravasation into the brain parenchyma from a ruptured cerebral blood vessel. The clinical impact of ICH appears disproportionately high among lower-resource populations both in the United States and internationally. In US-based studies, ICH incidence has been reported to be \u22481.6-fold greater among Black than White people2 and 1.6-fold greater among Mexican American than non-Hispanic White people.3 Internationally, ICH incidence is substantially higher in low- and middle-income versus high-income countries, both as a proportion of all strokes and in absolute incidence rates.4,5 Several additional features of ICH make it a greater public health threat than conveyed by incidence numbers alone. ICH is arguably the deadliest form of acute stroke, with early-term mortality about 30% to 40% and no or minimal trend toward improvement over more recent time epochs.6\u20139 Incidence of ICH increases sharply with age and is therefore expected to remain substantial as the population ages, even with counterbalancing public health improvements in blood pressure (BP) control.8 Another growing source of ICH is more widespread use of anticoagulants,10 a trend likely to counterbalance the reduced ICH risk associated with increasing prescription of direct oral anticoagulants (DOACs) relative to vitamin K antagonists (VKAs).11 ICH thus remains in need of novel treatments and improved application of established approaches for every aspect of the disease: primary and secondary prevention, acute inpatient care, and poststroke rehabilitation and recovery. This guideline seeks to synthesize data in the ICH field into practical recommendations for clinical practice."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "Voxel Scene Graph for Intracranial Hemorrhage"
    ],
    "c_abstract":[
      "Patients with Intracranial Hemorrhage (ICH) face a potentially life-threatening condition, and patient-centered individualized treatment remains challenging due to possible clinical complications. Deep-Learning-based methods can efficiently analyze the routinely acquired head CTs support decision-making. The majority of early work focuses on detection segmentation ICH, but do not model complex relations between ICH adjacent brain structures. In this work, we design tailored object method for which unite segmentation-grounded Scene Graph Generation (SGG) learn holistic representation cerebral scene. To best our knowledge, is first application SGG 3D voxel images. We evaluate two head-CT datasets demonstrate that recall up 74% clinically relevant relations. This lays foundation towards data. generated Graphs already provide insights clinician, are also valuable all downstream tasks as compact interpretable representation."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00614",
    "a_title":"Fast and scalable Wasserstein-1 neural optimal transport solver for\n  single-cell perturbation prediction",
    "a_abstract":"Predicting single-cell perturbation responses requires mapping between two\nunpaired single-cell data distributions. Optimal transport (OT) theory provides\na principled framework for constructing such mappings by minimizing transport\ncost. Recently, Wasserstein-2 ($W_2$) neural optimal transport solvers\n(\\textit{e.g.}, CellOT) have been employed for this prediction task. However,\n$W_2$ OT relies on the general Kantorovich dual formulation, which involves\noptimizing over two conjugate functions, leading to a complex min-max\noptimization problem that converges slowly. To address these challenges, we\npropose a novel solver based on the Wasserstein-1 ($W_1$) dual formulation.\nUnlike $W_2$, the $W_1$ dual simplifies the optimization to a maximization\nproblem over a single 1-Lipschitz function, thus eliminating the need for\ntime-consuming min-max optimization. While solving the $W_1$ dual only reveals\nthe transport direction and does not directly provide a unique optimal\ntransport map, we incorporate an additional step using adversarial training to\ndetermine an appropriate transport step size, effectively recovering the\ntransport map. Our experiments demonstrate that the proposed $W_1$ neural\noptimal transport solver can mimic the $W_2$ OT solvers in finding a unique and\n``monotonic\" map on 2D datasets. Moreover, the $W_1$ OT solver achieves\nperformance on par with or surpasses $W_2$ OT solvers on real single-cell\nperturbation datasets. Furthermore, we show that $W_1$ OT solver achieves $25\n\\sim 45\\times$ speedup, scales better on high dimensional transportation task,\nand can be directly applied on single-cell RNA-seq dataset with highly variable\ngenes. Our implementation and experiments are open-sourced at\n\\url{https:\/\/github.com\/poseidonchan\/w1ot}.",
    "explanation":"Predicting single-cell perturbation responses requires mapping between two unpaired single-\ncell data distributions. Optimal transport (OT) theory provides a principled framework for constructing\nsuch mappings by minimizing transport cost.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Multimodal pooled Perturb-CITE-seq screens in patient models define mechanisms of cancer immune evasion"
    ],
    "b_abstract":[
      "Resistance to immune checkpoint inhibitors (ICIs) is a key challenge in cancer therapy. To elucidate underlying mechanisms, we developed Perturb-CITE-sequencing (Perturb-CITE-seq), enabling pooled clustered regularly interspaced short palindromic repeat (CRISPR)\u2013Cas9 perturbations with single-cell transcriptome and protein readouts. In patient-derived melanoma cells and autologous tumor-infiltrating lymphocyte (TIL) co-cultures, we profiled transcriptomes and 20\u2009proteins in ~218,000\u2009cells under ~750\u2009perturbations associated with cancer cell-intrinsic ICI resistance (ICR). We recover known mechanisms of resistance, including defects in the interferon-\u03b3 (IFN-\u03b3)\u2013JAK\/STAT and antigen-presentation pathways in RNA, protein and perturbation space, and new ones, including loss\/downregulation of CD58. Loss of CD58 conferred immune evasion in multiple co-culture models and was downregulated in tumors of melanoma patients with ICR. CD58 protein expression was not induced by IFN-\u03b3 signaling, and CD58 loss conferred immune evasion without compromising major histocompatibility complex (MHC) expression, suggesting that it acts orthogonally to known mechanisms of ICR. This work provides a framework for the deciphering of complex mechanisms by large-scale perturbation screens with multimodal, single-cell readouts, and discovers potentially clinically relevant mechanisms of immune evasion."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Causal identification of single-cell experimental perturbation effects with CINEMA-OT"
    ],
    "c_abstract":[
      "Abstract Recent advancements in single-cell technologies allow characterization of experimental perturbations at resolution. While methods have been developed to analyze such experiments, the application a strict causal framework has not yet explored for inference treatment effects level. Here we present causal-inference-based approach perturbation analysis, termed CINEMA-OT (causal independent effect module attribution + optimal transport). separates confounding sources variation from obtain an transport matching that reflects counterfactual cell pairs. These pairs represent responses permitting number novel analyses, as individual treatment-effect response clustering, and synergy analysis. We benchmark on array estimation tasks several simulated real datasets show it outperforms other analysis methods. Finally, perform two newly generated datasets: (1) rhinovirus cigarette-smoke-exposed airway organoids, (2) combinatorial cytokine stimulation immune cells. In these reveals potential mechanisms by which cigarette-smoke exposure dulls antiviral response, well logic governs chemokine secretion peripheral recruitment."
    ],
    "c_categories":[
      "math.OC"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00714",
    "a_title":"Self-reinforcing cascades: A spreading model for beliefs or products of\n  varying intensity or quality",
    "a_abstract":"Models of how things spread often assume that transmission mechanisms are\nfixed over time. However, social contagions--the spread of ideas, beliefs,\ninnovations--can lose or gain in momentum as they spread: ideas can get\nreinforced, beliefs strengthened, products refined. We study the impacts of\nsuch self-reinforcement mechanisms in cascade dynamics. We use different\nmathematical modeling techniques to capture the recursive, yet changing nature\nof the process. We find a critical regime with a range of power-law cascade\nsize distributions with varying scaling exponents. This regime clashes with\nclassic models, where criticality requires fine tuning at a precise critical\npoint. Self-reinforced cascades produce critical-like behavior over a wide\nrange of parameters, which may help explain the ubiquity of power-law\ndistributions in empirical social data.",
    "explanation":"Models of how things spread often assume that transmission mechanisms are fixed over time. However, social\ncontagions\u2013the spread of ideas, beliefs, innovations\u2013can lose or gain in momentum as they spread: ideas can get\nreinforced, beliefs strengthened, products refined. e use different mathematical modeling techniques to capture the recursive, yet changing\nnature of the process.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Universality, criticality and complexity of information propagation in social media"
    ],
    "b_abstract":[
      "Abstract Statistical laws of information avalanches in social media appear, at least according to existing empirical studies, not robust across systems. As a consequence, radically different processes may represent plausible driving mechanisms for propagation. Here, we analyze almost one billion time-stamped events collected from several online platforms \u2013 including Telegram, Twitter and Weibo over observation windows longer than ten years, show that the propagation is universal critical process. Universality arises identical macroscopic patterns platforms, irrespective details specific system hand. Critical behavior deduced power-law distributions, corresponding hyperscaling relations, characterizing size duration information. testing on our data indicates mixture simple complex contagion characterizes media. Data suggest complexity process correlated with semantic content propagated."
    ],
    "b_categories":[
      "Human Behaviors"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "Random graphs with arbitrary degree distributions and their applications"
    ],
    "c_abstract":[
      "Recent work on the structure of social networks and internet has focused attention graphs with distributions vertex degree that are significantly different from Poisson have been widely studied in past. In this paper we develop detail theory random arbitrary distributions. addition to simple undirected, unipartite graphs, examine properties directed bipartite graphs. Among other results, derive exact expressions for position phase transition at which a giant component first forms, mean size, size if there is one, number vertices certain distance away randomly chosen vertex, average vertex-vertex within graph. We apply our some real-world including world-wide web collaboration scientists Fortune 1000 company directors. demonstrate cases appropriate predict surprising accuracy behavior real world, while others measurable discrepancy between reality, perhaps indicating presence additional network not captured by"
    ],
    "c_categories":[
      "Modeling"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.00749",
    "a_title":"PathoGen-X: A Cross-Modal Genomic Feature Trans-Align Network for\n  Enhanced Survival Prediction from Histopathology Images",
    "a_abstract":"Accurate survival prediction is essential for personalized cancer treatment.\nHowever, genomic data - often a more powerful predictor than pathology data -\nis costly and inaccessible. We present the cross-modal genomic feature\ntranslation and alignment network for enhanced survival prediction from\nhistopathology images (PathoGen-X). It is a deep learning framework that\nleverages both genomic and imaging data during training, relying solely on\nimaging data at testing. PathoGen-X employs transformer-based networks to align\nand translate image features into the genomic feature space, enhancing weaker\nimaging signals with stronger genomic signals. Unlike other methods, PathoGen-X\ntranslates and aligns features without projecting them to a shared latent space\nand requires fewer paired samples. Evaluated on TCGA-BRCA, TCGA-LUAD, and\nTCGA-GBM datasets, PathoGen-X demonstrates strong survival prediction\nperformance, emphasizing the potential of enriched imaging models for\naccessible cancer prognosis.",
    "explanation":"Accurate survival prediction is essential for personalized\ncancer treatment. . It is a\ndeep learning framework that leverages both genomic and\nimaging data during training, relying solely on imaging data\nat testing. ",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "A 2021 update on cancer image analytics with deep learning"
    ],
    "b_abstract":[
      "Deep learning (DL)-based interpretation of medical images has reached a critical juncture of expanding outside research projects into translational ones, and is ready to make its way to the clinics. Advances over the last decade in data availability, DL techniques, as well as computing capabilities have accelerated this journey. Through this journey, today we have a better understanding of the challenges to and pitfalls of wider adoption of DL into clinical care, which, according to us, should and will drive the advances in this field in the next few years. The most important among these challenges are the lack of an appropriately digitized environment within healthcare institutions, the lack of adequate open and representative datasets on which DL algorithms can be trained and tested, and the lack of robustness of widely used DL training algorithms to certain pervasive pathological characteristics of medical images and repositories. In this review, we provide an overview of the role of imaging in oncology, the different techniques that are shaping the way DL algorithms are being made ready for clinical use, and also the problems that DL techniques still need to address before DL can find a home in clinics. Finally, we also provide a summary of how DL can potentially drive the adoption of digital pathology, vendor neutral archives, and picture archival and communication systems. We caution that the respective researchers may find the coverage of their own fields to be at a high-level. This is so by design as this format is meant to only introduce those looking in from outside of deep learning and medical research, respectively, to gain an appreciation for the main concerns and limitations of these two fields instead of telling them something new about their own."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classification"
    ],
    "c_abstract":[
      "Multiple instance learning (MIL) is a powerful tool to solve the weakly supervised classification in whole slide image (WSI) based pathology diagnosis. However, current MIL methods are usually on independent and identical distribution hypothesis, thus neglect correlation among different instances. To address this problem, we proposed new framework, called correlated MIL, provided proof for convergence. Based devised Transformer (TransMIL), which explored both morphological spatial information. The TransMIL can effectively deal with unbalanced\/balanced binary\/multiple great visualization interpretability. We conducted various experiments three computational problems achieved better performance faster convergence compared state-of-the-art methods. test AUC binary tumor be up 93.09% over CAMELYON16 dataset. And cancer subtypes 96.03% 98.82% TCGA-NSCLC dataset TCGA-RCC dataset, respectively. Implementation available at: https:\/\/github.com\/szc19990412\/TransMIL."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.00758",
    "a_title":"Inverse methods for freeform optical design",
    "a_abstract":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design, based on Hamilton's characteristic functions and\nconservation of luminous flux, and briefly explain the connection with the\nmathematical theory of optimal transport. We outline several iterative\nleast-squares solvers for our models and demonstrate their performance for a\nfew challenging problems.",
    "explanation":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design .We outline several iterative least-squares solvers for our models and demonstrate their\nperformance for a few challenging problems.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Introduction to Nonimaging Optics, second edition"
    ],
    "b_abstract":[
      "Introduction to Nonimaging Optics covers the theoretical foundations and design methods of nonimaging optics, as well as key concepts from related fields. This fully updated, revised, and expanded Second Edition: \u2022 Features a new and intuitive introduction with a basic description of the advantages of nonimaging optics \u2022 Adds new chapters on wavefronts for a prescribed output (irradiance or intensity), infinitesimal \u00e9tendue optics (generalization of the aplanatic optics), and K\u00f6hler optics and color mixing \u2022 Incorporates new material on the simultaneous multiple surface (SMS) design method in 3-D, integral invariants, and \u00e9tendue 2-D \u2022 Contains 21 chapters, 24 fully worked and several other examples, and 1,000+ illustrations, including photos of real devices \u2022 Addresses applications ranging from solar energy concentration to illumination engineering Introduction to Nonimaging Optics, Second Edition invites newcomers to explore the growing field of nonimaging optics, while providing seasoned veterans with an extensive reference book."
    ],
    "b_categories":[
      "physics.optics"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "Inverse methods for illumination optics"
    ],
    "c_abstract":[
      "\u2022 A submitted manuscript is the version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website. \u2022 The final author version and the galley proof are versions of the publication after peer review. \u2022 The final published version features the final layout of the paper including the volume, issue and page numbers."
    ],
    "c_categories":[
      "math.MP"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.01291",
    "a_title":"Deep Multi-contrast Cardiac MRI Reconstruction via vSHARP with Auxiliary\n  Refinement Network",
    "a_abstract":"Cardiac MRI (CMRI) is a cornerstone imaging modality that provides in-depth\ninsights into cardiac structure and function. Multi-contrast CMRI (MCCMRI),\nwhich acquires sequences with varying contrast weightings, significantly\nenhances diagnostic capabilities by capturing a wide range of cardiac tissue\ncharacteristics. However, MCCMRI is often constrained by lengthy acquisition\ntimes and susceptibility to motion artifacts. To mitigate these challenges,\naccelerated imaging techniques that use k-space undersampling via different\nsampling schemes at acceleration factors have been developed to shorten scan\ndurations. In this context, we propose a deep learning-based reconstruction\nmethod for 2D dynamic multi-contrast, multi-scheme, and multi-acceleration MRI.\nOur approach integrates the state-of-the-art vSHARP model, which utilizes\nhalf-quadratic variable splitting and ADMM optimization, with a Variational\nNetwork serving as an Auxiliary Refinement Network (ARN) to better adapt to the\ndiverse nature of MCCMRI data. Specifically, the subsampled k-space data is fed\ninto the ARN, which produces an initial prediction for the denoising step used\nby vSHARP. This, along with the subsampled k-space, is then used by vSHARP to\ngenerate high-quality 2D sequence predictions. Our method outperforms\ntraditional reconstruction techniques and other vSHARP-based models.",
    "explanation":"Cardiac MRI (CMRI) is a cornerstone imaging modality that\nprovides in-depth insights into cardiac structure and function.  Our approach integrates the state-of-the-art vSHARP model, which uti-\nlizes half-quadratic variable splitting and ADMM optimization, with a\nVariational Network serving as an Auxiliary Refinement Network (ARN)\nto better adapt to the diverse nature of MCCMRI data. ",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting\n  Universal Machine Learning for Accelerated Cardiac MRI"
    ],
    "b_abstract":[
      "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically gold-standard technique for diagnosing cardiac diseases, thanks to its ability provide diverse information with multiple modalities and anatomical views. Accelerated MRI is highly expected achieve time-efficient patient-friendly imaging, then advanced image reconstruction approaches are required recover high-quality, interpretable images from undersampled measurements. However, the lack of publicly available k-space dataset in terms both quantity diversity severely hindered substantial technological progress, particularly data-driven artificial intelligence. Here, we standardized, diverse, high-quality CMRxRecon2024 facilitate technical development, fair evaluation, clinical transfer approaches, towards promoting universal frameworks that enable fast robust reconstructions across different protocols practice. To best our knowledge, largest most dataset. It acquired 330 healthy volunteers, covering commonly used modalities, views, acquisition trajectories workflows. Besides, an open platform tutorials, benchmarks, data processing tools provided usage, method performance evaluation."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b19"
    ],
    "c_title":[
      "vSHARP: variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse-Problems"
    ],
    "c_abstract":[
      "Medical Imaging (MI) tasks, such as accelerated parallel Magnetic Resonance Imaging (MRI), often involve reconstructing an image from noisy or incomplete measurements. This amounts to solving ill-posed inverse problems, where a satisfactory closed-form analytical solution is not available. Traditional methods such as Compressed Sensing (CS) in MRI reconstruction can be time-consuming or prone to obtaining low-fidelity images. Recently, a plethora of Deep Learning (DL) approaches have demonstrated superior performance in inverse-problem solving, surpassing conventional methods. In this study, we propose vSHARP (variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse Problems), a novel DL-based method for solving ill-posed inverse problems arising in MI. vSHARP utilizes the Half-Quadratic Variable Splitting method and employs the Alternating Direction Method of Multipliers (ADMM) to unroll the optimization process. For data consistency, vSHARP unrolls a differentiable gradient descent process in the image domain, while a DL-based denoiser, such as a U-Net architecture, is applied to enhance image quality. vSHARP also employs a dilated-convolution DL-based model to predict the Lagrange multipliers for the ADMM initialization. We evaluate vSHARP on tasks of accelerated parallel MRI Reconstruction using two distinct datasets and on accelerated parallel dynamic MRI Reconstruction using another dataset. Our comparative analysis with state-of-the-art methods demonstrates the superior performance of vSHARP in these applications."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01758",
    "a_title":"Disentangled PET Lesion Segmentation",
    "a_abstract":"PET imaging is an invaluable tool in clinical settings as it captures the\nfunctional activity of both healthy anatomy and cancerous lesions. Developing\nautomatic lesion segmentation methods for PET images is crucial since manual\nlesion segmentation is laborious and prone to inter- and intra-observer\nvariability. We propose PET-Disentangler, a 3D disentanglement method that uses\na 3D UNet-like encoder-decoder architecture to disentangle disease and normal\nhealthy anatomical features with losses for segmentation, reconstruction, and\nhealthy component plausibility. A critic network is used to encourage the\nhealthy latent features to match the distribution of healthy samples and thus\nencourages these features to not contain any lesion-related features. Our\nquantitative results show that PET-Disentangler is less prone to incorrectly\ndeclaring healthy and high tracer uptake regions as cancerous lesions, since\nsuch uptake pattern would be assigned to the disentangled healthy component.",
    "explanation":"PET imaging is an invaluable tool in clinical settings as it\ncaptures the functional activity of both healthy anatomy and\ncancerous lesions. Developing automatic lesion segmentation\nmethods for PET images is crucial since manual lesion seg-\nmentation is laborious and prone to inter- and intra-observer\nvariability. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Multi-site quality and variability analysis of 3D FDG PET segmentations based on phantom and clinical image data"
    ],
    "b_abstract":[
      "Purpose: Radiomics utilizes a large number of image-derived features for quantifying tumor characteristics that can in turn be correlated with response and prognosis. Unfortunately, extraction and analysis of such image-based features is subject to measurement variability and bias. The challenge for radiomics is particularly acute in Positron Emission Tomography (PET) where limited resolution, a high noise component related to the limited stochastic nature of the raw data, and the wide variety of reconstruction options confound quantitative feature metrics. Extracted feature quality is also affected by tumor segmentation methods used to define regions over which to calculate features, making it challenging to produce consistent radiomics analysis results across multiple institutions that use different segmentation algorithms in their PET image analysis. Understanding each element contributing to these inconsistencies in quantitative image feature and metric generation is paramount for ultimate utilization of these methods in multi-institutional trials and clinical oncology decision making. Methods: To assess segmentation quality and consistency at the multi-institutional level, we conducted a study of seven institutional members of the National Cancer Institute Quantitative Imaging Network. For the study, members were asked to segment a common set of phantom PET scans acquired over a range of imaging conditions as well as a second set of head and neck cancer (HNC) PET scans. Segmentations were generated at each institution using their preferred approach. In addition, participants were asked to repeat segmentations with a time interval between initial and repeat segmentation. This procedure resulted in overall 806 phantom insert and 641 lesion segmentations. Subsequently, the volume was computed from the segmentations and compared to the corresponding reference volume by means of statistical analysis. Results: On the two test sets (phantom and HNC PET scans), the performance of the seven segmentation approaches was as follows. On the phantom test set, the mean relative volume errors ranged from 29.9 to 87.8% of the ground truth reference volumes, and the repeat difference for each institution ranged between -36.4 to 39.9%. On the HNC test set, the mean relative volume error ranged between -50.5 to 701.5%, and the repeat difference for each institution ranged between -37.7 to 31.5%. In addition, performance measures per phantom insert\/lesion size categories are given in the paper. On phantom data, regression analysis resulted in coefficient of variation (CV) components of 42.5% for scanners, 26.8% for institutional approaches, 21.1% for repeated segmentations, 14.3% for relative contrasts, 5.3% for count statistics (acquisition times), and 0.0% for repeated scans. Analysis showed that the CV components for approaches and repeated segmentations were significantly larger on the HNC test set with increases by 112.7% and 102.4%, respectively. Conclusion: Analysis results underline the importance of PET scanner reconstruction harmonization and imaging protocol standardization for quantification of lesion volumes. In addition, to enable a distributed multi-site analysis of FDG PET images, harmonization of analysis approaches and operator training in combination with highly automated segmentation methods seems to be advisable. Future work will focus on quantifying the impact of segmentation variation on radiomics system performance."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b2"
    ],
    "c_title":[
      "A review on segmentation of positron emission tomography images"
    ],
    "c_abstract":[
      "Positron Emission Tomography (PET), a non-invasive functional imaging method at the molecular level, images the distribution of biologically targeted radiotracers with high sensitivity. PET imaging provides detailed quantitative information about many diseases and is often used to evaluate inflammation, infection, and cancer by detecting emitted photons from a radiotracer localized to abnormal cells. In order to differentiate abnormal tissue from surrounding areas in PET images, image segmentation methods play a vital role; therefore, accurate image segmentation is often necessary for proper disease detection, diagnosis, treatment planning, and follow-ups. In this review paper, we present state-of-the-art PET image segmentation methods, as well as the recent advances in image segmentation techniques. In order to make this manuscript self-contained, we also briefly explain the fundamentals of PET imaging, the challenges of diagnostic PET image analysis, and the effects of these challenges on the segmentation results."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03389",
    "a_title":"Neurons for Neutrons: A Transformer Model for Computation Load\n  Estimation on Domain-Decomposed Neutron Transport Problems",
    "a_abstract":"Domain decomposition is a technique used to reduce memory overhead on large\nneutron transport problems. Currently, the optimal load-balanced processor\nallocation for these domains is typically determined through small-scale\nsimulations of the problem, which can be time-consuming for researchers and\nmust be repeated anytime a problem input is changed. We propose a Transformer\nmodel with a unique 3D input embedding, and input representations designed for\ndomain-decomposed neutron transport problems, which can predict the subdomain\ncomputation loads generated by small-scale simulations. We demonstrate that\nsuch a model trained on domain-decomposed Small Modular Reactor (SMR)\nsimulations achieves 98.2% accuracy while being able to skip the small-scale\nsimulation step entirely. Tests of the model's robustness on variant fuel\nassemblies, other problem geometries, and changes in simulation parameters are\nalso discussed.",
    "explanation":"Currently, the optimal load-\nbalanced processor allocation for these domains is typically determined\nthrough small-scale simulations of the problem, which can be time-consuming\nfor researchers and must be repeated anytime a problem input is changed.\nWe propose a Transformer model with a unique 3D input embedding, and\ninput representations designed for domain-decomposed neutron transport\nproblems, which can predict the subdomain computation loads generated\nby small-scale simulations.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Attention Is All You Need"
    ],
    "b_abstract":[
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. best performing also connect the encoder and decoder through attention mechanism. We propose a new simple network architecture, Transformer, solely mechanisms, dispensing with recurrence convolutions entirely. Experiments two machine translation tasks show these to be superior quality while being more parallelizable requiring significantly less time train. Our model achieves 28.4 BLEU WMT 2014 English-to-German task, improving over existing results, including ensembles by 2 BLEU. On English-to-French our establishes single-model state-of-the-art score of 41.8 after training for 3.5 days eight GPUs, small fraction costs from literature. that Transformer generalizes well other applying it successfully English constituency parsing both large limited data."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Continuous-energy Monte Carlo neutron transport on GPUs in the Shift code"
    ],
    "c_abstract":[
      "A continuous-energy Monte Carlo neutron transport solver executing on GPUs has been developed within the Shift code. Several algorithmic approaches are considered, including both history-based and event-based implementations. Unlike in previous work involving multigroup Monte Carlo transport, it is demonstrated that event-based algorithms significantly outperform a history-based approach for continuous-energy transport as a result of increased device occupancy and reduced thread divergence. Numerical results are presented for detailed full-core models of a small modular reactor (SMR), including a model containing depleted fuel materials. These results demonstrate the substantial gains in performance that are possible with the latest-generation of GPUs. On the depleted SMR core configuration, an NVIDIA P100 GPU with 56 streaming multiprocessors provides performance equivalent to 90 CPU cores, and the latest V100 GPU with 80 multiprocessors offers the performance of more than 150 CPU cores."
    ],
    "c_categories":[
      "astro-ph.HE"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04682",
    "a_title":"DNN-based 3D Cloud Retrieval for Variable Solar Illumination and\n  Multiview Spaceborne Imaging",
    "a_abstract":"Climate studies often rely on remotely sensed images to retrieve\ntwo-dimensional maps of cloud properties. To advance volumetric analysis, we\nfocus on recovering the three-dimensional (3D) heterogeneous extinction\ncoefficient field of shallow clouds using multiview remote sensing data.\nClimate research requires large-scale worldwide statistics. To enable scalable\ndata processing, previous deep neural networks (DNNs) can infer at spaceborne\nremote sensing downlink rates. However, prior methods are limited to a fixed\nsolar illumination direction. In this work, we introduce the first scalable\nDNN-based system for 3D cloud retrieval that accommodates varying camera poses\nand solar directions. By integrating multiview cloud intensity images with\ncamera poses and solar direction data, we achieve greater flexibility in\nrecovery. Training of the DNN is performed by a novel two-stage scheme to\naddress the high number of degrees of freedom in this problem. Our approach\nshows substantial improvements over previous state-of-the-art, particularly in\nhandling variations in the sun's zenith angle.",
    "explanation":"Climate studies often rely on remotely sensed im-\nages to retrieve two-dimensional maps of cloud properties. To\nadvance volumetric analysis, we focus on recovering the three-\ndimensional (3D) heterogeneous extinction coefficient field of\nshallow clouds using multiview remote sensing data. \n\n\nTo enable\nscalable data processing, previous deep neural networks (DNNs)\ncan infer at spaceborne remote sensing downlink rates. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Distributed Sky Imaging Radiometry and Tomography"
    ],
    "b_abstract":[
      "The composition of the atmosphere is significant to our ecosystem. Accordingly, there a need sense distributions atmospheric scatterers such as aerosols and cloud droplets. There growing interest in recovering these scattering fields three-dimensions (3D). Even so, current observations usually use expensive unscalable equipment. Moreover, analysis retrieves partial information (e.g., cloud-base altitudes, water droplet size at tops) based on simplified 1D models. To advance retrievals, we develop new computational imaging approach for sensing analyzing atmosphere, volumetrically. Our comprises ground-based network cameras. We deployed it conjunction with additional remote equipment, including Raman lidar sunphotometer, which provide initialization algorithms ground truth. camera scalable, low cost, enables 3D high spatial temporal resolution. describe how system calibrated absolute radiometric readouts light field. Consequently, recover volumetric field scatterers, using tomography. tomography process adapted relative prior art, run large-scale domains being in-situ within scatterer fields. empirically demonstrate feasibility clouds, data."
    ],
    "b_categories":[
      "astro-ph.EP"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "Variable Imaging Projection Cloud Scattering Tomography"
    ],
    "c_abstract":[
      "Scattering-based computed tomography (CT) recovers a heterogeneous volumetric scattering medium using images taken from multiple directions. It is nonlinear problem. Prior art mainly approached it by explicit physics-based optimization of image-fitting, being slow and difficult to scale. Scale particularly important when the objects constitute large cloud fields, where recovery for climate studies. Besides speed, imaging need be flexible, efficiently handle variable viewing geometries resolutions. These can caused perturbation in camera poses or fusion data different types observational sensors. There fast projection clouds (VIP-CT). We develop learning-based solution, deep-neural network (DNN) which trains on labeled dataset. The DNN parameters are oblivious domain scale, hence work with arbitrarily domains. VIP-CT offers much better quality than state art. inference speed flexibility make effectively real-time context spaceborne observations. paper first demonstrate CT real empirical directly DNN. may offer model solution problems other scientific Our code available online."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.03156",
    "a_title":"Unleashing the power of novel conditional generative approaches for new\n  materials discovery",
    "a_abstract":"For a very long time, computational approaches to the design of new materials\nhave relied on an iterative process of finding a candidate material and\nmodeling its properties. AI has played a crucial role in this regard, helping\nto accelerate the discovery and optimization of crystal properties and\nstructures through advanced computational methodologies and data-driven\napproaches. To address the problem of new materials design and fasten the\nprocess of new materials search, we have applied latest generative approaches\nto the problem of crystal structure design, trying to solve the inverse\nproblem: by given properties generate a structure that satisfies them without\nutilizing supercomputer powers. In our work we propose two approaches: 1)\nconditional structure modification: optimization of the stability of an\narbitrary atomic configuration, using the energy difference between the most\nenergetically favorable structure and all its less stable polymorphs and 2)\nconditional structure generation. We used a representation for materials that\nincludes the following information: lattice, atom coordinates, atom types,\nchemical features, space group and formation energy of the structure. The loss\nfunction was optimized to take into account the periodic boundary conditions of\ncrystal structures. We have applied Diffusion models approach, Flow matching,\nusual Autoencoder (AE) and compared the results of the models and approaches.\nAs a metric for the study, physical PyMatGen matcher was employed: we compare\ntarget structure with generated one using default tolerances. So far, our\nmodifier and generator produce structures with needed properties with accuracy\n41% and 82% respectively. To prove the offered methodology efficiency,\ninference have been carried out, resulting in several potentially new\nstructures with formation energy below the AFLOW-derived convex hulls.",
    "explanation":"\" In our work we propose two approaches: 1) conditional structure modification: optimization of the stability of an arbitrary atomic configuration, using the energy difference between the most energetically favorable structure and all its less stable polymorphs and 2) conditional structure generation.\"",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Physics guided deep learning for generative design of crystal materials with symmetry constraints"
    ],
    "b_abstract":[
      "Abstract Discovering new materials is a challenging task in science crucial to the progress of human society. Conventional approaches based on experiments and simulations are labor-intensive or costly with success heavily depending experts\u2019 heuristic knowledge. Here, we propose deep learning Physics Guided Crystal Generative Model (PGCGM) for efficient crystal material design high structural diversity symmetry. Our model increases generation validity by more than 700% compared FTCP, one latest structure generators 45% our previous CubicGAN model. Density Functional Theory (DFT) calculations used validate generated structures 1869 out 2000 successfully optimized deposited into Carolina Materials Database www.carolinamatdb.org , which 39.6% have negative formation energy 5.3% energy-above-hull less 0.25 eV\/atom, indicating their thermodynamic stability potential synthesizability."
    ],
    "b_categories":[
      "physics.comp-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "High\u2010Throughput Discovery of Novel Cubic Crystal Materials Using Deep Generative Neural Networks"
    ],
    "c_abstract":[
      "Abstract High\u2010throughput screening has become one of the major strategies for discovery novel functional materials. However, its effectiveness is severely limited by lack sufficient and diverse materials in current repositories such as open quantum database (OQMD). Recent progress deep learning have enabled generative that learn implicit chemical rules creating hypothetical with new compositions structures. models difficulty generating structurally diverse, chemically valid, stable Here we propose CubicGAN, a adversarial network (GAN) based neural model large scale design cubic When trained on 375 749 ternary from OQMD database, authors show able to not only rediscover most currently known but also generate structure prototypes. A total 506 been verified phonon dispersion calculation. Considering importance wide applications solar panels, GAN provides promising approach significantly expand existing repositories, enabling via screening. The crystal structures discovered are freely accessible at www.carolinamatdb.org ."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.17907",
    "a_title":"A Multimodal Emotion Recognition System: Integrating Facial Expressions,\n  Body Movement, Speech, and Spoken Language",
    "a_abstract":"Traditional psychological evaluations rely heavily on human observation and\ninterpretation, which are prone to subjectivity, bias, fatigue, and\ninconsistency. To address these limitations, this work presents a multimodal\nemotion recognition system that provides a standardised, objective, and\ndata-driven tool to support evaluators, such as psychologists, psychiatrists,\nand clinicians. The system integrates recognition of facial expressions,\nspeech, spoken language, and body movement analysis to capture subtle emotional\ncues that are often overlooked in human evaluations. By combining these\nmodalities, the system provides more robust and comprehensive emotional state\nassessment, reducing the risk of mis- and overdiagnosis. Preliminary testing in\na simulated real-world condition demonstrates the system's potential to provide\nreliable emotional insights to improve the diagnostic accuracy. This work\nhighlights the promise of automated multimodal analysis as a valuable\ncomplement to traditional psychological evaluation practices, with applications\nin clinical and therapeutic settings.",
    "explanation":"Traditional psychological evaluations rely heavily\non human observation and interpretation, which are prone to\nsubjectivity, bias, fatigue, and inconsistency. To address these\nlimitations, this work presents a multimodal emotion recognition\nsystem that provides a standardised, objective, and data-driven\ntool to support evaluators, such as psychologists, psychiatrists,\nand clinicians.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Deep Facial Expression Recognition: A Survey"
    ],
    "b_abstract":[
      "With the transition of facial expression recognition (FER) from laboratory-controlled to challenging in-the-wild conditions and recent success deep learning techniques in various fields, neural networks have increasingly been leveraged learn discriminative representations for automatic FER. Recent FER systems generally focus on two important issues: overfitting caused by a lack sufficient training data expression-unrelated variations, such as illumination, head pose identity bias. In this paper, we provide comprehensive survey FER, including datasets algorithms that insights into these intrinsic problems. First, describe standard pipeline system with related background knowledge suggestions applicable implementations each stage. We then introduce available are widely used literature accepted selection evaluation principles datasets. For state art review existing novel strategies designed based both static images dynamic image sequences, discuss their advantages limitations. Competitive performances benchmarks also summarized section. extend our additional issues application scenarios. Finally, remaining challenges corresponding opportunities field well future directions design robust systems."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Recognizing and reducing cognitive bias in clinical and forensic neurology"
    ],
    "c_abstract":[
      "In medicine, cognitive errors form the basis of bias in clinical practice. Several types are common and pervasive, may lead to inaccurate diagnosis or treatment. Forensic neurology, even when aided by current technologies, still dependent on interpretations, therefore prone bias. This article discusses 4 biases that can clinician astray. They confirmation (selective gathering neglect contradictory evidence); base rate (ignoring misusing prevailing data); hindsight (oversimplification past causation); good old days (the tendency for patients misremember exaggerate their preinjury functioning). We briefly describe strategies adopted from field psychology could minimize While debiasing is not easy, reducing such requires awareness acknowledgment our susceptibility these distortions."
    ],
    "c_categories":[
      "Clinical Neurology"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05055",
    "a_title":"Integrating Large Language Models for Genetic Variant Classification",
    "a_abstract":"The classification of genetic variants, particularly Variants of Uncertain\nSignificance (VUS), poses a significant challenge in clinical genetics and\nprecision medicine. Large Language Models (LLMs) have emerged as transformative\ntools in this realm. These models can uncover intricate patterns and predictive\ninsights that traditional methods might miss, thus enhancing the predictive\naccuracy of genetic variant pathogenicity.\n  This study investigates the integration of state-of-the-art LLMs, including\nGPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for\nvariant classification. Our approach evaluates these integrated models using\nthe well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in\nclassification performance. The models were rigorously tested on a set of\nchallenging variants, demonstrating substantial improvements over existing\nstate-of-the-art tools, especially in handling ambiguous and clinically\nuncertain variants.\n  The results of this research underline the efficacy of combining multiple\nmodeling approaches to significantly refine the accuracy and reliability of\ngenetic variant classification systems. These findings support the deployment\nof these advanced computational models in clinical environments, where they can\nsignificantly enhance the diagnostic processes for genetic disorders,\nultimately pushing the boundaries of personalized medicine by offering more\ndetailed and actionable genetic insights.",
    "explanation":"This study investigates the integration of state-of-the-art LLMs,\nincluding GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for variant classification.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"
    ],
    "b_abstract":[
      "TensorFlow is an interface for expressing machine learning algorithms, and implementation executing such algorithms. A computation expressed using can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices as phones tablets up to large-scale distributed systems hundreds machines thousands computational GPU cards. The system flexible used express including training inference algorithms deep neural network models, it has been conducting research deploying into production across more than dozen areas computer science other fields, speech recognition, vision, robotics, information retrieval, natural language processing, geographic extraction, drug discovery. This paper describes the that we have built at Google. API reference were released open-source package under Apache 2.0 license in November, 2015 are available www.tensorflow.org."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Predicting Functional Effect of Human Missense Mutations Using PolyPhen\u20102"
    ],
    "c_abstract":[
      "Abstract PolyPhen\u20102 (Polymorphism Phenotyping v2), available as software and via a Web server, predicts the possible impact of amino acid substitutions on stability function human proteins using structural comparative evolutionary considerations. It performs functional annotation single\u2010nucleotide polymorphisms (SNPs), maps coding SNPs to gene transcripts, extracts protein sequence annotations attributes, builds conservation profiles. then estimates probability missense mutation being damaging based combination all these properties. features include high\u2010quality multiple alignment pipeline prediction method employing machine\u2010learning classification. The also integrates UCSC Genome Browser's genome MultiZ alignments vertebrate genomes with genome. is capable analyzing large volumes data produced by next\u2010generation sequencing projects, thanks built\u2010in support for high\u2010performance computing environments like Grid Engine Platform LSF. Curr. Protoc. Hum. Genet . 76:7.20.1\u20107.20.41. \u00a9 2013 John Wiley &amp; Sons, Inc."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.18156",
    "a_title":"scReader: Prompting Large Language Models to Interpret scRNA-seq Data",
    "a_abstract":"Large language models (LLMs) have demonstrated remarkable advancements,\nprimarily due to their capabilities in modeling the hidden relationships within\ntext sequences. This innovation presents a unique opportunity in the field of\nlife sciences, where vast collections of single-cell omics data from multiple\nspecies provide a foundation for training foundational models. However, the\nchallenge lies in the disparity of data scales across different species,\nhindering the development of a comprehensive model for interpreting genetic\ndata across diverse organisms. In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of LLMs with\ndomain-specific representation models for single-cell omics data\ninterpretation. We begin by focusing on genes as the fundamental unit of\nrepresentation. Gene representations are initialized using functional\ndescriptions, leveraging the strengths of mature language models such as\nLLaMA-2. By inputting single-cell gene-level expression data with prompts, we\neffectively model cellular representations based on the differential expression\nlevels of genes across various species and cell types. In the experiments, we\nconstructed developmental cells from humans and mice, specifically targeting\ncells that are challenging to annotate. We evaluated our methodology through\nbasic tasks such as cell annotation and visualization analysis. The results\ndemonstrate the efficacy of our approach compared to other methods using LLMs,\nhighlighting significant improvements in accuracy and interoperability. Our\nhybrid approach enhances the representation of single-cell data and offers a\nrobust framework for future research in cross-species genetic analysis.",
    "explanation":". In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of\nLLMs with domain-specific representation models for single-cell\nomics data interpretation.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Llamafactory: Unified efficient fine-tuning of 100+ language models"
    ],
    "b_abstract":[
      "Efficient fine-tuning is vital for adapting large language models (LLMs) to downstream tasks. However, it requires non-trivial efforts to implement these methods on different models. We present LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It provides a solution for flexibly customizing the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard. We empirically validate the efficiency and effectiveness of our framework on language modeling and text generation tasks."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b18"
    ],
    "c_title":[
      "GeneCompass: Deciphering Universal Gene Regulatory Mechanisms with Knowledge-Informed Cross-Species Foundation Model"
    ],
    "c_abstract":[
      "Abstract Deciphering the universal gene regulatory mechanisms in diverse organisms holds great potential to advance our knowledge of fundamental life process and facilitate research on clinical applications. However, traditional paradigm primarily focuses individual model organisms, resulting limited collection integration complex features various cell types across species. Recent breakthroughs single-cell sequencing advancements deep learning techniques present an unprecedented opportunity tackle this challenge. In study, we developed GeneCompass, first knowledge-informed, cross-species foundation pre-trained extensive dataset over 120 million transcriptomes from human mouse. During pre-training, GeneCompass effectively integrates four biological prior enhance understanding a self-supervised manner. Fine-tuning towards multiple downstream tasks, outperforms competing state-of-the-art models tasks single species unlocks new realms investigation. Overall, marks milestone advancing accelerating discovery key fate regulators candidate targets for drug development."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.07871",
    "a_title":"Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in\n  Alzheimer's Disease",
    "a_abstract":"The rapid advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have shown great potential in medical diagnostics, particularly\nin radiology, where datasets such as X-rays are paired with human-generated\ndiagnostic reports. However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer's disease, due\nto the lack of comprehensive diagnostic reports that can be utilized for model\nfine-tuning. This paper addresses this gap by generating synthetic diagnostic\nreports using GPT-4o-mini on structured data from the OASIS-4 dataset, which\ncomprises 663 patients. Using the synthetic reports as ground truth for\ntraining and validation, we then generated neurological reports directly from\nthe images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.\nOur proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,\nand METEOR score of 0.4163, revealing its potential in generating clinically\nrelevant and accurate diagnostic reports.",
    "explanation":"However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer\u2019s\ndisease, due to the lack of comprehensive diagnostic reports that\ncan be utilized for model fine-tuning. This paper addresses this\ngap by generating synthetic diagnostic reports using GPT-4o-mini\non structured data from the OASIS-4 dataset, which comprises\n663 patients",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "2016 Alzheimer's disease facts and figures"
    ],
    "b_abstract":[
      "This report describes the public health impact of Alzheimer's disease, including incidence and prevalence, mortality rates, costs care, overall on caregivers society. It also examines in detail financial families, annual to families difficult decisions must often make pay those costs. An estimated 5.4 million Americans have disease. By mid-century, number people living with disease United States is projected grow 13.8 million, fueled large part by aging baby boom generation. Today, someone country develops every 66 seconds. 2050, one new case expected develop 33 seconds, resulting nearly 1 cases per year. In 2013, official death certificates recorded 84,767 deaths from making it sixth leading cause fifth age \u2265 65 years. Between 2000 stroke, heart prostate cancer decreased 23%, 14%, 11%, respectively, whereas increased 71%. The actual which contributes likely much larger than certificates. 2016, an 700,000 years will die many them because complications caused 2015, more 15 family members other unpaid provided 18.1 billion hours care dementias, a contribution valued at $221 billion. Average per-person Medicare payments for services beneficiaries dementias are two half times as great all without these conditions, Medicaid 19 great. Total 2016 long-term hospice dementia be $236 may place substantial burden who take money out their retirement savings, cut back buying food, reduce own trips doctor. addition, incorrectly believe that pays nursing home types care. Such findings highlight need solutions prevent dementia-related jeopardizing security dementias."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Computer-aided diagnosis of Alzheimer\u2019s disease and neurocognitive disorders with multimodal Bi-Vision Transformer (BiViT)"
    ],
    "c_abstract":[
      "<jats:title>Abstract<\/jats:title><jats:p>Cognitive disorders affect various cognitive functions that can have a substantial impact on individual\u2019s daily life. Alzheimer\u2019s disease (AD) is one of such well-known cognitive disorders. Early detection and treatment of cognitive diseases using artificial intelligence can help contain them. However, the complex spatial relationships and long-range dependencies found in medical imaging data present challenges in achieving the objective. Moreover, for a few years, the application of transformers in imaging has emerged as a promising area of research. A reason can be transformer\u2019s impressive capabilities of tackling spatial relationships and long-range dependency challenges in two ways, i.e., (1) using their self-attention mechanism to generate comprehensive features, and (2) capture complex patterns by incorporating global context and long-range dependencies. In this work, a Bi-Vision Transformer (BiViT) architecture is proposed for classifying different stages of AD, and multiple types of cognitive disorders from 2-dimensional MRI imaging data. More specifically, the transformer is composed of two novel modules, namely Mutual Latent Fusion (MLF) and Parallel Coupled Encoding Strategy (PCES), for effective feature learning. Two different datasets have been used to evaluate the performance of proposed BiViT-based architecture. The first dataset contain several classes such as mild or moderate demented stages of the AD. The other dataset is composed of samples from patients with AD and different cognitive disorders such as mild, early, or moderate impairments. For comprehensive comparison, a multiple transfer learning algorithm and a deep autoencoder have been each trained on both datasets. The results show that the proposed BiViT-based model achieves an accuracy of 96.38% on the AD dataset. However, when applied to cognitive disease data, the accuracy slightly decreases below 96% which can be resulted due to smaller amount of data and imbalance in data distribution. Nevertheless, given the results, it can be hypothesized that the proposed algorithm can perform better if the imbalanced distribution and limited availability problems in data can be addressed.<\/jats:p>\n                <jats:p><jats:bold>Graphical abstract<\/jats:bold><\/jats:p>"
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.08073",
    "a_title":"LoRA-BERT: a Natural Language Processing Model for Robust and Accurate\n  Prediction of long non-coding RNAs",
    "a_abstract":"Long non-coding RNAs (lncRNAs) serve as crucial regulators in numerous\nbiological processes. Although they share sequence similarities with messenger\nRNAs (mRNAs), lncRNAs perform entirely different roles, providing new avenues\nfor biological research. The emergence of next-generation sequencing\ntechnologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify\nlong non-coding RNAs (lncRNAs). These advanced methods have significantly\nenhanced the efficiency of identifying lncRNAs. However, many of these methods\nare devoid of robustness and accuracy due to the extended length of the\nsequences involved. To tackle this issue, we have introduced a novel\npre-trained bidirectional encoder representation called LoRA-BERT. LoRA-BERT is\ndesigned to capture the importance of nucleotide-level information during\nsequence classification, leading to more robust and satisfactory outcomes. In a\ncomprehensive comparison with commonly used sequence prediction tools, we have\ndemonstrated that LoRA-BERT outperforms them in terms of accuracy and\nefficiency. Our results indicate that, when utilizing the transformer model,\nLoRA-BERT achieves state-of-the-art performance in predicting both lncRNAs and\nmRNAs for human and mouse species. Through the utilization of LoRA-BERT, we\nacquire valuable insights into the traits of lncRNAs and mRNAs, offering the\npotential to aid in the comprehension and detection of diseases linked to\nlncRNAs in humans.",
    "explanation":"The emergence of next-\ngeneration sequencing technologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify long non-coding\nRNAs (lncRNAs). ",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome"
    ],
    "b_abstract":[
      "Abstract Motivation Deciphering the language of non-coding DNA is one fundamental problems in genome research. Gene regulatory code highly complex due to existence polysemy and distant semantic relationship, which previous informatics methods often fail capture especially data-scarce scenarios. Results To address this challenge, we developed a novel pre-trained bidirectional encoder representation, named DNABERT, global transferrable understanding genomic sequences based on up downstream nucleotide contexts. We compared DNABERT most widely used programs for genome-wide elements prediction demonstrate its ease use, accuracy efficiency. show that single transformers model can simultaneously achieve state-of-the-art performance promoters, splice sites transcription factor binding sites, after easy fine-tuning using small task-specific labeled data. Further, enables direct visualization nucleotide-level importance relationship within input better interpretability accurate identification conserved sequence motifs functional genetic variant candidates. Finally, with human even be readily applied other organisms exceptional performance. anticipate fined tuned many analyses tasks. Availability implementation The source code, pretrained finetuned are available at GitHub (https:\/\/github.com\/jerryji1993\/DNABERT). Supplementary information data Bioinformatics online."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b20"
    ],
    "c_title":[
      "A primer on deep learning in genomics"
    ],
    "c_abstract":[
      "Deep learning methods are a class of machine learning techniques capable of identifying highly complex patterns in large datasets. Here, we provide a perspective and primer on deep learning applications for genome analysis. We discuss successful applications in the fields of regulatory genomics, variant calling and pathogenicity scores. We include general guidance for how to effectively use deep learning methods as well as a practical guide to tools and resources. This primer is accompanied by an interactive online tutorial."
    ],
    "c_categories":[
      "q-bio.GN"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.08664",
    "a_title":"UniMat: Unifying Materials Embeddings through Multi-modal Learning",
    "a_abstract":"Materials science datasets are inherently heterogeneous and are available in\ndifferent modalities such as characterization spectra, atomic structures,\nmicroscopic images, and text-based synthesis conditions. The advancements in\nmulti-modal learning, particularly in vision and language models, have opened\nnew avenues for integrating data in different forms. In this work, we evaluate\ncommon techniques in multi-modal learning (alignment and fusion) in unifying\nsome of the most important modalities in materials science: atomic structure,\nX-ray diffraction patterns (XRD), and composition. We show that structure graph\nmodality can be enhanced by aligning with XRD patterns. Additionally, we show\nthat aligning and fusing more experimentally accessible data formats, such as\nXRD patterns and compositions, can create more robust joint embeddings than\nindividual modalities across various tasks. This lays the groundwork for future\nstudies aiming to exploit the full potential of multi-modal data in materials\nscience, facilitating more informed decision-making in materials design and\ndiscovery.",
    "explanation":"n this work, we evaluate common techniques in multi-modal learning\n(alignment and fusion) in unifying some of the most important modalities in materials\nscience: atomic structure, X-ray diffraction patterns (XRD), and composition.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Comprehensive Inorganic Chemistry III (Third Edition)"
    ],
    "b_abstract":[
      "Comprehensive Inorganic Chemistry III, a ten-volume reference work, is intended to cover fundamental principles, recent discoveries, and significant applications of elements and their compounds. Authored by renowned experts in the field and edited by a world-class editorial board, each chapter provides a thorough and in-depth overview of the topic covered, featuring resources which will be useful to students, researchers, faculty as well as those in the industry. Comprehensive Inorganic Chemistry III focuses on main group chemistry, biological inorganic chemistry, solid state and materials chemistry, catalysis, and new developments in electrochemistry and photochemistry, as well as NMR and diffraction methods for studying inorganic compounds. The work expands on our 2013 work Comprehensive Inorganic Chemistry II while also adding new volumes on cutting-edge research areas and techniques for studying inorganic compounds. Researchers seeking background information on a specific problem involving the synthesis of inorganic compounds, as well as applications for numerous elements from the periodic table, and their compounds, will be able to rely on and refer to this authoritative scientific resource time and again."
    ],
    "b_categories":[
      "Material"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Multimodal Foundation Models for Material Property Prediction and Discovery"
    ],
    "c_abstract":[
      "Artificial intelligence is transforming computational materials science, improving the prediction of material properties, and accelerating the discovery of novel materials. Recently, publicly available material data repositories have grown rapidly. This growth encompasses not only more materials but also a greater variety and quantity of their associated properties. Existing machine learning efforts in materials science focus primarily on single-modality tasks, i.e. relationships between materials and a single physical property, thus not taking advantage of the rich and multimodal set of material properties. Here, we introduce Multimodal Learning for Materials (MultiMat), which enables self-supervised multi-modality training of foundation models for materials. We demonstrate our framework's potential using data from the Materials Project database on multiple axes: (i) MultiMat achieves state-of-the-art performance for challenging material property prediction tasks; (ii) MultiMat enables novel and accurate material discovery via latent space similarity, enabling screening for stable materials with desired properties; and (iii) MultiMat encodes interpretable emergent features that may provide novel scientific insights."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.09080",
    "a_title":"Language Models for Music Medicine Generation",
    "a_abstract":"Music therapy has been shown in recent years to provide multiple health\nbenefits related to emotional wellness. In turn, maintaining a healthy\nemotional state has proven to be effective for patients undergoing treatment,\nsuch as Parkinson's patients or patients suffering from stress and anxiety. We\npropose fine-tuning MusicGen, a music-generating transformer model, to create\nshort musical clips that assist patients in transitioning from negative to\ndesired emotional states. Using low-rank decomposition fine-tuning on the\nMTG-Jamendo Dataset with emotion tags, we generate 30-second clips that adhere\nto the iso principle, guiding patients through intermediate states in the\nvalence-arousal circumplex. The generated music is evaluated using a music\nemotion recognition model to ensure alignment with intended emotions. By\nconcatenating these clips, we produce a 15-minute \"music medicine\" resembling a\nmusic therapy session. Our approach is the first model to leverage Language\nModels to generate music medicine. Ultimately, the output is intended to be\nused as a temporary relief between music therapy sessions with a\nboard-certified therapist.",
    "explanation":"We propose fine-tuning MusicGen, a music-generating\ntransformer model, to create short musical clips that assist\npatients in transitioning from negative to desired emotional\nstates",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Music Transformer: Generating Music with Long-Term Structure"
    ],
    "b_abstract":[
      "Music relies heavily on repetition to build structure and meaning. Self-reference occurs on multiple timescales, from motifs to phrases to reusing of entire sections of music, such as in pieces with ABA structure. The Transformer (Vaswani et al., 2017), a sequence model based on self-attention, has achieved compelling results in many generation tasks that require maintaining long-range coherence. This suggests that self-attention might also be well-suited to modeling music. In musical composition and performance, however, relative timing is critically important. Existing approaches for representing relative positional information in the Transformer modulate attention based on pairwise distance (Shaw et al., 2018). This is impractical for long sequences such as musical compositions since their memory complexity for intermediate relative information is quadratic in the sequence length. We propose an algorithm that reduces their intermediate memory requirement to linear in the sequence length. This enables us to demonstrate that a Transformer with our modified relative attention mechanism can generate minute-long compositions (thousands of steps, four times the length modeled in Oore et al., 2018) with compelling structure, generate continuations that coherently elaborate on a given motif, and in a seq2seq setup generate accompaniments conditioned on melodies. We evaluate the Transformer with our relative attention mechanism on two datasets, JSB Chorales and Piano-e-Competition, and obtain state-of-the-art results on the latter."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b8"
    ],
    "c_title":[
      "On the use of AI for Generation of Functional Music to Improve Mental Health"
    ],
    "c_abstract":[
      "Increasingly music has been shown to have both physical and mental health benefits including improvements in cardiovascular health, a link reduction of cases dementia elderly populations, markers general well-being such as stress reduction. Here, we describe short case studies addressing (anxiety, stress-reduction) through AI-driven generation. Engaging active listening music-making activities (especially for at risk age groups) can be particularly beneficial, the practice therapy helpful range use across wide range. However, access prohibitive terms expertize, materials, cost. Furthermore existing functional outcomes (such targeted improvement suggested above) hindered by issues repetition subsequent over-familiarity with material. In this paper, machine learning approaches which create informed biophysiological measurement two studies, target emotional states opposing ends Cartesian affective space (a dimensional emotion points ranging from descriptors relaxation, fear). Galvanic skin response is used marker psychological arousal an estimate state control signal training algorithm. This algorithm creates non-linear time series musical features sound synthesis \u201con-the-fly\u201d, using perceptually feature similarity model. We find interaction between familiarity perceived response. also report on psychometric evaluation generated material, consider how these - similar techniques might useful generation tasks, example, nonlinear sound-tracking that found interactive media or video games."
    ],
    "c_categories":[
      "Mental Health"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.15211",
    "a_title":"LightLLM: A Versatile Large Language Model for Predictive Light Sensing",
    "a_abstract":"We propose LightLLM, a model that fine tunes pre-trained large language\nmodels (LLMs) for light-based sensing tasks. It integrates a sensor data\nencoder to extract key features, a contextual prompt to provide environmental\ninformation, and a fusion layer to combine these inputs into a unified\nrepresentation. This combined input is then processed by the pre-trained LLM,\nwhich remains frozen while being fine-tuned through the addition of\nlightweight, trainable components, allowing the model to adapt to new tasks\nwithout altering its original parameters. This approach enables flexible\nadaptation of LLM to specialized light sensing tasks with minimal computational\noverhead and retraining effort. We have implemented LightLLM for three light\nsensing tasks: light-based localization, outdoor solar forecasting, and indoor\nsolar estimation. Using real-world experimental datasets, we demonstrate that\nLightLLM significantly outperforms state-of-the-art methods, achieving 4.4x\nimprovement in localization accuracy and 3.4x improvement in indoor solar\nestimation when tested in previously unseen environments. We further\ndemonstrate that LightLLM outperforms ChatGPT-4 with direct prompting,\nhighlighting the advantages of LightLLM's specialized architecture for sensor\ndata fusion with textual prompts.",
    "explanation":"We propose LightLLM, a model that fine tunes pre-trained\nlarge language models (LLMs) for light-based sensing tasks.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Solar Cells for Indoor Applications: Progress and Development"
    ],
    "b_abstract":[
      "The Internet of things (IoT) has been rapidly growing in the past few years. IoT connects numerous devices, such as wireless sensors, actuators, and wearable to optimize monitor daily activities. Most these devices require power microwatt range operate indoors. To this end, a self-sustainable source, photovoltaic (PV) cell, which can harvest low-intensity indoor light, is appropriate. Recently, development highly efficient PV cells for applications attracted tremendous attention. Therefore, different types materials, inorganic, dye-sensitized, organic, perovskite have employed harvesting light energy. Although considerable efforts made by researchers develop low-cost, stable, applications, Extensive investigation necessary resolve some critical issues concerning cells, environmental stability, lifetime, large-area fabrication, mechanical flexibility, production cost. address issues, systematic review aspects will be useful research community. This study discusses current status based on previous reports. First, we provided relevant background information. Then, described sources, subsequently critically reviewed reports regarding solar active materials perovskite. Finally, placed an attempt provide insight into factors needed further improve feasibility technology applications."
    ],
    "b_categories":[
      "astro-ph.SR"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
    ],
    "c_abstract":[
      "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent models, BERT is designed to pre-train deep bidirectional representations unlabeled text by jointly conditioning on both left and right context in all layers. As result, the pre-trained can be fine-tuned with just one additional output layer create state-of-the-art models wide range of tasks, such as question answering inference, without substantial task-specific architecture modifications. conceptually simple empirically powerful. It obtains results eleven natural processing including pushing GLUE score 80.5% (7.7% point absolute improvement), MultiNLI accuracy 86.7% (4.6% SQuAD v1.1 Test F1 93.2 (1.5 improvement) v2.0 83.1 (5.1 improvement)."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00129",
    "a_title":"Scaling Particle Collision Data Analysis",
    "a_abstract":"For decades, researchers have developed task-specific models to address\nscientific challenges across diverse disciplines. Recently, large language\nmodels (LLMs) have shown enormous capabilities in handling general tasks;\nhowever, these models encounter difficulties in addressing real-world\nscientific problems, particularly in domains involving large-scale numerical\ndata analysis, such as experimental high energy physics. This limitation is\nprimarily due to BPE tokenization's inefficacy with numerical data. In this\npaper, we propose a task-agnostic architecture, BBT-Neutron, which employs a\nbinary tokenization method to facilitate pretraining on a mixture of textual\nand large-scale numerical experimental data. We demonstrate the application of\nBBT-Neutron to Jet Origin Identification (JoI), a critical categorization\nchallenge in high-energy physics that distinguishes jets originating from\nvarious quarks or gluons. Our results indicate that BBT-Neutron achieves\ncomparable performance to state-of-the-art task-specific JoI models.\nFurthermore, we examine the scaling behavior of BBT-Neutron's performance with\nincreasing data volume, suggesting the potential for BBT-Neutron to serve as a\nfoundational model for particle physics data analysis, with possible extensions\nto a broad spectrum of scientific computing applications for Big Science\nexperiments, industrial manufacturing and spacial computing. The project code\nis available at https:\/\/github.com\/supersymmetry-technologies\/bbt-neutron.",
    "explanation":"In this paper, we propose a task-agnostic architecture,\nBBT-Neutron, which employs a binary tokenization method to facilitate pre-\ntraining on a mixture of textual and large-scale numerical experimental data. We\ndemonstrate the application of BBT-Neutron to Jet Origin Identification (JoI),\na critical categorization challenge in high-energy physics that distinguishes jets\noriginating from various quarks or gluons",
    "b_id":[
      "b23"
    ],
    "b_title":[
      "DARWIN Series: Domain Specific Large Language Models for Natural Science"
    ],
    "b_abstract":[
      "Emerging tools bring forth fresh approaches to work, and the field of natural science is no different. In science, traditional manual, serial, labour-intensive work being augmented by automated, parallel, iterative processes driven artificial intelligence-based experimental automation more. To add new capabilities in enabling acceleration enrichment discovery process, we present DARWIN, a series tailored LLMs for mainly physics, chemistry, material science. This relies on open-source LLM, incorporating structured unstructured scientific knowledge from public datasets literature. We fine-tuned models using over 60,000 instruction data points, emphasizing factual correctness. During fine-tuning, introduce Scientific Instruction Generation (SIG) model, automating generation texts. eliminates need manual extraction or domain-specific graphs efficiently injects into model. also explore multi-task training strategies, revealing interconnections between tasks. DARWIN not only achieves state-of-the-art results various tasks but diminishes reliance closed-source AI models. Our research showcases ability LLM domain, with overarching goal fostering prosperity within broader community."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b29"
    ],
    "c_title":[
      "Study of Fermion pair production in e+e- collisions at 130-183 GeV"
    ],
    "c_abstract":[
      "The cross sections and forward-backward asymmetries of hadronic and leptonic\nevents produced in e+e- collisions at centre-of-mass energies of 130-183 GeV\nare presented. Results for ee, mumu, tautau, qq, bb and cc production show no\nsignificant deviation from the Standard Model predictions. This enable\nconstraints to be set upon physics beyond the Standard Model such as\nfour-fermion contact interactions, leptoquarks, Z' bosons and R-parity\nviolating squarks and sneutrinos. Limits on the energy scale Lambda of eeff\ncontact interactions are typically in the range from 2-10 TeV. Limits on\nR-parity violating sneutrinos reach masses of a few hundred GeV for large\nvalues of their Yukawa couplings."
    ],
    "c_categories":[
      "astro-ph.HE"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19475",
    "a_title":"Effective Fine-Tuning of Vision-Language Models for Accurate Galaxy\n  Morphology Analysis",
    "a_abstract":"Galaxy morphology analysis involves classifying galaxies by their shapes and\nstructures. For this task, directly training domain-specific models on large,\nannotated astronomical datasets is effective but costly. In contrast,\nfine-tuning vision foundation models on a smaller set of astronomical images is\nmore resource-efficient but generally results in lower accuracy. To harness the\nbenefits of both approaches and address their shortcomings, we propose\nGalaxAlign, a novel method that fine-tunes pre-trained foundation models to\nachieve high accuracy on astronomical tasks. Specifically, our method extends a\ncontrastive learning architecture to align three types of data in fine-tuning:\n(1) a set of schematic symbols representing galaxy shapes and structures, (2)\ntextual labels of these symbols, and (3) galaxy images. This way, GalaxAlign\nnot only eliminates the need for expensive pretraining but also enhances the\neffectiveness of fine-tuning. Extensive experiments on galaxy classification\nand similarity search demonstrate that our method effectively fine-tunes\ngeneral pre-trained models for astronomical tasks by incorporating\ndomain-specific multi-modal knowledge.",
    "explanation":"To harness the benefits of\nboth approaches and address their shortcomings, we pro-\npose GalaxAlign, a novel method that fine-tunes pre-trained\nfoundation models to achieve high accuracy on astronom-\nical tasks.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Radio galaxy zoo EMU: Towards a semantic radio galaxy morphology taxonomy"
    ],
    "b_abstract":[
      "ABSTRACT We present a novel natural language processing (NLP) approach to deriving plain English descriptors for science cases otherwise restricted by obfuscating technical terminology. address the limitations of common radio galaxy morphology classifications applying this approach. experimentally derive set semantic tags Radio Galaxy Zoo EMU (Evolutionary Map Universe) project and wider astronomical community. collect 8486 annotations morphology, from which we taxonomy tags. The are English. result is an extensible framework, more flexible, easily communicated, sensitive rare feature combinations, indescribable using current framework astronomy classifications."
    ],
    "b_categories":[
      "astro-ph.CO"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "ImageNet: A large-scale hierarchical image database"
    ],
    "c_abstract":[
      "The explosion of image data on the Internet has potential to foster more sophisticated and robust models algorithms index, retrieve, organize interact with images multimedia data. But exactly how such can be harnessed organized remains a critical problem. We introduce here new database called \"ImageNet\", large-scale ontology built upon backbone WordNet structure. ImageNet aims populate majority 80,000 synsets an average 500\u20131000 clean full resolution images. This will result in tens millions annotated by semantic hierarchy WordNet. paper offers detailed analysis its current state: 12 subtrees 5247 3.2 million total. show that is much larger scale diversity accurate than datasets. Constructing challenging task. describe collection scheme Amazon Mechanical Turk. Lastly, we illustrate usefulness through three simple applications object recognition, classification automatic clustering. hope scale, accuracy, hierarchical structure offer unparalleled opportunities researchers computer vision community beyond."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17595",
    "a_title":"Can artificial intelligence predict clinical trial outcomes?",
    "a_abstract":"The increasing complexity and cost of clinical trials, particularly in the\ncontext of oncology and advanced therapies, pose significant challenges for\ndrug development. This study evaluates the predictive capabilities of large\nlanguage models (LLMs) such as GPT-3.5, GPT-4, and HINT in determining clinical\ntrial outcomes. By leveraging a curated dataset of trials from\nClinicalTrials.gov, we compare the models' performance using metrics including\nbalanced accuracy, specificity, recall, and Matthews Correlation Coefficient\n(MCC). Results indicate that GPT-4o demonstrates robust performance in early\ntrial phases, achieving high recall but facing limitations in specificity.\nConversely, the HINT model excels in recognizing negative outcomes,\nparticularly in later trial phases, offering a balanced approach across diverse\nendpoints. Oncology trials, characterized by high complexity, remain\nchallenging for all models. Additionally, trial duration and disease categories\ninfluence predictive performance, with longer durations and complex diseases\nsuch as neoplasms reducing accuracy. This study highlights the complementary\nstrengths of LLMs and HINT, providing insights into optimizing predictive tools\nfor clinical trial design and risk management. Future advancements in LLMs are\nessential to address current gaps in handling negative outcomes and complex\ndomains.",
    "explanation":"This study evaluates the performance of large language models (LLMs) and the\nHINT model in predicting clinical trial outcomes, focusing on metrics includ-\ning Balanced Accuracy, Matthews Correlation Coefficient (MCC), Recall, and\nSpecificity",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Machine learning model to predict oncologic outcomes for drugs in randomized clinical trials"
    ],
    "b_abstract":[
      "Abstract Predicting oncologic outcome is challenging due to the diversity of cancer histologies and complex network underlying biological factors. In this study, we determine whether machine learning (ML) can extract meaningful associations between clinical trial, drug\u2010related biomarker molecular profile information. We analyzed therapeutic trials corresponding 1102 outcomes from 104 758 patients with advanced colorectal adenocarcinoma, pancreatic melanoma nonsmall\u2010cell lung cancer. For each intervention arm, a dataset following attributes was curated: line treatment, number cytotoxic chemotherapies, small\u2010molecule inhibitors, or monoclonal antibody agents, drug class, alteration status arm's population, type, probability sensitivity (PDS) (integrating genomic, transcriptomic proteomic biomarkers in population interest) outcome. A total 467 progression\u2010free survival (PFS) 369 overall (OS) data points were used as training sets build our ML (random forest) model. Cross\u2010validation for PFS OS, obtaining correlation coefficients ( r ) 0.82 0.70, respectively (outcome vs model's parameters). 156 110 OS test sets. The Spearman s predicted actual statistically significant (PFS: = 0.879, OS: 0.878, P &lt; .0001). better arm 81% N 59\/73, z 5.24, .0001) 71% (OS: 37\/52, 2.91, .004) randomized trials. success algorithm predict may be exploitable model optimize trial design pharmaceutical agents."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b9"
    ],
    "c_title":[
      "Lint: Llm interaction network for clinical trial outcome prediction"
    ],
    "c_abstract":[
      "Clinical trial outcome prediction aims to predict the success probability of a clinical trial that reaches its desirable endpoint. Most of the effort focuses on developing machine learning models for making accurate predictions with diverse data sources, including clinical trial descriptions, drug molecules, and target disease conditions. Accurate trial outcome prediction helps trial planning and asset portfolio prioritization. Previous works have focused on small-molecule drugs; however, biologics are a quickly growing intervention type that lacks information that is traditionally known for drugs, like molecular properties. Additionally, traditional methods like graph neural networks are much more difficult to apply to biologics data which are a fast-growing type of drug. To address these points, we propose a Language Interaction Network (LINT), a novel method for trial outcome prediction using only free-text descriptions. We validate the effectiveness of LINT with thorough experiments across three trial phases. Specifically, LINT obtains 0.770, 0.740, and 0.748 ROC-AUC scores on phase I, II, and III, respectively, for clinical trials with biologic interventions."
    ],
    "c_categories":[
      "Clinical trials"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.15395",
    "a_title":"ChatBCI: A P300 Speller BCI Leveraging Large Language Models for\n  Improved Sentence Composition in Realistic Scenarios",
    "a_abstract":"P300 speller BCIs allow users to compose sentences by selecting target keys\non a GUI through the detection of P300 component in their EEG signals following\nvisual stimuli. Most P300 speller BCIs require users to spell words letter by\nletter, or the first few initial letters, resulting in high keystroke demands\nthat increase time, cognitive load, and fatigue. This highlights the need for\nmore efficient, user-friendly methods for faster sentence composition. In this\nwork, we introduce ChatBCI, a P300 speller BCI that leverages the zero-shot\nlearning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing\nkeystrokes and accelerating sentence composition. ChatBCI retrieves word\nsuggestions through remote queries to the GPT-3.5 API. A new GUI, displaying\nGPT-3.5 word suggestions as extra keys is designed. SWLDA is used for the P300\nclassification. Seven subjects completed two online spelling tasks: 1)\ncopy-spelling a self-composed sentence using ChatBCI, and 2) improvising a\nsentence using ChatBCI's word suggestions. Results demonstrate that in Task 1,\non average, ChatBCI outperforms letter-by-letter BCI spellers, reducing time\nand keystrokes by 62.14% and 53.22%, respectively, and increasing information\ntransfer rate by 198.96%. In Task 2, ChatBCI achieves 80.68% keystroke savings\nand a record 8.53 characters\/min for typing speed. Overall, ChatBCI, by\nemploying remote LLM queries, enhances sentence composition in realistic\nscenarios, significantly outperforming traditional spellers without requiring\nlocal model training or storage. ChatBCI's (multi-) word predictions, combined\nwith its new GUI, pave the way for developing next-generation speller BCIs that\nare efficient and effective for real-time communication, especially for users\nwith communication and motor disabilities.",
    "explanation":"In this work, we introduce ChatBCI, a P300 speller BCI that leverages the zero-\nshot learning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing keystrokes\nand accelerating sentence composition. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Brain\u2013Computer Interface Spellers: A Review"
    ],
    "b_abstract":[
      "A Brain\u2013Computer Interface (BCI) provides a novel non-muscular communication method via brain signals. BCI-speller can be considered as one of the first published BCI applications and has opened gate for many advances in field. Although BCI-spellers have been developed during last few decades, to our knowledge, no reviews described different spellers proposed studied this vital The presented speller systems are categorized according major paradigms: P300, steady-state visual evoked potential (SSVEP), motor imagery (MI). Different paradigms require specific electroencephalogram (EEG) signal features lead development appropriate Graphical User Interfaces (GUIs). purpose review is consolidate most successful since 2010, while mentioning some other older which were built explicitly spelling purposes. We aim assist researchers concerned individuals field by illustrating highlights presenting them review. It almost impossible carry out an objective comparison between spellers, each its variables, parameters, conditions. However, gathered information provided taxonomy about helpful, it could identify suitable first-hand users, well opportunities learning from previous studies researchers."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b17"
    ],
    "c_title":[
      "Language Model-Guided Classifier Adaptation for Brain-Computer Interfaces for Communication"
    ],
    "c_abstract":[
      "Brain-computer interfaces (BCIs), such as the P300 speller, can provide a means of communication for individuals with severe neuromuscular limitations. BCIs interpret electroencephalography (EEG) signals in order to translate embedded information about user's intent into executable commands control external devices. However, EEG are inherently noisy and nonstationary, posing challenge extended BCI use. Conventionally, classifier is trained via supervised learning an offline calibration session; once trained, deployed online use not updated. As statistics data change over time, performance static may decline It therefore desirable automatically adapt current without requiring recalibration. In existing semi-supervised approach, on labeled then updated using incoming unlabeled classifier-predicted labels. To reduce risk from incorrect predictions, threshold imposed exclude low-confidence label predictions expanded training set when retraining adaptive classifier. this work, we propose language model spelling error correction disambiguation correctness during learning. Results simulations multi-session speller user demonstrate that our language-guided approach significantly improves accuracy relative conventional threshold-based"
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.08063",
    "a_title":"MatPilot: an LLM-enabled AI Materials Scientist under the Framework of\n  Human-Machine Collaboration",
    "a_abstract":"The rapid evolution of artificial intelligence, particularly large language\nmodels, presents unprecedented opportunities for materials science research. We\nproposed and developed an AI materials scientist named MatPilot, which has\nshown encouraging abilities in the discovery of new materials. The core\nstrength of MatPilot is its natural language interactive human-machine\ncollaboration, which augments the research capabilities of human scientist\nteams through a multi-agent system. MatPilot integrates unique cognitive\nabilities, extensive accumulated experience, and ongoing curiosity of\nhuman-beings with the AI agents' capabilities of advanced abstraction, complex\nknowledge storage and high-dimensional information processing. It could\ngenerate scientific hypotheses and experimental schemes, and employ predictive\nmodels and optimization algorithms to drive an automated experimental platform\nfor experiments. It turns out that our system demonstrates capabilities for\nefficient validation, continuous learning, and iterative optimization.",
    "explanation":"proposed and\ndeveloped an AI materials scientist named MatPilot, which has shown encouraging\nabilities in the discovery of new materials. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "A Data-Science Approach to Predict the Heat Capacity of Nanoporous Materials"
    ],
    "b_abstract":[
      "The heat capacity of a material is a fundamental property of great practical importance. For example, in a carbon capture process, the heat required to regenerate a solid sorbent is directly related to the heat capacity of the material. However, for most materials suitable for carbon capture applications, the heat capacity is not known, and thus the standard procedure is to assume the same value for all materials. In this work, we developed a machine learning approach, trained on density functional theory simulations, to accurately predict the heat capacity of these materials, that is, zeolites, metal\u2013organic frameworks and covalent\u2013organic frameworks. The accuracy of our prediction is confirmed with experimental data. Finally, for a temperature swing adsorption process that captures carbon from the flue gas of a coal-fired power plant, we show that for some materials, the heat requirement is reduced by as much as a factor of two using the correct heat capacity. Heat capacity of nanoporous materials is important for processes such as carbon capture, as this can affect process design energy requirements. Here, a machine learning approach for heat capacity prediction, trained on density functional theory simulations, is presented and experimentally verified."
    ],
    "b_categories":[
      "cond-mat.mtrl-sci"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "A deep-learning approach to realizing functionality in nanoelectronic devices"
    ],
    "c_abstract":[
      "Many nanoscale devices require precise optimization to function. Tuning them to the desired operation regime becomes increasingly difficult and time-consuming when the number of terminals and couplings grows. Imperfections and device-to-device variations hinder optimization that uses physics-based models. Deep neural networks (DNNs) can model various complex physical phenomena but, so far, are mainly used as predictive tools. Here, we propose a generic deep-learning approach to efficiently optimize complex, multi-terminal nanoelectronic devices for desired functionality. We demonstrate our approach for realizing functionality in a disordered network of dopant atoms in silicon. We model the input\u2013output characteristics of the device with a DNN, and subsequently optimize control parameters in the DNN model through gradient descent to realize various classification tasks. When the corresponding control settings are applied to the physical device, the resulting functionality is as predicted by the DNN model. We expect our approach to contribute to fast, in situ optimization of complex (quantum) nanoelectronic devices."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.13126",
    "a_title":"A Knowledge-enhanced Pathology Vision-language Foundation Model for\n  Cancer Diagnosis",
    "a_abstract":"Deep learning has enabled the development of highly robust foundation models\nfor various pathological tasks across diverse diseases and patient cohorts.\nAmong these models, vision-language pre-training, which leverages large-scale\npaired data to align pathology image and text embedding spaces, and provides a\nnovel zero-shot paradigm for downstream tasks. However, existing models have\nbeen primarily data-driven and lack the incorporation of domain-specific\nknowledge, which limits their performance in cancer diagnosis, especially for\nrare tumor subtypes. To address this limitation, we establish a\nKnowledge-enhanced Pathology (KEEP) foundation model that harnesses disease\nknowledge to facilitate vision-language pre-training. Specifically, we first\nconstruct a disease knowledge graph (KG) that covers 11,454 human diseases with\n139,143 disease attributes, including synonyms, definitions, and hypernym\nrelations. We then systematically reorganize the millions of publicly available\nnoisy pathology image-text pairs, into 143K well-structured semantic groups\nlinked through the hierarchical relations of the disease KG. To derive more\nnuanced image and text representations, we propose a novel knowledge-enhanced\nvision-language pre-training approach that integrates disease knowledge into\nthe alignment within hierarchical semantic groups instead of unstructured\nimage-text pairs. Validated on 18 diverse benchmarks with more than 14,000\nwhole slide images (WSIs), KEEP achieves state-of-the-art performance in\nzero-shot cancer diagnostic tasks. Notably, for cancer detection, KEEP\ndemonstrates an average sensitivity of 89.8% at a specificity of 95.0% across 7\ncancer types. For cancer subtyping, KEEP achieves a median balanced accuracy of\n0.456 in subtyping 30 rare brain cancers, indicating strong generalizability\nfor diagnosing rare tumors.",
    "explanation":"However, existing models have been primarily data-driven and\nlack the incorporation of domain-specific knowledge, which limits their performance in cancer diagnosis,\nespecially for rare tumor subtypes. To address this limitation, we establish a KnowledgE-Enhanced\nPathology (KEEP) foundation model that harnesses disease knowledge to facilitate vision-language\npre-training.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Machine Learning-driven Histotype Diagnosis of Ovarian Carcinoma: Insights from the OCEAN AI Challenge"
    ],
    "b_abstract":[
      "Ovarian cancer poses a significant health burden as one of the deadliest malignancies affecting women globally. Histotype assignment of epithelial ovarian cancers can be challenging due to morphologic overlap, inter-observer variability, and the lack of ancillary diagnostic techniques in some areas of the world. Moreover, rare cancers can pose particular diagnostic difficulties because of a relative lack of familiarity with them, underscoring the necessity for robust diagnostic methodologies. The emergence of Artificial Intelligence (AI) has brought promising prospects to the realm of ovarian cancer diagnosis. While various studies have underscored AI's promise, its validation across multiple healthcare centers and hospitals has been limited. Inspired by innovations in medical imaging driven by public competitions, we initiated the Ovarian Cancer subtypE clAssification and outlier detectioN (OCEAN) challenge, the most extensive histopathology competition to date."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b1"
    ],
    "c_title":[
      "Viable and necrotic tumor assessment from whole slide images of osteosarcoma using machine-learning and deep-learning models"
    ],
    "c_abstract":[
      "Pathological estimation of tumor necrosis after chemotherapy is essential for patients with osteosarcoma. This study reports the first fully automated tool to assess viable and necrotic in osteosarcoma, employing advances histopathology digitization learning. We selected 40 digitized whole slide images representing heterogeneity osteosarcoma response. With goal labeling diverse regions tissue into tumor, non-tumor, we trained 13 machine-learning models top performing one (a Support Vector Machine) based on reported accuracy. also developed a deep-learning architecture it same data set. computed receiver-operator characteristic discrimination non-tumor from followed by conditional found our exceptionally well. then used identify interest image-tiles generated test images. The classification output visualized as tumor-prediction map, displaying extent image. Thus, lay foundation complete assessment pipeline original histology map generation. proposed can be adopted other types tumor."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.17717",
    "a_title":"Comprehensive Methodology for Sample Augmentation in EEG Biomarker\n  Studies for Alzheimers Risk Classification",
    "a_abstract":"Background: Dementia, marked by cognitive decline, is a global health\nchallenge. Alzheimer's disease (AD), the leading type, accounts for ~70% of\ncases. Electroencephalography (EEG) measures show promise in identifying AD\nrisk, but obtaining large samples for reliable comparisons is challenging.\nObjective: This study integrates signal processing, harmonization, and\nstatistical techniques to enhance sample size and improve AD risk\nclassification reliability. Methods: We used advanced EEG preprocessing,\nfeature extraction, harmonization, and propensity score matching (PSM) to\nbalance healthy non-carriers (HC) and asymptomatic E280A mutation carriers\n(ACr). Data from four databases were harmonized to adjust site effects while\npreserving covariates like age and sex. PSM ratios (2:1, 5:1, 10:1) were\napplied to assess sample size impact on model performance. The final dataset\nunderwent machine learning analysis with decision trees and cross-validation\nfor robust results. Results: Balancing sample sizes via PSM significantly\nimproved classification accuracy, ranging from 0.92 to 0.96 across ratios. This\napproach enabled precise risk identification even with limited samples.\nConclusion: Integrating data processing, harmonization, and balancing\ntechniques improves AD risk classification accuracy, offering potential for\nother neurodegenerative diseases.",
    "explanation":"This study implements a\ncomprehensive methodology that integrates signal processing, data harmonization, and\nstatistical techniques to increase sample size and improve the reliability of Alzheimer's disease\nrisk classification models.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Neural biomarker diagnosis and prediction to mild cognitive impairment and Alzheimer\u2019s disease using EEG technology"
    ],
    "b_abstract":[
      "Background Electroencephalogram (EEG) has emerged as a non-invasive tool to detect the aberrant neuronal activity related to different stages of Alzheimer\u2019s disease (AD). However, the effectiveness of EEG in the precise diagnosis and assessment of AD and its preclinical stage, amnestic mild cognitive impairment (MCI), has yet to be fully elucidated. In this study, we aimed to identify key EEG biomarkers that are effective in distinguishing patients at the early stage of AD and monitoring the progression of AD. Methods A total of 890 participants, including 189 patients with MCI, 330 patients with AD, 125 patients with other dementias (frontotemporal dementia, dementia with Lewy bodies, and vascular cognitive impairment), and 246 healthy controls (HC) were enrolled. Biomarkers were extracted from resting-state EEG recordings for a three-level classification of HC, MCI, and AD. The optimal EEG biomarkers were then identified based on the classification performance. Random forest regression was used to train a series of models by combining participants\u2019 EEG biomarkers, demographic information (i.e., sex, age), CSF biomarkers, and APOE phenotype for assessing the disease progression and individual\u2019s cognitive function. Results The identified EEG biomarkers achieved over 70% accuracy in the three-level classification of HC, MCI, and AD. Among all six groups, the most prominent effects of AD-linked neurodegeneration on EEG metrics were localized at parieto-occipital regions. In the cross-validation predictive analyses, the optimal EEG features were more effective than the CSF + APOE biomarkers in predicting the age of onset and disease course, whereas the combination of EEG + CSF + APOE measures achieved the best performance for all targets of prediction. Conclusions Our study indicates that EEG can be used as a useful screening tool for the diagnosis and disease progression evaluation of MCI and AD."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Quantitative EEG analysis disease during resting and memory task in carriers and non-carriers of PS-1 E280A mutation of familial Alzheimer's"
    ],
    "c_abstract":[
      "Background: Alzheimer\u2019s disease is the most leading cause of dementia in world; mutation PS-1 E280A alters gene Presenilin-1 and causes an early onset familial disease. This has been found large kindred Antioquia, Colombia. The objective this study was to find differences revealed by electroencephalogram between healthy subjects asymptomatic carriers that can be used as clinical markers population. Methods: EEG recorded 15 non during resting a memory task using 64 channels amplifier. Two conditions were analyzed: encoding retrieval, process recording evocating information, respectively. Power spectrum calculated delta (0.5\u20134.0 Hz), theta (4.0\u20138. 0 alpha-1 (8.0\u201310.0 alpha-2 (10.0\u201313.0 beta (13.0\u201325.0 Hz) gamma (25.0\u201350 frequency bands for four regions interest. Changes evaluated different ANOVA analysis. Results: In condition significant decrease (p=0. 0001) increase frequencies (p=0.037) compare with controls. During significantly lower compared controls 008) comparing versus retrieval each group, there more synchronization carriers. Conclusion: Early changes observed recordings, it could use Also seems activate additional cortical order conserve successful cognitive functions before impairment ."
    ],
    "c_categories":[
      "q-bio.NC"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.16728",
    "a_title":"Maximizing the Impact of Deep Learning on Subseasonal-to-Seasonal\n  Climate Forecasting: The Essential Role of Optimization",
    "a_abstract":"Weather and climate forecasting is vital for sectors such as agriculture and\ndisaster management. Although numerical weather prediction (NWP) systems have\nadvanced, forecasting at the subseasonal-to-seasonal (S2S) scale, spanning 2 to\n6 weeks, remains challenging due to the chaotic and sparse atmospheric signals\nat this interval. Even state-of-the-art deep learning models struggle to\noutperform simple climatology models in this domain. This paper identifies that\noptimization, instead of network structure, could be the root cause of this\nperformance gap, and then we develop a novel multi-stage optimization strategy\nto close the gap. Extensive empirical studies demonstrate that our multi-stage\noptimization approach significantly improves key skill metrics, PCC and TCC,\nwhile utilizing the same backbone structure, surpassing the state-of-the-art\nNWP systems (ECMWF-S2S) by over \\textbf{19-91\\%}. Our research contests the\nrecent study that direct forecasting outperforms rolling forecasting for S2S\ntasks. Through theoretical analysis, we propose that the underperformance of\nrolling forecasting may arise from the accumulation of Jacobian matrix products\nduring training. Our multi-stage framework can be viewed as a form of teacher\nforcing to address this issue. Code is available at\n\\url{https:\/\/anonymous.4open.science\/r\/Baguan-S2S-23E7\/}",
    "explanation":"Weather and climate forecasting is vital for sectors such\nas agriculture and disaster management. Although numeri-\ncal weather prediction (NWP) systems have advanced, fore-\ncasting at the subseasonal-to-seasonal (S2S) scale, span-\nning 2 to 6 weeks, remains challenging due to the chaotic\nand sparse atmospheric signals at this interval.",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "FuXi-S2S: An accurate machine learning model for global subseasonal forecasts"
    ],
    "b_abstract":[
      "Skillful subseasonal forecasts beyond 2 weeks are crucial for a wide range of applications across various sectors society. Recently, state-of-the-art machine learning based weather forecasting models have made significant advancements, outperforming the high-resolution forecast (HRES) from European Centre Medium-Range Weather Forecasts (ECMWF). However, full potential in has yet to be fully explored. In this study, we introduce FuXi Subseasonal-to-Seasonal (FuXi-S2S), model that provides global daily mean up 42 days, covering 5 upper-air atmospheric variables at 13 pressure levels and 11 surface variables. FuXi-S2S integrates an enhanced base with perturbation module flow-dependent perturbations hidden features, incorporates Perlin noise perturb initial conditions. The is developed using 72 years statistics ECMWF ERA5 reanalysis data. When compared (S2S) reforecasts, demonstrate superior deterministic ensemble total precipitation (TP), outgoing longwave radiation (OLR), geopotential 500 hPa (Z500). Although it shows slightly inferior performance predicting 2-meter temperature (T2M), clear advantages over land area. Regarding extreme forecasts, outperforms S2S globally TP. Furthermore, surpass reforecasts Madden Julian Oscillation (MJO), key source predictability. They extend skillful prediction MJO 30 days 36 days."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b21"
    ],
    "c_title":[
      "Analysis methods for numerical weather prediction"
    ],
    "c_abstract":[
      "Abstract Bayesian probabilistic arguments are used to derive idealized equations for finding the best analysis numerical weather prediction. These compared with those from other published methods in light of physical characteristics NWP problem; namely predetermined nature basis analysis, need approximation because large\u2010order systems, underdeterminacy problem when using observations alone, and availability prior relationships resolve underdeterminacy. Prior result (1) knowledge time evolution model (which together use a distribution constitutes four\u2010dimensional data assimilation); (2) that atmosphere varies slowly (leading balance relationships); (3) nonlinear coupling parameters scales atmosphere. Methods discussed include variational techniques, smoothing splines, Kriging, optimal interpolation, successive corrections, constrained initialization, Kalman\u2010Bucy filter, adjoint assimilation. They all shown relate hence each other. Opinions given on particular might be more appropriate. By comparison method some insight is gained into appropriate choices practical methods."
    ],
    "c_categories":[
      "physics.data-an"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.02466",
    "a_title":"Weakly supervised deep learning model with size constraint for prostate\n  cancer detection in multiparametric MRI and generalization to unseen domains",
    "a_abstract":"Fully supervised deep models have shown promising performance for many\nmedical segmentation tasks. Still, the deployment of these tools in clinics is\nlimited by the very timeconsuming collection of manually expert-annotated data.\nMoreover, most of the state-ofthe-art models have been trained and validated on\nmoderately homogeneous datasets. It is known that deep learning methods are\noften greatly degraded by domain or label shifts and are yet to be built in\nsuch a way as to be robust to unseen data or label distributions. In the\nclinical setting, this problematic is particularly relevant as the deployment\ninstitutions may have different scanners or acquisition protocols than those\nfrom which the data has been collected to train the model. In this work, we\npropose to address these two challenges on the detection of clinically\nsignificant prostate cancer (csPCa) from bi-parametric MRI. We evaluate the\nmethod proposed by (Kervadec et al., 2018), which introduces a size constaint\nloss to produce fine semantic cancer lesions segmentations from weak circle\nscribbles annotations. Performance of the model is based on two public (PI-CAI\nand Prostate158) and one private databases. First, we show that the model\nachieves on-par performance with strong fully supervised baseline models, both\non in-distribution validation data and unseen test images. Second, we observe a\nperformance decrease for both fully supervised and weakly supervised models\nwhen tested on unseen data domains. This confirms the crucial need for\nefficient domain adaptation methods if deep learning models are aimed to be\ndeployed in a clinical environment. Finally, we show that ensemble predictions\nfrom multiple trainings increase generalization performance.",
    "explanation":"n this work, we propose to address these two challenges\non the detection of clinically significant prostate cancer (csPCa) from bi-parametric MRI.\nWe evaluate the method proposed by (Kervadec et al., 2018), which introduces a size con-\nstaint loss to produce fine semantic cancer lesions segmentations from weak circle scribbles\nannotations",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "A review of artificial intelligence in prostate cancer detection on imaging"
    ],
    "b_abstract":[
      "A multitude of studies have explored the role artificial intelligence (AI) in providing diagnostic support to radiologists, pathologists, and urologists prostate cancer detection, risk-stratification, management. This review provides a comprehensive overview relevant literature regarding use AI models (1) detecting on radiology images (magnetic resonance ultrasound imaging), (2) histopathology biopsy tissue, (3) assisting supporting tasks for detection (prostate gland segmentation, MRI-histopathology registration, MRI-ultrasound registration). We discuss both potential these assist clinical workflow diagnosis, as well current limitations including variability training data sets, algorithms, evaluation criteria. also ongoing challenges what is needed bridge gap between academic research commercial solutions that improve routine care."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b14"
    ],
    "c_title":[
      "Automatic Prostate Cancer Detection On Multi-Parametric Mri With Hierarchical Weakly Supervised Learning"
    ],
    "c_abstract":[
      "Multi-parametric MRI (mp-MRI) is one of the most commonly used non-invasive methods for prostate cancer (PCa) diagnosis. In recent years, computer aided diagnosis (CAD) PCa on mp-MRI based deep learning techniques has gained much attention and shown promising progress. The key success to obtain a large amount high quality region annotation such that network can accurately learn variation lesions. order precisely annotate mp-MRI, pathological whole mount data patient normally required as reference, which often difficult in real world clinical situations. Therefore, we are motivated propose new method integrate different levels information available screening workflow through multitask hierarchical weakly supervised framework detection mp-MRI. Experimental results show our achieves segmentation results."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.02614",
    "a_title":"Divergent Domains, Convergent Grading: Enhancing Generalization in\n  Diabetic Retinopathy Grading",
    "a_abstract":"Diabetic Retinopathy (DR) constitutes 5% of global blindness cases. While\nnumerous deep learning approaches have sought to enhance traditional DR grading\nmethods, they often falter when confronted with new out-of-distribution data\nthereby impeding their widespread application. In this study, we introduce a\nnovel deep learning method for achieving domain generalization (DG) in DR\ngrading and make the following contributions. First, we propose a new way of\ngenerating image-to-image diagnostically relevant fundus augmentations\nconditioned on the grade of the original fundus image. These augmentations are\ntailored to emulate the types of shifts in DR datasets thus increase the\nmodel's robustness. Second, we address the limitations of the standard\nclassification loss in DG for DR fundus datasets by proposing a new DG-specific\nloss, domain alignment loss; which ensures that the feature vectors from all\ndomains corresponding to the same class converge onto the same manifold for\nbetter domain generalization. Third, we tackle the coupled problem of data\nimbalance across DR domains and classes by proposing to employ Focal loss which\nseamlessly integrates with our new alignment loss. Fourth, due to inevitable\nobserver variability in DR diagnosis that induces label noise, we propose\nleveraging self-supervised pretraining. This approach ensures that our DG model\nremains robust against early susceptibility to label noise, even when only a\nlimited dataset of non-DR fundus images is available for pretraining. Our\nmethod demonstrates significant improvements over the strong Empirical Risk\nMinimization baseline and other recently proposed state-of-the-art DG methods\nfor DR grading. Code is available at https:\/\/github.com\/sharonchokuwa\/dg-adr.",
    "explanation":"In this study, we introduce a novel deep learning\nmethod for achieving domain generalization (DG) in DR\ngrading and make the following contributions.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Medical diffusion on a budget: textual inversion for medical image generation"
    ],
    "b_abstract":[
      "Diffusion-based models for text-to-image generation have gained immense popularity due to recent advancements in efficiency, accessibility, and quality. Although it is becoming increasingly feasible perform inference with these systems using consumer-grade GPUs, training them from scratch still requires access large datasets significant computational resources. In the case of medical image generation, availability large, publicly accessible that include text reports limited legal ethical concerns. While a diffusion model on private dataset may address this issue, not always institutions lacking necessary This work demonstrates pre-trained Stable Diffusion models, originally trained natural images, can be adapted various imaging modalities by embeddings textual inversion. study, we conducted experiments comprising only 100 samples three modalities. Embeddings were matter hours, while retaining diagnostic relevance generation. Experiments designed achieve several objectives. Firstly, fine-tuned processes inversion, revealing larger more examples are required. Secondly, validated our approach demonstrating 2\\% increase accuracy (AUC) detecting prostate cancer MRI, which challenging multi-modal modality, 0.78 0.80. Thirdly, performed simulations interpolating between healthy diseased states, combining multiple pathologies, inpainting show embedding flexibility control disease appearance. Finally, study small (less than 1 MB), facilitates easy sharing data reduced privacy"
    ],
    "b_categories":[
      "q-bio.OT"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "Deep Learning Techniques for Diabetic Retinopathy Classification: A Survey"
    ],
    "c_abstract":[
      "Diabetic Retinopathy (DR) is a degenerative disease that impacts the eyes and consequence of Diabetes mellitus, where high blood glucose levels induce lesions on eye retina.Diabetic regarded as leading cause blindness for diabetic patients, especially working-age population in developing nations.Treatment involves sustaining patient's current grade vision since irreversible.Early detection crucial order to sustain effectively.The main issue involved with DR manual diagnosis process very time, money, effort consuming an ophthalmologist's examination retinal fundus images.The latter also proves be more difficult, particularly early stages when features are less prominent images.Machine learning-based medical image analysis has proven competency assessing images, utilization deep learning algorithms aided (DR).This paper reviews analyzes state-of-the-art methods supervised, self-supervised, Vision Transformer setups, proposing classification detection.For instance, referable, non-referable, proliferative classifications reviewed summarized.Moreover, discusses available datasets used tasks such detection, classification, segmentation.The assesses research gaps area detection\/classification addresses various challenges need further study investigation."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.18767",
    "a_title":"Multi-Task Learning for Integrated Automated Contouring and Voxel-Based\n  Dose Prediction in Radiotherapy",
    "a_abstract":"Deep learning-based automated contouring and treatment planning has been\nproven to improve the efficiency and accuracy of radiotherapy. However,\nconventional radiotherapy treatment planning process has the automated\ncontouring and treatment planning as separate tasks. Moreover in deep learning\n(DL), the contouring and dose prediction tasks for automated treatment planning\nare done independently. In this study, we applied the multi-task learning (MTL)\napproach in order to seamlessly integrate automated contouring and voxel-based\ndose prediction tasks, as MTL can leverage common information between the two\ntasks and be able able to increase the efficiency of the automated tasks. We\ndeveloped our MTL framework using the two datasets: in-house prostate cancer\ndataset and the publicly available head and neck cancer dataset, OpenKBP.\nCompared to the sequential DL contouring and treatment planning tasks, our\nproposed method using MTL improved the mean absolute difference of dose volume\nhistogram metrics of prostate and head and neck sites by 19.82% and 16.33%,\nrespectively. Our MTL model for automated contouring and dose prediction tasks\ndemonstrated enhanced dose prediction performance while maintaining or\nsometimes even improving the contouring accuracy. Compared to the baseline\nautomated contouring model with the dice score coefficients of 0.818 for\nprostate and 0.674 for head and neck datasets, our MTL approach achieved\naverage scores of 0.824 and 0.716 for these datasets, respectively. Our study\nhighlights the potential of the proposed automated contouring and planning\nusing MTL to support the development of efficient and accurate automated\ntreatment planning for radiotherapy.",
    "explanation":"Deep learning-based automated contouring and treatment planning has\nbeen proven to improve the efficiency and accuracy of radiotherapy.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "A Transformer-Embedded Multi-Task Model for Dose Distribution Prediction"
    ],
    "b_abstract":[
      "Radiation therapy is a fundamental cancer treatment in the clinic. However, to satisfy clinical requirements, radiologists have iteratively adjust radiotherapy plan based on experience, causing it extremely subjective and time-consuming obtain clinically acceptable plan. To this end, we introduce transformer-embedded multi-task dose prediction (TransMTDP) network automatically predict distribution radiotherapy. Specifically, achieve more stable accurate predictions, three highly correlated tasks are included our TransMTDP network, i.e. main task provide each pixel with fine-grained value, an auxiliary isodose lines produce coarse-grained ranges, gradient learn subtle information such as radiation patterns edges maps. The integrated through shared encoder, following learning strategy. strengthen connection of output layers for different tasks, further use two additional constraints, consistency loss loss, reinforce match between features generated by task. Additionally, considering many organs human body symmetrical maps present abundant global features, embed transformer into framework capture long-range dependencies Evaluated in-house rectum dataset public head neck dataset, method gains superior performance compared state-of-the-art ones. Code available at https:\/\/github.com\/luuuwen\/TransMTDP."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b0"
    ],
    "c_title":[
      "Clinical integration of machine learning for curative-intent radiation treatment of patients with prostate cancer"
    ],
    "c_abstract":[
      "Machine learning (ML) holds great promise for impacting healthcare delivery; however, to date most methods are tested in \u2018simulated\u2019 environments that cannot recapitulate factors influencing real-world clinical practice. We prospectively deployed and evaluated a random forest algorithm for therapeutic curative-intent radiation therapy (RT) treatment planning for prostate cancer in a blinded, head-to-head study with full integration into the clinical workflow. ML- and human-generated RT treatment plans were directly compared in a retrospective simulation with retesting (n\u2009=\u200950) and a prospective clinical deployment (n\u2009=\u200950) phase. Consistently throughout the study phases, treating physicians assessed ML- and human-generated RT treatment plans in a blinded manner following a priori defined standardized criteria and peer review processes, with the selected RT plan in the prospective phase delivered for patient treatment. Overall, 89% of ML-generated RT plans were considered clinically acceptable and 72% were selected over human-generated RT plans in head-to-head comparisons. RT planning using ML reduced the median time required for the entire RT planning process by 60.1% (118 to 47\u2009h). While ML RT plan acceptability remained stable between the simulation and deployment phases (92 versus 86%), the number of ML RT plans selected for treatment was significantly reduced (83 versus 61%, respectively). These findings highlight that retrospective or simulated evaluation of ML methods, even under expert blinded review, may not be representative of algorithm acceptance in a real-world clinical setting when patient care is at stake."
    ],
    "c_categories":[
      "q-bio.CB"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.10004",
    "a_title":"EyeDiff: text-to-image diffusion model improves rare eye disease\n  diagnosis",
    "a_abstract":"The rising prevalence of vision-threatening retinal diseases poses a\nsignificant burden on the global healthcare systems. Deep learning (DL) offers\na promising solution for automatic disease screening but demands substantial\ndata. Collecting and labeling large volumes of ophthalmic images across various\nmodalities encounters several real-world challenges, especially for rare\ndiseases. Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and\nevaluate its applicability in diagnosing common and rare diseases. EyeDiff is\ntrained on eight large-scale datasets using the advanced latent diffusion\nmodel, covering 14 ophthalmic image modalities and over 80 ocular diseases, and\nis adapted to ten multi-country external datasets. The generated images\naccurately capture essential lesional characteristics, achieving high alignment\nwith text prompts as evaluated by objective metrics and human experts.\nFurthermore, integrating generated images significantly enhances the accuracy\nof detecting minority classes and rare eye diseases, surpassing traditional\noversampling methods in addressing data imbalance. EyeDiff effectively tackles\nthe issue of data imbalance and insufficiency typically encountered in rare\ndiseases and addresses the challenges of collecting large-scale annotated\nimages, offering a transformative solution to enhance the development of\nexpert-level diseases diagnosis models in ophthalmic field.",
    "explanation":"Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and evaluate its\napplicability in diagnosing common and rare diseases.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Artificial Intelligence for Pediatric Ophthalmology"
    ],
    "b_abstract":[
      "PURPOSE OF REVIEW: Despite the impressive results of recent artificial\nintelligence (AI) applications to general ophthalmology, comparatively less\nprogress has been made toward solving problems in pediatric ophthalmology using\nsimilar techniques. This article discusses the unique needs of pediatric\nophthalmology patients and how AI techniques can address these challenges,\nsurveys recent applications of AI to pediatric ophthalmology, and discusses\nfuture directions in the field.\n  RECENT FINDINGS: The most significant advances involve the automated\ndetection of retinopathy of prematurity (ROP), yielding results that rival\nexperts. Machine learning (ML) has also been successfully applied to the\nclassification of pediatric cataracts, prediction of post-operative\ncomplications following cataract surgery, detection of strabismus and\nrefractive error, prediction of future high myopia, and diagnosis of reading\ndisability via eye tracking. In addition, ML techniques have been used for the\nstudy of visual development, vessel segmentation in pediatric fundus images,\nand ophthalmic image synthesis.\n  SUMMARY: AI applications could significantly benefit clinical care for\npediatric ophthalmology patients by optimizing disease detection and grading,\nbroadening access to care, furthering scientific discovery, and improving\nclinical efficiency. These methods need to match or surpass physician\nperformance in clinical trials before deployment with patients. Due to\nwidespread use of closed-access data sets and software implementations, it is\ndifficult to directly compare the performance of these approaches, and\nreproducibility is poor. Open-access data sets and software implementations\ncould alleviate these issues, and encourage further AI applications to\npediatric ophthalmology.\n  KEYWORDS: pediatric ophthalmology, machine learning, artificial intelligence,\ndeep learning"
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b7"
    ],
    "c_title":[
      "Classification of Retinal Diseases in Optical Coherence Tomography Images Using Artificial Intelligence and Firefly Algorithm"
    ],
    "c_abstract":[
      "In recent years, the number of studies for automatic diagnosis biomedical diseases has increased. Many these have used Deep Learning, which gives extremely good results but requires a vast amount data and computing load. If processor is insufficient quality, this takes time places an excessive load on processor. On other hand, Machine Learning faster than does not much-needed load, it provide as high accuracy value Learning. Therefore, our goal to develop hybrid system that provides value, while requiring smaller less diagnose such retinal we chose study. For purpose, first, layer extraction was conducted through image preprocessing. Then, traditional feature extractors were combined with pre-trained extractors. To select best features, Firefly algorithm. end, multiple binary classifications instead multiclass classification classifiers. Two public datasets in The first dataset had mean 0.957, second 0.954."
    ],
    "c_categories":[
      "q-bio.TO"
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01375",
    "a_title":"Scaling Laws with Hidden Structure",
    "a_abstract":"Statistical learning in high-dimensional spaces is challenging without a\nstrong underlying data structure. Recent advances with foundational models\nsuggest that text and image data contain such hidden structures, which help\nmitigate the curse of dimensionality. Inspired by results from nonparametric\nstatistics, we hypothesize that this phenomenon can be partially explained in\nterms of decomposition of complex tasks into simpler subtasks. In this paper,\nwe present a controlled experimental framework to test whether neural networks\ncan indeed exploit such ``hidden factorial structures.'' We find that they do\nleverage these latent patterns to learn discrete distributions more\nefficiently, and derive scaling laws linking model sizes, hidden\nfactorizations, and accuracy. We also study the interplay between our\nstructural assumptions and the models' capacity for generalization.",
    "explanation":"The key references I chose in Task 3 combined the concepts of Neural Networks with Discrete Distribution Theory to support this IDR paper. In the abstract, the following lines describe the integration of those selected references:\n\"In this paper, we present a controlled experimental framework to test whether neural networks can indeed exploit such \u201chidden factorial structures.\u201d\n\"We find that they do leverage these latent patterns to learn discrete distributions more efficiently. \"\n\n",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Learning Parities with Neural Networks"
    ],
    "b_abstract":[
      "In recent years we see a rapidly growing line of research which shows learnability various models via common neural network algorithms. Yet, besides very few outliers, these results show that can be learned using linear methods. Namely, such learning neural-networks with gradient-descent is competitive classifier on top data-independent representation the examples. This leaves much to desired, as networks are far more successful than Furthermore, conceptual level, don't seem capture deepness deep networks. this paper make step towards showing leanability inherently non-linear. We under certain distributions, sparse parities learnable gradient decent depth-two network. On other hand, same cannot efficiently by"
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "Testing conditional independence of discrete distributions"
    ],
    "c_abstract":[
      "We study the problem of testing *conditional independence* for discrete distributions. Specifically, given samples from a random variable (X, Y, Z) on domain [\u21131]\u00d7[\u21132] \u00d7 [n], we want to distinguish, with probability at least 2\/3, between case that X and Y are conditionally independent Z is \u0454-far, in \u21131-distance, every distribution has this property. Conditional independence concept central importance statistics important applications various scientific domains. As such, statistical task conditional been extensively studied forms within econometrics community nearly century. Perhaps surprisingly, not previously considered framework property particular no tester *sublinear* sample complexity known, even special domains binary."
    ],
    "c_categories":[
      "stat.CO"
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2412.00544",
    "a_title":"RoBo6: Standardized MMT Light Curve Dataset for Rocket Body\n  Classification",
    "a_abstract":"Space debris presents a critical challenge for the sustainability of future\nspace missions, emphasizing the need for robust and standardized identification\nmethods. However, a comprehensive benchmark for rocket body classification\nremains absent. This paper addresses this gap by introducing the RoBo6 dataset\nfor rocket body classification based on light curves. The dataset, derived from\nthe Mini Mega Tortora database, includes light curves for six rocket body\nclasses: CZ-3B, Atlas 5 Centaur, Falcon 9, H-2A, Ariane 5, and Delta 4. With\n5,676 training and 1,404 test samples, it addresses data inconsistencies using\nresampling, normalization, and filtering techniques. Several machine learning\nmodels were evaluated, including CNN and transformer-based approaches, with\nAstroconformer reporting the best performance. The dataset establishes a common\nbenchmark for future comparisons and advancements in rocket body classification\ntasks.",
    "explanation":"The selected references in Task 3 were based from the following topics introduced in the abstract:\n\n\"Space debris presents a critical challenge for the sustainability of future space missions, emphasizing the need for robust and standardized identification methods.\"\n\"Several machine learning models were evaluated, including\nCNN and transformer-based approaches, with  Astroconformer reporting the best performance\"",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "Attention Is All You Need"
    ],
    "b_abstract":[
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. best performing also connect the encoder and decoder through attention mechanism. We propose a new simple network architecture, Transformer, solely mechanisms, dispensing with recurrence convolutions entirely. Experiments two machine translation tasks show these to be superior quality while being more parallelizable requiring significantly less time train. Our model achieves 28.4 BLEU WMT 2014 English-to-German task, improving over existing results, including ensembles by 2 BLEU. On English-to-French our establishes single-model state-of-the-art score of 41.8 after training for 3.5 days eight GPUs, small fraction costs from literature. that Transformer generalizes well other applying it successfully English constituency parsing both large limited data."
    ],
    "b_categories":[
      "cond-mat.dis-nn"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b5"
    ],
    "c_title":[
      "Space objects classification via lightcurve measurements: deep convolutional neural networks and model-based transfer learning"
    ],
    "c_abstract":[
      "Developing a detailed understanding of the Space Object (SO) population is a fundamental goal of Space Situational Awareness (SSA). The current SO catalog includes simplified characteristic for the observed space objects, mainly the solar radiation pressure and\/or drag ballistic coefficients. Such simplified description limits the dynamic propagation model used for predicting the state of motion of SO to models that assume cannon ball shapes and generic surface properties. The future SO catalog and SSA systems will have to be capable of building a detailed picture of SO characteristics. Traditional measurement sources for SO tracking, such as radar and optical, provide information on SO characteristics. These measurements have been shown to be sensitive to shape, attitude, angular velocity, and surface parameters. State-of-the-art in the literature has been advanced over the past decades and in recent years seen the development of multiple models, nonlinear state estimation, and full Bayesian inversion approaches for SO characterization. The key shortcoming of approaches in literature is their overall computational cost and the limited flexibility to deal with a larger and larger amount of data. In this paper, we present a data-driven method to classification of SO based on a deep learning approach that takes advantage of the representational power of deep neural networks. Here, we design, train and validate a Convolutional Neural Network (CNN) capable of learning to classify SOs from collected light-curve measurements. The proposed methodology relies a physically-based model capable of accurately representing SO reflected light as function of time, size shape and state of motion. The model generates thousands of light-curves per selected class of SO which are employ to train a deep CNN to learn the functional relationship between light curves and SO class. Additionally, a deep CNN is trained using real SO light curves to evaluate the performance on a real, but limited training set. CNNs are compared with more conventional machine learning techniques (bagged trees, support vector machines) and are shown to outperform such methods especially when trained on real data. The concept of model-based transfer learning is proposed as possible path forward to increase the accuracy and speedup the training process."
    ],
    "c_categories":[
      "astro-ph.HE"
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04840",
    "a_title":"Localized KBO with genetic dynamics for multi-modal optimization",
    "a_abstract":"In this paper, we introduce a novel approach to multi-modal optimization by\nenhancing the recently developed kinetic-based optimization (KBO) method with\ngenetic dynamics (GKBO). The proposed method targets objective functions with\nmultiple global minima, addressing a critical need in fields like engineering\ndesign, machine learning, and bioinformatics. By incorpo rating leader-follower\ndynamics and localized interactions, the algorithm efficiently navigates\nhigh-dimensional search spaces to detect multiple optimal solutions. After\nproviding a binary description, a mean-field approximation is derived, and\ndifferent numerical experiments are conducted to validate the results.",
    "explanation":"This IDR paper involves a combination of topics from different fields. In particular, I highlighted key references in Task 3 where topics in Genetics and the use of Data Structures and Algorithms come into play. Below are some sentences from the Abstract that reflect that:\n\n\"n this paper, we introduce a novel approach to multi-modal optimization by enhancing the recently developed kinetic-based optimization (KBO) method with genetic dynamics (GKBO)\"\n\" By incorporating leader-follower dynamics and localized interactions, the algorithm efficiently navigates high-dimensional search spaces to detect multiple optimal solution.\"",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Kinetic description and convergence analysis of genetic algorithms for global optimization"
    ],
    "b_abstract":[
      "Genetic Algorithms (GA) are a class of metaheuristic global optimization methods inspired by the process natural selection among individuals in population. Despite their widespread use, comprehensive theoretical analysis these remains challenging due to complexity heuristic mechanisms involved. In this work, relying on tools statistical physics, we take first step towards mathematical understanding GA showing how behavior for large number can be approximated through time-discrete kinetic model. This allows us prove convergence algorithm minimum under mild assumptions objective function popular choice mechanism. Furthermore, derive time-continuous model GA, represented Boltzmann-like partial differential equation, and establish relations with other mean-field dynamics optimization. Numerical experiments support validity proposed approximation investigate asymptotic configurations particle system different benchmark problems."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b25"
    ],
    "c_title":[
      "Genetic Algorithms + Data Structures = Evolution Programs"
    ],
    "c_abstract":[
      "Genetic algorithms are founded upon the principle of evolution, i.e., survival of the fittest. Hence evolution programming techniques, based on genetic algorithms, are applicable to many hard optimization problems, such as optimization of functions with linear and nonlinear constraints, the traveling salesman problem, and problems of scheduling, partitioning, and control. The importance of these techniques is still growing, since evolution programs are parallel in nature, and parallelism is one of the most promising directions in computer science. The book is self-contained and the only prerequisite is basic undergraduate mathematics. This third edition has been substantially revised and extended by three new chapters and by additional appendices containing working material to cover recent developments and a change in the perception of evolutionary computation."
    ],
    "c_categories":[
      "cs.DS"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2411.17342",
    "a_title":"Automatic Skull Reconstruction by Deep Learnable Symmetry Enforcement",
    "a_abstract":"Every year, thousands of people suffer from skull damage and require\npersonalized implants to fill the cranial cavity. Unfortunately, the waiting\ntime for reconstruction surgery can extend to several weeks or even months,\nespecially in less developed countries. One factor contributing to the extended\nwaiting period is the intricate process of personalized implant modeling.\nCurrently, the preparation of these implants by experienced biomechanical\nexperts is both costly and time-consuming. Recent advances in artificial\nintelligence, especially in deep learning, offer promising potential for\nautomating the process. However, deep learning-based cranial reconstruction\nfaces several challenges: (i) the limited size of training datasets, (ii) the\nhigh resolution of the volumetric data, and (iii) significant data\nheterogeneity. In this work, we propose a novel approach to address these\nchallenges by enhancing the reconstruction through learnable symmetry\nenforcement. We demonstrate that it is possible to train a neural network\ndedicated to calculating skull symmetry, which can be utilized either as an\nadditional objective function during training or as a post-reconstruction\nobjective during the refinement step. We quantitatively evaluate the proposed\nmethod using open SkullBreak and SkullFix datasets, and qualitatively using\nreal clinical cases. The results indicate that the symmetry-preserving\nreconstruction network achieves considerably better outcomes compared to the\nbaseline (0.94\/0.94\/1.31 vs 0.84\/0.76\/2.43 in terms of DSC, bDSC, and HD95).\nMoreover, the results are comparable to the best-performing methods while\nrequiring significantly fewer computational resources (< 500 vs > 100,000 GPU\nhours). The proposed method is a considerable contribution to the field of\napplied artificial intelligence in medicine and is a step toward automatic\ncranial defect reconstruction in clinical practice.",
    "explanation":"This IDR paper is an applied research paper that focuses on combining Neural Networks to advance biomechanics. Below are some sentences in the abstract that reflect the references in Task 3:\n\n\"We demonstrate that it is possible to train a neural network dedicated to calculating skull symmetry,\"\n\n\"Every year, thousands of people suffer from skull damage and require personalized implants to fill the cranial cavity. Unfortunately, the waiting time for reconstruction surgery can extend to several weeks or even months, especially in less developed countries.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Reconstruction of cranial defect with patient-specific implants: Four different cost-effective techniques"
    ],
    "b_abstract":[
      "Cranial defects secondary to trauma, surgery or pathological causes, result in large cranial imperfection, which affects the appearance of patient as well results sinking flap syndrome. Rehabilitation such a defect can be done using prosthetic options like custom-made polymethyl methacrylate (PMMA) prosthesis surgical outer table calvarial graft segments. It is usually observed that conventional moulage impression defective site most difficult task. The accuracy affected by impression, cast and techniques fabricating wax pattern. Orthodox method mark tentative outline make site. However, this an arbitrary offers challenges accurate replication borders defect. Recently, medical imaging digital modeling dentistry have paved way for dental practice additive manufacturing replacing manual subtractive procedures. use computerized tomography scan obtain 3 D image replica with rapid prototyping has markedly improved at margin defect\/prosthesis interface, resulting better fit optimal contour lending itself esthetic outcome. more reliable implant prosthesis, requires minimum adjustment when on OT table. These case reports compare rehabilitation PMMA methods technique. seen expensive but gives"
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b35"
    ],
    "c_title":[
      "Deep learning-based framework for automatic cranial defect reconstruction and implant modeling"
    ],
    "c_abstract":[
      "This article presents a robust, fast, and fully automatic method for personalized cranial defect reconstruction implant modeling.We propose two-step deep learning-based using modified U-Net architecture to perform the reconstruction, dedicated iterative procedure improve geometry, followed by an generation of models ready 3-D printing. We cross-case augmentation based on imperfect image registration combining cases from different datasets. Additional ablation studies compare strategies other state-of-the-art methods.We evaluate three datasets introduced during AutoImplant 2021 challenge, organized jointly with MICCAI conference. quantitative evaluation Dice boundary coefficients, Hausdorff distance. The coefficient, 95th percentile distance averaged across all test sets, are 0.91, 0.94, 1.53 mm respectively. additional qualitative printing visualization in mixed reality confirm implant's usefulness.The proposes complete pipeline that enables one create model described is greatly extended version scored 1st place challenge tasks. freely release source code, which together open datasets, makes results reproducible. defects may enable manufacturing implants significantly shorter time, possibly allowing process directly given intervention. Moreover, we show usability further reduce surgery time."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.04747",
    "a_title":"Equivariant Graph Attention Networks with Structural Motifs for\n  Predicting Cell Line-Specific Synergistic Drug Combinations",
    "a_abstract":"Cancer is the second leading cause of death, with chemotherapy as one of the\nprimary forms of treatment. As a result, researchers are turning to drug\ncombination therapy to decrease drug resistance and increase efficacy. Current\nmethods of drug combination screening, such as in vivo and in vitro, are\ninefficient due to stark time and monetary costs. In silico methods have become\nincreasingly important for screening drugs, but current methods are inaccurate\nand generalize poorly to unseen anticancer drugs. In this paper, I employ a\ngeometric deep-learning model utilizing a graph attention network that is\nequivariant to 3D rotations, translations, and reflections with structural\nmotifs. Additionally, the gene expression of cancer cell lines is utilized to\nclassify synergistic drug combinations specific to each cell line. I compared\nthe proposed geometric deep learning framework to current state-of-the-art\n(SOTA) methods, and the proposed model architecture achieved greater\nperformance on all 12 benchmark tasks performed on the DrugComb dataset.\nSpecifically, the proposed framework outperformed other SOTA methods by an\naccuracy difference greater than 28%. Based on these results, I believe that\nthe equivariant graph attention network's capability of learning geometric data\naccounts for the large performance improvements. The model's ability to\ngeneralize to foreign drugs is thought to be due to the structural motifs\nproviding a better representation of the molecule. Overall, I believe that the\nproposed equivariant geometric deep learning framework serves as an effective\ntool for virtually screening anticancer drug combinations for further\nvalidation in a wet lab environment. The code for this work is made available\nonline at: https:\/\/github.com\/WeToTheMoon\/EGAT_DrugSynergy.",
    "explanation":"From the key references cited in Task 3, below are some sentences that point to the significance of those references that show how this paper is an IDR.\n\n\"Additionally, the gene expression of cancer cell lines is utilized to classify synergistic drug combinations specificto each cell line. \"\n\"I compared the proposed geometric deep learning\nframework to current state-of-the-art (SOTA) methods\"\n\"Based on these results, I believe that the equivariant graph attention network\u2019s capability of learning geometric data accounts for the large performance improvements.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Trends in Phase II Trials for Cancer Therapies"
    ],
    "b_abstract":[
      "Background: Drug combinations are the standard of care in cancer treatment. Identifying effective drug has become more challenging because increasing number drugs. However, a substantial drugs stumble at Phase III clinical trials despite exhibiting favourable efficacy earlier Phase. Methods: We analysed recent II comprising 2165 response rates to uncover trends therapies and used null model non-interacting agents infer synergistic antagonistic combinations. compared our latest dataset with previous assess progress therapy. Results: Targeted reach higher when combination cytotoxic identify four 10 based on observed expected rates. demonstrate that targeted have not significantly increased Conclusions: conclude either we making or rate measured by tumour shrinkage is reliable surrogate endpoint for agents."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b16"
    ],
    "c_title":[
      "E(n) Equivariant Graph Neural Networks"
    ],
    "c_abstract":[
      "This paper introduces a new model to learn graph neural networks equivariant rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. addition, whereas methods are limited equivariance on 3 dimensional spaces, is easily scaled higher-dimensional spaces. We demonstrate the effectiveness of method dynamical systems modelling, representation learning autoencoders predicting molecular properties."
    ],
    "c_categories":[
      "cs.NE"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.11513",
    "a_title":"A Modular Open Source Framework for Genomic Variant Calling",
    "a_abstract":"Variant calling is a fundamental task in genomic research, essential for\ndetecting genetic variations such as single nucleotide polymorphisms (SNPs) and\ninsertions or deletions (indels). This paper presents an enhancement to\nDeepChem, a widely used open-source drug discovery framework, through the\nintegration of DeepVariant. In particular, we introduce a variant calling\npipeline that leverages DeepVariant's convolutional neural network (CNN)\narchitecture to improve the accuracy and reliability of variant detection. The\nimplemented pipeline includes stages for realignment of sequencing reads,\ncandidate variant detection, and pileup image generation, followed by variant\nclassification using a modified Inception v3 model. Our work adds a modular and\nextensible variant calling framework to the DeepChem framework and enables\nfuture work integrating DeepChem's drug discovery infrastructure more tightly\nwith bioinformatics pipelines.",
    "explanation":"Some sentences that point to the key references selected in Task 3 are specified below:\n\n\"Variant calling is a fundamental task in genomic research, essential for detecting genetic variations such as single nucleotide polymorphisms (SNPs) and insertions or deletions (indels).\"\n\n\"Our work adds a modular and extensible variant calling framework to the DeepChem framework and enables\nfuture work integrating DeepChem\u2019s drug discovery infrastructure more tightly with bioinformatics pipelines.\"",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "The Genome Analysis Toolkit: A MapReduce framework for analyzing next-generation DNA sequencing data"
    ],
    "b_abstract":[
      "Next-generation DNA sequencing (NGS) projects, such as the 1000 Genomes Project, are already revolutionizing our understanding of genetic variation among individuals. However, massive data sets generated by NGS\u2014the Genome pilot alone includes nearly five terabases\u2014make writing feature-rich, efficient, and robust analysis tools difficult for even computationally sophisticated Indeed, many professionals limited in scope ease with which they can answer scientific questions complexity accessing manipulating produced these machines. Here, we discuss Analysis Toolkit (GATK), a structured programming framework designed to development efficient next-generation sequencers using functional philosophy MapReduce. The GATK provides small but rich set access patterns that encompass majority tool needs. Separating specific calculations from common management infrastructure enables us optimize correctness, stability, CPU memory efficiency enable distributed shared parallelization. We highlight capabilities describing implementation application robust, scale-tolerant like coverage calculators single nucleotide polymorphism (SNP) calling. conclude developers analysts quickly easily write NGS tools, have been incorporated into large-scale projects Project Cancer Atlas."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b12"
    ],
    "c_title":[
      "Rethinking the Inception Architecture for Computer Vision"
    ],
    "c_abstract":[
      "Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety tasks. Since 2014 very deep convolutional started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend translate immediate quality tasks (as long as enough labeled data is provided training), efficiency low parameter count still enabling factors use cases such mobile big-data scenarios. Here we exploring ways scale up that aim utilizing added computation efficiently possible by suitably factorized convolutions aggressive regularization. We benchmark our methods on ILSVRC 2012 classification challenge validation set demonstrate over art: 21:2% top-1 5:6% top-5 error single frame evaluation using network with 5 billion multiply-adds per inference less than 25 million parameters. With an ensemble 4 models multi-crop evaluation, report 3:5% 17:3% 3:6% official test set."
    ],
    "c_categories":[
      "BioInformatics"
    ],
    "c_fields":[

    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00319",
    "a_title":"Improving speaker verification robustness with synthetic emotional\n  utterances",
    "a_abstract":"A speaker verification (SV) system offers an authentication service designed\nto confirm whether a given speech sample originates from a specific speaker.\nThis technology has paved the way for various personalized applications that\ncater to individual preferences. A noteworthy challenge faced by SV systems is\ntheir ability to perform consistently across a range of emotional spectra. Most\nexisting models exhibit high error rates when dealing with emotional utterances\ncompared to neutral ones. Consequently, this phenomenon often leads to missing\nout on speech of interest. This issue primarily stems from the limited\navailability of labeled emotional speech data, impeding the development of\nrobust speaker representations that encompass diverse emotional states.\n  To address this concern, we propose a novel approach employing the CycleGAN\nframework to serve as a data augmentation method. This technique synthesizes\nemotional speech segments for each specific speaker while preserving the unique\nvocal identity. Our experimental findings underscore the effectiveness of\nincorporating synthetic emotional data into the training process. The models\ntrained using this augmented dataset consistently outperform the baseline\nmodels on the task of verifying speakers in emotional speech scenarios,\nreducing equal error rate by as much as 3.64% relative.",
    "explanation":"A speaker verification (SV) system offers an authentication ser-\nvice designed to confirm whether a given speech sample orig-\ninates from a specific speaker. To address this concern, we propose a novel\napproach employing the CycleGAN framework to serve as a\ndata augmentation method. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Human-Centric Interfaces for Ambient Intelligence"
    ],
    "b_abstract":[
      "To create truly effective human-centric ambient intelligence systems both engineering and computing methods are needed. This is the first book to bridge data processing and intelligent reasoning methods for the creation of human-centered ambient intelligence systems. Interdisciplinary in nature, the book covers topics such as multi-modal interfaces, human-computer interaction, smart environments and pervasive computing, addressing principles, paradigms, methods and applications. This book will be an ideal reference for university researchers, R&amp;D engineers, computer engineers, and graduate students working in signal, speech and video processing, multi-modal interfaces, human-computer interaction and applications of ambient intelligence."
    ],
    "b_categories":[
      "physics.app-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b6"
    ],
    "c_title":[
      "Speaker Diarization with LSTM"
    ],
    "c_abstract":[
      "For many years, i-vector based audio embedding techniques were the dominant approach for speaker verification and diarization applications. However, mirroring rise of deep learning in various domains, neural network embeddings, also known as <i xmlns:mml=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" xmlns:xlink=\"http:\/\/www.w3.org\/1999\/xlink\">d-vectors<\/i> , have consistently demonstrated superior performance. In this paper, we build on success d-vector systems to develop a new diarization. Specifically, combine LSTM-based embeddings with recent work non-parametric clustering obtain state-of-the-art system. Our system is evaluated three standard public datasets, suggesting that offer significant advantages over traditional systems. We achieved 12.0% error rate NIST SRE 2000 CALLHOME, while our model trained out-of-domain data from voice search logs."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00173",
    "a_title":"Spatial Clustering of Molecular Localizations with Graph Neural Networks",
    "a_abstract":"Single-molecule localization microscopy generates point clouds corresponding\nto fluorophore localizations. Spatial cluster identification and analysis of\nthese point clouds are crucial for extracting insights about molecular\norganization. However, this task becomes challenging in the presence of\nlocalization noise, high point density, or complex biological structures. Here,\nwe introduce MIRO (Multimodal Integration through Relational Optimization), an\nalgorithm that uses recurrent graph neural networks to transform the point\nclouds in order to improve clustering efficiency when applying conventional\nclustering techniques. We show that MIRO supports simultaneous processing of\nclusters of different shapes and at multiple scales, demonstrating improved\nperformance across varied datasets. Our comprehensive evaluation demonstrates\nMIRO's transformative potential for single-molecule localization applications,\nshowcasing its capability to revolutionize cluster analysis and provide\naccurate, reliable details of molecular architecture. In addition, MIRO's\nrobust clustering capabilities hold promise for applications in various fields\nsuch as neuroscience, for the analysis of neural connectivity patterns, and\nenvironmental science, for studying spatial distributions of ecological data.",
    "explanation":"Single-molecule localization microscopy generates point clouds corresponding to\nfluorophore localizations.  Here, we introduce MIRO (Mul-\ntimodal Integration through Relational Optimization), an algorithm that uses\nrecurrent graph neural networks to transform the point clouds in order to improve\nclustering efficiency when applying conventional clustering techniques.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Turning single-molecule localization microscopy into a quantitative bioanalytical tool"
    ],
    "b_abstract":[
      "Single-molecule localization microscopy (SMLM) generates super-resolution images by serially detecting individual fluorescent molecules. The power of SMLM, however, goes beyond images: biologically relevant information can be extracted from the mathematical relationships between the positions of the fluorophores in space and time. Here we review the history of SMLM and how recent progress in methods for spatial point analysis has enabled quantitative measurement of SMLM data, providing insights into biomolecule patterning, clustering and oligomerization in biological systems."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b22"
    ],
    "c_title":[
      "A framework for evaluating the performance of SMLM cluster analysis algorithms"
    ],
    "c_abstract":[
      "This analysis compares the performance of seven algorithms for cluster analysis of single-molecule localization microscopy data. The results provide a framework for comparing these types of methods and point users to the best tools. Single-molecule localization microscopy (SMLM) generates data in the form of coordinates of localized fluorophores. Cluster analysis is an attractive route for extracting biologically meaningful information from such data and has been widely applied. Despite a range of cluster analysis algorithms, there exists no consensus framework for the evaluation of their performance. Here, we use a systematic approach based on two metrics to score the success of clustering algorithms in simulated conditions mimicking experimental data. We demonstrate the framework using seven diverse analysis algorithms: DBSCAN, ToMATo, KDE, FOCAL, CAML, ClusterViSu and SR-Tesseler. Given that the best performer depended on the underlying distribution of localizations, we demonstrate an analysis pipeline based on statistical similarity measures that enables the selection of the most appropriate algorithm, and the optimized analysis parameters for real SMLM data. We propose that these standard simulated conditions, metrics and analysis pipeline become the basis for future analysis algorithm development and evaluation."
    ],
    "c_categories":[
      "eess.IV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.19450",
    "a_title":"Unsupervised Learning Approach to Anomaly Detection in Gravitational\n  Wave Data",
    "a_abstract":"Gravitational waves (GW), predicted by Einstein's General Theory of\nRelativity, provide a powerful probe of astrophysical phenomena and fundamental\nphysics. In this work, we propose an unsupervised anomaly detection method\nusing variational autoencoders (VAEs) to analyze GW time-series data. By\ntraining on noise-only data, the VAE accurately reconstructs noise inputs while\nfailing to reconstruct anomalies, such as GW signals, which results in\nmeasurable spikes in the reconstruction error. The method was applied to data\nfrom the LIGO H1 and L1 detectors. Evaluation on testing datasets containing\nboth noise and GW events demonstrated reliable detection, achieving an area\nunder the ROC curve (AUC) of 0.89. This study introduces VAEs as a robust,\nunsupervised approach for identifying anomalies in GW data, which offers a\nscalable framework for detecting known and potentially new phenomena in\nphysics.",
    "explanation":"Gravitational waves (GW), predicted by Einstein\u2019s General Theory of Relativity, provide a pow-\nerful probe of astrophysical phenomena and fundamental physics. In this work, we propose an\nunsupervised anomaly detection method using variational autoencoders (VAEs) to analyze GW\ntime-series data. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining"
    ],
    "b_abstract":[
      "It is our great pleasure to welcome you the 2017 ACM Conference on Knowledge Discovery and Data Mining -- KDD 2017. We hope that content professional networking opportunities at will help succeed professionally by enabling to: identify new technology trends; learn from contributed papers, presentations, posters; discover tools, processes practices; job opportunities; hire team members. The terms \"Data Science\", Mining\" \"Big Data\" have, in last few years, grown out of research labs gained presence media everyday conversations. also hear these social decision makers various level governments corporations. impact technologies felt almost every walk life. Importantly, current rapid progress data science facilitated timely sharing newly discovered developed representations algorithms between those working interested industrial deployment. hallmark conferences past they have been bridge theory practise, facilitator catalyst for this exchange. Researchers practitioners meet person interact a meaningful way over several days. conference program, with its three parallel tracks - Research Track, Applied Science Track Invited Speakers brings two groups together. Participants are freely attend any track, events common all tracks. year continues tradition strong tutorial workshop program leading edge issues mining during first days program. devoted technical describing both novel, important contributions, deployed, innovative solutions. Three keynote talks, Cynthia Dwork, Bin Yu, Ren\u00e9e J. Miller touch some hard, emerging before field mining. With growing industry around AI assistants, Panel together experts spawn discussions an exchanges ideas. outstanding lineup speakers their experiences expertise deploying continue hands-on which participants how use practical tools. In order broaden increase participation attendees who would greatly benefit but otherwise found it financially challenging attend, we reserved substantial budget travel grants. awarded record USD 145k student set aside 25k enable smaller startups attend. \"Meet Experts\" sessions, gives researchers unique opportunity form networks share perspectives others aspects science. serve as meeting ground researchers, practitioners, funding agencies investors create commercial products."
    ],
    "b_categories":[
      "physics.gen-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b4"
    ],
    "c_title":[
      "Auto-Encoding Variational Bayes"
    ],
    "c_abstract":[
      "How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05237",
    "a_title":"Pruning the Path to Optimal Care: Identifying Systematically Suboptimal\n  Medical Decision-Making with Inverse Reinforcement Learning",
    "a_abstract":"In aims to uncover insights into medical decision-making embedded within\nobservational data from clinical settings, we present a novel application of\nInverse Reinforcement Learning (IRL) that identifies suboptimal clinician\nactions based on the actions of their peers. This approach centers two stages\nof IRL with an intermediate step to prune trajectories displaying behavior that\ndeviates significantly from the consensus. This enables us to effectively\nidentify clinical priorities and values from ICU data containing both optimal\nand suboptimal clinician decisions. We observe that the benefits of removing\nsuboptimal actions vary by disease and differentially impact certain\ndemographic groups.",
    "explanation":"In aims to uncover insights into medical decision-making embedded within observational data from clinical settings,\nwe present a novel application of Inverse Reinforcement Learning (IRL) that identifies suboptimal clinician actions\nbased on the actions of their peers. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Factors Influencing Physicians' Clinical Decision-making at Upazila Health Complexes in Bangladesh"
    ],
    "b_abstract":[
      "Selecting the most appropriate treatment for each patient is key activity in patient-physician encounters and providing healthcare services. Achieving desirable clinical goals mostly depends on making right decision at time any setting. But little known about physicians' decision-making primary care setting Bangladesh. Therefore, this study explored factors that influence decisions prescribing medications, ordering pathologic tests, counseling patients, average length of visits a consultation session, referral patients to other physicians or hospitals by Upazila Health Complexes (UHCs) country. It also structure social networks their association with process.This was cross-sectional descriptive used data collected from 85 physicians. The respondents, who work UHCs Rajshahi Division, were selected purposively. analyzed statistics including frequency, percentage, one-way analysis variance, linear regression understand relationships among variables.The results reveal multiple visits, referring UHCs. Most prescribe drugs keeping mind purchasing capacity. Risk violence patients' relatives better management are two decisions. professional personal play an influential role process. found dedicate 16.17 minutes session. influenced various distance between residence workplace, level education, number colleagues whom they have regular contact can seek help.The yielded some novel insights complexity everyday tasks would be interest public health researchers policy makers."
    ],
    "b_categories":[
      "Healthcare"
    ],
    "b_fields":[

    ],
    "c_id":[
      "b3"
    ],
    "c_title":[
      "Interactive Teaching Algorithms for Inverse Reinforcement Learning"
    ],
    "c_abstract":[
      "We study the problem of inverse reinforcement learning (IRL) with added twist that learner is assisted by a helpful teacher. More formally, we tackle following algorithmic question: How could teacher provide an informative sequence demonstrations to IRL speed up process? present interactive teaching framework where adaptively chooses next demonstration based on learner's current policy. In particular, design algorithms for two concrete settings: omniscient setting has full knowledge about dynamics and blackbox minimal knowledge. Then, sequential variant popular MCE-IRL prove convergence guarantees our algorithm in setting. Extensive experiments car driving simulator environment show progress can be speeded drastically as compared uninformative"
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"basic"
  },
  {
    "id":"2412.09927",
    "a_title":"Neural Vector Tomography for Reconstructing a Magnetization Vector Field",
    "a_abstract":"Discretized techniques for vector tomographic reconstructions are prone to\nproducing artifacts in the reconstructions. The quality of these\nreconstructions may further deteriorate as the amount of noise increases. In\nthis work, we instead model the underlying vector fields using smooth neural\nfields. Owing to the fact that the activation functions in the neural network\nmay be chosen to be smooth and the domain is no longer pixelated, the model\nresults in high-quality reconstructions, even under presence of noise. In the\ncase where we have underlying global continuous symmetry, we find that the\nneural network substantially improves the accuracy of the reconstruction over\nthe existing techniques.",
    "explanation":" In this work, we instead model the underlying\nvector fields using smooth neural fields",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Three-dimensional nanomagnetism"
    ],
    "b_abstract":[
      "Magnetic nanostructures are being developed for use in many aspects of our daily life, spanning areas such as data storage, sensing and biomedicine. Whereas patterned nanomagnets traditionally two-dimensional planar structures, recent work is expanding nanomagnetism into three dimensions; a move triggered by the advance unconventional synthesis methods discovery new magnetic effects. In three-dimensional more complex configurations become possible, with unprecedented properties. Here we review creation these structures their implications emergence physics, development instrumentation computational methods, exploitation numerous applications. Nanoscale devices play key role modern technologies but current applications involve only 2D like discs. authors progress fabrication understanding 3D nanostructures, enabling diverse functionalities."
    ],
    "b_categories":[
      "cond-mat.mes-hall"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b15"
    ],
    "c_title":[
      "MagNet: machine learning enhanced three-dimensional magnetic reconstruction"
    ],
    "c_abstract":[
      "Three-dimensional (3D) magnetic reconstruction is vital to the study of novel materials for 3D spintronics. Vector field electron tomography (VFET) a major in house tool achieve that. However, conventional VFET exhibits significant artefacts due unavoidable presence missing wedges. In this article, we propose deep-learning enhanced method address issue. A textures library built by micromagnetic simulations. MagNet, an U-shaped convolutional neural network, trained and tested with dataset generated from library. We demonstrate that MagNet outperforms under wedge. Quality reconstructed induction fields significantly improved."
    ],
    "c_categories":[
      "cs.CV"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.19927",
    "a_title":"Modeling Continuous Spatial-temporal Dynamics of Turbulent Flow with\n  Test-time Refinement",
    "a_abstract":"The precise simulation of turbulent flows holds immense significance across\nvarious scientific and engineering domains, including climate science,\nfreshwater science, and energy-efficient manufacturing. Within the realm of\nsimulating turbulent flows, large eddy simulation (LES) has emerged as a\nprevalent alternative to direct numerical simulation (DNS), offering\ncomputational efficiency. However, LES cannot accurately capture the full\nspectrum of turbulent transport scales and is present only at a lower spatial\nresolution. Reconstructing high-fidelity DNS data from the lower-resolution LES\ndata is essential for numerous applications, but it poses significant\nchallenges to existing super-resolution techniques, primarily due to the\ncomplex spatio-temporal nature of turbulent flows. This paper proposes a novel\nflow reconstruction approach that leverages physical knowledge to model flow\ndynamics. Different from traditional super-resolution techniques, the proposed\napproach uses LES data only in the testing phase through a degradation-based\nrefinement approach to enforce physical constraints and mitigate cumulative\nreconstruction errors over time. Furthermore, a feature sampling strategy is\ndeveloped to enable flow data reconstruction across different resolutions. The\nresults on two distinct sets of turbulent flow data indicate the effectiveness\nof the proposed method in reconstructing high-resolution DNS data, preserving\nthe inherent physical attributes of flow transport, and achieving DNS\nreconstruction at different resolutions.",
    "explanation":"his paper proposes a novel flow recon-\nstruction approach that leverages physical knowledge to\nmodel flow dynamics.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Model-free simulations of turbulent reactive flows"
    ],
    "b_abstract":[
      "A critical review of the modern computational methods for solving the transport equations of turbulent reacting single-phase flows is presented. Primary consideration is given to those methods which lead to \u2018model-free\u2019 simulations while some attention is devoted to \u2018turbulence modeling\u2019. Emphasis is placed upon the role of supercomputers and how their increased computational capacities may be exploited to allow better simulations of the physics of turbulent reactive flows. Comparisons between the commonly employed computational schemes for simulating these flows are given, with the advantages and the limitations associated with each scheme being highlighted. Examples are presented of recent applications of model-free simulations to a variety of unsteady reacting flows, with detailed discussions on the physical phenomena captured by such simulations. Due to the nature of this review, experimental contributions are mentioned only in the context of providing empirical evidence. References are made to other contributions which are not directly related to the computational efforts in order to provide a reasonably comprehensive bibliography for those interested in pursuing various topics in greater detail. Predictions of future accomplishments, as well as some suggestions for future work, are also given."
    ],
    "b_categories":[
      "physics.flu-dyn"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "b40"
    ],
    "c_title":[
      "Physics guided neural networks for spatio-temporal superresolution of turbulent flows"
    ],
    "c_abstract":[
      "Direct numerical simulation (DNS) of turbulent flows is computationally expensive and cannot be applied to flows with large Reynolds numbers. Low-resolution large eddy simulation (LES) is a popular alternative, but it is unable to capture all of the scales of turbulent transport accurately. Reconstructing DNS from low-resolution LES is critical for large-scale simulation in many scientific and engineering disciplines, but it poses many challenges to existing super-resolution methods due to the complexity of turbulent flows and computational cost of generating frequent LES data. We propose a physics-guided neural network for reconstructing frequent DNS from sparse LES data by enhancing its spatial resolution and temporal frequency. Our proposed method consists of a partial differential equation (PDE)-based recurrent unit for capturing underlying temporal processes and a physics-guided super-resolution model that incorporates additional physical constraints. We demonstrate the effectiveness of both components in reconstructing the Taylor-Green Vortex using sparse LES data. Moreover, we show that the proposed recurrent unit can preserve the physical characteristics of turbulent flows by leveraging the physical relationships in the Navier-Stokes equation."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.10196",
    "a_title":"High-dimensional Statistics Applications to Batch Effects in\n  Metabolomics",
    "a_abstract":"Batch effects are inevitable in large-scale metabolomics. Prior to formal\ndata analysis, batch effect correction (BEC) is applied to prevent from\nobscuring biological variations, and batch effect evaluation (BEE) is used for\ncorrection assessment. However, existing BEE algorithms neglect covariances\nbetween the variables, and existing BEC algorithms might fail to adequately\ncorrect the covariances. Therefore, we resort to recent advancements in\nhigh-dimensional statistics, and respectively propose \"quality control-based\nsimultaneous tests (QC-ST)\" and \"covariance correction (CoCo)\". Validated by\nthe simulation data, QC-ST can simultaneously detect the statistical\nsignificance of QC samples' mean vectors and covariance matrices across\ndifferent batches, and has a satisfactory statistical performance in empirical\nsizes, empirical powers, and computational speed. Then, we apply four QC-based\nBEC algorithms to two large cohort datasets, and find that extreme gradient\nboost (XGBoost) performs best in relative standard deviation (RSD) and\ndispersion-ratio (D-ratio). After prepositive BEC, if QC-ST still suggests that\nbatch effects between some two batches are significant, CoCo should be\nimplemented. And after CoCo (if necessary), the four metrics (i.e., RSD,\nD-ratio, classification performance, and QC-ST) might be further improved. In\nsummary, under the guidance of QC-ST, we can develop a matching strategy to\nintegrate multiple BEC algorithms more rationally and flexibly, and minimize\nbatch effects for reliable biological conclusions.",
    "explanation":"Batch effects are inevitable in large-scale metabolomics. Prior to formal data analysis, batch effect correction (BEC) is applied to prevent from obscuring biological variations, and batch effect evaluation (BEE) is used for correction assessment.we apply four QC-based BEC algorithms to two large cohort datasets, and find that extreme gradient boost (XGBoost) performs best in relative standard deviation (RSD) and dispersion-ratio (D-ratio).",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Quality assurance procedures for mass spectrometry untargeted metabolomics. a review"
    ],
    "b_abstract":[
      "Untargeted metabolomics, as a global approach, has already proven its great potential and capabilities for the investigation of health and disease, as well as the wide applicability for other research areas. Although great progress has been made on the feasibility of metabolomics experiments, there are still some challenges that should be faced and that includes all sources of fluctuations and bias affecting every step involved in multiplatform untargeted metabolomics studies. The identification and reduction of the main sources of unwanted variation regarding the pre-analytical, analytical and post-analytical phase of metabolomics experiments is essential to ensure high data quality. Nowadays, there is still a lack of information regarding harmonized guidelines for quality assurance as those available for targeted analysis. In this review, sources of variations to be considered and minimized along with methodologies and strategies for monitoring and improvement the quality of the results are discussed. The given information is based on evidences from different groups among our own experiences and recommendations for each stage of the metabolomics workflow. The comprehensive overview with tools presented here might serve other researchers interested in monitoring, controlling and improving the reliability of their findings by implementation of good experimental quality practices in the untargeted metabolomics study."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b16"
    ],
    "c_title":[
      "XGBoost: A Scalable Tree Boosting System"
    ],
    "c_abstract":[
      "Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems."
    ],
    "c_categories":[
      "cs.LG"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2412.00225",
    "a_title":"Meta-learning Loss Functions of Parametric Partial Differential\n  Equations Using Physics-Informed Neural Networks",
    "a_abstract":"This paper proposes a new way to learn Physics-Informed Neural Network loss\nfunctions using Generalized Additive Models. We apply our method by\nmeta-learning parametric partial differential equations, PDEs, on Burger's and\n2D Heat Equations. The goal is to learn a new loss function for each parametric\nPDE using meta-learning. The derived loss function replaces the traditional\ndata loss, allowing us to learn each parametric PDE more efficiently, improving\nthe meta-learner's performance and convergence.",
    "explanation":"This paper proposes a new way to learn Physics-Informed Neural Network loss functions using Generalized Additive Models.We apply our method by meta-learning parametric partial differential equations, PDEs, on Burger\u2019s and 2D Heat Equations.",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "The Burgers equation"
    ],
    "b_abstract":[
      "The Burgers equation is a simple equation to understand the main properties of the Navier-Stokes equations. In this one-dimensional equation the pressure is neglected but the effects of the nonlinear and viscous terms remain, hence as in the Navier-Stokes equations a Reynolds number can be defined. This number expresses the ratio between the advective and the viscous contribution in a flow. The present book deals with flows at high Reynolds numbers where the nonlinear terms play a fundamental role, and the physics is more complicated than that when the viscous term dominates. The simulation of the flow evolution then necessitates the use of accurate and robust numerical methods. In 3D turbulent flows, where the number of degrees of freedom is greater than in high Re laminar flows, to get solutions it is necessary to introduce some sort of closure to account for the impossibility to resolve the small scales. Before applying any new idea about numerical methods to 3D flows, the good sense suggests to find the simplest equation to test these ideas. This consideration explains why the Burgers equation was often used to check new numerical methods or closure for turbulent flows."
    ],
    "b_categories":[
      "math.AP"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "b17"
    ],
    "c_title":[
      "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations"
    ],
    "c_abstract":[
      "We introduce physics-informed neural networks \u2013 neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge\u2013Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction\u2013diffusion systems, and the propagation of nonlinear shallow-water waves."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.05456",
    "a_title":"Comparative Study of Probabilistic Atlas and Deep Learning Approaches\n  for Automatic Brain Tissue Segmentation from MRI Using N4 Bias Field\n  Correction and Anisotropic Diffusion Pre-processing Techniques",
    "a_abstract":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI)\nimages is vital for accurate diagnosis and further analysis in medical imaging.\nDespite advancements in segmentation techniques, a comprehensive comparison\nbetween traditional statistical methods and modern deep learning approaches\nusing pre-processing techniques like N4 Bias Field Correction and Anisotropic\nDiffusion remains underexplored. This study provides a comparative analysis of\nvarious segmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and\nLinkNet, enhanced with these pre-processing techniques to segment brain tissues\n(white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF)) on the\nInternet Brain Segmentation Repository (IBSR18) dataset. Our results\ndemonstrate that the 3D nnU-Net model outperforms others, achieving the highest\nmean Dice Coefficient score (0.937 +- 0.012), while the 2D nnU-Net model\nrecorded the lowest mean Hausdorff Distance (5.005 +- 0.343 mm) and the lowest\nmean Absolute Volumetric Difference (3.695 +- 2.931 mm) across five unseen test\nsamples. The findings highlight the superiority of nnU-Net models in brain\ntissue segmentation, particularly when combined with N4 Bias Field Correction\nand Anisotropic Diffusion pre-processing techniques. Our implemented code can\nbe accessed via GitHub.",
    "explanation":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI) images is vital for accurate diagnosis and further analysis in medical imaging. \n\nThis study provides a comparative analysis of various\nsegmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and LinkNet, enhanced with these preprocessing techniques to segment brain tissue",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "MRI segmentation of the human brain: challenges, methods, and applications"
    ],
    "b_abstract":[
      "Image segmentation is one of the most important tasks in medical image analysis and is often the first and the most critical step in many clinical applications. In brain MRI analysis, image segmentation is commonly used for measuring and visualizing the brain\u2019s anatomical structures, for analyzing brain changes, for delineating pathological regions, and for surgical planning and image-guided interventions. In the last few decades, various segmentation techniques of different accuracy and degree of complexity have been developed and reported in the literature. In this paper we review the most popular methods commonly used for brain MRI segmentation. We highlight differences between them and discuss their capabilities, advantages, and limitations. To address the complexity and challenges of the brain MRI segmentation problem, we first introduce the basic concepts of image segmentation. Then, we explain different MRI preprocessing steps including image registration, bias field correction, and removal of nonbrain tissue. Finally, after reviewing different brain MRI segmentation methods, we discuss the validation problem in brain MRI segmentation."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "b11"
    ],
    "c_title":[
      "U-net: Convolutional networks for biomedical image segmentation"
    ],
    "c_abstract":[
      "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU."
    ],
    "c_categories":[
      "cs.AI"
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":true,
    "research_type":"applied"
  },
  {
    "id":"2411.01019",
    "a_title":"A lightweight Convolutional Neural Network based on U shape structure\n  and Attention Mechanism for Anterior Mediastinum Segmentation",
    "a_abstract":"To automatically detect Anterior Mediastinum Lesions (AMLs) in the Anterior\nMediastinum (AM), the primary requirement will be an automatic segmentation\nmodel specifically designed for the AM. The prevalence of AML is extremely low,\nmaking it challenging to conduct screening research similar to lung cancer\nscreening. Retrospectively reviewing chest CT scans over a specific period to\ninvestigate the prevalence of AML requires substantial time. Therefore,\ndeveloping an Artificial Intelligence (AI) model to find location of AM helps\nradiologist to enhance their ability to manage workloads and improve diagnostic\naccuracy for AMLs. In this paper, we introduce a U-shaped structure network to\nsegment AM. Two attention mechanisms were used for maintaining long-range\ndependencies and localization. In order to have the potential of Multi-Head\nSelf-Attention (MHSA) and a lightweight network, we designed a parallel MHSA\nnamed Wide-MHSA (W-MHSA). Maintaining long-range dependencies is crucial for\nsegmentation when we upsample feature maps. Therefore, we designed a Dilated\nDepth-Wise Parallel Path connection (DDWPP) for this purpose. In order to\ndesign a lightweight architecture, we introduced an expanding convolution block\nand combine it with the proposed W-MHSA for feature extraction in the encoder\npart of the proposed U-shaped network. The proposed network was trained on 2775\nAM cases, which obtained an average Dice Similarity Coefficient (DSC) of\n87.83%, mean Intersection over Union (IoU) of 79.16%, and Sensitivity of\n89.60%. Our proposed architecture exhibited superior segmentation performance\ncompared to the most advanced segmentation networks, such as Trans Unet,\nAttention Unet, Res Unet, and Res Unet++.",
    "explanation":"It's leveraging AI in another diffrent domain, namely medical science, to detect Anterior Mediastinum Lesions.",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Anterior mediastinal nodular lesion segmentation from chest computed tomography imaging using UNet based neural network with attention mechanisms"
    ],
    "b_abstract":[
      "Automated detection of anterior mediastinal nodular lesions (AMLs) has significance for clinical usage as it is challenging for radiologists to accurately identify AMLs from chest computed tomography (CT) imaging due to various factors, including poor resolution, variations in intensity and the similarity of the AMLs to other tissues. To assist radiologists in AML detection from chest CT imaging, a UNet-based computer-aided detection (CADe) system is proposed to segment AMLs from slice images of the chest CT scans. The proposed network adopts a modified UNet architecture. To guide the proposed network to selectively focus on AMLs and potentially disregard others in the image, different attention mechanisms are utilized in the proposed network, including the self-attention mechanism and the convolutional block attention module (CBAM). The proposed network was trained and evaluated on 180 chest CT scans which consist of 180 AMLs. 90 AMLs were identified as thymic cysts, and 90 AMLs were diagnosed as thymoma. The proposed network achieved an average dice similarity coefficient (DSC) of 93.23 with 5-fold cross-validation, for which the mean Intersection over Union (IoU), sensitivity and specificity were 90.29, 93.98 and 95.68 respectively. Our method demonstrated an improved segmentation performance over state-of-the-art segmentation networks, including UNet, ResUNet, TransUNet and UNet++. The proposed network employing attention mechanisms exhibited a promising result for segmenting AMLs from chest CT imaging and could be used to automate the AML detection process for achieving improved diagnostic reliability."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.19343"
    ],
    "c_title":[
      "Effect of a new type of healthy and live food supplement on osteoporosis\n  blood parameters and induced rheumatoid arthritis in Wistar rats"
    ],
    "c_abstract":[
      "Summary Osteoporosis is a skeletal disorder, characterized by a decrease in\nbone strength and puts the individual at risk for fracture. On the other hand,\nrheumatoid arthritis is a systemic disease of unknown etiology that causes\ninflammation of the joints of the organs. Purpose Due to the destructive\neffects of these diseases and its increasing prevalence and lack of appropriate\nmedication for treatment, the present study aimed to evaluate the therapeutic\neffect of a new type of healthy and live food supplement on rheumatoid\narthritis and induced osteoporosis in rats. Methods In this research, healthy\nand live food powder were synthesized by a new and green route. This organic\nbiomaterial was named NBS. The NBS food supplement had various vitamins, macro\nand micro molecules, and ingredients. The new healthy and nutritious diet\nshowed that the use of this supplement led to the return of the parameters to\nnormal levels. Results The concentration of 12.5 mg\/ kg showed the least\ntherapeutic effect and 50 mg\/ kg had the highest therapeutic effect for\nosteoporosis. The results of blood parameters involved in inflammation in both\nhealthy and patient groups showed that the use of complete adjuvant induction\ncauses joint inflammation. In the study of the interaction of the\nconcentrations, it was observed that the concentration of 50 mg\/ kg had the\nhighest therapeutic effect against the disease in the studied mice. Conclusion\nThe results showed that the new healthy and viable supplement restores the\nblood osteoporotic and rheumatoid factors of the mice to normal."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.01019",
    "a_title":"A lightweight Convolutional Neural Network based on U shape structure\n  and Attention Mechanism for Anterior Mediastinum Segmentation",
    "a_abstract":"To automatically detect Anterior Mediastinum Lesions (AMLs) in the Anterior\nMediastinum (AM), the primary requirement will be an automatic segmentation\nmodel specifically designed for the AM. The prevalence of AML is extremely low,\nmaking it challenging to conduct screening research similar to lung cancer\nscreening. Retrospectively reviewing chest CT scans over a specific period to\ninvestigate the prevalence of AML requires substantial time. Therefore,\ndeveloping an Artificial Intelligence (AI) model to find location of AM helps\nradiologist to enhance their ability to manage workloads and improve diagnostic\naccuracy for AMLs. In this paper, we introduce a U-shaped structure network to\nsegment AM. Two attention mechanisms were used for maintaining long-range\ndependencies and localization. In order to have the potential of Multi-Head\nSelf-Attention (MHSA) and a lightweight network, we designed a parallel MHSA\nnamed Wide-MHSA (W-MHSA). Maintaining long-range dependencies is crucial for\nsegmentation when we upsample feature maps. Therefore, we designed a Dilated\nDepth-Wise Parallel Path connection (DDWPP) for this purpose. In order to\ndesign a lightweight architecture, we introduced an expanding convolution block\nand combine it with the proposed W-MHSA for feature extraction in the encoder\npart of the proposed U-shaped network. The proposed network was trained on 2775\nAM cases, which obtained an average Dice Similarity Coefficient (DSC) of\n87.83%, mean Intersection over Union (IoU) of 79.16%, and Sensitivity of\n89.60%. Our proposed architecture exhibited superior segmentation performance\ncompared to the most advanced segmentation networks, such as Trans Unet,\nAttention Unet, Res Unet, and Res Unet++.",
    "explanation":"It's leveraging AI in another diffrent domain, namely medical science, to detect Anterior Mediastinum Lesions.",
    "b_id":[
      "b6",
      "b1"
    ],
    "b_title":[
      "Screening for lung cancer: 2023 guideline update from the American Cancer Society",
      "Incidental Anterior Mediastinal Nodular Lesions on\u00a0Chest CT in Asymptomatic Subjects"
    ],
    "b_abstract":[
      "Abstract Lung cancer is the leading cause of mortality and person\u2010years life lost from among US men women. Early detection has been shown to be associated with reduced lung mortality. Our objective was update American Cancer Society (ACS) 2013 screening (LCS) guideline for adults at high risk cancer. The intended provide guidance health care providers their patients who are due a history smoking. ACS Guideline Development Group (GDG) utilized systematic review LCS literature commissioned Preventive Services Task Force 2021 recommendation update; second years since quitting smoking (YSQ); published 2021; two Intervention Surveillance Modeling Network\u2010validated models assess benefits harms screening; an epidemiologic modeling analysis examining effect YSQ aging on risk; updated benefit\u2010to\u2010radiation\u2010risk ratios follow\u2010up examinations. GDG also examined disease burden data National Institute\u2019s Surveillance, Epidemiology, End Results program. Formulation recommendations based quality evidence judgment (incorporating values preferences) about balance harms. judged that overall moderate sufficient support strong individuals meet eligibility criteria. in women aged 50\u201380 reduction deaths across range study designs, inferential supports older than 80 good health. recommends annual low\u2010dose computed tomography asymptomatic currently smoke or formerly smoked have \u226520 pack\u2010year ( , ). Before decision made initiate LCS, should engage shared decision\u2010making discussion qualified professional. For smoked, number not criterion begin stop screening. Individuals receive counseling quit connected cessation resources. comorbid conditions substantially limit expectancy screened. These considered by discussions LCS. If fully implemented, these likelihood significantly reducing death suffering United States.",
      "Objective: The aim of this study was to investigate the prevalence and characteristics of nodular lesions in the anterior mediastinum that had been found incidentally on screening chest computed tomography (CT) in asymptomatic subjects. Methods: We included 56,358 consecutive participants (mean age 52.4 \u00b1 10.5 years; male-female ratio 35,306:21,052) who underwent a baseline low-dose chest CT scan as part of a health checkup from 2006 through 2013. After the presence of anterior mediastinal nodular lesion had been confirmed, their CT findings, confirmatory diagnosis, and interval CT scan were reviewed. The standardized prevalence ratio for thymic epithelial tumor was calculated on the basis of the Republic of Korea cancer statistics for 2014. Results: Of the 56,358 participants, 413 (0.73%) had lesions (95% confidence interval: 0.66-0.80%); the prevalence increased with age (p <0.001) and a history of malignancy (p = 0.005). Of the lesions, 85.2% were smaller than 2 cm, 61.3% were round, and 80.2% had CT attenuation higher than 20 Hounsfield units. Among 51 proven cases, 39 lesions (76.9%) were benign and 12 (23.1%) were malignant. The standardized prevalence ratio for thymic epithelial tumor was 2.04 (95% confidence interval: 1.01-3.42). Of 11 resected thymic epithelial tumors, five were carcinomas, 10 were stage I or II, and all were completely resected without recurrence. Of the 237 unconfirmed cases with a follow-up CT scan, 82.2% were stable, 8.9% had increased, and the other 8.9% had decreased. Conclusions: The prevalence of incidental nodular lesion was 0.73%. Most lesions had CT features that were indistinguishable from thymic epithelial tumors, but a considerable portion of the lesions were suspected to be benign. Incidental thymic epithelial tumors were more prevalent than clinically detected tumors, were early-stage cancer, and showed favorable outcomes."
    ],
    "b_categories":[
      "q-bio.TO",
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.07709"
    ],
    "c_title":[
      "MAGELLAN: Metacognitive predictions of learning progress guide autotelic\n  LLM agents in large goal spaces"
    ],
    "c_abstract":[
      "Open-ended learning agents must efficiently prioritize goals in vast\npossibility spaces, focusing on those that maximize learning progress (LP).\nWhen such autotelic exploration is achieved by LLM agents trained with online\nRL in high-dimensional and evolving goal spaces, a key challenge for LP\nprediction is modeling one's own competence, a form of metacognitive\nmonitoring. Traditional approaches either require extensive sampling or rely on\nbrittle expert-defined goal groupings. We introduce MAGELLAN, a metacognitive\nframework that lets LLM agents learn to predict their competence and LP online.\nBy capturing semantic relationships between goals, MAGELLAN enables\nsample-efficient LP estimation and dynamic adaptation to evolving goal spaces\nthrough generalization. In an interactive learning environment, we show that\nMAGELLAN improves LP prediction efficiency and goal prioritization, being the\nonly method allowing the agent to fully master a large and evolving goal space.\nThese results demonstrate how augmenting LLM agents with a metacognitive\nability for LP predictions can effectively scale curriculum learning to\nopen-ended goal spaces."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.11084",
    "a_title":"BarcodeMamba: State Space Models for Biodiversity Analysis",
    "a_abstract":"DNA barcodes are crucial in biodiversity analysis for building automatic\nidentification systems that recognize known species and discover unseen\nspecies. Unlike human genome modeling, barcode-based invertebrate\nidentification poses challenges in the vast diversity of species and taxonomic\ncomplexity. Among Transformer-based foundation models, BarcodeBERT excelled in\nspecies-level identification of invertebrates, highlighting the effectiveness\nof self-supervised pretraining on barcode-specific datasets. Recently,\nstructured state space models (SSMs) have emerged, with a time complexity that\nscales sub-quadratically with the context length. SSMs provide an efficient\nparameterization of sequence modeling relative to attention-based\narchitectures. Given the success of Mamba and Mamba-2 in natural language, we\ndesigned BarcodeMamba, a performant and efficient foundation model for DNA\nbarcodes in biodiversity analysis. We conducted a comprehensive ablation study\non the impacts of self-supervised training and tokenization methods, and\ncompared both versions of Mamba layers in terms of expressiveness and their\ncapacity to identify \"unseen\" species held back from training. Our study shows\nthat BarcodeMamba has better performance than BarcodeBERT even when using only\n8.3% as many parameters, and improves accuracy to 99.2% on species-level\naccuracy in linear probing without fine-tuning for \"seen\" species. In our\nscaling study, BarcodeMamba with 63.6% of BarcodeBERT's parameters achieved\n70.2% genus-level accuracy in 1-nearest neighbor (1-NN) probing for unseen\nspecies. The code repository to reproduce our experiments is available at\nhttps:\/\/github.com\/bioscan-ml\/BarcodeMamba.",
    "explanation":"The paper talks about the use of BarcodeMamba for better scores in DNA barcode analysis of genomes.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "Biological identifications through DNA barcodes"
    ],
    "b_abstract":[
      "Although much biological research depends upon species diagnoses, taxonomic expertise is collapsing.We are convinced that the sole prospect for a sustainable identification capability lies in construction of systems employ DNA sequences as taxon 'barcodes'.We establish mitochondrial gene cytochrome c oxidase I (COI) can serve core global bioidentification system animals.First, we demonstrate COI profiles, derived from low-density sampling higher categories, ordinarily assign newly analysed taxa to appropriate phylum or order.Second, species-level assignments be obtained by creating comprehensive profiles.A model profile, based analysis single individual each 200 closely allied lepidopterans, was 100% successful correctly identifying subsequent specimens.When fully developed, will provide reliable, cost-effective and accessible solution current problem identification.Its assembly also generate important new insights into diversification life rules molecular evolution."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.15985"
    ],
    "c_title":[
      "Exploring the Reliability of Self-explanation and its Relationship with\n  Classification in Language Model-driven Financial Analysis"
    ],
    "c_abstract":[
      "Language models (LMs) have exhibited exceptional versatility in reasoning and\nin-depth financial analysis through their proprietary information processing\ncapabilities. Previous research focused on evaluating classification\nperformance while often overlooking explainability or pre-conceived that\nrefined explanation corresponds to higher classification accuracy. Using a\npublic dataset in finance domain, we quantitatively evaluated self-explanations\nby LMs, focusing on their factuality and causality. We identified the\nstatistically significant relationship between the accuracy of classifications\nand the factuality or causality of self-explanations. Our study built an\nempirical foundation for approximating classification confidence through\nself-explanations and for optimizing classification via proprietary reasoning."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.11084",
    "a_title":"BarcodeMamba: State Space Models for Biodiversity Analysis",
    "a_abstract":"DNA barcodes are crucial in biodiversity analysis for building automatic\nidentification systems that recognize known species and discover unseen\nspecies. Unlike human genome modeling, barcode-based invertebrate\nidentification poses challenges in the vast diversity of species and taxonomic\ncomplexity. Among Transformer-based foundation models, BarcodeBERT excelled in\nspecies-level identification of invertebrates, highlighting the effectiveness\nof self-supervised pretraining on barcode-specific datasets. Recently,\nstructured state space models (SSMs) have emerged, with a time complexity that\nscales sub-quadratically with the context length. SSMs provide an efficient\nparameterization of sequence modeling relative to attention-based\narchitectures. Given the success of Mamba and Mamba-2 in natural language, we\ndesigned BarcodeMamba, a performant and efficient foundation model for DNA\nbarcodes in biodiversity analysis. We conducted a comprehensive ablation study\non the impacts of self-supervised training and tokenization methods, and\ncompared both versions of Mamba layers in terms of expressiveness and their\ncapacity to identify \"unseen\" species held back from training. Our study shows\nthat BarcodeMamba has better performance than BarcodeBERT even when using only\n8.3% as many parameters, and improves accuracy to 99.2% on species-level\naccuracy in linear probing without fine-tuning for \"seen\" species. In our\nscaling study, BarcodeMamba with 63.6% of BarcodeBERT's parameters achieved\n70.2% genus-level accuracy in 1-nearest neighbor (1-NN) probing for unseen\nspecies. The code repository to reproduce our experiments is available at\nhttps:\/\/github.com\/bioscan-ml\/BarcodeMamba.",
    "explanation":"The paper talks about the use of BarcodeMamba for better scores in DNA barcode analysis of genomes.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "BarcodeBERT: Transformers for Biodiversity Analysis"
    ],
    "b_abstract":[
      "Understanding biodiversity is a global challenge, in which DNA barcodes - short snippets of that cluster by species play pivotal role. In particular, invertebrates, highly diverse and under-explored group, pose unique taxonomic complexities. We explore machine learning approaches, comparing supervised CNNs, fine-tuned foundation models, barcode-specific masking strategy across datasets varying complexity. While simpler tasks favor CNNs or transformers, challenging species-level identification demands paradigm shift towards self-supervised pretraining. propose BarcodeBERT, the first method for general analysis, leveraging 1.5 M invertebrate barcode reference library. This work highlights how dataset specifics coverage impact model selection, underscores role pretraining achieving high-accuracy barcode-based at genus level. Indeed, without fine-tuning step, BarcodeBERT pretrained on large outperforms DNABERT DNABERT-2 multiple downstream classification tasks. The code repository available https:\/\/github.com\/Kari-Genomics-Lab\/BarcodeBERT"
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04869"
    ],
    "c_title":[
      "Transcriptome signature for the identification of bevacizumab responders\n  in ovarian cancer"
    ],
    "c_abstract":[
      "The standard of care for ovarian cancer comprises cytoreductive surgery,\nfollowed by adjuvant platinum-based chemotherapy plus taxane therapy and\nmaintenance therapy with the antiangiogenic compound bevacizumab and\/or a PARP\ninhibitor. Nevertheless, there is currently no clear clinical indication for\nthe use of bevacizumab, highlighting the urgent need for biomarkers to assess\nthe response to bevacizumab. In the present study, based on a novel RNA-seq\ndataset (n=181) and a previously published microarray-based dataset (n=377), we\nhave identified an expression signature potentially associated with benefit\nfrom bevacizumab addition and assumed to reflect cancer stemness acquisition\ndriven by activation of CTCFL. Patients with this signature demonstrated\nimproved overall survival when bevacizumab was added to standard chemotherapy\nin both novel (HR=0.41(0.23-0.74), adj.p-value=7.70e-03) and previously\npublished cohorts (HR=0.51(0.34-0.75), adj.p-value=3.25e-03), while no\nsignificant differences in survival explained by treatment were observed in\npatients negative for this signature. In addition to the CTCFL signature, we\nfound several other reproducible expression signatures which may also represent\nbiomarker candidates not related to established molecular subtypes of ovarian\ncancer and require further validation studies based on additional RNA-seq data."
    ],
    "c_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00609",
    "a_title":"Tumor Location-weighted MRI-Report Contrastive Learning: A Framework for\n  Improving the Explainability of Pediatric Brain Tumor Diagnosis",
    "a_abstract":"Despite the promising performance of convolutional neural networks (CNNs) in\nbrain tumor diagnosis from magnetic resonance imaging (MRI), their integration\ninto the clinical workflow has been limited. That is mainly due to the fact\nthat the features contributing to a model's prediction are unclear to\nradiologists and hence, clinically irrelevant, i.e., lack of explainability. As\nthe invaluable sources of radiologists' knowledge and expertise, radiology\nreports can be integrated with MRI in a contrastive learning (CL) framework,\nenabling learning from image-report associations, to improve CNN\nexplainability. In this work, we train a multimodal CL architecture on 3D brain\nMRI scans and radiology reports to learn informative MRI representations.\nFurthermore, we integrate tumor location, salient to several brain tumor\nanalysis tasks, into this framework to improve its generalizability. We then\napply the learnt image representations to improve explainability and\nperformance of genetic marker classification of pediatric Low-grade Glioma, the\nmost prevalent brain tumor in children, as a downstream task. Our results\nindicate a Dice score of 31.1% between the model's attention maps and manual\ntumor segmentation (as an explainability measure) with test classification\nperformance of 87.7%, significantly outperforming the baselines. These\nenhancements can build trust in our model among radiologists, facilitating its\nintegration into clinical practices for more efficient tumor diagnosis.",
    "explanation":"The article presents a research involving the use of Computer Science methods to treat problems in Medicine. In this case, applying the use of Convolutional Neural Networks (CNN) for the recognition of pediatric tumors in medical images and Contrastive Learning (CL) to improve the explainability of the model.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Pediatric low-grade glioma: State-of-the-art and ongoing challenges"
    ],
    "b_abstract":[
      "Abstract The most common childhood central nervous system (CNS) tumor is pediatric low-grade glioma (pLGG), representing 30%\u201340% of all CNS tumors in children. Although there high associated morbidity, tumor-related mortality relatively rare. pLGG now conceptualized as a chronic disease, underscoring the importance functional outcomes and quality-of-life measures. A wealth data has emerged about these tumors, including better understanding their natural history molecular drivers, paving way for use targeted inhibitors. While treatments have heralded tremendous promise, challenges remain how to best optimize use, long-term toxicities with inhibitors unknown. International Pediatric Low-Grade Glioma Coalition (iPLGGc) global group physicians scientists expertise focused on addressing key issues. Here, iPLGGc provides an overview current state-of-the-art pLGG, epidemiology, histology, landscape, treatment paradigms, survival outcomes, imaging response, ongoing challenges. This paper also serves introduction 3 other manuscripts (1) preclinical models, (2) consensus framework conducting early-phase clinical trials (3) resistance, rebound, recurrence."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.11062"
    ],
    "c_title":[
      "Active Learning from Scene Embeddings for End-to-End Autonomous Driving"
    ],
    "c_abstract":[
      "In the field of autonomous driving, end-to-end deep learning models show\ngreat potential by learning driving decisions directly from sensor data.\nHowever, training these models requires large amounts of labeled data, which is\ntime-consuming and expensive. Considering that the real-world driving data\nexhibits a long-tailed distribution where simple scenarios constitute a\nmajority part of the data, we are thus inspired to identify the most\nchallenging scenarios within it. Subsequently, we can efficiently improve the\nperformance of the model by training with the selected data of the highest\nvalue. Prior research has focused on the selection of valuable data by\nempirically designed strategies. However, manually designed methods suffer from\nbeing less generalizable to new data distributions. Observing that the BEV\n(Bird's Eye View) features in end-to-end models contain all the information\nrequired to represent the scenario, we propose an active learning framework\nthat relies on these vectorized scene-level features, called SEAD. The\nframework selects initial data based on driving-environmental information and\nincremental data based on BEV features. Experiments show that we only need 30\\%\nof the nuScenes training data to achieve performance close to what can be\nachieved with the full dataset. The source code will be released."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00609",
    "a_title":"Tumor Location-weighted MRI-Report Contrastive Learning: A Framework for\n  Improving the Explainability of Pediatric Brain Tumor Diagnosis",
    "a_abstract":"Despite the promising performance of convolutional neural networks (CNNs) in\nbrain tumor diagnosis from magnetic resonance imaging (MRI), their integration\ninto the clinical workflow has been limited. That is mainly due to the fact\nthat the features contributing to a model's prediction are unclear to\nradiologists and hence, clinically irrelevant, i.e., lack of explainability. As\nthe invaluable sources of radiologists' knowledge and expertise, radiology\nreports can be integrated with MRI in a contrastive learning (CL) framework,\nenabling learning from image-report associations, to improve CNN\nexplainability. In this work, we train a multimodal CL architecture on 3D brain\nMRI scans and radiology reports to learn informative MRI representations.\nFurthermore, we integrate tumor location, salient to several brain tumor\nanalysis tasks, into this framework to improve its generalizability. We then\napply the learnt image representations to improve explainability and\nperformance of genetic marker classification of pediatric Low-grade Glioma, the\nmost prevalent brain tumor in children, as a downstream task. Our results\nindicate a Dice score of 31.1% between the model's attention maps and manual\ntumor segmentation (as an explainability measure) with test classification\nperformance of 87.7%, significantly outperforming the baselines. These\nenhancements can build trust in our model among radiologists, facilitating its\nintegration into clinical practices for more efficient tumor diagnosis.",
    "explanation":"The article presents a research involving the use of Computer Science methods to treat problems in Medicine. In this case, applying the use of Convolutional Neural Networks (CNN) for the recognition of pediatric tumors in medical images and Contrastive Learning (CL) to improve the explainability of the model.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Improving Pediatric Low-Grade Neuroepithelial Tumors Molecular Subtype\n  Identification Using a Novel AUROC Loss Function for Convolutional Neural\n  Networks"
    ],
    "b_abstract":[
      "Pediatric Low-Grade Neuroepithelial Tumors (PLGNT) are the most common pediatric cancer type, accounting for 40% of brain tumors in children, and identifying PLGNT molecular subtype is crucial treatment planning. However, gold standard to determine biopsy, which can be impractical or dangerous patients. This research improves performance Convolutional Neural Networks (CNNs) classifying subtypes through MRI scans by introducing a loss function that specifically model's Area Under Receiver Operating Characteristic (ROC) Curve (AUROC), offering non-invasive diagnostic alternative. In this study, retrospective dataset 339 children with (143 BRAF fusion, 71 V600E mutation, 125 non-BRAF) was curated. We employed CNN model Monte Carlo random data splitting. The baseline trained using binary cross entropy (BCE), achieved an AUROC 86.11% differentiating fusion mutations, improved 87.71% our proposed (p-value 0.045). With multiclass classification, from 74.42% 76. 59% 0.0016)."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.12092"
    ],
    "c_title":[
      "Using economic value signals from primate prefrontal cortex in\n  neuro-engineering applications"
    ],
    "c_abstract":[
      "Neural signals related to movement can be measured from intracranial\nrecordings and used in brain-machine interface devices (BMI) to restore\nphysical function in impaired patients. In this study, we explore the use of\nmore abstract neural signals related to economic value in a BMI context. Using\ndata collected from the orbitofrontal cortex in non-human primates, we develop\ndeep learning-based neural decoders that can predict the monkey's choice in a\nvalue-based decision-making task. Out-of-sample performance was improved by\naugmenting the training set with synthesized data, showing the feasibility of\nusing limited training data. We further demonstrate that we can predict the\nmonkey's choice sooner using a neural forecasting module that is equipped with\ntask-related information. These findings support the feasibility of user\npreference-informed neuroengineering devices that leverage abstract cognitive\nsignals."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00726",
    "a_title":"Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading\n  with Cataract",
    "a_abstract":"Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a\ncommon complication of diabetes. As two different imaging tools for DR grading,\ncolor fundus photography (CFP) and infrared fundus photography (IFP) are\nhighly-correlated and complementary in clinical applications. To the best of\nour knowledge, this is the first study that explores a novel multi-modal deep\nlearning framework to fuse the information from CFP and IFP towards more\naccurate DR grading. Specifically, we construct a dual-stream architecture\nCross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus\nimage modalities. In particular, a meticulously engineered Cross-Fundus\nAttention (CFA) module is introduced to capture the correspondence between CFP\nand IFP images. Moreover, we adopt both the single-modality and multi-modality\nsupervisions to maximize the overall performance for DR grading. Extensive\nexperiments on a clinical dataset consisting of 1,713 pairs of multi-modal\nfundus images demonstrate the superiority of our proposed method. Our code will\nbe released for public access.",
    "explanation":"The work combines transformers with two distinct methods that evaluate the quality of retinopathy",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Relation Between Retinal Vasculature and Retinal Thickness in Macular Edema"
    ],
    "b_abstract":[
      "This study has investigated the relationship of retinal vasculature and thickness for Macular Edema (ME) subjects. Ninety sets Fluorescein Angiograph (FA) Optical Coherence Tomography (OCT) 54 participants were analyzed. Multivariate analysis using binary logistic regression model was used to association between vessel parameters thickness. The results reveal feature i.e. fractal dimension (FD) as most sensitive parameter changes in associated with ME. Thus, indicating a direct which is caused due neovascular causing exudates, leakages hemorrhages, applications alternate modality detection"
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.06501"
    ],
    "c_title":[
      "Learning Clustering-based Prototypes for Compositional Zero-shot\n  Learning"
    ],
    "c_abstract":[
      "Learning primitive (i.e., attribute and object) concepts from seen\ncompositions is the primary challenge of Compositional Zero-Shot Learning\n(CZSL). Existing CZSL solutions typically rely on oversimplified data\nassumptions, e.g., modeling each primitive with a single centroid primitive\nrepresentation, ignoring the natural diversities of the attribute (resp.\nobject) when coupled with different objects (resp. attribute). In this work, we\ndevelop ClusPro, a robust clustering-based prototype mining framework for CZSL\nthat defines the conceptual boundaries of primitives through a set of\ndiversified prototypes. Specifically, ClusPro conducts within-primitive\nclustering on the embedding space for automatically discovering and dynamically\nupdating prototypes. These representative prototypes are subsequently used to\nrepaint a well-structured and independent primitive embedding space, ensuring\nintra-primitive separation and inter-primitive decorrelation through\nprototype-based contrastive learning and decorrelation learning. Moreover,\nClusPro efficiently performs prototype clustering in a non-parametric fashion\nwithout the introduction of additional learnable parameters or computational\nbudget during testing. Experiments on three benchmarks demonstrate ClusPro\noutperforms various top-leading CZSL solutions under both closed-world and\nopen-world settings."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00726",
    "a_title":"Cross-Fundus Transformer for Multi-modal Diabetic Retinopathy Grading\n  with Cataract",
    "a_abstract":"Diabetic retinopathy (DR) is a leading cause of blindness worldwide and a\ncommon complication of diabetes. As two different imaging tools for DR grading,\ncolor fundus photography (CFP) and infrared fundus photography (IFP) are\nhighly-correlated and complementary in clinical applications. To the best of\nour knowledge, this is the first study that explores a novel multi-modal deep\nlearning framework to fuse the information from CFP and IFP towards more\naccurate DR grading. Specifically, we construct a dual-stream architecture\nCross-Fundus Transformer (CFT) to fuse the ViT-based features of two fundus\nimage modalities. In particular, a meticulously engineered Cross-Fundus\nAttention (CFA) module is introduced to capture the correspondence between CFP\nand IFP images. Moreover, we adopt both the single-modality and multi-modality\nsupervisions to maximize the overall performance for DR grading. Extensive\nexperiments on a clinical dataset consisting of 1,713 pairs of multi-modal\nfundus images demonstrate the superiority of our proposed method. Our code will\nbe released for public access.",
    "explanation":"The work combines transformers with two distinct methods that evaluate the quality of retinopathy",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    ],
    "b_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.11130"
    ],
    "c_title":[
      "Advanced 3D-Printed Multiphasic Scaffold with Optimal PRP Dosage for\n  Chondrogenesis of BM-MSCs in Osteochondral Tissue Engineering"
    ],
    "c_abstract":[
      "In osteochondral tissue engineering (OCTE), simultaneously regenerating\nsubchondral bone and cartilage tissue presents a significant challenge.\nMultiphasic scaffolds were created and manufactured using 3D printing to\naddress this issue. Excellent interfacial mechanical properties and\nbiocompatibility enhance the growth and chondrogenic differentiation of bone\nmarrow mesenchymal stem cells (BM-MSCs). The subchondral bone bottom layer is\nmimicked by incorporating varying concentrations of graphene oxide (GO) (0%,\n1%, and 2% w\/v) into a bioink composed of alginate (Alg) and gelatin (Gel).\nBased on evaluations of mechanical and biocompatibility properties, 1% GO is\nselected for further studies. Subsequently, the GO concentration is kept\nconstant while varying the platelet-rich plasma (PRP) dosage in the multiphasic\nscaffolds. Different PRP dosages (0%, 1%, 2%, and 3% w\/v) are integrated into\nthe Alg-Gel bioink to simulate cartilage tissues. Results indicate that\n3D-printed scaffolds containing 1% or 2% PRP exhibit favorable biomechanical\nproperties, with no significant differences observed. However, BM-MSCs exposed\nto 2% PRP demonstrate enhanced adhesion, growth, and viability. Additionally,\nreal-time PCR and Alcian blue staining confirm increased chondrogenic\nexpression and glycosaminoglycans (GAGs) synthesis. This work highlights the\npromising potential of 3D-printed multiphasic frameworks in the development of\nOCTE."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05236",
    "a_title":"Designing a Light-based Communication System with a Biomolecular\n  Receiver",
    "a_abstract":"Biological systems transduce signals from their surroundings in numerous\nways. This paper introduces a communication system using the light-gated ion\nchannel Channelrhodopsin-2 (ChR2), which causes an ion current to flow in\nresponse to light. Our design includes a ChR2-based receiver along with\nencoding, modulation techniques and detection. Analyzing the resulting\ncommunication system, we discuss the effect of different parameters on the\nperformance of the system. Finally, we discuss its potential design in the\ncontext of bio-engineering and light-based communication and show that the data\nrate scales up with the number of receptors, indicating that high-speed\ncommunication may be possible.",
    "explanation":"The paper is interdisciplinary because it aims to use channelrhodopsin-2 (ChR2), a biomolecule, as a receiver to design a light-based communication system, which is a work related to engineering.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Channelrhodopsin-2, a directly light-gated cation-selective membrane channel"
    ],
    "b_abstract":[
      "Microbial-type rhodopsins are found in archaea, prokaryotes, and eukaryotes. Some of them represent membrane ion transport proteins such as bacteriorhodopsin, a light-driven proton pump, or channelrhodopsin-1 (ChR1), recently identified light-gated channel from the green alga Chlamydomonas reinhardtii . ChR1 ChR2, related microbial-type rhodopsin C. , were shown to be involved generation photocurrents this alga. We demonstrate by functional expression, both oocytes Xenopus laevis mammalian cells, that ChR2 is directly light-switched cation-selective channel. This opens rapidly after absorption photon generate large permeability for monovalent divalent cations. desensitizes continuous light smaller steady-state conductance. Recovery desensitization accelerated extracellular H + negative potential, whereas closing decelerated intracellular expressed mainly under low-light conditions, suggesting involvement photoreception dark-adapted cells. The predicted seven-transmembrane \u03b1 helices characteristic G protein-coupled receptors but reflect different motif Finally, we may used depolarize small simply illumination."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.02782"
    ],
    "c_title":[
      "A Comprehensive Survey on Feature Extraction Techniques Using I\/Q\n  Imbalance in RFFI"
    ],
    "c_abstract":[
      "The proliferation of Internet of Things (IoT) devices has increased the need\nfor secure authentication. While traditional encryption-based solutions can be\nrobust, they often impose high computational and energy overhead on\nresource-limited IoT nodes. As an alternative, radio frequency fingerprint\nidentification (RFFI) leverages hardware-induced imperfections-such as\nInphase\/Quadrature (I\/Q) imbalance-in Radio Frequency (RF) front-end components\nas unique identifiers that are inherently difficult to clone or spoof. Despite\nrecent advances, significant challenges remain in standardizing feature\nextraction methods, maintaining high accuracy across diverse environments, and\nefficiently handling large-scale IoT deployments. This paper addresses these\ngaps by providing a comprehensive review of feature extraction techniques that\nutilize I\/Q imbalance for RFFI. We also discuss other hardware-based RF\nfingerprinting sources, including power amplifier nonlinearity and oscillator\nimperfections, and examine modern machine learning (ML) and deep learning (DL)\napproaches that enhance device identification performance."
    ],
    "c_categories":[
      [
        "eess.SP"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05236",
    "a_title":"Designing a Light-based Communication System with a Biomolecular\n  Receiver",
    "a_abstract":"Biological systems transduce signals from their surroundings in numerous\nways. This paper introduces a communication system using the light-gated ion\nchannel Channelrhodopsin-2 (ChR2), which causes an ion current to flow in\nresponse to light. Our design includes a ChR2-based receiver along with\nencoding, modulation techniques and detection. Analyzing the resulting\ncommunication system, we discuss the effect of different parameters on the\nperformance of the system. Finally, we discuss its potential design in the\ncontext of bio-engineering and light-based communication and show that the data\nrate scales up with the number of receptors, indicating that high-speed\ncommunication may be possible.",
    "explanation":"The paper is interdisciplinary because it aims to use channelrhodopsin-2 (ChR2), a biomolecule, as a receiver to design a light-based communication system, which is a work related to engineering.",
    "b_id":[
      "b2",
      "b0"
    ],
    "b_title":[
      "Shannon capacity of signal transduction for multiple independent receptors",
      "DESIGN AND IMPLEMENTATION OF VISIBLE LIGHT COMMUNICATION SYSTEM IN INDOOR ENVIRONMENT"
    ],
    "b_abstract":[
      "Cyclic adenosine monophosphate (cAMP) is considered a model system for signal transduction, the mechanism by which cells exchange chemical messages. Our previous work calculated Shannon capacity of single cAMP receptor; however, typical cell may have thousands receptors operating in parallel. In this paper, we calculate transduction with an arbitrary number independent, indistinguishable receptors. By leveraging prior results on feedback receptor, show (somewhat unexpectedly) that achieved IID input distribution, and n times receptor.",
      "Visible Light communication (VLC) using White Light Emitting Diode (LED) is a promising technology for next generation communication for short range, high speed wireless data transmission. In this paper inexpensive transmitter and receiver of VLC system is designed and its performance is evaluated. The effect of natural and artificial ambient light noise sources is also considered. Experimental results show that the data transmission distance achieved upto 0.45m.Performance analysis is done with respect to optical power, photo sensitivity of photodiode at the receiver and the increase in distance between the transmitter and receiver."
    ],
    "b_categories":[
      "eess.SP",
      "cs.SY"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04258"
    ],
    "c_title":[
      "How Large is the Universe of RNA-Like Motifs? A Clustering Analysis of\n  RNA Graph Motifs Using Topological Descriptors"
    ],
    "c_abstract":[
      "We introduce a computational topology-based approach with unsupervised\nmachine-learning algorithms to estimate the database size and content of\nRNA-like graph topologies. Specifically, we apply graph theory enumeration to\ngenerate all 110,667 possible 2D dual graphs for vertex numbers ranging from 2\nto 9. Among them, only 0.11% graphs correspond to approximately 200,000 known\nRNA atomic fragments (collected in 2021) using the RNA-as-Graphs (RAG) mapping\nmethod. The remaining 99.89% of the dual graphs may be RNA-like or\nnon-RNA-like. To determine which dual graphs in the 99.89% hypothetical set are\nmore likely to be associated with RNA structures, we apply computational\ntopology descriptors using the Persistent Spectral Graphs (PSG) method to\ncharacterize each graph using 19 PSG-based features and use clustering\nalgorithms that partition all possible dual graphs into two clusters, RNA-like\ncluster and non-RNA-like cluster. The distance of each dual graph to the center\nof the RNA-like cluster represents the likelihood of it belonging to RNA\nstructures. From validation, our PSG-based RNA-like cluster includes 97.3% of\nthe 121 known RNA dual graphs, suggesting good performance. Furthermore,\n46.017% of the hypothetical RNAs are predicted to be RNA-like. Significantly,\nwe observe that all the top 15 RNA-like dual graphs can be separated into\nmultiple subgraphs, whereas the top 15 non-RNA-like dual graphs tend not to\nhave any subgraphs. Moreover, a significant topological difference between top\nRNA-like and non-RNA-like graphs is evident when comparing their topological\nfeatures. These findings provide valuable insights into the size of the RNA\nmotif universe and RNA design strategies, offering a novel framework for\npredicting RNA graph topologies and guiding the discovery of novel RNA motifs,\nperhaps anti-viral therapeutics by subgraph assembly."
    ],
    "c_categories":[
      [
        "q-bio.BM"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.02815",
    "a_title":"Artificial Intelligence-Enhanced Couinaud Segmentation for Precision\n  Liver Cancer Therapy",
    "a_abstract":"Precision therapy for liver cancer necessitates accurately delineating liver\nsub-regions to protect healthy tissue while targeting tumors, which is\nessential for reducing recurrence and improving survival rates. However, the\nsegmentation of hepatic segments, known as Couinaud segmentation, is\nchallenging due to indistinct sub-region boundaries and the need for extensive\nannotated datasets. This study introduces LiverFormer, a novel Couinaud\nsegmentation model that effectively integrates global context with low-level\nlocal features based on a 3D hybrid CNN-Transformer architecture. Additionally,\na registration-based data augmentation strategy is equipped to enhance the\nsegmentation performance with limited labeled data. Evaluated on CT images from\n123 patients, LiverFormer demonstrated high accuracy and strong concordance\nwith expert annotations across various metrics, allowing for enhanced treatment\nplanning for surgery and radiation therapy. It has great potential to reduces\ncomplications and minimizes potential damages to surrounding tissue, leading to\nimproved outcomes for patients undergoing complex liver cancer treatments.",
    "explanation":"The paper presents a tool that uses Convolutional Neural Networks (CNN) and Transformers, technologies from Computer Science, to improve the accuracy and efficiency of Couinaud segmentation in liver cancer treatment, a challenge in the field of Medicine.",
    "b_id":[
      "b36",
      "b33"
    ],
    "b_title":[
      "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "Automated segmentation of liver segment on portal venous phase MR images using a 3D convolutional neural network"
    ],
    "b_abstract":[
      "While the Transformer architecture has become de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used replace certain components of networks while keeping their overall structure place. We show that this reliance on CNNs not necessary and a pure transformer directly sequences image patches can perform very well classification tasks. When pre-trained large amounts data transferred multiple mid-sized small recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision (ViT) attains excellent results compared state-of-the-art requiring substantially fewer computational resources train.",
      "We aim to develop and validate a three-dimensional convolutional neural network (3D-CNN) model for automatic liver segment segmentation on MRI images.This retrospective study evaluated an automated method using deep that was trained, validated, tested with 367, 157, 158 portal venous phase MR images, respectively. The Dice similarity coefficient (DSC), mean surface distance (MSD), Hausdorff (HD), volume ratio (RV) were used quantitatively measure the accuracy of segmentation. time consumed manual also compared. In addition, applied 100 consecutive cases from real clinical scenario qualitative evaluation indirect evaluation.In quantitative evaluation, achieved high DSC, MSD, HD RV (0.920, 3.34, 3.61 1.01, respectively). Compared segmentation, reduced 26 min 8 s. quality rated as good in 79% cases, moderate 15% poor 6%. 93.4% (99\/106) lesions could be assigned correct by only referring results segmentation.The proposed may serve effective tool anatomical region annotation images."
    ],
    "b_categories":[
      "cs.CV",
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.18661"
    ],
    "c_title":[
      "Geometric immunosuppression in CAR-T cell treatment: Insights from\n  mathematical modeling"
    ],
    "c_abstract":[
      "Chimeric antigen receptor T (CAR-T) cell therapy has emerged as a promising\ntreatment for hematological malignancies, offering a targeted approach to\ncancer treatment. Understanding the complexities of CAR-T cell therapy within\nsolid tumors poses challenges due to the intricate interactions within the\ntumor microenvironment. Mathematical modeling may serve as a valuable tool to\nunravel the dynamics of CAR-T cell therapy and improve its effectiveness in\nsolid tumors. This study aimed to investigate the impact of spatial aspects in\nCAR-T therapy of solid tumors, utilizing cellular automata for modeling\npurposes. Our main objective was to deepen our understanding of treatment\neffects by analyzing scenarios with different spatial distributions and varying\nthe initial quantities of tumor and CAR-T cells. Tumor geometry significantly\ninfluenced treatment efficacy in-silico, with notable differences observed\nbetween tumors with block-like arrangements and those with sparse cell\ndistributions, leading to the concept of immune suppression due to geometrical\neffects. This research delves into the intricate relationship between spatial\ndynamics and the effectiveness of CAR-T therapy in solid tumors, highlighting\nthe relevance of tumor geometry in the outcome of cellular immunotherapy\ntreatments. Our results provide a basis for improving the efficacy of CAR-T\ncell treatments by combining them with other ones reducing the density of\ncompact tumor areas and thus opening access ways for tumor killing T-cells."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.02815",
    "a_title":"Artificial Intelligence-Enhanced Couinaud Segmentation for Precision\n  Liver Cancer Therapy",
    "a_abstract":"Precision therapy for liver cancer necessitates accurately delineating liver\nsub-regions to protect healthy tissue while targeting tumors, which is\nessential for reducing recurrence and improving survival rates. However, the\nsegmentation of hepatic segments, known as Couinaud segmentation, is\nchallenging due to indistinct sub-region boundaries and the need for extensive\nannotated datasets. This study introduces LiverFormer, a novel Couinaud\nsegmentation model that effectively integrates global context with low-level\nlocal features based on a 3D hybrid CNN-Transformer architecture. Additionally,\na registration-based data augmentation strategy is equipped to enhance the\nsegmentation performance with limited labeled data. Evaluated on CT images from\n123 patients, LiverFormer demonstrated high accuracy and strong concordance\nwith expert annotations across various metrics, allowing for enhanced treatment\nplanning for surgery and radiation therapy. It has great potential to reduces\ncomplications and minimizes potential damages to surrounding tissue, leading to\nimproved outcomes for patients undergoing complex liver cancer treatments.",
    "explanation":"The paper presents a tool that uses Convolutional Neural Networks (CNN) and Transformers, technologies from Computer Science, to improve the accuracy and efficiency of Couinaud segmentation in liver cancer treatment, a challenge in the field of Medicine.",
    "b_id":[
      "b13"
    ],
    "b_title":[
      "Liver Anatomy: Portal (and Suprahepatic) or Biliary Segmentation"
    ],
    "b_abstract":[
      "In liver anatomy and surgery, is portal hepatic vein segmentation (French segmentation) to be preferred over arteriobiliary (Healey Schroy, North American segmentation)?Several embryological arguments an analysis of anatomical data from a personal collection 110 vasculobiliary casts were made.Embryological arguments: Portal branching appears first, secondly follows the distribution. Segment II (the left lateral sector) development right lobe. The umbilical enters portion middle lobe, forming segment IV on III left: this paramedian sector. So fissure (between lobes) transversally crosses classical which not unit. VI late secondary prominence VII, reaching anterior margin only in man. Anatomical must added segmentation; academic lobe sector, separates lobes. preferred: duplication branches first order occurs 23.5% cases, while first-order noted 50% livers, being much simpler.Portal seems more accurate."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.16065"
    ],
    "c_title":[
      "CILP-FGDI: Exploiting Vision-Language Model for Generalizable Person\n  Re-Identification"
    ],
    "c_abstract":[
      "The Visual Language Model, known for its robust cross-modal capabilities, has\nbeen extensively applied in various computer vision tasks. In this paper, we\nexplore the use of CLIP (Contrastive Language-Image Pretraining), a\nvision-language model pretrained on large-scale image-text pairs to align\nvisual and textual features, for acquiring fine-grained and domain-invariant\nrepresentations in generalizable person re-identification. The adaptation of\nCLIP to the task presents two primary challenges: learning more fine-grained\nfeatures to enhance discriminative ability, and learning more domain-invariant\nfeatures to improve the model's generalization capabilities. To mitigate the\nfirst challenge thereby enhance the ability to learn fine-grained features, a\nthree-stage strategy is proposed to boost the accuracy of text descriptions.\nInitially, the image encoder is trained to effectively adapt to person\nre-identification tasks. In the second stage, the features extracted by the\nimage encoder are used to generate textual descriptions (i.e., prompts) for\neach image. Finally, the text encoder with the learned prompts is employed to\nguide the training of the final image encoder. To enhance the model's\ngeneralization capabilities to unseen domains, a bidirectional guiding method\nis introduced to learn domain-invariant image features. Specifically,\ndomain-invariant and domain-relevant prompts are generated, and both positive\n(pulling together image features and domain-invariant prompts) and negative\n(pushing apart image features and domain-relevant prompts) views are used to\ntrain the image encoder. Collectively, these strategies contribute to the\ndevelopment of an innovative CLIP-based framework for learning fine-grained\ngeneralized features in person re-identification."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00561",
    "a_title":"Automated Classification of Cell Shapes: A Comparative Evaluation of\n  Shape Descriptors",
    "a_abstract":"This study addresses the challenge of classifying cell shapes from noisy\ncontours, such as those obtained through cell instance segmentation of\nhistological images. We assess the performance of various features for shape\nclassification, including Elliptical Fourier Descriptors, curvature features,\nand lower dimensional representations. Using an annotated synthetic dataset of\nnoisy contours, we identify the most suitable shape descriptors and apply them\nto a set of real images for qualitative analysis. Our aim is to provide a\ncomprehensive evaluation of descriptors for classifying cell shapes, which can\nsupport cell type identification and tissue characterization-critical tasks in\nboth biological research and histopathological assessments.",
    "explanation":"This study addresses the challenge of classifying cell shapes from noisy contours, such as those obtained through cell instance segmentation of histological images.\n\nOur aim is to provide a comprehensive evaluation of descriptors for classifying cell shapes, which can support cell type identification and tissue characterization\u2014critical tasks in both biological research and histopathological assessments.\n",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "Retrieval and classification of shape-based objects using Fourier, generic Fourier, and wavelet-Fourier descriptors technique: A comparative study"
    ],
    "b_abstract":[
      "In this paper, we report retrieval and classification of shape-based objects employing three techniques-conventional Fourier descriptors (FD), generic Fourier descriptors (GFD) and wavelet-Fourier descriptors (WFD) techniques. All the three techniques have been applied to a database of seven different types of shapes. The centroid distance based shape signatures have been used for the derivation of descriptors. The Euclidean distance has been calculated as a similarity measure parameter for shape classification. For WFD technique, a Mexican-hat wavelet function was used. Classification results from all the three techniques were compared and it was observed that WFD performs better than FD and GFD technique. To study the effect of the noise on the retrieval and classification of shapes of different objects, additive and multiplicative noise of various variances were applied to the database. Precision and recall were also measured as parameters of performance metric."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.05607"
    ],
    "c_title":[
      "Prediction of Binding Affinity for ErbB Inhibitors Using Deep Neural\n  Network Model with Morgan Fingerprints as Features"
    ],
    "c_abstract":[
      "The ErbB receptor family, including EGFR and HER2, plays a crucial role in\ncell growth and survival and is associated with the progression of various\ncancers such as breast and lung cancer. In this study, we developed a deep\nlearning model to predict the binding affinity of ErbB inhibitors using\nmolecular fingerprints derived from SMILES representations. The SMILES\nrepresentations for each ErbB inhibitor were obtained from the ChEMBL database.\nWe first generated Morgan fingerprints from the SMILES strings and applied\nAutoDock Vina docking to calculate the binding affinity values. After filtering\nthe dataset based on binding affinity, we trained a deep neural network (DNN)\nmodel to predict binding affinity values from the molecular fingerprints. The\nmodel achieved significant performance, with a Mean Squared Error (MSE) of\n0.2591, Mean Absolute Error (MAE) of 0.3658, and an R-squared value of 0.9389\non the training set. Although performance decreased slightly on the test set (R\nsquared = 0.7731), the model still demonstrated robust generalization\ncapabilities. These results indicate that the deep learning approach is highly\neffective for predicting the binding affinity of ErbB inhibitors, offering a\nvaluable tool for virtual screening and drug discovery."
    ],
    "c_categories":[
      [
        "q-bio.BM"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00561",
    "a_title":"Automated Classification of Cell Shapes: A Comparative Evaluation of\n  Shape Descriptors",
    "a_abstract":"This study addresses the challenge of classifying cell shapes from noisy\ncontours, such as those obtained through cell instance segmentation of\nhistological images. We assess the performance of various features for shape\nclassification, including Elliptical Fourier Descriptors, curvature features,\nand lower dimensional representations. Using an annotated synthetic dataset of\nnoisy contours, we identify the most suitable shape descriptors and apply them\nto a set of real images for qualitative analysis. Our aim is to provide a\ncomprehensive evaluation of descriptors for classifying cell shapes, which can\nsupport cell type identification and tissue characterization-critical tasks in\nboth biological research and histopathological assessments.",
    "explanation":"This study addresses the challenge of classifying cell shapes from noisy contours, such as those obtained through cell instance segmentation of histological images.\n\nOur aim is to provide a comprehensive evaluation of descriptors for classifying cell shapes, which can support cell type identification and tissue characterization\u2014critical tasks in both biological research and histopathological assessments.\n",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "What is a cell type, really? The quest to categorize life's myriad forms."
    ],
    "b_abstract":[
      "The problem of cell type became clear to genome biologist Jason Buenrostro in 2013. He was studying a cell line derived from someone with cancer, trying to map out how the DNA was arranged in the nucleus. The cells should have been pretty much identical, he thought. But the more Buenrostro looked at the DNA, the more differences he found in how it was packaged1. \u201cI realized that there were probably hundreds of flavours,\u201d recalls Buenrostro, who was a graduate student at Stanford University in California at the time."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.03137"
    ],
    "c_title":[
      "L2R: Learning to Reduce Search Space for Generalizable Neural Routing\n  Solver"
    ],
    "c_abstract":[
      "Constructive neural combinatorial optimization (NCO) has attracted growing\nresearch attention due to its ability to solve complex routing problems without\nrelying on handcrafted rules. However, existing NCO methods face significant\nchallenges in generalizing to large-scale problems due to high computational\ncomplexity and inefficient capture of structural patterns. To address this\nissue, we propose a novel learning-based search space reduction method that\nadaptively selects a small set of promising candidate nodes at each step of the\nconstructive NCO process. Unlike traditional methods that rely on fixed\nheuristics, our selection model dynamically prioritizes nodes based on learned\npatterns, significantly reducing the search space while maintaining solution\nquality. Experimental results demonstrate that our method, trained solely on\n100-node instances from uniform distribution, generalizes remarkably well to\nlarge-scale Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing\nProblem (CVRP) instances with up to 1 million nodes from the uniform\ndistribution and over 80K nodes from other distributions."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00922",
    "a_title":"Lung tumor segmentation in MRI mice scans using 3D nnU-Net with minimum\n  annotations",
    "a_abstract":"In drug discovery, accurate lung tumor segmentation is an important step for\nassessing tumor size and its progression using \\textit{in-vivo} imaging such as\nMRI. While deep learning models have been developed to automate this process,\nthe focus has predominantly been on human subjects, neglecting the pivotal role\nof animal models in pre-clinical drug development. In this work, we focus on\noptimizing lung tumor segmentation in mice. First, we demonstrate that the\nnnU-Net model outperforms the U-Net, U-Net3+, and DeepMeta models. Most\nimportantly, we achieve better results with nnU-Net 3D models than 2D models,\nindicating the importance of spatial context for segmentation tasks in MRI mice\nscans. This study demonstrates the importance of 3D input over 2D input images\nfor lung tumor segmentation in MRI scans. Finally, we outperform the prior\nstate-of-the-art approach that involves the combined segmentation of lungs and\ntumors within the lungs. Our work achieves comparable results using only lung\ntumor annotations requiring fewer annotations, saving time and annotation\nefforts. This work\n(https:\/\/anonymous.4open.science\/r\/lung-tumour-mice-mri-64BB) is an important\nstep in automating pre-clinical animal studies to quantify the efficacy of\nexperimental drugs, particularly in assessing tumor changes.",
    "explanation":"In this work, we focus on optimizing lung tumor segmen-\ntation in mice. First, we demonstrate that the nnU-Net model outper-\nforms the U-Net, U-Net3+, and DeepMeta models.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Deep learning model for automatic segmentation of lungs and pulmonary metastasis in small animal MR images"
    ],
    "b_abstract":[
      "Lungs are the most frequent site of metastases growth. The amount and size pulmonary acquired from MRI imaging data important criteria to assess efficacy new drugs in preclinical models. While efficient solutions both for MR downstream automatic segmentation have been proposed human patients, lung animal models remains challenging due physiological motion (respiratory cardiac movements), low protons this organ particular challenge precise metastases. As a consequence post-mortem analysis is currently required obtain information on metastatic volume. In work, we developed complete methodological pipeline automated lungs mice, consisting an sequence image acquisition deep learning method On one hand, optimized mouse with high contrast detection sensitivity. other hand DeepMeta, multiclass U-Net 3+ model automatically segment images. To if able provide accurate metastases, longitudinally imaged mice fast- slow-growing metastasis. Fifty-five balb\/c were injected two different derivatives renal carcinoma cells. Mice SG-bSSFP (self-gated balanced steady state free precession) at time points after injection cancer Both segmentations manually performed by experts. DeepMeta was trained perform based resulting ground truth annotations. Volumes as well number per measured separate test dataset Thanks SG method, 3D bSSFP images artifact-free, enabling serial follow-up Moreover, accurately soon they reached volume \u223c0.02mm3 . Thus distinguish groups terms slow versus fast patterns growth We shown that our methodology combining learning, enables processing whole thus viable alternative histology alone."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.21130"
    ],
    "c_title":[
      "Fast and Accurate Gigapixel Pathological Image Classification with\n  Hierarchical Distillation Multi-Instance Learning"
    ],
    "c_abstract":[
      "Although multi-instance learning (MIL) has succeeded in pathological image\nclassification, it faces the challenge of high inference costs due to\nprocessing numerous patches from gigapixel whole slide images (WSIs). To\naddress this, we propose HDMIL, a hierarchical distillation multi-instance\nlearning framework that achieves fast and accurate classification by\neliminating irrelevant patches. HDMIL consists of two key components: the\ndynamic multi-instance network (DMIN) and the lightweight instance\npre-screening network (LIPN). DMIN operates on high-resolution WSIs, while LIPN\noperates on the corresponding low-resolution counterparts. During training,\nDMIN are trained for WSI classification while generating attention-score-based\nmasks that indicate irrelevant patches. These masks then guide the training of\nLIPN to predict the relevance of each low-resolution patch. During testing,\nLIPN first determines the useful regions within low-resolution WSIs, which\nindirectly enables us to eliminate irrelevant regions in high-resolution WSIs,\nthereby reducing inference time without causing performance degradation. In\naddition, we further design the first Chebyshev-polynomials-based\nKolmogorov-Arnold classifier in computational pathology, which enhances the\nperformance of HDMIL through learnable activation layers. Extensive experiments\non three public datasets demonstrate that HDMIL outperforms previous\nstate-of-the-art methods, e.g., achieving improvements of 3.13% in AUC while\nreducing inference time by 28.6% on the Camelyon16 dataset."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00922",
    "a_title":"Lung tumor segmentation in MRI mice scans using 3D nnU-Net with minimum\n  annotations",
    "a_abstract":"In drug discovery, accurate lung tumor segmentation is an important step for\nassessing tumor size and its progression using \\textit{in-vivo} imaging such as\nMRI. While deep learning models have been developed to automate this process,\nthe focus has predominantly been on human subjects, neglecting the pivotal role\nof animal models in pre-clinical drug development. In this work, we focus on\noptimizing lung tumor segmentation in mice. First, we demonstrate that the\nnnU-Net model outperforms the U-Net, U-Net3+, and DeepMeta models. Most\nimportantly, we achieve better results with nnU-Net 3D models than 2D models,\nindicating the importance of spatial context for segmentation tasks in MRI mice\nscans. This study demonstrates the importance of 3D input over 2D input images\nfor lung tumor segmentation in MRI scans. Finally, we outperform the prior\nstate-of-the-art approach that involves the combined segmentation of lungs and\ntumors within the lungs. Our work achieves comparable results using only lung\ntumor annotations requiring fewer annotations, saving time and annotation\nefforts. This work\n(https:\/\/anonymous.4open.science\/r\/lung-tumour-mice-mri-64BB) is an important\nstep in automating pre-clinical animal studies to quantify the efficacy of\nexperimental drugs, particularly in assessing tumor changes.",
    "explanation":"In this work, we focus on optimizing lung tumor segmen-\ntation in mice. First, we demonstrate that the nnU-Net model outper-\nforms the U-Net, U-Net3+, and DeepMeta models.",
    "b_id":[
      "b12"
    ],
    "b_title":[
      "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation"
    ],
    "b_abstract":[
      "Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.01319"
    ],
    "c_title":[
      "Photodynamic, UV-curable and fibre-forming polyvinyl alcohol derivative\n  with broad processability and staining-free antibacterial capability"
    ],
    "c_abstract":[
      "Antimicrobial photodynamic therapy (APDT) is a promising antibiotic-free\nstrategy for broad-spectrum infection control in chronic wounds, minimising\nbacterial resistance risks. However, rapid photosensitiser diffusion, tissue\nstaining, side toxicity, and short-lived antimicrobial effects present\nsignificant clinical limitations for integrating APDT into wound dressings. To\naddress these challenges, we present the design of a bespoke polyvinyl alcohol\n(PVA) derivative conjugated with both phenothiazine and methacrylate\nfunctionalities, enabling staining-free antibacterial photodynamic effects,\ncellular tolerability and processability into various wound dressing formats,\nincluding films, textile fibres and nanoscale coatings. Tosylation of PVA is\nleveraged for the covalent coupling of toluidine blue, as confirmed by UV-Vis\nspectroscopy and the minimal release of TB in vitro. UV-induced network\nformation is exploited to accomplish cast films and nanoscale integrated wound\ndressing coatings. UV curing is also successfully coupled with an in-house wet\nspinning process to realise individual, water-insoluble fibres as the building\nblocks of fibrous wound dressings. A fluorometric assay supports the generation\nof reactive oxygen species when the UV-cured samples are exposed to work, but\nnot UV, light, yielding a mean log10 reduction of up to 2.13 in S. aureus, and\nthe complete eradication of P. aeruginosa. Direct and extract cytotoxicity\ntests with UV-cured films and fibres demonstrate the viability of L929\nfibroblasts following 60-min light irradiation and 72-hour cell culture. The\nbespoke molecular architecture, broad processability and cellular tolerability\nof this PVA derivative are highly attractive aiming to integrate durable\nstaining-free photodynamic capability in a wide range of healthcare\ntechnologies, from chronic wound dressings up to minimally invasive localised\ntherapy."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03522",
    "a_title":"Exploring the Potentials and Challenges of Using Large Language Models\n  for the Analysis of Transcriptional Regulation of Long Non-coding RNAs",
    "a_abstract":"Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.",
    "explanation":"Given the tremendous success of large language mod-\nels (LLMs) in capturing complex dependencies in sequential data, this study aims to systematically explore the potential and limitations of LLMs in the sequence analysis related to the transcriptional regulation of lncRNA genes. ",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Language Models are Few-Shot Learners"
    ],
    "b_abstract":[
      "Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training a large corpus of text followed fine-tuning specific task. While typically task-agnostic in architecture, this method still requires task-specific datasets thousands or tens examples. By contrast, humans can generally perform new language task from only few examples simple instructions - something which current systems largely struggle to do. Here we show that scaling up models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art approaches. Specifically, train GPT-3, an autoregressive model 175 billion parameters, 10x more than any previous non-sparse model, test its performance the setting. For all tasks, GPT-3 is applied without gradient updates fine-tuning, demonstrations specified purely via interaction model. achieves strong datasets, including translation, question-answering, cloze as well several require on-the-fly reasoning domain adaptation, such unscrambling words, using novel word sentence, performing 3-digit arithmetic. At same time, also identify some where GPT-3's learning struggles, faces methodological issues related training web corpora. Finally, find generate samples news articles human evaluators have difficulty distinguishing written humans. We discuss broader societal impacts finding general."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.01834"
    ],
    "c_title":[
      "Intercellular contact is sufficient to drive Fibroblast to Myofibroblast\n  transitions"
    ],
    "c_abstract":[
      "Fibroblast cells play a key role in maintaining the extracellular matrix.\nDuring wound healing, fibroblasts differentiate into highly contractile\nmyofibroblasts, which secrete extracellular matrix proteins like collagen to\nfacilitate tissue repair. Under normal conditions, myofibroblasts undergo\nprogrammed cell death after healing to prevent excessive scar formation.\nHowever, in diseases like fibrosis, the myofibroblasts remain active even after\nthe wound is closed, resulting in excessive collagen buildup and a stiff,\nfibrotic matrix. The reasons for the persistence of myofibroblasts in fibrosis\nare not well understood. Here we show the existence of a mechanism where direct\nphysical contact between a fibroblast and a myofibroblast is sufficient for\nfibroblasts to transition into myofibroblasts. We show that\nfibroblast-myofibroblast transition can occur even in the absence of known\nbiochemical cues such as growth factor activation or mechanical cues from a\nstiff, fibrotic matrix. Further, we show that contact-based\nfibroblast-myofibroblast activation can be blocked by G{\\alpha}q\/11\/14\ninhibitor FR9003591, which inhibits the formation of myofibroblasts. These\nfindings offer new insights into the persistence of fibrosis despite\ntherapeutic interventions and suggest a potential strategy to target\nfibroblast-to-myofibroblast transition in fibrosis."
    ],
    "c_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03522",
    "a_title":"Exploring the Potentials and Challenges of Using Large Language Models\n  for the Analysis of Transcriptional Regulation of Long Non-coding RNAs",
    "a_abstract":"Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.",
    "explanation":"Given the tremendous success of large language mod-\nels (LLMs) in capturing complex dependencies in sequential data, this study aims to systematically explore the potential and limitations of LLMs in the sequence analysis related to the transcriptional regulation of lncRNA genes. ",
    "b_id":[
      "b20"
    ],
    "b_title":[
      "Long non-coding RNAs: definitions, functions, challenges and recommendations"
    ],
    "b_abstract":[
      "Genes specifying long non-coding RNAs (lncRNAs) occupy a large fraction of the genomes of complex organisms. The term \u2018lncRNAs\u2019 encompasses RNA polymerase I (Pol I), Pol II and Pol III transcribed RNAs, and RNAs from processed introns. The various functions of lncRNAs and their many isoforms and interleaved relationships with other genes make lncRNA classification and annotation difficult. Most lncRNAs evolve more rapidly than protein-coding sequences, are cell type specific and regulate many aspects of cell differentiation and development and other physiological processes. Many lncRNAs associate with chromatin-modifying complexes, are transcribed from enhancers and nucleate phase separation of nuclear condensates and domains, indicating an intimate link between lncRNA expression and the spatial control of gene expression during development. lncRNAs also have important roles in the cytoplasm and beyond, including in the regulation of translation, metabolism and signalling. lncRNAs often have a modular structure and are rich in repeats, which are increasingly being shown to be relevant to their function. In this Consensus Statement, we address the definition and nomenclature of lncRNAs and their conservation, expression, phenotypic visibility, structure and functions. We also discuss research challenges and provide recommendations to advance the understanding of the roles of lncRNAs in development, cell biology and disease."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.11041"
    ],
    "c_title":[
      "Enhancing Semantic Consistency of Large Language Models through Model\n  Editing: An Interpretability-Oriented Approach"
    ],
    "c_abstract":[
      "A Large Language Model (LLM) tends to generate inconsistent and sometimes\ncontradictory outputs when presented with a prompt that has equivalent\nsemantics but is expressed differently from the original prompt. To achieve\nsemantic consistency of an LLM, one of the key approaches is to finetune the\nmodel with prompt-output pairs with semantically equivalent meanings. Despite\nits effectiveness, a data-driven finetuning method incurs substantial\ncomputation costs in data preparation and model optimization. In this regime,\nan LLM is treated as a ``black box'', restricting our ability to gain deeper\ninsights into its internal mechanism. In this paper, we are motivated to\nenhance the semantic consistency of LLMs through a more interpretable method\n(i.e., model editing) to this end. We first identify the model components\n(i.e., attention heads) that have a key impact on the semantic consistency of\nan LLM. We subsequently inject biases into the output of these model components\nalong the semantic-consistency activation direction. It is noteworthy that\nthese modifications are cost-effective, without reliance on mass manipulations\nof the original model parameters. Through comprehensive experiments on the\nconstructed NLU and open-source NLG datasets, our method demonstrates\nsignificant improvements in the semantic consistency and task performance of\nLLMs. Additionally, our method exhibits promising generalization capabilities\nby performing well on tasks beyond the primary tasks."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00688",
    "a_title":"Why do we regularise in every iteration for imaging inverse problems?",
    "a_abstract":"Regularisation is commonly used in iterative methods for solving imaging\ninverse problems. Many algorithms involve the evaluation of the proximal\noperator of the regularisation term in every iteration, leading to a\nsignificant computational overhead since such evaluation can be costly. In this\ncontext, the ProxSkip algorithm, recently proposed for federated learning\npurposes, emerges as an solution. It randomly skips regularisation steps,\nreducing the computational time of an iterative algorithm without affecting its\nconvergence. Here we explore for the first time the efficacy of ProxSkip to a\nvariety of imaging inverse problems and we also propose a novel PDHGSkip\nversion. Extensive numerical results highlight the potential of these methods\nto accelerate computations while maintaining high-quality reconstructions.",
    "explanation":"Regularisation is commonly used in iterative methods for solving imaging inverse problems. Here we explore for the first time the efficacy of ProxSkip to a variety of imaging inverse problems and we also propose a novel PDHGSkip version.",
    "b_id":[
      "b19"
    ],
    "b_title":[
      "Parameter-Free FISTA by Adaptive Restart and Backtracking"
    ],
    "b_abstract":[
      "We consider a combined restarting and adaptive backtracking strategy for the\npopular Fast Iterative Shrinking-Thresholding Algorithm frequently employed for\naccelerating the convergence speed of large-scale structured convex\noptimization problems. Several variants of FISTA enjoy a provable linear\nconvergence rate for the function values $F(x_n)$ of the form $\\mathcal{O}(\ne^{-K\\sqrt{\\mu\/L}~n})$ under the prior knowledge of problem conditioning, i.e.\nof the ratio between the (\\L ojasiewicz) parameter $\\mu$ determining the growth\nof the objective function and the Lipschitz constant $L$ of its smooth\ncomponent. These parameters are nonetheless hard to estimate in many practical\ncases. Recent works address the problem by estimating either parameter via\nsuitable adaptive strategies. In our work both parameters can be estimated at\nthe same time by means of an algorithmic restarting scheme where, at each\nrestart, a non-monotone estimation of $L$ is performed. For this scheme,\ntheoretical convergence results are proved, showing that a $\\mathcal{O}(\ne^{-K\\sqrt{\\mu\/L}n})$ convergence speed can still be achieved along with\nquantitative estimates of the conditioning. The resulting Free-FISTA algorithm\nis therefore parameter-free. Several numerical results are reported to confirm\nthe practical interest of its use in many exemplar problems."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2501.09799"
    ],
    "c_title":[
      "Scan-Adaptive MRI Undersampling Using Neighbor-based Optimization (SUNO)"
    ],
    "c_abstract":[
      "Accelerated MRI involves collecting partial k-space measurements to reduce\nacquisition time, patient discomfort, and motion artifacts, and typically uses\nregular undersampling patterns or hand-designed schemes. Recent works have\nstudied population-adaptive sampling patterns that are learned from a group of\npatients (or scans) based on population-specific metrics. However, such a\ngeneral sampling pattern can be sub-optimal for any specific scan since it may\nlack scan or slice adaptive details. To overcome this issue, we propose a\nframework for jointly learning scan-adaptive Cartesian undersampling patterns\nand a corresponding reconstruction model from a training set. We use an\nalternating algorithm for learning the sampling patterns and reconstruction\nmodel where we use an iterative coordinate descent (ICD) based offline\noptimization of scan-adaptive k-space sampling patterns for each example in the\ntraining set. A nearest neighbor search is then used to select the\nscan-adaptive sampling pattern at test time from initially acquired\nlow-frequency k-space information. We applied the proposed framework (dubbed\nSUNO) to the fastMRI multi-coil knee and brain datasets, demonstrating improved\nperformance over currently used undersampling patterns at both 4x and 8x\nacceleration factors in terms of both visual quality and quantitative metrics.\nThe code for the proposed framework is available at\nhttps:\/\/github.com\/sidgautam95\/adaptive-sampling-mri-suno."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00688",
    "a_title":"Why do we regularise in every iteration for imaging inverse problems?",
    "a_abstract":"Regularisation is commonly used in iterative methods for solving imaging\ninverse problems. Many algorithms involve the evaluation of the proximal\noperator of the regularisation term in every iteration, leading to a\nsignificant computational overhead since such evaluation can be costly. In this\ncontext, the ProxSkip algorithm, recently proposed for federated learning\npurposes, emerges as an solution. It randomly skips regularisation steps,\nreducing the computational time of an iterative algorithm without affecting its\nconvergence. Here we explore for the first time the efficacy of ProxSkip to a\nvariety of imaging inverse problems and we also propose a novel PDHGSkip\nversion. Extensive numerical results highlight the potential of these methods\nto accelerate computations while maintaining high-quality reconstructions.",
    "explanation":"Regularisation is commonly used in iterative methods for solving imaging inverse problems. Here we explore for the first time the efficacy of ProxSkip to a variety of imaging inverse problems and we also propose a novel PDHGSkip version.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Convex generalizations of total variation based on the structure tensor with applications to inverse problems"
    ],
    "b_abstract":[
      "We introduce a generic convex energy functional that is suitable for both grayscale and vector-valued images. Our functional is based on the eigenvalues of the structure tensor, therefore it penalizes image variation at every point by taking into account the information from its neighborhood. It generalizes several existing variational penalties, such as the Total Variation and vectorial extensions of it. By introducing the concept of patch-based Jacobian operator, we derive an equivalent formulation of the proposed regularizer that is based on the Schatten norm of this operator. Using this new formulation, we prove convexity and develop a dual definition for the proposed energy, which gives rise to an efficient and parallelizable minimization algorithm. Moreover, we establish a connection between the minimization of the proposed convex regularizer and a generic type of nonlinear anisotropic diffusion that is driven by a spatially regularized and adaptive diffusion tensor. Finally, we perform extensive experiments with image denoising and deblurring for grayscale and color images. The results show the effectiveness of the proposed approach as well as its improved performance compared to Total Variation and existing vectorial extensions of it."
    ],
    "b_categories":[
      "eess.IV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.14981"
    ],
    "c_title":[
      "Convex Analysis in Spectral Decomposition Systems"
    ],
    "c_abstract":[
      "This work is concerned with convex analysis of so-called spectral functions\nof matrices that only depend on eigenvalues of the matrix. An abstract\nframework of spectral decomposition systems is proposed that covers a wide\nrange of previously studied settings, including eigenvalue decomposition of\nHermitian matrices and singular value decomposition of rectangular matrices and\nallows deriving new results in more general settings such as Euclidean Jordan\nalgebras. The main results characterize convexity, lower semicontinuity,\nFenchel conjugates, convex subdifferentials, and Bregman proximity operators of\nspectral functions in terms of the reduced functions. As a byproduct, a\ngeneralization of the Ky Fan majorization theorem is obtained."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00036",
    "a_title":"Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial\n  Market Dynamics",
    "a_abstract":"We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.",
    "explanation":"The paper proposes the use of a new method using diffusion model generative methodology to produce synthetic market scenarios.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "On the Distribution of the Two-Sample Cramer-von Mises Criterion"
    ],
    "b_abstract":[
      "The Cramer-von Mises $\\omega^2$ criterion for testing that a sample, $x_1, \\cdots, x_N$, has been drawn from specified continuous distribution $F(x)$ is \\begin{equation*}\\tag{1}\\omega^2 = \\int^\\infty_{-\\infty} \\lbrack F_N(x) - F(x)\\rbrack^2 dF(x),\\end{equation*} where $F_N(x)$ the empirical function of sample; is, $F_N(x) k\/N$ if exactly $k$ observations are less than or equal to $x(k 0, 1, N)$. If there second $y_1, y_M$, test hypothesis two samples come same (unspecified) can be based on analogue $N\\omega^2$, namely \\begin{equation*}\\tag{2} T NM\/(N + M)\\rbrack G_M(x)\\rbrack^2 dH_{N+M}(x),\\end{equation*} $G_M(x)$ sample and $H_{N+M}(x)$ together [that $(N M)H_{N+M}(x) NF_N(x) MG_M(x)\\rbrack$. limiting $N\\omega^2$ as $N \\rightarrow \\infty$ tabulated [2], it shown ([3], [4a], [7]) $T$ \\infty, M \\infty$, $N\/M \\lambda$, $\\lambda$ any finite positive constant. In this note we consider small values $N$ $M$ present tables permit use at some conventional significance levels $M$. seems surprisingly good approximation exact moderate sizes (corresponding feature [6]). accuracy better in case two-sample Kolmogorov-Smirnov statistic studied by Hodges [4]."
    ],
    "b_categories":[
      "q-fin.GN"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "2503.08065"
    ],
    "c_title":[
      "STGDPM:Vessel Trajectory Prediction with Spatio-Temporal Graph Diffusion\n  Probabilistic Model"
    ],
    "c_abstract":[
      "Vessel trajectory prediction is a critical component for ensuring maritime\ntraffic safety and avoiding collisions. Due to the inherent uncertainty in\nvessel behavior, trajectory prediction systems must adopt a multimodal approach\nto accurately model potential future motion states. However, existing vessel\ntrajectory prediction methods lack the ability to comprehensively model\nbehavioral multi-modality. To better capture multimodal behavior in interactive\nscenarios, we propose modeling interactions as dynamic graphs, replacing\ntraditional aggregation-based techniques that rely on vessel states. By\nleveraging the natural multimodal capabilities of diffusion models, we frame\nthe trajectory prediction task as an inverse process of motion uncertainty\ndiffusion, wherein uncertainties across potential navigational areas are\nprogressively eliminated until the desired trajectories is produced. In\nsummary, we pioneer the integration of Spatio-Temporal Graph (STG) with\ndiffusion models in ship trajectory prediction. Extensive experiments on real\nAutomatic Identification System (AIS) data validate the superiority of our\napproach."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00036",
    "a_title":"Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial\n  Market Dynamics",
    "a_abstract":"We propose a highly efficient and accurate methodology for generating\nsynthetic financial market data using a diffusion model approach. The synthetic\ndata produced by our methodology align closely with observed market data in\nseveral key aspects: (i) they pass the two-sample Cramer - von Mises test for\nportfolios of assets, and (ii) Q - Q plots demonstrate consistency across\nquantiles, including in the tails, between observed and generated market data.\nMoreover, the covariance matrices derived from a large set of synthetic market\ndata exhibit significantly lower condition numbers compared to the estimated\ncovariance matrices of the observed data. This property makes them suitable for\nuse as regularized versions of the latter. For model training, we develop an\nefficient and fast algorithm based on numerical integration rather than Monte\nCarlo simulations. The methodology is tested on a large set of equity data.",
    "explanation":"The paper proposes the use of a new method using diffusion model generative methodology to produce synthetic market scenarios.",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "Quant GANs: deep generation of financial time series"
    ],
    "b_abstract":[
      "Modeling financial time series by stochastic processes is a challenging task and a central area of research in financial mathematics. As an alternative, we introduce Quant GANs, a data-driven model which is inspired by the recent success of generative adversarial networks (GANs). Quant GANs consist of a generator and discriminator function, which utilize temporal convolutional networks (TCNs) and thereby achieve to capture long-range dependencies such as the presence of volatility clusters. The generator function is explicitly constructed such that the induced stochastic process allows a transition to its risk-neutral distribution. Our numerical results highlight that distributional properties for small and large lags are in an excellent agreement and dependence properties such as volatility clusters, leverage effects, and serial autocorrelations can be generated by the generator function of Quant GANs, demonstrably in high fidelity."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.15557"
    ],
    "c_title":[
      "Preventing Household Bankruptcy: The One-Third Rule in Financial\n  Planning with Mathematical Validation and Game-Theoretic Insights"
    ],
    "c_abstract":[
      "This paper analyzes the 1\/3 Financial Rule, a method of allocating income\nequally among debt repayment, savings, and living expenses. Through\nmathematical modeling, game theory, behavioral finance, and technological\nanalysis, we examine the rule's potential for supporting household financial\nstability and reducing bankruptcy risk. The research develops theoretical\nfoundations using utility maximization theory, demonstrating how equal\nallocation emerges as a solution under standard economic assumptions. The\ngame-theoretic analysis explores the rule's effectiveness across different\nhousehold structures, revealing potential strategic advantages in financial\ndecision-making. We investigate psychological factors influencing financial\nchoices, including cognitive biases and neurobiological mechanisms that impact\neconomic behavior. Technological approaches, such as AI-driven personalization,\nblockchain tracking, and smart contract applications, are examined for their\npotential to support financial planning. Empirical validation using U.S. Census\ndata and longitudinal studies assesses the rule's performance across various\nhousehold types. Stress testing under different economic conditions provides\ninsights into its adaptability and resilience. The research integrates\nmathematical analysis with behavioral insights and technological perspectives\nto develop a comprehensive approach to household financial management."
    ],
    "c_categories":[
      [
        "q-fin.GN"
      ]
    ],
    "c_fields":[
      "Economics and Quantitative Finance"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00640",
    "a_title":"Adding Error Bars to Evals: A Statistical Approach to Language Model\n  Evaluations",
    "a_abstract":"Evaluations are critical for understanding the capabilities of large language\nmodels (LLMs). Fundamentally, evaluations are experiments; but the literature\non evaluations has largely ignored the literature from other sciences on\nexperiment analysis and planning. This article shows researchers with some\ntraining in statistics how to think about and analyze data from language model\nevaluations. Conceptualizing evaluation questions as having been drawn from an\nunseen super-population, we present formulas for analyzing evaluation data,\nmeasuring differences between two models, and planning an evaluation\nexperiment. We make a number of specific recommendations for running language\nmodel evaluations and reporting experiment results in a way that minimizes\nstatistical noise and maximizes informativeness.",
    "explanation":"This is an interdisciplinary work because it combines two different subjects: LLM and statistics. This suggests that we could also consider the error bars in the evaluations. ",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "Quantifying Variance in Evaluation Benchmarks"
    ],
    "b_abstract":[
      "Evaluation benchmarks are the cornerstone of measuring capabilities large language models (LLMs), as well driving progress in said capabilities. Originally designed to make claims about (or lack thereof) fully pretrained models, evaluation now also extensively used decide between various training choices. Despite this widespread usage, we rarely quantify variance our benchmarks, which dictates whether differences performance meaningful. Here, define and measure a range metrics geared towards including seed across initialisations, monotonicity during training. By studying number -- both openly available from scratch provide empirical estimates for variety metrics, with considerations recommendations practitioners. We evaluate utility tradeoffs continuous versus discrete measures explore options better understanding reducing variance. find that simple changes, such framing choice tasks (like MMLU) completion tasks, can often reduce smaller scale ($\\sim$7B) while more involved methods inspired human testing literature (such item analysis response theory) struggle meaningfully Overall, work provides insights into suggests LM-specific techniques variance, generally encourages practitioners carefully factor when comparing models."
    ],
    "b_categories":[
      "stat.ME"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2502.19308"
    ],
    "c_title":[
      "WOFOSTGym: A Crop Simulator for Learning Annual and Perennial Crop\n  Management Strategies"
    ],
    "c_abstract":[
      "We introduce WOFOSTGym, a novel crop simulation environment designed to train\nreinforcement learning (RL) agents to optimize agromanagement decisions for\nannual and perennial crops in single and multi-farm settings. Effective crop\nmanagement requires optimizing yield and economic returns while minimizing\nenvironmental impact, a complex sequential decision-making problem well suited\nfor RL. However, the lack of simulators for perennial crops in multi-farm\ncontexts has hindered RL applications in this domain. Existing crop simulators\nalso do not support multiple annual crops. WOFOSTGym addresses these gaps by\nsupporting 23 annual crops and two perennial crops, enabling RL agents to learn\ndiverse agromanagement strategies in multi-year, multi-crop, and multi-farm\nsettings. Our simulator offers a suite of challenging tasks for learning under\npartial observability, non-Markovian dynamics, and delayed feedback.\nWOFOSTGym's standard RL interface allows researchers without agricultural\nexpertise to explore a wide range of agromanagement problems. Our experiments\ndemonstrate the learned behaviors across various crop varieties and soil types,\nhighlighting WOFOSTGym's potential for advancing RL-driven decision support in\nagriculture."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00640",
    "a_title":"Adding Error Bars to Evals: A Statistical Approach to Language Model\n  Evaluations",
    "a_abstract":"Evaluations are critical for understanding the capabilities of large language\nmodels (LLMs). Fundamentally, evaluations are experiments; but the literature\non evaluations has largely ignored the literature from other sciences on\nexperiment analysis and planning. This article shows researchers with some\ntraining in statistics how to think about and analyze data from language model\nevaluations. Conceptualizing evaluation questions as having been drawn from an\nunseen super-population, we present formulas for analyzing evaluation data,\nmeasuring differences between two models, and planning an evaluation\nexperiment. We make a number of specific recommendations for running language\nmodel evaluations and reporting experiment results in a way that minimizes\nstatistical noise and maximizes informativeness.",
    "explanation":"This is an interdisciplinary work because it combines two different subjects: LLM and statistics. This suggests that we could also consider the error bars in the evaluations. ",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "The Llama 3 Herd of Models"
    ],
    "b_abstract":[
      "Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.03065"
    ],
    "c_title":[
      "Meta-analysis of median survival times with inverse-variance weighting"
    ],
    "c_abstract":[
      "We consider the problem of meta-analyzing outcome measures based on median\nsurvival times, such as the difference of median survival times between groups.\nPrimary studies with time-to-event outcomes often report estimates of median\nsurvival times and corresponding confidence intervals based on the Kaplan-Meier\nestimator. However, applying conventional inverse-variance weighted methods to\nmeta-analyze outcome measures based on median survival is often challenging\nbecause within-study standard error estimates are typically not available in\nthis setting. In this article, we consider an inverse-variance weighted\napproach to meta-analyze median survival times that estimates the within-study\nstandard errors from the reported confidence intervals. We conduct a series of\nsimulation studies evaluating the performance of this approach at the study\nlevel (i.e., for estimating the standard error of median survival) and the\nmeta-analytic level (i.e., for estimating the pooled median, difference of\nmedians, and ratio of medians). We find that this approach often performs\ncomparable to a benchmark approach that uses the true within-study standard\nerrors for meta-analyzing median-based outcome measures. We then illustrate an\napplication of this approach in a meta-analysis evaluating survival benefits of\nbeing assigned to experimental arms versus comparator arms in randomized trials\nfor non-small cell lung cancer therapies."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06785",
    "a_title":"White-Box Diffusion Transformer for single-cell RNA-seq generation",
    "a_abstract":"As a powerful tool for characterizing cellular subpopulations and cellular\nheterogeneity, single cell RNA sequencing (scRNA-seq) technology offers\nadvantages of high throughput and multidimensional analysis. However, the\nprocess of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a hybrid model\nbased on Diffusion model and White-Box transformer that aims to generate\nsynthetic and biologically plausible scRNA-seq data. Diffusion model\nprogressively introduce noise into the data and then recover the original data\nthrough a denoising process, a forward and reverse process that is particularly\nsuitable for generating complex data distributions. White-Box transformer is a\ndeep learning architecture that emphasizes mathematical interpretability. By\nminimizing the encoding rate of the data and maximizing the sparsity of the\nrepresentation, it not only reduces the computational burden, but also provides\nclear insight into underlying structure. Our White-Box Diffusion Transformer\ncombines the generative capabilities of Diffusion model with the mathematical\ninterpretability of White-Box transformer. Through experiments using six\ndifferent single-cell RNA-Seq datasets, we visualize both generated and real\ndata using t-SNE dimensionality reduction technique, as well as quantify\nsimilarity between generated and real data using various metrics to demonstrate\ncomparable performance of White-Box Diffusion Transformer and Diffusion\nTransformer in generating scRNA-seq data alongside significant improvements in\ntraining efficiency and resource utilization. Our code is available at\nhttps:\/\/github.com\/lingximamo\/White-Box-Diffusion-Transformer",
    "explanation":"As a powerful tool for characterizing cellular subpopulations and cellular heterogeneity, single cell\nRNA sequencing (scRNA-seq) technology offers advantages of high throughput and multidimensional\nanalysis. However, the process of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a model based on Diffusion model\nand White-Box transformer that aims to generate synthetic and biologically plausible scRNA-seq\ndata.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "RNA-Seq: a revolutionary tool for transcriptomics"
    ],
    "b_abstract":[
      "RNA-Seq is a recently developed approach to transcriptome profiling that uses deep-sequencing technologies. Studies using this method have already altered our view of the extent and complexity of eukaryotic transcriptomes. RNA-Seq also provides a far more precise measurement of levels of transcripts and their isoforms than other methods. This article describes the RNA-Seq approach, the challenges associated with its application, and the advances made so far in characterizing several eukaryote transcriptomes."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.04583"
    ],
    "c_title":[
      "Overcoming Fake Solutions in Semi-Dual Neural Optimal Transport: A\n  Smoothing Approach for Learning the Optimal Transport Plan"
    ],
    "c_abstract":[
      "We address the convergence problem in learning the Optimal Transport (OT)\nmap, where the OT Map refers to a map from one distribution to another while\nminimizing the transport cost. Semi-dual Neural OT, a widely used approach for\nlearning OT Maps with neural networks, often generates fake solutions that fail\nto transfer one distribution to another accurately. We identify a sufficient\ncondition under which the max-min solution of Semi-dual Neural OT recovers the\ntrue OT Map. Moreover, to address cases when this sufficient condition is not\nsatisfied, we propose a novel method, OTP, which learns both the OT Map and the\nOptimal Transport Plan, representing the optimal coupling between two\ndistributions. Under sharp assumptions on the distributions, we prove that our\nmodel eliminates the fake solution issue and correctly solves the OT problem.\nOur experiments show that the OTP model recovers the optimal transport map\nwhere existing methods fail and outperforms current OT-based models in\nimage-to-image translation tasks. Notably, the OTP model can learn stochastic\ntransport maps when deterministic OT Maps do not exist, such as one-to-many\ntasks like colorization."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.06785",
    "a_title":"White-Box Diffusion Transformer for single-cell RNA-seq generation",
    "a_abstract":"As a powerful tool for characterizing cellular subpopulations and cellular\nheterogeneity, single cell RNA sequencing (scRNA-seq) technology offers\nadvantages of high throughput and multidimensional analysis. However, the\nprocess of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a hybrid model\nbased on Diffusion model and White-Box transformer that aims to generate\nsynthetic and biologically plausible scRNA-seq data. Diffusion model\nprogressively introduce noise into the data and then recover the original data\nthrough a denoising process, a forward and reverse process that is particularly\nsuitable for generating complex data distributions. White-Box transformer is a\ndeep learning architecture that emphasizes mathematical interpretability. By\nminimizing the encoding rate of the data and maximizing the sparsity of the\nrepresentation, it not only reduces the computational burden, but also provides\nclear insight into underlying structure. Our White-Box Diffusion Transformer\ncombines the generative capabilities of Diffusion model with the mathematical\ninterpretability of White-Box transformer. Through experiments using six\ndifferent single-cell RNA-Seq datasets, we visualize both generated and real\ndata using t-SNE dimensionality reduction technique, as well as quantify\nsimilarity between generated and real data using various metrics to demonstrate\ncomparable performance of White-Box Diffusion Transformer and Diffusion\nTransformer in generating scRNA-seq data alongside significant improvements in\ntraining efficiency and resource utilization. Our code is available at\nhttps:\/\/github.com\/lingximamo\/White-Box-Diffusion-Transformer",
    "explanation":"As a powerful tool for characterizing cellular subpopulations and cellular heterogeneity, single cell\nRNA sequencing (scRNA-seq) technology offers advantages of high throughput and multidimensional\nanalysis. However, the process of data acquisition is often constrained by high cost and limited\nsample availability. To overcome these limitations, we propose a model based on Diffusion model\nand White-Box transformer that aims to generate synthetic and biologically plausible scRNA-seq\ndata.",
    "b_id":[
      "b25"
    ],
    "b_title":[
      "White-Box Transformers via Sparse Rate Reduction"
    ],
    "b_abstract":[
      "In this paper, we contend that the objective of representation learning is to compress and transform distribution data, say sets tokens, towards a mixture low-dimensional Gaussian distributions supported on incoherent subspaces. The quality final can be measured by unified function called sparse rate reduction. From perspective, popular deep networks such as transformers naturally viewed realizing iterative schemes optimize incrementally. Particularly, show standard transformer block derived from alternating optimization complementary parts objective: multi-head self-attention operator gradient descent step token minimizing their lossy coding rate, subsequent multi-layer perceptron attempting sparsify tokens. This leads family white-box transformer-like network architectures which are mathematically fully interpretable. Despite simplicity, experiments these indeed learn designed they representations large-scale real-world vision datasets ImageNet, achieve performance very close thoroughly engineered ViT."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.15472"
    ],
    "c_title":[
      "GiantHunter: Accurate detection of giant virus in metagenomic data using\n  reinforcement-learning and Monte Carlo tree search"
    ],
    "c_abstract":[
      "Motivation: Nucleocytoplasmic large DNA viruses (NCLDVs) are notable for\ntheir large genomes and extensive gene repertoires, which contribute to their\nwidespread environmental presence and critical roles in processes such as host\nmetabolic reprogramming and nutrient cycling. Metagenomic sequencing has\nemerged as a powerful tool for uncovering novel NCLDVs in environmental\nsamples. However, identifying NCLDV sequences in metagenomic data remains\nchallenging due to their high genomic diversity, limited reference genomes, and\nshared regions with other microbes. Existing alignment-based and machine\nlearning methods struggle with achieving optimal trade-offs between sensitivity\nand precision. Results: In this work, we present GiantHunter, a reinforcement\nlearning-based tool for identifying NCLDVs from metagenomic data. By employing\na Monte Carlo tree search strategy, GiantHunter dynamically selects\nrepresentative non-NCLDV sequences as the negative training data, enabling the\nmodel to establish a robust decision boundary. Benchmarking on rigorously\ndesigned experiments shows that GiantHunter achieves high precision while\nmaintaining competitive sensitivity, improving the F1-score by 10% and reducing\ncomputational cost by 90% compared to the second-best method. To demonstrate\nits real-world utility, we applied GiantHunter to 60 metagenomic datasets\ncollected from six cities along the Yangtze River, located both upstream and\ndownstream of the Three Gorges Dam. The results reveal significant differences\nin NCLDV diversity correlated with proximity to the dam, likely influenced by\nreduced flow velocity caused by the dam. These findings highlight the potential\nof GiantSeeker to advance our understanding of NCLDVs and their ecological\nroles in diverse environments."
    ],
    "c_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00868",
    "a_title":"Quantifying perturbation impacts for large language models",
    "a_abstract":"We consider the problem of quantifying how an input perturbation impacts the\noutputs of large language models (LLMs), a fundamental task for model\nreliability and post-hoc interpretability. A key obstacle in this domain is\ndisentangling the meaningful changes in model responses from the intrinsic\nstochasticity of LLM outputs. To overcome this, we introduce Distribution-Based\nPerturbation Analysis (DBPA), a framework that reformulates LLM perturbation\nanalysis as a frequentist hypothesis testing problem. DBPA constructs empirical\nnull and alternative output distributions within a low-dimensional semantic\nsimilarity space via Monte Carlo sampling. Comparisons of Monte Carlo estimates\nin the reduced dimensionality space enables tractable frequentist inference\nwithout relying on restrictive distributional assumptions. The framework is\nmodel-agnostic, supports the evaluation of arbitrary input perturbations on any\nblack-box LLM, yields interpretable p-values, supports multiple perturbation\ntesting via controlled error rates, and provides scalar effect sizes for any\nchosen similarity or distance metric. We demonstrate the effectiveness of DBPA\nin evaluating perturbation impacts, showing its versatility for perturbation\nanalysis.",
    "explanation":"\"We consider the problem of quantifying how an input perturbation impacts the outputs of large language models (LLMs), a fundamental task for model reliability and post-hoc interpretability.\"",
    "b_id":[
      "b22"
    ],
    "b_title":[
      "Context-Aware Testing: A New Paradigm for Model Testing with Large\n  Language Models"
    ],
    "b_abstract":[
      "The predominant de facto paradigm of testing ML models relies on either using\nonly held-out data to compute aggregate evaluation metrics or by assessing the\nperformance on different subgroups. However, such data-only testing methods\noperate under the restrictive assumption that the available empirical data is\nthe sole input for testing ML models, disregarding valuable contextual\ninformation that could guide model testing. In this paper, we challenge the\ngo-to approach of data-only testing and introduce context-aware testing (CAT)\nwhich uses context as an inductive bias to guide the search for meaningful\nmodel failures. We instantiate the first CAT system, SMART Testing, which\nemploys large language models to hypothesize relevant and likely failures,\nwhich are evaluated on data using a self-falsification mechanism. Through\nempirical evaluations in diverse settings, we show that SMART automatically\nidentifies more relevant and impactful failures than alternatives,\ndemonstrating the potential of CAT as a testing paradigm."
    ],
    "b_categories":[
      "stat.ME"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2502.10197"
    ],
    "c_title":[
      "MathConstruct: Challenging LLM Reasoning with Constructive Proofs"
    ],
    "c_abstract":[
      "While Large Language Models (LLMs) demonstrate impressive performance in\nmathematics, existing math benchmarks come with significant limitations. Many\nfocus on problems with fixed ground-truth answers, and are often saturated due\nto problem simplicity or the viability of guessing or memorization. Crucially,\nthey capture only a narrow subset of relevant math problems. To address this\nresearch gap, we introduce \\mc, a new benchmark of 126 challenging problems\nsourced from various math competitions, which targets constructive proofs, a\nwidely encountered problem type requiring the construction of mathematical\nobjects with specific properties. These proofs are particularly suitable for\nLLM evaluation, as solution correctness can be easily verified. Our automated\nverifiers also enable MathConstruct to generate problem variations, used to\nevaluate robustness. State-of-the-art LLMs solve only 54% of MathConstruct\nproblems, highlighting its complexity and importance for LLM evaluation."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00868",
    "a_title":"Quantifying perturbation impacts for large language models",
    "a_abstract":"We consider the problem of quantifying how an input perturbation impacts the\noutputs of large language models (LLMs), a fundamental task for model\nreliability and post-hoc interpretability. A key obstacle in this domain is\ndisentangling the meaningful changes in model responses from the intrinsic\nstochasticity of LLM outputs. To overcome this, we introduce Distribution-Based\nPerturbation Analysis (DBPA), a framework that reformulates LLM perturbation\nanalysis as a frequentist hypothesis testing problem. DBPA constructs empirical\nnull and alternative output distributions within a low-dimensional semantic\nsimilarity space via Monte Carlo sampling. Comparisons of Monte Carlo estimates\nin the reduced dimensionality space enables tractable frequentist inference\nwithout relying on restrictive distributional assumptions. The framework is\nmodel-agnostic, supports the evaluation of arbitrary input perturbations on any\nblack-box LLM, yields interpretable p-values, supports multiple perturbation\ntesting via controlled error rates, and provides scalar effect sizes for any\nchosen similarity or distance metric. We demonstrate the effectiveness of DBPA\nin evaluating perturbation impacts, showing its versatility for perturbation\nanalysis.",
    "explanation":"\"We consider the problem of quantifying how an input perturbation impacts the outputs of large language models (LLMs), a fundamental task for model reliability and post-hoc interpretability.\"",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "How resilient are language models to text perturbations"
    ],
    "b_abstract":[
      "Large language models typically rely on highly curated datasets that lack common irregularities such as typos and contractions, resulting in a mismatch between their training environments and real-world applications. This study evaluates the resilience of four prominent models in five different NLP tasks when confronted with perturbed inputs. We investigate three categories of perturbations: character-level, word-level and miscellaneous perturbations. By comparing performance on original and altered datasets, our results reveal a significant sensitivity to input perturbations across all models, with varying degrees of vulnerability depending on both the specific task and the type of perturbation. In particular, the XLNet model consistently shows superior robustness, while tasks involving grammatical coherence are most adversely affected."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.00579"
    ],
    "c_title":[
      "Intrinsic Random Functions and Parametric Covariance Models of\n  Spatio-Temporal Random Processes on the Sphere"
    ],
    "c_abstract":[
      "Identifying an appropriate covariance function is one of the primary\ninterests in spatial and spatio-temporal statistics because it allows\nresearchers to analyze the dependence structure of the random process. For this\npurpose, spatial homogeneity and temporal stationarity are widely used\nassumptions, and many parametric covariance models have been developed under\nthese assumptions. However, these are strong and unrealistic conditions in many\ncases. In addition, on the sphere, although different statistical approaches\nfrom those on Euclidean space should be applied to build a proper covariance\nmodel considering its unique characteristics, relevant studies are rare. In\nthis research, we introduce novel parameterized models of the covariance\nfunction for spatially non-homogeneous and temporally non-stationary random\nprocesses on the sphere. To alleviate the spatial homogeneity assumption and\ntemporal stationarity, and to consider the spherical domain and time domain\ntogether, this research will apply the theories of Intrinsic Random Functions\n(IRF). We also provide a methodology to estimate the associated parameters for\nthe model. Finally, through a simulation study and analysis of a real-world\ndata set about global temperature anomaly, we demonstrate validity of the\nsuggested covariance model with its advantage of interpretability."
    ],
    "c_categories":[
      [
        "stat.ME"
      ]
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.01668",
    "a_title":"Linear Quadratic Mean Field Games with Quantile-Dependent Cost\n  Coefficients",
    "a_abstract":"This paper studies a class of linear quadratic mean field games where the\ncoefficients of quadratic cost functions depend on both the mean and the\nvariance of the population's state distribution through its quantile function.\nSuch a formulation allows for modelling agents that are sensitive to not only\nthe population average but also the population variance. The corresponding mean\nfield game equilibrium is identified, which involves solving two coupled\ndifferential equations: one is a Riccati equation and the other the variance\nevolution equation. Furthermore, the conditions for the existence and\nuniqueness of the mean field equilibrium are established. Finally, numerical\nresults are presented to illustrate the behavior of two coupled differential\nequations and the performance of the mean field game solution.",
    "explanation":"\"This paper studies a class of linear quadratic mean field games where the coefficients of quadratic cost functions depend on both the mean and the variance of the population\u2019s state distribution through its quantile function. \"\n\n\n",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Mean\u2010field games with differing beliefs for algorithmic trading"
    ],
    "b_abstract":[
      "Abstract Even when confronted with the same data, agents often disagree on a model of real world. Here, we address question how interacting heterogeneous agents, who what world follows, optimize their trading actions. The market has latent factors that drive prices, and account for permanent impact they have prices. This leads to large stochastic game, where each performance criteria are computed under different probability measure. We analyze mean\u2010field game (MFG) limit show Nash equilibrium is given by solution nonstandard vector\u2010valued forward\u2013backward differential equation. Under some mild assumptions, construct in terms expectations filtered states. Furthermore, prove MFG strategy forms an \u03b5\u2010Nash finite player game. Finally, present least square Monte Carlo based algorithm computing equilibria through simulations increasing disagreement may increase price volatility activity."
    ],
    "b_categories":[
      "q-fin.MF"
    ],
    "b_fields":[
      "Economics and Quantitative Finance"
    ],
    "c_id":[
      "2501.12533"
    ],
    "c_title":[
      "Multi-objective and hierarchical control for coupled stochastic\n  parabolic systems"
    ],
    "c_abstract":[
      "We study the Stackelberg-Nash null controllability of a coupled system\ngoverned by two linear forward stochastic parabolic equations. The system\nincludes one leader control localized in a subset of the domain, two additional\nleader controls in the diffusion terms, and \\( m \\) follower controls, where \\(\nm \\geq 2 \\). We consider two different scenarios for the followers: first, when\nthe followers minimize a functional involving both components of the system's\nstate, and second, when they minimize a functional involving only the second\ncomponent of the state. For fixed leader controls, we first establish the\nexistence and uniqueness of the Nash equilibrium in both scenarios and provide\nits characterization. As a byproduct, the problem is reformulated as a\nclassical null controllability issue for the associated coupled\nforward-backward stochastic parabolic system. To address this, we derive new\nCarleman estimates for the adjoint stochastic systems. As far as we know, this\nproblem is among the first to be discussed for stochastic coupled systems."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.01668",
    "a_title":"Linear Quadratic Mean Field Games with Quantile-Dependent Cost\n  Coefficients",
    "a_abstract":"This paper studies a class of linear quadratic mean field games where the\ncoefficients of quadratic cost functions depend on both the mean and the\nvariance of the population's state distribution through its quantile function.\nSuch a formulation allows for modelling agents that are sensitive to not only\nthe population average but also the population variance. The corresponding mean\nfield game equilibrium is identified, which involves solving two coupled\ndifferential equations: one is a Riccati equation and the other the variance\nevolution equation. Furthermore, the conditions for the existence and\nuniqueness of the mean field equilibrium are established. Finally, numerical\nresults are presented to illustrate the behavior of two coupled differential\nequations and the performance of the mean field game solution.",
    "explanation":"\"This paper studies a class of linear quadratic mean field games where the coefficients of quadratic cost functions depend on both the mean and the variance of the population\u2019s state distribution through its quantile function. \"\n\n\n",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Linear-quadratic mean field games"
    ],
    "b_abstract":[
      "In this article, we provide a comprehensive study of the linear-quadratic mean field games via the adjoint equation approach; although the problem has been considered in the literature by Huang, Caines and Malhame (HCM, 2007a), their method is based on Dynamic Programming. It turns out that two methods are not equivalent, as far as giving sufficient condition for the existence of a solution is concerned. Due to the linearity of the adjoint equations, the optimal mean field term satisfies a linear forward-backward ordinary differential equation. For the one dimensional case, we show that the equilibrium strategy always exists uniquely. For dimension greater than one, by choosing a suitable norm and then applying the Banach Fixed Point Theorem, a sufficient condition, which is independent of the solution of the standard Riccati differential equation, for the unique existence of the equilibrium strategy is provided. As a by-product, we also establish a neat and instructive sufficient condition for the unique existence of the solution for a class of non-trivial nonsymmetric Riccati equations. Numerical examples of non-existence of the equilibrium strategy and the comparison of HCM's approach will also be provided."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2503.01040"
    ],
    "c_title":[
      "Pricing time-capped American options using Least Squares Monte Carlo\n  method"
    ],
    "c_abstract":[
      "In this paper, we adopt the least squares Monte Carlo (LSMC) method to price\ntime-capped American options. The aforementioned cap can be an independent\nrandom variable or dependent on asset price at random time. We allow various\ntime caps. In particular, we give an algorithm for pricing the American options\ncapped by the first drawdown epoch. We focus on the geometric L\\'evy market. We\nprove that our estimator converges to the true price as one takes the\ndiscretisation step tending to zero and the number of trajectories going to\ninfinity."
    ],
    "c_categories":[
      [
        "q-fin.MF"
      ]
    ],
    "c_fields":[
      "Economics and Quantitative Finance"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.00575",
    "a_title":"A Semi-Discrete Optimal Transport Scheme for the 3D Incompressible\n  Semi-Geostrophic Equations",
    "a_abstract":"We describe a mesh-free three-dimensional numerical scheme for solving the\nincompressible semi-geostrophic equations based on semi-discrete optimal\ntransport techniques. These results generalise previous two-dimensional\nimplementations. The optimal transport methods we adopt are known for their\nstructural preservation and energy conservation qualities and achieve an\nexcellent level of efficiency and numerical energy-conservation. We use this\nscheme to generate numerical simulations of an important cyclone benchmark\nproblem. To our knowledge, this is the first fully three-dimensional simulation\nof the semi-geostrophic equations, evidencing semi-discrete optimal transport\nas a novel, robust numerical tool for meteorological and oceanographic\nmodelling.",
    "explanation":"We describe a mesh-free three-dimensional numerical scheme for solving the in-\ncompressible semi-geostrophic equations based on semi-discrete optimal transport techniques.\nThese results generalise previous two-dimensional implementations.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Weak Existence for the Semigeostrophic Equations Formulated as a Coupled Monge--Amp\u00e8re\/Transport Problem"
    ],
    "b_abstract":[
      "Hoskins's semigeostrophic equations are reformulated as a coupled Monge--Amp\u00e8re\/ transport problem [B. J. Hoskins, Quart. Royal Met. Soc., 97 (1971), pp. 139--153]. Existence of global weak solutions is obtained for this formulation."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2501.03866"
    ],
    "c_title":[
      "Disjointly non-singular operators and various topologies on Banach\n  lattices"
    ],
    "c_abstract":[
      "We continue the study of dispersed subspaces and disjointly non-singular\n(DNS) operators on Banach lattices using topological methods. In particular, we\nprovide a simple proof of the fact that in an order continuous Banach lattice\nan operator is DNS if and only if it is $n$-DNS, for some $n\\in\\mathbb{N}$. We\ncharacterize Banach lattices with order continuous dual in terms of dispersed\nsubspaces and absolute weak topology. We also connect these topics with the\nrecently launched study of phase retrieval in Banach lattices."
    ],
    "c_categories":[
      [
        "math.FA",
        "math.GN"
      ]
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.00575",
    "a_title":"A Semi-Discrete Optimal Transport Scheme for the 3D Incompressible\n  Semi-Geostrophic Equations",
    "a_abstract":"We describe a mesh-free three-dimensional numerical scheme for solving the\nincompressible semi-geostrophic equations based on semi-discrete optimal\ntransport techniques. These results generalise previous two-dimensional\nimplementations. The optimal transport methods we adopt are known for their\nstructural preservation and energy conservation qualities and achieve an\nexcellent level of efficiency and numerical energy-conservation. We use this\nscheme to generate numerical simulations of an important cyclone benchmark\nproblem. To our knowledge, this is the first fully three-dimensional simulation\nof the semi-geostrophic equations, evidencing semi-discrete optimal transport\nas a novel, robust numerical tool for meteorological and oceanographic\nmodelling.",
    "explanation":"We describe a mesh-free three-dimensional numerical scheme for solving the in-\ncompressible semi-geostrophic equations based on semi-discrete optimal transport techniques.\nThese results generalise previous two-dimensional implementations.",
    "b_id":[
      "b22"
    ],
    "b_title":[
      "Vertical slice modelling of nonlinear Eady waves using a compatible finite element method"
    ],
    "b_abstract":[
      "A vertical slice model is developed for the Euler-Boussinesq equations with a\nconstant temperature gradient in the direction normal to the slice (the\nEady-Boussinesq model). The model is a solution of the full three-dimensional\nequations with no variation normal to the slice, which is an idealized problem\nused to study the formation and subsequent evolution of weather fronts. A\ncompatible finite element method is used to discretise the governing equations.\nTo extend the Charney-Phillips grid staggering in the compatible finite element\nframework, we use the same node locations for buoyancy as the vertical part of\nvelocity and apply a transport scheme for a partially continuous finite element\nspace. For the time discretisation, we solve the semi-implicit equations\ntogether with an explicit strong-stability-preserving Runge-Kutta scheme to all\nof the advection terms. The model reproduces several quasi-periodic lifecycles\nof fronts despite the presence of strong discontinuities. An asymptotic limit\nanalysis based on the semi-geostrophic theory shows that the model solutions\nare converging to a solution in cross-front geostrophic balance. The results\nare consistent with the previous results using finite difference methods,\nindicating that the compatible finite element method is performing as well as\nfinite difference methods for this test problem. We observe dissipation of\nkinetic energy of the cross-front velocity in the model due to the lack of\nresolution at the fronts, even though the energy loss is not likely to account\nfor the large gap on the strength of the fronts between the model result and\nthe semi-geostrophic limit solution."
    ],
    "b_categories":[
      "math.MP"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2501.12533"
    ],
    "c_title":[
      "Multi-objective and hierarchical control for coupled stochastic\n  parabolic systems"
    ],
    "c_abstract":[
      "We study the Stackelberg-Nash null controllability of a coupled system\ngoverned by two linear forward stochastic parabolic equations. The system\nincludes one leader control localized in a subset of the domain, two additional\nleader controls in the diffusion terms, and \\( m \\) follower controls, where \\(\nm \\geq 2 \\). We consider two different scenarios for the followers: first, when\nthe followers minimize a functional involving both components of the system's\nstate, and second, when they minimize a functional involving only the second\ncomponent of the state. For fixed leader controls, we first establish the\nexistence and uniqueness of the Nash equilibrium in both scenarios and provide\nits characterization. As a byproduct, the problem is reformulated as a\nclassical null controllability issue for the associated coupled\nforward-backward stochastic parabolic system. To address this, we derive new\nCarleman estimates for the adjoint stochastic systems. As far as we know, this\nproblem is among the first to be discussed for stochastic coupled systems."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.00578",
    "a_title":"Federated Voxel Scene Graph for Intracranial Hemorrhage",
    "a_abstract":"Intracranial Hemorrhage is a potentially lethal condition whose manifestation\nis vastly diverse and shifts across clinical centers worldwide.\nDeep-learning-based solutions are starting to model complex relations between\nbrain structures, but still struggle to generalize. While gathering more\ndiverse data is the most natural approach, privacy regulations often limit the\nsharing of medical data. We propose the first application of Federated Scene\nGraph Generation. We show that our models can leverage the increased training\ndata diversity. For Scene Graph Generation, they can recall up to 20% more\nclinically relevant relations across datasets compared to models trained on a\nsingle centralized dataset. Learning structured data representation in a\nfederated setting can open the way to the development of new methods that can\nleverage this finer information to regularize across clients more effectively.",
    "explanation":"intracranial Hemorrhage is a potentially lethal condition whose manifestation is vastly diverse and shifts across\nclinical centers worldwide. Deep-learning-based solutions are starting to model complex relations between brain\nstructures, but still struggle to generalize.",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "American Heart Association\/American Stroke Association. 2022 guideline for the management of patients with spontaneous intracerebral hemorrhage: A guideline from the american heart association\/american stroke association"
    ],
    "b_abstract":[
      "Approximately 10% of the 795\u2009000 strokes per year in the United States are intracerebral hemorrhages (ICHs),1 defined by brain injury attributable to acute blood extravasation into the brain parenchyma from a ruptured cerebral blood vessel. The clinical impact of ICH appears disproportionately high among lower-resource populations both in the United States and internationally. In US-based studies, ICH incidence has been reported to be \u22481.6-fold greater among Black than White people2 and 1.6-fold greater among Mexican American than non-Hispanic White people.3 Internationally, ICH incidence is substantially higher in low- and middle-income versus high-income countries, both as a proportion of all strokes and in absolute incidence rates.4,5 Several additional features of ICH make it a greater public health threat than conveyed by incidence numbers alone. ICH is arguably the deadliest form of acute stroke, with early-term mortality about 30% to 40% and no or minimal trend toward improvement over more recent time epochs.6\u20139 Incidence of ICH increases sharply with age and is therefore expected to remain substantial as the population ages, even with counterbalancing public health improvements in blood pressure (BP) control.8 Another growing source of ICH is more widespread use of anticoagulants,10 a trend likely to counterbalance the reduced ICH risk associated with increasing prescription of direct oral anticoagulants (DOACs) relative to vitamin K antagonists (VKAs).11 ICH thus remains in need of novel treatments and improved application of established approaches for every aspect of the disease: primary and secondary prevention, acute inpatient care, and poststroke rehabilitation and recovery. This guideline seeks to synthesize data in the ICH field into practical recommendations for clinical practice."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.10186"
    ],
    "c_title":[
      "Generative Artificial Intelligence: Implications for Biomedical and\n  Health Professions Education"
    ],
    "c_abstract":[
      "Generative AI has had a profound impact on biomedicine and health, both in\nprofessional work and in education. Based on large language models (LLMs),\ngenerative AI has been found to perform as well as humans in simulated\nsituations taking medical board exams, answering clinical questions, solving\nclinical cases, applying clinical reasoning, and summarizing information.\nGenerative AI is also being used widely in education, performing well in\nacademic courses and their assessments. This review summarizes the successes of\nLLMs and highlights some of their challenges in the context of education, most\nnotably aspects that may undermines the acquisition of knowledge and skills for\nprofessional work. It then provides recommendations for best practices\novercoming shortcomings for LLM use in education. Although there are challenges\nfor use of generative AI in education, all students and faculty, in biomedicine\nand health and beyond, must have understanding and be competent in its use."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00578",
    "a_title":"Federated Voxel Scene Graph for Intracranial Hemorrhage",
    "a_abstract":"Intracranial Hemorrhage is a potentially lethal condition whose manifestation\nis vastly diverse and shifts across clinical centers worldwide.\nDeep-learning-based solutions are starting to model complex relations between\nbrain structures, but still struggle to generalize. While gathering more\ndiverse data is the most natural approach, privacy regulations often limit the\nsharing of medical data. We propose the first application of Federated Scene\nGraph Generation. We show that our models can leverage the increased training\ndata diversity. For Scene Graph Generation, they can recall up to 20% more\nclinically relevant relations across datasets compared to models trained on a\nsingle centralized dataset. Learning structured data representation in a\nfederated setting can open the way to the development of new methods that can\nleverage this finer information to regularize across clients more effectively.",
    "explanation":"intracranial Hemorrhage is a potentially lethal condition whose manifestation is vastly diverse and shifts across\nclinical centers worldwide. Deep-learning-based solutions are starting to model complex relations between brain\nstructures, but still struggle to generalize.",
    "b_id":[
      "b25"
    ],
    "b_title":[
      "Voxel Scene Graph for Intracranial Hemorrhage"
    ],
    "b_abstract":[
      "Patients with Intracranial Hemorrhage (ICH) face a potentially life-threatening condition, and patient-centered individualized treatment remains challenging due to possible clinical complications. Deep-Learning-based methods can efficiently analyze the routinely acquired head CTs support decision-making. The majority of early work focuses on detection segmentation ICH, but do not model complex relations between ICH adjacent brain structures. In this work, we design tailored object method for which unite segmentation-grounded Scene Graph Generation (SGG) learn holistic representation cerebral scene. To best our knowledge, is first application SGG 3D voxel images. We evaluate two head-CT datasets demonstrate that recall up 74% clinically relevant relations. This lays foundation towards data. generated Graphs already provide insights clinician, are also valuable all downstream tasks as compact interpretable representation."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.19343"
    ],
    "c_title":[
      "Effect of a new type of healthy and live food supplement on osteoporosis\n  blood parameters and induced rheumatoid arthritis in Wistar rats"
    ],
    "c_abstract":[
      "Summary Osteoporosis is a skeletal disorder, characterized by a decrease in\nbone strength and puts the individual at risk for fracture. On the other hand,\nrheumatoid arthritis is a systemic disease of unknown etiology that causes\ninflammation of the joints of the organs. Purpose Due to the destructive\neffects of these diseases and its increasing prevalence and lack of appropriate\nmedication for treatment, the present study aimed to evaluate the therapeutic\neffect of a new type of healthy and live food supplement on rheumatoid\narthritis and induced osteoporosis in rats. Methods In this research, healthy\nand live food powder were synthesized by a new and green route. This organic\nbiomaterial was named NBS. The NBS food supplement had various vitamins, macro\nand micro molecules, and ingredients. The new healthy and nutritious diet\nshowed that the use of this supplement led to the return of the parameters to\nnormal levels. Results The concentration of 12.5 mg\/ kg showed the least\ntherapeutic effect and 50 mg\/ kg had the highest therapeutic effect for\nosteoporosis. The results of blood parameters involved in inflammation in both\nhealthy and patient groups showed that the use of complete adjuvant induction\ncauses joint inflammation. In the study of the interaction of the\nconcentrations, it was observed that the concentration of 50 mg\/ kg had the\nhighest therapeutic effect against the disease in the studied mice. Conclusion\nThe results showed that the new healthy and viable supplement restores the\nblood osteoporotic and rheumatoid factors of the mice to normal."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00614",
    "a_title":"Fast and scalable Wasserstein-1 neural optimal transport solver for\n  single-cell perturbation prediction",
    "a_abstract":"Predicting single-cell perturbation responses requires mapping between two\nunpaired single-cell data distributions. Optimal transport (OT) theory provides\na principled framework for constructing such mappings by minimizing transport\ncost. Recently, Wasserstein-2 ($W_2$) neural optimal transport solvers\n(\\textit{e.g.}, CellOT) have been employed for this prediction task. However,\n$W_2$ OT relies on the general Kantorovich dual formulation, which involves\noptimizing over two conjugate functions, leading to a complex min-max\noptimization problem that converges slowly. To address these challenges, we\npropose a novel solver based on the Wasserstein-1 ($W_1$) dual formulation.\nUnlike $W_2$, the $W_1$ dual simplifies the optimization to a maximization\nproblem over a single 1-Lipschitz function, thus eliminating the need for\ntime-consuming min-max optimization. While solving the $W_1$ dual only reveals\nthe transport direction and does not directly provide a unique optimal\ntransport map, we incorporate an additional step using adversarial training to\ndetermine an appropriate transport step size, effectively recovering the\ntransport map. Our experiments demonstrate that the proposed $W_1$ neural\noptimal transport solver can mimic the $W_2$ OT solvers in finding a unique and\n``monotonic\" map on 2D datasets. Moreover, the $W_1$ OT solver achieves\nperformance on par with or surpasses $W_2$ OT solvers on real single-cell\nperturbation datasets. Furthermore, we show that $W_1$ OT solver achieves $25\n\\sim 45\\times$ speedup, scales better on high dimensional transportation task,\nand can be directly applied on single-cell RNA-seq dataset with highly variable\ngenes. Our implementation and experiments are open-sourced at\n\\url{https:\/\/github.com\/poseidonchan\/w1ot}.",
    "explanation":"Predicting single-cell perturbation responses requires mapping between two unpaired single-\ncell data distributions. Optimal transport (OT) theory provides a principled framework for constructing\nsuch mappings by minimizing transport cost.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Multimodal pooled Perturb-CITE-seq screens in patient models define mechanisms of cancer immune evasion"
    ],
    "b_abstract":[
      "Resistance to immune checkpoint inhibitors (ICIs) is a key challenge in cancer therapy. To elucidate underlying mechanisms, we developed Perturb-CITE-sequencing (Perturb-CITE-seq), enabling pooled clustered regularly interspaced short palindromic repeat (CRISPR)\u2013Cas9 perturbations with single-cell transcriptome and protein readouts. In patient-derived melanoma cells and autologous tumor-infiltrating lymphocyte (TIL) co-cultures, we profiled transcriptomes and 20\u2009proteins in ~218,000\u2009cells under ~750\u2009perturbations associated with cancer cell-intrinsic ICI resistance (ICR). We recover known mechanisms of resistance, including defects in the interferon-\u03b3 (IFN-\u03b3)\u2013JAK\/STAT and antigen-presentation pathways in RNA, protein and perturbation space, and new ones, including loss\/downregulation of CD58. Loss of CD58 conferred immune evasion in multiple co-culture models and was downregulated in tumors of melanoma patients with ICR. CD58 protein expression was not induced by IFN-\u03b3 signaling, and CD58 loss conferred immune evasion without compromising major histocompatibility complex (MHC) expression, suggesting that it acts orthogonally to known mechanisms of ICR. This work provides a framework for the deciphering of complex mechanisms by large-scale perturbation screens with multimodal, single-cell readouts, and discovers potentially clinically relevant mechanisms of immune evasion."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.03470"
    ],
    "c_title":[
      "Positivstellens\\\"atze for polynomial matrices with universal quantifiers"
    ],
    "c_abstract":[
      "This paper studies Positivstellens\\\"atze for a polynomial matrix subject to\npolynomial matrix inequality constraints with universal quantifiers. We first\npresent a Scherer-Hol-type Positivstellensatz under the Archimedean condition.\nWhen the objective is a scalar polynomial, we further provide a sparse\nScherer-Hol-type Positivstellensatz in the presence of correlative sparsity.\nNext, without assuming the Archimedean condition, we derive\nPutinar-Vasilescu-type, P\\'olya-type, and Lasserre-Netzer-type\nPositivstellens\\\"atze under the same setting. These results can be viewed as\ncommon generalizations of corresponding Positivstellens\\\"atze in the cases of\npolynomials, polynomials with universal quantifiers, and polynomial matrices.\nFor the proofs, techniques from *-algebra, real algebraic geometry, operator\ntheory, and convex optimization are employed. Applications of the established\nPositivstellens\\\"atze to robust polynomial matrix optimization are also\ndiscussed."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00614",
    "a_title":"Fast and scalable Wasserstein-1 neural optimal transport solver for\n  single-cell perturbation prediction",
    "a_abstract":"Predicting single-cell perturbation responses requires mapping between two\nunpaired single-cell data distributions. Optimal transport (OT) theory provides\na principled framework for constructing such mappings by minimizing transport\ncost. Recently, Wasserstein-2 ($W_2$) neural optimal transport solvers\n(\\textit{e.g.}, CellOT) have been employed for this prediction task. However,\n$W_2$ OT relies on the general Kantorovich dual formulation, which involves\noptimizing over two conjugate functions, leading to a complex min-max\noptimization problem that converges slowly. To address these challenges, we\npropose a novel solver based on the Wasserstein-1 ($W_1$) dual formulation.\nUnlike $W_2$, the $W_1$ dual simplifies the optimization to a maximization\nproblem over a single 1-Lipschitz function, thus eliminating the need for\ntime-consuming min-max optimization. While solving the $W_1$ dual only reveals\nthe transport direction and does not directly provide a unique optimal\ntransport map, we incorporate an additional step using adversarial training to\ndetermine an appropriate transport step size, effectively recovering the\ntransport map. Our experiments demonstrate that the proposed $W_1$ neural\noptimal transport solver can mimic the $W_2$ OT solvers in finding a unique and\n``monotonic\" map on 2D datasets. Moreover, the $W_1$ OT solver achieves\nperformance on par with or surpasses $W_2$ OT solvers on real single-cell\nperturbation datasets. Furthermore, we show that $W_1$ OT solver achieves $25\n\\sim 45\\times$ speedup, scales better on high dimensional transportation task,\nand can be directly applied on single-cell RNA-seq dataset with highly variable\ngenes. Our implementation and experiments are open-sourced at\n\\url{https:\/\/github.com\/poseidonchan\/w1ot}.",
    "explanation":"Predicting single-cell perturbation responses requires mapping between two unpaired single-\ncell data distributions. Optimal transport (OT) theory provides a principled framework for constructing\nsuch mappings by minimizing transport cost.",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Causal identification of single-cell experimental perturbation effects with CINEMA-OT"
    ],
    "b_abstract":[
      "Abstract Recent advancements in single-cell technologies allow characterization of experimental perturbations at resolution. While methods have been developed to analyze such experiments, the application a strict causal framework has not yet explored for inference treatment effects level. Here we present causal-inference-based approach perturbation analysis, termed CINEMA-OT (causal independent effect module attribution + optimal transport). separates confounding sources variation from obtain an transport matching that reflects counterfactual cell pairs. These pairs represent responses permitting number novel analyses, as individual treatment-effect response clustering, and synergy analysis. We benchmark on array estimation tasks several simulated real datasets show it outperforms other analysis methods. Finally, perform two newly generated datasets: (1) rhinovirus cigarette-smoke-exposed airway organoids, (2) combinatorial cytokine stimulation immune cells. In these reveals potential mechanisms by which cigarette-smoke exposure dulls antiviral response, well logic governs chemokine secretion peripheral recruitment."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2501.05607"
    ],
    "c_title":[
      "Prediction of Binding Affinity for ErbB Inhibitors Using Deep Neural\n  Network Model with Morgan Fingerprints as Features"
    ],
    "c_abstract":[
      "The ErbB receptor family, including EGFR and HER2, plays a crucial role in\ncell growth and survival and is associated with the progression of various\ncancers such as breast and lung cancer. In this study, we developed a deep\nlearning model to predict the binding affinity of ErbB inhibitors using\nmolecular fingerprints derived from SMILES representations. The SMILES\nrepresentations for each ErbB inhibitor were obtained from the ChEMBL database.\nWe first generated Morgan fingerprints from the SMILES strings and applied\nAutoDock Vina docking to calculate the binding affinity values. After filtering\nthe dataset based on binding affinity, we trained a deep neural network (DNN)\nmodel to predict binding affinity values from the molecular fingerprints. The\nmodel achieved significant performance, with a Mean Squared Error (MSE) of\n0.2591, Mean Absolute Error (MAE) of 0.3658, and an R-squared value of 0.9389\non the training set. Although performance decreased slightly on the test set (R\nsquared = 0.7731), the model still demonstrated robust generalization\ncapabilities. These results indicate that the deep learning approach is highly\neffective for predicting the binding affinity of ErbB inhibitors, offering a\nvaluable tool for virtual screening and drug discovery."
    ],
    "c_categories":[
      [
        "q-bio.BM"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00749",
    "a_title":"PathoGen-X: A Cross-Modal Genomic Feature Trans-Align Network for\n  Enhanced Survival Prediction from Histopathology Images",
    "a_abstract":"Accurate survival prediction is essential for personalized cancer treatment.\nHowever, genomic data - often a more powerful predictor than pathology data -\nis costly and inaccessible. We present the cross-modal genomic feature\ntranslation and alignment network for enhanced survival prediction from\nhistopathology images (PathoGen-X). It is a deep learning framework that\nleverages both genomic and imaging data during training, relying solely on\nimaging data at testing. PathoGen-X employs transformer-based networks to align\nand translate image features into the genomic feature space, enhancing weaker\nimaging signals with stronger genomic signals. Unlike other methods, PathoGen-X\ntranslates and aligns features without projecting them to a shared latent space\nand requires fewer paired samples. Evaluated on TCGA-BRCA, TCGA-LUAD, and\nTCGA-GBM datasets, PathoGen-X demonstrates strong survival prediction\nperformance, emphasizing the potential of enriched imaging models for\naccessible cancer prognosis.",
    "explanation":"Accurate survival prediction is essential for personalized\ncancer treatment. . It is a\ndeep learning framework that leverages both genomic and\nimaging data during training, relying solely on imaging data\nat testing. ",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "A 2021 update on cancer image analytics with deep learning"
    ],
    "b_abstract":[
      "Deep learning (DL)-based interpretation of medical images has reached a critical juncture of expanding outside research projects into translational ones, and is ready to make its way to the clinics. Advances over the last decade in data availability, DL techniques, as well as computing capabilities have accelerated this journey. Through this journey, today we have a better understanding of the challenges to and pitfalls of wider adoption of DL into clinical care, which, according to us, should and will drive the advances in this field in the next few years. The most important among these challenges are the lack of an appropriately digitized environment within healthcare institutions, the lack of adequate open and representative datasets on which DL algorithms can be trained and tested, and the lack of robustness of widely used DL training algorithms to certain pervasive pathological characteristics of medical images and repositories. In this review, we provide an overview of the role of imaging in oncology, the different techniques that are shaping the way DL algorithms are being made ready for clinical use, and also the problems that DL techniques still need to address before DL can find a home in clinics. Finally, we also provide a summary of how DL can potentially drive the adoption of digital pathology, vendor neutral archives, and picture archival and communication systems. We caution that the respective researchers may find the coverage of their own fields to be at a high-level. This is so by design as this format is meant to only introduce those looking in from outside of deep learning and medical research, respectively, to gain an appreciation for the main concerns and limitations of these two fields instead of telling them something new about their own."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.16938"
    ],
    "c_title":[
      "Interpretable Machine Learning for Oral Lesion Diagnosis through\n  Prototypical Instances Identification"
    ],
    "c_abstract":[
      "Decision-making processes in healthcare can be highly complex and\nchallenging. Machine Learning tools offer significant potential to assist in\nthese processes. However, many current methodologies rely on complex models\nthat are not easily interpretable by experts. This underscores the need to\ndevelop interpretable models that can provide meaningful support in clinical\ndecision-making. When approaching such tasks, humans typically compare the\nsituation at hand to a few key examples and representative cases imprinted in\ntheir memory. Using an approach which selects such exemplary cases and grounds\nits predictions on them could contribute to obtaining high-performing\ninterpretable solutions to such problems. To this end, we evaluate PivotTree,\nan interpretable prototype selection model, on an oral lesion detection\nproblem, specifically trying to detect the presence of neoplastic, aphthous and\ntraumatic ulcerated lesions from oral cavity images. We demonstrate the\nefficacy of using such method in terms of performance and offer a qualitative\nand quantitative comparison between exemplary cases and ground-truth prototypes\nselected by experts."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00749",
    "a_title":"PathoGen-X: A Cross-Modal Genomic Feature Trans-Align Network for\n  Enhanced Survival Prediction from Histopathology Images",
    "a_abstract":"Accurate survival prediction is essential for personalized cancer treatment.\nHowever, genomic data - often a more powerful predictor than pathology data -\nis costly and inaccessible. We present the cross-modal genomic feature\ntranslation and alignment network for enhanced survival prediction from\nhistopathology images (PathoGen-X). It is a deep learning framework that\nleverages both genomic and imaging data during training, relying solely on\nimaging data at testing. PathoGen-X employs transformer-based networks to align\nand translate image features into the genomic feature space, enhancing weaker\nimaging signals with stronger genomic signals. Unlike other methods, PathoGen-X\ntranslates and aligns features without projecting them to a shared latent space\nand requires fewer paired samples. Evaluated on TCGA-BRCA, TCGA-LUAD, and\nTCGA-GBM datasets, PathoGen-X demonstrates strong survival prediction\nperformance, emphasizing the potential of enriched imaging models for\naccessible cancer prognosis.",
    "explanation":"Accurate survival prediction is essential for personalized\ncancer treatment. . It is a\ndeep learning framework that leverages both genomic and\nimaging data during training, relying solely on imaging data\nat testing. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classification"
    ],
    "b_abstract":[
      "Multiple instance learning (MIL) is a powerful tool to solve the weakly supervised classification in whole slide image (WSI) based pathology diagnosis. However, current MIL methods are usually on independent and identical distribution hypothesis, thus neglect correlation among different instances. To address this problem, we proposed new framework, called correlated MIL, provided proof for convergence. Based devised Transformer (TransMIL), which explored both morphological spatial information. The TransMIL can effectively deal with unbalanced\/balanced binary\/multiple great visualization interpretability. We conducted various experiments three computational problems achieved better performance faster convergence compared state-of-the-art methods. test AUC binary tumor be up 93.09% over CAMELYON16 dataset. And cancer subtypes 96.03% 98.82% TCGA-NSCLC dataset TCGA-RCC dataset, respectively. Implementation available at: https:\/\/github.com\/szc19990412\/TransMIL."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.03001"
    ],
    "c_title":[
      "Multicellular self-organization in Escherichia coli"
    ],
    "c_abstract":[
      "Escherichia coli has long been a trusty companion, maintaining health in our\nguts and advancing biological knowledge in the laboratory. In light of recent\nfindings, we discuss multicellular self-organization in E. coli and develop\ngeneral ideas for multicellularity, including the necessity for multicellular\ndynamics and interpretation by dynamic graphs, applicable to both unicellular\nand multicellular organisms. In this context, we next discuss the documented\nbehaviors of E. coli self-organization (rosette formation, multicellular\nextension, and attached dormancy) and two potential behaviors (internal\ncommunication and mating). Finally, by comparing the dynamic graphs for\ndifferent communities, we develop principles relevant to the theory of\nmulticellularity."
    ],
    "c_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.00758",
    "a_title":"Inverse methods for freeform optical design",
    "a_abstract":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design, based on Hamilton's characteristic functions and\nconservation of luminous flux, and briefly explain the connection with the\nmathematical theory of optimal transport. We outline several iterative\nleast-squares solvers for our models and demonstrate their performance for a\nfew challenging problems.",
    "explanation":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design .We outline several iterative least-squares solvers for our models and demonstrate their\nperformance for a few challenging problems.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Introduction to Nonimaging Optics, second edition"
    ],
    "b_abstract":[
      "Introduction to Nonimaging Optics covers the theoretical foundations and design methods of nonimaging optics, as well as key concepts from related fields. This fully updated, revised, and expanded Second Edition: \u2022 Features a new and intuitive introduction with a basic description of the advantages of nonimaging optics \u2022 Adds new chapters on wavefronts for a prescribed output (irradiance or intensity), infinitesimal \u00e9tendue optics (generalization of the aplanatic optics), and K\u00f6hler optics and color mixing \u2022 Incorporates new material on the simultaneous multiple surface (SMS) design method in 3-D, integral invariants, and \u00e9tendue 2-D \u2022 Contains 21 chapters, 24 fully worked and several other examples, and 1,000+ illustrations, including photos of real devices \u2022 Addresses applications ranging from solar energy concentration to illumination engineering Introduction to Nonimaging Optics, Second Edition invites newcomers to explore the growing field of nonimaging optics, while providing seasoned veterans with an extensive reference book."
    ],
    "b_categories":[
      "physics.optics"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2501.08789"
    ],
    "c_title":[
      "On Erlang Queue with Multiple Arrivals and its Time-changed Variant"
    ],
    "c_abstract":[
      "We introduce and study a queue with the Erlang service system and whose\narrivals are governed by a counting process in which there is a possibility of\nfinitely many arrivals in an infinitesimal time interval. We call it the Erlang\nqueue with multiple arrivals. Some of its distributional properties are\nobtained that includes the state-phase probabilities, the mean queue length and\nthe distribution of busy period etc. Also, we study a time-changed variant of\nit by subordinating it with an independent inverse stable subordinator where we\nobtain its state probabilities and the mean queue length."
    ],
    "c_categories":[
      [
        "math.PR"
      ]
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.00758",
    "a_title":"Inverse methods for freeform optical design",
    "a_abstract":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design, based on Hamilton's characteristic functions and\nconservation of luminous flux, and briefly explain the connection with the\nmathematical theory of optimal transport. We outline several iterative\nleast-squares solvers for our models and demonstrate their performance for a\nfew challenging problems.",
    "explanation":"We present a systematic derivation of three mathematical models of increasing\ncomplexity for optical design .We outline several iterative least-squares solvers for our models and demonstrate their\nperformance for a few challenging problems.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "Inverse methods for illumination optics"
    ],
    "b_abstract":[
      "\u2022 A submitted manuscript is the version of the article upon submission and before peer-review. There can be important differences between the submitted version and the official published version of record. People interested in the research are advised to contact the author for the final version of the publication, or visit the DOI to the publisher's website. \u2022 The final author version and the galley proof are versions of the publication after peer review. \u2022 The final published version features the final layout of the paper including the volume, issue and page numbers."
    ],
    "b_categories":[
      "math.MP"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2503.16249"
    ],
    "c_title":[
      "A GHz fiber comb on silica"
    ],
    "c_abstract":[
      "We present a 1 GHz Yb-fiber laser frequency comb built on silica substrates,\nutilizing \"optical cubes\" to house all optical components, ensuring long-term\nstability and practical operation. Both the femtosecond laser and f-to-2f\ninterferometer are constructed to silica bricks, with a compact footprint of\n290 mm $\\times$ 250 mm, and a total weight of 1.8 kg. This system provides a\nstable repetition rate, offset frequency, and a supercontinuum spanning\n460-1560 nm without requiring amplification. The carrier-envelop offset\nfrequency exhibits exceptional stability, with a fractional frequency\ninstability of $3.07\\times 10^{-18}$ at a 1 second averaging time, improving to\n$2.12\\times 10^{-20}$ at a 10,000 second, maintaining uninterrupted operation\nfor over 60 hours. This work demonstrates a high-performance GHz fiber-based\nfrequency comb, paving the way for applications beyond laboratory environments,\nincluding dual-comb spectroscopy, astronomical spectrograph calibration, and\nportable optical clocks."
    ],
    "c_categories":[
      [
        "physics.optics"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.01291",
    "a_title":"Deep Multi-contrast Cardiac MRI Reconstruction via vSHARP with Auxiliary\n  Refinement Network",
    "a_abstract":"Cardiac MRI (CMRI) is a cornerstone imaging modality that provides in-depth\ninsights into cardiac structure and function. Multi-contrast CMRI (MCCMRI),\nwhich acquires sequences with varying contrast weightings, significantly\nenhances diagnostic capabilities by capturing a wide range of cardiac tissue\ncharacteristics. However, MCCMRI is often constrained by lengthy acquisition\ntimes and susceptibility to motion artifacts. To mitigate these challenges,\naccelerated imaging techniques that use k-space undersampling via different\nsampling schemes at acceleration factors have been developed to shorten scan\ndurations. In this context, we propose a deep learning-based reconstruction\nmethod for 2D dynamic multi-contrast, multi-scheme, and multi-acceleration MRI.\nOur approach integrates the state-of-the-art vSHARP model, which utilizes\nhalf-quadratic variable splitting and ADMM optimization, with a Variational\nNetwork serving as an Auxiliary Refinement Network (ARN) to better adapt to the\ndiverse nature of MCCMRI data. Specifically, the subsampled k-space data is fed\ninto the ARN, which produces an initial prediction for the denoising step used\nby vSHARP. This, along with the subsampled k-space, is then used by vSHARP to\ngenerate high-quality 2D sequence predictions. Our method outperforms\ntraditional reconstruction techniques and other vSHARP-based models.",
    "explanation":"Cardiac MRI (CMRI) is a cornerstone imaging modality that\nprovides in-depth insights into cardiac structure and function.  Our approach integrates the state-of-the-art vSHARP model, which uti-\nlizes half-quadratic variable splitting and ADMM optimization, with a\nVariational Network serving as an Auxiliary Refinement Network (ARN)\nto better adapt to the diverse nature of MCCMRI data. ",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "CMRxRecon2024: A Multi-Modality, Multi-View K-Space Dataset Boosting\n  Universal Machine Learning for Accelerated Cardiac MRI"
    ],
    "b_abstract":[
      "Cardiac magnetic resonance imaging (MRI) has emerged as a clinically gold-standard technique for diagnosing cardiac diseases, thanks to its ability provide diverse information with multiple modalities and anatomical views. Accelerated MRI is highly expected achieve time-efficient patient-friendly imaging, then advanced image reconstruction approaches are required recover high-quality, interpretable images from undersampled measurements. However, the lack of publicly available k-space dataset in terms both quantity diversity severely hindered substantial technological progress, particularly data-driven artificial intelligence. Here, we standardized, diverse, high-quality CMRxRecon2024 facilitate technical development, fair evaluation, clinical transfer approaches, towards promoting universal frameworks that enable fast robust reconstructions across different protocols practice. To best our knowledge, largest most dataset. It acquired 330 healthy volunteers, covering commonly used modalities, views, acquisition trajectories workflows. Besides, an open platform tutorials, benchmarks, data processing tools provided usage, method performance evaluation."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.06561"
    ],
    "c_title":[
      "Where to Go Next Day: Multi-scale Spatial-Temporal Decoupled Model for\n  Mid-term Human Mobility Prediction"
    ],
    "c_abstract":[
      "Predicting individual mobility patterns is crucial across various\napplications. While current methods mainly focus on predicting the next\nlocation for personalized services like recommendations, they often fall short\nin supporting broader applications such as traffic management and epidemic\ncontrol, which require longer period forecasts of human mobility. This study\naddresses mid-term mobility prediction, aiming to capture daily travel patterns\nand forecast trajectories for the upcoming day or week. We propose a novel\nMulti-scale Spatial-Temporal Decoupled Predictor (MSTDP) designed to\nefficiently extract spatial and temporal information by decoupling daily\ntrajectories into distinct location-duration chains. Our approach employs a\nhierarchical encoder to model multi-scale temporal patterns, including daily\nrecurrence and weekly periodicity, and utilizes a transformer-based decoder to\nglobally attend to predicted information in the location or duration chain.\nAdditionally, we introduce a spatial heterogeneous graph learner to capture\nmulti-scale spatial relationships, enhancing semantic-rich representations.\nExtensive experiments, including statistical physics analysis, are conducted on\nlarge-scale mobile phone records in five cities (Boston, Los Angeles, SF Bay\nArea, Shanghai, and Tokyo), to demonstrate MSTDP's advantages. Applied to\nepidemic modeling in Boston, MSTDP significantly outperforms the\nbest-performing baseline, achieving a remarkable 62.8% reduction in MAE for\ncumulative new cases."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.01291",
    "a_title":"Deep Multi-contrast Cardiac MRI Reconstruction via vSHARP with Auxiliary\n  Refinement Network",
    "a_abstract":"Cardiac MRI (CMRI) is a cornerstone imaging modality that provides in-depth\ninsights into cardiac structure and function. Multi-contrast CMRI (MCCMRI),\nwhich acquires sequences with varying contrast weightings, significantly\nenhances diagnostic capabilities by capturing a wide range of cardiac tissue\ncharacteristics. However, MCCMRI is often constrained by lengthy acquisition\ntimes and susceptibility to motion artifacts. To mitigate these challenges,\naccelerated imaging techniques that use k-space undersampling via different\nsampling schemes at acceleration factors have been developed to shorten scan\ndurations. In this context, we propose a deep learning-based reconstruction\nmethod for 2D dynamic multi-contrast, multi-scheme, and multi-acceleration MRI.\nOur approach integrates the state-of-the-art vSHARP model, which utilizes\nhalf-quadratic variable splitting and ADMM optimization, with a Variational\nNetwork serving as an Auxiliary Refinement Network (ARN) to better adapt to the\ndiverse nature of MCCMRI data. Specifically, the subsampled k-space data is fed\ninto the ARN, which produces an initial prediction for the denoising step used\nby vSHARP. This, along with the subsampled k-space, is then used by vSHARP to\ngenerate high-quality 2D sequence predictions. Our method outperforms\ntraditional reconstruction techniques and other vSHARP-based models.",
    "explanation":"Cardiac MRI (CMRI) is a cornerstone imaging modality that\nprovides in-depth insights into cardiac structure and function.  Our approach integrates the state-of-the-art vSHARP model, which uti-\nlizes half-quadratic variable splitting and ADMM optimization, with a\nVariational Network serving as an Auxiliary Refinement Network (ARN)\nto better adapt to the diverse nature of MCCMRI data. ",
    "b_id":[
      "b19"
    ],
    "b_title":[
      "vSHARP: variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse-Problems"
    ],
    "b_abstract":[
      "Medical Imaging (MI) tasks, such as accelerated parallel Magnetic Resonance Imaging (MRI), often involve reconstructing an image from noisy or incomplete measurements. This amounts to solving ill-posed inverse problems, where a satisfactory closed-form analytical solution is not available. Traditional methods such as Compressed Sensing (CS) in MRI reconstruction can be time-consuming or prone to obtaining low-fidelity images. Recently, a plethora of Deep Learning (DL) approaches have demonstrated superior performance in inverse-problem solving, surpassing conventional methods. In this study, we propose vSHARP (variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse Problems), a novel DL-based method for solving ill-posed inverse problems arising in MI. vSHARP utilizes the Half-Quadratic Variable Splitting method and employs the Alternating Direction Method of Multipliers (ADMM) to unroll the optimization process. For data consistency, vSHARP unrolls a differentiable gradient descent process in the image domain, while a DL-based denoiser, such as a U-Net architecture, is applied to enhance image quality. vSHARP also employs a dilated-convolution DL-based model to predict the Lagrange multipliers for the ADMM initialization. We evaluate vSHARP on tasks of accelerated parallel MRI Reconstruction using two distinct datasets and on accelerated parallel dynamic MRI Reconstruction using another dataset. Our comparative analysis with state-of-the-art methods demonstrates the superior performance of vSHARP in these applications."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04504"
    ],
    "c_title":[
      "Integrating anatomy and electrophysiology in the healthy human heart:\n  Insights from biventricular statistical shape analysis using universal\n  coordinates"
    ],
    "c_abstract":[
      "A cardiac digital twin is a virtual replica of a patient-specific heart,\nmimicking its anatomy and physiology. A crucial step of building a cardiac\ndigital twin is anatomical twinning, where the computational mesh of the\ndigital twin is tailored to the patient-specific cardiac anatomy. In a number\nof studies, the effect of anatomical variation on clinically relevant\nfunctional measurements like electrocardiograms (ECGs) is investigated, using\ncomputational simulations. While such a simulation environment provides\nresearchers with a carefully controlled ground truth, the impact of anatomical\ndifferences on functional measurements in real-world patients remains\nunderstudied. In this study, we develop a biventricular statistical shape model\nand use it to quantify the effect of biventricular anatomy on ECG-derived and\ndemographic features, providing novel insights for the development of digital\ntwins of cardiac electrophysiology. To this end, a dataset comprising\nhigh-resolution cardiac CT scans from 271 healthy individuals, including\nathletes, is utilized. Furthermore, a novel, universal, ventricular\ncoordinate-based method is developed to establish lightweight shape\ncorrespondence. The performance of the shape model is rigorously established,\nfocusing on its dimensionality reduction capabilities and the training data\nrequirements. Additionally, a comprehensive synthetic cohort is made available,\nfeaturing ready-to-use biventricular meshes with fiber structures and\nanatomical region annotations. These meshes are well-suited for\nelectrophysiological simulations."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.01758",
    "a_title":"Disentangled PET Lesion Segmentation",
    "a_abstract":"PET imaging is an invaluable tool in clinical settings as it captures the\nfunctional activity of both healthy anatomy and cancerous lesions. Developing\nautomatic lesion segmentation methods for PET images is crucial since manual\nlesion segmentation is laborious and prone to inter- and intra-observer\nvariability. We propose PET-Disentangler, a 3D disentanglement method that uses\na 3D UNet-like encoder-decoder architecture to disentangle disease and normal\nhealthy anatomical features with losses for segmentation, reconstruction, and\nhealthy component plausibility. A critic network is used to encourage the\nhealthy latent features to match the distribution of healthy samples and thus\nencourages these features to not contain any lesion-related features. Our\nquantitative results show that PET-Disentangler is less prone to incorrectly\ndeclaring healthy and high tracer uptake regions as cancerous lesions, since\nsuch uptake pattern would be assigned to the disentangled healthy component.",
    "explanation":"PET imaging is an invaluable tool in clinical settings as it\ncaptures the functional activity of both healthy anatomy and\ncancerous lesions. Developing automatic lesion segmentation\nmethods for PET images is crucial since manual lesion seg-\nmentation is laborious and prone to inter- and intra-observer\nvariability. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Multi-site quality and variability analysis of 3D FDG PET segmentations based on phantom and clinical image data"
    ],
    "b_abstract":[
      "Purpose: Radiomics utilizes a large number of image-derived features for quantifying tumor characteristics that can in turn be correlated with response and prognosis. Unfortunately, extraction and analysis of such image-based features is subject to measurement variability and bias. The challenge for radiomics is particularly acute in Positron Emission Tomography (PET) where limited resolution, a high noise component related to the limited stochastic nature of the raw data, and the wide variety of reconstruction options confound quantitative feature metrics. Extracted feature quality is also affected by tumor segmentation methods used to define regions over which to calculate features, making it challenging to produce consistent radiomics analysis results across multiple institutions that use different segmentation algorithms in their PET image analysis. Understanding each element contributing to these inconsistencies in quantitative image feature and metric generation is paramount for ultimate utilization of these methods in multi-institutional trials and clinical oncology decision making. Methods: To assess segmentation quality and consistency at the multi-institutional level, we conducted a study of seven institutional members of the National Cancer Institute Quantitative Imaging Network. For the study, members were asked to segment a common set of phantom PET scans acquired over a range of imaging conditions as well as a second set of head and neck cancer (HNC) PET scans. Segmentations were generated at each institution using their preferred approach. In addition, participants were asked to repeat segmentations with a time interval between initial and repeat segmentation. This procedure resulted in overall 806 phantom insert and 641 lesion segmentations. Subsequently, the volume was computed from the segmentations and compared to the corresponding reference volume by means of statistical analysis. Results: On the two test sets (phantom and HNC PET scans), the performance of the seven segmentation approaches was as follows. On the phantom test set, the mean relative volume errors ranged from 29.9 to 87.8% of the ground truth reference volumes, and the repeat difference for each institution ranged between -36.4 to 39.9%. On the HNC test set, the mean relative volume error ranged between -50.5 to 701.5%, and the repeat difference for each institution ranged between -37.7 to 31.5%. In addition, performance measures per phantom insert\/lesion size categories are given in the paper. On phantom data, regression analysis resulted in coefficient of variation (CV) components of 42.5% for scanners, 26.8% for institutional approaches, 21.1% for repeated segmentations, 14.3% for relative contrasts, 5.3% for count statistics (acquisition times), and 0.0% for repeated scans. Analysis showed that the CV components for approaches and repeated segmentations were significantly larger on the HNC test set with increases by 112.7% and 102.4%, respectively. Conclusion: Analysis results underline the importance of PET scanner reconstruction harmonization and imaging protocol standardization for quantification of lesion volumes. In addition, to enable a distributed multi-site analysis of FDG PET images, harmonization of analysis approaches and operator training in combination with highly automated segmentation methods seems to be advisable. Future work will focus on quantifying the impact of segmentation variation on radiomics system performance."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.07540"
    ],
    "c_title":[
      "AI-Enabled Knowledge Sharing for Enhanced Collaboration and\n  Decision-Making in Non-Profit Healthcare Organizations: A Scoping Review\n  Protocol"
    ],
    "c_abstract":[
      "This protocol outlines a scoping review designed to systematically map the\nexisting body of evidence on AI-enabled knowledge sharing in resource-limited\nnon-profit healthcare organizations. The review aims to investigate how such\ntechnologies enhance collaboration and decision-making, particularly in the\ncontext of reduced external support following the cessation of USAID\noperations. Guided by three theoretical frameworks namely, the Resource-Based\nView, Dynamic Capabilities Theory, and Absorptive Capacity Theory, this study\nwill explore the dual role of AI as a strategic resource and an enabler of\norganizational learning and agility. The protocol details a rigorous\nmethodological approach based on PRISMA-ScR guidelines, encompassing a\nsystematic search strategy across multiple databases, inclusion and exclusion\ncriteria, and a structured data extraction process. By integrating theoretical\ninsights with empirical evidence, this scoping review seeks to identify\ncritical gaps in the literature and inform the design of effective,\nresource-optimized AI solutions in non-profit healthcare settings."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.01758",
    "a_title":"Disentangled PET Lesion Segmentation",
    "a_abstract":"PET imaging is an invaluable tool in clinical settings as it captures the\nfunctional activity of both healthy anatomy and cancerous lesions. Developing\nautomatic lesion segmentation methods for PET images is crucial since manual\nlesion segmentation is laborious and prone to inter- and intra-observer\nvariability. We propose PET-Disentangler, a 3D disentanglement method that uses\na 3D UNet-like encoder-decoder architecture to disentangle disease and normal\nhealthy anatomical features with losses for segmentation, reconstruction, and\nhealthy component plausibility. A critic network is used to encourage the\nhealthy latent features to match the distribution of healthy samples and thus\nencourages these features to not contain any lesion-related features. Our\nquantitative results show that PET-Disentangler is less prone to incorrectly\ndeclaring healthy and high tracer uptake regions as cancerous lesions, since\nsuch uptake pattern would be assigned to the disentangled healthy component.",
    "explanation":"PET imaging is an invaluable tool in clinical settings as it\ncaptures the functional activity of both healthy anatomy and\ncancerous lesions. Developing automatic lesion segmentation\nmethods for PET images is crucial since manual lesion seg-\nmentation is laborious and prone to inter- and intra-observer\nvariability. ",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "A review on segmentation of positron emission tomography images"
    ],
    "b_abstract":[
      "Positron Emission Tomography (PET), a non-invasive functional imaging method at the molecular level, images the distribution of biologically targeted radiotracers with high sensitivity. PET imaging provides detailed quantitative information about many diseases and is often used to evaluate inflammation, infection, and cancer by detecting emitted photons from a radiotracer localized to abnormal cells. In order to differentiate abnormal tissue from surrounding areas in PET images, image segmentation methods play a vital role; therefore, accurate image segmentation is often necessary for proper disease detection, diagnosis, treatment planning, and follow-ups. In this review paper, we present state-of-the-art PET image segmentation methods, as well as the recent advances in image segmentation techniques. In order to make this manuscript self-contained, we also briefly explain the fundamentals of PET imaging, the challenges of diagnostic PET image analysis, and the effects of these challenges on the segmentation results."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.03001"
    ],
    "c_title":[
      "Multicellular self-organization in Escherichia coli"
    ],
    "c_abstract":[
      "Escherichia coli has long been a trusty companion, maintaining health in our\nguts and advancing biological knowledge in the laboratory. In light of recent\nfindings, we discuss multicellular self-organization in E. coli and develop\ngeneral ideas for multicellularity, including the necessity for multicellular\ndynamics and interpretation by dynamic graphs, applicable to both unicellular\nand multicellular organisms. In this context, we next discuss the documented\nbehaviors of E. coli self-organization (rosette formation, multicellular\nextension, and attached dormancy) and two potential behaviors (internal\ncommunication and mating). Finally, by comparing the dynamic graphs for\ndifferent communities, we develop principles relevant to the theory of\nmulticellularity."
    ],
    "c_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03389",
    "a_title":"Neurons for Neutrons: A Transformer Model for Computation Load\n  Estimation on Domain-Decomposed Neutron Transport Problems",
    "a_abstract":"Domain decomposition is a technique used to reduce memory overhead on large\nneutron transport problems. Currently, the optimal load-balanced processor\nallocation for these domains is typically determined through small-scale\nsimulations of the problem, which can be time-consuming for researchers and\nmust be repeated anytime a problem input is changed. We propose a Transformer\nmodel with a unique 3D input embedding, and input representations designed for\ndomain-decomposed neutron transport problems, which can predict the subdomain\ncomputation loads generated by small-scale simulations. We demonstrate that\nsuch a model trained on domain-decomposed Small Modular Reactor (SMR)\nsimulations achieves 98.2% accuracy while being able to skip the small-scale\nsimulation step entirely. Tests of the model's robustness on variant fuel\nassemblies, other problem geometries, and changes in simulation parameters are\nalso discussed.",
    "explanation":"Currently, the optimal load-\nbalanced processor allocation for these domains is typically determined\nthrough small-scale simulations of the problem, which can be time-consuming\nfor researchers and must be repeated anytime a problem input is changed.\nWe propose a Transformer model with a unique 3D input embedding, and\ninput representations designed for domain-decomposed neutron transport\nproblems, which can predict the subdomain computation loads generated\nby small-scale simulations.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Attention Is All You Need"
    ],
    "b_abstract":[
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. best performing also connect the encoder and decoder through attention mechanism. We propose a new simple network architecture, Transformer, solely mechanisms, dispensing with recurrence convolutions entirely. Experiments two machine translation tasks show these to be superior quality while being more parallelizable requiring significantly less time train. Our model achieves 28.4 BLEU WMT 2014 English-to-German task, improving over existing results, including ensembles by 2 BLEU. On English-to-French our establishes single-model state-of-the-art score of 41.8 after training for 3.5 days eight GPUs, small fraction costs from literature. that Transformer generalizes well other applying it successfully English constituency parsing both large limited data."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.10153"
    ],
    "c_title":[
      "Contemporaneous optical-radio observations of a fast radio burst in a\n  close galaxy pair"
    ],
    "c_abstract":[
      "We present the MeerKAT discovery and MeerLICHT contemporaneous optical\nobservations of the Fast Radio Burst (FRB) 20230808F, which was found to have a\ndispersion measure of $\\mathrm{DM}=653.2\\pm0.4\\mathrm{\\,pc\\,cm^{-3}}$. FRB\n20230808F has a scattering timescale $\\tau_{s}=3.1\\pm0.1\\,\\mathrm{ms}$ at\n$1563.6$ MHz, a rotation measure\n$\\mathrm{RM}=169.4\\pm0.2\\,\\mathrm{rad\\,m^{-2}}$, and a radio fluence\n$F_{\\mathrm{radio}}=1.72\\pm0.01\\,\\mathrm{Jy\\,ms}$. We find no optical\ncounterpart in the time immediately after the FRB, nor in the three months\nafter the FRB during which we continued to monitor the field of the FRB. We set\nan optical upper flux limit in MeerLICHT's $q$-band of $11.7\\,\\mathrm{\\mu Jy}$\nfor a 60 s exposure which started $\\sim3.4$ s after the burst, which\ncorresponds to an optical fluence, $F_{\\mathrm{opt}}$, of\n$0.039\\,\\mathrm{Jy\\,ms}$ on a timescale of $\\sim3.4$ s. We obtain an estimate\nfor the $q-$band luminosity limit of $vL_{v}\\sim\n1.3\\times10^{43}\\,\\mathrm{erg\\,s^{-1}}$. We localise the burst to a close\ngalaxy pair at a redshift of $z_{\\mathrm{spec}}=0.3472\\pm0.0002$. Our time\ndelay of $\\sim3.4$ s between the FRB arrival time and the start of our optical\nexposure is the shortest ever for an as yet non-repeating FRB, and hence the\nclosest to simultaneous optical follow-up that exists for such an FRB."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03389",
    "a_title":"Neurons for Neutrons: A Transformer Model for Computation Load\n  Estimation on Domain-Decomposed Neutron Transport Problems",
    "a_abstract":"Domain decomposition is a technique used to reduce memory overhead on large\nneutron transport problems. Currently, the optimal load-balanced processor\nallocation for these domains is typically determined through small-scale\nsimulations of the problem, which can be time-consuming for researchers and\nmust be repeated anytime a problem input is changed. We propose a Transformer\nmodel with a unique 3D input embedding, and input representations designed for\ndomain-decomposed neutron transport problems, which can predict the subdomain\ncomputation loads generated by small-scale simulations. We demonstrate that\nsuch a model trained on domain-decomposed Small Modular Reactor (SMR)\nsimulations achieves 98.2% accuracy while being able to skip the small-scale\nsimulation step entirely. Tests of the model's robustness on variant fuel\nassemblies, other problem geometries, and changes in simulation parameters are\nalso discussed.",
    "explanation":"Currently, the optimal load-\nbalanced processor allocation for these domains is typically determined\nthrough small-scale simulations of the problem, which can be time-consuming\nfor researchers and must be repeated anytime a problem input is changed.\nWe propose a Transformer model with a unique 3D input embedding, and\ninput representations designed for domain-decomposed neutron transport\nproblems, which can predict the subdomain computation loads generated\nby small-scale simulations.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Continuous-energy Monte Carlo neutron transport on GPUs in the Shift code"
    ],
    "b_abstract":[
      "A continuous-energy Monte Carlo neutron transport solver executing on GPUs has been developed within the Shift code. Several algorithmic approaches are considered, including both history-based and event-based implementations. Unlike in previous work involving multigroup Monte Carlo transport, it is demonstrated that event-based algorithms significantly outperform a history-based approach for continuous-energy transport as a result of increased device occupancy and reduced thread divergence. Numerical results are presented for detailed full-core models of a small modular reactor (SMR), including a model containing depleted fuel materials. These results demonstrate the substantial gains in performance that are possible with the latest-generation of GPUs. On the depleted SMR core configuration, an NVIDIA P100 GPU with 56 streaming multiprocessors provides performance equivalent to 90 CPU cores, and the latest V100 GPU with 80 multiprocessors offers the performance of more than 150 CPU cores."
    ],
    "b_categories":[
      "astro-ph.HE"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.07540"
    ],
    "c_title":[
      "AI-Enabled Knowledge Sharing for Enhanced Collaboration and\n  Decision-Making in Non-Profit Healthcare Organizations: A Scoping Review\n  Protocol"
    ],
    "c_abstract":[
      "This protocol outlines a scoping review designed to systematically map the\nexisting body of evidence on AI-enabled knowledge sharing in resource-limited\nnon-profit healthcare organizations. The review aims to investigate how such\ntechnologies enhance collaboration and decision-making, particularly in the\ncontext of reduced external support following the cessation of USAID\noperations. Guided by three theoretical frameworks namely, the Resource-Based\nView, Dynamic Capabilities Theory, and Absorptive Capacity Theory, this study\nwill explore the dual role of AI as a strategic resource and an enabler of\norganizational learning and agility. The protocol details a rigorous\nmethodological approach based on PRISMA-ScR guidelines, encompassing a\nsystematic search strategy across multiple databases, inclusion and exclusion\ncriteria, and a structured data extraction process. By integrating theoretical\ninsights with empirical evidence, this scoping review seeks to identify\ncritical gaps in the literature and inform the design of effective,\nresource-optimized AI solutions in non-profit healthcare settings."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04682",
    "a_title":"DNN-based 3D Cloud Retrieval for Variable Solar Illumination and\n  Multiview Spaceborne Imaging",
    "a_abstract":"Climate studies often rely on remotely sensed images to retrieve\ntwo-dimensional maps of cloud properties. To advance volumetric analysis, we\nfocus on recovering the three-dimensional (3D) heterogeneous extinction\ncoefficient field of shallow clouds using multiview remote sensing data.\nClimate research requires large-scale worldwide statistics. To enable scalable\ndata processing, previous deep neural networks (DNNs) can infer at spaceborne\nremote sensing downlink rates. However, prior methods are limited to a fixed\nsolar illumination direction. In this work, we introduce the first scalable\nDNN-based system for 3D cloud retrieval that accommodates varying camera poses\nand solar directions. By integrating multiview cloud intensity images with\ncamera poses and solar direction data, we achieve greater flexibility in\nrecovery. Training of the DNN is performed by a novel two-stage scheme to\naddress the high number of degrees of freedom in this problem. Our approach\nshows substantial improvements over previous state-of-the-art, particularly in\nhandling variations in the sun's zenith angle.",
    "explanation":"Climate studies often rely on remotely sensed im-\nages to retrieve two-dimensional maps of cloud properties. To\nadvance volumetric analysis, we focus on recovering the three-\ndimensional (3D) heterogeneous extinction coefficient field of\nshallow clouds using multiview remote sensing data. \n\n\nTo enable\nscalable data processing, previous deep neural networks (DNNs)\ncan infer at spaceborne remote sensing downlink rates. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Distributed Sky Imaging Radiometry and Tomography"
    ],
    "b_abstract":[
      "The composition of the atmosphere is significant to our ecosystem. Accordingly, there a need sense distributions atmospheric scatterers such as aerosols and cloud droplets. There growing interest in recovering these scattering fields three-dimensions (3D). Even so, current observations usually use expensive unscalable equipment. Moreover, analysis retrieves partial information (e.g., cloud-base altitudes, water droplet size at tops) based on simplified 1D models. To advance retrievals, we develop new computational imaging approach for sensing analyzing atmosphere, volumetrically. Our comprises ground-based network cameras. We deployed it conjunction with additional remote equipment, including Raman lidar sunphotometer, which provide initialization algorithms ground truth. camera scalable, low cost, enables 3D high spatial temporal resolution. describe how system calibrated absolute radiometric readouts light field. Consequently, recover volumetric field scatterers, using tomography. tomography process adapted relative prior art, run large-scale domains being in-situ within scatterer fields. empirically demonstrate feasibility clouds, data."
    ],
    "b_categories":[
      "astro-ph.EP"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.02330"
    ],
    "c_title":[
      "Exploring Simple Siamese Network for High-Resolution Video Quality\n  Assessment"
    ],
    "c_abstract":[
      "In the research of video quality assessment (VQA), two-branch network has\nemerged as a promising solution. It decouples VQA with separate technical and\naesthetic branches to measure the perception of low-level distortions and\nhigh-level semantics respectively. However, we argue that while technical and\naesthetic perspectives are complementary, the technical perspective itself\nshould be measured in semantic-aware manner. We hypothesize that existing\ntechnical branch struggles to perceive the semantics of high-resolution videos,\nas it is trained on local mini-patches sampled from videos. This issue can be\nhidden by apparently good results on low-resolution videos, but indeed becomes\ncritical for high-resolution VQA. This work introduces SiamVQA, a simple but\neffective Siamese network for highre-solution VQA. SiamVQA shares weights\nbetween technical and aesthetic branches, enhancing the semantic perception\nability of technical branch to facilitate technical-quality representation\nlearning. Furthermore, it integrates a dual cross-attention layer for fusing\ntechnical and aesthetic features. SiamVQA achieves state-of-the-art accuracy on\nhigh-resolution benchmarks, and competitive results on lower-resolution\nbenchmarks. Codes will be available at: https:\/\/github.com\/srcn-ivl\/SiamVQA"
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04682",
    "a_title":"DNN-based 3D Cloud Retrieval for Variable Solar Illumination and\n  Multiview Spaceborne Imaging",
    "a_abstract":"Climate studies often rely on remotely sensed images to retrieve\ntwo-dimensional maps of cloud properties. To advance volumetric analysis, we\nfocus on recovering the three-dimensional (3D) heterogeneous extinction\ncoefficient field of shallow clouds using multiview remote sensing data.\nClimate research requires large-scale worldwide statistics. To enable scalable\ndata processing, previous deep neural networks (DNNs) can infer at spaceborne\nremote sensing downlink rates. However, prior methods are limited to a fixed\nsolar illumination direction. In this work, we introduce the first scalable\nDNN-based system for 3D cloud retrieval that accommodates varying camera poses\nand solar directions. By integrating multiview cloud intensity images with\ncamera poses and solar direction data, we achieve greater flexibility in\nrecovery. Training of the DNN is performed by a novel two-stage scheme to\naddress the high number of degrees of freedom in this problem. Our approach\nshows substantial improvements over previous state-of-the-art, particularly in\nhandling variations in the sun's zenith angle.",
    "explanation":"Climate studies often rely on remotely sensed im-\nages to retrieve two-dimensional maps of cloud properties. To\nadvance volumetric analysis, we focus on recovering the three-\ndimensional (3D) heterogeneous extinction coefficient field of\nshallow clouds using multiview remote sensing data. \n\n\nTo enable\nscalable data processing, previous deep neural networks (DNNs)\ncan infer at spaceborne remote sensing downlink rates. ",
    "b_id":[
      "b8"
    ],
    "b_title":[
      "Variable Imaging Projection Cloud Scattering Tomography"
    ],
    "b_abstract":[
      "Scattering-based computed tomography (CT) recovers a heterogeneous volumetric scattering medium using images taken from multiple directions. It is nonlinear problem. Prior art mainly approached it by explicit physics-based optimization of image-fitting, being slow and difficult to scale. Scale particularly important when the objects constitute large cloud fields, where recovery for climate studies. Besides speed, imaging need be flexible, efficiently handle variable viewing geometries resolutions. These can caused perturbation in camera poses or fusion data different types observational sensors. There fast projection clouds (VIP-CT). We develop learning-based solution, deep-neural network (DNN) which trains on labeled dataset. The DNN parameters are oblivious domain scale, hence work with arbitrarily domains. VIP-CT offers much better quality than state art. inference speed flexibility make effectively real-time context spaceborne observations. paper first demonstrate CT real empirical directly DNN. may offer model solution problems other scientific Our code available online."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.13332"
    ],
    "c_title":[
      "Solar System objects observed with TESS -- Early Data Release 2: I.\n  Spin-shape recovery potential of multi-epoch TESS observations"
    ],
    "c_abstract":[
      "Using multidirectional measurements from the Transiting Exoplanet Survey\nSatellite (TESS), we investigated the viability of determining the approximate\nshape and spin axis orientations for 44 selected main belt asteroids, using\nlight curve inversion, assuming Lommel-Seeliger ellipsoids. This study aims to\ninvestigate the applicability of low-degree-of-freedom shape models in those\ncases when rotation periods can be accurately determined, but light curves are\nonly available in a limited number of geometries or orbital phases. Our results\nare compared with the shape and spin axis solutions obtained for the same set\nof asteroids by more complex light curve inversion methods using mainly\nground-based measurements, available via the Database of Asteroid Models from\nInversion Techniques (DAMIT).The best-fit spin-axis orientations show a\nmoderately good match with the DAMIT solutions; however, a better agreement is\nreached with triaxial ellipsoid solution obtained from other large, independent\nsurveys. This suggests that while TESS-only data works well for finding\nrotation periods, it has its limitations when determining asteroid shape and\nspin-axis orientation. We discuss the challenges and potential applications of\nthis approach for studying large number of asteroids observed by TESS."
    ],
    "c_categories":[
      [
        "astro-ph.EP"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03156",
    "a_title":"Unleashing the power of novel conditional generative approaches for new\n  materials discovery",
    "a_abstract":"For a very long time, computational approaches to the design of new materials\nhave relied on an iterative process of finding a candidate material and\nmodeling its properties. AI has played a crucial role in this regard, helping\nto accelerate the discovery and optimization of crystal properties and\nstructures through advanced computational methodologies and data-driven\napproaches. To address the problem of new materials design and fasten the\nprocess of new materials search, we have applied latest generative approaches\nto the problem of crystal structure design, trying to solve the inverse\nproblem: by given properties generate a structure that satisfies them without\nutilizing supercomputer powers. In our work we propose two approaches: 1)\nconditional structure modification: optimization of the stability of an\narbitrary atomic configuration, using the energy difference between the most\nenergetically favorable structure and all its less stable polymorphs and 2)\nconditional structure generation. We used a representation for materials that\nincludes the following information: lattice, atom coordinates, atom types,\nchemical features, space group and formation energy of the structure. The loss\nfunction was optimized to take into account the periodic boundary conditions of\ncrystal structures. We have applied Diffusion models approach, Flow matching,\nusual Autoencoder (AE) and compared the results of the models and approaches.\nAs a metric for the study, physical PyMatGen matcher was employed: we compare\ntarget structure with generated one using default tolerances. So far, our\nmodifier and generator produce structures with needed properties with accuracy\n41% and 82% respectively. To prove the offered methodology efficiency,\ninference have been carried out, resulting in several potentially new\nstructures with formation energy below the AFLOW-derived convex hulls.",
    "explanation":"\" In our work we propose two approaches: 1) conditional structure modification: optimization of the stability of an arbitrary atomic configuration, using the energy difference between the most energetically favorable structure and all its less stable polymorphs and 2) conditional structure generation.\"",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Physics guided deep learning for generative design of crystal materials with symmetry constraints"
    ],
    "b_abstract":[
      "Abstract Discovering new materials is a challenging task in science crucial to the progress of human society. Conventional approaches based on experiments and simulations are labor-intensive or costly with success heavily depending experts\u2019 heuristic knowledge. Here, we propose deep learning Physics Guided Crystal Generative Model (PGCGM) for efficient crystal material design high structural diversity symmetry. Our model increases generation validity by more than 700% compared FTCP, one latest structure generators 45% our previous CubicGAN model. Density Functional Theory (DFT) calculations used validate generated structures 1869 out 2000 successfully optimized deposited into Carolina Materials Database www.carolinamatdb.org , which 39.6% have negative formation energy 5.3% energy-above-hull less 0.25 eV\/atom, indicating their thermodynamic stability potential synthesizability."
    ],
    "b_categories":[
      "physics.comp-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.00594"
    ],
    "c_title":[
      "Estimation of total body fat using symbolic regression and evolutionary\n  algorithms"
    ],
    "c_abstract":[
      "Body fat percentage is an increasingly popular alternative to Body Mass Index\nto measure overweight and obesity, offering a more accurate representation of\nbody composition. In this work, we evaluate three evolutionary computation\ntechniques, Grammatical Evolution, Context-Free Grammar Genetic Programming,\nand Dynamic Structured Grammatical Evolution, to derive an interpretable\nmathematical expression to estimate the percentage of body fat that are also\naccurate. Our primary objective is to obtain a model that balances accuracy\nwith explainability, making it useful for clinical and health applications. We\ncompare the performance of the three variants on a public anthropometric\ndataset and compare the results obtained with the QLattice framework.\nExperimental results show that grammatical evolution techniques can obtain\ncompetitive results in performance and interpretability."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.03156",
    "a_title":"Unleashing the power of novel conditional generative approaches for new\n  materials discovery",
    "a_abstract":"For a very long time, computational approaches to the design of new materials\nhave relied on an iterative process of finding a candidate material and\nmodeling its properties. AI has played a crucial role in this regard, helping\nto accelerate the discovery and optimization of crystal properties and\nstructures through advanced computational methodologies and data-driven\napproaches. To address the problem of new materials design and fasten the\nprocess of new materials search, we have applied latest generative approaches\nto the problem of crystal structure design, trying to solve the inverse\nproblem: by given properties generate a structure that satisfies them without\nutilizing supercomputer powers. In our work we propose two approaches: 1)\nconditional structure modification: optimization of the stability of an\narbitrary atomic configuration, using the energy difference between the most\nenergetically favorable structure and all its less stable polymorphs and 2)\nconditional structure generation. We used a representation for materials that\nincludes the following information: lattice, atom coordinates, atom types,\nchemical features, space group and formation energy of the structure. The loss\nfunction was optimized to take into account the periodic boundary conditions of\ncrystal structures. We have applied Diffusion models approach, Flow matching,\nusual Autoencoder (AE) and compared the results of the models and approaches.\nAs a metric for the study, physical PyMatGen matcher was employed: we compare\ntarget structure with generated one using default tolerances. So far, our\nmodifier and generator produce structures with needed properties with accuracy\n41% and 82% respectively. To prove the offered methodology efficiency,\ninference have been carried out, resulting in several potentially new\nstructures with formation energy below the AFLOW-derived convex hulls.",
    "explanation":"\" In our work we propose two approaches: 1) conditional structure modification: optimization of the stability of an arbitrary atomic configuration, using the energy difference between the most energetically favorable structure and all its less stable polymorphs and 2) conditional structure generation.\"",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "High\u2010Throughput Discovery of Novel Cubic Crystal Materials Using Deep Generative Neural Networks"
    ],
    "b_abstract":[
      "Abstract High\u2010throughput screening has become one of the major strategies for discovery novel functional materials. However, its effectiveness is severely limited by lack sufficient and diverse materials in current repositories such as open quantum database (OQMD). Recent progress deep learning have enabled generative that learn implicit chemical rules creating hypothetical with new compositions structures. models difficulty generating structurally diverse, chemically valid, stable Here we propose CubicGAN, a adversarial network (GAN) based neural model large scale design cubic When trained on 375 749 ternary from OQMD database, authors show able to not only rediscover most currently known but also generate structure prototypes. A total 506 been verified phonon dispersion calculation. Considering importance wide applications solar panels, GAN provides promising approach significantly expand existing repositories, enabling via screening. The crystal structures discovered are freely accessible at www.carolinamatdb.org ."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.06578"
    ],
    "c_title":[
      "Generalized exchange cluster algorithm to compute efficiently\n  covariances and susceptibilities in Monte Carlo"
    ],
    "c_abstract":[
      "We present a Monte Carlo method to compute efficiently susceptibilites or\ncovariances of two physical variables. The method relies on a generalization of\nthe exchange cluster algorithm to any model of interacting particles with any\n$2$-body interactions. The principle is to select clusters of variables\nbelonging to two independent replicas of the system. An improved estimator of\nthe covariance of two physical variables (in one replica) is then proposed.\nThis estimator has the zero-variance property in the limit wh ere these\nvariables are independent.In practice the scaling of the statistical\nfluctuations as a function of the number of degrees of freedom $N$ is reduced\nfrom $O(N ^2)$ to $O(N)$. This lower scaling is illustrated on a Lennard Jones\nmodel."
    ],
    "c_categories":[
      [
        "physics.comp-ph"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05055",
    "a_title":"Integrating Large Language Models for Genetic Variant Classification",
    "a_abstract":"The classification of genetic variants, particularly Variants of Uncertain\nSignificance (VUS), poses a significant challenge in clinical genetics and\nprecision medicine. Large Language Models (LLMs) have emerged as transformative\ntools in this realm. These models can uncover intricate patterns and predictive\ninsights that traditional methods might miss, thus enhancing the predictive\naccuracy of genetic variant pathogenicity.\n  This study investigates the integration of state-of-the-art LLMs, including\nGPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for\nvariant classification. Our approach evaluates these integrated models using\nthe well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in\nclassification performance. The models were rigorously tested on a set of\nchallenging variants, demonstrating substantial improvements over existing\nstate-of-the-art tools, especially in handling ambiguous and clinically\nuncertain variants.\n  The results of this research underline the efficacy of combining multiple\nmodeling approaches to significantly refine the accuracy and reliability of\ngenetic variant classification systems. These findings support the deployment\nof these advanced computational models in clinical environments, where they can\nsignificantly enhance the diagnostic processes for genetic disorders,\nultimately pushing the boundaries of personalized medicine by offering more\ndetailed and actionable genetic insights.",
    "explanation":"This study investigates the integration of state-of-the-art LLMs,\nincluding GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for variant classification.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems"
    ],
    "b_abstract":[
      "TensorFlow is an interface for expressing machine learning algorithms, and implementation executing such algorithms. A computation expressed using can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices as phones tablets up to large-scale distributed systems hundreds machines thousands computational GPU cards. The system flexible used express including training inference algorithms deep neural network models, it has been conducting research deploying into production across more than dozen areas computer science other fields, speech recognition, vision, robotics, information retrieval, natural language processing, geographic extraction, drug discovery. This paper describes the that we have built at Google. API reference were released open-source package under Apache 2.0 license in November, 2015 are available www.tensorflow.org."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.08363"
    ],
    "c_title":[
      "TopoLa: A Universal Framework to Enhance Cell Representations for\n  Single-cell and Spatial Omics through Topology-encoded Latent Hyperbolic\n  Geometry"
    ],
    "c_abstract":[
      "Recent advances in cellular research demonstrate that scRNA-seq characterizes\ncellular heterogeneity, while spatial transcriptomics reveals the spatial\ndistribution of gene expression. Cell representation is the fundamental issue\nin the two fields. Here, we propose Topology-encoded Latent Hyperbolic Geometry\n(TopoLa), a computational framework enhancing cell representations by capturing\nfine-grained intercellular topological relationships. The framework introduces\na new metric, TopoLa distance (TLd), which quantifies the geometric distance\nbetween cells within latent hyperbolic space, capturing the network's\ntopological structure more effectively. With this framework, the cell\nrepresentation can be enhanced considerably by performing convolution on its\nneighboring cells. Performance evaluation across seven biological tasks,\nincluding scRNA-seq data clustering and spatial transcriptomics domain\nidentification, shows that TopoLa significantly improves the performance of\nseveral state-of-the-art models. These results underscore the generalizability\nand robustness of TopoLa, establishing it as a valuable tool for advancing both\nbiological discovery and computational methodologies."
    ],
    "c_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05055",
    "a_title":"Integrating Large Language Models for Genetic Variant Classification",
    "a_abstract":"The classification of genetic variants, particularly Variants of Uncertain\nSignificance (VUS), poses a significant challenge in clinical genetics and\nprecision medicine. Large Language Models (LLMs) have emerged as transformative\ntools in this realm. These models can uncover intricate patterns and predictive\ninsights that traditional methods might miss, thus enhancing the predictive\naccuracy of genetic variant pathogenicity.\n  This study investigates the integration of state-of-the-art LLMs, including\nGPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for\nvariant classification. Our approach evaluates these integrated models using\nthe well-annotated ProteinGym and ClinVar datasets, setting new benchmarks in\nclassification performance. The models were rigorously tested on a set of\nchallenging variants, demonstrating substantial improvements over existing\nstate-of-the-art tools, especially in handling ambiguous and clinically\nuncertain variants.\n  The results of this research underline the efficacy of combining multiple\nmodeling approaches to significantly refine the accuracy and reliability of\ngenetic variant classification systems. These findings support the deployment\nof these advanced computational models in clinical environments, where they can\nsignificantly enhance the diagnostic processes for genetic disorders,\nultimately pushing the boundaries of personalized medicine by offering more\ndetailed and actionable genetic insights.",
    "explanation":"This study investigates the integration of state-of-the-art LLMs,\nincluding GPN-MSA, ESM1b, and AlphaMissense, which leverage DNA and protein sequence data\nalongside structural insights to form a comprehensive analytical framework for variant classification.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Predicting Functional Effect of Human Missense Mutations Using PolyPhen\u20102"
    ],
    "b_abstract":[
      "Abstract PolyPhen\u20102 (Polymorphism Phenotyping v2), available as software and via a Web server, predicts the possible impact of amino acid substitutions on stability function human proteins using structural comparative evolutionary considerations. It performs functional annotation single\u2010nucleotide polymorphisms (SNPs), maps coding SNPs to gene transcripts, extracts protein sequence annotations attributes, builds conservation profiles. then estimates probability missense mutation being damaging based combination all these properties. features include high\u2010quality multiple alignment pipeline prediction method employing machine\u2010learning classification. The also integrates UCSC Genome Browser's genome MultiZ alignments vertebrate genomes with genome. is capable analyzing large volumes data produced by next\u2010generation sequencing projects, thanks built\u2010in support for high\u2010performance computing environments like Grid Engine Platform LSF. Curr. Protoc. Hum. Genet . 76:7.20.1\u20107.20.41. \u00a9 2013 John Wiley &amp; Sons, Inc."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.04506"
    ],
    "c_title":[
      "When One LLM Drools, Multi-LLM Collaboration Rules"
    ],
    "c_abstract":[
      "This position paper argues that in many realistic (i.e., complex,\ncontextualized, subjective) scenarios, one LLM is not enough to produce a\nreliable output. We challenge the status quo of relying solely on a single\ngeneral-purpose LLM and argue for multi-LLM collaboration to better represent\nthe extensive diversity of data, skills, and people. We first posit that a\nsingle LLM underrepresents real-world data distributions, heterogeneous skills,\nand pluralistic populations, and that such representation gaps cannot be\ntrivially patched by further training a single LLM. We then organize existing\nmulti-LLM collaboration methods into a hierarchy, based on the level of access\nand information exchange, ranging from API-level, text-level, logit-level, to\nweight-level collaboration. Based on these methods, we highlight how multi-LLM\ncollaboration addresses challenges that a single LLM struggles with, such as\nreliability, democratization, and pluralism. Finally, we identify the\nlimitations of existing multi-LLM methods and motivate future work. We envision\nmulti-LLM collaboration as an essential path toward compositional intelligence\nand collaborative AI development."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.18156",
    "a_title":"scReader: Prompting Large Language Models to Interpret scRNA-seq Data",
    "a_abstract":"Large language models (LLMs) have demonstrated remarkable advancements,\nprimarily due to their capabilities in modeling the hidden relationships within\ntext sequences. This innovation presents a unique opportunity in the field of\nlife sciences, where vast collections of single-cell omics data from multiple\nspecies provide a foundation for training foundational models. However, the\nchallenge lies in the disparity of data scales across different species,\nhindering the development of a comprehensive model for interpreting genetic\ndata across diverse organisms. In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of LLMs with\ndomain-specific representation models for single-cell omics data\ninterpretation. We begin by focusing on genes as the fundamental unit of\nrepresentation. Gene representations are initialized using functional\ndescriptions, leveraging the strengths of mature language models such as\nLLaMA-2. By inputting single-cell gene-level expression data with prompts, we\neffectively model cellular representations based on the differential expression\nlevels of genes across various species and cell types. In the experiments, we\nconstructed developmental cells from humans and mice, specifically targeting\ncells that are challenging to annotate. We evaluated our methodology through\nbasic tasks such as cell annotation and visualization analysis. The results\ndemonstrate the efficacy of our approach compared to other methods using LLMs,\nhighlighting significant improvements in accuracy and interoperability. Our\nhybrid approach enhances the representation of single-cell data and offers a\nrobust framework for future research in cross-species genetic analysis.",
    "explanation":". In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of\nLLMs with domain-specific representation models for single-cell\nomics data interpretation.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Llamafactory: Unified efficient fine-tuning of 100+ language models"
    ],
    "b_abstract":[
      "Efficient fine-tuning is vital for adapting large language models (LLMs) to downstream tasks. However, it requires non-trivial efforts to implement these methods on different models. We present LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It provides a solution for flexibly customizing the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard. We empirically validate the efficiency and effectiveness of our framework on language modeling and text generation tasks."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.02284"
    ],
    "c_title":[
      "Origin of $\\alpha$-satellite repeat arrays from mitochondrial molecular\n  fossils -- sequential insertion, expansion, and evolution in the nuclear\n  genome"
    ],
    "c_abstract":[
      "Alpha satellite DNA is large tandem arrays of 150-400 bp units, and its\norigin remains an evolutionary mystery. In this research, we identified 1,545\nalpha-satellite-like (SatL) repeat units in the nuclear genome of jewel wasp\nNasonia vitripennis. Among them, thirty-nine copies of SatL were organized in\ntwo palindromic arrays in mitochondria, resulting in a 50% increase in the\ngenome size. Strikingly, genomic neighborhood analyses of 1,516 nuclear SatL\nrepeats revealed that they are located in NuMT (nuclear mitochondrial DNA)\nregions, and SatL phylogeny matched perfectly with mitochondrial genes and NuMT\npseudogenes. These results support that SatL arrays originated from ten\nindependent mitochondria insertion events into the nuclear genome within the\nlast 500,000 years, after divergence from its sister species N. giraulti.\nDramatic repeat GC-percent elevation (from 33.9% to 50.4%) is a hallmark of\nrapid SatL sequence evolution in mitochondria due to GC-biased gene conversion\nfacilitated by the palindromic sequence pairing of the two mitochondrial SatL\narrays. The nuclear SatL repeat arrays underwent substantial copy number\nexpansion, from 12-15 (SatL1) to over 400 copies (SatL4). The oldest SatL4B\narray consists of four types of repeat units derived from deletions in the\nAT-rich region of ancestral repeats, and complex high-order structures have\nevolved through duplications. We also discovered similar repeat insertions into\nthe nuclear genome of Muscidifurax, suggesting this mechanism can be common in\ninsects. This is the first report of the mitochondrial origin of nuclear\nsatellite sequences, and our findings shed new light on the origin and\nevolution of satellite DNA."
    ],
    "c_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.18156",
    "a_title":"scReader: Prompting Large Language Models to Interpret scRNA-seq Data",
    "a_abstract":"Large language models (LLMs) have demonstrated remarkable advancements,\nprimarily due to their capabilities in modeling the hidden relationships within\ntext sequences. This innovation presents a unique opportunity in the field of\nlife sciences, where vast collections of single-cell omics data from multiple\nspecies provide a foundation for training foundational models. However, the\nchallenge lies in the disparity of data scales across different species,\nhindering the development of a comprehensive model for interpreting genetic\ndata across diverse organisms. In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of LLMs with\ndomain-specific representation models for single-cell omics data\ninterpretation. We begin by focusing on genes as the fundamental unit of\nrepresentation. Gene representations are initialized using functional\ndescriptions, leveraging the strengths of mature language models such as\nLLaMA-2. By inputting single-cell gene-level expression data with prompts, we\neffectively model cellular representations based on the differential expression\nlevels of genes across various species and cell types. In the experiments, we\nconstructed developmental cells from humans and mice, specifically targeting\ncells that are challenging to annotate. We evaluated our methodology through\nbasic tasks such as cell annotation and visualization analysis. The results\ndemonstrate the efficacy of our approach compared to other methods using LLMs,\nhighlighting significant improvements in accuracy and interoperability. Our\nhybrid approach enhances the representation of single-cell data and offers a\nrobust framework for future research in cross-species genetic analysis.",
    "explanation":". In this study, we propose an innovative hybrid\napproach that integrates the general knowledge capabilities of\nLLMs with domain-specific representation models for single-cell\nomics data interpretation.",
    "b_id":[
      "b18"
    ],
    "b_title":[
      "GeneCompass: Deciphering Universal Gene Regulatory Mechanisms with Knowledge-Informed Cross-Species Foundation Model"
    ],
    "b_abstract":[
      "Abstract Deciphering the universal gene regulatory mechanisms in diverse organisms holds great potential to advance our knowledge of fundamental life process and facilitate research on clinical applications. However, traditional paradigm primarily focuses individual model organisms, resulting limited collection integration complex features various cell types across species. Recent breakthroughs single-cell sequencing advancements deep learning techniques present an unprecedented opportunity tackle this challenge. In study, we developed GeneCompass, first knowledge-informed, cross-species foundation pre-trained extensive dataset over 120 million transcriptomes from human mouse. During pre-training, GeneCompass effectively integrates four biological prior enhance understanding a self-supervised manner. Fine-tuning towards multiple downstream tasks, outperforms competing state-of-the-art models tasks single species unlocks new realms investigation. Overall, marks milestone advancing accelerating discovery key fate regulators candidate targets for drug development."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.12583"
    ],
    "c_title":[
      "LongFaith: Enhancing Long-Context Reasoning in LLMs with Faithful\n  Synthetic Data"
    ],
    "c_abstract":[
      "Despite the growing development of long-context large language models (LLMs),\ndata-centric approaches relying on synthetic data have been hindered by issues\nrelated to faithfulness, which limit their effectiveness in enhancing model\nperformance on tasks such as long-context reasoning and question answering\n(QA). These challenges are often exacerbated by misinformation caused by lack\nof verification, reasoning without attribution, and potential knowledge\nconflicts. We propose LongFaith, a novel pipeline for synthesizing faithful\nlong-context reasoning instruction datasets. By integrating ground truth and\ncitation-based reasoning prompts, we eliminate distractions and improve the\naccuracy of reasoning chains, thus mitigating the need for costly verification\nprocesses. We open-source two synthesized datasets, LongFaith-SFT and\nLongFaith-PO, which systematically address multiple dimensions of faithfulness,\nincluding verified reasoning, attribution, and contextual grounding. Extensive\nexperiments on multi-hop reasoning datasets and LongBench demonstrate that\nmodels fine-tuned on these datasets significantly improve performance. Our\nablation studies highlight the scalability and adaptability of the LongFaith\npipeline, showcasing its broad applicability in developing long-context LLMs."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.07871",
    "a_title":"Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in\n  Alzheimer's Disease",
    "a_abstract":"The rapid advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have shown great potential in medical diagnostics, particularly\nin radiology, where datasets such as X-rays are paired with human-generated\ndiagnostic reports. However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer's disease, due\nto the lack of comprehensive diagnostic reports that can be utilized for model\nfine-tuning. This paper addresses this gap by generating synthetic diagnostic\nreports using GPT-4o-mini on structured data from the OASIS-4 dataset, which\ncomprises 663 patients. Using the synthetic reports as ground truth for\ntraining and validation, we then generated neurological reports directly from\nthe images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.\nOur proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,\nand METEOR score of 0.4163, revealing its potential in generating clinically\nrelevant and accurate diagnostic reports.",
    "explanation":"However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer\u2019s\ndisease, due to the lack of comprehensive diagnostic reports that\ncan be utilized for model fine-tuning. This paper addresses this\ngap by generating synthetic diagnostic reports using GPT-4o-mini\non structured data from the OASIS-4 dataset, which comprises\n663 patients",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "2016 Alzheimer's disease facts and figures"
    ],
    "b_abstract":[
      "This report describes the public health impact of Alzheimer's disease, including incidence and prevalence, mortality rates, costs care, overall on caregivers society. It also examines in detail financial families, annual to families difficult decisions must often make pay those costs. An estimated 5.4 million Americans have disease. By mid-century, number people living with disease United States is projected grow 13.8 million, fueled large part by aging baby boom generation. Today, someone country develops every 66 seconds. 2050, one new case expected develop 33 seconds, resulting nearly 1 cases per year. In 2013, official death certificates recorded 84,767 deaths from making it sixth leading cause fifth age \u2265 65 years. Between 2000 stroke, heart prostate cancer decreased 23%, 14%, 11%, respectively, whereas increased 71%. The actual which contributes likely much larger than certificates. 2016, an 700,000 years will die many them because complications caused 2015, more 15 family members other unpaid provided 18.1 billion hours care dementias, a contribution valued at $221 billion. Average per-person Medicare payments for services beneficiaries dementias are two half times as great all without these conditions, Medicaid 19 great. Total 2016 long-term hospice dementia be $236 may place substantial burden who take money out their retirement savings, cut back buying food, reduce own trips doctor. addition, incorrectly believe that pays nursing home types care. Such findings highlight need solutions prevent dementia-related jeopardizing security dementias."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.15840"
    ],
    "c_title":[
      "Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents"
    ],
    "c_abstract":[
      "While Large Language Models (LLMs) can exhibit impressive proficiency in\nisolated, short-term tasks, they often fail to maintain coherent performance\nover longer time horizons. In this paper, we present Vending-Bench, a simulated\nenvironment designed to specifically test an LLM-based agent's ability to\nmanage a straightforward, long-running business scenario: operating a vending\nmachine. Agents must balance inventories, place orders, set prices, and handle\ndaily fees - tasks that are each simple but collectively, over long horizons\n(>20M tokens per run) stress an LLM's capacity for sustained, coherent\ndecision-making. Our experiments reveal high variance in performance across\nmultiple LLMs: Claude 3.5 Sonnet and o3-mini manage the machine well in most\nruns and turn a profit, but all models have runs that derail, either through\nmisinterpreting delivery schedules, forgetting orders, or descending into\ntangential \"meltdown\" loops from which they rarely recover. We find no clear\ncorrelation between failures and the point at which the model's context window\nbecomes full, suggesting that these breakdowns do not stem from memory limits.\nApart from highlighting the high variance in performance over long time\nhorizons, Vending-Bench also tests models' ability to acquire capital, a\nnecessity in many hypothetical dangerous AI scenarios. We hope the benchmark\ncan help in preparing for the advent of stronger AI systems."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.07871",
    "a_title":"Leveraging Multimodal Models for Enhanced Neuroimaging Diagnostics in\n  Alzheimer's Disease",
    "a_abstract":"The rapid advancements in Large Language Models (LLMs) and Vision-Language\nModels (VLMs) have shown great potential in medical diagnostics, particularly\nin radiology, where datasets such as X-rays are paired with human-generated\ndiagnostic reports. However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer's disease, due\nto the lack of comprehensive diagnostic reports that can be utilized for model\nfine-tuning. This paper addresses this gap by generating synthetic diagnostic\nreports using GPT-4o-mini on structured data from the OASIS-4 dataset, which\ncomprises 663 patients. Using the synthetic reports as ground truth for\ntraining and validation, we then generated neurological reports directly from\nthe images in the dataset leveraging the pre-trained BiomedCLIP and T5 models.\nOur proposed method achieved a BLEU-4 score of 0.1827, ROUGE-L score of 0.3719,\nand METEOR score of 0.4163, revealing its potential in generating clinically\nrelevant and accurate diagnostic reports.",
    "explanation":"However, a significant research gap exists in the\nneuroimaging field, especially for conditions such as Alzheimer\u2019s\ndisease, due to the lack of comprehensive diagnostic reports that\ncan be utilized for model fine-tuning. This paper addresses this\ngap by generating synthetic diagnostic reports using GPT-4o-mini\non structured data from the OASIS-4 dataset, which comprises\n663 patients",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "Computer-aided diagnosis of Alzheimer\u2019s disease and neurocognitive disorders with multimodal Bi-Vision Transformer (BiViT)"
    ],
    "b_abstract":[
      "<jats:title>Abstract<\/jats:title><jats:p>Cognitive disorders affect various cognitive functions that can have a substantial impact on individual\u2019s daily life. Alzheimer\u2019s disease (AD) is one of such well-known cognitive disorders. Early detection and treatment of cognitive diseases using artificial intelligence can help contain them. However, the complex spatial relationships and long-range dependencies found in medical imaging data present challenges in achieving the objective. Moreover, for a few years, the application of transformers in imaging has emerged as a promising area of research. A reason can be transformer\u2019s impressive capabilities of tackling spatial relationships and long-range dependency challenges in two ways, i.e., (1) using their self-attention mechanism to generate comprehensive features, and (2) capture complex patterns by incorporating global context and long-range dependencies. In this work, a Bi-Vision Transformer (BiViT) architecture is proposed for classifying different stages of AD, and multiple types of cognitive disorders from 2-dimensional MRI imaging data. More specifically, the transformer is composed of two novel modules, namely Mutual Latent Fusion (MLF) and Parallel Coupled Encoding Strategy (PCES), for effective feature learning. Two different datasets have been used to evaluate the performance of proposed BiViT-based architecture. The first dataset contain several classes such as mild or moderate demented stages of the AD. The other dataset is composed of samples from patients with AD and different cognitive disorders such as mild, early, or moderate impairments. For comprehensive comparison, a multiple transfer learning algorithm and a deep autoencoder have been each trained on both datasets. The results show that the proposed BiViT-based model achieves an accuracy of 96.38% on the AD dataset. However, when applied to cognitive disease data, the accuracy slightly decreases below 96% which can be resulted due to smaller amount of data and imbalance in data distribution. Nevertheless, given the results, it can be hypothesized that the proposed algorithm can perform better if the imbalanced distribution and limited availability problems in data can be addressed.<\/jats:p>\n                <jats:p><jats:bold>Graphical abstract<\/jats:bold><\/jats:p>"
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.21217"
    ],
    "c_title":[
      "Dynamic Markov Blanket Detection for Macroscopic Physics Discovery"
    ],
    "c_abstract":[
      "The free energy principle (FEP), along with the associated constructs of\nMarkov blankets and ontological potentials, have recently been presented as the\ncore components of a generalized modeling method capable of mathematically\ndescribing arbitrary objects that persist in random dynamical systems; that is,\na mathematical theory of ``every'' ``thing''. Here, we leverage the FEP to\ndevelop a mathematical physics approach to the identification of objects,\nobject types, and the macroscopic, object-type-specific rules that govern their\nbehavior. We take a generative modeling approach and use variational Bayesian\nexpectation maximization to develop a dynamic Markov blanket detection\nalgorithm that is capable of identifying and classifying macroscopic objects,\ngiven partial observation of microscopic dynamics. This unsupervised algorithm\nuses Bayesian attention to explicitly label observable microscopic elements\naccording to their current role in a given system, as either the internal or\nboundary elements of a given macroscopic object; and it identifies macroscopic\nphysical laws that govern how the object interacts with its environment.\nBecause these labels are dynamic or evolve over time, the algorithm is capable\nof identifying complex objects that travel through fixed media or exchange\nmatter with their environment. This approach leads directly to a flexible class\nof structured, unsupervised algorithms that sensibly partition complex\nmany-particle or many-component systems into collections of interacting\nmacroscopic subsystems, namely, ``objects'' or ``things''. We derive a few\nexamples of this kind of macroscopic physics discovery algorithm and\ndemonstrate its utility with simple numerical experiments, in which the\nalgorithm correctly labels the components of Newton's cradle, a burning fuse,\nthe Lorenz attractor, and a simulated cell."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.08073",
    "a_title":"LoRA-BERT: a Natural Language Processing Model for Robust and Accurate\n  Prediction of long non-coding RNAs",
    "a_abstract":"Long non-coding RNAs (lncRNAs) serve as crucial regulators in numerous\nbiological processes. Although they share sequence similarities with messenger\nRNAs (mRNAs), lncRNAs perform entirely different roles, providing new avenues\nfor biological research. The emergence of next-generation sequencing\ntechnologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify\nlong non-coding RNAs (lncRNAs). These advanced methods have significantly\nenhanced the efficiency of identifying lncRNAs. However, many of these methods\nare devoid of robustness and accuracy due to the extended length of the\nsequences involved. To tackle this issue, we have introduced a novel\npre-trained bidirectional encoder representation called LoRA-BERT. LoRA-BERT is\ndesigned to capture the importance of nucleotide-level information during\nsequence classification, leading to more robust and satisfactory outcomes. In a\ncomprehensive comparison with commonly used sequence prediction tools, we have\ndemonstrated that LoRA-BERT outperforms them in terms of accuracy and\nefficiency. Our results indicate that, when utilizing the transformer model,\nLoRA-BERT achieves state-of-the-art performance in predicting both lncRNAs and\nmRNAs for human and mouse species. Through the utilization of LoRA-BERT, we\nacquire valuable insights into the traits of lncRNAs and mRNAs, offering the\npotential to aid in the comprehension and detection of diseases linked to\nlncRNAs in humans.",
    "explanation":"The emergence of next-\ngeneration sequencing technologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify long non-coding\nRNAs (lncRNAs). ",
    "b_id":[
      "b24"
    ],
    "b_title":[
      "DNABERT: pre-trained Bidirectional Encoder Representations from Transformers model for DNA-language in genome"
    ],
    "b_abstract":[
      "Abstract Motivation Deciphering the language of non-coding DNA is one fundamental problems in genome research. Gene regulatory code highly complex due to existence polysemy and distant semantic relationship, which previous informatics methods often fail capture especially data-scarce scenarios. Results To address this challenge, we developed a novel pre-trained bidirectional encoder representation, named DNABERT, global transferrable understanding genomic sequences based on up downstream nucleotide contexts. We compared DNABERT most widely used programs for genome-wide elements prediction demonstrate its ease use, accuracy efficiency. show that single transformers model can simultaneously achieve state-of-the-art performance promoters, splice sites transcription factor binding sites, after easy fine-tuning using small task-specific labeled data. Further, enables direct visualization nucleotide-level importance relationship within input better interpretability accurate identification conserved sequence motifs functional genetic variant candidates. Finally, with human even be readily applied other organisms exceptional performance. anticipate fined tuned many analyses tasks. Availability implementation The source code, pretrained finetuned are available at GitHub (https:\/\/github.com\/jerryji1993\/DNABERT). Supplementary information data Bioinformatics online."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.17418"
    ],
    "c_title":[
      "Application of Single-cell Deep Learning in Elucidating the Mapping\n  Relationship Between Visceral and Body Surface Inflammatory Patterns"
    ],
    "c_abstract":[
      "As a system of integrated homeostasis, life is susceptible to disruptions by\nvisceral inflammation, which can disturb internal environment equilibrium. The\nrole of body-spread subcutaneous fascia (scFascia) in this process is poorly\nunderstood. In the rat model of Salmonella-induced dysentery, scRNA-seq of\nscFascia and deep-learning analysis revealed Warburg-like metabolic\nreprogramming in macrophages (MPs) with reduced citrate cycle activity.\nCd34+\/Pdgfra+ telocytes (CPTCs) regulated MPs differentiation and proliferation\nvia Wnt\/Fgf signal, suggesting a pathological crosstalk pattern in the\nscFascia, herein termed the fascia-visceral inflammatory crosstalk pattern\n(FVICP). PySCENIC analysis indicated increased activity transcription factors\nFosl1, Nfkb2, and Atf4, modulated by CPTCs signaling to MPs, downregulating\naerobic respiration and upregulating cell cycle, DNA replication, and\ntranscription. This study highlights scFascia's role in immunomodulation and\nmetabolic reprogramming during visceral inflammation, underscoring its function\nin systemic homeostasis."
    ],
    "c_categories":[
      [
        "q-bio.GN"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.08073",
    "a_title":"LoRA-BERT: a Natural Language Processing Model for Robust and Accurate\n  Prediction of long non-coding RNAs",
    "a_abstract":"Long non-coding RNAs (lncRNAs) serve as crucial regulators in numerous\nbiological processes. Although they share sequence similarities with messenger\nRNAs (mRNAs), lncRNAs perform entirely different roles, providing new avenues\nfor biological research. The emergence of next-generation sequencing\ntechnologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify\nlong non-coding RNAs (lncRNAs). These advanced methods have significantly\nenhanced the efficiency of identifying lncRNAs. However, many of these methods\nare devoid of robustness and accuracy due to the extended length of the\nsequences involved. To tackle this issue, we have introduced a novel\npre-trained bidirectional encoder representation called LoRA-BERT. LoRA-BERT is\ndesigned to capture the importance of nucleotide-level information during\nsequence classification, leading to more robust and satisfactory outcomes. In a\ncomprehensive comparison with commonly used sequence prediction tools, we have\ndemonstrated that LoRA-BERT outperforms them in terms of accuracy and\nefficiency. Our results indicate that, when utilizing the transformer model,\nLoRA-BERT achieves state-of-the-art performance in predicting both lncRNAs and\nmRNAs for human and mouse species. Through the utilization of LoRA-BERT, we\nacquire valuable insights into the traits of lncRNAs and mRNAs, offering the\npotential to aid in the comprehension and detection of diseases linked to\nlncRNAs in humans.",
    "explanation":"The emergence of next-\ngeneration sequencing technologies has greatly advanced the detection and identification of lncRNA\ntranscripts and deep learning-based approaches have been introduced to classify long non-coding\nRNAs (lncRNAs). ",
    "b_id":[
      "b20"
    ],
    "b_title":[
      "A primer on deep learning in genomics"
    ],
    "b_abstract":[
      "Deep learning methods are a class of machine learning techniques capable of identifying highly complex patterns in large datasets. Here, we provide a perspective and primer on deep learning applications for genome analysis. We discuss successful applications in the fields of regulatory genomics, variant calling and pathogenicity scores. We include general guidance for how to effectively use deep learning methods as well as a practical guide to tools and resources. This primer is accompanied by an interactive online tutorial."
    ],
    "b_categories":[
      "q-bio.GN"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.15840"
    ],
    "c_title":[
      "Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents"
    ],
    "c_abstract":[
      "While Large Language Models (LLMs) can exhibit impressive proficiency in\nisolated, short-term tasks, they often fail to maintain coherent performance\nover longer time horizons. In this paper, we present Vending-Bench, a simulated\nenvironment designed to specifically test an LLM-based agent's ability to\nmanage a straightforward, long-running business scenario: operating a vending\nmachine. Agents must balance inventories, place orders, set prices, and handle\ndaily fees - tasks that are each simple but collectively, over long horizons\n(>20M tokens per run) stress an LLM's capacity for sustained, coherent\ndecision-making. Our experiments reveal high variance in performance across\nmultiple LLMs: Claude 3.5 Sonnet and o3-mini manage the machine well in most\nruns and turn a profit, but all models have runs that derail, either through\nmisinterpreting delivery schedules, forgetting orders, or descending into\ntangential \"meltdown\" loops from which they rarely recover. We find no clear\ncorrelation between failures and the point at which the model's context window\nbecomes full, suggesting that these breakdowns do not stem from memory limits.\nApart from highlighting the high variance in performance over long time\nhorizons, Vending-Bench also tests models' ability to acquire capital, a\nnecessity in many hypothetical dangerous AI scenarios. We hope the benchmark\ncan help in preparing for the advent of stronger AI systems."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.15211",
    "a_title":"LightLLM: A Versatile Large Language Model for Predictive Light Sensing",
    "a_abstract":"We propose LightLLM, a model that fine tunes pre-trained large language\nmodels (LLMs) for light-based sensing tasks. It integrates a sensor data\nencoder to extract key features, a contextual prompt to provide environmental\ninformation, and a fusion layer to combine these inputs into a unified\nrepresentation. This combined input is then processed by the pre-trained LLM,\nwhich remains frozen while being fine-tuned through the addition of\nlightweight, trainable components, allowing the model to adapt to new tasks\nwithout altering its original parameters. This approach enables flexible\nadaptation of LLM to specialized light sensing tasks with minimal computational\noverhead and retraining effort. We have implemented LightLLM for three light\nsensing tasks: light-based localization, outdoor solar forecasting, and indoor\nsolar estimation. Using real-world experimental datasets, we demonstrate that\nLightLLM significantly outperforms state-of-the-art methods, achieving 4.4x\nimprovement in localization accuracy and 3.4x improvement in indoor solar\nestimation when tested in previously unseen environments. We further\ndemonstrate that LightLLM outperforms ChatGPT-4 with direct prompting,\nhighlighting the advantages of LightLLM's specialized architecture for sensor\ndata fusion with textual prompts.",
    "explanation":"We propose LightLLM, a model that fine tunes pre-trained\nlarge language models (LLMs) for light-based sensing tasks.",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Solar Cells for Indoor Applications: Progress and Development"
    ],
    "b_abstract":[
      "The Internet of things (IoT) has been rapidly growing in the past few years. IoT connects numerous devices, such as wireless sensors, actuators, and wearable to optimize monitor daily activities. Most these devices require power microwatt range operate indoors. To this end, a self-sustainable source, photovoltaic (PV) cell, which can harvest low-intensity indoor light, is appropriate. Recently, development highly efficient PV cells for applications attracted tremendous attention. Therefore, different types materials, inorganic, dye-sensitized, organic, perovskite have employed harvesting light energy. Although considerable efforts made by researchers develop low-cost, stable, applications, Extensive investigation necessary resolve some critical issues concerning cells, environmental stability, lifetime, large-area fabrication, mechanical flexibility, production cost. address issues, systematic review aspects will be useful research community. This study discusses current status based on previous reports. First, we provided relevant background information. Then, described sources, subsequently critically reviewed reports regarding solar active materials perovskite. Finally, placed an attempt provide insight into factors needed further improve feasibility technology applications."
    ],
    "b_categories":[
      "astro-ph.SR"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.04530"
    ],
    "c_title":[
      "SOLAR: Scalable Optimization of Large-scale Architecture for Reasoning"
    ],
    "c_abstract":[
      "Large Language Models (LLMs) excel in reasoning but remain constrained by\ntheir Chain-of-Thought (CoT) approach, which struggles with complex tasks\nrequiring more nuanced topological reasoning. We introduce SOLAR, Scalable\nOptimization of Large-scale Architecture for Reasoning, a framework that\ndynamically optimizes various reasoning topologies to enhance accuracy and\nefficiency.\n  Our Topological Annotation Generation (TAG) system automates topological\ndataset creation and segmentation, improving post-training and evaluation.\nAdditionally, we propose Topological-Scaling, a reward-driven framework that\naligns training and inference scaling, equipping LLMs with adaptive, task-aware\nreasoning.\n  SOLAR achieves substantial gains on MATH and GSM8K: +5% accuracy with\nTopological Tuning, +9% with Topological Reward, and +10.02% with Hybrid\nScaling. It also reduces response length by over 5% for complex problems,\nlowering inference latency.\n  To foster the reward system, we train a multi-task Topological Reward Model\n(M-TRM), which autonomously selects the best reasoning topology and answer in a\nsingle pass, eliminating the need for training and inference on multiple\nsingle-task TRMs (S-TRMs), thus reducing both training cost and inference\nlatency. In addition, in terms of performance, M-TRM surpasses all S-TRMs,\nimproving accuracy by +10% and rank correlation by +9%.\n  To the best of our knowledge, SOLAR sets a new benchmark for scalable,\nhigh-precision LLM reasoning while introducing an automated annotation process\nand a dynamic reasoning topology competition mechanism."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.15211",
    "a_title":"LightLLM: A Versatile Large Language Model for Predictive Light Sensing",
    "a_abstract":"We propose LightLLM, a model that fine tunes pre-trained large language\nmodels (LLMs) for light-based sensing tasks. It integrates a sensor data\nencoder to extract key features, a contextual prompt to provide environmental\ninformation, and a fusion layer to combine these inputs into a unified\nrepresentation. This combined input is then processed by the pre-trained LLM,\nwhich remains frozen while being fine-tuned through the addition of\nlightweight, trainable components, allowing the model to adapt to new tasks\nwithout altering its original parameters. This approach enables flexible\nadaptation of LLM to specialized light sensing tasks with minimal computational\noverhead and retraining effort. We have implemented LightLLM for three light\nsensing tasks: light-based localization, outdoor solar forecasting, and indoor\nsolar estimation. Using real-world experimental datasets, we demonstrate that\nLightLLM significantly outperforms state-of-the-art methods, achieving 4.4x\nimprovement in localization accuracy and 3.4x improvement in indoor solar\nestimation when tested in previously unseen environments. We further\ndemonstrate that LightLLM outperforms ChatGPT-4 with direct prompting,\nhighlighting the advantages of LightLLM's specialized architecture for sensor\ndata fusion with textual prompts.",
    "explanation":"We propose LightLLM, a model that fine tunes pre-trained\nlarge language models (LLMs) for light-based sensing tasks.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
    ],
    "b_abstract":[
      "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent models, BERT is designed to pre-train deep bidirectional representations unlabeled text by jointly conditioning on both left and right context in all layers. As result, the pre-trained can be fine-tuned with just one additional output layer create state-of-the-art models wide range of tasks, such as question answering inference, without substantial task-specific architecture modifications. conceptually simple empirically powerful. It obtains results eleven natural processing including pushing GLUE score 80.5% (7.7% point absolute improvement), MultiNLI accuracy 86.7% (4.6% SQuAD v1.1 Test F1 93.2 (1.5 improvement) v2.0 83.1 (5.1 improvement)."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.02976"
    ],
    "c_title":[
      "Spectroscopic Diagnosis of a B-Class Flare and an Associated Filament\n  Eruption"
    ],
    "c_abstract":[
      "The flare ribbon and an associated filament eruption are diagnosed using O iv\n1401.16 A, Si iv 1402.77 A, and Mg ii k 2796.35 A spectral lines provided by\nIRIS. The flare ribbons have downflow (redshifts) in all these lines, and this\nredshift decreases from the transition region to the chromosphere. While the\noverlapping region (flare-ribbon+filament rise\/eruption is dominated by\nupflows(blueshifts) in all three spectral lines. We found an extremely\nblueshifted Si iv profile (i.e., blueshift around -180 km\/s) in the overlapping\nregion. The mean non-thermal velocity (v_nt) in the flare ribbons is higher in\nO iv than Si iv. While, in the overlapping region, O iv have lower v_nt than Si\niv. Note that very high v_nt around 80 km\/s (in Si iv) exists in this weak\nB-class flare. The Mg ii k line widths are almost the same in the flare ribbon\nand overlapping region but, they are extremely broad than previously reported.\nWe found double peak profiles of Si iv and O iv in the overlapping region. Most\nprobably, one peak is due to downflow (flare ribbon) and another due to upflow\n(filament rise\/eruption). We report a high redshift of more than 150 km\/s in\nthe weak B-class flare. In some cases, both peaks show upflows which might be\nthe result of the superposition of two different sources, i.e., overlapping of\ntwo different velocity distributions in the line of sight."
    ],
    "c_categories":[
      [
        "astro-ph.SR"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00129",
    "a_title":"Scaling Particle Collision Data Analysis",
    "a_abstract":"For decades, researchers have developed task-specific models to address\nscientific challenges across diverse disciplines. Recently, large language\nmodels (LLMs) have shown enormous capabilities in handling general tasks;\nhowever, these models encounter difficulties in addressing real-world\nscientific problems, particularly in domains involving large-scale numerical\ndata analysis, such as experimental high energy physics. This limitation is\nprimarily due to BPE tokenization's inefficacy with numerical data. In this\npaper, we propose a task-agnostic architecture, BBT-Neutron, which employs a\nbinary tokenization method to facilitate pretraining on a mixture of textual\nand large-scale numerical experimental data. We demonstrate the application of\nBBT-Neutron to Jet Origin Identification (JoI), a critical categorization\nchallenge in high-energy physics that distinguishes jets originating from\nvarious quarks or gluons. Our results indicate that BBT-Neutron achieves\ncomparable performance to state-of-the-art task-specific JoI models.\nFurthermore, we examine the scaling behavior of BBT-Neutron's performance with\nincreasing data volume, suggesting the potential for BBT-Neutron to serve as a\nfoundational model for particle physics data analysis, with possible extensions\nto a broad spectrum of scientific computing applications for Big Science\nexperiments, industrial manufacturing and spacial computing. The project code\nis available at https:\/\/github.com\/supersymmetry-technologies\/bbt-neutron.",
    "explanation":"In this paper, we propose a task-agnostic architecture,\nBBT-Neutron, which employs a binary tokenization method to facilitate pre-\ntraining on a mixture of textual and large-scale numerical experimental data. We\ndemonstrate the application of BBT-Neutron to Jet Origin Identification (JoI),\na critical categorization challenge in high-energy physics that distinguishes jets\noriginating from various quarks or gluons",
    "b_id":[
      "b23"
    ],
    "b_title":[
      "DARWIN Series: Domain Specific Large Language Models for Natural Science"
    ],
    "b_abstract":[
      "Emerging tools bring forth fresh approaches to work, and the field of natural science is no different. In science, traditional manual, serial, labour-intensive work being augmented by automated, parallel, iterative processes driven artificial intelligence-based experimental automation more. To add new capabilities in enabling acceleration enrichment discovery process, we present DARWIN, a series tailored LLMs for mainly physics, chemistry, material science. This relies on open-source LLM, incorporating structured unstructured scientific knowledge from public datasets literature. We fine-tuned models using over 60,000 instruction data points, emphasizing factual correctness. During fine-tuning, introduce Scientific Instruction Generation (SIG) model, automating generation texts. eliminates need manual extraction or domain-specific graphs efficiently injects into model. also explore multi-task training strategies, revealing interconnections between tasks. DARWIN not only achieves state-of-the-art results various tasks but diminishes reliance closed-source AI models. Our research showcases ability LLM domain, with overarching goal fostering prosperity within broader community."
    ],
    "b_categories":[
      "cs.CL"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.07049"
    ],
    "c_title":[
      "The timing and spectral properties of the 2022 outburst of SGR\n  J1935+2154 observed with NICER"
    ],
    "c_abstract":[
      "The magnetar SGR J1935+2154 entered a new active episode on October 10, 2022,\nwith X-ray bursts and enhanced persistent emission. At the tail of high burst\nrate interval, lasting several hours, radio bursts were detected, revealing the\nconnection between the X-ray activities and radio emissions. We analyzed\nobservations of SGR J1935+2154 for nearly three months, using data from Neutron\nStar Interior Composition Explorer (NICER). We report the timing and spectral\nresults following the onset of this outburst. In general, the X-ray flux of the\npersistent emission decays exponentially. While a flare is evident on the light\ncurve, a fast radio burst (FRB) was detected immediately following the peak of\nthis flare. We found a phase jump of pulse profile, with a deviation of\n$0.16\\pm0.03$ phase, which is related to the glitch. The spectra are well fit\nwith the combination of a blackbody and a power law model. The decay of the\noutburst is dominated by the drop of the non-thermal component, which also\nleads to the increase of thermal proportion. The photon index of the power law\nis inversely correlated with both the unabsorbed flux and the burst rate. We\nfind that unlike the large variety of the persistent emission around FRB\n221014, the X-ray properties are very stable when FRBs 221021 and 221201\nhappened. These results manifest the connection between glitch, phase jump,\nX-ray burst, and radio burst, crucial for studying the mutation in twisted\nmagnetic fields and constraining the trigger mechanism of radio bursts."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00129",
    "a_title":"Scaling Particle Collision Data Analysis",
    "a_abstract":"For decades, researchers have developed task-specific models to address\nscientific challenges across diverse disciplines. Recently, large language\nmodels (LLMs) have shown enormous capabilities in handling general tasks;\nhowever, these models encounter difficulties in addressing real-world\nscientific problems, particularly in domains involving large-scale numerical\ndata analysis, such as experimental high energy physics. This limitation is\nprimarily due to BPE tokenization's inefficacy with numerical data. In this\npaper, we propose a task-agnostic architecture, BBT-Neutron, which employs a\nbinary tokenization method to facilitate pretraining on a mixture of textual\nand large-scale numerical experimental data. We demonstrate the application of\nBBT-Neutron to Jet Origin Identification (JoI), a critical categorization\nchallenge in high-energy physics that distinguishes jets originating from\nvarious quarks or gluons. Our results indicate that BBT-Neutron achieves\ncomparable performance to state-of-the-art task-specific JoI models.\nFurthermore, we examine the scaling behavior of BBT-Neutron's performance with\nincreasing data volume, suggesting the potential for BBT-Neutron to serve as a\nfoundational model for particle physics data analysis, with possible extensions\nto a broad spectrum of scientific computing applications for Big Science\nexperiments, industrial manufacturing and spacial computing. The project code\nis available at https:\/\/github.com\/supersymmetry-technologies\/bbt-neutron.",
    "explanation":"In this paper, we propose a task-agnostic architecture,\nBBT-Neutron, which employs a binary tokenization method to facilitate pre-\ntraining on a mixture of textual and large-scale numerical experimental data. We\ndemonstrate the application of BBT-Neutron to Jet Origin Identification (JoI),\na critical categorization challenge in high-energy physics that distinguishes jets\noriginating from various quarks or gluons",
    "b_id":[
      "b29"
    ],
    "b_title":[
      "Study of Fermion pair production in e+e- collisions at 130-183 GeV"
    ],
    "b_abstract":[
      "The cross sections and forward-backward asymmetries of hadronic and leptonic\nevents produced in e+e- collisions at centre-of-mass energies of 130-183 GeV\nare presented. Results for ee, mumu, tautau, qq, bb and cc production show no\nsignificant deviation from the Standard Model predictions. This enable\nconstraints to be set upon physics beyond the Standard Model such as\nfour-fermion contact interactions, leptoquarks, Z' bosons and R-parity\nviolating squarks and sneutrinos. Limits on the energy scale Lambda of eeff\ncontact interactions are typically in the range from 2-10 TeV. Limits on\nR-parity violating sneutrinos reach masses of a few hundred GeV for large\nvalues of their Yukawa couplings."
    ],
    "b_categories":[
      "astro-ph.HE"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.01275"
    ],
    "c_title":[
      "Enhancing Non-English Capabilities of English-Centric Large Language\n  Models through Deep Supervision Fine-Tuning"
    ],
    "c_abstract":[
      "Large language models (LLMs) have demonstrated significant progress in\nmultilingual language understanding and generation. However, due to the\nimbalance in training data, their capabilities in non-English languages are\nlimited. Recent studies revealed the English-pivot multilingual mechanism of\nLLMs, where LLMs implicitly convert non-English queries into English ones at\nthe bottom layers and adopt English for thinking at the middle layers. However,\ndue to the absence of explicit supervision for cross-lingual alignment in the\nintermediate layers of LLMs, the internal representations during these stages\nmay become inaccurate. In this work, we introduce a deep supervision\nfine-tuning method (DFT) that incorporates additional supervision in the\ninternal layers of the model to guide its workflow. Specifically, we introduce\ntwo training objectives on different layers of LLMs: one at the bottom layers\nto constrain the conversion of the target language into English, and another at\nthe middle layers to constrain reasoning in English. To effectively achieve the\nguiding purpose, we designed two types of supervision signals: logits and\nfeature, which represent a stricter constraint and a relatively more relaxed\nguidance. Our method guides the model to not only consider the final generated\nresult when processing non-English inputs but also ensure the accuracy of\ninternal representations. We conducted extensive experiments on typical\nEnglish-centric large models, LLaMA-2 and Gemma-2, and the results on multiple\nmultilingual datasets show that our method significantly outperforms\ntraditional fine-tuning methods."
    ],
    "c_categories":[
      [
        "cs.CL"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.19475",
    "a_title":"Effective Fine-Tuning of Vision-Language Models for Accurate Galaxy\n  Morphology Analysis",
    "a_abstract":"Galaxy morphology analysis involves classifying galaxies by their shapes and\nstructures. For this task, directly training domain-specific models on large,\nannotated astronomical datasets is effective but costly. In contrast,\nfine-tuning vision foundation models on a smaller set of astronomical images is\nmore resource-efficient but generally results in lower accuracy. To harness the\nbenefits of both approaches and address their shortcomings, we propose\nGalaxAlign, a novel method that fine-tunes pre-trained foundation models to\nachieve high accuracy on astronomical tasks. Specifically, our method extends a\ncontrastive learning architecture to align three types of data in fine-tuning:\n(1) a set of schematic symbols representing galaxy shapes and structures, (2)\ntextual labels of these symbols, and (3) galaxy images. This way, GalaxAlign\nnot only eliminates the need for expensive pretraining but also enhances the\neffectiveness of fine-tuning. Extensive experiments on galaxy classification\nand similarity search demonstrate that our method effectively fine-tunes\ngeneral pre-trained models for astronomical tasks by incorporating\ndomain-specific multi-modal knowledge.",
    "explanation":"To harness the benefits of\nboth approaches and address their shortcomings, we pro-\npose GalaxAlign, a novel method that fine-tunes pre-trained\nfoundation models to achieve high accuracy on astronom-\nical tasks.",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Radio galaxy zoo EMU: Towards a semantic radio galaxy morphology taxonomy"
    ],
    "b_abstract":[
      "ABSTRACT We present a novel natural language processing (NLP) approach to deriving plain English descriptors for science cases otherwise restricted by obfuscating technical terminology. address the limitations of common radio galaxy morphology classifications applying this approach. experimentally derive set semantic tags Radio Galaxy Zoo EMU (Evolutionary Map Universe) project and wider astronomical community. collect 8486 annotations morphology, from which we taxonomy tags. The are English. result is an extensible framework, more flexible, easily communicated, sensitive rare feature combinations, indescribable using current framework astronomy classifications."
    ],
    "b_categories":[
      "astro-ph.CO"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.10568"
    ],
    "c_title":[
      "Autoregressive Image Generation with Randomized Parallel Decoding"
    ],
    "c_abstract":[
      "We introduce ARPG, a novel visual autoregressive model that enables\nrandomized parallel generation, addressing the inherent limitations of\nconventional raster-order approaches, which hinder inference efficiency and\nzero-shot generalization due to their sequential, predefined token generation\norder. Our key insight is that effective random-order modeling necessitates\nexplicit guidance for determining the position of the next predicted token. To\nthis end, we propose a novel guided decoding framework that decouples\npositional guidance from content representation, encoding them separately as\nqueries and key-value pairs. By directly incorporating this guidance into the\ncausal attention mechanism, our approach enables fully random-order training\nand generation, eliminating the need for bidirectional attention. Consequently,\nARPG readily generalizes to zero-shot tasks such as image inpainting,\noutpainting, and resolution expansion. Furthermore, it supports parallel\ninference by concurrently processing multiple queries using a shared KV cache.\nOn the ImageNet-1K 256 benchmark, our approach attains an FID of 1.94 with only\n64 sampling steps, achieving over a 20-fold increase in throughput while\nreducing memory consumption by over 75% compared to representative recent\nautoregressive models at a similar scale."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.19475",
    "a_title":"Effective Fine-Tuning of Vision-Language Models for Accurate Galaxy\n  Morphology Analysis",
    "a_abstract":"Galaxy morphology analysis involves classifying galaxies by their shapes and\nstructures. For this task, directly training domain-specific models on large,\nannotated astronomical datasets is effective but costly. In contrast,\nfine-tuning vision foundation models on a smaller set of astronomical images is\nmore resource-efficient but generally results in lower accuracy. To harness the\nbenefits of both approaches and address their shortcomings, we propose\nGalaxAlign, a novel method that fine-tunes pre-trained foundation models to\nachieve high accuracy on astronomical tasks. Specifically, our method extends a\ncontrastive learning architecture to align three types of data in fine-tuning:\n(1) a set of schematic symbols representing galaxy shapes and structures, (2)\ntextual labels of these symbols, and (3) galaxy images. This way, GalaxAlign\nnot only eliminates the need for expensive pretraining but also enhances the\neffectiveness of fine-tuning. Extensive experiments on galaxy classification\nand similarity search demonstrate that our method effectively fine-tunes\ngeneral pre-trained models for astronomical tasks by incorporating\ndomain-specific multi-modal knowledge.",
    "explanation":"To harness the benefits of\nboth approaches and address their shortcomings, we pro-\npose GalaxAlign, a novel method that fine-tunes pre-trained\nfoundation models to achieve high accuracy on astronom-\nical tasks.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "ImageNet: A large-scale hierarchical image database"
    ],
    "b_abstract":[
      "The explosion of image data on the Internet has potential to foster more sophisticated and robust models algorithms index, retrieve, organize interact with images multimedia data. But exactly how such can be harnessed organized remains a critical problem. We introduce here new database called \"ImageNet\", large-scale ontology built upon backbone WordNet structure. ImageNet aims populate majority 80,000 synsets an average 500\u20131000 clean full resolution images. This will result in tens millions annotated by semantic hierarchy WordNet. paper offers detailed analysis its current state: 12 subtrees 5247 3.2 million total. show that is much larger scale diversity accurate than datasets. Constructing challenging task. describe collection scheme Amazon Mechanical Turk. Lastly, we illustrate usefulness through three simple applications object recognition, classification automatic clustering. hope scale, accuracy, hierarchical structure offer unparalleled opportunities researchers computer vision community beyond."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.10844"
    ],
    "c_title":[
      "Cosmic filament spin -- II: filament spin and its impact on galaxy\n  spin-filament alignment in a cosmological simulation"
    ],
    "c_abstract":[
      "Observational studies have reported that cosmic filaments on the megaparsec\nscale exhibit rotational motion. Subsequent simulation studies have shown\nqualitative agreement with these findings, but quantitative discrepancies\nremain due to differences in data and methods, which require verification. To\naddress this issue, we adopt the same methodology as used in the observations\nto identify filament spin from the galaxy distribution constructed from a\nhydrodynamic simulation. Using the same approach to measure filament spin, we\nfind that the simulation results closely match the observational findings, with\nonly minor discrepancies arising from slight differences in the fraction of\nfilaments classified as dynamically cold or hot based on their dynamic\ntemperature. Additionally, an analysis of how filament spin affects the galaxy\nspin-filament correlation shows that filaments with strong spin signals and\ndynamically cold have a greater impact on the galaxy spin-filament correlation\nthan those with weaker spin signals and dynamically hot filaments. These\nresults not only provide further evidence that cosmic filaments exhibit spin,\nbut also highlight the importance of this rotation in the acquisition of\nangular momentum by individual galaxies. Future studies exploring the influence\nof filament spin on galaxy spin may shed light on the physical origins of\nfilaments and the angular momentum of galaxies."
    ],
    "c_categories":[
      [
        "astro-ph.CO"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.15395",
    "a_title":"ChatBCI: A P300 Speller BCI Leveraging Large Language Models for\n  Improved Sentence Composition in Realistic Scenarios",
    "a_abstract":"P300 speller BCIs allow users to compose sentences by selecting target keys\non a GUI through the detection of P300 component in their EEG signals following\nvisual stimuli. Most P300 speller BCIs require users to spell words letter by\nletter, or the first few initial letters, resulting in high keystroke demands\nthat increase time, cognitive load, and fatigue. This highlights the need for\nmore efficient, user-friendly methods for faster sentence composition. In this\nwork, we introduce ChatBCI, a P300 speller BCI that leverages the zero-shot\nlearning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing\nkeystrokes and accelerating sentence composition. ChatBCI retrieves word\nsuggestions through remote queries to the GPT-3.5 API. A new GUI, displaying\nGPT-3.5 word suggestions as extra keys is designed. SWLDA is used for the P300\nclassification. Seven subjects completed two online spelling tasks: 1)\ncopy-spelling a self-composed sentence using ChatBCI, and 2) improvising a\nsentence using ChatBCI's word suggestions. Results demonstrate that in Task 1,\non average, ChatBCI outperforms letter-by-letter BCI spellers, reducing time\nand keystrokes by 62.14% and 53.22%, respectively, and increasing information\ntransfer rate by 198.96%. In Task 2, ChatBCI achieves 80.68% keystroke savings\nand a record 8.53 characters\/min for typing speed. Overall, ChatBCI, by\nemploying remote LLM queries, enhances sentence composition in realistic\nscenarios, significantly outperforming traditional spellers without requiring\nlocal model training or storage. ChatBCI's (multi-) word predictions, combined\nwith its new GUI, pave the way for developing next-generation speller BCIs that\nare efficient and effective for real-time communication, especially for users\nwith communication and motor disabilities.",
    "explanation":"In this work, we introduce ChatBCI, a P300 speller BCI that leverages the zero-\nshot learning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing keystrokes\nand accelerating sentence composition. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Brain\u2013Computer Interface Spellers: A Review"
    ],
    "b_abstract":[
      "A Brain\u2013Computer Interface (BCI) provides a novel non-muscular communication method via brain signals. BCI-speller can be considered as one of the first published BCI applications and has opened gate for many advances in field. Although BCI-spellers have been developed during last few decades, to our knowledge, no reviews described different spellers proposed studied this vital The presented speller systems are categorized according major paradigms: P300, steady-state visual evoked potential (SSVEP), motor imagery (MI). Different paradigms require specific electroencephalogram (EEG) signal features lead development appropriate Graphical User Interfaces (GUIs). purpose review is consolidate most successful since 2010, while mentioning some other older which were built explicitly spelling purposes. We aim assist researchers concerned individuals field by illustrating highlights presenting them review. It almost impossible carry out an objective comparison between spellers, each its variables, parameters, conditions. However, gathered information provided taxonomy about helpful, it could identify suitable first-hand users, well opportunities learning from previous studies researchers."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.10114"
    ],
    "c_title":[
      "Infrastructure for AI Agents"
    ],
    "c_abstract":[
      "Increasingly many AI systems can plan and execute interactions in open-ended\nenvironments, such as making phone calls or buying online goods. As developers\ngrow the space of tasks that such AI agents can accomplish, we will need tools\nboth to unlock their benefits and manage their risks. Current tools are largely\ninsufficient because they are not designed to shape how agents interact with\nexisting institutions (e.g., legal and economic systems) or actors (e.g.,\ndigital service providers, humans, other AI agents). For example, alignment\ntechniques by nature do not assure counterparties that some human will be held\naccountable when a user instructs an agent to perform an illegal action. To\nfill this gap, we propose the concept of agent infrastructure: technical\nsystems and shared protocols external to agents that are designed to mediate\nand influence their interactions with and impacts on their environments. Agent\ninfrastructure comprises both new tools and reconfigurations or extensions of\nexisting tools. For example, to facilitate accountability, protocols that tie\nusers to agents could build upon existing systems for user authentication, such\nas OpenID. Just as the Internet relies on infrastructure like HTTPS, we argue\nthat agent infrastructure will be similarly indispensable to ecosystems of\nagents. We identify three functions for agent infrastructure: 1) attributing\nactions, properties, and other information to specific agents, their users, or\nother actors; 2) shaping agents' interactions; and 3) detecting and remedying\nharmful actions from agents. We propose infrastructure that could help achieve\neach function, explaining use cases, adoption, limitations, and open questions.\nMaking progress on agent infrastructure can prepare society for the adoption of\nmore advanced agents."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.15395",
    "a_title":"ChatBCI: A P300 Speller BCI Leveraging Large Language Models for\n  Improved Sentence Composition in Realistic Scenarios",
    "a_abstract":"P300 speller BCIs allow users to compose sentences by selecting target keys\non a GUI through the detection of P300 component in their EEG signals following\nvisual stimuli. Most P300 speller BCIs require users to spell words letter by\nletter, or the first few initial letters, resulting in high keystroke demands\nthat increase time, cognitive load, and fatigue. This highlights the need for\nmore efficient, user-friendly methods for faster sentence composition. In this\nwork, we introduce ChatBCI, a P300 speller BCI that leverages the zero-shot\nlearning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing\nkeystrokes and accelerating sentence composition. ChatBCI retrieves word\nsuggestions through remote queries to the GPT-3.5 API. A new GUI, displaying\nGPT-3.5 word suggestions as extra keys is designed. SWLDA is used for the P300\nclassification. Seven subjects completed two online spelling tasks: 1)\ncopy-spelling a self-composed sentence using ChatBCI, and 2) improvising a\nsentence using ChatBCI's word suggestions. Results demonstrate that in Task 1,\non average, ChatBCI outperforms letter-by-letter BCI spellers, reducing time\nand keystrokes by 62.14% and 53.22%, respectively, and increasing information\ntransfer rate by 198.96%. In Task 2, ChatBCI achieves 80.68% keystroke savings\nand a record 8.53 characters\/min for typing speed. Overall, ChatBCI, by\nemploying remote LLM queries, enhances sentence composition in realistic\nscenarios, significantly outperforming traditional spellers without requiring\nlocal model training or storage. ChatBCI's (multi-) word predictions, combined\nwith its new GUI, pave the way for developing next-generation speller BCIs that\nare efficient and effective for real-time communication, especially for users\nwith communication and motor disabilities.",
    "explanation":"In this work, we introduce ChatBCI, a P300 speller BCI that leverages the zero-\nshot learning capabilities of large language models (LLMs) to suggest words from\nuser-spelled initial letters or predict the subsequent word(s), reducing keystrokes\nand accelerating sentence composition. ",
    "b_id":[
      "b17"
    ],
    "b_title":[
      "Language Model-Guided Classifier Adaptation for Brain-Computer Interfaces for Communication"
    ],
    "b_abstract":[
      "Brain-computer interfaces (BCIs), such as the P300 speller, can provide a means of communication for individuals with severe neuromuscular limitations. BCIs interpret electroencephalography (EEG) signals in order to translate embedded information about user's intent into executable commands control external devices. However, EEG are inherently noisy and nonstationary, posing challenge extended BCI use. Conventionally, classifier is trained via supervised learning an offline calibration session; once trained, deployed online use not updated. As statistics data change over time, performance static may decline It therefore desirable automatically adapt current without requiring recalibration. In existing semi-supervised approach, on labeled then updated using incoming unlabeled classifier-predicted labels. To reduce risk from incorrect predictions, threshold imposed exclude low-confidence label predictions expanded training set when retraining adaptive classifier. this work, we propose language model spelling error correction disambiguation correctness during learning. Results simulations multi-session speller user demonstrate that our language-guided approach significantly improves accuracy relative conventional threshold-based"
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.09672"
    ],
    "c_title":[
      "Mechanoreceptive A$\\beta$ primary afferents discriminate naturalistic\n  social touch inputs at a functionally relevant time scale"
    ],
    "c_abstract":[
      "Interpersonal touch is an important channel of social emotional interaction.\nHow these physical skin-to-skin touch expressions are processed in the\nperipheral nervous system is not well understood. From microneurography\nrecordings in humans, we evaluated the capacity of six subtypes of cutaneous\nmechanoreceptive afferents to differentiate human-delivered social touch\nexpressions. Leveraging statistical and classification analyses, we found that\nsingle units of multiple mechanoreceptive A$\\beta$ subtypes, especially slowly\nadapting type II (SA-II) and fast adapting hair follicle afferents (HFA), can\nreliably differentiate social touch expressions at accuracies similar to human\nrecognition. We then identified the most informative firing patterns of SA-II\nand HFA afferents, which indicate that average durations of 3-4 s of firing\nprovide sufficient discriminative information. Those two subtypes also exhibit\nrobust tolerance to spike-timing shifts of up to 10-20 ms, varying with touch\nexpressions due to their specific firing properties. Greater shifts in\nspike-timing, however, can change a firing pattern's envelope to resemble that\nof another expression and drastically compromise an afferent's discrimination\ncapacity. Altogether, the findings indicate that SA-II and HFA afferents\ndifferentiate the skin contact of social touch at time scales relevant for such\ninteractions, which are 1-2 orders of magnitude longer than those for\nnon-social touch."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.08063",
    "a_title":"MatPilot: an LLM-enabled AI Materials Scientist under the Framework of\n  Human-Machine Collaboration",
    "a_abstract":"The rapid evolution of artificial intelligence, particularly large language\nmodels, presents unprecedented opportunities for materials science research. We\nproposed and developed an AI materials scientist named MatPilot, which has\nshown encouraging abilities in the discovery of new materials. The core\nstrength of MatPilot is its natural language interactive human-machine\ncollaboration, which augments the research capabilities of human scientist\nteams through a multi-agent system. MatPilot integrates unique cognitive\nabilities, extensive accumulated experience, and ongoing curiosity of\nhuman-beings with the AI agents' capabilities of advanced abstraction, complex\nknowledge storage and high-dimensional information processing. It could\ngenerate scientific hypotheses and experimental schemes, and employ predictive\nmodels and optimization algorithms to drive an automated experimental platform\nfor experiments. It turns out that our system demonstrates capabilities for\nefficient validation, continuous learning, and iterative optimization.",
    "explanation":"proposed and\ndeveloped an AI materials scientist named MatPilot, which has shown encouraging\nabilities in the discovery of new materials. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "A Data-Science Approach to Predict the Heat Capacity of Nanoporous Materials"
    ],
    "b_abstract":[
      "The heat capacity of a material is a fundamental property of great practical importance. For example, in a carbon capture process, the heat required to regenerate a solid sorbent is directly related to the heat capacity of the material. However, for most materials suitable for carbon capture applications, the heat capacity is not known, and thus the standard procedure is to assume the same value for all materials. In this work, we developed a machine learning approach, trained on density functional theory simulations, to accurately predict the heat capacity of these materials, that is, zeolites, metal\u2013organic frameworks and covalent\u2013organic frameworks. The accuracy of our prediction is confirmed with experimental data. Finally, for a temperature swing adsorption process that captures carbon from the flue gas of a coal-fired power plant, we show that for some materials, the heat requirement is reduced by as much as a factor of two using the correct heat capacity. Heat capacity of nanoporous materials is important for processes such as carbon capture, as this can affect process design energy requirements. Here, a machine learning approach for heat capacity prediction, trained on density functional theory simulations, is presented and experimentally verified."
    ],
    "b_categories":[
      "cond-mat.mtrl-sci"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.03274"
    ],
    "c_title":[
      "A Scalable Approach to Probabilistic Neuro-Symbolic Verification"
    ],
    "c_abstract":[
      "Neuro-Symbolic Artificial Intelligence (NeSy AI) has emerged as a promising\ndirection for integrating neural learning with symbolic reasoning. In the\nprobabilistic variant of such systems, a neural network first extracts a set of\nsymbols from sub-symbolic input, which are then used by a symbolic component to\nreason in a probabilistic manner towards answering a query. In this work, we\naddress the problem of formally verifying the robustness of such NeSy\nprobabilistic reasoning systems, therefore paving the way for their safe\ndeployment in critical domains. We analyze the complexity of solving this\nproblem exactly, and show that it is $\\mathrm{NP}^{\\# \\mathrm{P}}$-hard. To\novercome this issue, we propose the first approach for approximate,\nrelaxation-based verification of probabilistic NeSy systems. We demonstrate\nexperimentally that the proposed method scales exponentially better than\nsolver-based solutions and apply our technique to a real-world autonomous\ndriving dataset, where we verify a safety property under large input\ndimensionalities and network sizes."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.08063",
    "a_title":"MatPilot: an LLM-enabled AI Materials Scientist under the Framework of\n  Human-Machine Collaboration",
    "a_abstract":"The rapid evolution of artificial intelligence, particularly large language\nmodels, presents unprecedented opportunities for materials science research. We\nproposed and developed an AI materials scientist named MatPilot, which has\nshown encouraging abilities in the discovery of new materials. The core\nstrength of MatPilot is its natural language interactive human-machine\ncollaboration, which augments the research capabilities of human scientist\nteams through a multi-agent system. MatPilot integrates unique cognitive\nabilities, extensive accumulated experience, and ongoing curiosity of\nhuman-beings with the AI agents' capabilities of advanced abstraction, complex\nknowledge storage and high-dimensional information processing. It could\ngenerate scientific hypotheses and experimental schemes, and employ predictive\nmodels and optimization algorithms to drive an automated experimental platform\nfor experiments. It turns out that our system demonstrates capabilities for\nefficient validation, continuous learning, and iterative optimization.",
    "explanation":"proposed and\ndeveloped an AI materials scientist named MatPilot, which has shown encouraging\nabilities in the discovery of new materials. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "A deep-learning approach to realizing functionality in nanoelectronic devices"
    ],
    "b_abstract":[
      "Many nanoscale devices require precise optimization to function. Tuning them to the desired operation regime becomes increasingly difficult and time-consuming when the number of terminals and couplings grows. Imperfections and device-to-device variations hinder optimization that uses physics-based models. Deep neural networks (DNNs) can model various complex physical phenomena but, so far, are mainly used as predictive tools. Here, we propose a generic deep-learning approach to efficiently optimize complex, multi-terminal nanoelectronic devices for desired functionality. We demonstrate our approach for realizing functionality in a disordered network of dopant atoms in silicon. We model the input\u2013output characteristics of the device with a DNN, and subsequently optimize control parameters in the DNN model through gradient descent to realize various classification tasks. When the corresponding control settings are applied to the physical device, the resulting functionality is as predicted by the DNN model. We expect our approach to contribute to fast, in situ optimization of complex (quantum) nanoelectronic devices."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.02853"
    ],
    "c_title":[
      "BaTiO$_3$ -- SrTiO$_3$ composites: a microscopic study on paraelectric\n  cubic inclusions"
    ],
    "c_abstract":[
      "Composites of ferroelectric and paraelectric perovskites have attracted a lot\nof attention due to their application potential in energy storage as well as\nnovel computing and memory devices. So far the main focus of research has been\non superlattices and ferroelectric particles in a paraelectric matrix, while\nthe impact of paraelectric inclusions on the ferroelectric matrix is\nsurprisingly underrepresented. To close this gap in knowledge we perform\nmolecular dynamics simulations using an $ab\\ initio$ derived effective\nHamiltonian for BaTiO$_3$--SrTiO$_3$ and reveal the dependency of phase\nstability and phase transitions on the size and distances of paraelectric\ninclusions. We discuss how the combination of compressive strain and\ndepolarization fields at the SrTiO$_3$ interfaces induces large local\npolarization, complex domain structures and coexisting phases as well as\ndiffuse phase transitions and reduced coercive fields."
    ],
    "c_categories":[
      [
        "cond-mat.mtrl-sci"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.13126",
    "a_title":"A Knowledge-enhanced Pathology Vision-language Foundation Model for\n  Cancer Diagnosis",
    "a_abstract":"Deep learning has enabled the development of highly robust foundation models\nfor various pathological tasks across diverse diseases and patient cohorts.\nAmong these models, vision-language pre-training, which leverages large-scale\npaired data to align pathology image and text embedding spaces, and provides a\nnovel zero-shot paradigm for downstream tasks. However, existing models have\nbeen primarily data-driven and lack the incorporation of domain-specific\nknowledge, which limits their performance in cancer diagnosis, especially for\nrare tumor subtypes. To address this limitation, we establish a\nKnowledge-enhanced Pathology (KEEP) foundation model that harnesses disease\nknowledge to facilitate vision-language pre-training. Specifically, we first\nconstruct a disease knowledge graph (KG) that covers 11,454 human diseases with\n139,143 disease attributes, including synonyms, definitions, and hypernym\nrelations. We then systematically reorganize the millions of publicly available\nnoisy pathology image-text pairs, into 143K well-structured semantic groups\nlinked through the hierarchical relations of the disease KG. To derive more\nnuanced image and text representations, we propose a novel knowledge-enhanced\nvision-language pre-training approach that integrates disease knowledge into\nthe alignment within hierarchical semantic groups instead of unstructured\nimage-text pairs. Validated on 18 diverse benchmarks with more than 14,000\nwhole slide images (WSIs), KEEP achieves state-of-the-art performance in\nzero-shot cancer diagnostic tasks. Notably, for cancer detection, KEEP\ndemonstrates an average sensitivity of 89.8% at a specificity of 95.0% across 7\ncancer types. For cancer subtyping, KEEP achieves a median balanced accuracy of\n0.456 in subtyping 30 rare brain cancers, indicating strong generalizability\nfor diagnosing rare tumors.",
    "explanation":"However, existing models have been primarily data-driven and\nlack the incorporation of domain-specific knowledge, which limits their performance in cancer diagnosis,\nespecially for rare tumor subtypes. To address this limitation, we establish a KnowledgE-Enhanced\nPathology (KEEP) foundation model that harnesses disease knowledge to facilitate vision-language\npre-training.",
    "b_id":[
      "b2"
    ],
    "b_title":[
      "Machine Learning-driven Histotype Diagnosis of Ovarian Carcinoma: Insights from the OCEAN AI Challenge"
    ],
    "b_abstract":[
      "Ovarian cancer poses a significant health burden as one of the deadliest malignancies affecting women globally. Histotype assignment of epithelial ovarian cancers can be challenging due to morphologic overlap, inter-observer variability, and the lack of ancillary diagnostic techniques in some areas of the world. Moreover, rare cancers can pose particular diagnostic difficulties because of a relative lack of familiarity with them, underscoring the necessity for robust diagnostic methodologies. The emergence of Artificial Intelligence (AI) has brought promising prospects to the realm of ovarian cancer diagnosis. While various studies have underscored AI's promise, its validation across multiple healthcare centers and hospitals has been limited. Inspired by innovations in medical imaging driven by public competitions, we initiated the Ovarian Cancer subtypE clAssification and outlier detectioN (OCEAN) challenge, the most extensive histopathology competition to date."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.18947"
    ],
    "c_title":[
      "Trait-structured chemotaxis: Exploring ligand-receptor dynamics and\n  travelling wave properties in a Keller-Segel model"
    ],
    "c_abstract":[
      "A novel trait-structured Keller-Segel model that explores the dynamics of a\nmigrating cell population guided by chemotaxis in response to an external\nligand concentration is derived and analysed. Unlike traditional Keller-Segel\nmodels, this framework introduces an explicit representation of ligand-receptor\nbindings on the cell membrane, where the percentage of occupied receptors\nconstitutes the trait that influences cellular phenotype. The model posits that\nthe cell's phenotypic state directly modulates its capacity for chemotaxis and\nproliferation, governed by a trade-off due to a finite energy budget: cells\nhighly proficient in chemotaxis exhibit lower proliferation rates, while more\nproliferative cells show diminished chemotactic abilities. The model is derived\nfrom the principles of a biased random walk, resulting in a system of two\nnon-local partial differential equations, describing the densities of both\ncells and ligands. Using a Hopf-Cole transformation, we derive an equation that\ncharacterises the distribution of cellular traits within travelling wave\nsolutions for the total cell density, allowing us to uncover the monotonicity\nproperties of these waves. Numerical investigations are conducted to examine\nthe model's behaviour across various biological scenarios, providing insights\ninto the complex interplay between chemotaxis, proliferation, and phenotypic\ndiversity in migrating cell populations."
    ],
    "c_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.13126",
    "a_title":"A Knowledge-enhanced Pathology Vision-language Foundation Model for\n  Cancer Diagnosis",
    "a_abstract":"Deep learning has enabled the development of highly robust foundation models\nfor various pathological tasks across diverse diseases and patient cohorts.\nAmong these models, vision-language pre-training, which leverages large-scale\npaired data to align pathology image and text embedding spaces, and provides a\nnovel zero-shot paradigm for downstream tasks. However, existing models have\nbeen primarily data-driven and lack the incorporation of domain-specific\nknowledge, which limits their performance in cancer diagnosis, especially for\nrare tumor subtypes. To address this limitation, we establish a\nKnowledge-enhanced Pathology (KEEP) foundation model that harnesses disease\nknowledge to facilitate vision-language pre-training. Specifically, we first\nconstruct a disease knowledge graph (KG) that covers 11,454 human diseases with\n139,143 disease attributes, including synonyms, definitions, and hypernym\nrelations. We then systematically reorganize the millions of publicly available\nnoisy pathology image-text pairs, into 143K well-structured semantic groups\nlinked through the hierarchical relations of the disease KG. To derive more\nnuanced image and text representations, we propose a novel knowledge-enhanced\nvision-language pre-training approach that integrates disease knowledge into\nthe alignment within hierarchical semantic groups instead of unstructured\nimage-text pairs. Validated on 18 diverse benchmarks with more than 14,000\nwhole slide images (WSIs), KEEP achieves state-of-the-art performance in\nzero-shot cancer diagnostic tasks. Notably, for cancer detection, KEEP\ndemonstrates an average sensitivity of 89.8% at a specificity of 95.0% across 7\ncancer types. For cancer subtyping, KEEP achieves a median balanced accuracy of\n0.456 in subtyping 30 rare brain cancers, indicating strong generalizability\nfor diagnosing rare tumors.",
    "explanation":"However, existing models have been primarily data-driven and\nlack the incorporation of domain-specific knowledge, which limits their performance in cancer diagnosis,\nespecially for rare tumor subtypes. To address this limitation, we establish a KnowledgE-Enhanced\nPathology (KEEP) foundation model that harnesses disease knowledge to facilitate vision-language\npre-training.",
    "b_id":[
      "b1"
    ],
    "b_title":[
      "Viable and necrotic tumor assessment from whole slide images of osteosarcoma using machine-learning and deep-learning models"
    ],
    "b_abstract":[
      "Pathological estimation of tumor necrosis after chemotherapy is essential for patients with osteosarcoma. This study reports the first fully automated tool to assess viable and necrotic in osteosarcoma, employing advances histopathology digitization learning. We selected 40 digitized whole slide images representing heterogeneity osteosarcoma response. With goal labeling diverse regions tissue into tumor, non-tumor, we trained 13 machine-learning models top performing one (a Support Vector Machine) based on reported accuracy. also developed a deep-learning architecture it same data set. computed receiver-operator characteristic discrimination non-tumor from followed by conditional found our exceptionally well. then used identify interest image-tiles generated test images. The classification output visualized as tumor-prediction map, displaying extent image. Thus, lay foundation complete assessment pipeline original histology map generation. proposed can be adopted other types tumor."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.03274"
    ],
    "c_title":[
      "A Scalable Approach to Probabilistic Neuro-Symbolic Verification"
    ],
    "c_abstract":[
      "Neuro-Symbolic Artificial Intelligence (NeSy AI) has emerged as a promising\ndirection for integrating neural learning with symbolic reasoning. In the\nprobabilistic variant of such systems, a neural network first extracts a set of\nsymbols from sub-symbolic input, which are then used by a symbolic component to\nreason in a probabilistic manner towards answering a query. In this work, we\naddress the problem of formally verifying the robustness of such NeSy\nprobabilistic reasoning systems, therefore paving the way for their safe\ndeployment in critical domains. We analyze the complexity of solving this\nproblem exactly, and show that it is $\\mathrm{NP}^{\\# \\mathrm{P}}$-hard. To\novercome this issue, we propose the first approach for approximate,\nrelaxation-based verification of probabilistic NeSy systems. We demonstrate\nexperimentally that the proposed method scales exponentially better than\nsolver-based solutions and apply our technique to a real-world autonomous\ndriving dataset, where we verify a safety property under large input\ndimensionalities and network sizes."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17717",
    "a_title":"Comprehensive Methodology for Sample Augmentation in EEG Biomarker\n  Studies for Alzheimers Risk Classification",
    "a_abstract":"Background: Dementia, marked by cognitive decline, is a global health\nchallenge. Alzheimer's disease (AD), the leading type, accounts for ~70% of\ncases. Electroencephalography (EEG) measures show promise in identifying AD\nrisk, but obtaining large samples for reliable comparisons is challenging.\nObjective: This study integrates signal processing, harmonization, and\nstatistical techniques to enhance sample size and improve AD risk\nclassification reliability. Methods: We used advanced EEG preprocessing,\nfeature extraction, harmonization, and propensity score matching (PSM) to\nbalance healthy non-carriers (HC) and asymptomatic E280A mutation carriers\n(ACr). Data from four databases were harmonized to adjust site effects while\npreserving covariates like age and sex. PSM ratios (2:1, 5:1, 10:1) were\napplied to assess sample size impact on model performance. The final dataset\nunderwent machine learning analysis with decision trees and cross-validation\nfor robust results. Results: Balancing sample sizes via PSM significantly\nimproved classification accuracy, ranging from 0.92 to 0.96 across ratios. This\napproach enabled precise risk identification even with limited samples.\nConclusion: Integrating data processing, harmonization, and balancing\ntechniques improves AD risk classification accuracy, offering potential for\nother neurodegenerative diseases.",
    "explanation":"This study implements a\ncomprehensive methodology that integrates signal processing, data harmonization, and\nstatistical techniques to increase sample size and improve the reliability of Alzheimer's disease\nrisk classification models.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Neural biomarker diagnosis and prediction to mild cognitive impairment and Alzheimer\u2019s disease using EEG technology"
    ],
    "b_abstract":[
      "Background Electroencephalogram (EEG) has emerged as a non-invasive tool to detect the aberrant neuronal activity related to different stages of Alzheimer\u2019s disease (AD). However, the effectiveness of EEG in the precise diagnosis and assessment of AD and its preclinical stage, amnestic mild cognitive impairment (MCI), has yet to be fully elucidated. In this study, we aimed to identify key EEG biomarkers that are effective in distinguishing patients at the early stage of AD and monitoring the progression of AD. Methods A total of 890 participants, including 189 patients with MCI, 330 patients with AD, 125 patients with other dementias (frontotemporal dementia, dementia with Lewy bodies, and vascular cognitive impairment), and 246 healthy controls (HC) were enrolled. Biomarkers were extracted from resting-state EEG recordings for a three-level classification of HC, MCI, and AD. The optimal EEG biomarkers were then identified based on the classification performance. Random forest regression was used to train a series of models by combining participants\u2019 EEG biomarkers, demographic information (i.e., sex, age), CSF biomarkers, and APOE phenotype for assessing the disease progression and individual\u2019s cognitive function. Results The identified EEG biomarkers achieved over 70% accuracy in the three-level classification of HC, MCI, and AD. Among all six groups, the most prominent effects of AD-linked neurodegeneration on EEG metrics were localized at parieto-occipital regions. In the cross-validation predictive analyses, the optimal EEG features were more effective than the CSF + APOE biomarkers in predicting the age of onset and disease course, whereas the combination of EEG + CSF + APOE measures achieved the best performance for all targets of prediction. Conclusions Our study indicates that EEG can be used as a useful screening tool for the diagnosis and disease progression evaluation of MCI and AD."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.08070"
    ],
    "c_title":[
      "Normative Cerebral Perfusion Across the Lifespan"
    ],
    "c_abstract":[
      "Cerebral perfusion plays a crucial role in maintaining brain function and is\ntightly coupled with neuronal activity. While previous studies have examined\ncerebral perfusion trajectories across development and aging, precise\ncharacterization of its lifespan dynamics has been limited by small sample\nsizes and methodological inconsistencies. In this study, we construct the first\ncomprehensive normative model of cerebral perfusion across the human lifespan\n(birth to 85 years) using a large multi-site dataset of over 12,000\nhigh-quality arterial spin labeling (ASL) MRI scans. Leveraging generalized\nadditive models for location, scale, and shape (GAMLSS), we mapped nonlinear\ngrowth trajectories of cerebral perfusion at global, network, and regional\nlevels. We observed a rapid postnatal increase in cerebral perfusion, peaking\nat approximately 7.1 years, followed by a gradual decline into adulthood. Sex\ndifferences were evident, with distinct regional maturation patterns rather\nthan uniform differences across all brain regions. Beyond normative modeling,\nwe quantified individual deviations from expected CBF patterns in\nneurodegenerative and psychiatric conditions, identifying disease-specific\nperfusion abnormalities across four brain disorders. Using longitudinal data,\nwe established typical and atypical cerebral perfusion trajectories,\nhighlighting the prognostic value of perfusion-based biomarkers for detecting\ndisease progression. Our findings provide a robust normative framework for\ncerebral perfusion, facilitating precise characterization of brain health\nacross the lifespan and enhancing the early identification of neurovascular\ndysfunction in clinical populations."
    ],
    "c_categories":[
      [
        "q-bio.NC"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17717",
    "a_title":"Comprehensive Methodology for Sample Augmentation in EEG Biomarker\n  Studies for Alzheimers Risk Classification",
    "a_abstract":"Background: Dementia, marked by cognitive decline, is a global health\nchallenge. Alzheimer's disease (AD), the leading type, accounts for ~70% of\ncases. Electroencephalography (EEG) measures show promise in identifying AD\nrisk, but obtaining large samples for reliable comparisons is challenging.\nObjective: This study integrates signal processing, harmonization, and\nstatistical techniques to enhance sample size and improve AD risk\nclassification reliability. Methods: We used advanced EEG preprocessing,\nfeature extraction, harmonization, and propensity score matching (PSM) to\nbalance healthy non-carriers (HC) and asymptomatic E280A mutation carriers\n(ACr). Data from four databases were harmonized to adjust site effects while\npreserving covariates like age and sex. PSM ratios (2:1, 5:1, 10:1) were\napplied to assess sample size impact on model performance. The final dataset\nunderwent machine learning analysis with decision trees and cross-validation\nfor robust results. Results: Balancing sample sizes via PSM significantly\nimproved classification accuracy, ranging from 0.92 to 0.96 across ratios. This\napproach enabled precise risk identification even with limited samples.\nConclusion: Integrating data processing, harmonization, and balancing\ntechniques improves AD risk classification accuracy, offering potential for\nother neurodegenerative diseases.",
    "explanation":"This study implements a\ncomprehensive methodology that integrates signal processing, data harmonization, and\nstatistical techniques to increase sample size and improve the reliability of Alzheimer's disease\nrisk classification models.",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "Quantitative EEG analysis disease during resting and memory task in carriers and non-carriers of PS-1 E280A mutation of familial Alzheimer's"
    ],
    "b_abstract":[
      "Background: Alzheimer\u2019s disease is the most leading cause of dementia in world; mutation PS-1 E280A alters gene Presenilin-1 and causes an early onset familial disease. This has been found large kindred Antioquia, Colombia. The objective this study was to find differences revealed by electroencephalogram between healthy subjects asymptomatic carriers that can be used as clinical markers population. Methods: EEG recorded 15 non during resting a memory task using 64 channels amplifier. Two conditions were analyzed: encoding retrieval, process recording evocating information, respectively. Power spectrum calculated delta (0.5\u20134.0 Hz), theta (4.0\u20138. 0 alpha-1 (8.0\u201310.0 alpha-2 (10.0\u201313.0 beta (13.0\u201325.0 Hz) gamma (25.0\u201350 frequency bands for four regions interest. Changes evaluated different ANOVA analysis. Results: In condition significant decrease (p=0. 0001) increase frequencies (p=0.037) compare with controls. During significantly lower compared controls 008) comparing versus retrieval each group, there more synchronization carriers. Conclusion: Early changes observed recordings, it could use Also seems activate additional cortical order conserve successful cognitive functions before impairment ."
    ],
    "b_categories":[
      "q-bio.NC"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.06727"
    ],
    "c_title":[
      "Application of Artificial Intelligence (AI) in Civil Engineering"
    ],
    "c_abstract":[
      "Hard computing generally deals with precise data, which provides ideal\nsolutions to problems. However, in the civil engineering field, amongst other\ndisciplines, that is not always the case as real-world systems are continuously\nchanging. Here lies the need to explore soft computing methods and artificial\nintelligence to solve civil engineering shortcomings. The integration of\nadvanced computational models, including Artificial Neural Networks (ANNs),\nFuzzy Logic, Genetic Algorithms (GAs), and Probabilistic Reasoning, has\nrevolutionized the domain of civil engineering. These models have significantly\nadvanced diverse sub-fields by offering innovative solutions and improved\nanalysis capabilities. Sub-fields such as: slope stability analysis, bearing\ncapacity, water quality and treatment, transportation systems, air quality,\nstructural materials, etc. ANNs predict non-linearities and provide accurate\nestimates. Fuzzy logic uses an efficient decision-making process to provide a\nmore precise assessment of systems. Lastly, while GAs optimizes models (based\non evolutionary processes) for better outcomes, probabilistic reasoning lowers\ntheir statistical uncertainties."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.16728",
    "a_title":"Maximizing the Impact of Deep Learning on Subseasonal-to-Seasonal\n  Climate Forecasting: The Essential Role of Optimization",
    "a_abstract":"Weather and climate forecasting is vital for sectors such as agriculture and\ndisaster management. Although numerical weather prediction (NWP) systems have\nadvanced, forecasting at the subseasonal-to-seasonal (S2S) scale, spanning 2 to\n6 weeks, remains challenging due to the chaotic and sparse atmospheric signals\nat this interval. Even state-of-the-art deep learning models struggle to\noutperform simple climatology models in this domain. This paper identifies that\noptimization, instead of network structure, could be the root cause of this\nperformance gap, and then we develop a novel multi-stage optimization strategy\nto close the gap. Extensive empirical studies demonstrate that our multi-stage\noptimization approach significantly improves key skill metrics, PCC and TCC,\nwhile utilizing the same backbone structure, surpassing the state-of-the-art\nNWP systems (ECMWF-S2S) by over \\textbf{19-91\\%}. Our research contests the\nrecent study that direct forecasting outperforms rolling forecasting for S2S\ntasks. Through theoretical analysis, we propose that the underperformance of\nrolling forecasting may arise from the accumulation of Jacobian matrix products\nduring training. Our multi-stage framework can be viewed as a form of teacher\nforcing to address this issue. Code is available at\n\\url{https:\/\/anonymous.4open.science\/r\/Baguan-S2S-23E7\/}",
    "explanation":"Weather and climate forecasting is vital for sectors such\nas agriculture and disaster management. Although numeri-\ncal weather prediction (NWP) systems have advanced, fore-\ncasting at the subseasonal-to-seasonal (S2S) scale, span-\nning 2 to 6 weeks, remains challenging due to the chaotic\nand sparse atmospheric signals at this interval.",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "FuXi-S2S: An accurate machine learning model for global subseasonal forecasts"
    ],
    "b_abstract":[
      "Skillful subseasonal forecasts beyond 2 weeks are crucial for a wide range of applications across various sectors society. Recently, state-of-the-art machine learning based weather forecasting models have made significant advancements, outperforming the high-resolution forecast (HRES) from European Centre Medium-Range Weather Forecasts (ECMWF). However, full potential in has yet to be fully explored. In this study, we introduce FuXi Subseasonal-to-Seasonal (FuXi-S2S), model that provides global daily mean up 42 days, covering 5 upper-air atmospheric variables at 13 pressure levels and 11 surface variables. FuXi-S2S integrates an enhanced base with perturbation module flow-dependent perturbations hidden features, incorporates Perlin noise perturb initial conditions. The is developed using 72 years statistics ECMWF ERA5 reanalysis data. When compared (S2S) reforecasts, demonstrate superior deterministic ensemble total precipitation (TP), outgoing longwave radiation (OLR), geopotential 500 hPa (Z500). Although it shows slightly inferior performance predicting 2-meter temperature (T2M), clear advantages over land area. Regarding extreme forecasts, outperforms S2S globally TP. Furthermore, surpass reforecasts Madden Julian Oscillation (MJO), key source predictability. They extend skillful prediction MJO 30 days 36 days."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.01476"
    ],
    "c_title":[
      "Sparse identification of evolution equations via Bayesian model\n  selection"
    ],
    "c_abstract":[
      "The quantitative formulation of evolution equations is the backbone for\nprediction, control, and understanding of dynamical systems across diverse\nscientific fields. Besides deriving differential equations for dynamical\nsystems based on basic scientific reasoning or prior knowledge in recent times\na growing interest emerged to infer these equations purely from data. In this\narticle, we introduce a novel method for the sparse identification of nonlinear\ndynamical systems from observational data, based on the observation how the key\nchallenges of the quality of time derivatives and sampling rates influence this\nproblem. Our approach combines system identification based on thresholded least\nsquares minimization with additional error measures that account for both the\ndeviation between the model and the time derivative of the data, and the\nintegrated performance of the model in forecasting dynamics. Specifically, we\nintegrate a least squares error as well as the Wasserstein metric for estimated\nmodels and combine them within a Bayesian optimization framework to efficiently\ndetermine optimal hyperparameters for thresholding and weighting of the\ndifferent error norms. Additionally, we employ distinct regularization\nparameters for each differential equation in the system, enhancing the method's\nprecision and flexibility. We demonstrate the capabilities of our approach\nthrough applications to dynamical fMRI data and the prototypical example of a\nwake flow behind a cylinder. In the wake flow problem, our method identifies a\nsparse, accurate model that correctly captures transient dynamics, oscillation\nperiods, and phase information, outperforming existing methods. In the fMRI\nexample, we show how our approach extracts insights from a trained recurrent\nneural network, offering a novel avenue for explainable AI by inferring\ndifferential equations that capture potentially causal relationships."
    ],
    "c_categories":[
      [
        "physics.data-an"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.16728",
    "a_title":"Maximizing the Impact of Deep Learning on Subseasonal-to-Seasonal\n  Climate Forecasting: The Essential Role of Optimization",
    "a_abstract":"Weather and climate forecasting is vital for sectors such as agriculture and\ndisaster management. Although numerical weather prediction (NWP) systems have\nadvanced, forecasting at the subseasonal-to-seasonal (S2S) scale, spanning 2 to\n6 weeks, remains challenging due to the chaotic and sparse atmospheric signals\nat this interval. Even state-of-the-art deep learning models struggle to\noutperform simple climatology models in this domain. This paper identifies that\noptimization, instead of network structure, could be the root cause of this\nperformance gap, and then we develop a novel multi-stage optimization strategy\nto close the gap. Extensive empirical studies demonstrate that our multi-stage\noptimization approach significantly improves key skill metrics, PCC and TCC,\nwhile utilizing the same backbone structure, surpassing the state-of-the-art\nNWP systems (ECMWF-S2S) by over \\textbf{19-91\\%}. Our research contests the\nrecent study that direct forecasting outperforms rolling forecasting for S2S\ntasks. Through theoretical analysis, we propose that the underperformance of\nrolling forecasting may arise from the accumulation of Jacobian matrix products\nduring training. Our multi-stage framework can be viewed as a form of teacher\nforcing to address this issue. Code is available at\n\\url{https:\/\/anonymous.4open.science\/r\/Baguan-S2S-23E7\/}",
    "explanation":"Weather and climate forecasting is vital for sectors such\nas agriculture and disaster management. Although numeri-\ncal weather prediction (NWP) systems have advanced, fore-\ncasting at the subseasonal-to-seasonal (S2S) scale, span-\nning 2 to 6 weeks, remains challenging due to the chaotic\nand sparse atmospheric signals at this interval.",
    "b_id":[
      "b21"
    ],
    "b_title":[
      "Analysis methods for numerical weather prediction"
    ],
    "b_abstract":[
      "Abstract Bayesian probabilistic arguments are used to derive idealized equations for finding the best analysis numerical weather prediction. These compared with those from other published methods in light of physical characteristics NWP problem; namely predetermined nature basis analysis, need approximation because large\u2010order systems, underdeterminacy problem when using observations alone, and availability prior relationships resolve underdeterminacy. Prior result (1) knowledge time evolution model (which together use a distribution constitutes four\u2010dimensional data assimilation); (2) that atmosphere varies slowly (leading balance relationships); (3) nonlinear coupling parameters scales atmosphere. Methods discussed include variational techniques, smoothing splines, Kriging, optimal interpolation, successive corrections, constrained initialization, Kalman\u2010Bucy filter, adjoint assimilation. They all shown relate hence each other. Opinions given on particular might be more appropriate. By comparison method some insight is gained into appropriate choices practical methods."
    ],
    "b_categories":[
      "physics.data-an"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2501.07290"
    ],
    "c_title":[
      "Principles for Responsible AI Consciousness Research"
    ],
    "c_abstract":[
      "Recent research suggests that it may be possible to build conscious AI\nsystems now or in the near future. Conscious AI systems would arguably deserve\nmoral consideration, and it may be the case that large numbers of conscious\nsystems could be created and caused to suffer. Furthermore, AI systems or\nAI-generated characters may increasingly give the impression of being\nconscious, leading to debate about their moral status. Organisations involved\nin AI research must establish principles and policies to guide research and\ndeployment choices and public communication concerning consciousness. Even if\nan organisation chooses not to study AI consciousness as such, it will still\nneed policies in place, as those developing advanced AI systems risk\ninadvertently creating conscious entities. Responsible research and deployment\npractices are essential to address this possibility. We propose five principles\nfor responsible research and argue that research organisations should make\nvoluntary, public commitments to principles on these lines. Our principles\nconcern research objectives and procedures, knowledge sharing and public\ncommunications."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.02466",
    "a_title":"Weakly supervised deep learning model with size constraint for prostate\n  cancer detection in multiparametric MRI and generalization to unseen domains",
    "a_abstract":"Fully supervised deep models have shown promising performance for many\nmedical segmentation tasks. Still, the deployment of these tools in clinics is\nlimited by the very timeconsuming collection of manually expert-annotated data.\nMoreover, most of the state-ofthe-art models have been trained and validated on\nmoderately homogeneous datasets. It is known that deep learning methods are\noften greatly degraded by domain or label shifts and are yet to be built in\nsuch a way as to be robust to unseen data or label distributions. In the\nclinical setting, this problematic is particularly relevant as the deployment\ninstitutions may have different scanners or acquisition protocols than those\nfrom which the data has been collected to train the model. In this work, we\npropose to address these two challenges on the detection of clinically\nsignificant prostate cancer (csPCa) from bi-parametric MRI. We evaluate the\nmethod proposed by (Kervadec et al., 2018), which introduces a size constaint\nloss to produce fine semantic cancer lesions segmentations from weak circle\nscribbles annotations. Performance of the model is based on two public (PI-CAI\nand Prostate158) and one private databases. First, we show that the model\nachieves on-par performance with strong fully supervised baseline models, both\non in-distribution validation data and unseen test images. Second, we observe a\nperformance decrease for both fully supervised and weakly supervised models\nwhen tested on unseen data domains. This confirms the crucial need for\nefficient domain adaptation methods if deep learning models are aimed to be\ndeployed in a clinical environment. Finally, we show that ensemble predictions\nfrom multiple trainings increase generalization performance.",
    "explanation":"n this work, we propose to address these two challenges\non the detection of clinically significant prostate cancer (csPCa) from bi-parametric MRI.\nWe evaluate the method proposed by (Kervadec et al., 2018), which introduces a size con-\nstaint loss to produce fine semantic cancer lesions segmentations from weak circle scribbles\nannotations",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "A review of artificial intelligence in prostate cancer detection on imaging"
    ],
    "b_abstract":[
      "A multitude of studies have explored the role artificial intelligence (AI) in providing diagnostic support to radiologists, pathologists, and urologists prostate cancer detection, risk-stratification, management. This review provides a comprehensive overview relevant literature regarding use AI models (1) detecting on radiology images (magnetic resonance ultrasound imaging), (2) histopathology biopsy tissue, (3) assisting supporting tasks for detection (prostate gland segmentation, MRI-histopathology registration, MRI-ultrasound registration). We discuss both potential these assist clinical workflow diagnosis, as well current limitations including variability training data sets, algorithms, evaluation criteria. also ongoing challenges what is needed bridge gap between academic research commercial solutions that improve routine care."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.01834"
    ],
    "c_title":[
      "Intercellular contact is sufficient to drive Fibroblast to Myofibroblast\n  transitions"
    ],
    "c_abstract":[
      "Fibroblast cells play a key role in maintaining the extracellular matrix.\nDuring wound healing, fibroblasts differentiate into highly contractile\nmyofibroblasts, which secrete extracellular matrix proteins like collagen to\nfacilitate tissue repair. Under normal conditions, myofibroblasts undergo\nprogrammed cell death after healing to prevent excessive scar formation.\nHowever, in diseases like fibrosis, the myofibroblasts remain active even after\nthe wound is closed, resulting in excessive collagen buildup and a stiff,\nfibrotic matrix. The reasons for the persistence of myofibroblasts in fibrosis\nare not well understood. Here we show the existence of a mechanism where direct\nphysical contact between a fibroblast and a myofibroblast is sufficient for\nfibroblasts to transition into myofibroblasts. We show that\nfibroblast-myofibroblast transition can occur even in the absence of known\nbiochemical cues such as growth factor activation or mechanical cues from a\nstiff, fibrotic matrix. Further, we show that contact-based\nfibroblast-myofibroblast activation can be blocked by G{\\alpha}q\/11\/14\ninhibitor FR9003591, which inhibits the formation of myofibroblasts. These\nfindings offer new insights into the persistence of fibrosis despite\ntherapeutic interventions and suggest a potential strategy to target\nfibroblast-to-myofibroblast transition in fibrosis."
    ],
    "c_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.02466",
    "a_title":"Weakly supervised deep learning model with size constraint for prostate\n  cancer detection in multiparametric MRI and generalization to unseen domains",
    "a_abstract":"Fully supervised deep models have shown promising performance for many\nmedical segmentation tasks. Still, the deployment of these tools in clinics is\nlimited by the very timeconsuming collection of manually expert-annotated data.\nMoreover, most of the state-ofthe-art models have been trained and validated on\nmoderately homogeneous datasets. It is known that deep learning methods are\noften greatly degraded by domain or label shifts and are yet to be built in\nsuch a way as to be robust to unseen data or label distributions. In the\nclinical setting, this problematic is particularly relevant as the deployment\ninstitutions may have different scanners or acquisition protocols than those\nfrom which the data has been collected to train the model. In this work, we\npropose to address these two challenges on the detection of clinically\nsignificant prostate cancer (csPCa) from bi-parametric MRI. We evaluate the\nmethod proposed by (Kervadec et al., 2018), which introduces a size constaint\nloss to produce fine semantic cancer lesions segmentations from weak circle\nscribbles annotations. Performance of the model is based on two public (PI-CAI\nand Prostate158) and one private databases. First, we show that the model\nachieves on-par performance with strong fully supervised baseline models, both\non in-distribution validation data and unseen test images. Second, we observe a\nperformance decrease for both fully supervised and weakly supervised models\nwhen tested on unseen data domains. This confirms the crucial need for\nefficient domain adaptation methods if deep learning models are aimed to be\ndeployed in a clinical environment. Finally, we show that ensemble predictions\nfrom multiple trainings increase generalization performance.",
    "explanation":"n this work, we propose to address these two challenges\non the detection of clinically significant prostate cancer (csPCa) from bi-parametric MRI.\nWe evaluate the method proposed by (Kervadec et al., 2018), which introduces a size con-\nstaint loss to produce fine semantic cancer lesions segmentations from weak circle scribbles\nannotations",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "Automatic Prostate Cancer Detection On Multi-Parametric Mri With Hierarchical Weakly Supervised Learning"
    ],
    "b_abstract":[
      "Multi-parametric MRI (mp-MRI) is one of the most commonly used non-invasive methods for prostate cancer (PCa) diagnosis. In recent years, computer aided diagnosis (CAD) PCa on mp-MRI based deep learning techniques has gained much attention and shown promising progress. The key success to obtain a large amount high quality region annotation such that network can accurately learn variation lesions. order precisely annotate mp-MRI, pathological whole mount data patient normally required as reference, which often difficult in real world clinical situations. Therefore, we are motivated propose new method integrate different levels information available screening workflow through multitask hierarchical weakly supervised framework detection mp-MRI. Experimental results show our achieves segmentation results."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2503.04261"
    ],
    "c_title":[
      "VirtualXAI: A User-Centric Framework for Explainability Assessment\n  Leveraging GPT-Generated Personas"
    ],
    "c_abstract":[
      "In today's data-driven era, computational systems generate vast amounts of\ndata that drive the digital transformation of industries, where Artificial\nIntelligence (AI) plays a key role. Currently, the demand for eXplainable AI\n(XAI) has increased to enhance the interpretability, transparency, and\ntrustworthiness of AI models. However, evaluating XAI methods remains\nchallenging: existing evaluation frameworks typically focus on quantitative\nproperties such as fidelity, consistency, and stability without taking into\naccount qualitative characteristics such as satisfaction and interpretability.\nIn addition, practitioners face a lack of guidance in selecting appropriate\ndatasets, AI models, and XAI methods -a major hurdle in human-AI collaboration.\nTo address these gaps, we propose a framework that integrates quantitative\nbenchmarking with qualitative user assessments through virtual personas based\non the \"Anthology\" of backstories of the Large Language Model (LLM). Our\nframework also incorporates a content-based recommender system that leverages\ndataset-specific characteristics to match new input data with a repository of\nbenchmarked datasets. This yields an estimated XAI score and provides tailored\nrecommendations for both the optimal AI model and the XAI method for a given\nscenario."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.02614",
    "a_title":"Divergent Domains, Convergent Grading: Enhancing Generalization in\n  Diabetic Retinopathy Grading",
    "a_abstract":"Diabetic Retinopathy (DR) constitutes 5% of global blindness cases. While\nnumerous deep learning approaches have sought to enhance traditional DR grading\nmethods, they often falter when confronted with new out-of-distribution data\nthereby impeding their widespread application. In this study, we introduce a\nnovel deep learning method for achieving domain generalization (DG) in DR\ngrading and make the following contributions. First, we propose a new way of\ngenerating image-to-image diagnostically relevant fundus augmentations\nconditioned on the grade of the original fundus image. These augmentations are\ntailored to emulate the types of shifts in DR datasets thus increase the\nmodel's robustness. Second, we address the limitations of the standard\nclassification loss in DG for DR fundus datasets by proposing a new DG-specific\nloss, domain alignment loss; which ensures that the feature vectors from all\ndomains corresponding to the same class converge onto the same manifold for\nbetter domain generalization. Third, we tackle the coupled problem of data\nimbalance across DR domains and classes by proposing to employ Focal loss which\nseamlessly integrates with our new alignment loss. Fourth, due to inevitable\nobserver variability in DR diagnosis that induces label noise, we propose\nleveraging self-supervised pretraining. This approach ensures that our DG model\nremains robust against early susceptibility to label noise, even when only a\nlimited dataset of non-DR fundus images is available for pretraining. Our\nmethod demonstrates significant improvements over the strong Empirical Risk\nMinimization baseline and other recently proposed state-of-the-art DG methods\nfor DR grading. Code is available at https:\/\/github.com\/sharonchokuwa\/dg-adr.",
    "explanation":"In this study, we introduce a novel deep learning\nmethod for achieving domain generalization (DG) in DR\ngrading and make the following contributions.",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "Medical diffusion on a budget: textual inversion for medical image generation"
    ],
    "b_abstract":[
      "Diffusion-based models for text-to-image generation have gained immense popularity due to recent advancements in efficiency, accessibility, and quality. Although it is becoming increasingly feasible perform inference with these systems using consumer-grade GPUs, training them from scratch still requires access large datasets significant computational resources. In the case of medical image generation, availability large, publicly accessible that include text reports limited legal ethical concerns. While a diffusion model on private dataset may address this issue, not always institutions lacking necessary This work demonstrates pre-trained Stable Diffusion models, originally trained natural images, can be adapted various imaging modalities by embeddings textual inversion. study, we conducted experiments comprising only 100 samples three modalities. Embeddings were matter hours, while retaining diagnostic relevance generation. Experiments designed achieve several objectives. Firstly, fine-tuned processes inversion, revealing larger more examples are required. Secondly, validated our approach demonstrating 2\\% increase accuracy (AUC) detecting prostate cancer MRI, which challenging multi-modal modality, 0.78 0.80. Thirdly, performed simulations interpolating between healthy diseased states, combining multiple pathologies, inpainting show embedding flexibility control disease appearance. Finally, study small (less than 1 MB), facilitates easy sharing data reduced privacy"
    ],
    "b_categories":[
      "q-bio.OT"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.04686"
    ],
    "c_title":[
      "Learning Strategic Language Agents in the Werewolf Game with Iterative\n  Latent Space Policy Optimization"
    ],
    "c_abstract":[
      "Large language model (LLM)-based agents have recently shown impressive\nprogress in a variety of domains, including open-ended conversation and\nmulti-step decision-making. However, applying these agents to social deduction\ngames such as Werewolf, which requires both strategic decision-making and\nfree-form language interaction, remains non-trivial. Traditional methods based\non Counterfactual Regret Minimization (CFR) or reinforcement learning (RL)\ntypically depend on a predefined action space, making them unsuitable for\nlanguage games with unconstrained text action space. Meanwhile, pure LLM-based\nagents often suffer from intrinsic biases and require prohibitively large\ndatasets for fine-tuning. We propose Latent Space Policy Optimization (LSPO),\nan iterative framework that addresses these challenges by first mapping\nfree-form text to a discrete latent space, where methods like CFR and RL can\nlearn strategic policy more effectively. We then translate the learned policy\nback into natural language dialogues, which are used to fine-tune an LLM via\nDirect Preference Optimization (DPO). By iteratively alternating between these\nstages, our LSPO agent progressively enhances both strategic reasoning and\nlanguage communication. Experiment results on the Werewolf game show that our\nmethod improves the agent's performance in each iteration and outperforms\nexisting Werewolf agents, underscoring its promise for free-form language\ndecision-making."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.02614",
    "a_title":"Divergent Domains, Convergent Grading: Enhancing Generalization in\n  Diabetic Retinopathy Grading",
    "a_abstract":"Diabetic Retinopathy (DR) constitutes 5% of global blindness cases. While\nnumerous deep learning approaches have sought to enhance traditional DR grading\nmethods, they often falter when confronted with new out-of-distribution data\nthereby impeding their widespread application. In this study, we introduce a\nnovel deep learning method for achieving domain generalization (DG) in DR\ngrading and make the following contributions. First, we propose a new way of\ngenerating image-to-image diagnostically relevant fundus augmentations\nconditioned on the grade of the original fundus image. These augmentations are\ntailored to emulate the types of shifts in DR datasets thus increase the\nmodel's robustness. Second, we address the limitations of the standard\nclassification loss in DG for DR fundus datasets by proposing a new DG-specific\nloss, domain alignment loss; which ensures that the feature vectors from all\ndomains corresponding to the same class converge onto the same manifold for\nbetter domain generalization. Third, we tackle the coupled problem of data\nimbalance across DR domains and classes by proposing to employ Focal loss which\nseamlessly integrates with our new alignment loss. Fourth, due to inevitable\nobserver variability in DR diagnosis that induces label noise, we propose\nleveraging self-supervised pretraining. This approach ensures that our DG model\nremains robust against early susceptibility to label noise, even when only a\nlimited dataset of non-DR fundus images is available for pretraining. Our\nmethod demonstrates significant improvements over the strong Empirical Risk\nMinimization baseline and other recently proposed state-of-the-art DG methods\nfor DR grading. Code is available at https:\/\/github.com\/sharonchokuwa\/dg-adr.",
    "explanation":"In this study, we introduce a novel deep learning\nmethod for achieving domain generalization (DG) in DR\ngrading and make the following contributions.",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Deep Learning Techniques for Diabetic Retinopathy Classification: A Survey"
    ],
    "b_abstract":[
      "Diabetic Retinopathy (DR) is a degenerative disease that impacts the eyes and consequence of Diabetes mellitus, where high blood glucose levels induce lesions on eye retina.Diabetic regarded as leading cause blindness for diabetic patients, especially working-age population in developing nations.Treatment involves sustaining patient's current grade vision since irreversible.Early detection crucial order to sustain effectively.The main issue involved with DR manual diagnosis process very time, money, effort consuming an ophthalmologist's examination retinal fundus images.The latter also proves be more difficult, particularly early stages when features are less prominent images.Machine learning-based medical image analysis has proven competency assessing images, utilization deep learning algorithms aided (DR).This paper reviews analyzes state-of-the-art methods supervised, self-supervised, Vision Transformer setups, proposing classification detection.For instance, referable, non-referable, proliferative classifications reviewed summarized.Moreover, discusses available datasets used tasks such detection, classification, segmentation.The assesses research gaps area detection\/classification addresses various challenges need further study investigation."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.14929"
    ],
    "c_title":[
      "Cytogenetic, Hematobiochemical, and Histopathological Assessment of\n  Albino Rats (Rattus norvegicus) Fed on Gluten Extracts"
    ],
    "c_abstract":[
      "Background: Literature shows that most of the information on the toxicity of\ngluten is generated from survey and observational studies, resulting in\ninconsistent outcomes and a decrease in the acceptability of gluten-rich foods.\nTo determine gluten's safety, an in-depth in vitro and in vivo toxicological\nexamination is required. This enables scientists to come up with ameliorative\nstrategies if it turns out to have side effects, and consumers' trust can be\nrestored. Objectives: The objective of this study was to assess the toxicity of\ngluten extracts on albino rats (Rattus norvegicus). Materials and Methods:\nTwenty-four rats were randomly selected and divided into four groups, each\ncomprising six rats. Group 1 (control) rats were fed on pellet feeds and groups\n2, 3, and 4 were fed on daily dosages of 0.5, 1.0, and 1.5 g gluten extracts,\nrespectively. The rats' body weights and reactions were observed for 90 days\nbefore blood samples were collected for hematobiochemical and micronucleus\ntests. Histopathological examinations of the liver and kidneys were also\nperformed. Results: There was no difference (P > 0.05) in body weight, blood\nglucose level, or micronuclei between the control and treated rats. The\nlymphocytes, alkaline phosphatase, alanine transaminase, total protein, and\ncalcium ions of the test rats were all significantly (P < 0.05) altered but\nremained within the normal ranges. Other hematobiochemical parameters,\nincluding packed cell volume, hemoglobin, white and red blood cells, aspartate\ntransaminase, albumin, sodium ions, potassium ions, chloride ions, and urea,\nrevealed no marked changes. The treated rats' livers and kidneys showed no\nhistopathological changes. Conclusion: Gluten had no adverse effects. However,\nit altered hematobiochemical parameters, particularly the lymphocytes, alkaline\nphosphatase, alanine transaminase, total protein, and calcium ions."
    ],
    "c_categories":[
      [
        "q-bio.OT"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.18767",
    "a_title":"Multi-Task Learning for Integrated Automated Contouring and Voxel-Based\n  Dose Prediction in Radiotherapy",
    "a_abstract":"Deep learning-based automated contouring and treatment planning has been\nproven to improve the efficiency and accuracy of radiotherapy. However,\nconventional radiotherapy treatment planning process has the automated\ncontouring and treatment planning as separate tasks. Moreover in deep learning\n(DL), the contouring and dose prediction tasks for automated treatment planning\nare done independently. In this study, we applied the multi-task learning (MTL)\napproach in order to seamlessly integrate automated contouring and voxel-based\ndose prediction tasks, as MTL can leverage common information between the two\ntasks and be able able to increase the efficiency of the automated tasks. We\ndeveloped our MTL framework using the two datasets: in-house prostate cancer\ndataset and the publicly available head and neck cancer dataset, OpenKBP.\nCompared to the sequential DL contouring and treatment planning tasks, our\nproposed method using MTL improved the mean absolute difference of dose volume\nhistogram metrics of prostate and head and neck sites by 19.82% and 16.33%,\nrespectively. Our MTL model for automated contouring and dose prediction tasks\ndemonstrated enhanced dose prediction performance while maintaining or\nsometimes even improving the contouring accuracy. Compared to the baseline\nautomated contouring model with the dice score coefficients of 0.818 for\nprostate and 0.674 for head and neck datasets, our MTL approach achieved\naverage scores of 0.824 and 0.716 for these datasets, respectively. Our study\nhighlights the potential of the proposed automated contouring and planning\nusing MTL to support the development of efficient and accurate automated\ntreatment planning for radiotherapy.",
    "explanation":"Deep learning-based automated contouring and treatment planning has\nbeen proven to improve the efficiency and accuracy of radiotherapy.",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "A Transformer-Embedded Multi-Task Model for Dose Distribution Prediction"
    ],
    "b_abstract":[
      "Radiation therapy is a fundamental cancer treatment in the clinic. However, to satisfy clinical requirements, radiologists have iteratively adjust radiotherapy plan based on experience, causing it extremely subjective and time-consuming obtain clinically acceptable plan. To this end, we introduce transformer-embedded multi-task dose prediction (TransMTDP) network automatically predict distribution radiotherapy. Specifically, achieve more stable accurate predictions, three highly correlated tasks are included our TransMTDP network, i.e. main task provide each pixel with fine-grained value, an auxiliary isodose lines produce coarse-grained ranges, gradient learn subtle information such as radiation patterns edges maps. The integrated through shared encoder, following learning strategy. strengthen connection of output layers for different tasks, further use two additional constraints, consistency loss loss, reinforce match between features generated by task. Additionally, considering many organs human body symmetrical maps present abundant global features, embed transformer into framework capture long-range dependencies Evaluated in-house rectum dataset public head neck dataset, method gains superior performance compared state-of-the-art ones. Code available at https:\/\/github.com\/luuuwen\/TransMTDP."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.03001"
    ],
    "c_title":[
      "Multicellular self-organization in Escherichia coli"
    ],
    "c_abstract":[
      "Escherichia coli has long been a trusty companion, maintaining health in our\nguts and advancing biological knowledge in the laboratory. In light of recent\nfindings, we discuss multicellular self-organization in E. coli and develop\ngeneral ideas for multicellularity, including the necessity for multicellular\ndynamics and interpretation by dynamic graphs, applicable to both unicellular\nand multicellular organisms. In this context, we next discuss the documented\nbehaviors of E. coli self-organization (rosette formation, multicellular\nextension, and attached dormancy) and two potential behaviors (internal\ncommunication and mating). Finally, by comparing the dynamic graphs for\ndifferent communities, we develop principles relevant to the theory of\nmulticellularity."
    ],
    "c_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.18767",
    "a_title":"Multi-Task Learning for Integrated Automated Contouring and Voxel-Based\n  Dose Prediction in Radiotherapy",
    "a_abstract":"Deep learning-based automated contouring and treatment planning has been\nproven to improve the efficiency and accuracy of radiotherapy. However,\nconventional radiotherapy treatment planning process has the automated\ncontouring and treatment planning as separate tasks. Moreover in deep learning\n(DL), the contouring and dose prediction tasks for automated treatment planning\nare done independently. In this study, we applied the multi-task learning (MTL)\napproach in order to seamlessly integrate automated contouring and voxel-based\ndose prediction tasks, as MTL can leverage common information between the two\ntasks and be able able to increase the efficiency of the automated tasks. We\ndeveloped our MTL framework using the two datasets: in-house prostate cancer\ndataset and the publicly available head and neck cancer dataset, OpenKBP.\nCompared to the sequential DL contouring and treatment planning tasks, our\nproposed method using MTL improved the mean absolute difference of dose volume\nhistogram metrics of prostate and head and neck sites by 19.82% and 16.33%,\nrespectively. Our MTL model for automated contouring and dose prediction tasks\ndemonstrated enhanced dose prediction performance while maintaining or\nsometimes even improving the contouring accuracy. Compared to the baseline\nautomated contouring model with the dice score coefficients of 0.818 for\nprostate and 0.674 for head and neck datasets, our MTL approach achieved\naverage scores of 0.824 and 0.716 for these datasets, respectively. Our study\nhighlights the potential of the proposed automated contouring and planning\nusing MTL to support the development of efficient and accurate automated\ntreatment planning for radiotherapy.",
    "explanation":"Deep learning-based automated contouring and treatment planning has\nbeen proven to improve the efficiency and accuracy of radiotherapy.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Clinical integration of machine learning for curative-intent radiation treatment of patients with prostate cancer"
    ],
    "b_abstract":[
      "Machine learning (ML) holds great promise for impacting healthcare delivery; however, to date most methods are tested in \u2018simulated\u2019 environments that cannot recapitulate factors influencing real-world clinical practice. We prospectively deployed and evaluated a random forest algorithm for therapeutic curative-intent radiation therapy (RT) treatment planning for prostate cancer in a blinded, head-to-head study with full integration into the clinical workflow. ML- and human-generated RT treatment plans were directly compared in a retrospective simulation with retesting (n\u2009=\u200950) and a prospective clinical deployment (n\u2009=\u200950) phase. Consistently throughout the study phases, treating physicians assessed ML- and human-generated RT treatment plans in a blinded manner following a priori defined standardized criteria and peer review processes, with the selected RT plan in the prospective phase delivered for patient treatment. Overall, 89% of ML-generated RT plans were considered clinically acceptable and 72% were selected over human-generated RT plans in head-to-head comparisons. RT planning using ML reduced the median time required for the entire RT planning process by 60.1% (118 to 47\u2009h). While ML RT plan acceptability remained stable between the simulation and deployment phases (92 versus 86%), the number of ML RT plans selected for treatment was significantly reduced (83 versus 61%, respectively). These findings highlight that retrospective or simulated evaluation of ML methods, even under expert blinded review, may not be representative of algorithm acceptance in a real-world clinical setting when patient care is at stake."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.04686"
    ],
    "c_title":[
      "Learning Strategic Language Agents in the Werewolf Game with Iterative\n  Latent Space Policy Optimization"
    ],
    "c_abstract":[
      "Large language model (LLM)-based agents have recently shown impressive\nprogress in a variety of domains, including open-ended conversation and\nmulti-step decision-making. However, applying these agents to social deduction\ngames such as Werewolf, which requires both strategic decision-making and\nfree-form language interaction, remains non-trivial. Traditional methods based\non Counterfactual Regret Minimization (CFR) or reinforcement learning (RL)\ntypically depend on a predefined action space, making them unsuitable for\nlanguage games with unconstrained text action space. Meanwhile, pure LLM-based\nagents often suffer from intrinsic biases and require prohibitively large\ndatasets for fine-tuning. We propose Latent Space Policy Optimization (LSPO),\nan iterative framework that addresses these challenges by first mapping\nfree-form text to a discrete latent space, where methods like CFR and RL can\nlearn strategic policy more effectively. We then translate the learned policy\nback into natural language dialogues, which are used to fine-tune an LLM via\nDirect Preference Optimization (DPO). By iteratively alternating between these\nstages, our LSPO agent progressively enhances both strategic reasoning and\nlanguage communication. Experiment results on the Werewolf game show that our\nmethod improves the agent's performance in each iteration and outperforms\nexisting Werewolf agents, underscoring its promise for free-form language\ndecision-making."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.10004",
    "a_title":"EyeDiff: text-to-image diffusion model improves rare eye disease\n  diagnosis",
    "a_abstract":"The rising prevalence of vision-threatening retinal diseases poses a\nsignificant burden on the global healthcare systems. Deep learning (DL) offers\na promising solution for automatic disease screening but demands substantial\ndata. Collecting and labeling large volumes of ophthalmic images across various\nmodalities encounters several real-world challenges, especially for rare\ndiseases. Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and\nevaluate its applicability in diagnosing common and rare diseases. EyeDiff is\ntrained on eight large-scale datasets using the advanced latent diffusion\nmodel, covering 14 ophthalmic image modalities and over 80 ocular diseases, and\nis adapted to ten multi-country external datasets. The generated images\naccurately capture essential lesional characteristics, achieving high alignment\nwith text prompts as evaluated by objective metrics and human experts.\nFurthermore, integrating generated images significantly enhances the accuracy\nof detecting minority classes and rare eye diseases, surpassing traditional\noversampling methods in addressing data imbalance. EyeDiff effectively tackles\nthe issue of data imbalance and insufficiency typically encountered in rare\ndiseases and addresses the challenges of collecting large-scale annotated\nimages, offering a transformative solution to enhance the development of\nexpert-level diseases diagnosis models in ophthalmic field.",
    "explanation":"Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and evaluate its\napplicability in diagnosing common and rare diseases.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Artificial Intelligence for Pediatric Ophthalmology"
    ],
    "b_abstract":[
      "PURPOSE OF REVIEW: Despite the impressive results of recent artificial\nintelligence (AI) applications to general ophthalmology, comparatively less\nprogress has been made toward solving problems in pediatric ophthalmology using\nsimilar techniques. This article discusses the unique needs of pediatric\nophthalmology patients and how AI techniques can address these challenges,\nsurveys recent applications of AI to pediatric ophthalmology, and discusses\nfuture directions in the field.\n  RECENT FINDINGS: The most significant advances involve the automated\ndetection of retinopathy of prematurity (ROP), yielding results that rival\nexperts. Machine learning (ML) has also been successfully applied to the\nclassification of pediatric cataracts, prediction of post-operative\ncomplications following cataract surgery, detection of strabismus and\nrefractive error, prediction of future high myopia, and diagnosis of reading\ndisability via eye tracking. In addition, ML techniques have been used for the\nstudy of visual development, vessel segmentation in pediatric fundus images,\nand ophthalmic image synthesis.\n  SUMMARY: AI applications could significantly benefit clinical care for\npediatric ophthalmology patients by optimizing disease detection and grading,\nbroadening access to care, furthering scientific discovery, and improving\nclinical efficiency. These methods need to match or surpass physician\nperformance in clinical trials before deployment with patients. Due to\nwidespread use of closed-access data sets and software implementations, it is\ndifficult to directly compare the performance of these approaches, and\nreproducibility is poor. Open-access data sets and software implementations\ncould alleviate these issues, and encourage further AI applications to\npediatric ophthalmology.\n  KEYWORDS: pediatric ophthalmology, machine learning, artificial intelligence,\ndeep learning"
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.03661"
    ],
    "c_title":[
      "Bridging high resolution sub-cellular imaging with physiologically\n  relevant engineered tissues"
    ],
    "c_abstract":[
      "While high-resolution microscopic techniques are crucial for studying\ncellular structures in cell biology, obtaining such images from thick 3D\nengineered tissues remains challenging. In this review, we explore advancements\nin fluorescence microscopy, alongside the use of various fluorescent probes and\nmaterial processing techniques to address these challenges. We navigate through\nthe diverse array of imaging options available in tissue engineering field,\nfrom wide field to super-resolution microscopy, so researchers can make more\ninformed decisions based on the specific tissue and cellular structures of\ninterest. Finally, we provide some recent examples of how traditional\nlimitations on obtaining high-resolution images on sub-cellular architecture\nwithin 3D tissues have been overcome by combining imaging advancements with\ninnovative tissue engineering approaches."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.10004",
    "a_title":"EyeDiff: text-to-image diffusion model improves rare eye disease\n  diagnosis",
    "a_abstract":"The rising prevalence of vision-threatening retinal diseases poses a\nsignificant burden on the global healthcare systems. Deep learning (DL) offers\na promising solution for automatic disease screening but demands substantial\ndata. Collecting and labeling large volumes of ophthalmic images across various\nmodalities encounters several real-world challenges, especially for rare\ndiseases. Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and\nevaluate its applicability in diagnosing common and rare diseases. EyeDiff is\ntrained on eight large-scale datasets using the advanced latent diffusion\nmodel, covering 14 ophthalmic image modalities and over 80 ocular diseases, and\nis adapted to ten multi-country external datasets. The generated images\naccurately capture essential lesional characteristics, achieving high alignment\nwith text prompts as evaluated by objective metrics and human experts.\nFurthermore, integrating generated images significantly enhances the accuracy\nof detecting minority classes and rare eye diseases, surpassing traditional\noversampling methods in addressing data imbalance. EyeDiff effectively tackles\nthe issue of data imbalance and insufficiency typically encountered in rare\ndiseases and addresses the challenges of collecting large-scale annotated\nimages, offering a transformative solution to enhance the development of\nexpert-level diseases diagnosis models in ophthalmic field.",
    "explanation":"Here, we introduce EyeDiff, a text-to-image model designed to\ngenerate multimodal ophthalmic images from natural language prompts and evaluate its\napplicability in diagnosing common and rare diseases.",
    "b_id":[
      "b7"
    ],
    "b_title":[
      "Classification of Retinal Diseases in Optical Coherence Tomography Images Using Artificial Intelligence and Firefly Algorithm"
    ],
    "b_abstract":[
      "In recent years, the number of studies for automatic diagnosis biomedical diseases has increased. Many these have used Deep Learning, which gives extremely good results but requires a vast amount data and computing load. If processor is insufficient quality, this takes time places an excessive load on processor. On other hand, Machine Learning faster than does not much-needed load, it provide as high accuracy value Learning. Therefore, our goal to develop hybrid system that provides value, while requiring smaller less diagnose such retinal we chose study. For purpose, first, layer extraction was conducted through image preprocessing. Then, traditional feature extractors were combined with pre-trained extractors. To select best features, Firefly algorithm. end, multiple binary classifications instead multiclass classification classifiers. Two public datasets in The first dataset had mean 0.957, second 0.954."
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.10197"
    ],
    "c_title":[
      "MathConstruct: Challenging LLM Reasoning with Constructive Proofs"
    ],
    "c_abstract":[
      "While Large Language Models (LLMs) demonstrate impressive performance in\nmathematics, existing math benchmarks come with significant limitations. Many\nfocus on problems with fixed ground-truth answers, and are often saturated due\nto problem simplicity or the viability of guessing or memorization. Crucially,\nthey capture only a narrow subset of relevant math problems. To address this\nresearch gap, we introduce \\mc, a new benchmark of 126 challenging problems\nsourced from various math competitions, which targets constructive proofs, a\nwidely encountered problem type requiring the construction of mathematical\nobjects with specific properties. These proofs are particularly suitable for\nLLM evaluation, as solution correctness can be easily verified. Our automated\nverifiers also enable MathConstruct to generate problem variations, used to\nevaluate robustness. State-of-the-art LLMs solve only 54% of MathConstruct\nproblems, highlighting its complexity and importance for LLM evaluation."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.01375",
    "a_title":"Scaling Laws with Hidden Structure",
    "a_abstract":"Statistical learning in high-dimensional spaces is challenging without a\nstrong underlying data structure. Recent advances with foundational models\nsuggest that text and image data contain such hidden structures, which help\nmitigate the curse of dimensionality. Inspired by results from nonparametric\nstatistics, we hypothesize that this phenomenon can be partially explained in\nterms of decomposition of complex tasks into simpler subtasks. In this paper,\nwe present a controlled experimental framework to test whether neural networks\ncan indeed exploit such ``hidden factorial structures.'' We find that they do\nleverage these latent patterns to learn discrete distributions more\nefficiently, and derive scaling laws linking model sizes, hidden\nfactorizations, and accuracy. We also study the interplay between our\nstructural assumptions and the models' capacity for generalization.",
    "explanation":"The key references I chose in Task 3 combined the concepts of Neural Networks with Discrete Distribution Theory to support this IDR paper. In the abstract, the following lines describe the integration of those selected references:\n\"In this paper, we present a controlled experimental framework to test whether neural networks can indeed exploit such \u201chidden factorial structures.\u201d\n\"We find that they do leverage these latent patterns to learn discrete distributions more efficiently. \"\n\n",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "Learning Parities with Neural Networks"
    ],
    "b_abstract":[
      "In recent years we see a rapidly growing line of research which shows learnability various models via common neural network algorithms. Yet, besides very few outliers, these results show that can be learned using linear methods. Namely, such learning neural-networks with gradient-descent is competitive classifier on top data-independent representation the examples. This leaves much to desired, as networks are far more successful than Furthermore, conceptual level, don't seem capture deepness deep networks. this paper make step towards showing leanability inherently non-linear. We under certain distributions, sparse parities learnable gradient decent depth-two network. On other hand, same cannot efficiently by"
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.05908"
    ],
    "c_title":[
      "MCMC for multi-modal distributions"
    ],
    "c_abstract":[
      "We explain the fundamental challenges of sampling from multimodal\ndistributions, particularly for high-dimensional problems. We present the major\ntypes of MCMC algorithms that are designed for this purpose, including parallel\ntempering, mode jumping and Wang-Landau, as well as several state-of-the-art\napproaches that have recently been proposed. We demonstrate these methods using\nboth synthetic and real-world examples of multimodal distributions with\ndiscrete or continuous state spaces."
    ],
    "c_categories":[
      [
        "stat.CO"
      ]
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.01375",
    "a_title":"Scaling Laws with Hidden Structure",
    "a_abstract":"Statistical learning in high-dimensional spaces is challenging without a\nstrong underlying data structure. Recent advances with foundational models\nsuggest that text and image data contain such hidden structures, which help\nmitigate the curse of dimensionality. Inspired by results from nonparametric\nstatistics, we hypothesize that this phenomenon can be partially explained in\nterms of decomposition of complex tasks into simpler subtasks. In this paper,\nwe present a controlled experimental framework to test whether neural networks\ncan indeed exploit such ``hidden factorial structures.'' We find that they do\nleverage these latent patterns to learn discrete distributions more\nefficiently, and derive scaling laws linking model sizes, hidden\nfactorizations, and accuracy. We also study the interplay between our\nstructural assumptions and the models' capacity for generalization.",
    "explanation":"The key references I chose in Task 3 combined the concepts of Neural Networks with Discrete Distribution Theory to support this IDR paper. In the abstract, the following lines describe the integration of those selected references:\n\"In this paper, we present a controlled experimental framework to test whether neural networks can indeed exploit such \u201chidden factorial structures.\u201d\n\"We find that they do leverage these latent patterns to learn discrete distributions more efficiently. \"\n\n",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "Testing conditional independence of discrete distributions"
    ],
    "b_abstract":[
      "We study the problem of testing *conditional independence* for discrete distributions. Specifically, given samples from a random variable (X, Y, Z) on domain [\u21131]\u00d7[\u21132] \u00d7 [n], we want to distinguish, with probability at least 2\/3, between case that X and Y are conditionally independent Z is \u0454-far, in \u21131-distance, every distribution has this property. Conditional independence concept central importance statistics important applications various scientific domains. As such, statistical task conditional been extensively studied forms within econometrics community nearly century. Perhaps surprisingly, not previously considered framework property particular no tester *sublinear* sample complexity known, even special domains binary."
    ],
    "b_categories":[
      "stat.CO"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2502.12555"
    ],
    "c_title":[
      "Warm Starting of CMA-ES for Contextual Optimization Problems"
    ],
    "c_abstract":[
      "Several practical applications of evolutionary computation possess objective\nfunctions that receive the design variables and externally given parameters.\nSuch problems are termed contextual optimization problems. These problems\nrequire finding the optimal solutions corresponding to the given context\nvectors. Existing contextual optimization methods train a policy model to\npredict the optimal solution from context vectors. However, the performance of\nsuch models is limited by their representation ability. By contrast, warm\nstarting methods have been used to initialize evolutionary algorithms on a\ngiven problem using the optimization results on similar problems. Because warm\nstarting methods do not consider the context vectors, their performances can be\nimproved on contextual optimization problems. Herein, we propose a covariance\nmatrix adaptation evolution strategy with contextual warm starting (CMA-ES-CWS)\nto efficiently optimize the contextual optimization problem with a given\ncontext vector. The CMA-ES-CWS utilizes the optimization results of past\ncontext vectors to train the multivariate Gaussian process regression.\nSubsequently, the CMA-ES-CWS performs warm starting for a given context vector\nby initializing the search distribution using posterior distribution of the\nGaussian process regression. The results of the numerical simulation suggest\nthat CMA-ES-CWS outperforms the existing contextual optimization and warm\nstarting methods."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2412.00544",
    "a_title":"RoBo6: Standardized MMT Light Curve Dataset for Rocket Body\n  Classification",
    "a_abstract":"Space debris presents a critical challenge for the sustainability of future\nspace missions, emphasizing the need for robust and standardized identification\nmethods. However, a comprehensive benchmark for rocket body classification\nremains absent. This paper addresses this gap by introducing the RoBo6 dataset\nfor rocket body classification based on light curves. The dataset, derived from\nthe Mini Mega Tortora database, includes light curves for six rocket body\nclasses: CZ-3B, Atlas 5 Centaur, Falcon 9, H-2A, Ariane 5, and Delta 4. With\n5,676 training and 1,404 test samples, it addresses data inconsistencies using\nresampling, normalization, and filtering techniques. Several machine learning\nmodels were evaluated, including CNN and transformer-based approaches, with\nAstroconformer reporting the best performance. The dataset establishes a common\nbenchmark for future comparisons and advancements in rocket body classification\ntasks.",
    "explanation":"The selected references in Task 3 were based from the following topics introduced in the abstract:\n\n\"Space debris presents a critical challenge for the sustainability of future space missions, emphasizing the need for robust and standardized identification methods.\"\n\"Several machine learning models were evaluated, including\nCNN and transformer-based approaches, with  Astroconformer reporting the best performance\"",
    "b_id":[
      "b10"
    ],
    "b_title":[
      "Attention Is All You Need"
    ],
    "b_abstract":[
      "The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. best performing also connect the encoder and decoder through attention mechanism. We propose a new simple network architecture, Transformer, solely mechanisms, dispensing with recurrence convolutions entirely. Experiments two machine translation tasks show these to be superior quality while being more parallelizable requiring significantly less time train. Our model achieves 28.4 BLEU WMT 2014 English-to-German task, improving over existing results, including ensembles by 2 BLEU. On English-to-French our establishes single-model state-of-the-art score of 41.8 after training for 3.5 days eight GPUs, small fraction costs from literature. that Transformer generalizes well other applying it successfully English constituency parsing both large limited data."
    ],
    "b_categories":[
      "cond-mat.dis-nn"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.19324"
    ],
    "c_title":[
      "Anisotropy signal of UHECRs from a structured magnetized Universe"
    ],
    "c_abstract":[
      "The surprising isotropy of the ultra-high-energy cosmic ray (UHECR) sky makes\nit difficult to identify their sources. Observables such as energy spectrum,\nmass composition and arrival directions are affected by interactions with\nbackground photon fields and by deflection in the extragalactic and galactic\nmagnetic fields (EGMF and GMF). In this work, we simulate the propagation of\nUHECRs with energy above 8 EeV in magnetized replicas of the local Universe,\nobtained from constrained simulations of the Large Scale Structure. We obtain\nthe real magnetic deflection in structured EGMF models with realistic\nthree-dimensional simulations. We investigate different scenarios for the UHECR\nsource distributions and densities. The effect of the GMF can be different\ndepending on the field model considered. In this work we consider the JF12\nmodel by mapping the arrival directions at the edge of the galaxy to those at\nEarth. We study the arrival direction distribution of the propagated UHECRs,\nand in particular their angular power spectrum, dipole and quadrupole moments.\nWe find that the properties of the source distribution affect the cosmic ray\nanisotropy more than the EGMF model considered. In particular, the low\nmultipole components depend on both the source distribution and the density. We\nalso find that it is difficult to simultaneously reproduce the observed dipole\nand quadrupole values above EeV. In general, we predict too large a quadrupole\nstrength, incompatible with observations."
    ],
    "c_categories":[
      [
        "astro-ph.HE"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00544",
    "a_title":"RoBo6: Standardized MMT Light Curve Dataset for Rocket Body\n  Classification",
    "a_abstract":"Space debris presents a critical challenge for the sustainability of future\nspace missions, emphasizing the need for robust and standardized identification\nmethods. However, a comprehensive benchmark for rocket body classification\nremains absent. This paper addresses this gap by introducing the RoBo6 dataset\nfor rocket body classification based on light curves. The dataset, derived from\nthe Mini Mega Tortora database, includes light curves for six rocket body\nclasses: CZ-3B, Atlas 5 Centaur, Falcon 9, H-2A, Ariane 5, and Delta 4. With\n5,676 training and 1,404 test samples, it addresses data inconsistencies using\nresampling, normalization, and filtering techniques. Several machine learning\nmodels were evaluated, including CNN and transformer-based approaches, with\nAstroconformer reporting the best performance. The dataset establishes a common\nbenchmark for future comparisons and advancements in rocket body classification\ntasks.",
    "explanation":"The selected references in Task 3 were based from the following topics introduced in the abstract:\n\n\"Space debris presents a critical challenge for the sustainability of future space missions, emphasizing the need for robust and standardized identification methods.\"\n\"Several machine learning models were evaluated, including\nCNN and transformer-based approaches, with  Astroconformer reporting the best performance\"",
    "b_id":[
      "b5"
    ],
    "b_title":[
      "Space objects classification via lightcurve measurements: deep convolutional neural networks and model-based transfer learning"
    ],
    "b_abstract":[
      "Developing a detailed understanding of the Space Object (SO) population is a fundamental goal of Space Situational Awareness (SSA). The current SO catalog includes simplified characteristic for the observed space objects, mainly the solar radiation pressure and\/or drag ballistic coefficients. Such simplified description limits the dynamic propagation model used for predicting the state of motion of SO to models that assume cannon ball shapes and generic surface properties. The future SO catalog and SSA systems will have to be capable of building a detailed picture of SO characteristics. Traditional measurement sources for SO tracking, such as radar and optical, provide information on SO characteristics. These measurements have been shown to be sensitive to shape, attitude, angular velocity, and surface parameters. State-of-the-art in the literature has been advanced over the past decades and in recent years seen the development of multiple models, nonlinear state estimation, and full Bayesian inversion approaches for SO characterization. The key shortcoming of approaches in literature is their overall computational cost and the limited flexibility to deal with a larger and larger amount of data. In this paper, we present a data-driven method to classification of SO based on a deep learning approach that takes advantage of the representational power of deep neural networks. Here, we design, train and validate a Convolutional Neural Network (CNN) capable of learning to classify SOs from collected light-curve measurements. The proposed methodology relies a physically-based model capable of accurately representing SO reflected light as function of time, size shape and state of motion. The model generates thousands of light-curves per selected class of SO which are employ to train a deep CNN to learn the functional relationship between light curves and SO class. Additionally, a deep CNN is trained using real SO light curves to evaluate the performance on a real, but limited training set. CNNs are compared with more conventional machine learning techniques (bagged trees, support vector machines) and are shown to outperform such methods especially when trained on real data. The concept of model-based transfer learning is proposed as possible path forward to increase the accuracy and speedup the training process."
    ],
    "b_categories":[
      "astro-ph.HE"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.16219"
    ],
    "c_title":[
      "Scaling of many-body localization transitions: Quantum dynamics in Fock\n  space and real space"
    ],
    "c_abstract":[
      "Many-body-localization (MBL) transitions are studied in a family of\nsingle-spin-flip spin-$\\frac12$ models, including the one-dimensional (1D)\nchain with nearest-neighbor interactions, the quantum dot (QD) model with\nall-to-all pair interactions, and the quantum random energy model (QREM). We\ninvestigate the generalized imbalance that characterizes propagation in Fock\nspace out of an initial basis state and, at the same time, can be efficiently\nprobed by real-space measurements. For all models considered, the average\nimbalance and its quantum and mesoscopic fluctuations provide excellent\nindicators for the position of the MBL transition $W_c(n)$, where $n$ is the\nnumber of spins. Combining these findings with earlier results on level\nstatistics, we determine phase diagrams of the MBL transitions in the $n$-$W$\nplane. Our results provide evidence for a direct transition between the ergodic\nand MBL phases for each of the models, without any intermediate phase. For QREM\nand QD model, $W_c(n)$ grows as a power law of $n$ (with logarithmic\ncorrections), in agreement with analytical predictions $W_c^{\\rm QREM}(n) \\sim\nn^{1\/2} \\ln n$ and $W_c^{\\rm QD}(n) \\gtrsim n^{3\/4} \\ln^{1\/2} n$. This growth\nis in stark contrast to the 1D model, where $W_c(n)$ is essentially independent\nof $n$, consistent with the analytic expectation $W_c^{\\rm 1D}(n\\to \\infty)=\n{\\rm const}$. We also determine the scaling of the transition width $\\Delta W\n(n) \/ W_c(n)$ and estimate the system size $n$ needed to study the asymptotic\nscaling behavior. While these values of $n$ are not accessible to exact\nsimulations on a classical computer, they are within the reach of quantum\nsimulators. Our results indicate feasibility of experimental studies of $n$-$W$\nphase diagrams and scaling properties of MBL transitions in models of 1D and QD\ntype and in their extensions to other spatial geometry or distance-dependent\ninteractions."
    ],
    "c_categories":[
      [
        "cond-mat.dis-nn"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04840",
    "a_title":"Localized KBO with genetic dynamics for multi-modal optimization",
    "a_abstract":"In this paper, we introduce a novel approach to multi-modal optimization by\nenhancing the recently developed kinetic-based optimization (KBO) method with\ngenetic dynamics (GKBO). The proposed method targets objective functions with\nmultiple global minima, addressing a critical need in fields like engineering\ndesign, machine learning, and bioinformatics. By incorpo rating leader-follower\ndynamics and localized interactions, the algorithm efficiently navigates\nhigh-dimensional search spaces to detect multiple optimal solutions. After\nproviding a binary description, a mean-field approximation is derived, and\ndifferent numerical experiments are conducted to validate the results.",
    "explanation":"This IDR paper involves a combination of topics from different fields. In particular, I highlighted key references in Task 3 where topics in Genetics and the use of Data Structures and Algorithms come into play. Below are some sentences from the Abstract that reflect that:\n\n\"n this paper, we introduce a novel approach to multi-modal optimization by enhancing the recently developed kinetic-based optimization (KBO) method with genetic dynamics (GKBO)\"\n\" By incorporating leader-follower dynamics and localized interactions, the algorithm efficiently navigates high-dimensional search spaces to detect multiple optimal solution.\"",
    "b_id":[
      "b9"
    ],
    "b_title":[
      "Kinetic description and convergence analysis of genetic algorithms for global optimization"
    ],
    "b_abstract":[
      "Genetic Algorithms (GA) are a class of metaheuristic global optimization methods inspired by the process natural selection among individuals in population. Despite their widespread use, comprehensive theoretical analysis these remains challenging due to complexity heuristic mechanisms involved. In this work, relying on tools statistical physics, we take first step towards mathematical understanding GA showing how behavior for large number can be approximated through time-discrete kinetic model. This allows us prove convergence algorithm minimum under mild assumptions objective function popular choice mechanism. Furthermore, derive time-continuous model GA, represented Boltzmann-like partial differential equation, and establish relations with other mean-field dynamics optimization. Numerical experiments support validity proposed approximation investigate asymptotic configurations particle system different benchmark problems."
    ],
    "b_categories":[
      "math.OC"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2503.02415"
    ],
    "c_title":[
      "On the sensitivity of CDAWG-grammars"
    ],
    "c_abstract":[
      "The compact directed acyclic word graphs (CDAWG) [Blumer et al. 1987] of a\nstring is the minimal compact automaton that recognizes all the suffixes of the\nstring. CDAWGs are known to be useful for various string tasks including text\npattern searching, data compression, and pattern discovery. The CDAWG-grammar\n[Belazzougui & Cunial 2017] is a grammar-based text compression based on the\nCDAWG. In this paper, we prove that the CDAWG-grammar size $g$ can increase by\nat most an additive factor of $4e + 4$ than the original after any\nsingle-character edit operation is performed on the input string, where $e$\ndenotes the number of edges in the corresponding CDAWG before the edit."
    ],
    "c_categories":[
      [
        "cs.DS"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.04840",
    "a_title":"Localized KBO with genetic dynamics for multi-modal optimization",
    "a_abstract":"In this paper, we introduce a novel approach to multi-modal optimization by\nenhancing the recently developed kinetic-based optimization (KBO) method with\ngenetic dynamics (GKBO). The proposed method targets objective functions with\nmultiple global minima, addressing a critical need in fields like engineering\ndesign, machine learning, and bioinformatics. By incorpo rating leader-follower\ndynamics and localized interactions, the algorithm efficiently navigates\nhigh-dimensional search spaces to detect multiple optimal solutions. After\nproviding a binary description, a mean-field approximation is derived, and\ndifferent numerical experiments are conducted to validate the results.",
    "explanation":"This IDR paper involves a combination of topics from different fields. In particular, I highlighted key references in Task 3 where topics in Genetics and the use of Data Structures and Algorithms come into play. Below are some sentences from the Abstract that reflect that:\n\n\"n this paper, we introduce a novel approach to multi-modal optimization by enhancing the recently developed kinetic-based optimization (KBO) method with genetic dynamics (GKBO)\"\n\" By incorporating leader-follower dynamics and localized interactions, the algorithm efficiently navigates high-dimensional search spaces to detect multiple optimal solution.\"",
    "b_id":[
      "b25"
    ],
    "b_title":[
      "Genetic Algorithms + Data Structures = Evolution Programs"
    ],
    "b_abstract":[
      "Genetic algorithms are founded upon the principle of evolution, i.e., survival of the fittest. Hence evolution programming techniques, based on genetic algorithms, are applicable to many hard optimization problems, such as optimization of functions with linear and nonlinear constraints, the traveling salesman problem, and problems of scheduling, partitioning, and control. The importance of these techniques is still growing, since evolution programs are parallel in nature, and parallelism is one of the most promising directions in computer science. The book is self-contained and the only prerequisite is basic undergraduate mathematics. This third edition has been substantially revised and extended by three new chapters and by additional appendices containing working material to cover recent developments and a change in the perception of evolutionary computation."
    ],
    "b_categories":[
      "cs.DS"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.15419"
    ],
    "c_title":[
      "A primal-dual interior point trust region method for\n  inequality-constrained optimization problems on Riemannian manifolds"
    ],
    "c_abstract":[
      "We consider Riemannian inequality-constrained optimization problems and\npropose a Riemannian primal-dual interior point trust region method (RIPTRM)\nfor solving them. We prove its global convergence to an approximate\nKarush-Kuhn-Tucker point and a second-order stationary point. We also establish\nthe local near-quadratic convergence. To the best of our knowledge, this is the\nfirst algorithm that incorporates the trust region strategy and has the\nsecond-order convergence property for optimization problems on Riemannian\nmanifolds with nonlinear inequality constraints. It is also the first\nRiemannian interior point method that possesses both global and local\nconvergence properties. We conduct numerical experiments in which we introduce\na truncated conjugate gradient method and an eigenvalue-based subsolver for\nRIPTRM to approximately and exactly solve the trust region subproblems,\nrespectively. Empirical results show that RIPTRMs find solutions with higher\naccuracy compared to an existing Riemannian interior point method and other\nalgorithms. Additionally, we observe that RIPTRM with the exact search\ndirection shows significantly promising performance in an instance where the\nHessian of the Lagrangian has a large negative eigenvalue."
    ],
    "c_categories":[
      [
        "math.OC"
      ]
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"basic"
  },
  {
    "id":"2411.17342",
    "a_title":"Automatic Skull Reconstruction by Deep Learnable Symmetry Enforcement",
    "a_abstract":"Every year, thousands of people suffer from skull damage and require\npersonalized implants to fill the cranial cavity. Unfortunately, the waiting\ntime for reconstruction surgery can extend to several weeks or even months,\nespecially in less developed countries. One factor contributing to the extended\nwaiting period is the intricate process of personalized implant modeling.\nCurrently, the preparation of these implants by experienced biomechanical\nexperts is both costly and time-consuming. Recent advances in artificial\nintelligence, especially in deep learning, offer promising potential for\nautomating the process. However, deep learning-based cranial reconstruction\nfaces several challenges: (i) the limited size of training datasets, (ii) the\nhigh resolution of the volumetric data, and (iii) significant data\nheterogeneity. In this work, we propose a novel approach to address these\nchallenges by enhancing the reconstruction through learnable symmetry\nenforcement. We demonstrate that it is possible to train a neural network\ndedicated to calculating skull symmetry, which can be utilized either as an\nadditional objective function during training or as a post-reconstruction\nobjective during the refinement step. We quantitatively evaluate the proposed\nmethod using open SkullBreak and SkullFix datasets, and qualitatively using\nreal clinical cases. The results indicate that the symmetry-preserving\nreconstruction network achieves considerably better outcomes compared to the\nbaseline (0.94\/0.94\/1.31 vs 0.84\/0.76\/2.43 in terms of DSC, bDSC, and HD95).\nMoreover, the results are comparable to the best-performing methods while\nrequiring significantly fewer computational resources (< 500 vs > 100,000 GPU\nhours). The proposed method is a considerable contribution to the field of\napplied artificial intelligence in medicine and is a step toward automatic\ncranial defect reconstruction in clinical practice.",
    "explanation":"This IDR paper is an applied research paper that focuses on combining Neural Networks to advance biomechanics. Below are some sentences in the abstract that reflect the references in Task 3:\n\n\"We demonstrate that it is possible to train a neural network dedicated to calculating skull symmetry,\"\n\n\"Every year, thousands of people suffer from skull damage and require personalized implants to fill the cranial cavity. Unfortunately, the waiting time for reconstruction surgery can extend to several weeks or even months, especially in less developed countries.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Reconstruction of cranial defect with patient-specific implants: Four different cost-effective techniques"
    ],
    "b_abstract":[
      "Cranial defects secondary to trauma, surgery or pathological causes, result in large cranial imperfection, which affects the appearance of patient as well results sinking flap syndrome. Rehabilitation such a defect can be done using prosthetic options like custom-made polymethyl methacrylate (PMMA) prosthesis surgical outer table calvarial graft segments. It is usually observed that conventional moulage impression defective site most difficult task. The accuracy affected by impression, cast and techniques fabricating wax pattern. Orthodox method mark tentative outline make site. However, this an arbitrary offers challenges accurate replication borders defect. Recently, medical imaging digital modeling dentistry have paved way for dental practice additive manufacturing replacing manual subtractive procedures. use computerized tomography scan obtain 3 D image replica with rapid prototyping has markedly improved at margin defect\/prosthesis interface, resulting better fit optimal contour lending itself esthetic outcome. more reliable implant prosthesis, requires minimum adjustment when on OT table. These case reports compare rehabilitation PMMA methods technique. seen expensive but gives"
    ],
    "b_categories":[
      "q-bio.TO"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.05824"
    ],
    "c_title":[
      "Aerial Reliable Collaborative Communications for Terrestrial Mobile\n  Users via Evolutionary Multi-Objective Deep Reinforcement Learning"
    ],
    "c_abstract":[
      "Unmanned aerial vehicles (UAVs) have emerged as the potential aerial base\nstations (BSs) to improve terrestrial communications. However, the limited\nonboard energy and antenna power of a UAV restrict its communication range and\ntransmission capability. To address these limitations, this work employs\ncollaborative beamforming through a UAV-enabled virtual antenna array to\nimprove transmission performance from the UAV to terrestrial mobile users,\nunder interference from non-associated BSs and dynamic channel conditions.\nSpecifically, we introduce a memory-based random walk model to more accurately\ndepict the mobility patterns of terrestrial mobile users. Following this, we\nformulate a multi-objective optimization problem (MOP) focused on maximizing\nthe transmission rate while minimizing the flight energy consumption of the UAV\nswarm. Given the NP-hard nature of the formulated MOP and the highly dynamic\nenvironment, we transform this problem into a multi-objective Markov decision\nprocess and propose an improved evolutionary multi-objective reinforcement\nlearning algorithm. Specifically, this algorithm introduces an evolutionary\nlearning approach to obtain the approximate Pareto set for the formulated MOP.\nMoreover, the algorithm incorporates a long short-term memory network and\nhyper-sphere-based task selection method to discern the movement patterns of\nterrestrial mobile users and improve the diversity of the obtained Pareto set.\nSimulation results demonstrate that the proposed method effectively generates a\ndiverse range of non-dominated policies and outperforms existing methods.\nAdditional simulations demonstrate the scalability and robustness of the\nproposed CB-based method under different system parameters and various\nunexpected circumstances."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.17342",
    "a_title":"Automatic Skull Reconstruction by Deep Learnable Symmetry Enforcement",
    "a_abstract":"Every year, thousands of people suffer from skull damage and require\npersonalized implants to fill the cranial cavity. Unfortunately, the waiting\ntime for reconstruction surgery can extend to several weeks or even months,\nespecially in less developed countries. One factor contributing to the extended\nwaiting period is the intricate process of personalized implant modeling.\nCurrently, the preparation of these implants by experienced biomechanical\nexperts is both costly and time-consuming. Recent advances in artificial\nintelligence, especially in deep learning, offer promising potential for\nautomating the process. However, deep learning-based cranial reconstruction\nfaces several challenges: (i) the limited size of training datasets, (ii) the\nhigh resolution of the volumetric data, and (iii) significant data\nheterogeneity. In this work, we propose a novel approach to address these\nchallenges by enhancing the reconstruction through learnable symmetry\nenforcement. We demonstrate that it is possible to train a neural network\ndedicated to calculating skull symmetry, which can be utilized either as an\nadditional objective function during training or as a post-reconstruction\nobjective during the refinement step. We quantitatively evaluate the proposed\nmethod using open SkullBreak and SkullFix datasets, and qualitatively using\nreal clinical cases. The results indicate that the symmetry-preserving\nreconstruction network achieves considerably better outcomes compared to the\nbaseline (0.94\/0.94\/1.31 vs 0.84\/0.76\/2.43 in terms of DSC, bDSC, and HD95).\nMoreover, the results are comparable to the best-performing methods while\nrequiring significantly fewer computational resources (< 500 vs > 100,000 GPU\nhours). The proposed method is a considerable contribution to the field of\napplied artificial intelligence in medicine and is a step toward automatic\ncranial defect reconstruction in clinical practice.",
    "explanation":"This IDR paper is an applied research paper that focuses on combining Neural Networks to advance biomechanics. Below are some sentences in the abstract that reflect the references in Task 3:\n\n\"We demonstrate that it is possible to train a neural network dedicated to calculating skull symmetry,\"\n\n\"Every year, thousands of people suffer from skull damage and require personalized implants to fill the cranial cavity. Unfortunately, the waiting time for reconstruction surgery can extend to several weeks or even months, especially in less developed countries.\"",
    "b_id":[
      "b35"
    ],
    "b_title":[
      "Deep learning-based framework for automatic cranial defect reconstruction and implant modeling"
    ],
    "b_abstract":[
      "This article presents a robust, fast, and fully automatic method for personalized cranial defect reconstruction implant modeling.We propose two-step deep learning-based using modified U-Net architecture to perform the reconstruction, dedicated iterative procedure improve geometry, followed by an generation of models ready 3-D printing. We cross-case augmentation based on imperfect image registration combining cases from different datasets. Additional ablation studies compare strategies other state-of-the-art methods.We evaluate three datasets introduced during AutoImplant 2021 challenge, organized jointly with MICCAI conference. quantitative evaluation Dice boundary coefficients, Hausdorff distance. The coefficient, 95th percentile distance averaged across all test sets, are 0.91, 0.94, 1.53 mm respectively. additional qualitative printing visualization in mixed reality confirm implant's usefulness.The proposes complete pipeline that enables one create model described is greatly extended version scored 1st place challenge tasks. freely release source code, which together open datasets, makes results reproducible. defects may enable manufacturing implants significantly shorter time, possibly allowing process directly given intervention. Moreover, we show usability further reduce surgery time."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.00197"
    ],
    "c_title":[
      "Unveiling sex dimorphism in the healthy cardiac anatomy: fundamental\n  differences between male and female heart shapes"
    ],
    "c_abstract":[
      "Sex-based differences in cardiovascular disease are well documented, yet the\nprecise nature and extent of these discrepancies in cardiac anatomy remain\nincompletely understood. Traditional scaling models often fail to capture the\ninterplay of age, blood pressure, and body size, prompting a more nuanced\ninvestigation. Here, we employ statistical shape modeling in a healthy subset\n(n=456) of the UK Biobank to explore sex-specific variations in biventricular\nanatomy. We reconstruct 3D meshes and perform multivariate analyses of shape\ncoefficients, controlling for age, blood pressure, and various body size\nmetrics. Our findings reveal that sex alone explains at least 25 percent of\nmorphological variability, with strong discrimination between men and women\n(AUC=0.96-0.71) persisting even after correction for confounders. Notably, the\nmost discriminative modes highlight pronounced differences in cardiac chamber\nvolumes, the anterior-posterior width of the right ventricle, and the relative\npositioning of the cardiac chambers. These results underscore that sex has a\nfundamental influence on cardiac morphology, which may have important clinical\nimplications for differing cardiac structural assessments in men and women.\nFuture work should investigate how these anatomical differences manifest in\nvarious cardiovascular conditions, ultimately paving the way for more precise\nrisk stratification and personalized therapeutic strategies for both men and\nwomen."
    ],
    "c_categories":[
      [
        "q-bio.TO"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04747",
    "a_title":"Equivariant Graph Attention Networks with Structural Motifs for\n  Predicting Cell Line-Specific Synergistic Drug Combinations",
    "a_abstract":"Cancer is the second leading cause of death, with chemotherapy as one of the\nprimary forms of treatment. As a result, researchers are turning to drug\ncombination therapy to decrease drug resistance and increase efficacy. Current\nmethods of drug combination screening, such as in vivo and in vitro, are\ninefficient due to stark time and monetary costs. In silico methods have become\nincreasingly important for screening drugs, but current methods are inaccurate\nand generalize poorly to unseen anticancer drugs. In this paper, I employ a\ngeometric deep-learning model utilizing a graph attention network that is\nequivariant to 3D rotations, translations, and reflections with structural\nmotifs. Additionally, the gene expression of cancer cell lines is utilized to\nclassify synergistic drug combinations specific to each cell line. I compared\nthe proposed geometric deep learning framework to current state-of-the-art\n(SOTA) methods, and the proposed model architecture achieved greater\nperformance on all 12 benchmark tasks performed on the DrugComb dataset.\nSpecifically, the proposed framework outperformed other SOTA methods by an\naccuracy difference greater than 28%. Based on these results, I believe that\nthe equivariant graph attention network's capability of learning geometric data\naccounts for the large performance improvements. The model's ability to\ngeneralize to foreign drugs is thought to be due to the structural motifs\nproviding a better representation of the molecule. Overall, I believe that the\nproposed equivariant geometric deep learning framework serves as an effective\ntool for virtually screening anticancer drug combinations for further\nvalidation in a wet lab environment. The code for this work is made available\nonline at: https:\/\/github.com\/WeToTheMoon\/EGAT_DrugSynergy.",
    "explanation":"From the key references cited in Task 3, below are some sentences that point to the significance of those references that show how this paper is an IDR.\n\n\"Additionally, the gene expression of cancer cell lines is utilized to classify synergistic drug combinations specificto each cell line. \"\n\"I compared the proposed geometric deep learning\nframework to current state-of-the-art (SOTA) methods\"\n\"Based on these results, I believe that the equivariant graph attention network\u2019s capability of learning geometric data accounts for the large performance improvements.\"",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "Trends in Phase II Trials for Cancer Therapies"
    ],
    "b_abstract":[
      "Background: Drug combinations are the standard of care in cancer treatment. Identifying effective drug has become more challenging because increasing number drugs. However, a substantial drugs stumble at Phase III clinical trials despite exhibiting favourable efficacy earlier Phase. Methods: We analysed recent II comprising 2165 response rates to uncover trends therapies and used null model non-interacting agents infer synergistic antagonistic combinations. compared our latest dataset with previous assess progress therapy. Results: Targeted reach higher when combination cytotoxic identify four 10 based on observed expected rates. demonstrate that targeted have not significantly increased Conclusions: conclude either we making or rate measured by tumour shrinkage is reliable surrogate endpoint for agents."
    ],
    "b_categories":[
      "q-bio.CB"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2501.09976"
    ],
    "c_title":[
      "Dendritic Localized Learning: Toward Biologically Plausible Algorithm"
    ],
    "c_abstract":[
      "Backpropagation is the foundational algorithm for training neural networks\nand a key driver of deep learning's success. However, its biological\nplausibility has been challenged due to three primary limitations: weight\nsymmetry, reliance on global error signals, and the dual-phase nature of\ntraining, as highlighted by the existing literature. Although various\nalternative learning approaches have been proposed to address these issues,\nmost either fail to satisfy all three criteria simultaneously or yield\nsuboptimal results. Inspired by the dynamics and plasticity of pyramidal\nneurons, we propose Dendritic Localized Learning (DLL), a novel learning\nalgorithm designed to overcome these challenges. Extensive empirical\nexperiments demonstrate that DLL satisfies all three criteria of biological\nplausibility while achieving state-of-the-art performance among algorithms that\nmeet these requirements. Furthermore, DLL exhibits strong generalization across\na range of architectures, including MLPs, CNNs, and RNNs. These results,\nbenchmarked against existing biologically plausible learning algorithms, offer\nvaluable empirical insights for future research. We hope this study can inspire\nthe development of new biologically plausible algorithms for training\nmultilayer networks and advancing progress in both neuroscience and machine\nlearning."
    ],
    "c_categories":[
      [
        "cs.NE"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.04747",
    "a_title":"Equivariant Graph Attention Networks with Structural Motifs for\n  Predicting Cell Line-Specific Synergistic Drug Combinations",
    "a_abstract":"Cancer is the second leading cause of death, with chemotherapy as one of the\nprimary forms of treatment. As a result, researchers are turning to drug\ncombination therapy to decrease drug resistance and increase efficacy. Current\nmethods of drug combination screening, such as in vivo and in vitro, are\ninefficient due to stark time and monetary costs. In silico methods have become\nincreasingly important for screening drugs, but current methods are inaccurate\nand generalize poorly to unseen anticancer drugs. In this paper, I employ a\ngeometric deep-learning model utilizing a graph attention network that is\nequivariant to 3D rotations, translations, and reflections with structural\nmotifs. Additionally, the gene expression of cancer cell lines is utilized to\nclassify synergistic drug combinations specific to each cell line. I compared\nthe proposed geometric deep learning framework to current state-of-the-art\n(SOTA) methods, and the proposed model architecture achieved greater\nperformance on all 12 benchmark tasks performed on the DrugComb dataset.\nSpecifically, the proposed framework outperformed other SOTA methods by an\naccuracy difference greater than 28%. Based on these results, I believe that\nthe equivariant graph attention network's capability of learning geometric data\naccounts for the large performance improvements. The model's ability to\ngeneralize to foreign drugs is thought to be due to the structural motifs\nproviding a better representation of the molecule. Overall, I believe that the\nproposed equivariant geometric deep learning framework serves as an effective\ntool for virtually screening anticancer drug combinations for further\nvalidation in a wet lab environment. The code for this work is made available\nonline at: https:\/\/github.com\/WeToTheMoon\/EGAT_DrugSynergy.",
    "explanation":"From the key references cited in Task 3, below are some sentences that point to the significance of those references that show how this paper is an IDR.\n\n\"Additionally, the gene expression of cancer cell lines is utilized to classify synergistic drug combinations specificto each cell line. \"\n\"I compared the proposed geometric deep learning\nframework to current state-of-the-art (SOTA) methods\"\n\"Based on these results, I believe that the equivariant graph attention network\u2019s capability of learning geometric data accounts for the large performance improvements.\"",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "E(n) Equivariant Graph Neural Networks"
    ],
    "b_abstract":[
      "This paper introduces a new model to learn graph neural networks equivariant rotations, translations, reflections and permutations called E(n)-Equivariant Graph Neural Networks (EGNNs). In contrast with existing methods, our work does not require computationally expensive higher-order representations in intermediate layers while it still achieves competitive or better performance. addition, whereas methods are limited equivariance on 3 dimensional spaces, is easily scaled higher-dimensional spaces. We demonstrate the effectiveness of method dynamical systems modelling, representation learning autoencoders predicting molecular properties."
    ],
    "b_categories":[
      "cs.NE"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.18947"
    ],
    "c_title":[
      "Trait-structured chemotaxis: Exploring ligand-receptor dynamics and\n  travelling wave properties in a Keller-Segel model"
    ],
    "c_abstract":[
      "A novel trait-structured Keller-Segel model that explores the dynamics of a\nmigrating cell population guided by chemotaxis in response to an external\nligand concentration is derived and analysed. Unlike traditional Keller-Segel\nmodels, this framework introduces an explicit representation of ligand-receptor\nbindings on the cell membrane, where the percentage of occupied receptors\nconstitutes the trait that influences cellular phenotype. The model posits that\nthe cell's phenotypic state directly modulates its capacity for chemotaxis and\nproliferation, governed by a trade-off due to a finite energy budget: cells\nhighly proficient in chemotaxis exhibit lower proliferation rates, while more\nproliferative cells show diminished chemotactic abilities. The model is derived\nfrom the principles of a biased random walk, resulting in a system of two\nnon-local partial differential equations, describing the densities of both\ncells and ligands. Using a Hopf-Cole transformation, we derive an equation that\ncharacterises the distribution of cellular traits within travelling wave\nsolutions for the total cell density, allowing us to uncover the monotonicity\nproperties of these waves. Numerical investigations are conducted to examine\nthe model's behaviour across various biological scenarios, providing insights\ninto the complex interplay between chemotaxis, proliferation, and phenotypic\ndiversity in migrating cell populations."
    ],
    "c_categories":[
      [
        "q-bio.CB"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00319",
    "a_title":"Improving speaker verification robustness with synthetic emotional\n  utterances",
    "a_abstract":"A speaker verification (SV) system offers an authentication service designed\nto confirm whether a given speech sample originates from a specific speaker.\nThis technology has paved the way for various personalized applications that\ncater to individual preferences. A noteworthy challenge faced by SV systems is\ntheir ability to perform consistently across a range of emotional spectra. Most\nexisting models exhibit high error rates when dealing with emotional utterances\ncompared to neutral ones. Consequently, this phenomenon often leads to missing\nout on speech of interest. This issue primarily stems from the limited\navailability of labeled emotional speech data, impeding the development of\nrobust speaker representations that encompass diverse emotional states.\n  To address this concern, we propose a novel approach employing the CycleGAN\nframework to serve as a data augmentation method. This technique synthesizes\nemotional speech segments for each specific speaker while preserving the unique\nvocal identity. Our experimental findings underscore the effectiveness of\nincorporating synthetic emotional data into the training process. The models\ntrained using this augmented dataset consistently outperform the baseline\nmodels on the task of verifying speakers in emotional speech scenarios,\nreducing equal error rate by as much as 3.64% relative.",
    "explanation":"A speaker verification (SV) system offers an authentication ser-\nvice designed to confirm whether a given speech sample orig-\ninates from a specific speaker. To address this concern, we propose a novel\napproach employing the CycleGAN framework to serve as a\ndata augmentation method. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Human-Centric Interfaces for Ambient Intelligence"
    ],
    "b_abstract":[
      "To create truly effective human-centric ambient intelligence systems both engineering and computing methods are needed. This is the first book to bridge data processing and intelligent reasoning methods for the creation of human-centered ambient intelligence systems. Interdisciplinary in nature, the book covers topics such as multi-modal interfaces, human-computer interaction, smart environments and pervasive computing, addressing principles, paradigms, methods and applications. This book will be an ideal reference for university researchers, R&amp;D engineers, computer engineers, and graduate students working in signal, speech and video processing, multi-modal interfaces, human-computer interaction and applications of ambient intelligence."
    ],
    "b_categories":[
      "physics.app-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.15762"
    ],
    "c_title":[
      "Dialogic Learning in Child-Robot Interaction: A Hybrid Approach to\n  Personalized Educational Content Generation"
    ],
    "c_abstract":[
      "Dialogic learning fosters motivation and deeper understanding in education\nthrough purposeful and structured dialogues. Foundational models offer a\ntransformative potential for child-robot interactions, enabling the design of\npersonalized, engaging, and scalable interactions. However, their integration\ninto educational contexts presents challenges in terms of ensuring\nage-appropriate and safe content and alignment with pedagogical goals. We\nintroduce a hybrid approach to designing personalized educational dialogues in\nchild-robot interactions. By combining rule-based systems with LLMs for\nselective offline content generation and human validation, the framework\nensures educational quality and developmental appropriateness. We illustrate\nthis approach through a project aimed at enhancing reading motivation, in which\na robot facilitated book-related dialogues."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00319",
    "a_title":"Improving speaker verification robustness with synthetic emotional\n  utterances",
    "a_abstract":"A speaker verification (SV) system offers an authentication service designed\nto confirm whether a given speech sample originates from a specific speaker.\nThis technology has paved the way for various personalized applications that\ncater to individual preferences. A noteworthy challenge faced by SV systems is\ntheir ability to perform consistently across a range of emotional spectra. Most\nexisting models exhibit high error rates when dealing with emotional utterances\ncompared to neutral ones. Consequently, this phenomenon often leads to missing\nout on speech of interest. This issue primarily stems from the limited\navailability of labeled emotional speech data, impeding the development of\nrobust speaker representations that encompass diverse emotional states.\n  To address this concern, we propose a novel approach employing the CycleGAN\nframework to serve as a data augmentation method. This technique synthesizes\nemotional speech segments for each specific speaker while preserving the unique\nvocal identity. Our experimental findings underscore the effectiveness of\nincorporating synthetic emotional data into the training process. The models\ntrained using this augmented dataset consistently outperform the baseline\nmodels on the task of verifying speakers in emotional speech scenarios,\nreducing equal error rate by as much as 3.64% relative.",
    "explanation":"A speaker verification (SV) system offers an authentication ser-\nvice designed to confirm whether a given speech sample orig-\ninates from a specific speaker. To address this concern, we propose a novel\napproach employing the CycleGAN framework to serve as a\ndata augmentation method. ",
    "b_id":[
      "b6"
    ],
    "b_title":[
      "Speaker Diarization with LSTM"
    ],
    "b_abstract":[
      "For many years, i-vector based audio embedding techniques were the dominant approach for speaker verification and diarization applications. However, mirroring rise of deep learning in various domains, neural network embeddings, also known as <i xmlns:mml=\"http:\/\/www.w3.org\/1998\/Math\/MathML\" xmlns:xlink=\"http:\/\/www.w3.org\/1999\/xlink\">d-vectors<\/i> , have consistently demonstrated superior performance. In this paper, we build on success d-vector systems to develop a new diarization. Specifically, combine LSTM-based embeddings with recent work non-parametric clustering obtain state-of-the-art system. Our system is evaluated three standard public datasets, suggesting that offer significant advantages over traditional systems. We achieved 12.0% error rate NIST SRE 2000 CALLHOME, while our model trained out-of-domain data from voice search logs."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.07723"
    ],
    "c_title":[
      "Total acoustic transmission between fluids using a solid material with\n  emphasis on the air-water interface"
    ],
    "c_abstract":[
      "Total acoustic transmission between water and air is modeled using a purely\nsolid interface comprising two elastic plates separated by periodically spaced\nribs. The frequency of full transmission depends only on, and is inversely\nproportional to, the areal density of the plate facing the air. Total\ntransmission also requires a specific dependence of the rib spacing on the\nbending stiffness of the two plates. These relations are the result of an\nexplicit analytical solution for the transmitted and reflected acoustic waves\ncombined with asymptotic approximations based on the small parameter defined by\nthe air-to-water impedance ratio. Surprisingly, the total transmission effect\nis almost independent of the angle of incidence, even though the transmission\nconditions are predicated on normal incidence. Parametric studies are performed\nto examine the effect on the frequency bandwidth and Q-factor of the acoustic\ntransmissivity. A lower bound for the Q-factor of $30.6$ is simply related to\nthe water-air impedance ratio."
    ],
    "c_categories":[
      [
        "physics.app-ph"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00173",
    "a_title":"Spatial Clustering of Molecular Localizations with Graph Neural Networks",
    "a_abstract":"Single-molecule localization microscopy generates point clouds corresponding\nto fluorophore localizations. Spatial cluster identification and analysis of\nthese point clouds are crucial for extracting insights about molecular\norganization. However, this task becomes challenging in the presence of\nlocalization noise, high point density, or complex biological structures. Here,\nwe introduce MIRO (Multimodal Integration through Relational Optimization), an\nalgorithm that uses recurrent graph neural networks to transform the point\nclouds in order to improve clustering efficiency when applying conventional\nclustering techniques. We show that MIRO supports simultaneous processing of\nclusters of different shapes and at multiple scales, demonstrating improved\nperformance across varied datasets. Our comprehensive evaluation demonstrates\nMIRO's transformative potential for single-molecule localization applications,\nshowcasing its capability to revolutionize cluster analysis and provide\naccurate, reliable details of molecular architecture. In addition, MIRO's\nrobust clustering capabilities hold promise for applications in various fields\nsuch as neuroscience, for the analysis of neural connectivity patterns, and\nenvironmental science, for studying spatial distributions of ecological data.",
    "explanation":"Single-molecule localization microscopy generates point clouds corresponding to\nfluorophore localizations.  Here, we introduce MIRO (Mul-\ntimodal Integration through Relational Optimization), an algorithm that uses\nrecurrent graph neural networks to transform the point clouds in order to improve\nclustering efficiency when applying conventional clustering techniques.",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Turning single-molecule localization microscopy into a quantitative bioanalytical tool"
    ],
    "b_abstract":[
      "Single-molecule localization microscopy (SMLM) generates super-resolution images by serially detecting individual fluorescent molecules. The power of SMLM, however, goes beyond images: biologically relevant information can be extracted from the mathematical relationships between the positions of the fluorophores in space and time. Here we review the history of SMLM and how recent progress in methods for spatial point analysis has enabled quantitative measurement of SMLM data, providing insights into biomolecule patterning, clustering and oligomerization in biological systems."
    ],
    "b_categories":[
      "q-bio.BM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.20927"
    ],
    "c_title":[
      "Goal-Oriented Semantic Communication for Wireless Video Transmission via\n  Generative AI"
    ],
    "c_abstract":[
      "Efficient video transmission is essential for seamless communication and\ncollaboration within the visually-driven digital landscape. To achieve low\nlatency and high-quality video transmission over a bandwidth-constrained noisy\nwireless channel, we propose a stable diffusion (SD)-based goal-oriented\nsemantic communication (GSC) framework. In this framework, we first design a\nsemantic encoder that effectively identify the keyframes from video and extract\nthe relevant semantic information (SI) to reduce the transmission data size. We\nthen develop a semantic decoder to reconstruct the keyframes from the received\nSI and further generate the full video from the reconstructed keyframes using\nframe interpolation to ensure high-quality reconstruction. Recognizing the\nimpact of wireless channel noise on SI transmission, we also propose an\nSD-based denoiser for GSC (SD-GSC) condition on an instantaneous channel gain\nto remove the channel noise from the received noisy SI under a known channel.\nFor scenarios with an unknown channel, we further propose a parallel SD\ndenoiser for GSC (PSD-GSC) to jointly learn the distribution of channel gains\nand denoise the received SI. It is shown that, with the known channel, our\nproposed SD-GSC outperforms state-of-the-art ADJSCC, Latent-Diff DNSC, DeepWiVe\nand DVST, improving Peak Signal-to-Noise Ratio (PSNR) by 69%, 58%, 33% and 38%,\nreducing mean squared error (MSE) by 52%, 50%, 41% and 45%, and reducing\nFr\\'echet Video Distance (FVD) by 38%, 32%, 22% and 24%, respectively. With the\nunknown channel, our PSD-GSC achieves a 17% improvement in PSNR, a 29%\nreduction in MSE, and a 19% reduction in FVD compared to MMSE\nequalizer-enhanced SD-GSC. These significant performance improvements\ndemonstrate the robustness and superiority of our proposed methods in enhancing\nvideo transmission quality and efficiency under various channel conditions."
    ],
    "c_categories":[
      [
        "eess.IV"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00173",
    "a_title":"Spatial Clustering of Molecular Localizations with Graph Neural Networks",
    "a_abstract":"Single-molecule localization microscopy generates point clouds corresponding\nto fluorophore localizations. Spatial cluster identification and analysis of\nthese point clouds are crucial for extracting insights about molecular\norganization. However, this task becomes challenging in the presence of\nlocalization noise, high point density, or complex biological structures. Here,\nwe introduce MIRO (Multimodal Integration through Relational Optimization), an\nalgorithm that uses recurrent graph neural networks to transform the point\nclouds in order to improve clustering efficiency when applying conventional\nclustering techniques. We show that MIRO supports simultaneous processing of\nclusters of different shapes and at multiple scales, demonstrating improved\nperformance across varied datasets. Our comprehensive evaluation demonstrates\nMIRO's transformative potential for single-molecule localization applications,\nshowcasing its capability to revolutionize cluster analysis and provide\naccurate, reliable details of molecular architecture. In addition, MIRO's\nrobust clustering capabilities hold promise for applications in various fields\nsuch as neuroscience, for the analysis of neural connectivity patterns, and\nenvironmental science, for studying spatial distributions of ecological data.",
    "explanation":"Single-molecule localization microscopy generates point clouds corresponding to\nfluorophore localizations.  Here, we introduce MIRO (Mul-\ntimodal Integration through Relational Optimization), an algorithm that uses\nrecurrent graph neural networks to transform the point clouds in order to improve\nclustering efficiency when applying conventional clustering techniques.",
    "b_id":[
      "b22"
    ],
    "b_title":[
      "A framework for evaluating the performance of SMLM cluster analysis algorithms"
    ],
    "b_abstract":[
      "This analysis compares the performance of seven algorithms for cluster analysis of single-molecule localization microscopy data. The results provide a framework for comparing these types of methods and point users to the best tools. Single-molecule localization microscopy (SMLM) generates data in the form of coordinates of localized fluorophores. Cluster analysis is an attractive route for extracting biologically meaningful information from such data and has been widely applied. Despite a range of cluster analysis algorithms, there exists no consensus framework for the evaluation of their performance. Here, we use a systematic approach based on two metrics to score the success of clustering algorithms in simulated conditions mimicking experimental data. We demonstrate the framework using seven diverse analysis algorithms: DBSCAN, ToMATo, KDE, FOCAL, CAML, ClusterViSu and SR-Tesseler. Given that the best performer depended on the underlying distribution of localizations, we demonstrate an analysis pipeline based on statistical similarity measures that enables the selection of the most appropriate algorithm, and the optimized analysis parameters for real SMLM data. We propose that these standard simulated conditions, metrics and analysis pipeline become the basis for future analysis algorithm development and evaluation."
    ],
    "b_categories":[
      "eess.IV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04258"
    ],
    "c_title":[
      "How Large is the Universe of RNA-Like Motifs? A Clustering Analysis of\n  RNA Graph Motifs Using Topological Descriptors"
    ],
    "c_abstract":[
      "We introduce a computational topology-based approach with unsupervised\nmachine-learning algorithms to estimate the database size and content of\nRNA-like graph topologies. Specifically, we apply graph theory enumeration to\ngenerate all 110,667 possible 2D dual graphs for vertex numbers ranging from 2\nto 9. Among them, only 0.11% graphs correspond to approximately 200,000 known\nRNA atomic fragments (collected in 2021) using the RNA-as-Graphs (RAG) mapping\nmethod. The remaining 99.89% of the dual graphs may be RNA-like or\nnon-RNA-like. To determine which dual graphs in the 99.89% hypothetical set are\nmore likely to be associated with RNA structures, we apply computational\ntopology descriptors using the Persistent Spectral Graphs (PSG) method to\ncharacterize each graph using 19 PSG-based features and use clustering\nalgorithms that partition all possible dual graphs into two clusters, RNA-like\ncluster and non-RNA-like cluster. The distance of each dual graph to the center\nof the RNA-like cluster represents the likelihood of it belonging to RNA\nstructures. From validation, our PSG-based RNA-like cluster includes 97.3% of\nthe 121 known RNA dual graphs, suggesting good performance. Furthermore,\n46.017% of the hypothetical RNAs are predicted to be RNA-like. Significantly,\nwe observe that all the top 15 RNA-like dual graphs can be separated into\nmultiple subgraphs, whereas the top 15 non-RNA-like dual graphs tend not to\nhave any subgraphs. Moreover, a significant topological difference between top\nRNA-like and non-RNA-like graphs is evident when comparing their topological\nfeatures. These findings provide valuable insights into the size of the RNA\nmotif universe and RNA design strategies, offering a novel framework for\npredicting RNA graph topologies and guiding the discovery of novel RNA motifs,\nperhaps anti-viral therapeutics by subgraph assembly."
    ],
    "c_categories":[
      [
        "q-bio.BM"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.19450",
    "a_title":"Unsupervised Learning Approach to Anomaly Detection in Gravitational\n  Wave Data",
    "a_abstract":"Gravitational waves (GW), predicted by Einstein's General Theory of\nRelativity, provide a powerful probe of astrophysical phenomena and fundamental\nphysics. In this work, we propose an unsupervised anomaly detection method\nusing variational autoencoders (VAEs) to analyze GW time-series data. By\ntraining on noise-only data, the VAE accurately reconstructs noise inputs while\nfailing to reconstruct anomalies, such as GW signals, which results in\nmeasurable spikes in the reconstruction error. The method was applied to data\nfrom the LIGO H1 and L1 detectors. Evaluation on testing datasets containing\nboth noise and GW events demonstrated reliable detection, achieving an area\nunder the ROC curve (AUC) of 0.89. This study introduces VAEs as a robust,\nunsupervised approach for identifying anomalies in GW data, which offers a\nscalable framework for detecting known and potentially new phenomena in\nphysics.",
    "explanation":"Gravitational waves (GW), predicted by Einstein\u2019s General Theory of Relativity, provide a pow-\nerful probe of astrophysical phenomena and fundamental physics. In this work, we propose an\nunsupervised anomaly detection method using variational autoencoders (VAEs) to analyze GW\ntime-series data. ",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining"
    ],
    "b_abstract":[
      "It is our great pleasure to welcome you the 2017 ACM Conference on Knowledge Discovery and Data Mining -- KDD 2017. We hope that content professional networking opportunities at will help succeed professionally by enabling to: identify new technology trends; learn from contributed papers, presentations, posters; discover tools, processes practices; job opportunities; hire team members. The terms \"Data Science\", Mining\" \"Big Data\" have, in last few years, grown out of research labs gained presence media everyday conversations. also hear these social decision makers various level governments corporations. impact technologies felt almost every walk life. Importantly, current rapid progress data science facilitated timely sharing newly discovered developed representations algorithms between those working interested industrial deployment. hallmark conferences past they have been bridge theory practise, facilitator catalyst for this exchange. Researchers practitioners meet person interact a meaningful way over several days. conference program, with its three parallel tracks - Research Track, Applied Science Track Invited Speakers brings two groups together. Participants are freely attend any track, events common all tracks. year continues tradition strong tutorial workshop program leading edge issues mining during first days program. devoted technical describing both novel, important contributions, deployed, innovative solutions. Three keynote talks, Cynthia Dwork, Bin Yu, Ren\u00e9e J. Miller touch some hard, emerging before field mining. With growing industry around AI assistants, Panel together experts spawn discussions an exchanges ideas. outstanding lineup speakers their experiences expertise deploying continue hands-on which participants how use practical tools. In order broaden increase participation attendees who would greatly benefit but otherwise found it financially challenging attend, we reserved substantial budget travel grants. awarded record USD 145k student set aside 25k enable smaller startups attend. \"Meet Experts\" sessions, gives researchers unique opportunity form networks share perspectives others aspects science. serve as meeting ground researchers, practitioners, funding agencies investors create commercial products."
    ],
    "b_categories":[
      "physics.gen-ph"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2503.06242"
    ],
    "c_title":[
      "LapSum -- One Method to Differentiate Them All: Ranking, Sorting and\n  Top-k Selection"
    ],
    "c_abstract":[
      "We present a novel technique for constructing differentiable order-type\noperations, including soft ranking, soft top-k selection, and soft\npermutations. Our approach leverages an efficient closed-form formula for the\ninverse of the function LapSum, defined as the sum of Laplace distributions.\nThis formulation ensures low computational and memory complexity in selecting\nthe highest activations, enabling losses and gradients to be computed in\n$O(n\\log{}n)$ time. Through extensive experiments, we demonstrate that our\nmethod outperforms state-of-the-art techniques for high-dimensional vectors and\nlarge $k$ values. Furthermore, we provide efficient implementations for both\nCPU and CUDA environments, underscoring the practicality and scalability of our\nmethod for large-scale ranking and differentiable ordering problems."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.19450",
    "a_title":"Unsupervised Learning Approach to Anomaly Detection in Gravitational\n  Wave Data",
    "a_abstract":"Gravitational waves (GW), predicted by Einstein's General Theory of\nRelativity, provide a powerful probe of astrophysical phenomena and fundamental\nphysics. In this work, we propose an unsupervised anomaly detection method\nusing variational autoencoders (VAEs) to analyze GW time-series data. By\ntraining on noise-only data, the VAE accurately reconstructs noise inputs while\nfailing to reconstruct anomalies, such as GW signals, which results in\nmeasurable spikes in the reconstruction error. The method was applied to data\nfrom the LIGO H1 and L1 detectors. Evaluation on testing datasets containing\nboth noise and GW events demonstrated reliable detection, achieving an area\nunder the ROC curve (AUC) of 0.89. This study introduces VAEs as a robust,\nunsupervised approach for identifying anomalies in GW data, which offers a\nscalable framework for detecting known and potentially new phenomena in\nphysics.",
    "explanation":"Gravitational waves (GW), predicted by Einstein\u2019s General Theory of Relativity, provide a pow-\nerful probe of astrophysical phenomena and fundamental physics. In this work, we propose an\nunsupervised anomaly detection method using variational autoencoders (VAEs) to analyze GW\ntime-series data. ",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Auto-Encoding Variational Bayes"
    ],
    "b_abstract":[
      "How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions are two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for i.i.d. datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04045"
    ],
    "c_title":[
      "A new type of Multiverse, G\\\"odel theorems and the nonstandard logic of\n  classical, quantum mechanics and quantum gravity"
    ],
    "c_abstract":[
      "The problem is posed of establishing a possible relationship between a new\ntype of Multi-verse representation, G\\\"odel undecidability theorems and the\nlogic of classical, quantum mechanics and quantum gravity. For this purpose\nexample cases of multi-verses are first discussed in the context of\nnon-relativistic classical, quantum mechanics and quantum gravity. As a result,\nit is confirmed that thanks to G\\\"odel theorems non-relativistic classical and\nquantum mechanics, as well as quantum gravity theory are incomplete. As a\nconsequence, they necessarily admit undecidable logical propositions and\ntherefore obey a three-way boolean logical, i.e., a propositional logic with\nthe three different logical truth values true, false and undecidable."
    ],
    "c_categories":[
      [
        "physics.gen-ph"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.09927",
    "a_title":"Neural Vector Tomography for Reconstructing a Magnetization Vector Field",
    "a_abstract":"Discretized techniques for vector tomographic reconstructions are prone to\nproducing artifacts in the reconstructions. The quality of these\nreconstructions may further deteriorate as the amount of noise increases. In\nthis work, we instead model the underlying vector fields using smooth neural\nfields. Owing to the fact that the activation functions in the neural network\nmay be chosen to be smooth and the domain is no longer pixelated, the model\nresults in high-quality reconstructions, even under presence of noise. In the\ncase where we have underlying global continuous symmetry, we find that the\nneural network substantially improves the accuracy of the reconstruction over\nthe existing techniques.",
    "explanation":" In this work, we instead model the underlying\nvector fields using smooth neural fields",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Three-dimensional nanomagnetism"
    ],
    "b_abstract":[
      "Magnetic nanostructures are being developed for use in many aspects of our daily life, spanning areas such as data storage, sensing and biomedicine. Whereas patterned nanomagnets traditionally two-dimensional planar structures, recent work is expanding nanomagnetism into three dimensions; a move triggered by the advance unconventional synthesis methods discovery new magnetic effects. In three-dimensional more complex configurations become possible, with unprecedented properties. Here we review creation these structures their implications emergence physics, development instrumentation computational methods, exploitation numerous applications. Nanoscale devices play key role modern technologies but current applications involve only 2D like discs. authors progress fabrication understanding 3D nanostructures, enabling diverse functionalities."
    ],
    "b_categories":[
      "cond-mat.mes-hall"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2501.19140"
    ],
    "c_title":[
      "Transformation trees -- documentation of multimodal image registration"
    ],
    "c_abstract":[
      "Multimodal image registration plays a key role in creating digital patient\nmodels by combining data from different imaging techniques into a single\ncoordinate system. This process often involves multiple sequential and\ninterconnected transformations, which must be well-documented to ensure\ntransparency and reproducibility. In this paper, we propose the use of\ntransformation trees as a method for structured recording and management of\nthese transformations. This approach has been implemented in the dpVision\nsoftware and uses a dedicated .dpw file format to store hierarchical\nrelationships between images, transformations, and motion data. Transformation\ntrees allow precise tracking of all image processing steps, reduce the need to\nstore multiple copies of the same data, and enable the indirect registration of\nimages that do not share common reference points. This improves the\nreproducibility of the analyses and facilitates later processing and\nintegration of images from different sources. The practical application of this\nmethod is demonstrated with examples from orthodontics, including the\nintegration of 3D face scans, intraoral scans, and CBCT images, as well as the\ndocumentation of mandibular motion. Beyond orthodontics, this method can be\napplied in other fields that require systematic management of image\nregistration processes, such as maxillofacial surgery, oncology, and\nbiomechanical analysis. Maintaining long-term data consistency is essential for\nboth scientific research and clinical practice. It enables easier comparison of\nresults in longitudinal studies, improves retrospective analysis, and supports\nthe development of artificial intelligence algorithms by providing standardized\nand well-documented datasets. The proposed approach enhances data organization,\nallows for efficient analysis, and facilitates the reuse of information in\nfuture studies and diagnostic procedures."
    ],
    "c_categories":[
      [
        "cs.CV"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.09927",
    "a_title":"Neural Vector Tomography for Reconstructing a Magnetization Vector Field",
    "a_abstract":"Discretized techniques for vector tomographic reconstructions are prone to\nproducing artifacts in the reconstructions. The quality of these\nreconstructions may further deteriorate as the amount of noise increases. In\nthis work, we instead model the underlying vector fields using smooth neural\nfields. Owing to the fact that the activation functions in the neural network\nmay be chosen to be smooth and the domain is no longer pixelated, the model\nresults in high-quality reconstructions, even under presence of noise. In the\ncase where we have underlying global continuous symmetry, we find that the\nneural network substantially improves the accuracy of the reconstruction over\nthe existing techniques.",
    "explanation":" In this work, we instead model the underlying\nvector fields using smooth neural fields",
    "b_id":[
      "b15"
    ],
    "b_title":[
      "MagNet: machine learning enhanced three-dimensional magnetic reconstruction"
    ],
    "b_abstract":[
      "Three-dimensional (3D) magnetic reconstruction is vital to the study of novel materials for 3D spintronics. Vector field electron tomography (VFET) a major in house tool achieve that. However, conventional VFET exhibits significant artefacts due unavoidable presence missing wedges. In this article, we propose deep-learning enhanced method address issue. A textures library built by micromagnetic simulations. MagNet, an U-shaped convolutional neural network, trained and tested with dataset generated from library. We demonstrate that MagNet outperforms under wedge. Quality reconstructed induction fields significantly improved."
    ],
    "b_categories":[
      "cs.CV"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2503.12671"
    ],
    "c_title":[
      "Stability of Majorana modes in Coulomb-disordered topological insulator\n  nanowires"
    ],
    "c_abstract":[
      "We evaluate theoretically the possibility to realize Majorana zero modes in\nhybrid devices made from topological-insulator (TI) nanowires proximity-coupled\nto a superconductor. Such systems have been suggested as building blocks of\nfuture topological quantum computers, as they have been predicted to realize\nMajorana zero modes protected by large gaps. A main obstacle is, however, the\npresence of a relatively large density of charged impurities, $n_\\text{imp}\\sim\n10^{19}$cm$^{-3}$. Based on extensive numerical simulations, we show that the\nproximity to the superconductor leads to an efficient screening of the disorder\npotential. By analyzing the Majorana splitting energy, the size of the Andreev\ngap and the localization of edge modes, we show that robust Majorana modes can\nbe realized for realistic levels of impurity concentrations and wire radii."
    ],
    "c_categories":[
      [
        "cond-mat.mes-hall"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.19927",
    "a_title":"Modeling Continuous Spatial-temporal Dynamics of Turbulent Flow with\n  Test-time Refinement",
    "a_abstract":"The precise simulation of turbulent flows holds immense significance across\nvarious scientific and engineering domains, including climate science,\nfreshwater science, and energy-efficient manufacturing. Within the realm of\nsimulating turbulent flows, large eddy simulation (LES) has emerged as a\nprevalent alternative to direct numerical simulation (DNS), offering\ncomputational efficiency. However, LES cannot accurately capture the full\nspectrum of turbulent transport scales and is present only at a lower spatial\nresolution. Reconstructing high-fidelity DNS data from the lower-resolution LES\ndata is essential for numerous applications, but it poses significant\nchallenges to existing super-resolution techniques, primarily due to the\ncomplex spatio-temporal nature of turbulent flows. This paper proposes a novel\nflow reconstruction approach that leverages physical knowledge to model flow\ndynamics. Different from traditional super-resolution techniques, the proposed\napproach uses LES data only in the testing phase through a degradation-based\nrefinement approach to enforce physical constraints and mitigate cumulative\nreconstruction errors over time. Furthermore, a feature sampling strategy is\ndeveloped to enable flow data reconstruction across different resolutions. The\nresults on two distinct sets of turbulent flow data indicate the effectiveness\nof the proposed method in reconstructing high-resolution DNS data, preserving\nthe inherent physical attributes of flow transport, and achieving DNS\nreconstruction at different resolutions.",
    "explanation":"his paper proposes a novel flow recon-\nstruction approach that leverages physical knowledge to\nmodel flow dynamics.",
    "b_id":[
      "b4"
    ],
    "b_title":[
      "Model-free simulations of turbulent reactive flows"
    ],
    "b_abstract":[
      "A critical review of the modern computational methods for solving the transport equations of turbulent reacting single-phase flows is presented. Primary consideration is given to those methods which lead to \u2018model-free\u2019 simulations while some attention is devoted to \u2018turbulence modeling\u2019. Emphasis is placed upon the role of supercomputers and how their increased computational capacities may be exploited to allow better simulations of the physics of turbulent reactive flows. Comparisons between the commonly employed computational schemes for simulating these flows are given, with the advantages and the limitations associated with each scheme being highlighted. Examples are presented of recent applications of model-free simulations to a variety of unsteady reacting flows, with detailed discussions on the physical phenomena captured by such simulations. Due to the nature of this review, experimental contributions are mentioned only in the context of providing empirical evidence. References are made to other contributions which are not directly related to the computational efforts in order to provide a reasonably comprehensive bibliography for those interested in pursuing various topics in greater detail. Predictions of future accomplishments, as well as some suggestions for future work, are also given."
    ],
    "b_categories":[
      "physics.flu-dyn"
    ],
    "b_fields":[
      "Physics"
    ],
    "c_id":[
      "2502.17361"
    ],
    "c_title":[
      "A Closer Look at TabPFN v2: Strength, Limitation, and Extension"
    ],
    "c_abstract":[
      "Tabular datasets are inherently heterogeneous, posing significant challenges\nfor developing pre-trained foundation models. The recently introduced\ntransformer-based Tabular Prior-data Fitted Network v2 (TabPFN v2) achieves\nunprecedented in-context learning accuracy across multiple tabular datasets,\nmarking a pivotal advancement in tabular foundation models. In this paper, we\ncomprehensively evaluate TabPFN v2 on over 300 datasets, confirming its\nexceptional generalization capabilities on small- to medium-scale tasks. Our\nanalysis identifies randomized feature tokens as a key factor behind TabPFN\nv2's success, as they unify heterogeneous datasets into a fixed-dimensional\nrepresentation, enabling more effective training and inference. To further\nunderstand TabPFN v2's predictions, we propose a leave-one-fold-out approach,\ntransforming TabPFN v2 into a feature extractor and revealing its capability to\nsimplify data distributions and boost accuracy. Lastly, to address TabPFN v2's\nlimitations in high-dimensional, large-scale, and many-category tasks, we\nintroduce a divide-and-conquer mechanism inspired by Chain-of-Thought\nprompting, enabling scalable inference. By uncovering the mechanisms behind\nTabPFN v2's success and introducing strategies to expand its applicability,\nthis study provides key insights into the future of tabular foundation models."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.19927",
    "a_title":"Modeling Continuous Spatial-temporal Dynamics of Turbulent Flow with\n  Test-time Refinement",
    "a_abstract":"The precise simulation of turbulent flows holds immense significance across\nvarious scientific and engineering domains, including climate science,\nfreshwater science, and energy-efficient manufacturing. Within the realm of\nsimulating turbulent flows, large eddy simulation (LES) has emerged as a\nprevalent alternative to direct numerical simulation (DNS), offering\ncomputational efficiency. However, LES cannot accurately capture the full\nspectrum of turbulent transport scales and is present only at a lower spatial\nresolution. Reconstructing high-fidelity DNS data from the lower-resolution LES\ndata is essential for numerous applications, but it poses significant\nchallenges to existing super-resolution techniques, primarily due to the\ncomplex spatio-temporal nature of turbulent flows. This paper proposes a novel\nflow reconstruction approach that leverages physical knowledge to model flow\ndynamics. Different from traditional super-resolution techniques, the proposed\napproach uses LES data only in the testing phase through a degradation-based\nrefinement approach to enforce physical constraints and mitigate cumulative\nreconstruction errors over time. Furthermore, a feature sampling strategy is\ndeveloped to enable flow data reconstruction across different resolutions. The\nresults on two distinct sets of turbulent flow data indicate the effectiveness\nof the proposed method in reconstructing high-resolution DNS data, preserving\nthe inherent physical attributes of flow transport, and achieving DNS\nreconstruction at different resolutions.",
    "explanation":"his paper proposes a novel flow recon-\nstruction approach that leverages physical knowledge to\nmodel flow dynamics.",
    "b_id":[
      "b40"
    ],
    "b_title":[
      "Physics guided neural networks for spatio-temporal superresolution of turbulent flows"
    ],
    "b_abstract":[
      "Direct numerical simulation (DNS) of turbulent flows is computationally expensive and cannot be applied to flows with large Reynolds numbers. Low-resolution large eddy simulation (LES) is a popular alternative, but it is unable to capture all of the scales of turbulent transport accurately. Reconstructing DNS from low-resolution LES is critical for large-scale simulation in many scientific and engineering disciplines, but it poses many challenges to existing super-resolution methods due to the complexity of turbulent flows and computational cost of generating frequent LES data. We propose a physics-guided neural network for reconstructing frequent DNS from sparse LES data by enhancing its spatial resolution and temporal frequency. Our proposed method consists of a partial differential equation (PDE)-based recurrent unit for capturing underlying temporal processes and a physics-guided super-resolution model that incorporates additional physical constraints. We demonstrate the effectiveness of both components in reconstructing the Taylor-Green Vortex using sparse LES data. Moreover, we show that the proposed recurrent unit can preserve the physical characteristics of turbulent flows by leveraging the physical relationships in the Navier-Stokes equation."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.13966"
    ],
    "c_title":[
      "High-efficient machine learning projection method for incompressible\n  Navier-Stokes equations"
    ],
    "c_abstract":[
      "This study proposes a high-efficient machine learning (ML) projection method\nusing forward-generated data for incompressible Navier-Stokes equations. A\nPoisson neural network (Poisson-NN) embedded method and a wavelet transform\nconvolutional neural network multigrid (WTCNN-MG) method are proposed,\nintegrated into the projection method framework in patchwork and overall\ndifferentiable manners with MG method, respectively. The solution of the\npressure Poisson equation split from the Navier-Stokes equations is first\ngenerated either following a random field (e.g. Gaussian random field, GRF,\ncomputational complexity O(NlogN), N is the number of spatial points) or\nphysical laws (e.g. a kind of spectra, computational complexity O(NM), M is the\nnumber of modes), then the source terms, boundary conditions and initial\nconditions are constructed via balance of equations, avoiding the difficulties\nof obtaining high-fidelity training datasets. The feasibility of generated data\nfor training Poisson-NN and WTCNN as well as the acceleration performances of\nthe Poisson-NN embedded method and WTCNN-MG method are validated. The results\nindicate that even without any DNS data, the generated data can train these two\nmodels with excellent generalization and accuracy. The data following physical\nlaws can significantly improve the high-frequency approximation, convergence\nrate, generalization and accuracy than that generated following GRF. The ML\nprojection method offers significant improvements in computational efficiency.\nParticularly, the Poisson-NN embedded method achieves an average speed-up of\n5.83 times over the traditional MG method, while the WTCNN-MG method offers an\neven greater average speed-up of 7.03 times, demonstrating impressive\nacceleration performance."
    ],
    "c_categories":[
      [
        "physics.flu-dyn"
      ]
    ],
    "c_fields":[
      "Physics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.10196",
    "a_title":"High-dimensional Statistics Applications to Batch Effects in\n  Metabolomics",
    "a_abstract":"Batch effects are inevitable in large-scale metabolomics. Prior to formal\ndata analysis, batch effect correction (BEC) is applied to prevent from\nobscuring biological variations, and batch effect evaluation (BEE) is used for\ncorrection assessment. However, existing BEE algorithms neglect covariances\nbetween the variables, and existing BEC algorithms might fail to adequately\ncorrect the covariances. Therefore, we resort to recent advancements in\nhigh-dimensional statistics, and respectively propose \"quality control-based\nsimultaneous tests (QC-ST)\" and \"covariance correction (CoCo)\". Validated by\nthe simulation data, QC-ST can simultaneously detect the statistical\nsignificance of QC samples' mean vectors and covariance matrices across\ndifferent batches, and has a satisfactory statistical performance in empirical\nsizes, empirical powers, and computational speed. Then, we apply four QC-based\nBEC algorithms to two large cohort datasets, and find that extreme gradient\nboost (XGBoost) performs best in relative standard deviation (RSD) and\ndispersion-ratio (D-ratio). After prepositive BEC, if QC-ST still suggests that\nbatch effects between some two batches are significant, CoCo should be\nimplemented. And after CoCo (if necessary), the four metrics (i.e., RSD,\nD-ratio, classification performance, and QC-ST) might be further improved. In\nsummary, under the guidance of QC-ST, we can develop a matching strategy to\nintegrate multiple BEC algorithms more rationally and flexibly, and minimize\nbatch effects for reliable biological conclusions.",
    "explanation":"Batch effects are inevitable in large-scale metabolomics. Prior to formal data analysis, batch effect correction (BEC) is applied to prevent from obscuring biological variations, and batch effect evaluation (BEE) is used for correction assessment.we apply four QC-based BEC algorithms to two large cohort datasets, and find that extreme gradient boost (XGBoost) performs best in relative standard deviation (RSD) and dispersion-ratio (D-ratio).",
    "b_id":[
      "b0"
    ],
    "b_title":[
      "Quality assurance procedures for mass spectrometry untargeted metabolomics. a review"
    ],
    "b_abstract":[
      "Untargeted metabolomics, as a global approach, has already proven its great potential and capabilities for the investigation of health and disease, as well as the wide applicability for other research areas. Although great progress has been made on the feasibility of metabolomics experiments, there are still some challenges that should be faced and that includes all sources of fluctuations and bias affecting every step involved in multiplatform untargeted metabolomics studies. The identification and reduction of the main sources of unwanted variation regarding the pre-analytical, analytical and post-analytical phase of metabolomics experiments is essential to ensure high data quality. Nowadays, there is still a lack of information regarding harmonized guidelines for quality assurance as those available for targeted analysis. In this review, sources of variations to be considered and minimized along with methodologies and strategies for monitoring and improvement the quality of the results are discussed. The given information is based on evidences from different groups among our own experiences and recommendations for each stage of the metabolomics workflow. The comprehensive overview with tools presented here might serve other researchers interested in monitoring, controlling and improving the reliability of their findings by implementation of good experimental quality practices in the untargeted metabolomics study."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.07141"
    ],
    "c_title":[
      "Small steps no more: Global convergence of stochastic gradient bandits\n  for arbitrary learning rates"
    ],
    "c_abstract":[
      "We provide a new understanding of the stochastic gradient bandit algorithm by\nshowing that it converges to a globally optimal policy almost surely using\n\\emph{any} constant learning rate. This result demonstrates that the stochastic\ngradient algorithm continues to balance exploration and exploitation\nappropriately even in scenarios where standard smoothness and noise control\nassumptions break down. The proofs are based on novel findings about action\nsampling rates and the relationship between cumulative progress and noise, and\nextend the current understanding of how simple stochastic gradient methods\nbehave in bandit settings."
    ],
    "c_categories":[
      [
        "cs.LG"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.10196",
    "a_title":"High-dimensional Statistics Applications to Batch Effects in\n  Metabolomics",
    "a_abstract":"Batch effects are inevitable in large-scale metabolomics. Prior to formal\ndata analysis, batch effect correction (BEC) is applied to prevent from\nobscuring biological variations, and batch effect evaluation (BEE) is used for\ncorrection assessment. However, existing BEE algorithms neglect covariances\nbetween the variables, and existing BEC algorithms might fail to adequately\ncorrect the covariances. Therefore, we resort to recent advancements in\nhigh-dimensional statistics, and respectively propose \"quality control-based\nsimultaneous tests (QC-ST)\" and \"covariance correction (CoCo)\". Validated by\nthe simulation data, QC-ST can simultaneously detect the statistical\nsignificance of QC samples' mean vectors and covariance matrices across\ndifferent batches, and has a satisfactory statistical performance in empirical\nsizes, empirical powers, and computational speed. Then, we apply four QC-based\nBEC algorithms to two large cohort datasets, and find that extreme gradient\nboost (XGBoost) performs best in relative standard deviation (RSD) and\ndispersion-ratio (D-ratio). After prepositive BEC, if QC-ST still suggests that\nbatch effects between some two batches are significant, CoCo should be\nimplemented. And after CoCo (if necessary), the four metrics (i.e., RSD,\nD-ratio, classification performance, and QC-ST) might be further improved. In\nsummary, under the guidance of QC-ST, we can develop a matching strategy to\nintegrate multiple BEC algorithms more rationally and flexibly, and minimize\nbatch effects for reliable biological conclusions.",
    "explanation":"Batch effects are inevitable in large-scale metabolomics. Prior to formal data analysis, batch effect correction (BEC) is applied to prevent from obscuring biological variations, and batch effect evaluation (BEE) is used for correction assessment.we apply four QC-based BEC algorithms to two large cohort datasets, and find that extreme gradient boost (XGBoost) performs best in relative standard deviation (RSD) and dispersion-ratio (D-ratio).",
    "b_id":[
      "b16"
    ],
    "b_title":[
      "XGBoost: A Scalable Tree Boosting System"
    ],
    "b_abstract":[
      "Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems."
    ],
    "b_categories":[
      "cs.LG"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.02971"
    ],
    "c_title":[
      "Bowel Incision Closure with a Semi-Automated Robot-Assisted Laser Tissue\n  Soldering System"
    ],
    "c_abstract":[
      "Traditional methods for closing gastrointestinal (GI) surgery incisions, like\nsuturing and stapling, present significant challenges, including potentially\nlife-threatening leaks. These techniques, especially in robot-assisted\nminimally invasive surgery (RAMIS), require advanced manual skills. While their\nrepetitive and time-consuming nature makes them suitable candidates for\nautomation, the automation process is complicated by the need for extensive\ncontact with the tissue. Addressing this, we demonstrate a semi-autonomous\ncontactless surgical procedure using our novel Robot-assisted Laser Tissue\nSoldering (RLTS) system on a live porcine bowel. Towards this in-vivo\ndemonstration, we optimized soldering protocols and system parameters in\nex-vivo experiments on porcine bowels and a porcine cadaver. To assess the RLTS\nsystem performance, we compared the pressure at which the anastomosis leaked\nbetween our robotic soldering and manual suturing. With the best setup, we\nadvanced to an in-vivo Heineke Mikulicz closure on small bowel incision in live\npigs and evaluated their healing for two weeks. All pigs successfully\ncompleting the procedure (N=5) survived without leaks and the histology\nindicated mucosal regeneration and fibrous tissue adhesion. This marks the\nfirst in-vivo semi-automated contactless incision closure, paving the way for\nautomating GI surgery incision closure which has the potential to become an\nalternative to traditional methods."
    ],
    "c_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00225",
    "a_title":"Meta-learning Loss Functions of Parametric Partial Differential\n  Equations Using Physics-Informed Neural Networks",
    "a_abstract":"This paper proposes a new way to learn Physics-Informed Neural Network loss\nfunctions using Generalized Additive Models. We apply our method by\nmeta-learning parametric partial differential equations, PDEs, on Burger's and\n2D Heat Equations. The goal is to learn a new loss function for each parametric\nPDE using meta-learning. The derived loss function replaces the traditional\ndata loss, allowing us to learn each parametric PDE more efficiently, improving\nthe meta-learner's performance and convergence.",
    "explanation":"This paper proposes a new way to learn Physics-Informed Neural Network loss functions using Generalized Additive Models.We apply our method by meta-learning parametric partial differential equations, PDEs, on Burger\u2019s and 2D Heat Equations.",
    "b_id":[
      "b14"
    ],
    "b_title":[
      "The Burgers equation"
    ],
    "b_abstract":[
      "The Burgers equation is a simple equation to understand the main properties of the Navier-Stokes equations. In this one-dimensional equation the pressure is neglected but the effects of the nonlinear and viscous terms remain, hence as in the Navier-Stokes equations a Reynolds number can be defined. This number expresses the ratio between the advective and the viscous contribution in a flow. The present book deals with flows at high Reynolds numbers where the nonlinear terms play a fundamental role, and the physics is more complicated than that when the viscous term dominates. The simulation of the flow evolution then necessitates the use of accurate and robust numerical methods. In 3D turbulent flows, where the number of degrees of freedom is greater than in high Re laminar flows, to get solutions it is necessary to introduce some sort of closure to account for the impossibility to resolve the small scales. Before applying any new idea about numerical methods to 3D flows, the good sense suggests to find the simplest equation to test these ideas. This consideration explains why the Burgers equation was often used to check new numerical methods or closure for turbulent flows."
    ],
    "b_categories":[
      "math.AP"
    ],
    "b_fields":[
      "Mathematics and Statistics"
    ],
    "c_id":[
      "2502.07709"
    ],
    "c_title":[
      "MAGELLAN: Metacognitive predictions of learning progress guide autotelic\n  LLM agents in large goal spaces"
    ],
    "c_abstract":[
      "Open-ended learning agents must efficiently prioritize goals in vast\npossibility spaces, focusing on those that maximize learning progress (LP).\nWhen such autotelic exploration is achieved by LLM agents trained with online\nRL in high-dimensional and evolving goal spaces, a key challenge for LP\nprediction is modeling one's own competence, a form of metacognitive\nmonitoring. Traditional approaches either require extensive sampling or rely on\nbrittle expert-defined goal groupings. We introduce MAGELLAN, a metacognitive\nframework that lets LLM agents learn to predict their competence and LP online.\nBy capturing semantic relationships between goals, MAGELLAN enables\nsample-efficient LP estimation and dynamic adaptation to evolving goal spaces\nthrough generalization. In an interactive learning environment, we show that\nMAGELLAN improves LP prediction efficiency and goal prioritization, being the\nonly method allowing the agent to fully master a large and evolving goal space.\nThese results demonstrate how augmenting LLM agents with a metacognitive\nability for LP predictions can effectively scale curriculum learning to\nopen-ended goal spaces."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2412.00225",
    "a_title":"Meta-learning Loss Functions of Parametric Partial Differential\n  Equations Using Physics-Informed Neural Networks",
    "a_abstract":"This paper proposes a new way to learn Physics-Informed Neural Network loss\nfunctions using Generalized Additive Models. We apply our method by\nmeta-learning parametric partial differential equations, PDEs, on Burger's and\n2D Heat Equations. The goal is to learn a new loss function for each parametric\nPDE using meta-learning. The derived loss function replaces the traditional\ndata loss, allowing us to learn each parametric PDE more efficiently, improving\nthe meta-learner's performance and convergence.",
    "explanation":"This paper proposes a new way to learn Physics-Informed Neural Network loss functions using Generalized Additive Models.We apply our method by meta-learning parametric partial differential equations, PDEs, on Burger\u2019s and 2D Heat Equations.",
    "b_id":[
      "b17"
    ],
    "b_title":[
      "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations"
    ],
    "b_abstract":[
      "We introduce physics-informed neural networks \u2013 neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge\u2013Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction\u2013diffusion systems, and the propagation of nonlinear shallow-water waves."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2502.02049"
    ],
    "c_title":[
      "Normalized solutions to focusing Sobolev critical biharmonic\n  Schr\\\"{o}dinger equation with mixed dispersion"
    ],
    "c_abstract":[
      "This paper is concerned with the following focusing biharmonic\nSchr\\\"{o}dinger equation with mixed dispersion and Sobolev critical growth: $$\n\\begin{cases}\n  {\\Delta}^2u-\\Delta u-\\lambda u-\\mu|u|^{p-2}u-|u|^{4^*-2}u=0\\ \\ \\mbox{in}\\\n\\mathbb{R}^N, \\\\[0.1cm]\n  \\int_{\\mathbb{R}^N} u^2 dx = c, \\end{cases} $$ where $N \\geq 5$, $\\mu,c>0$,\n$2<p<4^*:=\\frac{2N}{N-4}$ and $\\lambda \\in \\mathbb{R}$ is a Lagrange\nmultiplier. For this problem, under the $L^2$-subcritical perturbation\n($2<p<2+\\frac{8}{N}$), we derive the existence and multiplicity of normalized\nsolutions via the truncation technique, concentration-compactness principle and\nthe genus theory presented by C.O. Alves et al. (Arxiv, (2021), doi:\n2103.07940v2). Compared to the results of C.O. Alves et al. we obtain a more\ngeneral result after removing the further assumptions given in (3.2) of their\npaper. In the case of $L^2$-supercritical perturbation ($2+\\frac{8}{N}<p<4^*$),\nwe explore the existence results of normalized solutions by applying the\nconstrained variational methods and the mountain pass theorem. Moreover, we\npropose a novel method to address the effects of the dispersion term $\\Delta\nu$. This approach allows us to extend the recent results obtained by X. Chang\net al. (Arxiv, (2023), doi: 2305.00327v1) to the mixed dispersion situation."
    ],
    "c_categories":[
      [
        "math.AP"
      ]
    ],
    "c_fields":[
      "Mathematics and Statistics"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05456",
    "a_title":"Comparative Study of Probabilistic Atlas and Deep Learning Approaches\n  for Automatic Brain Tissue Segmentation from MRI Using N4 Bias Field\n  Correction and Anisotropic Diffusion Pre-processing Techniques",
    "a_abstract":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI)\nimages is vital for accurate diagnosis and further analysis in medical imaging.\nDespite advancements in segmentation techniques, a comprehensive comparison\nbetween traditional statistical methods and modern deep learning approaches\nusing pre-processing techniques like N4 Bias Field Correction and Anisotropic\nDiffusion remains underexplored. This study provides a comparative analysis of\nvarious segmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and\nLinkNet, enhanced with these pre-processing techniques to segment brain tissues\n(white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF)) on the\nInternet Brain Segmentation Repository (IBSR18) dataset. Our results\ndemonstrate that the 3D nnU-Net model outperforms others, achieving the highest\nmean Dice Coefficient score (0.937 +- 0.012), while the 2D nnU-Net model\nrecorded the lowest mean Hausdorff Distance (5.005 +- 0.343 mm) and the lowest\nmean Absolute Volumetric Difference (3.695 +- 2.931 mm) across five unseen test\nsamples. The findings highlight the superiority of nnU-Net models in brain\ntissue segmentation, particularly when combined with N4 Bias Field Correction\nand Anisotropic Diffusion pre-processing techniques. Our implemented code can\nbe accessed via GitHub.",
    "explanation":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI) images is vital for accurate diagnosis and further analysis in medical imaging. \n\nThis study provides a comparative analysis of various\nsegmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and LinkNet, enhanced with these preprocessing techniques to segment brain tissue",
    "b_id":[
      "b3"
    ],
    "b_title":[
      "MRI segmentation of the human brain: challenges, methods, and applications"
    ],
    "b_abstract":[
      "Image segmentation is one of the most important tasks in medical image analysis and is often the first and the most critical step in many clinical applications. In brain MRI analysis, image segmentation is commonly used for measuring and visualizing the brain\u2019s anatomical structures, for analyzing brain changes, for delineating pathological regions, and for surgical planning and image-guided interventions. In the last few decades, various segmentation techniques of different accuracy and degree of complexity have been developed and reported in the literature. In this paper we review the most popular methods commonly used for brain MRI segmentation. We highlight differences between them and discuss their capabilities, advantages, and limitations. To address the complexity and challenges of the brain MRI segmentation problem, we first introduce the basic concepts of image segmentation. Then, we explain different MRI preprocessing steps including image registration, bias field correction, and removal of nonbrain tissue. Finally, after reviewing different brain MRI segmentation methods, we discuss the validation problem in brain MRI segmentation."
    ],
    "b_categories":[
      "q-bio.QM"
    ],
    "b_fields":[
      "Quantitative Biology"
    ],
    "c_id":[
      "2502.14102"
    ],
    "c_title":[
      "Explainable Distributed Constraint Optimization Problems"
    ],
    "c_abstract":[
      "The Distributed Constraint Optimization Problem (DCOP) formulation is a\npowerful tool to model cooperative multi-agent problems that need to be solved\ndistributively. A core assumption of existing approaches is that DCOP solutions\ncan be easily understood, accepted, and adopted, which may not hold, as\nevidenced by the large body of literature on Explainable AI. In this paper, we\npropose the Explainable DCOP (X-DCOP) model, which extends a DCOP to include\nits solution and a contrastive query for that solution. We formally define some\nkey properties that contrastive explanations must satisfy for them to be\nconsidered as valid solutions to X-DCOPs as well as theoretical results on the\nexistence of such valid explanations. To solve X-DCOPs, we propose a\ndistributed framework as well as several optimizations and suboptimal variants\nto find valid explanations. We also include a human user study that showed that\nusers, not surprisingly, prefer shorter explanations over longer ones. Our\nempirical evaluations showed that our approach can scale to large problems, and\nthe different variants provide different options for trading off explanation\nlengths for smaller runtimes. Thus, our model and algorithmic contributions\nextend the state of the art by reducing the barrier for users to understand\nDCOP solutions, facilitating their adoption in more real-world applications."
    ],
    "c_categories":[
      [
        "cs.AI"
      ]
    ],
    "c_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "y_true":false,
    "research_type":"applied"
  },
  {
    "id":"2411.05456",
    "a_title":"Comparative Study of Probabilistic Atlas and Deep Learning Approaches\n  for Automatic Brain Tissue Segmentation from MRI Using N4 Bias Field\n  Correction and Anisotropic Diffusion Pre-processing Techniques",
    "a_abstract":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI)\nimages is vital for accurate diagnosis and further analysis in medical imaging.\nDespite advancements in segmentation techniques, a comprehensive comparison\nbetween traditional statistical methods and modern deep learning approaches\nusing pre-processing techniques like N4 Bias Field Correction and Anisotropic\nDiffusion remains underexplored. This study provides a comparative analysis of\nvarious segmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and\nLinkNet, enhanced with these pre-processing techniques to segment brain tissues\n(white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF)) on the\nInternet Brain Segmentation Repository (IBSR18) dataset. Our results\ndemonstrate that the 3D nnU-Net model outperforms others, achieving the highest\nmean Dice Coefficient score (0.937 +- 0.012), while the 2D nnU-Net model\nrecorded the lowest mean Hausdorff Distance (5.005 +- 0.343 mm) and the lowest\nmean Absolute Volumetric Difference (3.695 +- 2.931 mm) across five unseen test\nsamples. The findings highlight the superiority of nnU-Net models in brain\ntissue segmentation, particularly when combined with N4 Bias Field Correction\nand Anisotropic Diffusion pre-processing techniques. Our implemented code can\nbe accessed via GitHub.",
    "explanation":"Automatic brain tissue segmentation from Magnetic Resonance Imaging (MRI) images is vital for accurate diagnosis and further analysis in medical imaging. \n\nThis study provides a comparative analysis of various\nsegmentation models, including Probabilistic ATLAS, U-Net, nnU-Net, and LinkNet, enhanced with these preprocessing techniques to segment brain tissue",
    "b_id":[
      "b11"
    ],
    "b_title":[
      "U-net: Convolutional networks for biomedical image segmentation"
    ],
    "b_abstract":[
      "There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU."
    ],
    "b_categories":[
      "cs.AI"
    ],
    "b_fields":[
      "Computer Science, Electrical Engineering and Systems Science"
    ],
    "c_id":[
      "2501.04147"
    ],
    "c_title":[
      "A Framework for Building Enviromics Matrices in Mixed Models"
    ],
    "c_abstract":[
      "This study introduces a framework for constructing enviromics matrices in\nmixed models to integrate genetic and environmental data to enhance phenotypic\npredictions in plant breeding. Enviromics utilizes diverse data sources, such\nas climate and soil, to characterize genotype-by-environment (GxE)\ninteractions. The approach employs block-diagonal structures in the design\nmatrix to incorporate random effects from genetic and envirotypic covariates\nacross trials. The covariance structure is modeled using the Kronecker product\nof the genetic relationship matrix and an identity matrix representing\nenvirotypic effects, capturing genetic and environmental variability. This dual\nrepresentation enables more accurate crop performance predictions across\nenvironments, improving selection strategies in breeding programs. The\nframework is compatible with existing mixed model software, including rrBLUP\nand BGLR, and can be extended for more complex interactions. By combining\ngenetic relationships and environmental influences, this approach offers a\npowerful tool for advancing GxE studies and accelerating the development of\nimproved crop varieties."
    ],
    "c_categories":[
      [
        "q-bio.QM"
      ]
    ],
    "c_fields":[
      "Quantitative Biology"
    ],
    "y_true":false,
    "research_type":"applied"
  }
]